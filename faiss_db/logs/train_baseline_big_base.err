INFO:root:Output: big_baseline_base
INFO:root:Steps per epochs:248
INFO:root:Total steps:49600
Some weights of the model checkpoint at bert-base-uncased were not used when initializing RetrievalGenerationModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing RetrievalGenerationModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RetrievalGenerationModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/200 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
INFO:root:current mean train loss 68642.48508522728
INFO:root:current train perplexity876.1915283203125
INFO:root:current mean train loss 55723.46445116206
INFO:root:current train perplexity242.8968048095703


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.16s/it]
INFO:root:final mean train loss: 51161.530281313004
INFO:root:final train perplexity: 155.42697143554688
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it]
INFO:root:eval mean loss: 30560.20968191964
INFO:root:eval perplexity: 23.63787078857422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/1

  0%|          | 1/200 [01:08<3:46:21, 68.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 29354.370902267157
INFO:root:current train perplexity18.105253219604492
INFO:root:current mean train loss 27463.289243584437
INFO:root:current train perplexity14.967013359069824


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.13s/it]
INFO:root:final mean train loss: 26053.34041078629
INFO:root:final train perplexity: 13.06189250946045
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.51s/it]
INFO:root:eval mean loss: 25060.118094308036
INFO:root:eval perplexity: 13.378033638000488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/2

  1%|          | 2/200 [02:02<3:18:06, 60.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 22635.4921875
INFO:root:current train perplexity9.223062515258789
INFO:root:current mean train loss 22125.909113319176
INFO:root:current train perplexity8.866670608520508
INFO:root:current mean train loss 21668.04087130542
INFO:root:current train perplexity8.463598251342773


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it]
INFO:root:final mean train loss: 21482.20070722026
INFO:root:final train perplexity: 8.321456909179688
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it]
INFO:root:eval mean loss: 23606.846284412204
INFO:root:eval perplexity: 11.509894371032715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/3

  2%|â–         | 3/200 [02:56<3:08:31, 57.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20258.77666903409
INFO:root:current train perplexity7.347653865814209
INFO:root:current mean train loss 20048.026890120967
INFO:root:current train perplexity7.214231014251709


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.18s/it]
INFO:root:final mean train loss: 19886.274949596773
INFO:root:final train perplexity: 7.109470844268799
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.51s/it]
INFO:root:eval mean loss: 23053.09835379464
INFO:root:eval perplexity: 10.868799209594727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/4

  2%|â–         | 4/200 [03:51<3:03:32, 56.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19125.315290178572
INFO:root:current train perplexity6.730858325958252
INFO:root:current mean train loss 19226.79866384346
INFO:root:current train perplexity6.634002685546875
INFO:root:current mean train loss 19102.11814990942
INFO:root:current train perplexity6.572622776031494


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.30s/it]
INFO:root:final mean train loss: 19044.29439027848
INFO:root:final train perplexity: 6.542904853820801
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it]
INFO:root:eval mean loss: 22725.4931640625
INFO:root:eval perplexity: 10.506462097167969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/5

  2%|â–Ž         | 5/200 [04:45<3:00:24, 55.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18615.587129237287
INFO:root:current train perplexity6.270985126495361
INFO:root:current mean train loss 18572.38593258648
INFO:root:current train perplexity6.226354598999023


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.23s/it]
INFO:root:final mean train loss: 18481.086748676917
INFO:root:final train perplexity: 6.189355373382568
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.57s/it]
INFO:root:eval mean loss: 22553.468122209822
INFO:root:eval perplexity: 10.321061134338379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/6

  3%|â–Ž         | 6/200 [05:39<2:58:18, 55.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18361.717507102272
INFO:root:current train perplexity5.999767780303955
INFO:root:current mean train loss 18131.852917370496
INFO:root:current train perplexity5.954414367675781
INFO:root:current mean train loss 18095.416358116112
INFO:root:current train perplexity5.945565700531006


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.17s/it]
INFO:root:final mean train loss: 18054.35162156628
INFO:root:final train perplexity: 5.934252738952637
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.40s/it]
INFO:root:eval mean loss: 22382.300316220237
INFO:root:eval perplexity: 10.139833450317383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/7

  4%|â–Ž         | 7/200 [06:35<2:57:27, 55.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17808.395399305555
INFO:root:current train perplexity5.766366004943848
INFO:root:current mean train loss 17749.803309528375
INFO:root:current train perplexity5.753777027130127


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.17s/it]
INFO:root:final mean train loss: 17720.73131142893
INFO:root:final train perplexity: 5.742159843444824
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it]
INFO:root:eval mean loss: 22249.620535714286
INFO:root:eval perplexity: 10.001547813415527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/8

  4%|â–         | 8/200 [07:29<2:55:35, 54.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17589.4859375
INFO:root:current train perplexity5.62197208404541
INFO:root:current mean train loss 17486.165608016305
INFO:root:current train perplexity5.592577934265137
INFO:root:current mean train loss 17455.255922965116
INFO:root:current train perplexity5.586699485778809


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.41s/it]
INFO:root:final mean train loss: 17425.169654107864
INFO:root:final train perplexity: 5.577181816101074
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it]
INFO:root:eval mean loss: 22191.34375
INFO:root:eval perplexity: 9.941405296325684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/9

  4%|â–         | 9/200 [08:23<2:54:18, 54.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17167.0526614972
INFO:root:current train perplexity5.438899040222168
INFO:root:current mean train loss 17240.88751988211
INFO:root:current train perplexity5.4519758224487305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it]
INFO:root:final mean train loss: 17181.796516664566
INFO:root:final train perplexity: 5.444897174835205
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.50s/it]
INFO:root:eval mean loss: 22157.14892578125
INFO:root:eval perplexity: 9.906283378601074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/10

  5%|â–Œ         | 10/200 [09:18<2:52:58, 54.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16953.88209292763
INFO:root:current train perplexity5.342830181121826
INFO:root:current mean train loss 16988.11321559874
INFO:root:current train perplexity5.325374603271484
INFO:root:current mean train loss 16972.48764804509
INFO:root:current train perplexity5.326448917388916


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.33s/it]
INFO:root:final mean train loss: 16953.499188823083
INFO:root:final train perplexity: 5.323662757873535
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.53s/it]
INFO:root:eval mean loss: 22120.137555803572
INFO:root:eval perplexity: 9.86841106414795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/11

  6%|â–Œ         | 11/200 [10:12<2:52:04, 54.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16810.51131987236
INFO:root:current train perplexity5.2348456382751465
INFO:root:current mean train loss 16791.49092539291
INFO:root:current train perplexity5.226010322570801


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.30s/it]
INFO:root:final mean train loss: 16761.492159935737
INFO:root:final train perplexity: 5.223791599273682
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.48s/it]
INFO:root:eval mean loss: 22087.060105096727
INFO:root:eval perplexity: 9.834687232971191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/12

  6%|â–Œ         | 12/200 [11:07<2:50:55, 54.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16485.822138247284
INFO:root:current train perplexity5.108064651489258
INFO:root:current mean train loss 16584.84954585874
INFO:root:current train perplexity5.130079746246338
INFO:root:current mean train loss 16592.33922190303
INFO:root:current train perplexity5.132432460784912


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.26s/it]
INFO:root:final mean train loss: 16579.099692067794
INFO:root:final train perplexity: 5.130656719207764
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.51s/it]
INFO:root:eval mean loss: 22056.230654761905
INFO:root:eval perplexity: 9.803354263305664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/13

  6%|â–‹         | 13/200 [12:01<2:49:52, 54.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16399.6766796875
INFO:root:current train perplexity5.025201797485352
INFO:root:current mean train loss 16417.501863839287
INFO:root:current train perplexity5.033592224121094


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.36s/it]
INFO:root:final mean train loss: 16408.49628669985
INFO:root:final train perplexity: 5.045045375823975
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it]
INFO:root:eval mean loss: 22023.50711495536
INFO:root:eval perplexity: 9.770209312438965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/14

  7%|â–‹         | 14/200 [12:55<2:48:52, 54.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16195.453088831018
INFO:root:current train perplexity4.960155963897705
INFO:root:current mean train loss 16246.206039308563
INFO:root:current train perplexity4.966325283050537
INFO:root:current mean train loss 16259.123610441906
INFO:root:current train perplexity4.9643473625183105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.32s/it]
INFO:root:final mean train loss: 16248.239915417087
INFO:root:final train perplexity: 4.965927600860596
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it]
INFO:root:eval mean loss: 22028.240187872023
INFO:root:eval perplexity: 9.77499771118164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/15

  8%|â–Š         | 15/200 [13:50<2:47:53, 54.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16118.67852551424
INFO:root:current train perplexity4.873433589935303
INFO:root:current mean train loss 16108.984582314944
INFO:root:current train perplexity4.8838958740234375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it]
INFO:root:final mean train loss: 16102.632784935737
INFO:root:final train perplexity: 4.895118236541748
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it]
INFO:root:eval mean loss: 22004.473074776786
INFO:root:eval perplexity: 9.750982284545898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/16
###############################best#####################
  8%|â–Š         | 16/200 [14:44<2:46:55, 54.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16027.5986328125
INFO:root:current train perplexity4.810408115386963
INFO:root:current mean train loss 15939.464038645037
INFO:root:current train perplexity4.821068286895752
INFO:root:current mean train loss 15973.231977982954
INFO:root:current train perplexity4.829169273376465


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.12s/it]
INFO:root:final mean train loss: 15966.255894814769
INFO:root:final train perplexity: 4.829714775085449
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it]
INFO:root:eval mean loss: 22039.698149181546
INFO:root:eval perplexity: 9.786596298217773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/17

  8%|â–Š         | 17/200 [15:38<2:45:47, 54.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15819.760400978916
INFO:root:current train perplexity4.756982326507568
INFO:root:current mean train loss 15812.04788891735
INFO:root:current train perplexity4.761519432067871


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.31s/it]
INFO:root:final mean train loss: 15835.986351751511
INFO:root:final train perplexity: 4.768056392669678
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it]
INFO:root:eval mean loss: 22026.443894159227
INFO:root:eval perplexity: 9.77318000793457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/18

  9%|â–‰         | 18/200 [16:33<2:44:53, 54.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15686.316629464285
INFO:root:current train perplexity4.672750949859619
INFO:root:current mean train loss 15689.020985243056
INFO:root:current train perplexity4.701974391937256
INFO:root:current mean train loss 15724.553631981384
INFO:root:current train perplexity4.708709716796875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.16s/it]
INFO:root:final mean train loss: 15710.945592080394
INFO:root:final train perplexity: 4.7096123695373535
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it]
INFO:root:eval mean loss: 22018.37658110119
INFO:root:eval perplexity: 9.76502513885498
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/19

 10%|â–‰         | 19/200 [17:27<2:43:51, 54.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15533.682583512931
INFO:root:current train perplexity4.632473468780518
INFO:root:current mean train loss 15575.872049423462
INFO:root:current train perplexity4.646869659423828


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.16s/it]
INFO:root:final mean train loss: 15590.529127551663
INFO:root:final train perplexity: 4.654007911682129
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it]
INFO:root:eval mean loss: 22039.898414248513
INFO:root:eval perplexity: 9.7868013381958
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/20

 10%|â–ˆ         | 20/200 [18:21<2:42:51, 54.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15364.579326923076
INFO:root:current train perplexity4.571551322937012
INFO:root:current mean train loss 15460.661062556204
INFO:root:current train perplexity4.593350887298584
INFO:root:current mean train loss 15487.338883531642
INFO:root:current train perplexity4.601739883422852


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.09s/it]
INFO:root:final mean train loss: 15477.328239194809
INFO:root:final train perplexity: 4.602334022521973
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it]
INFO:root:eval mean loss: 22138.00023251488
INFO:root:eval perplexity: 9.88667106628418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/21

 10%|â–ˆ         | 21/200 [19:15<2:41:47, 54.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15342.559817135989
INFO:root:current train perplexity4.540908336639404
INFO:root:current mean train loss 15393.371385184882
INFO:root:current train perplexity4.551445484161377


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it]
INFO:root:final mean train loss: 15367.13095388105
INFO:root:final train perplexity: 4.552581310272217
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it]
INFO:root:eval mean loss: 22115.418108258928
INFO:root:eval perplexity: 9.863593101501465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/22

 11%|â–ˆ         | 22/200 [20:10<2:40:54, 54.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15175.275504178779
INFO:root:current train perplexity4.45937442779541
INFO:root:current mean train loss 15222.67832850743
INFO:root:current train perplexity4.484677791595459
INFO:root:current mean train loss 15273.233494888118
INFO:root:current train perplexity4.504295349121094


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.52s/it]
INFO:root:final mean train loss: 15261.331377583165
INFO:root:final train perplexity: 4.505321025848389
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it]
INFO:root:eval mean loss: 22123.237165178572
INFO:root:eval perplexity: 9.871578216552734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/23

 12%|â–ˆâ–        | 23/200 [21:04<2:40:18, 54.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15148.841354851973
INFO:root:current train perplexity4.448780536651611
INFO:root:current mean train loss 15171.361778846154
INFO:root:current train perplexity4.456735610961914


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.42s/it]
INFO:root:final mean train loss: 15157.655328566028
INFO:root:final train perplexity: 4.4594855308532715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it]
INFO:root:eval mean loss: 22200.87927827381
INFO:root:eval perplexity: 9.95122241973877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/24

 12%|â–ˆâ–        | 24/200 [21:59<2:39:33, 54.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15021.917386968085
INFO:root:current train perplexity4.404242992401123
INFO:root:current mean train loss 15059.465023118622
INFO:root:current train perplexity4.408941268920898
INFO:root:current mean train loss 15069.734094287702
INFO:root:current train perplexity4.4161176681518555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.27s/it]
INFO:root:final mean train loss: 15058.38039078251
INFO:root:final train perplexity: 4.416032314300537
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it]
INFO:root:eval mean loss: 22239.967447916668
INFO:root:eval perplexity: 9.991559028625488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/25

 12%|â–ˆâ–Ž        | 25/200 [22:53<2:38:33, 54.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14908.000325520834
INFO:root:current train perplexity4.348968029022217
INFO:root:current mean train loss 14953.874131399183
INFO:root:current train perplexity4.3661041259765625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.31s/it]
INFO:root:final mean train loss: 14958.784286006805
INFO:root:final train perplexity: 4.372864723205566
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it]
INFO:root:eval mean loss: 22241.477027529763
INFO:root:eval perplexity: 9.993119239807129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/26

 13%|â–ˆâ–Ž        | 26/200 [23:47<2:37:37, 54.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14765.509286917892
INFO:root:current train perplexity4.296664237976074
INFO:root:current mean train loss 14818.556065035182
INFO:root:current train perplexity4.315237522125244


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it]
INFO:root:final mean train loss: 14868.4790984123
INFO:root:final train perplexity: 4.3340888023376465
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.40s/it]
INFO:root:eval mean loss: 22275.870442708332
INFO:root:eval perplexity: 10.028757095336914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/27

 14%|â–ˆâ–Ž        | 27/200 [24:42<2:36:34, 54.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14662.5625
INFO:root:current train perplexity4.24372673034668
INFO:root:current mean train loss 14765.257983161408
INFO:root:current train perplexity4.280629634857178
INFO:root:current mean train loss 14775.81486203048
INFO:root:current train perplexity4.288101673126221


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.02s/it]
INFO:root:final mean train loss: 14771.89441311744
INFO:root:final train perplexity: 4.292996406555176
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it]
INFO:root:eval mean loss: 22340.354096912204
INFO:root:eval perplexity: 10.095911026000977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/28

 14%|â–ˆâ–        | 28/200 [25:36<2:35:28, 54.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14600.41532315341
INFO:root:current train perplexity4.234006404876709
INFO:root:current mean train loss 14635.69966607863
INFO:root:current train perplexity4.243224620819092


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.46s/it]
INFO:root:final mean train loss: 14678.494554088962
INFO:root:final train perplexity: 4.253630638122559
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it]
INFO:root:eval mean loss: 22323.594215029763
INFO:root:eval perplexity: 10.078412055969238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/29

 14%|â–ˆâ–        | 29/200 [26:30<2:34:47, 54.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14485.434291294643
INFO:root:current train perplexity4.2353692054748535
INFO:root:current mean train loss 14580.085362514603
INFO:root:current train perplexity4.199037075042725
INFO:root:current mean train loss 14590.373603562803
INFO:root:current train perplexity4.214887619018555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.02s/it]
INFO:root:final mean train loss: 14593.69228830645
INFO:root:final train perplexity: 4.218199729919434
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it]
INFO:root:eval mean loss: 22414.83972749256
INFO:root:eval perplexity: 10.174038887023926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/30

 15%|â–ˆâ–Œ        | 30/200 [27:24<2:33:38, 54.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14464.537274894068
INFO:root:current train perplexity4.1726975440979
INFO:root:current mean train loss 14500.796580188678
INFO:root:current train perplexity4.176525592803955


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it]
INFO:root:final mean train loss: 14504.799399099042
INFO:root:final train perplexity: 4.18137788772583
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it]
INFO:root:eval mean loss: 22420.394438244046
INFO:root:eval perplexity: 10.179888725280762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/31

 16%|â–ˆâ–Œ        | 31/200 [28:18<2:32:48, 54.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14395.492453835228
INFO:root:current train perplexity4.103132247924805
INFO:root:current mean train loss 14412.203054617117
INFO:root:current train perplexity4.131381511688232
INFO:root:current mean train loss 14429.754632886552
INFO:root:current train perplexity4.145163059234619


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.06s/it]
INFO:root:final mean train loss: 14418.5134749874
INFO:root:final train perplexity: 4.145942687988281
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it]
INFO:root:eval mean loss: 22459.379371279763
INFO:root:eval perplexity: 10.221044540405273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/32

 16%|â–ˆâ–Œ        | 32/200 [29:13<2:31:46, 54.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14349.999906994048
INFO:root:current train perplexity4.095570087432861
INFO:root:current mean train loss 14339.83098878451
INFO:root:current train perplexity4.109313488006592


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.26s/it]
INFO:root:final mean train loss: 14336.640302104335
INFO:root:final train perplexity: 4.112597465515137
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.38s/it]
INFO:root:eval mean loss: 22539.11063058036
INFO:root:eval perplexity: 10.305736541748047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/33

 16%|â–ˆâ–‹        | 33/200 [30:07<2:30:52, 54.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14094.375520833333
INFO:root:current train perplexity4.023701190948486
INFO:root:current mean train loss 14217.308890964674
INFO:root:current train perplexity4.06247615814209
INFO:root:current mean train loss 14255.9546875
INFO:root:current train perplexity4.079824447631836


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.94s/it]
INFO:root:final mean train loss: 14254.695655084426
INFO:root:final train perplexity: 4.079492092132568
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.39s/it]
INFO:root:eval mean loss: 22538.894438244046
INFO:root:eval perplexity: 10.305505752563477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/34

 17%|â–ˆâ–‹        | 34/200 [31:01<2:29:44, 54.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14149.619169776119
INFO:root:current train perplexity4.0412516593933105
INFO:root:current mean train loss 14160.635531671032
INFO:root:current train perplexity4.04572057723999


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.11s/it]
INFO:root:final mean train loss: 14178.607571509576
INFO:root:final train perplexity: 4.0489912033081055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.39s/it]
INFO:root:eval mean loss: 22609.48572358631
INFO:root:eval perplexity: 10.381072044372559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/35

 18%|â–ˆâ–Š        | 35/200 [31:55<2:28:49, 54.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14016.237253289473
INFO:root:current train perplexity4.000923156738281
INFO:root:current mean train loss 14070.28077402836
INFO:root:current train perplexity4.007638454437256
INFO:root:current mean train loss 14088.793517230308
INFO:root:current train perplexity4.010589599609375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.34s/it]
INFO:root:final mean train loss: 14094.596510364163
INFO:root:final train perplexity: 4.015578746795654
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it]
INFO:root:eval mean loss: 22617.73204985119
INFO:root:eval perplexity: 10.389936447143555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/36

 18%|â–ˆâ–Š        | 36/200 [32:49<2:28:08, 54.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14010.6728515625
INFO:root:current train perplexity3.9860801696777344
INFO:root:current mean train loss 14022.613738121345
INFO:root:current train perplexity3.982393503189087


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.28s/it]
INFO:root:final mean train loss: 14017.484697895665
INFO:root:final train perplexity: 3.9851531982421875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.39s/it]
INFO:root:eval mean loss: 22670.96435546875
INFO:root:eval perplexity: 10.447334289550781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/37

 18%|â–ˆâ–Š        | 37/200 [33:43<2:27:18, 54.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13855.333092730978
INFO:root:current train perplexity3.9122204780578613
INFO:root:current mean train loss 13901.95318851626
INFO:root:current train perplexity3.9309017658233643
INFO:root:current mean train loss 13940.945894934137
INFO:root:current train perplexity3.952274799346924


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.99s/it]
INFO:root:final mean train loss: 13935.924131331905
INFO:root:final train perplexity: 3.953223705291748
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it]
INFO:root:eval mean loss: 22724.085867745536
INFO:root:eval perplexity: 10.504931449890137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/38

 19%|â–ˆâ–‰        | 38/200 [34:38<2:26:20, 54.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13855.103307291667
INFO:root:current train perplexity3.9066038131713867
INFO:root:current mean train loss 13858.388364955357
INFO:root:current train perplexity3.915895700454712


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.21s/it]
INFO:root:final mean train loss: 13858.544787991432
INFO:root:final train perplexity: 3.9231674671173096
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.40s/it]
INFO:root:eval mean loss: 22757.863188244046
INFO:root:eval perplexity: 10.541720390319824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/39

 20%|â–ˆâ–‰        | 39/200 [35:32<2:25:27, 54.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13770.723415798611
INFO:root:current train perplexity3.868992328643799
INFO:root:current mean train loss 13787.313199741633
INFO:root:current train perplexity3.8840410709381104
INFO:root:current mean train loss 13789.648893515969
INFO:root:current train perplexity3.892563819885254


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it]
INFO:root:final mean train loss: 13784.843797253025
INFO:root:final train perplexity: 3.89475154876709
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it]
INFO:root:eval mean loss: 22835.734049479168
INFO:root:eval perplexity: 10.62702465057373
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/40

 20%|â–ˆâ–ˆ        | 40/200 [36:26<2:24:32, 54.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13676.810831190665
INFO:root:current train perplexity3.8520069122314453
INFO:root:current mean train loss 13699.102653631286
INFO:root:current train perplexity3.8633100986480713


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.24s/it]
INFO:root:final mean train loss: 13713.803549489667
INFO:root:final train perplexity: 3.8675572872161865
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.39s/it]
INFO:root:eval mean loss: 22855.97581845238
INFO:root:eval perplexity: 10.649308204650879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/41

 20%|â–ˆâ–ˆ        | 41/200 [37:20<2:23:39, 54.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13574.14314516129
INFO:root:current train perplexity3.81201434135437
INFO:root:current mean train loss 13609.722939527672
INFO:root:current train perplexity3.8246607780456543
INFO:root:current mean train loss 13640.948960869859
INFO:root:current train perplexity3.838226079940796


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.30s/it]
INFO:root:final mean train loss: 13637.225912770917
INFO:root:final train perplexity: 3.8384552001953125
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.40s/it]
INFO:root:eval mean loss: 22913.114234561013
INFO:root:eval perplexity: 10.712471961975098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/42

 21%|â–ˆâ–ˆ        | 42/200 [38:15<2:22:49, 54.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13545.62934158509
INFO:root:current train perplexity3.7869784832000732
INFO:root:current mean train loss 13554.911783854166
INFO:root:current train perplexity3.800539255142212


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it]
INFO:root:final mean train loss: 13567.679951329384
INFO:root:final train perplexity: 3.812215805053711
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it]
INFO:root:eval mean loss: 22928.767113095237
INFO:root:eval perplexity: 10.729838371276855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/43

 22%|â–ˆâ–ˆâ–       | 43/200 [39:09<2:21:55, 54.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13423.330524553572
INFO:root:current train perplexity3.764669179916382
INFO:root:current mean train loss 13479.11752025463
INFO:root:current train perplexity3.777852773666382
INFO:root:current mean train loss 13509.102721908244
INFO:root:current train perplexity3.7834525108337402


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.23s/it]
INFO:root:final mean train loss: 13496.752657982612
INFO:root:final train perplexity: 3.785639762878418
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it]
INFO:root:eval mean loss: 23006.59558686756
INFO:root:eval perplexity: 10.81661605834961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/44

 22%|â–ˆâ–ˆâ–       | 44/200 [40:03<2:21:04, 54.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13426.040184985632
INFO:root:current train perplexity3.752265453338623
INFO:root:current mean train loss 13418.480218081551
INFO:root:current train perplexity3.7566025257110596


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.40s/it]
INFO:root:final mean train loss: 13430.962780367943
INFO:root:final train perplexity: 3.7611546516418457
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.39s/it]
INFO:root:eval mean loss: 23003.602074032737
INFO:root:eval perplexity: 10.81326675415039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/45

 22%|â–ˆâ–ˆâ–Ž       | 45/200 [40:57<2:20:15, 54.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13328.289463141025
INFO:root:current train perplexity3.7089831829071045
INFO:root:current mean train loss 13331.952633205936
INFO:root:current train perplexity3.719879388809204
INFO:root:current mean train loss 13363.075742841265
INFO:root:current train perplexity3.733248472213745


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.09s/it]
INFO:root:final mean train loss: 13359.50066548009
INFO:root:final train perplexity: 3.734736919403076
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it]
INFO:root:eval mean loss: 23093.950846354168
INFO:root:eval perplexity: 10.9148530960083
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/46

 23%|â–ˆâ–ˆâ–Ž       | 46/200 [41:54<2:20:53, 54.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13228.934752747253
INFO:root:current train perplexity3.6854708194732666
INFO:root:current mean train loss 13288.569003599476
INFO:root:current train perplexity3.7021539211273193


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.17s/it]
INFO:root:final mean train loss: 13291.334307270665
INFO:root:final train perplexity: 3.7097110748291016
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.39s/it]
INFO:root:eval mean loss: 23115.424990699405
INFO:root:eval perplexity: 10.939136505126953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/47

 24%|â–ˆâ–ˆâ–Ž       | 47/200 [42:48<2:19:26, 54.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13227.883584665698
INFO:root:current train perplexity3.6590709686279297
INFO:root:current mean train loss 13216.369666466346
INFO:root:current train perplexity3.6754612922668457
INFO:root:current mean train loss 13233.435337898663
INFO:root:current train perplexity3.684312105178833


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.46s/it]
INFO:root:final mean train loss: 13221.331046811996
INFO:root:final train perplexity: 3.68418550491333
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.51s/it]
INFO:root:eval mean loss: 23186.7607421875
INFO:root:eval perplexity: 11.0201997756958
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/48

 24%|â–ˆâ–ˆâ–       | 48/200 [43:43<2:18:28, 54.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13123.592300575658
INFO:root:current train perplexity3.637303352355957
INFO:root:current mean train loss 13152.740710136219
INFO:root:current train perplexity3.652839183807373


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.03s/it]
INFO:root:final mean train loss: 13152.847353043095
INFO:root:final train perplexity: 3.6593832969665527
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it]
INFO:root:eval mean loss: 23234.662644159227
INFO:root:eval perplexity: 11.074967384338379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/49

 24%|â–ˆâ–ˆâ–       | 49/200 [44:37<2:17:08, 54.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13033.852580618352
INFO:root:current train perplexity3.611811637878418
INFO:root:current mean train loss 13057.014116974915
INFO:root:current train perplexity3.6257309913635254
INFO:root:current mean train loss 13098.778893598179
INFO:root:current train perplexity3.63619065284729


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.25s/it]
INFO:root:final mean train loss: 13088.07572297127
INFO:root:final train perplexity: 3.6360795497894287
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.53s/it]
INFO:root:eval mean loss: 23265.978190104168
INFO:root:eval perplexity: 11.110920906066895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/50

 25%|â–ˆâ–ˆâ–Œ       | 50/200 [45:31<2:16:09, 54.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12984.388070154671
INFO:root:current train perplexity3.5942180156707764
INFO:root:current mean train loss 13014.253695233983
INFO:root:current train perplexity3.608734369277954


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.28s/it]
INFO:root:final mean train loss: 13022.089745306199
INFO:root:final train perplexity: 3.6124916076660156
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.51s/it]
INFO:root:eval mean loss: 23335.215634300595
INFO:root:eval perplexity: 11.190823554992676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/51

 26%|â–ˆâ–ˆâ–Œ       | 51/200 [46:25<2:15:11, 54.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12942.615310968138
INFO:root:current train perplexity3.5695881843566895
INFO:root:current mean train loss 12952.049429584024
INFO:root:current train perplexity3.5836095809936523


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.10s/it]
INFO:root:final mean train loss: 12957.785014490928
INFO:root:final train perplexity: 3.5896518230438232
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it]
INFO:root:eval mean loss: 23361.451474144345
INFO:root:eval perplexity: 11.221254348754883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/52

 26%|â–ˆâ–ˆâ–Œ       | 52/200 [47:20<2:14:04, 54.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12834.664713541666
INFO:root:current train perplexity3.5351550579071045
INFO:root:current mean train loss 12868.687594811894
INFO:root:current train perplexity3.5614371299743652
INFO:root:current mean train loss 12888.269112723214
INFO:root:current train perplexity3.5618443489074707


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.31s/it]
INFO:root:final mean train loss: 12897.817796276462
INFO:root:final train perplexity: 3.5684826374053955
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.40s/it]
INFO:root:eval mean loss: 23411.570638020832
INFO:root:eval perplexity: 11.279608726501465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/53

 26%|â–ˆâ–ˆâ–‹       | 53/200 [48:14<2:13:09, 54.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12795.829438920455
INFO:root:current train perplexity3.517200231552124
INFO:root:current mean train loss 12833.713098538306
INFO:root:current train perplexity3.5356431007385254


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.08s/it]
INFO:root:final mean train loss: 12833.72326266381
INFO:root:final train perplexity: 3.545994758605957
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it]
INFO:root:eval mean loss: 23461.160946800595
INFO:root:eval perplexity: 11.33764934539795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/54

 27%|â–ˆâ–ˆâ–‹       | 54/200 [49:08<2:12:05, 54.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12800.560965401786
INFO:root:current train perplexity3.4977974891662598
INFO:root:current mean train loss 12725.446590245327
INFO:root:current train perplexity3.506866693496704
INFO:root:current mean train loss 12761.672162779287
INFO:root:current train perplexity3.5187644958496094


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.33s/it]
INFO:root:final mean train loss: 12766.440315492691
INFO:root:final train perplexity: 3.522540807723999
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it]
INFO:root:eval mean loss: 23521.210472470237
INFO:root:eval perplexity: 11.408329963684082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/55

 28%|â–ˆâ–ˆâ–Š       | 55/200 [50:02<2:11:13, 54.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12626.01598914195
INFO:root:current train perplexity3.477004289627075
INFO:root:current mean train loss 12684.586023486636
INFO:root:current train perplexity3.4915530681610107


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.15s/it]
INFO:root:final mean train loss: 12704.188893964214
INFO:root:final train perplexity: 3.5009779930114746
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.48s/it]
INFO:root:eval mean loss: 23573.847819010418
INFO:root:eval perplexity: 11.470650672912598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/56

 28%|â–ˆâ–ˆâ–Š       | 56/200 [50:57<2:10:16, 54.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12585.700816761364
INFO:root:current train perplexity3.4379751682281494
INFO:root:current mean train loss 12612.468195734797
INFO:root:current train perplexity3.4602150917053223
INFO:root:current mean train loss 12643.313536729858
INFO:root:current train perplexity3.477518081665039


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.33s/it]
INFO:root:final mean train loss: 12645.402186239919
INFO:root:final train perplexity: 3.4807372093200684
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it]
INFO:root:eval mean loss: 23602.77734375
INFO:root:eval perplexity: 11.505045890808105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/57

 28%|â–ˆâ–ˆâ–Š       | 57/200 [51:51<2:09:26, 54.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12543.01240079365
INFO:root:current train perplexity3.4432387351989746
INFO:root:current mean train loss 12589.351005320168
INFO:root:current train perplexity3.454641342163086


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.38s/it]
INFO:root:final mean train loss: 12589.818052230343
INFO:root:final train perplexity: 3.461707353591919
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.50s/it]
INFO:root:eval mean loss: 23641.453171502977
INFO:root:eval perplexity: 11.551191329956055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/58

 29%|â–ˆâ–ˆâ–‰       | 58/200 [52:45<2:08:39, 54.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12463.776171875
INFO:root:current train perplexity3.408947467803955
INFO:root:current mean train loss 12481.0509765625
INFO:root:current train perplexity3.424788236618042
INFO:root:current mean train loss 12519.622901526163
INFO:root:current train perplexity3.4337291717529297


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.36s/it]
INFO:root:final mean train loss: 12522.922473538307
INFO:root:final train perplexity: 3.438941478729248
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it]
INFO:root:eval mean loss: 23703.826706659227
INFO:root:eval perplexity: 11.62600040435791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/59

 30%|â–ˆâ–ˆâ–‰       | 59/200 [53:40<2:07:47, 54.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12422.447804920708
INFO:root:current train perplexity3.4017796516418457
INFO:root:current mean train loss 12444.76675360217
INFO:root:current train perplexity3.4127280712127686


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it]
INFO:root:final mean train loss: 12467.55269499748
INFO:root:final train perplexity: 3.4202122688293457
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it]
INFO:root:eval mean loss: 23771.15515718006
INFO:root:eval perplexity: 11.707293510437012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/60

 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [54:34<2:06:46, 54.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12356.538291529605
INFO:root:current train perplexity3.3511924743652344
INFO:root:current mean train loss 12372.969381893383
INFO:root:current train perplexity3.391493797302246
INFO:root:current mean train loss 12415.245353524544
INFO:root:current train perplexity3.401287078857422


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.30s/it]
INFO:root:final mean train loss: 12412.547008883568
INFO:root:final train perplexity: 3.4017066955566406
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it]
INFO:root:eval mean loss: 23812.256649925595
INFO:root:eval perplexity: 11.757200241088867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/61

 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [55:28<2:05:51, 54.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12304.112868617958
INFO:root:current train perplexity3.358880043029785
INFO:root:current mean train loss 12341.883069490132
INFO:root:current train perplexity3.372951030731201


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.31s/it]
INFO:root:final mean train loss: 12349.55939311366
INFO:root:final train perplexity: 3.380638360977173
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it]
INFO:root:eval mean loss: 23851.896809895832
INFO:root:eval perplexity: 11.805533409118652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/62

 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [56:23<2:04:58, 54.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12167.59523607337
INFO:root:current train perplexity3.3338117599487305
INFO:root:current mean train loss 12255.26218718242
INFO:root:current train perplexity3.347285032272339
INFO:root:current mean train loss 12297.047330437219
INFO:root:current train perplexity3.3609049320220947


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.42s/it]
INFO:root:final mean train loss: 12292.471352854083
INFO:root:final train perplexity: 3.361656427383423
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it]
INFO:root:eval mean loss: 23911.631184895832
INFO:root:eval perplexity: 11.878743171691895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/63

 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [57:17<2:04:07, 54.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12180.963671875
INFO:root:current train perplexity3.327287435531616
INFO:root:current mean train loss 12231.966238839286
INFO:root:current train perplexity3.3350532054901123


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it]
INFO:root:final mean train loss: 12237.07947171119
INFO:root:final train perplexity: 3.3433403968811035
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.48s/it]
INFO:root:eval mean loss: 23953.56298828125
INFO:root:eval perplexity: 11.930408477783203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/64

 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [58:11<2:03:09, 54.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12035.64525462963
INFO:root:current train perplexity3.284014940261841
INFO:root:current mean train loss 12146.300742802658
INFO:root:current train perplexity3.311772108078003
INFO:root:current mean train loss 12181.920038030012
INFO:root:current train perplexity3.3214609622955322


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.50s/it]
INFO:root:final mean train loss: 12182.072431010585
INFO:root:final train perplexity: 3.3252503871917725
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.48s/it]
INFO:root:eval mean loss: 24008.08923921131
INFO:root:eval perplexity: 11.997925758361816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/65

 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [59:06<2:02:25, 54.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12063.511038864715
INFO:root:current train perplexity3.2878525257110596
INFO:root:current mean train loss 12116.456889402933
INFO:root:current train perplexity3.298980712890625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.24s/it]
INFO:root:final mean train loss: 12127.868959488407
INFO:root:final train perplexity: 3.307520866394043
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.53s/it]
INFO:root:eval mean loss: 24028.128022693454
INFO:root:eval perplexity: 12.022835731506348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/66

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [1:00:00<2:01:30, 54.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12011.809538810483
INFO:root:current train perplexity3.261887550354004
INFO:root:current mean train loss 12040.23378608063
INFO:root:current train perplexity3.27614164352417
INFO:root:current mean train loss 12071.947891301406
INFO:root:current train perplexity3.28814697265625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.30s/it]
INFO:root:final mean train loss: 12070.935637443295
INFO:root:final train perplexity: 3.288999319076538
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it]
INFO:root:eval mean loss: 24110.95975167411
INFO:root:eval perplexity: 12.12634563446045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/67

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [1:00:55<2:00:33, 54.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12012.9011907003
INFO:root:current train perplexity3.259453535079956
INFO:root:current mean train loss 12013.474641393443
INFO:root:current train perplexity3.2701950073242188


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.14s/it]
INFO:root:final mean train loss: 12018.923154769405
INFO:root:final train perplexity: 3.272169351577759
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.40s/it]
INFO:root:eval mean loss: 24123.31798735119
INFO:root:eval perplexity: 12.141863822937012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/68

 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [1:01:49<1:59:29, 54.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11944.415680803571
INFO:root:current train perplexity3.23445987701416
INFO:root:current mean train loss 11953.805324074074
INFO:root:current train perplexity3.250014066696167
INFO:root:current mean train loss 11973.101446143617
INFO:root:current train perplexity3.255472183227539


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.22s/it]
INFO:root:final mean train loss: 11968.80949155746
INFO:root:final train perplexity: 3.256035566329956
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.40s/it]
INFO:root:eval mean loss: 24204.877487909227
INFO:root:eval perplexity: 12.244789123535156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/69

 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [1:02:43<1:58:31, 54.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11869.220781698994
INFO:root:current train perplexity3.217686653137207
INFO:root:current mean train loss 11899.638692764038
INFO:root:current train perplexity3.2314507961273193


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.13s/it]
INFO:root:final mean train loss: 11915.675261466733
INFO:root:final train perplexity: 3.239016532897949
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it]
INFO:root:eval mean loss: 24225.32933407738
INFO:root:eval perplexity: 12.270734786987305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/70

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [1:03:37<1:57:32, 54.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11802.611904046475
INFO:root:current train perplexity3.1993610858917236
INFO:root:current mean train loss 11851.542104597573
INFO:root:current train perplexity3.2180652618408203
INFO:root:current mean train loss 11873.264015101988
INFO:root:current train perplexity3.222055435180664


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.30s/it]
INFO:root:final mean train loss: 11865.943713772682
INFO:root:final train perplexity: 3.2231671810150146
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it]
INFO:root:eval mean loss: 24273.72888764881
INFO:root:eval perplexity: 12.332352638244629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/71

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [1:04:32<1:56:40, 54.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11768.913676167582
INFO:root:current train perplexity3.1876630783081055
INFO:root:current mean train loss 11794.872254376636
INFO:root:current train perplexity3.200641632080078


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it]
INFO:root:final mean train loss: 11809.633088142642
INFO:root:final train perplexity: 3.205315589904785
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it]
INFO:root:eval mean loss: 24342.26781063988
INFO:root:eval perplexity: 12.420145034790039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/72

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [1:05:26<1:55:47, 54.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11715.31190952035
INFO:root:current train perplexity3.1648762226104736
INFO:root:current mean train loss 11755.319370083042
INFO:root:current train perplexity3.185631513595581
INFO:root:current mean train loss 11771.016959233539
INFO:root:current train perplexity3.1902198791503906


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.59s/it]
INFO:root:final mean train loss: 11760.925340221775
INFO:root:final train perplexity: 3.189953327178955
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it]
INFO:root:eval mean loss: 24401.070731026786
INFO:root:eval perplexity: 12.495963096618652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/73

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [1:06:21<1:55:08, 54.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11687.43784950658
INFO:root:current train perplexity3.1585428714752197
INFO:root:current mean train loss 11707.272546073718
INFO:root:current train perplexity3.168030261993408


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.44s/it]
INFO:root:final mean train loss: 11709.891333795364
INFO:root:final train perplexity: 3.173936605453491
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it]
INFO:root:eval mean loss: 24426.059012276786
INFO:root:eval perplexity: 12.528321266174316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/74

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [1:07:15<1:54:17, 54.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11606.431661402925
INFO:root:current train perplexity3.138070821762085
INFO:root:current mean train loss 11644.611407844388
INFO:root:current train perplexity3.1511313915252686
INFO:root:current mean train loss 11667.447190504809
INFO:root:current train perplexity3.157810688018799


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.37s/it]
INFO:root:final mean train loss: 11659.036298198085
INFO:root:final train perplexity: 3.1580569744110107
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it]
INFO:root:eval mean loss: 24478.762672061013
INFO:root:eval perplexity: 12.596843719482422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/75

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [1:08:10<1:53:23, 54.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11579.67734966856
INFO:root:current train perplexity3.135056257247925
INFO:root:current mean train loss 11601.04824415044
INFO:root:current train perplexity3.1415798664093018


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.24s/it]
INFO:root:final mean train loss: 11614.080152942288
INFO:root:final train perplexity: 3.1440839767456055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it]
INFO:root:eval mean loss: 24516.057942708332
INFO:root:eval perplexity: 12.645565032958984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/76

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [1:09:04<1:52:24, 54.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11517.841720281862
INFO:root:current train perplexity3.1165337562561035
INFO:root:current mean train loss 11540.73539683361
INFO:root:current train perplexity3.1211283206939697


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.17s/it]
INFO:root:final mean train loss: 11565.010494109123
INFO:root:final train perplexity: 3.128904104232788
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.40s/it]
INFO:root:eval mean loss: 24567.76697358631
INFO:root:eval perplexity: 12.713419914245605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/77

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [1:09:58<1:51:30, 54.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11306.140950520834
INFO:root:current train perplexity3.0493569374084473
INFO:root:current mean train loss 11459.33190799454
INFO:root:current train perplexity3.0905916690826416
INFO:root:current mean train loss 11508.208272398399
INFO:root:current train perplexity3.107393980026245


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.15s/it]
INFO:root:final mean train loss: 11513.18068375126
INFO:root:final train perplexity: 3.1129493713378906
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.50s/it]
INFO:root:eval mean loss: 24615.231491815477
INFO:root:eval perplexity: 12.776022911071777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/78

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [1:10:53<1:50:30, 54.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11379.638512073863
INFO:root:current train perplexity3.078106641769409
INFO:root:current mean train loss 11447.561258820564
INFO:root:current train perplexity3.0937905311584473


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.32s/it]
INFO:root:final mean train loss: 11471.436621881301
INFO:root:final train perplexity: 3.1001594066619873
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it]
INFO:root:eval mean loss: 24691.15564546131
INFO:root:eval perplexity: 12.876810073852539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/79

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [1:11:47<1:49:36, 54.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11343.61021205357
INFO:root:current train perplexity3.0537054538726807
INFO:root:current mean train loss 11398.012622298482
INFO:root:current train perplexity3.0760457515716553
INFO:root:current mean train loss 11421.530981091486
INFO:root:current train perplexity3.084710121154785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.48s/it]
INFO:root:final mean train loss: 11425.457326581402
INFO:root:final train perplexity: 3.0861318111419678
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it]
INFO:root:eval mean loss: 24685.0244140625
INFO:root:eval perplexity: 12.868646621704102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/80

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [1:12:41<1:48:48, 54.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11291.865499205509
INFO:root:current train perplexity3.0566580295562744
INFO:root:current mean train loss 11362.488606770834
INFO:root:current train perplexity3.0691945552825928


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.32s/it]
INFO:root:final mean train loss: 11377.225944272934
INFO:root:final train perplexity: 3.0714852809906006
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it]
INFO:root:eval mean loss: 24767.39383370536
INFO:root:eval perplexity: 12.978816032409668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/81

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [1:13:36<1:47:53, 54.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11325.594282670454
INFO:root:current train perplexity3.021104335784912
INFO:root:current mean train loss 11320.020411036036
INFO:root:current train perplexity3.0484397411346436
INFO:root:current mean train loss 11334.533175355451
INFO:root:current train perplexity3.055525541305542


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.36s/it]
INFO:root:final mean train loss: 11334.42701376638
INFO:root:final train perplexity: 3.058547019958496
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it]
INFO:root:eval mean loss: 24774.805199032737
INFO:root:eval perplexity: 12.988774299621582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/82

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [1:14:30<1:47:00, 54.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11240.97333829365
INFO:root:current train perplexity3.0309276580810547
INFO:root:current mean train loss 11265.542956767638
INFO:root:current train perplexity3.03804874420166


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.28s/it]
INFO:root:final mean train loss: 11282.9736328125
INFO:root:final train perplexity: 3.0430638790130615
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it]
INFO:root:eval mean loss: 24851.23523530506
INFO:root:eval perplexity: 13.091926574707031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/83

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [1:15:25<1:46:03, 54.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11198.097916666668
INFO:root:current train perplexity3.0105111598968506
INFO:root:current mean train loss 11215.005672554347
INFO:root:current train perplexity3.019580602645874
INFO:root:current mean train loss 11245.775803960756
INFO:root:current train perplexity3.0289344787597656


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.28s/it]
INFO:root:final mean train loss: 11244.322265625
INFO:root:final train perplexity: 3.031484842300415
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it]
INFO:root:eval mean loss: 24929.859933035714
INFO:root:eval perplexity: 13.198892593383789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/84

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [1:16:19<1:45:06, 54.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11150.760144589553
INFO:root:current train perplexity2.996519088745117
INFO:root:current mean train loss 11190.757590288174
INFO:root:current train perplexity3.010342836380005


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.25s/it]
INFO:root:final mean train loss: 11197.756245274697
INFO:root:final train perplexity: 3.0175933837890625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it]
INFO:root:eval mean loss: 24937.478701636905
INFO:root:eval perplexity: 13.209306716918945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/85

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [1:17:13<1:44:10, 54.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11128.02790912829
INFO:root:current train perplexity2.9683213233947754
INFO:root:current mean train loss 11151.16372603729
INFO:root:current train perplexity2.997765064239502
INFO:root:current mean train loss 11168.105183361871
INFO:root:current train perplexity3.002894639968872


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.60s/it]
INFO:root:final mean train loss: 11160.414377520161
INFO:root:final train perplexity: 3.006499767303467
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it]
INFO:root:eval mean loss: 24984.511904761905
INFO:root:eval perplexity: 13.273760795593262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/86

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [1:18:08<1:43:25, 54.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11083.88143705986
INFO:root:current train perplexity2.982042074203491
INFO:root:current mean train loss 11112.149933753655
INFO:root:current train perplexity2.98817777633667


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.38s/it]
INFO:root:final mean train loss: 11114.406958795364
INFO:root:final train perplexity: 2.9928882122039795
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it]
INFO:root:eval mean loss: 25047.277483258928
INFO:root:eval perplexity: 13.36026668548584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/87

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [1:19:02<1:42:31, 54.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11028.648692255434
INFO:root:current train perplexity2.9686691761016846
INFO:root:current mean train loss 11071.89894563008
INFO:root:current train perplexity2.9734928607940674
INFO:root:current mean train loss 11077.552861371916
INFO:root:current train perplexity2.980149745941162


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.10s/it]
INFO:root:final mean train loss: 11079.597293976814
INFO:root:final train perplexity: 2.9826297760009766
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.50s/it]
INFO:root:eval mean loss: 25065.40504092262
INFO:root:eval perplexity: 13.385355949401855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/88

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [1:19:56<1:41:29, 54.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11011.458450520833
INFO:root:current train perplexity2.956275701522827
INFO:root:current mean train loss 11033.96755580357
INFO:root:current train perplexity2.962683916091919


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.40s/it]
INFO:root:final mean train loss: 11033.089678364415
INFO:root:final train perplexity: 2.9689793586730957
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it]
INFO:root:eval mean loss: 25123.206589471727
INFO:root:eval perplexity: 13.465669631958008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/89

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [1:20:51<1:40:39, 54.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10974.146339699075
INFO:root:current train perplexity2.9487407207489014
INFO:root:current mean train loss 10977.934231975885
INFO:root:current train perplexity2.94600510597229
INFO:root:current mean train loss 11004.158857034692
INFO:root:current train perplexity2.9556427001953125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.53s/it]
INFO:root:final mean train loss: 10989.333952872983
INFO:root:final train perplexity: 2.9561939239501953
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.50s/it]
INFO:root:eval mean loss: 25183.308896019345
INFO:root:eval perplexity: 13.549695014953613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/90

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [1:21:46<1:39:52, 54.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10930.836345431171
INFO:root:current train perplexity2.936255693435669
INFO:root:current mean train loss 10947.391759776536
INFO:root:current train perplexity2.9421305656433105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.26s/it]
INFO:root:final mean train loss: 10954.284518334174
INFO:root:final train perplexity: 2.9459917545318604
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it]
INFO:root:eval mean loss: 25217.030203683036
INFO:root:eval perplexity: 13.597064971923828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/91

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [1:22:40<1:38:50, 54.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10852.925907258064
INFO:root:current train perplexity2.9003283977508545
INFO:root:current mean train loss 10888.646268189408
INFO:root:current train perplexity2.9247190952301025
INFO:root:current mean train loss 10922.815953902867
INFO:root:current train perplexity2.9334561824798584


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it]
INFO:root:final mean train loss: 10915.996471774193
INFO:root:final train perplexity: 2.9348878860473633
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.54s/it]
INFO:root:eval mean loss: 25242.540201822918
INFO:root:eval perplexity: 13.633012771606445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/92

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [1:23:34<1:37:55, 54.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10826.198995199547
INFO:root:current train perplexity2.911806106567383
INFO:root:current mean train loss 10865.275017076503
INFO:root:current train perplexity2.917346239089966


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.09s/it]
INFO:root:final mean train loss: 10872.18056955645
INFO:root:final train perplexity: 2.9222311973571777
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it]
INFO:root:eval mean loss: 25283.25365048363
INFO:root:eval perplexity: 13.690577507019043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/93

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [1:24:28<1:36:50, 54.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10837.804464285715
INFO:root:current train perplexity2.896303653717041
INFO:root:current mean train loss 10815.267925347222
INFO:root:current train perplexity2.905083179473877
INFO:root:current mean train loss 10845.980435505318
INFO:root:current train perplexity2.911437749862671


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.15s/it]
INFO:root:final mean train loss: 10838.796134702621
INFO:root:final train perplexity: 2.9126250743865967
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it]
INFO:root:eval mean loss: 25314.683012462796
INFO:root:eval perplexity: 13.73518180847168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/94

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [1:25:23<1:35:55, 54.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10749.8781092852
INFO:root:current train perplexity2.8910470008850098
INFO:root:current mean train loss 10785.964096966913
INFO:root:current train perplexity2.895576238632202


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it]
INFO:root:final mean train loss: 10795.70404249622
INFO:root:final train perplexity: 2.900271415710449
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it]
INFO:root:eval mean loss: 25377.581984747023
INFO:root:eval perplexity: 13.82489013671875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/95

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [1:26:17<1:35:02, 54.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10696.508288261219
INFO:root:current train perplexity2.8809187412261963
INFO:root:current mean train loss 10745.713670469873
INFO:root:current train perplexity2.8876521587371826
INFO:root:current mean train loss 10765.598175176518
INFO:root:current train perplexity2.889009714126587


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it]
INFO:root:final mean train loss: 10756.626177387852
INFO:root:final train perplexity: 2.8891148567199707
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it]
INFO:root:eval mean loss: 25450.464983258928
INFO:root:eval perplexity: 13.92956256866455
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/96

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [1:27:11<1:34:06, 54.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10703.477066878435
INFO:root:current train perplexity2.8633172512054443
INFO:root:current mean train loss 10722.546573339332
INFO:root:current train perplexity2.874882936477661


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.24s/it]
INFO:root:final mean train loss: 10724.539826423892
INFO:root:final train perplexity: 2.879985809326172
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it]
INFO:root:eval mean loss: 25479.765648251487
INFO:root:eval perplexity: 13.971867561340332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/97

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [1:28:06<1:33:12, 54.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10623.63515170785
INFO:root:current train perplexity2.8543131351470947
INFO:root:current mean train loss 10677.570585664336
INFO:root:current train perplexity2.864013671875
INFO:root:current mean train loss 10698.657957979682
INFO:root:current train perplexity2.8693652153015137


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.39s/it]
INFO:root:final mean train loss: 10688.5166015625
INFO:root:final train perplexity: 2.8697712421417236
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.51s/it]
INFO:root:eval mean loss: 25545.260416666668
INFO:root:eval perplexity: 14.066901206970215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/98

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [1:29:00<1:32:24, 54.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10628.370662006579
INFO:root:current train perplexity2.8452656269073486
INFO:root:current mean train loss 10646.554752604166
INFO:root:current train perplexity2.8551084995269775


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.40s/it]
INFO:root:final mean train loss: 10655.036613218246
INFO:root:final train perplexity: 2.8603103160858154
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it]
INFO:root:eval mean loss: 25517.789202008928
INFO:root:eval perplexity: 14.026960372924805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/99

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [1:29:54<1:31:32, 54.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10592.597323803191
INFO:root:current train perplexity2.8313822746276855
INFO:root:current mean train loss 10601.28081818665
INFO:root:current train perplexity2.8409464359283447
INFO:root:current mean train loss 10620.983437974442
INFO:root:current train perplexity2.848682165145874


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it]
INFO:root:final mean train loss: 10613.500909620716
INFO:root:final train perplexity: 2.848616123199463
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it]
INFO:root:eval mean loss: 25587.95191592262
INFO:root:eval perplexity: 14.12918758392334
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/100

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [1:30:49<1:30:36, 54.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10565.537898516413
INFO:root:current train perplexity2.8252201080322266
INFO:root:current mean train loss 10578.352224992148
INFO:root:current train perplexity2.8367838859558105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.44s/it]
INFO:root:final mean train loss: 10585.04195280998
INFO:root:final train perplexity: 2.8406314849853516
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it]
INFO:root:eval mean loss: 25625.867699032737
INFO:root:eval perplexity: 14.184738159179688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/101

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [1:31:43<1:29:44, 54.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10490.962814031862
INFO:root:current train perplexity2.8097050189971924
INFO:root:current mean train loss 10542.613514072847
INFO:root:current train perplexity2.822047472000122


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.17s/it]
INFO:root:final mean train loss: 10553.811334425403
INFO:root:final train perplexity: 2.831894636154175
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.54s/it]
INFO:root:eval mean loss: 25663.019670758928
INFO:root:eval perplexity: 14.239389419555664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/102

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [1:32:38<1:28:48, 54.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10287.6787109375
INFO:root:current train perplexity2.812896490097046
INFO:root:current mean train loss 10496.028102245145
INFO:root:current train perplexity2.815953016281128
INFO:root:current mean train loss 10526.729843365149
INFO:root:current train perplexity2.8224539756774902


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.05s/it]
INFO:root:final mean train loss: 10526.461756552419
INFO:root:final train perplexity: 2.824265718460083
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it]
INFO:root:eval mean loss: 25719.277529761905
INFO:root:eval perplexity: 14.322535514831543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/103

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [1:33:32<1:27:46, 54.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10457.335475852273
INFO:root:current train perplexity2.794436454772949
INFO:root:current mean train loss 10478.790291078629
INFO:root:current train perplexity2.8075578212738037


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it]
INFO:root:final mean train loss: 10482.736863659275
INFO:root:final train perplexity: 2.8121118545532227
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it]
INFO:root:eval mean loss: 25721.609933035714
INFO:root:eval perplexity: 14.325995445251465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/104

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [1:34:26<1:26:51, 54.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10374.698660714286
INFO:root:current train perplexity2.7788498401641846
INFO:root:current mean train loss 10421.251788843458
INFO:root:current train perplexity2.787662982940674
INFO:root:current mean train loss 10449.147673233696
INFO:root:current train perplexity2.799553871154785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.17s/it]
INFO:root:final mean train loss: 10451.68212890625
INFO:root:final train perplexity: 2.8035120964050293
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.39s/it]
INFO:root:eval mean loss: 25763.367280505954
INFO:root:eval perplexity: 14.388040542602539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/105

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [1:35:20<1:25:54, 54.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10366.82858845339
INFO:root:current train perplexity2.781952381134033
INFO:root:current mean train loss 10405.788098221305
INFO:root:current train perplexity2.7890994548797607


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it]
INFO:root:final mean train loss: 10418.581499653477
INFO:root:final train perplexity: 2.7943737506866455
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it]
INFO:root:eval mean loss: 25851.976888020832
INFO:root:eval perplexity: 14.520596504211426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/106

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [1:36:14<1:24:59, 54.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10269.401899857954
INFO:root:current train perplexity2.752993583679199
INFO:root:current mean train loss 10350.705465230856
INFO:root:current train perplexity2.7797703742980957
INFO:root:current mean train loss 10388.74265032583
INFO:root:current train perplexity2.7858269214630127


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.23s/it]
INFO:root:final mean train loss: 10390.191130607358
INFO:root:final train perplexity: 2.786559820175171
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.40s/it]
INFO:root:eval mean loss: 25856.937523251487
INFO:root:eval perplexity: 14.528056144714355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/107

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [1:37:09<1:24:04, 54.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10294.581101190477
INFO:root:current train perplexity2.7663326263427734
INFO:root:current mean train loss 10340.118631374617
INFO:root:current train perplexity2.7726306915283203


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.12s/it]
INFO:root:final mean train loss: 10353.691526351437
INFO:root:final train perplexity: 2.776546001434326
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it]
INFO:root:eval mean loss: 25938.805245535714
INFO:root:eval perplexity: 14.651670455932617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/108

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [1:38:03<1:23:08, 54.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10269.673177083334
INFO:root:current train perplexity2.7502474784851074
INFO:root:current mean train loss 10300.150356657608
INFO:root:current train perplexity2.760840654373169
INFO:root:current mean train loss 10323.316987645348
INFO:root:current train perplexity2.7648489475250244


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.25s/it]
INFO:root:final mean train loss: 10322.183707944809
INFO:root:final train perplexity: 2.767930746078491
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it]
INFO:root:eval mean loss: 25979.550385974704
INFO:root:eval perplexity: 14.71358585357666
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/109

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [1:38:57<1:22:16, 54.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10266.269881063432
INFO:root:current train perplexity2.746973752975464
INFO:root:current mean train loss 10290.56542383982
INFO:root:current train perplexity2.756040334701538


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.22s/it]
INFO:root:final mean train loss: 10296.0203109249
INFO:root:final train perplexity: 2.7607972621917725
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it]
INFO:root:eval mean loss: 25980.800757998513
INFO:root:eval perplexity: 14.715494155883789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/110

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [1:39:51<1:21:24, 54.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10228.782534950658
INFO:root:current train perplexity2.737189292907715
INFO:root:current mean train loss 10240.274701286764
INFO:root:current train perplexity2.744276762008667
INFO:root:current mean train loss 10268.56453339041
INFO:root:current train perplexity2.749309778213501


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.27s/it]
INFO:root:final mean train loss: 10264.016633064517
INFO:root:final train perplexity: 2.75209641456604
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it]
INFO:root:eval mean loss: 26019.736955915178
INFO:root:eval perplexity: 14.774913787841797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/111

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [1:40:46<1:20:32, 54.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10191.76495103433
INFO:root:current train perplexity2.7329578399658203
INFO:root:current mean train loss 10222.86280724598
INFO:root:current train perplexity2.7400431632995605


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.26s/it]
INFO:root:final mean train loss: 10235.800737934727
INFO:root:final train perplexity: 2.744447708129883
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.52s/it]
INFO:root:eval mean loss: 26037.169084821428
INFO:root:eval perplexity: 14.801592826843262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/112

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [1:41:40<1:19:41, 54.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10165.569718070652
INFO:root:current train perplexity2.728055000305176
INFO:root:current mean train loss 10197.596068343495
INFO:root:current train perplexity2.7328736782073975
INFO:root:current mean train loss 10218.259099985986
INFO:root:current train perplexity2.7361583709716797


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.47s/it]
INFO:root:final mean train loss: 10210.675025201614
INFO:root:final train perplexity: 2.7376549243927
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it]
INFO:root:eval mean loss: 26098.85997953869
INFO:root:eval perplexity: 14.896397590637207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/113

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [1:42:35<1:18:50, 54.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10132.597708333333
INFO:root:current train perplexity2.724893808364868
INFO:root:current mean train loss 10176.39109375
INFO:root:current train perplexity2.7276182174682617


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it]
INFO:root:final mean train loss: 10182.618051836567
INFO:root:final train perplexity: 2.730088949203491
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it]
INFO:root:eval mean loss: 26117.660714285714
INFO:root:eval perplexity: 14.925414085388184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/114

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [1:43:29<1:17:53, 54.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10114.672815393518
INFO:root:current train perplexity2.708915948867798
INFO:root:current mean train loss 10124.642601193405
INFO:root:current train perplexity2.713364601135254
INFO:root:current mean train loss 10156.237025055067
INFO:root:current train perplexity2.720979928970337


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.27s/it]
INFO:root:final mean train loss: 10154.155797158519
INFO:root:final train perplexity: 2.722435712814331
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.38s/it]
INFO:root:eval mean loss: 26216.460914248513
INFO:root:eval perplexity: 15.078813552856445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/115

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [1:44:23<1:16:56, 54.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10110.577853045887
INFO:root:current train perplexity2.707472085952759
INFO:root:current mean train loss 10123.840585719274
INFO:root:current train perplexity2.7116246223449707


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.25s/it]
INFO:root:final mean train loss: 10128.246908864667
INFO:root:final train perplexity: 2.7154879570007324
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it]
INFO:root:eval mean loss: 26207.20045107887
INFO:root:eval perplexity: 15.06436824798584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/116

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [1:45:18<1:16:03, 54.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10049.085653981854
INFO:root:current train perplexity2.702510118484497
INFO:root:current mean train loss 10075.105386748568
INFO:root:current train perplexity2.701253890991211
INFO:root:current mean train loss 10096.0484180533
INFO:root:current train perplexity2.7055063247680664


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.41s/it]
INFO:root:final mean train loss: 10092.350101594002
INFO:root:final train perplexity: 2.705890655517578
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it]
INFO:root:eval mean loss: 26244.899274553572
INFO:root:eval perplexity: 15.123260498046875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/117

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [1:46:12<1:15:12, 54.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10041.76609563253
INFO:root:current train perplexity2.6887612342834473
INFO:root:current mean train loss 10065.612918374318
INFO:root:current train perplexity2.697181463241577


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.28s/it]
INFO:root:final mean train loss: 10068.538483650455
INFO:root:final train perplexity: 2.699542760848999
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it]
INFO:root:eval mean loss: 26299.190011160714
INFO:root:eval perplexity: 15.208474159240723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/118

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [1:47:06<1:14:17, 54.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9994.126422991072
INFO:root:current train perplexity2.6821770668029785
INFO:root:current mean train loss 10010.73117042824
INFO:root:current train perplexity2.688112735748291
INFO:root:current mean train loss 10047.10756732048
INFO:root:current train perplexity2.6923396587371826


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.45s/it]
INFO:root:final mean train loss: 10042.734378937752
INFO:root:final train perplexity: 2.692680835723877
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.50s/it]
INFO:root:eval mean loss: 26332.66336495536
INFO:root:eval perplexity: 15.26125431060791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/119

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [1:48:01<1:13:28, 54.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9984.518700610632
INFO:root:current train perplexity2.6778008937835693
INFO:root:current mean train loss 10013.092783882019
INFO:root:current train perplexity2.683016061782837


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.57s/it]
INFO:root:final mean train loss: 10023.229915495842
INFO:root:final train perplexity: 2.6875057220458984
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.52s/it]
INFO:root:eval mean loss: 26357.028180803572
INFO:root:eval perplexity: 15.299788475036621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/120

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [1:48:56<1:12:40, 54.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9974.861553485576
INFO:root:current train perplexity2.66906476020813
INFO:root:current mean train loss 9993.829171818796
INFO:root:current train perplexity2.6721794605255127
INFO:root:current mean train loss 10000.270499640428
INFO:root:current train perplexity2.6779539585113525


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.18s/it]
INFO:root:final mean train loss: 9991.427198840725
INFO:root:final train perplexity: 2.679089069366455
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it]
INFO:root:eval mean loss: 26395.936011904763
INFO:root:eval perplexity: 15.361515998840332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/121

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [1:49:50<1:11:38, 54.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9936.984654017857
INFO:root:current train perplexity2.6674325466156006
INFO:root:current mean train loss 9964.522951775196
INFO:root:current train perplexity2.6697497367858887


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it]
INFO:root:final mean train loss: 9968.829286636845
INFO:root:final train perplexity: 2.673124313354492
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.52s/it]
INFO:root:eval mean loss: 26442.285714285714
INFO:root:eval perplexity: 15.435385704040527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/122

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [1:50:44<1:10:44, 54.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9915.879133357557
INFO:root:current train perplexity2.6523959636688232
INFO:root:current mean train loss 9927.127274093094
INFO:root:current train perplexity2.6589884757995605
INFO:root:current mean train loss 9948.480762120627
INFO:root:current train perplexity2.6664092540740967


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.31s/it]
INFO:root:final mean train loss: 9942.638226909023
INFO:root:final train perplexity: 2.6662275791168213
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it]
INFO:root:eval mean loss: 26447.001953125
INFO:root:eval perplexity: 15.442924499511719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/123

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [1:51:39<1:09:47, 54.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9909.276233552631
INFO:root:current train perplexity2.6559462547302246
INFO:root:current mean train loss 9922.663917267628
INFO:root:current train perplexity2.6582279205322266


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.36s/it]
INFO:root:final mean train loss: 9921.492530084426
INFO:root:final train perplexity: 2.660672664642334
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it]
INFO:root:eval mean loss: 26506.140066964286
INFO:root:eval perplexity: 15.537734985351562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/124

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [1:52:33<1:08:54, 54.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9847.80836519282
INFO:root:current train perplexity2.646057605743408
INFO:root:current mean train loss 9884.681082589286
INFO:root:current train perplexity2.6497645378112793
INFO:root:current mean train loss 9900.892238107288
INFO:root:current train perplexity2.6534838676452637


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.16s/it]
INFO:root:final mean train loss: 9894.10546875
INFO:root:final train perplexity: 2.6534953117370605
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it]
INFO:root:eval mean loss: 26526.12951078869
INFO:root:eval perplexity: 15.56991195678711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/125

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [1:53:27<1:07:54, 54.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9840.077325994318
INFO:root:current train perplexity2.637497663497925
INFO:root:current mean train loss 9869.595158409235
INFO:root:current train perplexity2.645033121109009


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it]
INFO:root:final mean train loss: 9870.41109343498
INFO:root:final train perplexity: 2.647300958633423
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.51s/it]
INFO:root:eval mean loss: 26569.062453497023
INFO:root:eval perplexity: 15.639238357543945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/126

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [1:54:21<1:07:00, 54.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9821.731789981617
INFO:root:current train perplexity2.625368356704712
INFO:root:current mean train loss 9848.127942622103
INFO:root:current train perplexity2.6358425617218018


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it]
INFO:root:final mean train loss: 9853.776778682586
INFO:root:final train perplexity: 2.642961025238037
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it]
INFO:root:eval mean loss: 26589.07886904762
INFO:root:eval perplexity: 15.671674728393555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/127

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [1:55:16<1:06:04, 54.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9698.212565104166
INFO:root:current train perplexity2.6272175312042236
INFO:root:current mean train loss 9808.971461620145
INFO:root:current train perplexity2.6329894065856934
INFO:root:current mean train loss 9831.524332281404
INFO:root:current train perplexity2.6356396675109863


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.08s/it]
INFO:root:final mean train loss: 9832.223827731224
INFO:root:final train perplexity: 2.6373488903045654
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it]
INFO:root:eval mean loss: 26623.325869605655
INFO:root:eval perplexity: 15.72731876373291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/128

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [1:56:10<1:05:08, 54.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9779.659623579546
INFO:root:current train perplexity2.622835397720337
INFO:root:current mean train loss 9797.389377520161
INFO:root:current train perplexity2.627802848815918


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.24s/it]
INFO:root:final mean train loss: 9806.3662109375
INFO:root:final train perplexity: 2.630631446838379
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it]
INFO:root:eval mean loss: 26658.778180803572
INFO:root:eval perplexity: 15.785136222839355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/129

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [1:57:04<1:04:13, 54.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9678.37806919643
INFO:root:current train perplexity2.61072039604187
INFO:root:current mean train loss 9772.224837543808
INFO:root:current train perplexity2.6210033893585205
INFO:root:current mean train loss 9795.638884171196
INFO:root:current train perplexity2.6257195472717285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.11s/it]
INFO:root:final mean train loss: 9789.543941374748
INFO:root:final train perplexity: 2.626270055770874
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it]
INFO:root:eval mean loss: 26671.788667224704
INFO:root:eval perplexity: 15.806398391723633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/130

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [1:57:58<1:03:17, 54.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9726.317184189618
INFO:root:current train perplexity2.6118736267089844
INFO:root:current mean train loss 9755.657189711084
INFO:root:current train perplexity2.6178975105285645


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it]
INFO:root:final mean train loss: 9767.682802261845
INFO:root:final train perplexity: 2.6206133365631104
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it]
INFO:root:eval mean loss: 26701.244559151786
INFO:root:eval perplexity: 15.85466480255127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/131

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [1:58:53<1:02:24, 54.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9693.165749289772
INFO:root:current train perplexity2.58495831489563
INFO:root:current mean train loss 9709.253343186936
INFO:root:current train perplexity2.607513427734375
INFO:root:current mean train loss 9746.175938610782
INFO:root:current train perplexity2.6137919425964355


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.96s/it]
INFO:root:final mean train loss: 9745.093722435737
INFO:root:final train perplexity: 2.614781141281128
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it]
INFO:root:eval mean loss: 26755.251906622023
INFO:root:eval perplexity: 15.943528175354004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/132

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [1:59:47<1:01:24, 54.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9729.58872767857
INFO:root:current train perplexity2.6034486293792725
INFO:root:current mean train loss 9716.2178992523
INFO:root:current train perplexity2.6049180030822754


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.17s/it]
INFO:root:final mean train loss: 9722.760933168473
INFO:root:final train perplexity: 2.60902738571167
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.51s/it]
INFO:root:eval mean loss: 26768.29813058036
INFO:root:eval perplexity: 15.965072631835938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/133

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [2:00:41<1:00:32, 54.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9633.425716145834
INFO:root:current train perplexity2.614354133605957
INFO:root:current mean train loss 9691.751112432064
INFO:root:current train perplexity2.6016669273376465
INFO:root:current mean train loss 9712.629324127907
INFO:root:current train perplexity2.604539394378662


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.08s/it]
INFO:root:final mean train loss: 9707.236221805695
INFO:root:final train perplexity: 2.6050355434417725
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it]
INFO:root:eval mean loss: 26813.21023995536
INFO:root:eval perplexity: 16.03945541381836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/134

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [2:01:35<59:38, 54.21s/it]  

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9671.916336287313
INFO:root:current train perplexity2.589038848876953
INFO:root:current mean train loss 9681.85384894274
INFO:root:current train perplexity2.5951950550079346


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.08s/it]
INFO:root:final mean train loss: 9682.586898311492
INFO:root:final train perplexity: 2.59870982170105
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it]
INFO:root:eval mean loss: 26841.329520089286
INFO:root:eval perplexity: 16.086198806762695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/135

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [2:02:29<58:42, 54.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9655.04646381579
INFO:root:current train perplexity2.576486349105835
INFO:root:current mean train loss 9645.52232963498
INFO:root:current train perplexity2.589515209197998
INFO:root:current mean train loss 9668.008111265697
INFO:root:current train perplexity2.592480421066284


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it]
INFO:root:final mean train loss: 9662.042498188634
INFO:root:final train perplexity: 2.593449354171753
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.48s/it]
INFO:root:eval mean loss: 26847.54659598214
INFO:root:eval perplexity: 16.096553802490234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/136

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [2:03:24<57:49, 54.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9630.985599141726
INFO:root:current train perplexity2.5826284885406494
INFO:root:current mean train loss 9642.847730491594
INFO:root:current train perplexity2.588743209838867


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.26s/it]
INFO:root:final mean train loss: 9645.972514490928
INFO:root:final train perplexity: 2.589341878890991
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it]
INFO:root:eval mean loss: 26888.287272135418
INFO:root:eval perplexity: 16.16457176208496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/137

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [2:04:18<56:56, 54.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9629.143469769022
INFO:root:current train perplexity2.5863068103790283
INFO:root:current mean train loss 9615.917214494411
INFO:root:current train perplexity2.580864667892456
INFO:root:current mean train loss 9629.797072064182
INFO:root:current train perplexity2.5835187435150146


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.42s/it]
INFO:root:final mean train loss: 9627.076853106098
INFO:root:final train perplexity: 2.5845208168029785
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it]
INFO:root:eval mean loss: 26914.184268043155
INFO:root:eval perplexity: 16.207956314086914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/138

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [2:05:12<56:06, 54.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9581.2754296875
INFO:root:current train perplexity2.570491075515747
INFO:root:current mean train loss 9604.1944921875
INFO:root:current train perplexity2.578934669494629


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.16s/it]
INFO:root:final mean train loss: 9604.659018239667
INFO:root:final train perplexity: 2.57881236076355
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.52s/it]
INFO:root:eval mean loss: 26941.914155505954
INFO:root:eval perplexity: 16.254535675048828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/139

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [2:06:07<55:12, 54.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9554.042136863425
INFO:root:current train perplexity2.56618332862854
INFO:root:current mean train loss 9575.917753444883
INFO:root:current train perplexity2.5685946941375732
INFO:root:current mean train loss 9584.74181752478
INFO:root:current train perplexity2.5724635124206543


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.26s/it]
INFO:root:final mean train loss: 9583.821531234249
INFO:root:final train perplexity: 2.5735175609588623
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it]
INFO:root:eval mean loss: 27007.581845238095
INFO:root:eval perplexity: 16.365385055541992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/140

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [2:07:01<54:18, 54.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9545.800360957279
INFO:root:current train perplexity2.57084059715271
INFO:root:current mean train loss 9572.548555342179
INFO:root:current train perplexity2.571200370788574


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it]
INFO:root:final mean train loss: 9576.949445170741
INFO:root:final train perplexity: 2.5717740058898926
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it]
INFO:root:eval mean loss: 26989.461402529763
INFO:root:eval perplexity: 16.334720611572266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/141

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [2:07:55<53:25, 54.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9509.23330393145
INFO:root:current train perplexity2.5539751052856445
INFO:root:current mean train loss 9537.11536855916
INFO:root:current train perplexity2.563324213027954
INFO:root:current mean train loss 9557.589027834145
INFO:root:current train perplexity2.5657565593719482


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.41s/it]
INFO:root:final mean train loss: 9554.032949139995
INFO:root:final train perplexity: 2.565967559814453
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.53s/it]
INFO:root:eval mean loss: 27028.342633928572
INFO:root:eval perplexity: 16.400588989257812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/142

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [2:08:50<52:35, 54.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9520.644954819278
INFO:root:current train perplexity2.561215400695801
INFO:root:current mean train loss 9534.768880208334
INFO:root:current train perplexity2.5581932067871094


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.35s/it]
INFO:root:final mean train loss: 9536.329351609753
INFO:root:final train perplexity: 2.561490535736084
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it]
INFO:root:eval mean loss: 27051.13936941964
INFO:root:eval perplexity: 16.4393310546875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/143

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [2:09:44<51:41, 54.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9523.014536830357
INFO:root:current train perplexity2.5478451251983643
INFO:root:current mean train loss 9505.423191550926
INFO:root:current train perplexity2.550046682357788
INFO:root:current mean train loss 9526.633548038564
INFO:root:current train perplexity2.55671763420105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.32s/it]
INFO:root:final mean train loss: 9519.219509986138
INFO:root:final train perplexity: 2.557171583175659
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.48s/it]
INFO:root:eval mean loss: 27092.64318266369
INFO:root:eval perplexity: 16.51009178161621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/144

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [2:10:39<50:46, 54.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9473.202530082615
INFO:root:current train perplexity2.5450406074523926
INFO:root:current mean train loss 9501.552149481951
INFO:root:current train perplexity2.55053448677063


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.26s/it]
INFO:root:final mean train loss: 9501.779125582787
INFO:root:final train perplexity: 2.55277681350708
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it]
INFO:root:eval mean loss: 27088.052780877977
INFO:root:eval perplexity: 16.50225257873535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/145

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [2:11:33<49:50, 54.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9481.122971754809
INFO:root:current train perplexity2.540527820587158
INFO:root:current mean train loss 9483.379552607914
INFO:root:current train perplexity2.5479631423950195
INFO:root:current mean train loss 9494.873831393828
INFO:root:current train perplexity2.5489730834960938


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.21s/it]
INFO:root:final mean train loss: 9487.415403304562
INFO:root:final train perplexity: 2.5491626262664795
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it]
INFO:root:eval mean loss: 27094.047991071428
INFO:root:eval perplexity: 16.512493133544922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/146

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [2:12:27<48:55, 54.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9444.957664405907
INFO:root:current train perplexity2.5382261276245117
INFO:root:current mean train loss 9472.093898273888
INFO:root:current train perplexity2.5427772998809814


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.35s/it]
INFO:root:final mean train loss: 9473.608154296875
INFO:root:final train perplexity: 2.5456936359405518
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it]
INFO:root:eval mean loss: 27135.665969122023
INFO:root:eval perplexity: 16.583768844604492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/147

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [2:13:22<48:01, 54.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9433.35465116279
INFO:root:current train perplexity2.5366241931915283
INFO:root:current mean train loss 9450.85236833479
INFO:root:current train perplexity2.5421700477600098
INFO:root:current mean train loss 9464.43244839892
INFO:root:current train perplexity2.5414958000183105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.32s/it]
INFO:root:final mean train loss: 9457.211002472908
INFO:root:final train perplexity: 2.5415799617767334
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.50s/it]
INFO:root:eval mean loss: 27163.243815104168
INFO:root:eval perplexity: 16.631168365478516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/148

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [2:14:16<47:07, 54.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9423.254266036185
INFO:root:current train perplexity2.5336170196533203
INFO:root:current mean train loss 9445.661288060897
INFO:root:current train perplexity2.5363926887512207


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.12s/it]
INFO:root:final mean train loss: 9447.128171859249
INFO:root:final train perplexity: 2.539053440093994
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.48s/it]
INFO:root:eval mean loss: 27157.572358630954
INFO:root:eval perplexity: 16.621410369873047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/149

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [2:15:10<46:10, 54.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9425.506129488032
INFO:root:current train perplexity2.535513401031494
INFO:root:current mean train loss 9430.244612298044
INFO:root:current train perplexity2.5328190326690674
INFO:root:current mean train loss 9440.646089005566
INFO:root:current train perplexity2.5355770587921143


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.42s/it]
INFO:root:final mean train loss: 9433.276942099294
INFO:root:final train perplexity: 2.5355868339538574
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it]
INFO:root:eval mean loss: 27235.22335379464
INFO:root:eval perplexity: 16.75552749633789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/150

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [2:16:05<45:18, 54.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9411.47129498106
INFO:root:current train perplexity2.5266273021698
INFO:root:current mean train loss 9418.870622644472
INFO:root:current train perplexity2.5288894176483154


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.27s/it]
INFO:root:final mean train loss: 9416.359788463962
INFO:root:final train perplexity: 2.5313596725463867
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it]
INFO:root:eval mean loss: 27242.18884858631
INFO:root:eval perplexity: 16.76761245727539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/151

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [2:16:59<44:23, 54.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9363.572763480392
INFO:root:current train perplexity2.5226449966430664
INFO:root:current mean train loss 9402.50492808361
INFO:root:current train perplexity2.5241851806640625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.28s/it]
INFO:root:final mean train loss: 9397.178766066028
INFO:root:final train perplexity: 2.5265750885009766
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it]
INFO:root:eval mean loss: 27255.416201636905
INFO:root:eval perplexity: 16.79058265686035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/152

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [2:17:54<43:29, 54.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9368.935221354166
INFO:root:current train perplexity2.538055658340454
INFO:root:current mean train loss 9374.735721328883
INFO:root:current train perplexity2.5215678215026855
INFO:root:current mean train loss 9385.461644665947
INFO:root:current train perplexity2.522231101989746


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it]
INFO:root:final mean train loss: 9385.18193201865
INFO:root:final train perplexity: 2.523587465286255
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it]
INFO:root:eval mean loss: 27302.78590029762
INFO:root:eval perplexity: 16.873098373413086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/153

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [2:18:48<42:33, 54.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9348.042613636364
INFO:root:current train perplexity2.526956558227539
INFO:root:current mean train loss 9369.519398941533
INFO:root:current train perplexity2.5183465480804443


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.04s/it]
INFO:root:final mean train loss: 9371.816821682838
INFO:root:final train perplexity: 2.520263195037842
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it]
INFO:root:eval mean loss: 27325.095377604168
INFO:root:eval perplexity: 16.912109375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/154

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [2:19:42<41:35, 54.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9332.139229910714
INFO:root:current train perplexity2.4938502311706543
INFO:root:current mean train loss 9354.243054541472
INFO:root:current train perplexity2.5096940994262695
INFO:root:current mean train loss 9364.517285628019
INFO:root:current train perplexity2.5144834518432617


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.28s/it]
INFO:root:final mean train loss: 9357.236206054688
INFO:root:final train perplexity: 2.5166409015655518
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.50s/it]
INFO:root:eval mean loss: 27319.707589285714
INFO:root:eval perplexity: 16.902671813964844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/155

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [2:20:36<40:43, 54.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9320.452181541314
INFO:root:current train perplexity2.5059399604797363
INFO:root:current mean train loss 9333.582135662342
INFO:root:current train perplexity2.510179042816162


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.14s/it]
INFO:root:final mean train loss: 9342.063098538307
INFO:root:final train perplexity: 2.5128774642944336
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it]
INFO:root:eval mean loss: 27344.079287574405
INFO:root:eval perplexity: 16.945369720458984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/156

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [2:21:30<39:48, 54.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9291.054953835228
INFO:root:current train perplexity2.504539728164673
INFO:root:current mean train loss 9320.746190526464
INFO:root:current train perplexity2.5084540843963623
INFO:root:current mean train loss 9335.707669949645
INFO:root:current train perplexity2.5114240646362305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it]
INFO:root:final mean train loss: 9335.070753528225
INFO:root:final train perplexity: 2.5111453533172607
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it]
INFO:root:eval mean loss: 27368.36365327381
INFO:root:eval perplexity: 16.988006591796875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/157

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [2:22:25<38:54, 54.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9321.006820436507
INFO:root:current train perplexity2.4936532974243164
INFO:root:current mean train loss 9331.298720283743
INFO:root:current train perplexity2.501345634460449


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.21s/it]
INFO:root:final mean train loss: 9322.505087575604
INFO:root:final train perplexity: 2.5080349445343018
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it]
INFO:root:eval mean loss: 27375.168154761905
INFO:root:eval perplexity: 16.99997901916504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/158

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [2:23:19<37:59, 54.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9317.1076171875
INFO:root:current train perplexity2.5023813247680664
INFO:root:current mean train loss 9298.779560122282
INFO:root:current train perplexity2.496427297592163
INFO:root:current mean train loss 9309.730491460756
INFO:root:current train perplexity2.5018107891082764


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.21s/it]
INFO:root:final mean train loss: 9308.194249306956
INFO:root:final train perplexity: 2.5044970512390137
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.38s/it]
INFO:root:eval mean loss: 27396.039992559523
INFO:root:eval perplexity: 17.03673553466797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/159

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [2:24:13<37:04, 54.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9275.711024953358
INFO:root:current train perplexity2.493640184402466
INFO:root:current mean train loss 9289.171418880987
INFO:root:current train perplexity2.4997663497924805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.11s/it]
INFO:root:final mean train loss: 9297.075750535534
INFO:root:final train perplexity: 2.5017523765563965
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it]
INFO:root:eval mean loss: 27412.181640625
INFO:root:eval perplexity: 17.065221786499023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/160

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [2:25:07<36:08, 54.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9257.191457648027
INFO:root:current train perplexity2.504488468170166
INFO:root:current mean train loss 9275.58102186187
INFO:root:current train perplexity2.4962611198425293
INFO:root:current mean train loss 9287.843522581335
INFO:root:current train perplexity2.4985201358795166


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.61s/it]
INFO:root:final mean train loss: 9284.297774776336
INFO:root:final train perplexity: 2.498601198196411
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.51s/it]
INFO:root:eval mean loss: 27451.13611421131
INFO:root:eval perplexity: 17.134164810180664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/161

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [2:26:02<35:20, 54.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9256.10772447183
INFO:root:current train perplexity2.4927475452423096
INFO:root:current mean train loss 9267.959161412646
INFO:root:current train perplexity2.4930338859558105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.15s/it]
INFO:root:final mean train loss: 9269.617831322455
INFO:root:final train perplexity: 2.494986057281494
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it]
INFO:root:eval mean loss: 27457.72195870536
INFO:root:eval perplexity: 17.145849227905273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/162

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [2:26:56<34:24, 54.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9265.114894701086
INFO:root:current train perplexity2.482193946838379
INFO:root:current mean train loss 9262.75107183689
INFO:root:current train perplexity2.4899699687957764
INFO:root:current mean train loss 9267.980722743834
INFO:root:current train perplexity2.4939541816711426


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it]
INFO:root:final mean train loss: 9265.455314390121
INFO:root:final train perplexity: 2.4939615726470947
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it]
INFO:root:eval mean loss: 27487.464425223214
INFO:root:eval perplexity: 17.198705673217773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/163

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [2:27:51<33:30, 54.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9234.360872395833
INFO:root:current train perplexity2.488452672958374
INFO:root:current mean train loss 9246.072025669642
INFO:root:current train perplexity2.489017963409424


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.22s/it]
INFO:root:final mean train loss: 9250.188645885837
INFO:root:final train perplexity: 2.4902093410491943
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it]
INFO:root:eval mean loss: 27491.63699776786
INFO:root:eval perplexity: 17.206132888793945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/164

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [2:28:45<32:35, 54.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9234.067418981482
INFO:root:current train perplexity2.478738784790039
INFO:root:current mean train loss 9251.50601316437
INFO:root:current train perplexity2.485816240310669
INFO:root:current mean train loss 9250.864989158865
INFO:root:current train perplexity2.488095998764038


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.39s/it]
INFO:root:final mean train loss: 9243.031913511215
INFO:root:final train perplexity: 2.488452196121216
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it]
INFO:root:eval mean loss: 27514.438337053572
INFO:root:eval perplexity: 17.246784210205078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/165

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [2:29:39<31:42, 54.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9218.407473793513
INFO:root:current train perplexity2.482182025909424
INFO:root:current mean train loss 9231.95910439944
INFO:root:current train perplexity2.4854846000671387


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.24s/it]
INFO:root:final mean train loss: 9233.240517893146
INFO:root:final train perplexity: 2.4860498905181885
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it]
INFO:root:eval mean loss: 27512.073800223214
INFO:root:eval perplexity: 17.24256706237793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/166

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [2:30:34<30:47, 54.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9225.125945060483
INFO:root:current train perplexity2.4814398288726807
INFO:root:current mean train loss 9223.93071624523
INFO:root:current train perplexity2.481517791748047
INFO:root:current mean train loss 9234.725374560336
INFO:root:current train perplexity2.483207941055298


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.09s/it]
INFO:root:final mean train loss: 9226.107280115928
INFO:root:final train perplexity: 2.4843013286590576
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it]
INFO:root:eval mean loss: 27537.606119791668
INFO:root:eval perplexity: 17.288183212280273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/167

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [2:31:28<29:51, 54.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9190.689676675453
INFO:root:current train perplexity2.477579116821289
INFO:root:current mean train loss 9216.04838520321
INFO:root:current train perplexity2.4787559509277344


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.22s/it]
INFO:root:final mean train loss: 9216.189689390121
INFO:root:final train perplexity: 2.48187255859375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it]
INFO:root:eval mean loss: 27562.13416108631
INFO:root:eval perplexity: 17.33213233947754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/168

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [2:32:22<28:57, 54.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9185.638643973214
INFO:root:current train perplexity2.4740171432495117
INFO:root:current mean train loss 9197.467274305556
INFO:root:current train perplexity2.478731632232666
INFO:root:current mean train loss 9211.217657081117
INFO:root:current train perplexity2.4788296222686768


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.14s/it]
INFO:root:final mean train loss: 9203.75679655998
INFO:root:final train perplexity: 2.4788310527801514
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.41s/it]
INFO:root:eval mean loss: 27588.961867559523
INFO:root:eval perplexity: 17.380321502685547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/169

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [2:33:16<28:01, 54.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9186.428026221265
INFO:root:current train perplexity2.470980405807495
INFO:root:current mean train loss 9196.032654787767
INFO:root:current train perplexity2.4769468307495117


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it]
INFO:root:final mean train loss: 9193.622497558594
INFO:root:final train perplexity: 2.4763545989990234
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.48s/it]
INFO:root:eval mean loss: 27585.019856770832
INFO:root:eval perplexity: 17.37323570251465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/170

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [2:34:11<27:07, 54.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9165.460987580129
INFO:root:current train perplexity2.467581033706665
INFO:root:current mean train loss 9177.35855300135
INFO:root:current train perplexity2.4708807468414307
INFO:root:current mean train loss 9190.547577798117
INFO:root:current train perplexity2.474010467529297


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.37s/it]
INFO:root:final mean train loss: 9186.03470734627
INFO:root:final train perplexity: 2.474501848220825
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it]
INFO:root:eval mean loss: 27604.671363467263
INFO:root:eval perplexity: 17.40860366821289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/171

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [2:35:06<26:23, 54.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9172.27276141827
INFO:root:current train perplexity2.4637451171875
INFO:root:current mean train loss 9181.735152159687
INFO:root:current train perplexity2.470445156097412


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.23s/it]
INFO:root:final mean train loss: 9177.569438319053
INFO:root:final train perplexity: 2.4724366664886475
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it]
INFO:root:eval mean loss: 27618.05138578869
INFO:root:eval perplexity: 17.432727813720703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/172

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [2:36:00<25:26, 54.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9127.849495821221
INFO:root:current train perplexity2.4662067890167236
INFO:root:current mean train loss 9159.472970388986
INFO:root:current train perplexity2.4665024280548096
INFO:root:current mean train loss 9169.76252652392
INFO:root:current train perplexity2.469226598739624


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.66s/it]
INFO:root:final mean train loss: 9162.898094915574
INFO:root:final train perplexity: 2.4688615798950195
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it]
INFO:root:eval mean loss: 27629.045433407737
INFO:root:eval perplexity: 17.45257568359375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/173

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [2:36:55<24:33, 54.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9154.738918585526
INFO:root:current train perplexity2.468985080718994
INFO:root:current mean train loss 9164.714127604168
INFO:root:current train perplexity2.4684159755706787


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.17s/it]
INFO:root:final mean train loss: 9162.94063641948
INFO:root:final train perplexity: 2.468871831893921
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it]
INFO:root:eval mean loss: 27637.504557291668
INFO:root:eval perplexity: 17.467859268188477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/174

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [2:37:49<23:36, 54.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9138.817902260638
INFO:root:current train perplexity2.460008382797241
INFO:root:current mean train loss 9150.393846991921
INFO:root:current train perplexity2.4648349285125732
INFO:root:current mean train loss 9162.864787607541
INFO:root:current train perplexity2.467109441757202


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.27s/it]
INFO:root:final mean train loss: 9155.609172205772
INFO:root:final train perplexity: 2.4670870304107666
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.44s/it]
INFO:root:eval mean loss: 27646.363188244046
INFO:root:eval perplexity: 17.483882904052734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/175

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [2:38:44<22:40, 54.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9148.38858309659
INFO:root:current train perplexity2.4629602432250977
INFO:root:current mean train loss 9151.219711840453
INFO:root:current train perplexity2.4633193016052246


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.32s/it]
INFO:root:final mean train loss: 9147.175836378528
INFO:root:final train perplexity: 2.465035915374756
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.50s/it]
INFO:root:eval mean loss: 27650.223074776786
INFO:root:eval perplexity: 17.49086570739746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/176

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [2:39:38<21:46, 54.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9117.963848039215
INFO:root:current train perplexity2.4656102657318115
INFO:root:current mean train loss 9138.470056394868
INFO:root:current train perplexity2.461834192276001


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.31s/it]
INFO:root:final mean train loss: 9140.228783392136
INFO:root:final train perplexity: 2.4633471965789795
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it]
INFO:root:eval mean loss: 27659.58765811012
INFO:root:eval perplexity: 17.50782585144043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/177

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [2:40:32<20:51, 54.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9079.494140625
INFO:root:current train perplexity2.4267523288726807
INFO:root:current mean train loss 9134.591825318568
INFO:root:current train perplexity2.4548306465148926
INFO:root:current mean train loss 9135.237468249692
INFO:root:current train perplexity2.459555149078369


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.07s/it]
INFO:root:final mean train loss: 9129.313413558468
INFO:root:final train perplexity: 2.4606971740722656
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it]
INFO:root:eval mean loss: 27686.885323660714
INFO:root:eval perplexity: 17.55735969543457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/178

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [2:41:27<19:55, 54.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9110.981498579546
INFO:root:current train perplexity2.4578168392181396
INFO:root:current mean train loss 9128.30282888105
INFO:root:current train perplexity2.4579455852508545


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.25s/it]
INFO:root:final mean train loss: 9123.91812232233
INFO:root:final train perplexity: 2.45938777923584
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.43s/it]
INFO:root:eval mean loss: 27697.712751116072
INFO:root:eval perplexity: 17.577049255371094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/179

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [2:42:21<19:00, 54.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9100.18861607143
INFO:root:current train perplexity2.4430902004241943
INFO:root:current mean train loss 9115.251405519859
INFO:root:current train perplexity2.4524266719818115
INFO:root:current mean train loss 9123.339806008455
INFO:root:current train perplexity2.4575247764587402


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.39s/it]
INFO:root:final mean train loss: 9119.377531974545
INFO:root:final train perplexity: 2.4582865238189697
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.51s/it]
INFO:root:eval mean loss: 27683.87965029762
INFO:root:eval perplexity: 17.551898956298828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/180

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [2:43:15<18:07, 54.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9106.80078125
INFO:root:current train perplexity2.4524009227752686
INFO:root:current mean train loss 9116.630582989386
INFO:root:current train perplexity2.4550015926361084


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it]
INFO:root:final mean train loss: 9110.830347861012
INFO:root:final train perplexity: 2.4562151432037354
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it]
INFO:root:eval mean loss: 27707.965773809523
INFO:root:eval perplexity: 17.595705032348633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/181

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [2:44:10<17:12, 54.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9113.203746448864
INFO:root:current train perplexity2.453005790710449
INFO:root:current mean train loss 9114.278698620496
INFO:root:current train perplexity2.4488630294799805
INFO:root:current mean train loss 9114.381748000593
INFO:root:current train perplexity2.4515459537506104


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.23s/it]
INFO:root:final mean train loss: 9102.833785518524
INFO:root:final train perplexity: 2.4542784690856934
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.48s/it]
INFO:root:eval mean loss: 27721.49865141369
INFO:root:eval perplexity: 17.620372772216797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/182

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [2:45:04<16:18, 54.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9103.616551959325
INFO:root:current train perplexity2.4431235790252686
INFO:root:current mean train loss 9105.495860093943
INFO:root:current train perplexity2.4486899375915527


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.23s/it]
INFO:root:final mean train loss: 9100.206322454636
INFO:root:final train perplexity: 2.4536423683166504
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it]
INFO:root:eval mean loss: 27723.896065848214
INFO:root:eval perplexity: 17.624746322631836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/183

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [2:45:58<15:23, 54.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9088.34765625
INFO:root:current train perplexity2.442329168319702
INFO:root:current mean train loss 9087.096127717392
INFO:root:current train perplexity2.450695037841797
INFO:root:current mean train loss 9096.835596838662
INFO:root:current train perplexity2.451364040374756


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it]
INFO:root:final mean train loss: 9093.057172221523
INFO:root:final train perplexity: 2.4519131183624268
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.48s/it]
INFO:root:eval mean loss: 27740.085100446428
INFO:root:eval perplexity: 17.654294967651367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/184

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [2:46:53<14:29, 54.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9087.595542793842
INFO:root:current train perplexity2.449491024017334
INFO:root:current mean train loss 9092.87256736527
INFO:root:current train perplexity2.449848175048828


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.50s/it]
INFO:root:final mean train loss: 9098.103176978326
INFO:root:final train perplexity: 2.4531335830688477
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it]
INFO:root:eval mean loss: 27735.37820870536
INFO:root:eval perplexity: 17.645706176757812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/185

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [2:47:47<13:36, 54.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9084.712376644737
INFO:root:current train perplexity2.4513192176818848
INFO:root:current mean train loss 9097.97400210084
INFO:root:current train perplexity2.4486894607543945
INFO:root:current mean train loss 9090.19592340896
INFO:root:current train perplexity2.4502265453338623


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.24s/it]
INFO:root:final mean train loss: 9085.443674395161
INFO:root:final train perplexity: 2.4500722885131836
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.50s/it]
INFO:root:eval mean loss: 27745.706008184523
INFO:root:eval perplexity: 17.664575576782227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/186

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [2:48:42<12:41, 54.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9082.429604973591
INFO:root:current train perplexity2.452275514602661
INFO:root:current mean train loss 9085.513186449196
INFO:root:current train perplexity2.4492807388305664


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.29s/it]
INFO:root:final mean train loss: 9080.738747873615
INFO:root:final train perplexity: 2.4489357471466064
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it]
INFO:root:eval mean loss: 27758.036783854168
INFO:root:eval perplexity: 17.68712615966797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/187

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [2:49:36<11:46, 54.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9086.900602921196
INFO:root:current train perplexity2.452730655670166
INFO:root:current mean train loss 9075.529717670224
INFO:root:current train perplexity2.4487361907958984
INFO:root:current mean train loss 9079.238246216368
INFO:root:current train perplexity2.447870969772339


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it]
INFO:root:final mean train loss: 9075.683526808216
INFO:root:final train perplexity: 2.4477150440216064
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it]
INFO:root:eval mean loss: 27763.890485491072
INFO:root:eval perplexity: 17.697845458984375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/188

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [2:50:30<10:52, 54.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9073.466015625
INFO:root:current train perplexity2.444765567779541
INFO:root:current mean train loss 9072.119458705358
INFO:root:current train perplexity2.4464240074157715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.28s/it]
INFO:root:final mean train loss: 9072.961276146674
INFO:root:final train perplexity: 2.4470577239990234
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.39s/it]
INFO:root:eval mean loss: 27772.68870907738
INFO:root:eval perplexity: 17.71397590637207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/189

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [2:51:25<09:57, 54.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9065.4404296875
INFO:root:current train perplexity2.4487674236297607
INFO:root:current mean train loss 9073.261557271162
INFO:root:current train perplexity2.4461252689361572
INFO:root:current mean train loss 9074.729956807543
INFO:root:current train perplexity2.4458093643188477


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.25s/it]
INFO:root:final mean train loss: 9067.087991037677
INFO:root:final train perplexity: 2.445640802383423
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it]
INFO:root:eval mean loss: 27768.730608258928
INFO:root:eval perplexity: 17.706716537475586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/190

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [2:52:19<09:03, 54.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9066.56385977057
INFO:root:current train perplexity2.4459383487701416
INFO:root:current mean train loss 9073.90490790852
INFO:root:current train perplexity2.4447197914123535


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.35s/it]
INFO:root:final mean train loss: 9071.069639144405
INFO:root:final train perplexity: 2.446601152420044
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.42s/it]
INFO:root:eval mean loss: 27773.332589285714
INFO:root:eval perplexity: 17.715145111083984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/191

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [2:53:13<08:09, 54.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9069.354114163307
INFO:root:current train perplexity2.4423394203186035
INFO:root:current mean train loss 9069.764573890745
INFO:root:current train perplexity2.4430296421051025
INFO:root:current mean train loss 9069.179708637717
INFO:root:current train perplexity2.443399429321289


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.40s/it]
INFO:root:final mean train loss: 9061.933385049144
INFO:root:final train perplexity: 2.4443976879119873
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it]
INFO:root:eval mean loss: 27779.515159970237
INFO:root:eval perplexity: 17.726490020751953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/192

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [2:54:08<07:15, 54.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9061.594479480422
INFO:root:current train perplexity2.44059157371521
INFO:root:current mean train loss 9067.688572617828
INFO:root:current train perplexity2.4408280849456787


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.19s/it]
INFO:root:final mean train loss: 9054.548826156124
INFO:root:final train perplexity: 2.442617893218994
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it]
INFO:root:eval mean loss: 27787.058175223214
INFO:root:eval perplexity: 17.74033546447754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/193

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [2:55:02<06:20, 54.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9055.509375
INFO:root:current train perplexity2.4410839080810547
INFO:root:current mean train loss 9063.37413917824
INFO:root:current train perplexity2.4444799423217773
INFO:root:current mean train loss 9061.616435339096
INFO:root:current train perplexity2.4437339305877686


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it]
INFO:root:final mean train loss: 9058.227755638862
INFO:root:final train perplexity: 2.4435040950775146
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.50s/it]
INFO:root:eval mean loss: 27790.672898065477
INFO:root:eval perplexity: 17.74696922302246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/194

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [2:55:56<05:25, 54.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9059.017308728447
INFO:root:current train perplexity2.4449002742767334
INFO:root:current mean train loss 9060.67666903409
INFO:root:current train perplexity2.4406280517578125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.25s/it]
INFO:root:final mean train loss: 9055.17386750252
INFO:root:final train perplexity: 2.4427685737609863
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.51s/it]
INFO:root:eval mean loss: 27796.996558779763
INFO:root:eval perplexity: 17.75859260559082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/195

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [2:56:51<04:31, 54.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9052.817482972756
INFO:root:current train perplexity2.4445719718933105
INFO:root:current mean train loss 9057.502810251799
INFO:root:current train perplexity2.4410276412963867
INFO:root:current mean train loss 9059.203210806747
INFO:root:current train perplexity2.4417836666107178


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.32s/it]
INFO:root:final mean train loss: 9052.517578125
INFO:root:final train perplexity: 2.4421284198760986
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.47s/it]
INFO:root:eval mean loss: 27798.926432291668
INFO:root:eval perplexity: 17.76214027404785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/196

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [2:57:45<03:37, 54.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9052.724877661401
INFO:root:current train perplexity2.4384777545928955
INFO:root:current mean train loss 9053.766054482985
INFO:root:current train perplexity2.4427578449249268


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.30s/it]
INFO:root:final mean train loss: 9049.351491620464
INFO:root:final train perplexity: 2.441366195678711
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.46s/it]
INFO:root:eval mean loss: 27793.72986421131
INFO:root:eval perplexity: 17.752593994140625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/197

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [2:58:39<02:43, 54.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9050.626612463662
INFO:root:current train perplexity2.439446210861206
INFO:root:current mean train loss 9053.459762893357
INFO:root:current train perplexity2.437955141067505
INFO:root:current mean train loss 9052.035730934927
INFO:root:current train perplexity2.440791130065918


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.37s/it]
INFO:root:final mean train loss: 9046.009848317792
INFO:root:final train perplexity: 2.440561532974243
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it]
INFO:root:eval mean loss: 27798.92061941964
INFO:root:eval perplexity: 17.762123107910156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/198

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [2:59:34<01:48, 54.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9042.639905427632
INFO:root:current train perplexity2.4400691986083984
INFO:root:current mean train loss 9046.260486778847
INFO:root:current train perplexity2.4396259784698486


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.39s/it]
INFO:root:final mean train loss: 9040.839359406502
INFO:root:final train perplexity: 2.439317226409912
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.45s/it]
INFO:root:eval mean loss: 27797.819428943454
INFO:root:eval perplexity: 17.760099411010742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [3:00:28<00:54, 54.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9040.604138962766
INFO:root:current train perplexity2.435797929763794
INFO:root:current mean train loss 9059.940230389031
INFO:root:current train perplexity2.4401750564575195
INFO:root:current mean train loss 9049.852562784667
INFO:root:current train perplexity2.4396469593048096


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.43s/it]
INFO:root:final mean train loss: 9042.548741494456
INFO:root:final train perplexity: 2.4397284984588623
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.49s/it]
INFO:root:eval mean loss: 27799.905366443454
INFO:root:eval perplexity: 17.763935089111328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: big_baseline_base/200

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [3:01:23<00:00, 54.44s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [3:01:23<00:00, 54.42s/it]
INFO:root:evaluating final model
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.48s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:06<00:00,  6.48s/it]
INFO:root:eval mean loss: 27799.905366443454
INFO:root:eval perplexity: 17.763935089111328
INFO:root:evalaution complete
INFO:root:save model final: big_baseline_base/final
