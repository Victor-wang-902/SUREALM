INFO:root:Output: small_multiqa_scratch
INFO:root:Steps per epochs:248
INFO:root:Total steps:49600
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/200 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
INFO:root:current mean train loss 99013.05989583333
INFO:root:current train perplexity17099.837890625
INFO:root:current mean train loss 95404.98355056533
INFO:root:current train perplexity12078.1318359375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.50s/it]
INFO:root:final mean train loss: 93457.70123487903
INFO:root:final train perplexity: 10076.30859375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:10<00:00, 70.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:10<00:00, 70.39s/it]
INFO:root:eval mean loss: 80105.17196800595
INFO:root:eval perplexity: 3985.985107421875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/1

  0%|          | 1/200 [08:42<28:51:33, 522.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 81891.87254901961
INFO:root:current train perplexity3197.814453125
INFO:root:current mean train loss 77512.71455918874
INFO:root:current train perplexity2055.704833984375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.33s/it]
INFO:root:final mean train loss: 72727.65226499496
INFO:root:final train perplexity: 1304.1290283203125
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:13<00:00, 73.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:13<00:00, 73.88s/it]
INFO:root:eval mean loss: 58804.95777529762
INFO:root:eval perplexity: 439.68585205078125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/2

  1%|          | 2/200 [17:29<28:52:31, 525.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 60808.677083333336
INFO:root:current train perplexity392.20440673828125
INFO:root:current mean train loss 56179.678246359224
INFO:root:current train perplexity254.86021423339844
INFO:root:current mean train loss 52867.35912484606
INFO:root:current train perplexity183.12008666992188


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.50s/it]
INFO:root:final mean train loss: 51579.7545047883
INFO:root:final train perplexity: 161.97251892089844
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:12<00:00, 72.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:12<00:00, 72.64s/it]
INFO:root:eval mean loss: 44870.992280505954
INFO:root:eval perplexity: 103.95460510253906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/3

  2%|â–         | 3/200 [26:06<28:32:28, 521.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 44095.80909090909
INFO:root:current train perplexity77.16156768798828
INFO:root:current mean train loss 42460.97273185484
INFO:root:current train perplexity65.18090057373047


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.99s/it]
INFO:root:final mean train loss: 41048.69068957913
INFO:root:final train perplexity: 57.32424545288086
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.36s/it]
INFO:root:eval mean loss: 38658.31170944941
INFO:root:eval perplexity: 54.65107727050781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/4

  2%|â–         | 4/200 [34:56<28:34:14, 524.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 37880.97154017857
INFO:root:current train perplexity41.592430114746094
INFO:root:current mean train loss 36790.587799357476
INFO:root:current train perplexity37.5555305480957
INFO:root:current mean train loss 35929.70927687198
INFO:root:current train perplexity34.50428009033203


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.37s/it]
INFO:root:final mean train loss: 35576.72626323085
INFO:root:final train perplexity: 33.41523742675781
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.15s/it]
INFO:root:eval mean loss: 35178.97442336309
INFO:root:eval perplexity: 38.12506866455078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/5

  2%|â–Ž         | 5/200 [43:48<28:34:40, 527.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 33065.887811175846
INFO:root:current train perplexity26.371673583984375
INFO:root:current mean train loss 32703.0673889544
INFO:root:current train perplexity25.089969635009766


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:32<00:00, 452.78s/it]
INFO:root:final mean train loss: 32188.703975554436
INFO:root:final train perplexity: 23.92308235168457
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.21s/it]
INFO:root:eval mean loss: 32914.47716703869
INFO:root:eval perplexity: 30.159706115722656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/6

  3%|â–Ž         | 6/200 [52:41<28:31:02, 529.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 30850.106711647728
INFO:root:current train perplexity20.80977439880371
INFO:root:current mean train loss 30379.755419481982
INFO:root:current train perplexity19.99985694885254
INFO:root:current mean train loss 30043.778389736373
INFO:root:current train perplexity19.32534408569336


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.09s/it]
INFO:root:final mean train loss: 29885.370258946572
INFO:root:final train perplexity: 19.061315536499023
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.66s/it]
INFO:root:eval mean loss: 31356.919270833332
INFO:root:eval perplexity: 25.66956329345703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/7

  4%|â–Ž         | 7/200 [1:01:40<28:32:40, 532.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 28726.928075396827
INFO:root:current train perplexity16.994779586791992
INFO:root:current mean train loss 28528.07654332822
INFO:root:current train perplexity16.611738204956055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.15s/it]
INFO:root:final mean train loss: 28249.526871219758
INFO:root:final train perplexity: 16.221115112304688
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.86s/it]
INFO:root:eval mean loss: 30211.900204613095
INFO:root:eval perplexity: 22.800939559936523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/8

  4%|â–         | 8/200 [1:10:35<28:26:47, 533.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 27604.961588541668
INFO:root:current train perplexity15.117420196533203
INFO:root:current mean train loss 27355.356419836957
INFO:root:current train perplexity14.732355117797852
INFO:root:current mean train loss 27043.200572311045
INFO:root:current train perplexity14.36120891571045


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.37s/it]
INFO:root:final mean train loss: 26959.86328125
INFO:root:final train perplexity: 14.283592224121094
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.26s/it]
INFO:root:eval mean loss: 29293.45252046131
INFO:root:eval perplexity: 20.733409881591797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/9

  4%|â–         | 9/200 [1:19:31<28:19:51, 533.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 26283.180008162315
INFO:root:current train perplexity13.314067840576172
INFO:root:current mean train loss 26083.175570733532
INFO:root:current train perplexity13.103524208068848


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.61s/it]
INFO:root:final mean train loss: 25931.43367250504
INFO:root:final train perplexity: 12.905777931213379
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.32s/it]
INFO:root:eval mean loss: 28574.3642578125
INFO:root:eval perplexity: 19.24638557434082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/10

  5%|â–Œ         | 10/200 [1:28:28<28:14:13, 535.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 25632.76480263158
INFO:root:current train perplexity12.344018936157227
INFO:root:current mean train loss 25263.074432116595
INFO:root:current train perplexity12.055949211120605
INFO:root:current mean train loss 25117.832521760844
INFO:root:current train perplexity11.891633033752441


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.64s/it]
INFO:root:final mean train loss: 25055.72275075605
INFO:root:final train perplexity: 11.837847709655762
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.69s/it]
INFO:root:eval mean loss: 28008.615652901786
INFO:root:eval perplexity: 18.151823043823242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/11

  6%|â–Œ         | 11/200 [1:37:30<28:12:04, 537.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24502.764084507042
INFO:root:current train perplexity11.214584350585938
INFO:root:current mean train loss 24412.464740953947
INFO:root:current train perplexity11.120464324951172


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.27s/it]
INFO:root:final mean train loss: 24347.357902280746
INFO:root:final train perplexity: 11.038994789123535
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.96s/it]
INFO:root:eval mean loss: 27502.867838541668
INFO:root:eval perplexity: 17.226146697998047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/12

  6%|â–Œ         | 12/200 [1:46:26<28:01:51, 536.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 23778.026834239132
INFO:root:current train perplexity10.620036125183105
INFO:root:current mean train loss 23887.778105945123
INFO:root:current train perplexity10.56123161315918
INFO:root:current mean train loss 23779.46460727298
INFO:root:current train perplexity10.422783851623535


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.55s/it]
INFO:root:final mean train loss: 23738.809373424898
INFO:root:final train perplexity: 10.395903587341309
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.64s/it]
INFO:root:eval mean loss: 27115.270414806546
INFO:root:eval perplexity: 16.548803329467773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/13

  6%|â–‹         | 13/200 [1:55:27<27:57:09, 538.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 23459.953541666666
INFO:root:current train perplexity10.055205345153809
INFO:root:current mean train loss 23306.582388392857
INFO:root:current train perplexity9.936630249023438


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.65s/it]
INFO:root:final mean train loss: 23207.15443075857
INFO:root:final train perplexity: 9.86480712890625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.47s/it]
INFO:root:eval mean loss: 26761.103469122023
INFO:root:eval perplexity: 15.953193664550781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/14

  7%|â–‹         | 14/200 [2:04:24<27:46:45, 537.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 23049.69777199074
INFO:root:current train perplexity9.665105819702148
INFO:root:current mean train loss 22844.15249753937
INFO:root:current train perplexity9.52400016784668
INFO:root:current mean train loss 22801.422787031937
INFO:root:current train perplexity9.458185195922852


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.98s/it]
INFO:root:final mean train loss: 22761.892530871977
INFO:root:final train perplexity: 9.440945625305176
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:18<00:00, 78.06s/it]
INFO:root:eval mean loss: 26468.06222098214
INFO:root:eval perplexity: 15.476616859436035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/15

  8%|â–Š         | 15/200 [2:13:27<27:42:48, 539.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 22509.54942147943
INFO:root:current train perplexity9.187352180480957
INFO:root:current mean train loss 22407.614143243714
INFO:root:current train perplexity9.110651969909668


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.29s/it]
INFO:root:final mean train loss: 22350.088544291833
INFO:root:final train perplexity: 9.065166473388672
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.54s/it]
INFO:root:eval mean loss: 26271.1630859375
INFO:root:eval perplexity: 15.164423942565918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/16

  8%|â–Š         | 16/200 [2:22:27<27:35:06, 539.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 22095.6736391129
INFO:root:current train perplexity8.893717765808105
INFO:root:current mean train loss 22072.071967437976
INFO:root:current train perplexity8.81275749206543
INFO:root:current mean train loss 22010.353431074134
INFO:root:current train perplexity8.756741523742676


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.97s/it]
INFO:root:final mean train loss: 21991.497723979333
INFO:root:final train perplexity: 8.750146865844727
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:27<00:00, 87.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:27<00:00, 87.51s/it]
INFO:root:eval mean loss: 25996.503371465773
INFO:root:eval perplexity: 14.739423751831055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/17

  8%|â–Š         | 17/200 [2:31:38<27:35:55, 542.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 21745.88241246235
INFO:root:current train perplexity8.540801048278809
INFO:root:current mean train loss 21729.082874402324
INFO:root:current train perplexity8.516242027282715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.94s/it]
INFO:root:final mean train loss: 21678.059790826614
INFO:root:final train perplexity: 8.483772277832031
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.45s/it]
INFO:root:eval mean loss: 25793.471214657737
INFO:root:eval perplexity: 14.432938575744629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/18

  9%|â–‰         | 18/200 [2:40:43<27:29:25, 543.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 21396.734486607143
INFO:root:current train perplexity8.280586242675781
INFO:root:current mean train loss 21468.020963541665
INFO:root:current train perplexity8.29426097869873
INFO:root:current mean train loss 21410.358685172872
INFO:root:current train perplexity8.256620407104492


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.59s/it]
INFO:root:final mean train loss: 21401.26636529738
INFO:root:final train perplexity: 8.255293846130371
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.85s/it]
INFO:root:eval mean loss: 25621.334658668155
INFO:root:eval perplexity: 14.17808723449707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/19

 10%|â–‰         | 19/200 [2:49:45<27:17:55, 542.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 21222.75168372845
INFO:root:current train perplexity8.092211723327637
INFO:root:current mean train loss 21182.92195855615
INFO:root:current train perplexity8.060790061950684


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.28s/it]
INFO:root:final mean train loss: 21144.289235761087
INFO:root:final train perplexity: 8.04868221282959
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.42s/it]
INFO:root:eval mean loss: 25437.300734747023
INFO:root:eval perplexity: 13.910599708557129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/20

 10%|â–ˆ         | 20/200 [2:58:48<27:08:57, 542.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20915.12950721154
INFO:root:current train perplexity7.894265651702881
INFO:root:current mean train loss 20962.34879440198
INFO:root:current train perplexity7.881157875061035
INFO:root:current mean train loss 20940.154844403765
INFO:root:current train perplexity7.872941493988037


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.02s/it]
INFO:root:final mean train loss: 20913.211315524193
INFO:root:final train perplexity: 7.867314338684082
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.74s/it]
INFO:root:eval mean loss: 25318.964936755954
INFO:root:eval perplexity: 13.741271018981934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/21

 10%|â–ˆ         | 21/200 [3:07:48<26:57:34, 542.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20763.472720638736
INFO:root:current train perplexity7.727946758270264
INFO:root:current mean train loss 20715.069249018325
INFO:root:current train perplexity7.710764408111572


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.66s/it]
INFO:root:final mean train loss: 20687.60342111895
INFO:root:final train perplexity: 7.694183349609375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.90s/it]
INFO:root:eval mean loss: 25180.277785528273
INFO:root:eval perplexity: 13.54544734954834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/22

 11%|â–ˆ         | 22/200 [3:16:48<26:46:32, 541.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20581.42432776163
INFO:root:current train perplexity7.547699928283691
INFO:root:current mean train loss 20569.501557036714
INFO:root:current train perplexity7.572451114654541
INFO:root:current mean train loss 20509.944315843622
INFO:root:current train perplexity7.544114112854004


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.32s/it]
INFO:root:final mean train loss: 20482.568698021674
INFO:root:final train perplexity: 7.5401458740234375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.97s/it]
INFO:root:eval mean loss: 25037.614815848214
INFO:root:eval perplexity: 13.346918106079102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/23

 12%|â–ˆâ–        | 23/200 [3:25:49<26:37:09, 541.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20448.716118421053
INFO:root:current train perplexity7.46640157699585
INFO:root:current mean train loss 20355.564012419873
INFO:root:current train perplexity7.421075344085693


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.69s/it]
INFO:root:final mean train loss: 20300.281202746977
INFO:root:final train perplexity: 7.405789852142334
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.66s/it]
INFO:root:eval mean loss: 24918.806594122023
INFO:root:eval perplexity: 13.183802604675293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/24

 12%|â–ˆâ–        | 24/200 [3:34:50<26:27:54, 541.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20148.810422207447
INFO:root:current train perplexity7.278232097625732
INFO:root:current mean train loss 20134.847231079933
INFO:root:current train perplexity7.274509906768799
INFO:root:current mean train loss 20143.00965492156
INFO:root:current train perplexity7.279750347137451


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.03s/it]
INFO:root:final mean train loss: 20126.249086441534
INFO:root:final train perplexity: 7.2797532081604
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.17s/it]
INFO:root:eval mean loss: 24860.56661551339
INFO:root:eval perplexity: 13.10457706451416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/25

 12%|â–ˆâ–Ž        | 25/200 [3:43:51<26:18:33, 541.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19987.91712042298
INFO:root:current train perplexity7.1785736083984375
INFO:root:current mean train loss 19981.111023869347
INFO:root:current train perplexity7.173073768615723


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.83s/it]
INFO:root:final mean train loss: 19961.58617376512
INFO:root:final train perplexity: 7.162477016448975
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.76s/it]
INFO:root:eval mean loss: 24745.32459077381
INFO:root:eval perplexity: 12.94920539855957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/26

 13%|â–ˆâ–Ž        | 26/200 [3:52:53<26:10:25, 541.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19858.889093137255
INFO:root:current train perplexity7.077754974365234
INFO:root:current mean train loss 19834.314918770695
INFO:root:current train perplexity7.064296722412109


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.82s/it]
INFO:root:final mean train loss: 19814.175584362398
INFO:root:final train perplexity: 7.059091567993164
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.68s/it]
INFO:root:eval mean loss: 24649.765927269345
INFO:root:eval perplexity: 12.821771621704102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/27

 14%|â–ˆâ–Ž        | 27/200 [4:01:55<26:01:02, 541.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19423.268880208332
INFO:root:current train perplexity6.920751094818115
INFO:root:current mean train loss 19662.689566899273
INFO:root:current train perplexity6.957767009735107
INFO:root:current mean train loss 19714.57178455973
INFO:root:current train perplexity6.976350784301758


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.92s/it]
INFO:root:final mean train loss: 19672.889872889366
INFO:root:final train perplexity: 6.961403846740723
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.07s/it]
INFO:root:eval mean loss: 24583.713960193454
INFO:root:eval perplexity: 12.734417915344238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/28

 14%|â–ˆâ–        | 28/200 [4:11:01<25:56:30, 542.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19526.896484375
INFO:root:current train perplexity6.872419357299805
INFO:root:current mean train loss 19577.20522933468
INFO:root:current train perplexity6.883820056915283


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.93s/it]
INFO:root:final mean train loss: 19541.52908423639
INFO:root:final train perplexity: 6.871789455413818
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.06s/it]
INFO:root:eval mean loss: 24517.591889880954
INFO:root:eval perplexity: 12.64756965637207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/29

 14%|â–ˆâ–        | 29/200 [4:20:03<25:46:14, 542.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19645.198381696428
INFO:root:current train perplexity6.920633792877197
INFO:root:current mean train loss 19468.085554176403
INFO:root:current train perplexity6.819066524505615
INFO:root:current mean train loss 19439.176988979467
INFO:root:current train perplexity6.792778491973877


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.46s/it]
INFO:root:final mean train loss: 19416.955093876008
INFO:root:final train perplexity: 6.787873268127441
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:25<00:00, 85.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:25<00:00, 85.47s/it]
INFO:root:eval mean loss: 24453.13402157738
INFO:root:eval perplexity: 12.5634765625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/30

 15%|â–ˆâ–Œ        | 30/200 [4:29:13<25:43:39, 544.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19450.95332362288
INFO:root:current train perplexity6.7438483238220215
INFO:root:current mean train loss 19321.51616548742
INFO:root:current train perplexity6.716813564300537


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.36s/it]
INFO:root:final mean train loss: 19297.54115344632
INFO:root:final train perplexity: 6.708393573760986
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.89s/it]
INFO:root:eval mean loss: 24365.824125744046
INFO:root:eval perplexity: 12.45046329498291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/31

 16%|â–ˆâ–Œ        | 31/200 [4:38:12<25:29:26, 543.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19371.153409090908
INFO:root:current train perplexity6.606318950653076
INFO:root:current mean train loss 19226.648138372748
INFO:root:current train perplexity6.640958309173584
INFO:root:current mean train loss 19174.63965306576
INFO:root:current train perplexity6.628152370452881


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.30s/it]
INFO:root:final mean train loss: 19185.470458984375
INFO:root:final train perplexity: 6.63464879989624
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.79s/it]
INFO:root:eval mean loss: 24310.15173921131
INFO:root:eval perplexity: 12.378931999206543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/32

 16%|â–ˆâ–Œ        | 32/200 [4:47:13<25:18:58, 542.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19077.336402529763
INFO:root:current train perplexity6.550225257873535
INFO:root:current mean train loss 19089.757057611198
INFO:root:current train perplexity6.557852268218994


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.06s/it]
INFO:root:final mean train loss: 19082.774382560485
INFO:root:final train perplexity: 6.567784786224365
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.74s/it]
INFO:root:eval mean loss: 24236.77906436012
INFO:root:eval perplexity: 12.285286903381348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/33

 16%|â–ˆâ–‹        | 33/200 [4:56:16<25:10:23, 542.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19186.727473958334
INFO:root:current train perplexity6.530857086181641
INFO:root:current mean train loss 18983.401358695653
INFO:root:current train perplexity6.504523754119873
INFO:root:current mean train loss 18990.777988735466
INFO:root:current train perplexity6.501062870025635


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.53s/it]
INFO:root:final mean train loss: 18979.35138530116
INFO:root:final train perplexity: 6.501128673553467
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.13s/it]
INFO:root:eval mean loss: 24226.019112723214
INFO:root:eval perplexity: 12.271613121032715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/34

 17%|â–ˆâ–‹        | 34/200 [5:05:20<25:02:18, 543.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18886.95414528918
INFO:root:current train perplexity6.4352521896362305
INFO:root:current mean train loss 18901.104883982036
INFO:root:current train perplexity6.449105262756348


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.16s/it]
INFO:root:final mean train loss: 18882.17808483493
INFO:root:final train perplexity: 6.439116477966309
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.44s/it]
INFO:root:eval mean loss: 24148.878487723214
INFO:root:eval perplexity: 12.17402458190918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/35

 18%|â–ˆâ–Š        | 35/200 [5:14:22<24:52:35, 542.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18644.739206414473
INFO:root:current train perplexity6.367602348327637
INFO:root:current mean train loss 18841.6305311187
INFO:root:current train perplexity6.389838695526123
INFO:root:current mean train loss 18801.88004780251
INFO:root:current train perplexity6.381101608276367


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.57s/it]
INFO:root:final mean train loss: 18784.150004725303
INFO:root:final train perplexity: 6.3771586418151855
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.31s/it]
INFO:root:eval mean loss: 24122.16748046875
INFO:root:eval perplexity: 12.140421867370605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/36

 18%|â–ˆâ–Š        | 36/200 [5:23:26<24:44:36, 543.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18739.742820202464
INFO:root:current train perplexity6.319999694824219
INFO:root:current mean train loss 18740.292123538013
INFO:root:current train perplexity6.329310894012451


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.33s/it]
INFO:root:final mean train loss: 18700.82703030494
INFO:root:final train perplexity: 6.324963569641113
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.26s/it]
INFO:root:eval mean loss: 24072.521833147322
INFO:root:eval perplexity: 12.078202247619629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/37

 18%|â–ˆâ–Š        | 37/200 [5:32:32<24:37:50, 543.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18565.78116508152
INFO:root:current train perplexity6.30840539932251
INFO:root:current mean train loss 18635.267879827235
INFO:root:current train perplexity6.289990425109863
INFO:root:current mean train loss 18634.728235355942
INFO:root:current train perplexity6.275935173034668


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.66s/it]
INFO:root:final mean train loss: 18615.578581779235
INFO:root:final train perplexity: 6.2720046043396
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:35<00:00, 95.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:35<00:00, 95.16s/it]
INFO:root:eval mean loss: 24048.463913690477
INFO:root:eval perplexity: 12.048164367675781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/38

 19%|â–ˆâ–‰        | 38/200 [5:41:54<24:43:20, 549.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18554.296223958332
INFO:root:current train perplexity6.215400695800781
INFO:root:current mean train loss 18528.233348214286
INFO:root:current train perplexity6.219580173492432


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.26s/it]
INFO:root:final mean train loss: 18536.992096931703
INFO:root:final train perplexity: 6.223577976226807
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.45s/it]
INFO:root:eval mean loss: 23976.97337704613
INFO:root:eval perplexity: 11.959351539611816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/39

 20%|â–ˆâ–‰        | 39/200 [5:50:55<24:27:44, 546.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18627.410517939814
INFO:root:current train perplexity6.169692516326904
INFO:root:current mean train loss 18489.938284325788
INFO:root:current train perplexity6.170526504516602
INFO:root:current mean train loss 18467.226588312224
INFO:root:current train perplexity6.172550201416016


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.86s/it]
INFO:root:final mean train loss: 18456.48644625756
INFO:root:final train perplexity: 6.174356460571289
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.28s/it]
INFO:root:eval mean loss: 23969.656436011905
INFO:root:eval perplexity: 11.950299263000488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/40

 20%|â–ˆâ–ˆ        | 40/200 [5:59:57<24:14:26, 545.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18374.673506724685
INFO:root:current train perplexity6.118381023406982
INFO:root:current mean train loss 18414.60114787011
INFO:root:current train perplexity6.133112907409668


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.59s/it]
INFO:root:final mean train loss: 18381.784439579133
INFO:root:final train perplexity: 6.129031181335449
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.80s/it]
INFO:root:eval mean loss: 23930.225190662204
INFO:root:eval perplexity: 11.901628494262695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/41

 20%|â–ˆâ–ˆ        | 41/200 [6:08:58<24:01:32, 543.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18343.456590221773
INFO:root:current train perplexity6.091350078582764
INFO:root:current mean train loss 18342.612968153626
INFO:root:current train perplexity6.085762023925781
INFO:root:current mean train loss 18314.309278612014
INFO:root:current train perplexity6.080190658569336


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.30s/it]
INFO:root:final mean train loss: 18308.240730531754
INFO:root:final train perplexity: 6.084732532501221
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.14s/it]
INFO:root:eval mean loss: 23906.22326078869
INFO:root:eval perplexity: 11.872100830078125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/42

 21%|â–ˆâ–ˆ        | 42/200 [6:17:58<23:49:45, 542.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18210.076171875
INFO:root:current train perplexity6.04986572265625
INFO:root:current mean train loss 18235.948012721994
INFO:root:current train perplexity6.045093059539795


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.29s/it]
INFO:root:final mean train loss: 18242.128973191786
INFO:root:final train perplexity: 6.045184135437012
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.41s/it]
INFO:root:eval mean loss: 23849.15792410714
INFO:root:eval perplexity: 11.802189826965332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/43

 22%|â–ˆâ–ˆâ–       | 43/200 [6:26:59<23:38:51, 542.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18213.217578125
INFO:root:current train perplexity6.040281295776367
INFO:root:current mean train loss 18224.049406828704
INFO:root:current train perplexity6.007580280303955
INFO:root:current mean train loss 18201.743126662233
INFO:root:current train perplexity6.007136344909668


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.82s/it]
INFO:root:final mean train loss: 18173.75720608619
INFO:root:final train perplexity: 6.00455379486084
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.52s/it]
INFO:root:eval mean loss: 23828.984468005954
INFO:root:eval perplexity: 11.77757453918457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/44

 22%|â–ˆâ–ˆâ–       | 44/200 [6:36:00<23:28:47, 541.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18086.85775862069
INFO:root:current train perplexity5.951039791107178
INFO:root:current mean train loss 18125.96949156083
INFO:root:current train perplexity5.962641716003418


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.56s/it]
INFO:root:final mean train loss: 18108.967214276712
INFO:root:final train perplexity: 5.966305732727051
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.85s/it]
INFO:root:eval mean loss: 23820.12179129464
INFO:root:eval perplexity: 11.766777038574219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/45

 22%|â–ˆâ–ˆâ–Ž       | 45/200 [6:45:06<23:23:35, 543.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18044.3551181891
INFO:root:current train perplexity5.94368839263916
INFO:root:current mean train loss 18003.438553844426
INFO:root:current train perplexity5.920917987823486
INFO:root:current mean train loss 18066.79875457636
INFO:root:current train perplexity5.931397438049316


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.44s/it]
INFO:root:final mean train loss: 18048.25474499118
INFO:root:final train perplexity: 5.9306840896606445
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:26<00:00, 86.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:26<00:00, 86.86s/it]
INFO:root:eval mean loss: 23766.33435639881
INFO:root:eval perplexity: 11.701452255249023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/46

 23%|â–ˆâ–ˆâ–Ž       | 46/200 [6:54:25<23:26:11, 547.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18000.01128949176
INFO:root:current train perplexity5.889209270477295
INFO:root:current mean train loss 18024.32161117474
INFO:root:current train perplexity5.899251937866211


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.23s/it]
INFO:root:final mean train loss: 17987.234949911795
INFO:root:final train perplexity: 5.895097255706787
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:27<00:00, 87.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:27<00:00, 87.45s/it]
INFO:root:eval mean loss: 23769.112165178572
INFO:root:eval perplexity: 11.704817771911621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/47

 24%|â–ˆâ–ˆâ–Ž       | 47/200 [7:03:38<23:21:19, 549.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17918.40393350291
INFO:root:current train perplexity5.874266624450684
INFO:root:current mean train loss 17944.46905048077
INFO:root:current train perplexity5.85973596572876
INFO:root:current mean train loss 17944.701195987655
INFO:root:current train perplexity5.862274169921875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.89s/it]
INFO:root:final mean train loss: 17931.589087701614
INFO:root:final train perplexity: 5.862831115722656
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.81s/it]
INFO:root:eval mean loss: 23725.66573660714
INFO:root:eval perplexity: 11.65230655670166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/48

 24%|â–ˆâ–ˆâ–       | 48/200 [7:12:42<23:07:55, 547.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17943.055982730264
INFO:root:current train perplexity5.844152927398682
INFO:root:current mean train loss 17904.98865184295
INFO:root:current train perplexity5.837101936340332


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:09<00:00, 489.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:09<00:00, 489.02s/it]
INFO:root:final mean train loss: 17872.998877740676
INFO:root:final train perplexity: 5.829048156738281
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:22<00:00, 82.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:22<00:00, 82.53s/it]
INFO:root:eval mean loss: 23725.13204520089
INFO:root:eval perplexity: 11.651662826538086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/49

 24%|â–ˆâ–ˆâ–       | 49/200 [7:22:17<23:19:16, 556.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17783.35908410904
INFO:root:current train perplexity5.793151378631592
INFO:root:current mean train loss 17803.62917198129
INFO:root:current train perplexity5.795037746429443
INFO:root:current mean train loss 17838.784650177124
INFO:root:current train perplexity5.801334381103516


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.07s/it]
INFO:root:final mean train loss: 17823.370101436492
INFO:root:final train perplexity: 5.800585746765137
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.22s/it]
INFO:root:eval mean loss: 23696.026878720237
INFO:root:eval perplexity: 11.616615295410156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/50

 25%|â–ˆâ–ˆâ–Œ       | 50/200 [7:31:34<23:10:22, 556.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17861.848129734848
INFO:root:current train perplexity5.796347141265869
INFO:root:current mean train loss 17795.87974049937
INFO:root:current train perplexity5.779017448425293


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.43s/it]
INFO:root:final mean train loss: 17768.676320722025
INFO:root:final train perplexity: 5.769377708435059
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.24s/it]
INFO:root:eval mean loss: 23674.90906343006
INFO:root:eval perplexity: 11.591257095336914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/51

 26%|â–ˆâ–ˆâ–Œ       | 51/200 [7:40:40<22:53:32, 553.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17625.408394607843
INFO:root:current train perplexity5.721550941467285
INFO:root:current mean train loss 17728.436206539736
INFO:root:current train perplexity5.742345333099365


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.51s/it]
INFO:root:final mean train loss: 17719.200537896926
INFO:root:final train perplexity: 5.7412919998168945
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.69s/it]
INFO:root:eval mean loss: 23690.140648251487
INFO:root:eval perplexity: 11.609540939331055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/52

 26%|â–ˆâ–ˆâ–Œ       | 52/200 [7:49:44<22:37:48, 550.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17402.170572916668
INFO:root:current train perplexity5.671285629272461
INFO:root:current mean train loss 17649.578087075242
INFO:root:current train perplexity5.696004390716553
INFO:root:current mean train loss 17678.042891779558
INFO:root:current train perplexity5.714580059051514


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.80s/it]
INFO:root:final mean train loss: 17666.727294921875
INFO:root:final train perplexity: 5.711654186248779
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.75s/it]
INFO:root:eval mean loss: 23615.346214657737
INFO:root:eval perplexity: 11.520021438598633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/53

 26%|â–ˆâ–ˆâ–‹       | 53/200 [7:58:49<22:24:45, 548.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17664.17784090909
INFO:root:current train perplexity5.699002742767334
INFO:root:current mean train loss 17636.75279737903
INFO:root:current train perplexity5.679558753967285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.78s/it]
INFO:root:final mean train loss: 17622.139502740676
INFO:root:final train perplexity: 5.686590671539307
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.00s/it]
INFO:root:eval mean loss: 23613.190476190477
INFO:root:eval perplexity: 11.517454147338867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/54

 27%|â–ˆâ–ˆâ–‹       | 54/200 [8:07:54<22:12:48, 547.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17624.297991071428
INFO:root:current train perplexity5.647942543029785
INFO:root:current mean train loss 17558.041691004673
INFO:root:current train perplexity5.638244152069092
INFO:root:current mean train loss 17580.1758520154
INFO:root:current train perplexity5.649943828582764


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.07s/it]
INFO:root:final mean train loss: 17571.781450825354
INFO:root:final train perplexity: 5.658415794372559
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.19s/it]
INFO:root:eval mean loss: 23617.265438988095
INFO:root:eval perplexity: 11.522310256958008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/55

 28%|â–ˆâ–ˆâ–Š       | 55/200 [8:17:02<22:03:36, 547.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17472.475718352754
INFO:root:current train perplexity5.6213698387146
INFO:root:current mean train loss 17530.737095862816
INFO:root:current train perplexity5.633514881134033


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.73s/it]
INFO:root:final mean train loss: 17524.16931939894
INFO:root:final train perplexity: 5.631906032562256
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.45s/it]
INFO:root:eval mean loss: 23573.704938616072
INFO:root:eval perplexity: 11.470479011535645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/56

 28%|â–ˆâ–ˆâ–Š       | 56/200 [8:26:07<21:52:21, 546.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17482.148792613636
INFO:root:current train perplexity5.612813472747803
INFO:root:current mean train loss 17489.558321016328
INFO:root:current train perplexity5.59961462020874
INFO:root:current mean train loss 17498.812699015107
INFO:root:current train perplexity5.607186794281006


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.91s/it]
INFO:root:final mean train loss: 17482.348042149697
INFO:root:final train perplexity: 5.60872220993042
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.68s/it]
INFO:root:eval mean loss: 23588.521414620536
INFO:root:eval perplexity: 11.48808479309082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/57

 28%|â–ˆâ–ˆâ–Š       | 57/200 [8:35:09<21:39:42, 545.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17368.562375992064
INFO:root:current train perplexity5.563312530517578
INFO:root:current mean train loss 17431.800889091257
INFO:root:current train perplexity5.576048374176025


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.44s/it]
INFO:root:final mean train loss: 17439.09320265247
INFO:root:final train perplexity: 5.584846019744873
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.62s/it]
INFO:root:eval mean loss: 23563.2509765625
INFO:root:eval perplexity: 11.458077430725098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/58

 29%|â–ˆâ–ˆâ–‰       | 58/200 [8:44:14<21:30:36, 545.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17305.066796875
INFO:root:current train perplexity5.536873817443848
INFO:root:current mean train loss 17425.425917119566
INFO:root:current train perplexity5.571175575256348
INFO:root:current mean train loss 17405.190915697673
INFO:root:current train perplexity5.561054706573486


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.10s/it]
INFO:root:final mean train loss: 17397.1937531502
INFO:root:final train perplexity: 5.561812400817871
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.59s/it]
INFO:root:eval mean loss: 23551.16834077381
INFO:root:eval perplexity: 11.443755149841309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/59

 30%|â–ˆâ–ˆâ–‰       | 59/200 [8:53:17<21:19:45, 544.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17336.469114388994
INFO:root:current train perplexity5.5332255363464355
INFO:root:current mean train loss 17347.963966598054
INFO:root:current train perplexity5.530208110809326


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.42s/it]
INFO:root:final mean train loss: 17356.17185137349
INFO:root:final train perplexity: 5.53935432434082
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.83s/it]
INFO:root:eval mean loss: 23544.05787295387
INFO:root:eval perplexity: 11.435341835021973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/60

 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [9:02:14<21:05:28, 542.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17339.555201480263
INFO:root:current train perplexity5.526544570922852
INFO:root:current mean train loss 17339.63645614496
INFO:root:current train perplexity5.521836757659912
INFO:root:current mean train loss 17342.452019121003
INFO:root:current train perplexity5.520753860473633


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.71s/it]
INFO:root:final mean train loss: 17311.809286794356
INFO:root:final train perplexity: 5.515170097351074
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.53s/it]
INFO:root:eval mean loss: 23553.06468563988
INFO:root:eval perplexity: 11.446003913879395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/61

 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [9:11:12<20:53:39, 541.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17341.189673195422
INFO:root:current train perplexity5.512226104736328
INFO:root:current mean train loss 17306.010719343933
INFO:root:current train perplexity5.498184680938721


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.10s/it]
INFO:root:final mean train loss: 17276.15607280116
INFO:root:final train perplexity: 5.495809555053711
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.34s/it]
INFO:root:eval mean loss: 23526.523902529763
INFO:root:eval perplexity: 11.414607048034668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/62

 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [9:20:12<20:44:00, 540.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17213.38773777174
INFO:root:current train perplexity5.4696760177612305
INFO:root:current mean train loss 17261.68186293191
INFO:root:current train perplexity5.480471134185791
INFO:root:current mean train loss 17264.297172785875
INFO:root:current train perplexity5.4787163734436035


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.33s/it]
INFO:root:final mean train loss: 17236.911707724295
INFO:root:final train perplexity: 5.474577903747559
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.28s/it]
INFO:root:eval mean loss: 23511.107840401786
INFO:root:eval perplexity: 11.396409034729004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/63

 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [9:29:11<20:33:37, 540.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17196.561875
INFO:root:current train perplexity5.454286098480225
INFO:root:current mean train loss 17196.19159598214
INFO:root:current train perplexity5.447582721710205


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.00s/it]
INFO:root:final mean train loss: 17198.203762915826
INFO:root:final train perplexity: 5.453716278076172
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.06s/it]
INFO:root:eval mean loss: 23472.03283110119
INFO:root:eval perplexity: 11.350412368774414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/64

 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [9:38:13<20:25:44, 540.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17166.298755787036
INFO:root:current train perplexity5.453220367431641
INFO:root:current mean train loss 17167.321604330707
INFO:root:current train perplexity5.434403896331787
INFO:root:current mean train loss 17179.693101252753
INFO:root:current train perplexity5.435485363006592


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.56s/it]
INFO:root:final mean train loss: 17161.609248991936
INFO:root:final train perplexity: 5.434067249298096
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.63s/it]
INFO:root:eval mean loss: 23489.851399739582
INFO:root:eval perplexity: 11.371366500854492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/65

 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [9:47:15<20:17:16, 541.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17109.805849485758
INFO:root:current train perplexity5.418570041656494
INFO:root:current mean train loss 17138.83064005761
INFO:root:current train perplexity5.4162445068359375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.65s/it]
INFO:root:final mean train loss: 17125.238308814263
INFO:root:final train perplexity: 5.414608001708984
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.99s/it]
INFO:root:eval mean loss: 23458.23888578869
INFO:root:eval perplexity: 11.334221839904785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/66

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [9:56:16<20:08:29, 541.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17060.662739415322
INFO:root:current train perplexity5.382273197174072
INFO:root:current mean train loss 17096.86510019084
INFO:root:current train perplexity5.38578987121582
INFO:root:current mean train loss 17098.729936079544
INFO:root:current train perplexity5.395001411437988


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.69s/it]
INFO:root:final mean train loss: 17091.005036384828
INFO:root:final train perplexity: 5.396356105804443
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.25s/it]
INFO:root:eval mean loss: 23487.509114583332
INFO:root:eval perplexity: 11.368609428405762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/67

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [10:05:12<19:56:08, 539.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17076.405649943525
INFO:root:current train perplexity5.364645481109619
INFO:root:current mean train loss 17058.341401980873
INFO:root:current train perplexity5.3762993812561035


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.46s/it]
INFO:root:final mean train loss: 17059.438645885835
INFO:root:final train perplexity: 5.379581928253174
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.12s/it]
INFO:root:eval mean loss: 23484.402436755954
INFO:root:eval perplexity: 11.36495304107666
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/68

 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [10:14:09<19:45:17, 538.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17035.587527901786
INFO:root:current train perplexity5.353700160980225
INFO:root:current mean train loss 16991.622265625
INFO:root:current train perplexity5.3418731689453125
INFO:root:current mean train loss 17040.291888297874
INFO:root:current train perplexity5.359528064727783


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.16s/it]
INFO:root:final mean train loss: 17023.881410660284
INFO:root:final train perplexity: 5.360747337341309
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.34s/it]
INFO:root:eval mean loss: 23454.511742001487
INFO:root:eval perplexity: 11.329848289489746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/69

 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [10:23:08<19:36:17, 538.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16944.394306752874
INFO:root:current train perplexity5.324034214019775
INFO:root:current mean train loss 16998.59935870655
INFO:root:current train perplexity5.336864471435547


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.44s/it]
INFO:root:final mean train loss: 16990.480027721773
INFO:root:final train perplexity: 5.343116760253906
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.91s/it]
INFO:root:eval mean loss: 23441.406761532737
INFO:root:eval perplexity: 11.314493179321289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/70

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [10:32:06<19:26:56, 538.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17041.452724358973
INFO:root:current train perplexity5.322042465209961
INFO:root:current mean train loss 16977.890877922662
INFO:root:current train perplexity5.323530673980713
INFO:root:current mean train loss 16972.42867416318
INFO:root:current train perplexity5.323836326599121


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.04s/it]
INFO:root:final mean train loss: 16959.427214591735
INFO:root:final train perplexity: 5.326776027679443
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.97s/it]
INFO:root:eval mean loss: 23436.1982421875
INFO:root:eval perplexity: 11.308396339416504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/71

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [10:41:03<19:16:58, 538.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17009.742691878433
INFO:root:current train perplexity5.321558475494385
INFO:root:current mean train loss 16952.276939831478
INFO:root:current train perplexity5.3105669021606445


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.76s/it]
INFO:root:final mean train loss: 16927.27601672757
INFO:root:final train perplexity: 5.309911251068115
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.04s/it]
INFO:root:eval mean loss: 23450.568870907737
INFO:root:eval perplexity: 11.325226783752441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/72

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [10:50:05<19:10:16, 539.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16772.81672420058
INFO:root:current train perplexity5.261414051055908
INFO:root:current mean train loss 16901.752615548514
INFO:root:current train perplexity5.299614906311035
INFO:root:current mean train loss 16910.046139564045
INFO:root:current train perplexity5.2953667640686035


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.71s/it]
INFO:root:final mean train loss: 16895.683932396674
INFO:root:final train perplexity: 5.293390274047852
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.75s/it]
INFO:root:eval mean loss: 23422.725167410714
INFO:root:eval perplexity: 11.29263973236084
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/73

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [10:59:00<18:58:54, 538.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16821.89300986842
INFO:root:current train perplexity5.267029762268066
INFO:root:current mean train loss 16860.97764423077
INFO:root:current train perplexity5.280620098114014


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.88s/it]
INFO:root:final mean train loss: 16870.442524571572
INFO:root:final train perplexity: 5.280228137969971
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.85s/it]
INFO:root:eval mean loss: 23413.16378348214
INFO:root:eval perplexity: 11.281466484069824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/74

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [11:08:02<18:52:25, 539.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16902.145570146276
INFO:root:current train perplexity5.290909767150879
INFO:root:current mean train loss 16873.93494233631
INFO:root:current train perplexity5.2766337394714355
INFO:root:current mean train loss 16856.48756958502
INFO:root:current train perplexity5.264321804046631


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.98s/it]
INFO:root:final mean train loss: 16840.077101184477
INFO:root:final train perplexity: 5.264438152313232
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.81s/it]
INFO:root:eval mean loss: 23421.443405877977
INFO:root:eval perplexity: 11.29114055633545
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/75

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [11:17:01<18:43:17, 539.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16817.10236150568
INFO:root:current train perplexity5.253942966461182
INFO:root:current mean train loss 16838.56627865892
INFO:root:current train perplexity5.2502851486206055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.95s/it]
INFO:root:final mean train loss: 16811.328310074347
INFO:root:final train perplexity: 5.2495317459106445
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.88s/it]
INFO:root:eval mean loss: 23427.748976934523
INFO:root:eval perplexity: 11.298513412475586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/76

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [11:25:59<18:33:30, 538.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16796.431659773283
INFO:root:current train perplexity5.2354559898376465
INFO:root:current mean train loss 16758.21841370033
INFO:root:current train perplexity5.2227911949157715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.82s/it]
INFO:root:final mean train loss: 16779.898350869455
INFO:root:final train perplexity: 5.233283042907715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:17<00:00, 77.98s/it]
INFO:root:eval mean loss: 23415.702171688987
INFO:root:eval perplexity: 11.28443431854248
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/77

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [11:34:58<18:24:28, 538.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16452.938802083332
INFO:root:current train perplexity5.1486735343933105
INFO:root:current mean train loss 16745.741239381066
INFO:root:current train perplexity5.208462238311768
INFO:root:current mean train loss 16755.050487800185
INFO:root:current train perplexity5.215000152587891


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.62s/it]
INFO:root:final mean train loss: 16753.78216749622
INFO:root:final train perplexity: 5.219820022583008
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.49s/it]
INFO:root:eval mean loss: 23387.98986235119
INFO:root:eval perplexity: 11.252114295959473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/78

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [11:43:58<18:16:09, 539.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16711.230806107953
INFO:root:current train perplexity5.194565773010254
INFO:root:current mean train loss 16740.24669858871
INFO:root:current train perplexity5.211543560028076


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.19s/it]
INFO:root:final mean train loss: 16727.505166330644
INFO:root:final train perplexity: 5.206308841705322
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.57s/it]
INFO:root:eval mean loss: 23385.74060639881
INFO:root:eval perplexity: 11.249496459960938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/79

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [11:53:38<18:32:18, 551.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16650.03292410714
INFO:root:current train perplexity5.1654486656188965
INFO:root:current mean train loss 16726.468631352218
INFO:root:current train perplexity5.193428039550781
INFO:root:current mean train loss 16716.85634152325
INFO:root:current train perplexity5.196115016937256


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.98s/it]
INFO:root:final mean train loss: 16700.42726578251
INFO:root:final train perplexity: 5.192422866821289
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.03s/it]
INFO:root:eval mean loss: 23417.24144345238
INFO:root:eval perplexity: 11.28623104095459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/80

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [12:03:58<19:03:40, 571.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16563.444269729873
INFO:root:current train perplexity5.154743671417236
INFO:root:current mean train loss 16669.386448506288
INFO:root:current train perplexity5.169323444366455


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.18s/it]
INFO:root:final mean train loss: 16671.288696289062
INFO:root:final train perplexity: 5.177521228790283
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.94s/it]
INFO:root:eval mean loss: 23389.935616629464
INFO:root:eval perplexity: 11.254382133483887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/81

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [12:12:53<18:32:17, 560.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16405.212002840908
INFO:root:current train perplexity5.079136848449707
INFO:root:current mean train loss 16636.551159557996
INFO:root:current train perplexity5.1533942222595215
INFO:root:current mean train loss 16646.891291469194
INFO:root:current train perplexity5.159969329833984


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.60s/it]
INFO:root:final mean train loss: 16645.925340221773
INFO:root:final train perplexity: 5.164585590362549
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:24<00:00, 84.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:24<00:00, 84.98s/it]
INFO:root:eval mean loss: 23385.500139508928
INFO:root:eval perplexity: 11.249217987060547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/82

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [12:23:23<19:03:41, 581.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16546.290380084327
INFO:root:current train perplexity5.137951850891113
INFO:root:current mean train loss 16651.150438554447
INFO:root:current train perplexity5.158547401428223


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.89s/it]
INFO:root:final mean train loss: 16622.56754426033
INFO:root:final train perplexity: 5.152700901031494
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.88s/it]
INFO:root:eval mean loss: 23374.734561011905
INFO:root:eval perplexity: 11.236685752868652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/83

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [12:32:25<18:31:18, 569.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16525.6794921875
INFO:root:current train perplexity5.11851692199707
INFO:root:current mean train loss 16574.11055536685
INFO:root:current train perplexity5.140701770782471
INFO:root:current mean train loss 16614.317432776163
INFO:root:current train perplexity5.143887519836426


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.77s/it]
INFO:root:final mean train loss: 16596.364942981352
INFO:root:final train perplexity: 5.139400959014893
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.88s/it]
INFO:root:eval mean loss: 23390.386625744046
INFO:root:eval perplexity: 11.254907608032227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/84

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [12:41:24<18:03:33, 560.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16541.524312033584
INFO:root:current train perplexity5.106551647186279
INFO:root:current mean train loss 16584.479211498878
INFO:root:current train perplexity5.131285190582275


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.92s/it]
INFO:root:final mean train loss: 16569.74622763357
INFO:root:final train perplexity: 5.125925540924072
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.04s/it]
INFO:root:eval mean loss: 23371.396484375
INFO:root:eval perplexity: 11.232807159423828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/85

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [12:50:24<17:42:33, 554.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16575.855365953947
INFO:root:current train perplexity5.119189262390137
INFO:root:current mean train loss 16525.292435333507
INFO:root:current train perplexity5.096877098083496
INFO:root:current mean train loss 16562.072568849886
INFO:root:current train perplexity5.109339714050293


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.47s/it]
INFO:root:final mean train loss: 16545.94205597908
INFO:root:final train perplexity: 5.113903999328613
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.29s/it]
INFO:root:eval mean loss: 23374.91090029762
INFO:root:eval perplexity: 11.236894607543945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/86

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [13:00:50<18:14:24, 576.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16535.68908175616
INFO:root:current train perplexity5.099042892456055
INFO:root:current mean train loss 16562.567497030337
INFO:root:current train perplexity5.107723712921143


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.59s/it]
INFO:root:final mean train loss: 16522.927336662047
INFO:root:final train perplexity: 5.1023101806640625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.46s/it]
INFO:root:eval mean loss: 23369.222028459822
INFO:root:eval perplexity: 11.230279922485352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/87

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [13:09:44<17:41:00, 563.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16351.450917119566
INFO:root:current train perplexity5.101315021514893
INFO:root:current mean train loss 16458.600697090955
INFO:root:current train perplexity5.085195064544678
INFO:root:current mean train loss 16517.797728944788
INFO:root:current train perplexity5.093896389007568


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.48s/it]
INFO:root:final mean train loss: 16500.977082283265
INFO:root:final train perplexity: 5.091274261474609
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.28s/it]
INFO:root:eval mean loss: 23394.160249255954
INFO:root:eval perplexity: 11.25930404663086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/88

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [13:18:43<17:17:47, 555.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16494.529088541665
INFO:root:current train perplexity5.079026222229004
INFO:root:current mean train loss 16491.90467075893
INFO:root:current train perplexity5.07710599899292


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.73s/it]
INFO:root:final mean train loss: 16475.33946966356
INFO:root:final train perplexity: 5.0784173011779785
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.28s/it]
INFO:root:eval mean loss: 23385.424967447918
INFO:root:eval perplexity: 11.249129295349121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/89

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [13:27:39<16:57:29, 550.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16520.438151041668
INFO:root:current train perplexity5.093000411987305
INFO:root:current mean train loss 16490.05591781496
INFO:root:current train perplexity5.072761058807373
INFO:root:current mean train loss 16475.046629783865
INFO:root:current train perplexity5.070215702056885


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.89s/it]
INFO:root:final mean train loss: 16452.357252551665
INFO:root:final train perplexity: 5.066917896270752
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.75s/it]
INFO:root:eval mean loss: 23371.10779389881
INFO:root:eval perplexity: 11.232470512390137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/90

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [13:36:37<16:41:33, 546.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16413.87282436709
INFO:root:current train perplexity5.049816131591797
INFO:root:current mean train loss 16427.493398655726
INFO:root:current train perplexity5.053869247436523


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.78s/it]
INFO:root:final mean train loss: 16432.228551064767
INFO:root:final train perplexity: 5.056869029998779
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.83s/it]
INFO:root:eval mean loss: 23373.087332589286
INFO:root:eval perplexity: 11.234773635864258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/91

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [13:45:35<16:28:05, 543.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16474.26130922379
INFO:root:current train perplexity5.068939685821533
INFO:root:current mean train loss 16412.4078676646
INFO:root:current train perplexity5.05452299118042
INFO:root:current mean train loss 16420.831845238095
INFO:root:current train perplexity5.045600414276123


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.19s/it]
INFO:root:final mean train loss: 16413.932097404235
INFO:root:final train perplexity: 5.047750473022461
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.85s/it]
INFO:root:eval mean loss: 23362.178176153273
INFO:root:eval perplexity: 11.222097396850586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/92

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [13:54:34<16:16:15, 542.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16379.328077936747
INFO:root:current train perplexity5.014768123626709
INFO:root:current mean train loss 16398.372764045424
INFO:root:current train perplexity5.027655601501465


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.11s/it]
INFO:root:final mean train loss: 16388.631906817038
INFO:root:final train perplexity: 5.035170078277588
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.03s/it]
INFO:root:eval mean loss: 23373.77648344494
INFO:root:eval perplexity: 11.235576629638672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/93

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [14:03:35<16:06:30, 541.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16414.95092075893
INFO:root:current train perplexity5.03852653503418
INFO:root:current mean train loss 16330.637384259258
INFO:root:current train perplexity5.0123443603515625
INFO:root:current mean train loss 16384.647564827126
INFO:root:current train perplexity5.026471138000488


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.65s/it]
INFO:root:final mean train loss: 16369.33843797253
INFO:root:final train perplexity: 5.02559757232666
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.89s/it]
INFO:root:eval mean loss: 23371.965285528273
INFO:root:eval perplexity: 11.233471870422363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/94

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [14:12:33<15:55:29, 540.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16351.936905082615
INFO:root:current train perplexity5.0245842933654785
INFO:root:current mean train loss 16343.098664146057
INFO:root:current train perplexity5.01106071472168


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.68s/it]
INFO:root:final mean train loss: 16348.458259828629
INFO:root:final train perplexity: 5.015258312225342
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.98s/it]
INFO:root:eval mean loss: 23374.90711030506
INFO:root:eval perplexity: 11.236889839172363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/95

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [14:21:32<15:45:27, 540.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16353.322966746795
INFO:root:current train perplexity5.011008262634277
INFO:root:current mean train loss 16332.730384442446
INFO:root:current train perplexity5.00355863571167
INFO:root:current mean train loss 16343.623361499738
INFO:root:current train perplexity5.004252910614014


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.89s/it]
INFO:root:final mean train loss: 16326.110005040322
INFO:root:final train perplexity: 5.004215240478516
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.71s/it]
INFO:root:eval mean loss: 23366.172340029763
INFO:root:eval perplexity: 11.22673511505127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/96

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [14:30:31<15:35:55, 539.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16337.638768458104
INFO:root:current train perplexity4.9861159324646
INFO:root:current mean train loss 16329.513482697972
INFO:root:current train perplexity4.993178367614746


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.79s/it]
INFO:root:final mean train loss: 16306.956826486896
INFO:root:final train perplexity: 4.994771480560303
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.41s/it]
INFO:root:eval mean loss: 23356.999488467263
INFO:root:eval perplexity: 11.216084480285645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/97

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [14:39:26<15:24:22, 538.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16339.44949127907
INFO:root:current train perplexity5.004957675933838
INFO:root:current mean train loss 16310.242515297203
INFO:root:current train perplexity4.989914894104004
INFO:root:current mean train loss 16302.996443383488
INFO:root:current train perplexity4.986551284790039


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.74s/it]
INFO:root:final mean train loss: 16290.728078534527
INFO:root:final train perplexity: 4.986782550811768
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.42s/it]
INFO:root:eval mean loss: 23362.32931082589
INFO:root:eval perplexity: 11.222270965576172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/98

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [14:48:24<15:15:06, 538.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16273.397481496711
INFO:root:current train perplexity4.974502086639404
INFO:root:current mean train loss 16282.013827123397
INFO:root:current train perplexity4.97915506362915


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.41s/it]
INFO:root:final mean train loss: 16265.854385868195
INFO:root:final train perplexity: 4.974562644958496
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.18s/it]
INFO:root:eval mean loss: 23367.381533668155
INFO:root:eval perplexity: 11.228140830993652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/99

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [14:57:20<15:04:51, 537.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16265.463555518618
INFO:root:current train perplexity4.950313568115234
INFO:root:current mean train loss 16272.862092102467
INFO:root:current train perplexity4.96779727935791
INFO:root:current mean train loss 16264.892593939778
INFO:root:current train perplexity4.967947959899902


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.41s/it]
INFO:root:final mean train loss: 16251.615348569809
INFO:root:final train perplexity: 4.967581272125244
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.92s/it]
INFO:root:eval mean loss: 23376.37430245536
INFO:root:eval perplexity: 11.238595962524414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/100

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [15:06:18<14:56:11, 537.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16187.354640151516
INFO:root:current train perplexity4.934316635131836
INFO:root:current mean train loss 16230.266842022613
INFO:root:current train perplexity4.955984115600586


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.37s/it]
INFO:root:final mean train loss: 16232.67917952999
INFO:root:final train perplexity: 4.958311557769775
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.22s/it]
INFO:root:eval mean loss: 23360.862932477678
INFO:root:eval perplexity: 11.220569610595703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/101

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [15:15:17<14:47:48, 538.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16228.531479779413
INFO:root:current train perplexity4.972474098205566
INFO:root:current mean train loss 16242.59917606581
INFO:root:current train perplexity4.956930637359619


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.39s/it]
INFO:root:final mean train loss: 16213.375157510081
INFO:root:final train perplexity: 4.948880672454834
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.39s/it]
INFO:root:eval mean loss: 23365.0244140625
INFO:root:eval perplexity: 11.225401878356934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/102

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [15:24:16<14:39:32, 538.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16361.2548828125
INFO:root:current train perplexity5.0114970207214355
INFO:root:current mean train loss 16154.793651395632
INFO:root:current train perplexity4.923135280609131
INFO:root:current mean train loss 16194.954000538793
INFO:root:current train perplexity4.933579444885254


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.61s/it]
INFO:root:final mean train loss: 16191.759702620968
INFO:root:final train perplexity: 4.93834114074707
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.21s/it]
INFO:root:eval mean loss: 23357.077101934523
INFO:root:eval perplexity: 11.21617317199707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/103

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [15:33:13<14:29:45, 537.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16217.273544034091
INFO:root:current train perplexity4.939198017120361
INFO:root:current mean train loss 16177.671213457661
INFO:root:current train perplexity4.925779342651367


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.65s/it]
INFO:root:final mean train loss: 16170.976259293095
INFO:root:final train perplexity: 4.928227424621582
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.38s/it]
INFO:root:eval mean loss: 23355.92159598214
INFO:root:eval perplexity: 11.21483325958252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/104

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [15:42:14<14:22:17, 538.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15996.437220982143
INFO:root:current train perplexity4.870412349700928
INFO:root:current mean train loss 16122.600093092873
INFO:root:current train perplexity4.908785343170166
INFO:root:current mean train loss 16157.311098845108
INFO:root:current train perplexity4.919342994689941


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.88s/it]
INFO:root:final mean train loss: 16160.948683215725
INFO:root:final train perplexity: 4.923356533050537
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.86s/it]
INFO:root:eval mean loss: 23366.424618675595
INFO:root:eval perplexity: 11.227029800415039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/105

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [15:51:14<14:13:34, 539.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16115.512248411016
INFO:root:current train perplexity4.9026665687561035
INFO:root:current mean train loss 16135.936658559356
INFO:root:current train perplexity4.907849311828613


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.11s/it]
INFO:root:final mean train loss: 16138.666791362148
INFO:root:final train perplexity: 4.912547588348389
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.69s/it]
INFO:root:eval mean loss: 23350.404227120536
INFO:root:eval perplexity: 11.208431243896484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/106
#################best#######
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [16:00:11<14:03:54, 538.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16022.721324573864
INFO:root:current train perplexity4.909031867980957
INFO:root:current mean train loss 16117.636868313626
INFO:root:current train perplexity4.899979591369629
INFO:root:current mean train loss 16140.334530509479
INFO:root:current train perplexity4.908658981323242


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.46s/it]
INFO:root:final mean train loss: 16120.16410187752
INFO:root:final train perplexity: 4.903591632843018
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.42s/it]
INFO:root:eval mean loss: 23371.74930245536
INFO:root:eval perplexity: 11.233220100402832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/107

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [16:09:13<13:56:18, 539.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16043.049107142857
INFO:root:current train perplexity4.874122142791748
INFO:root:current mean train loss 16111.795544957822
INFO:root:current train perplexity4.895618438720703


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.50s/it]
INFO:root:final mean train loss: 16103.73812767767
INFO:root:final train perplexity: 4.895653247833252
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.00s/it]
INFO:root:eval mean loss: 23384.107817150296
INFO:root:eval perplexity: 11.247597694396973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/108

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [16:18:12<13:47:15, 539.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15845.7193359375
INFO:root:current train perplexity4.809702396392822
INFO:root:current mean train loss 16120.525356657608
INFO:root:current train perplexity4.881567001342773
INFO:root:current mean train loss 16112.158825399709
INFO:root:current train perplexity4.890686511993408


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.41s/it]
INFO:root:final mean train loss: 16088.697501890121
INFO:root:final train perplexity: 4.888395309448242
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.27s/it]
INFO:root:eval mean loss: 23366.40490141369
INFO:root:eval perplexity: 11.227005958557129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/109

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [16:27:10<13:37:30, 539.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16015.536686683768
INFO:root:current train perplexity4.865495204925537
INFO:root:current mean train loss 16045.94630660554
INFO:root:current train perplexity4.8791704177856445


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.69s/it]
INFO:root:final mean train loss: 16074.489230248237
INFO:root:final train perplexity: 4.88154935836792
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.50s/it]
INFO:root:eval mean loss: 23387.08370535714
INFO:root:eval perplexity: 11.251060485839844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/110

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [16:36:09<13:28:10, 538.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16057.076017680922
INFO:root:current train perplexity4.884654521942139
INFO:root:current mean train loss 16084.831415769433
INFO:root:current train perplexity4.876397609710693
INFO:root:current mean train loss 16081.319929009704
INFO:root:current train perplexity4.874669551849365


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.28s/it]
INFO:root:final mean train loss: 16057.672611359627
INFO:root:final train perplexity: 4.873459815979004
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.12s/it]
INFO:root:eval mean loss: 23388.58958798363
INFO:root:eval perplexity: 11.252814292907715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/111

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [16:45:09<13:19:45, 539.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16056.59209947183
INFO:root:current train perplexity4.861103057861328
INFO:root:current mean train loss 16054.52031935307
INFO:root:current train perplexity4.859703540802002


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.47s/it]
INFO:root:final mean train loss: 16044.177698935231
INFO:root:final train perplexity: 4.866977214813232
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.85s/it]
INFO:root:eval mean loss: 23377.08084542411
INFO:root:eval perplexity: 11.239418983459473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/112

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [16:54:06<13:10:00, 538.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16100.360224184782
INFO:root:current train perplexity4.869877815246582
INFO:root:current mean train loss 16028.92017594004
INFO:root:current train perplexity4.851061820983887
INFO:root:current mean train loss 16035.817619289517
INFO:root:current train perplexity4.8578901290893555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.94s/it]
INFO:root:final mean train loss: 16028.371589906754
INFO:root:final train perplexity: 4.859395980834961
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.94s/it]
INFO:root:eval mean loss: 23380.25709170387
INFO:root:eval perplexity: 11.243115425109863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/113

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [17:03:05<13:01:06, 538.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15928.031328125
INFO:root:current train perplexity4.8284430503845215
INFO:root:current mean train loss 15991.408537946429
INFO:root:current train perplexity4.845419883728027


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.87s/it]
INFO:root:final mean train loss: 16010.83172016759
INFO:root:final train perplexity: 4.8509955406188965
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.20s/it]
INFO:root:eval mean loss: 23357.103352864582
INFO:root:eval perplexity: 11.216204643249512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/114

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [17:12:01<12:50:54, 537.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16058.781575520834
INFO:root:current train perplexity4.832051753997803
INFO:root:current mean train loss 16006.768408587599
INFO:root:current train perplexity4.839990139007568
INFO:root:current mean train loss 16002.222346503304
INFO:root:current train perplexity4.838624000549316


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.87s/it]
INFO:root:final mean train loss: 15994.977897397934
INFO:root:final train perplexity: 4.843416690826416
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.41s/it]
INFO:root:eval mean loss: 23396.643368675595
INFO:root:eval perplexity: 11.262198448181152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/115

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [17:20:59<12:41:59, 537.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15986.322327432754
INFO:root:current train perplexity4.827647686004639
INFO:root:current mean train loss 15985.354972285266
INFO:root:current train perplexity4.827808856964111


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.77s/it]
INFO:root:final mean train loss: 15980.998578471523
INFO:root:final train perplexity: 4.836743354797363
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.42s/it]
INFO:root:eval mean loss: 23383.4453125
INFO:root:eval perplexity: 11.246822357177734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/116

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [17:29:57<12:33:07, 537.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15890.53427419355
INFO:root:current train perplexity4.779646873474121
INFO:root:current mean train loss 15974.735433563932
INFO:root:current train perplexity4.81051778793335
INFO:root:current mean train loss 15970.495857007576
INFO:root:current train perplexity4.825940132141113


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.92s/it]
INFO:root:final mean train loss: 15960.30867250504
INFO:root:final train perplexity: 4.826882839202881
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.81s/it]
INFO:root:eval mean loss: 23390.777901785714
INFO:root:eval perplexity: 11.255361557006836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/117

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [17:38:59<12:26:01, 539.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15940.200818900603
INFO:root:current train perplexity4.830227851867676
INFO:root:current mean train loss 15979.062281207309
INFO:root:current train perplexity4.828492641448975


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.27s/it]
INFO:root:final mean train loss: 15954.05193501134
INFO:root:final train perplexity: 4.823904991149902
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.52s/it]
INFO:root:eval mean loss: 23373.933151971727
INFO:root:eval perplexity: 11.235756874084473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/118

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [17:48:02<12:18:17, 540.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16044.341099330357
INFO:root:current train perplexity4.818377494812012
INFO:root:current mean train loss 15962.982523148148
INFO:root:current train perplexity4.822237968444824
INFO:root:current mean train loss 15946.592278922872
INFO:root:current train perplexity4.816901206970215


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.72s/it]
INFO:root:final mean train loss: 15938.768294795867
INFO:root:final train perplexity: 4.816638946533203
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.45s/it]
INFO:root:eval mean loss: 23400.625534784227
INFO:root:eval perplexity: 11.266841888427734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/119

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [17:56:59<12:08:21, 539.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15974.156418372844
INFO:root:current train perplexity4.813959121704102
INFO:root:current mean train loss 15951.82722154913
INFO:root:current train perplexity4.815191745758057


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.64s/it]
INFO:root:final mean train loss: 15925.91439720892
INFO:root:final train perplexity: 4.810536861419678
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.26s/it]
INFO:root:eval mean loss: 23390.936500186013
INFO:root:eval perplexity: 11.255546569824219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/120

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [18:05:57<11:58:34, 538.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15885.50415665064
INFO:root:current train perplexity4.801664352416992
INFO:root:current mean train loss 15911.724574246853
INFO:root:current train perplexity4.799984455108643
INFO:root:current mean train loss 15926.105542298641
INFO:root:current train perplexity4.806000232696533


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.75s/it]
INFO:root:final mean train loss: 15912.81967064642
INFO:root:final train perplexity: 4.80432653427124
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.23s/it]
INFO:root:eval mean loss: 23368.45191592262
INFO:root:eval perplexity: 11.229385375976562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/121

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [18:14:56<11:49:31, 538.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15876.945140796703
INFO:root:current train perplexity4.798038959503174
INFO:root:current mean train loss 15905.309145942409
INFO:root:current train perplexity4.79530668258667


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.26s/it]
INFO:root:final mean train loss: 15900.174269153225
INFO:root:final train perplexity: 4.798338413238525
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.08s/it]
INFO:root:eval mean loss: 23386.386579241072
INFO:root:eval perplexity: 11.250249862670898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/122

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [18:23:56<11:41:03, 539.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15911.789562136628
INFO:root:current train perplexity4.767866134643555
INFO:root:current mean train loss 15902.350524475525
INFO:root:current train perplexity4.78668212890625
INFO:root:current mean train loss 15896.71403597608
INFO:root:current train perplexity4.790966033935547


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.41s/it]
INFO:root:final mean train loss: 15885.426497920867
INFO:root:final train perplexity: 4.79136323928833
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.07s/it]
INFO:root:eval mean loss: 23406.472005208332
INFO:root:eval perplexity: 11.273658752441406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/123

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [18:32:56<11:32:26, 539.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15857.679975328947
INFO:root:current train perplexity4.765265464782715
INFO:root:current mean train loss 15873.15009014423
INFO:root:current train perplexity4.781292915344238


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.46s/it]
INFO:root:final mean train loss: 15870.904840284778
INFO:root:final train perplexity: 4.784505844116211
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 76.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 76.00s/it]
INFO:root:eval mean loss: 23388.133114769345
INFO:root:eval perplexity: 11.252283096313477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/124

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [18:41:57<11:24:04, 540.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15862.247340425532
INFO:root:current train perplexity4.760406970977783
INFO:root:current mean train loss 15847.568698182398
INFO:root:current train perplexity4.7772040367126465
INFO:root:current mean train loss 15868.134097450658
INFO:root:current train perplexity4.77716064453125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.95s/it]
INFO:root:final mean train loss: 15855.391235351562
INFO:root:final train perplexity: 4.777190208435059
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.62s/it]
INFO:root:eval mean loss: 23392.568173363095
INFO:root:eval perplexity: 11.25744915008545
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/125

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [18:50:55<11:14:10, 539.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15824.185527146465
INFO:root:current train perplexity4.7667765617370605
INFO:root:current mean train loss 15833.04043165044
INFO:root:current train perplexity4.768364906311035


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.76s/it]
INFO:root:final mean train loss: 15844.686566752773
INFO:root:final train perplexity: 4.772150039672852
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.98s/it]
INFO:root:eval mean loss: 23369.519391741072
INFO:root:eval perplexity: 11.23062515258789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/126

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [18:59:55<11:05:13, 539.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15891.064204197304
INFO:root:current train perplexity4.778397560119629
INFO:root:current mean train loss 15843.579282646937
INFO:root:current train perplexity4.7610883712768555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.43s/it]
INFO:root:final mean train loss: 15827.345498361896
INFO:root:final train perplexity: 4.763994216918945
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.03s/it]
INFO:root:eval mean loss: 23397.28650483631
INFO:root:eval perplexity: 11.262947082519531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/127

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [19:08:51<10:55:01, 538.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16125.2041015625
INFO:root:current train perplexity4.879770755767822
INFO:root:current mean train loss 15818.144853610436
INFO:root:current train perplexity4.766356468200684
INFO:root:current mean train loss 15827.71392010468
INFO:root:current train perplexity4.759308338165283


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.27s/it]
INFO:root:final mean train loss: 15821.603464434223
INFO:root:final train perplexity: 4.761297225952148
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.94s/it]
INFO:root:eval mean loss: 23392.16882905506
INFO:root:eval perplexity: 11.25698471069336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/128

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [19:17:49<10:46:03, 538.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15872.340056818182
INFO:root:current train perplexity4.7675251960754395
INFO:root:current mean train loss 15837.00490171371
INFO:root:current train perplexity4.756641387939453


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.59s/it]
INFO:root:final mean train loss: 15809.826455393146
INFO:root:final train perplexity: 4.7557692527771
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.87s/it]
INFO:root:eval mean loss: 23382.775692894345
INFO:root:eval perplexity: 11.246045112609863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/129

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [19:26:47<10:36:59, 538.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15786.397739955357
INFO:root:current train perplexity4.804741859436035
INFO:root:current mean train loss 15781.489449474298
INFO:root:current train perplexity4.748328685760498
INFO:root:current mean train loss 15791.715758982487
INFO:root:current train perplexity4.744399547576904


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.96s/it]
INFO:root:final mean train loss: 15795.337083385837
INFO:root:final train perplexity: 4.7489776611328125
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.65s/it]
INFO:root:eval mean loss: 23378.787527901786
INFO:root:eval perplexity: 11.241402626037598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/130

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [19:35:47<10:28:43, 538.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15768.360798463984
INFO:root:current train perplexity4.722548007965088
INFO:root:current mean train loss 15777.207393622248
INFO:root:current train perplexity4.726378917694092


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.26s/it]
INFO:root:final mean train loss: 15782.727326423892
INFO:root:final train perplexity: 4.743074893951416
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.37s/it]
INFO:root:eval mean loss: 23409.89122953869
INFO:root:eval perplexity: 11.277650833129883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/131

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [19:44:50<10:20:56, 539.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15671.414240056818
INFO:root:current train perplexity4.730236053466797
INFO:root:current mean train loss 15763.852195945947
INFO:root:current train perplexity4.720203876495361
INFO:root:current mean train loss 15775.364007886552
INFO:root:current train perplexity4.735430717468262


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.88s/it]
INFO:root:final mean train loss: 15774.721333165322
INFO:root:final train perplexity: 4.739331245422363
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.55s/it]
INFO:root:eval mean loss: 23404.353864397322
INFO:root:eval perplexity: 11.271185874938965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/132

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [19:53:49<10:11:42, 539.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15767.609328497023
INFO:root:current train perplexity4.724776744842529
INFO:root:current mean train loss 15759.675146184816
INFO:root:current train perplexity4.722067356109619


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.40s/it]
INFO:root:final mean train loss: 15758.653233681956
INFO:root:final train perplexity: 4.731825828552246
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.30s/it]
INFO:root:eval mean loss: 23397.781715029763
INFO:root:eval perplexity: 11.263522148132324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/133

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [20:02:47<10:01:57, 539.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15733.399934895833
INFO:root:current train perplexity4.6984992027282715
INFO:root:current mean train loss 15745.452021059782
INFO:root:current train perplexity4.72999382019043
INFO:root:current mean train loss 15753.080904796512
INFO:root:current train perplexity4.7268266677856445


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.96s/it]
INFO:root:final mean train loss: 15753.234032415574
INFO:root:final train perplexity: 4.729297161102295
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.25s/it]
INFO:root:eval mean loss: 23402.965680803572
INFO:root:eval perplexity: 11.26956844329834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/134

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [20:11:44<9:52:23, 538.54s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15732.804075326492
INFO:root:current train perplexity4.723285675048828
INFO:root:current mean train loss 15757.931389174775
INFO:root:current train perplexity4.720738887786865


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.33s/it]
INFO:root:final mean train loss: 15740.057136781754
INFO:root:final train perplexity: 4.723154544830322
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.47s/it]
INFO:root:eval mean loss: 23394.662155877977
INFO:root:eval perplexity: 11.259888648986816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/135

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [20:20:40<9:42:44, 537.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15736.15470805921
INFO:root:current train perplexity4.725099086761475
INFO:root:current mean train loss 15700.12375262605
INFO:root:current train perplexity4.698439121246338
INFO:root:current mean train loss 15719.905099529109
INFO:root:current train perplexity4.714182376861572


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.47s/it]
INFO:root:final mean train loss: 15732.216962260585
INFO:root:final train perplexity: 4.719503879547119
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.14s/it]
INFO:root:eval mean loss: 23425.190290178572
INFO:root:eval perplexity: 11.295520782470703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/136

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [20:29:39<9:33:56, 538.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15732.663099691901
INFO:root:current train perplexity4.707475662231445
INFO:root:current mean train loss 15707.947745339912
INFO:root:current train perplexity4.709222793579102


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.96s/it]
INFO:root:final mean train loss: 15720.211488785282
INFO:root:final train perplexity: 4.713918685913086
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.72s/it]
INFO:root:eval mean loss: 23404.775739397322
INFO:root:eval perplexity: 11.27168083190918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/137

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [20:38:38<9:25:23, 538.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15829.500891644022
INFO:root:current train perplexity4.739874839782715
INFO:root:current mean train loss 15688.115409044716
INFO:root:current train perplexity4.708590507507324
INFO:root:current mean train loss 15707.172330437219
INFO:root:current train perplexity4.710707664489746


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.08s/it]
INFO:root:final mean train loss: 15708.320785030242
INFO:root:final train perplexity: 4.708393096923828
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.34s/it]
INFO:root:eval mean loss: 23396.610305059523
INFO:root:eval perplexity: 11.262163162231445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/138

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [20:47:38<9:16:43, 538.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15618.032486979168
INFO:root:current train perplexity4.684410572052002
INFO:root:current mean train loss 15698.988828125
INFO:root:current train perplexity4.695923805236816


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.29s/it]
INFO:root:final mean train loss: 15697.823112241684
INFO:root:final train perplexity: 4.703520774841309
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.56s/it]
INFO:root:eval mean loss: 23430.53634207589
INFO:root:eval perplexity: 11.301773071289062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/139

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [20:56:38<9:08:17, 539.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15702.101273148148
INFO:root:current train perplexity4.690973281860352
INFO:root:current mean train loss 15653.227254552165
INFO:root:current train perplexity4.682347297668457
INFO:root:current mean train loss 15696.815343646751
INFO:root:current train perplexity4.696763515472412


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.08s/it]
INFO:root:final mean train loss: 15689.084141885081
INFO:root:final train perplexity: 4.69946813583374
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.43s/it]
INFO:root:eval mean loss: 23406.077008928572
INFO:root:eval perplexity: 11.273201942443848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/140

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [21:05:37<8:59:08, 539.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15726.536033920094
INFO:root:current train perplexity4.708092212677002
INFO:root:current mean train loss 15695.805942300978
INFO:root:current train perplexity4.70035457611084


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.33s/it]
INFO:root:final mean train loss: 15680.189063287551
INFO:root:final train perplexity: 4.695347309112549
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.31s/it]
INFO:root:eval mean loss: 23415.78185453869
INFO:root:eval perplexity: 11.284524917602539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/141

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [21:14:38<8:50:48, 539.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15535.479555191532
INFO:root:current train perplexity4.660120964050293
INFO:root:current mean train loss 15658.149078602099
INFO:root:current train perplexity4.6839375495910645
INFO:root:current mean train loss 15671.962446732954
INFO:root:current train perplexity4.6855244636535645


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.26s/it]
INFO:root:final mean train loss: 15664.778178553428
INFO:root:final train perplexity: 4.688216209411621
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.79s/it]
INFO:root:eval mean loss: 23408.395903087796
INFO:root:eval perplexity: 11.27590274810791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/142

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [21:23:39<8:41:56, 539.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15690.583701995482
INFO:root:current train perplexity4.69328498840332
INFO:root:current mean train loss 15688.603707735656
INFO:root:current train perplexity4.689393997192383


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.03s/it]
INFO:root:final mean train loss: 15658.027863533267
INFO:root:final train perplexity: 4.685095310211182
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.64s/it]
INFO:root:eval mean loss: 23411.252604166668
INFO:root:eval perplexity: 11.279239654541016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/143

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [21:32:36<8:32:20, 539.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15724.101004464286
INFO:root:current train perplexity4.702262878417969
INFO:root:current mean train loss 15660.782414641204
INFO:root:current train perplexity4.683270454406738
INFO:root:current mean train loss 15665.256640625
INFO:root:current train perplexity4.683296203613281


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.14s/it]
INFO:root:final mean train loss: 15653.581755607358
INFO:root:final train perplexity: 4.683041572570801
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.50s/it]
INFO:root:eval mean loss: 23422.584658668155
INFO:root:eval perplexity: 11.292472839355469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/144

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [21:41:37<8:23:39, 539.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15694.697220725575
INFO:root:current train perplexity4.669046878814697
INFO:root:current mean train loss 15645.786670705214
INFO:root:current train perplexity4.667002201080322


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.35s/it]
INFO:root:final mean train loss: 15644.470112462197
INFO:root:final train perplexity: 4.678834915161133
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.64s/it]
INFO:root:eval mean loss: 23435.440266927082
INFO:root:eval perplexity: 11.307509422302246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/145

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [21:50:35<8:14:24, 539.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15656.595227363781
INFO:root:current train perplexity4.6646833419799805
INFO:root:current mean train loss 15621.94113225045
INFO:root:current train perplexity4.671711444854736
INFO:root:current mean train loss 15640.758650137292
INFO:root:current train perplexity4.67241096496582


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.63s/it]
INFO:root:final mean train loss: 15632.497353830646
INFO:root:final train perplexity: 4.673311710357666
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.63s/it]
INFO:root:eval mean loss: 23414.956496465773
INFO:root:eval perplexity: 11.283564567565918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/146

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [21:59:36<8:05:41, 539.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15620.675373454671
INFO:root:current train perplexity4.671074867248535
INFO:root:current mean train loss 15637.056952511453
INFO:root:current train perplexity4.668888092041016


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.72s/it]
INFO:root:final mean train loss: 15621.68542874244
INFO:root:final train perplexity: 4.668331623077393
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.37s/it]
INFO:root:eval mean loss: 23433.76941499256
INFO:root:eval perplexity: 11.305551528930664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/147

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [22:08:36<7:56:44, 539.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15604.39882358285
INFO:root:current train perplexity4.669331073760986
INFO:root:current mean train loss 15621.83194247159
INFO:root:current train perplexity4.66691255569458
INFO:root:current mean train loss 15626.767835326646
INFO:root:current train perplexity4.664447784423828


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.91s/it]
INFO:root:final mean train loss: 15616.23527280746
INFO:root:final train perplexity: 4.665822505950928
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.21s/it]
INFO:root:eval mean loss: 23429.938546316964
INFO:root:eval perplexity: 11.30107307434082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/148

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [22:17:36<7:47:46, 539.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15585.485248766447
INFO:root:current train perplexity4.665496349334717
INFO:root:current mean train loss 15610.145663060897
INFO:root:current train perplexity4.6613593101501465


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.83s/it]
INFO:root:final mean train loss: 15609.555478988155
INFO:root:final train perplexity: 4.662749290466309
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.79s/it]
INFO:root:eval mean loss: 23427.621628534227
INFO:root:eval perplexity: 11.298362731933594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/149

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [22:26:35<7:38:48, 539.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15612.307596409575
INFO:root:current train perplexity4.668173789978027
INFO:root:current mean train loss 15583.681235384778
INFO:root:current train perplexity4.649269104003906
INFO:root:current mean train loss 15610.156269768471
INFO:root:current train perplexity4.656677722930908


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.98s/it]
INFO:root:final mean train loss: 15596.438015845513
INFO:root:final train perplexity: 4.6567206382751465
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.29s/it]
INFO:root:eval mean loss: 23425.427641369046
INFO:root:eval perplexity: 11.295798301696777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/150

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [22:35:37<7:30:14, 540.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15608.438545612375
INFO:root:current train perplexity4.649231910705566
INFO:root:current mean train loss 15601.343637130967
INFO:root:current train perplexity4.654818058013916


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.76s/it]
INFO:root:final mean train loss: 15590.019799017136
INFO:root:final train perplexity: 4.653773307800293
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.94s/it]
INFO:root:eval mean loss: 23434.00413876488
INFO:root:eval perplexity: 11.305830001831055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/151

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [22:44:34<7:20:21, 539.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15561.46036305147
INFO:root:current train perplexity4.651087284088135
INFO:root:current mean train loss 15576.789780370447
INFO:root:current train perplexity4.63773250579834


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.42s/it]
INFO:root:final mean train loss: 15579.827975365424
INFO:root:final train perplexity: 4.6490983963012695
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.48s/it]
INFO:root:eval mean loss: 23421.920107886905
INFO:root:eval perplexity: 11.29169750213623
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/152

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [22:53:36<7:12:02, 540.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15614.080403645834
INFO:root:current train perplexity4.639019966125488
INFO:root:current mean train loss 15592.189339350729
INFO:root:current train perplexity4.655999660491943
INFO:root:current mean train loss 15596.557352601601
INFO:root:current train perplexity4.6487956047058105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.77s/it]
INFO:root:final mean train loss: 15576.521456810737
INFO:root:final train perplexity: 4.647582054138184
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.78s/it]
INFO:root:eval mean loss: 23443.670270647322
INFO:root:eval perplexity: 11.317145347595215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/153

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [23:02:34<7:02:36, 539.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15566.954580965908
INFO:root:current train perplexity4.636167526245117
INFO:root:current mean train loss 15591.326965725806
INFO:root:current train perplexity4.645894527435303


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.59s/it]
INFO:root:final mean train loss: 15568.842942760837
INFO:root:final train perplexity: 4.644063949584961
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.37s/it]
INFO:root:eval mean loss: 23435.373953683036
INFO:root:eval perplexity: 11.307433128356934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/154

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [23:11:33<6:53:39, 539.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15773.85560825893
INFO:root:current train perplexity4.673561096191406
INFO:root:current mean train loss 15630.195723203855
INFO:root:current train perplexity4.6435933113098145
INFO:root:current mean train loss 15583.320774833937
INFO:root:current train perplexity4.640166759490967


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.02s/it]
INFO:root:final mean train loss: 15560.533667779739
INFO:root:final train perplexity: 4.640259265899658
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.39s/it]
INFO:root:eval mean loss: 23447.51297433036
INFO:root:eval perplexity: 11.321646690368652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/155

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [23:20:35<6:45:03, 540.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15521.26115598517
INFO:root:current train perplexity4.619467735290527
INFO:root:current mean train loss 15556.31142516706
INFO:root:current train perplexity4.635499477386475


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.56s/it]
INFO:root:final mean train loss: 15555.29339796497
INFO:root:final train perplexity: 4.637861728668213
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.32s/it]
INFO:root:eval mean loss: 23428.09044828869
INFO:root:eval perplexity: 11.298909187316895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/156

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [23:29:35<6:36:04, 540.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15595.617009943182
INFO:root:current train perplexity4.638976097106934
INFO:root:current mean train loss 15559.286036036036
INFO:root:current train perplexity4.632555961608887
INFO:root:current mean train loss 15566.35608893661
INFO:root:current train perplexity4.634004592895508


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.74s/it]
INFO:root:final mean train loss: 15547.046882875504
INFO:root:final train perplexity: 4.634089946746826
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.76s/it]
INFO:root:eval mean loss: 23419.91138857887
INFO:root:eval perplexity: 11.289350509643555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/157

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [23:38:35<6:27:06, 540.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15573.544596354166
INFO:root:current train perplexity4.6471943855285645
INFO:root:current mean train loss 15565.791830425613
INFO:root:current train perplexity4.634946346282959


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.99s/it]
INFO:root:final mean train loss: 15536.422788558468
INFO:root:final train perplexity: 4.629237174987793
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.14s/it]
INFO:root:eval mean loss: 23437.68152436756
INFO:root:eval perplexity: 11.310132026672363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/158

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [23:47:35<6:18:06, 540.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15599.381901041666
INFO:root:current train perplexity4.623966217041016
INFO:root:current mean train loss 15568.23019701087
INFO:root:current train perplexity4.630424499511719
INFO:root:current mean train loss 15535.245049055233
INFO:root:current train perplexity4.622951507568359


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.71s/it]
INFO:root:final mean train loss: 15527.932424237652
INFO:root:final train perplexity: 4.625361919403076
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:25<00:00, 85.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:25<00:00, 85.07s/it]
INFO:root:eval mean loss: 23427.832077752977
INFO:root:eval perplexity: 11.29861068725586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/159

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [23:56:43<6:10:36, 542.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15506.017665578358
INFO:root:current train perplexity4.618455410003662
INFO:root:current mean train loss 15527.936447417665
INFO:root:current train perplexity4.620759963989258


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.53s/it]
INFO:root:final mean train loss: 15527.837236958165
INFO:root:final train perplexity: 4.6253180503845215
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.32s/it]
INFO:root:eval mean loss: 23443.319521949405
INFO:root:eval perplexity: 11.316730499267578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/160

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [24:05:44<6:01:24, 542.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15458.192125822368
INFO:root:current train perplexity4.620771884918213
INFO:root:current mean train loss 15501.624138327206
INFO:root:current train perplexity4.611266613006592
INFO:root:current mean train loss 15528.22237978025
INFO:root:current train perplexity4.620126724243164


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.31s/it]
INFO:root:final mean train loss: 15520.570674773186
INFO:root:final train perplexity: 4.622004985809326
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.64s/it]
INFO:root:eval mean loss: 23447.412527901786
INFO:root:eval perplexity: 11.321528434753418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/161

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [24:14:43<5:51:41, 541.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15548.972670004401
INFO:root:current train perplexity4.617938995361328
INFO:root:current mean train loss 15515.367964181287
INFO:root:current train perplexity4.613925933837891


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.52s/it]
INFO:root:final mean train loss: 15513.994479271674
INFO:root:final train perplexity: 4.619007587432861
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.41s/it]
INFO:root:eval mean loss: 23434.345796130954
INFO:root:eval perplexity: 11.306231498718262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/162

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [24:23:47<5:43:10, 541.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15483.911939538044
INFO:root:current train perplexity4.614163398742676
INFO:root:current mean train loss 15502.340232787094
INFO:root:current train perplexity4.61485481262207
INFO:root:current mean train loss 15523.104417741031
INFO:root:current train perplexity4.616459846496582


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.21s/it]
INFO:root:final mean train loss: 15507.0046859249
INFO:root:final train perplexity: 4.615823745727539
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.24s/it]
INFO:root:eval mean loss: 23450.219215029763
INFO:root:eval perplexity: 11.324819564819336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/163

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [24:32:46<5:33:38, 541.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15539.831028645833
INFO:root:current train perplexity4.6207427978515625
INFO:root:current mean train loss 15533.5928125
INFO:root:current train perplexity4.616781711578369


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.68s/it]
INFO:root:final mean train loss: 15503.260005827873
INFO:root:final train perplexity: 4.614120006561279
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.78s/it]
INFO:root:eval mean loss: 23437.729933965773
INFO:root:eval perplexity: 11.310189247131348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/164

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [24:41:46<5:24:27, 540.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15503.274594907407
INFO:root:current train perplexity4.61093807220459
INFO:root:current mean train loss 15502.256943590059
INFO:root:current train perplexity4.615524768829346
INFO:root:current mean train loss 15521.956317111784
INFO:root:current train perplexity4.6154351234436035


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.76s/it]
INFO:root:final mean train loss: 15500.200049615676
INFO:root:final train perplexity: 4.612727642059326
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.67s/it]
INFO:root:eval mean loss: 23444.567475818454
INFO:root:eval perplexity: 11.318195343017578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/165

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [24:50:44<5:14:58, 539.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15498.898709454113
INFO:root:current train perplexity4.601593017578125
INFO:root:current mean train loss 15493.974451160964
INFO:root:current train perplexity4.604978084564209


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.03s/it]
INFO:root:final mean train loss: 15491.367971112652
INFO:root:final train perplexity: 4.608710765838623
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.04s/it]
INFO:root:eval mean loss: 23448.94005766369
INFO:root:eval perplexity: 11.323320388793945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/166

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [24:59:44<5:05:57, 539.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15616.51619203629
INFO:root:current train perplexity4.639957427978516
INFO:root:current mean train loss 15502.013567509543
INFO:root:current train perplexity4.606666088104248
INFO:root:current mean train loss 15487.235178233224
INFO:root:current train perplexity4.601901054382324


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.95s/it]
INFO:root:final mean train loss: 15484.511297410534
INFO:root:final train perplexity: 4.605595111846924
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.26s/it]
INFO:root:eval mean loss: 23463.59988839286
INFO:root:eval perplexity: 11.3405122756958
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/167

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [25:08:42<4:56:42, 539.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15450.593020519578
INFO:root:current train perplexity4.58875846862793
INFO:root:current mean train loss 15483.515897156762
INFO:root:current train perplexity4.600268840789795


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.70s/it]
INFO:root:final mean train loss: 15478.480051348286
INFO:root:final train perplexity: 4.602856159210205
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.70s/it]
INFO:root:eval mean loss: 23446.02901785714
INFO:root:eval perplexity: 11.319906234741211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/168

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [25:17:42<4:47:43, 539.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15456.311579241072
INFO:root:current train perplexity4.588123321533203
INFO:root:current mean train loss 15501.509006076389
INFO:root:current train perplexity4.600818634033203
INFO:root:current mean train loss 15488.61059674202
INFO:root:current train perplexity4.601752758026123


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.33s/it]
INFO:root:final mean train loss: 15472.018830330142
INFO:root:final train perplexity: 4.599923610687256
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.05s/it]
INFO:root:eval mean loss: 23454.04808407738
INFO:root:eval perplexity: 11.329307556152344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/169

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [25:26:40<4:38:30, 539.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15494.836835488506
INFO:root:current train perplexity4.600190162658691
INFO:root:current mean train loss 15473.105218081551
INFO:root:current train perplexity4.594902992248535


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.93s/it]
INFO:root:final mean train loss: 15469.159494707661
INFO:root:final train perplexity: 4.598626613616943
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.88s/it]
INFO:root:eval mean loss: 23444.125093005954
INFO:root:eval perplexity: 11.31767749786377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/170

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [25:35:40<4:29:44, 539.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15417.80969551282
INFO:root:current train perplexity4.569969654083252
INFO:root:current mean train loss 15493.38115445144
INFO:root:current train perplexity4.594973087310791
INFO:root:current mean train loss 15480.433127941946
INFO:root:current train perplexity4.598559379577637


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.19s/it]
INFO:root:final mean train loss: 15465.635907573085
INFO:root:final train perplexity: 4.597028732299805
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.15s/it]
INFO:root:eval mean loss: 23449.63792782738
INFO:root:eval perplexity: 11.324135780334473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/171

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [25:44:37<4:20:24, 538.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15476.154769059065
INFO:root:current train perplexity4.588569164276123
INFO:root:current mean train loss 15465.376886657396
INFO:root:current train perplexity4.59168815612793


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.57s/it]
INFO:root:final mean train loss: 15453.80025359123
INFO:root:final train perplexity: 4.591665744781494
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.12s/it]
INFO:root:eval mean loss: 23453.524367559523
INFO:root:eval perplexity: 11.328694343566895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/172

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [25:53:36<4:11:23, 538.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15459.247819767443
INFO:root:current train perplexity4.578910827636719
INFO:root:current mean train loss 15484.782554359703
INFO:root:current train perplexity4.587671279907227
INFO:root:current mean train loss 15477.254943094136
INFO:root:current train perplexity4.5939412117004395


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.80s/it]
INFO:root:final mean train loss: 15454.619786416331
INFO:root:final train perplexity: 4.592036724090576
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.36s/it]
INFO:root:eval mean loss: 23459.504208519345
INFO:root:eval perplexity: 11.335705757141113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/173

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [26:02:37<4:02:42, 539.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15426.285248766448
INFO:root:current train perplexity4.5762434005737305
INFO:root:current mean train loss 15458.477569110577
INFO:root:current train perplexity4.588634490966797


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.32s/it]
INFO:root:final mean train loss: 15450.556845388104
INFO:root:final train perplexity: 4.5901970863342285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.76s/it]
INFO:root:eval mean loss: 23456.673014322918
INFO:root:eval perplexity: 11.33238697052002
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/174

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [26:11:39<3:54:02, 540.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15474.99526263298
INFO:root:current train perplexity4.578584671020508
INFO:root:current mean train loss 15462.545420121174
INFO:root:current train perplexity4.590363025665283
INFO:root:current mean train loss 15461.091535931175
INFO:root:current train perplexity4.589024543762207


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.85s/it]
INFO:root:final mean train loss: 15446.246345766129
INFO:root:final train perplexity: 4.588245868682861
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:14<00:00, 74.86s/it]
INFO:root:eval mean loss: 23456.063662574405
INFO:root:eval perplexity: 11.331668853759766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/175

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [26:20:38<3:44:53, 539.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15454.581123737375
INFO:root:current train perplexity4.587454319000244
INFO:root:current mean train loss 15460.106263740578
INFO:root:current train perplexity4.584546089172363


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.23s/it]
INFO:root:final mean train loss: 15441.592312720513
INFO:root:final train perplexity: 4.586140155792236
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.03s/it]
INFO:root:eval mean loss: 23462.56912667411
INFO:root:eval perplexity: 11.339301109313965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/176

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [26:29:40<3:36:09, 540.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15435.951937806372
INFO:root:current train perplexity4.602401256561279
INFO:root:current mean train loss 15438.914269453642
INFO:root:current train perplexity4.585022926330566

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.87s/it]
INFO:root:final mean train loss: 15440.591611800655
INFO:root:final train perplexity: 4.58568811416626
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.87s/it]
INFO:root:eval mean loss: 23458.762509300595
INFO:root:eval perplexity: 11.334837913513184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/177
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [26:38:39<3:27:04, 540.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15742.28125
INFO:root:current train perplexity4.645421981811523
INFO:root:current mean train loss 15450.760855961771
INFO:root:current train perplexity4.5888519287109375
INFO:root:current mean train loss 15447.983047259851
INFO:root:current train perplexity4.5815629959106445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.13s/it]
INFO:root:final mean train loss: 15431.462953629032
INFO:root:final train perplexity: 4.581560134887695
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.70s/it]
INFO:root:eval mean loss: 23472.058663504464
INFO:root:eval perplexity: 11.350444793701172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/178
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [26:47:42<3:18:20, 540.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15476.02725497159
INFO:root:current train perplexity4.57798957824707
INFO:root:current mean train loss 15429.761466733871
INFO:root:current train perplexity4.572408676147461

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.54s/it]
INFO:root:final mean train loss: 15425.882469915574
INFO:root:final train perplexity: 4.579039573669434
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.72s/it]
INFO:root:eval mean loss: 23466.58203125
INFO:root:eval perplexity: 11.344011306762695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/179
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [26:56:43<3:09:22, 541.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15472.61900111607
INFO:root:current train perplexity4.565942287445068
INFO:root:current mean train loss 15437.53491895444
INFO:root:current train perplexity4.575618267059326
INFO:root:current mean train loss 15436.695246452295
INFO:root:current train perplexity4.577545642852783

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.15s/it]
INFO:root:final mean train loss: 15424.746625346523
INFO:root:final train perplexity: 4.578526496887207
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.88s/it]
INFO:root:eval mean loss: 23459.51683407738
INFO:root:eval perplexity: 11.335721969604492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/180
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [27:05:44<3:00:19, 540.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15385.538168697034
INFO:root:current train perplexity4.575414180755615
INFO:root:current mean train loss 15433.751818003144
INFO:root:current train perplexity4.572275161743164

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.68s/it]
INFO:root:final mean train loss: 15424.71089812248
INFO:root:final train perplexity: 4.578509330749512
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.63s/it]
INFO:root:eval mean loss: 23463.344377790178
INFO:root:eval perplexity: 11.340211868286133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/181
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [27:16:23<3:00:39, 570.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15503.115678267046
INFO:root:current train perplexity4.608394145965576
INFO:root:current mean train loss 15406.044473184122
INFO:root:current train perplexity4.574250221252441
INFO:root:current mean train loss 15424.056353672986
INFO:root:current train perplexity4.575716018676758

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.80s/it]
INFO:root:final mean train loss: 15417.972136466733
INFO:root:final train perplexity: 4.575468063354492
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.11s/it]
INFO:root:eval mean loss: 23461.654482886905
INFO:root:eval perplexity: 11.33823013305664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/182
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [27:25:40<2:49:52, 566.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15349.459712921627
INFO:root:current train perplexity4.558581829071045
INFO:root:current mean train loss 15419.675224070168
INFO:root:current train perplexity4.572717666625977

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.20s/it]
INFO:root:final mean train loss: 15414.283285817792
INFO:root:final train perplexity: 4.573803424835205
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.09s/it]
INFO:root:eval mean loss: 23458.150530133928
INFO:root:eval perplexity: 11.334118843078613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/183
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [27:36:21<2:46:46, 588.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15357.227083333333
INFO:root:current train perplexity4.560274124145508
INFO:root:current mean train loss 15432.865854279891
INFO:root:current train perplexity4.583130359649658
INFO:root:current mean train loss 15417.92234284157
INFO:root:current train perplexity4.573657512664795

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.59s/it]
INFO:root:final mean train loss: 15411.342198525706
INFO:root:final train perplexity: 4.572476863861084
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.14s/it]
INFO:root:eval mean loss: 23463.89381045387
INFO:root:eval perplexity: 11.340855598449707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/184
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [27:47:09<2:41:45, 606.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15390.044091068097
INFO:root:current train perplexity4.568182468414307
INFO:root:current mean train loss 15404.032010198353
INFO:root:current train perplexity4.564944744110107

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.61s/it]
INFO:root:final mean train loss: 15410.551745999244
INFO:root:final train perplexity: 4.57211971282959
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.14s/it]
INFO:root:eval mean loss: 23461.325381324405
INFO:root:eval perplexity: 11.337843894958496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/185
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [27:57:47<2:34:00, 616.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15445.771946957237
INFO:root:current train perplexity4.553565502166748
INFO:root:current mean train loss 15413.38271402311
INFO:root:current train perplexity4.5630011558532715
INFO:root:current mean train loss 15414.038607662671
INFO:root:current train perplexity4.568668365478516

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.95s/it]
INFO:root:final mean train loss: 15404.752846994708
INFO:root:final train perplexity: 4.569506645202637
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.54s/it]
INFO:root:eval mean loss: 23456.372163318454
INFO:root:eval perplexity: 11.332030296325684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/186
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [28:06:46<2:18:21, 592.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15440.648382482394
INFO:root:current train perplexity4.564491271972656
INFO:root:current mean train loss 15424.827394005848
INFO:root:current train perplexity4.563722133636475

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.27s/it]
INFO:root:final mean train loss: 15403.75642641129
INFO:root:final train perplexity: 4.569057941436768
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.94s/it]
INFO:root:eval mean loss: 23456.92833891369
INFO:root:eval perplexity: 11.332681655883789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/187
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [28:15:45<2:04:55, 576.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15478.23874830163
INFO:root:current train perplexity4.591013431549072
INFO:root:current mean train loss 15477.719440739329
INFO:root:current train perplexity4.581738471984863
INFO:root:current mean train loss 15426.548245690863
INFO:root:current train perplexity4.570552825927734

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.87s/it]
INFO:root:final mean train loss: 15404.45826376638
INFO:root:final train perplexity: 4.56937313079834
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.14s/it]
INFO:root:eval mean loss: 23460.24637276786
INFO:root:eval perplexity: 11.336578369140625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/188
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [28:24:44<1:53:06, 565.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15361.315221354167
INFO:root:current train perplexity4.547774314880371
INFO:root:current mean train loss 15395.871958705357
INFO:root:current train perplexity4.56450080871582

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.69s/it]
INFO:root:final mean train loss: 15397.304443359375
INFO:root:final train perplexity: 4.566150665283203
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.51s/it]
INFO:root:eval mean loss: 23458.979073660714
INFO:root:eval perplexity: 11.335089683532715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/189
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [28:33:44<1:42:16, 557.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15429.802155671296
INFO:root:current train perplexity4.562765121459961
INFO:root:current mean train loss 15396.836737204725
INFO:root:current train perplexity4.565275192260742
INFO:root:current mean train loss 15407.702118323237
INFO:root:current train perplexity4.565773963928223

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.48s/it]
INFO:root:final mean train loss: 15401.537046370968
INFO:root:final train perplexity: 4.568057537078857
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 75.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.01s/it]
INFO:root:eval mean loss: 23463.533226376487
INFO:root:eval perplexity: 11.340435981750488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/190
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [28:42:46<1:32:08, 552.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15398.767157832279
INFO:root:current train perplexity4.554225921630859
INFO:root:current mean train loss 15405.828512351605
INFO:root:current train perplexity4.559539794921875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.65s/it]
INFO:root:final mean train loss: 15392.593450730847
INFO:root:final train perplexity: 4.564029216766357
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.38s/it]
INFO:root:eval mean loss: 23464.673804873513
INFO:root:eval perplexity: 11.341772079467773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/191
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [28:51:47<1:22:24, 549.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15360.460622479839
INFO:root:current train perplexity4.5770344734191895
INFO:root:current mean train loss 15393.765930641699
INFO:root:current train perplexity4.557547092437744
INFO:root:current mean train loss 15401.769510112283
INFO:root:current train perplexity4.567139148712158

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.25s/it]
INFO:root:final mean train loss: 15392.303608555947
INFO:root:final train perplexity: 4.563899040222168
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.71s/it]
INFO:root:eval mean loss: 23468.802153087796
INFO:root:eval perplexity: 11.34661865234375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/192
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [29:00:53<1:13:07, 548.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15346.003059111446
INFO:root:current train perplexity4.540824890136719
INFO:root:current mean train loss 15405.870997694672
INFO:root:current train perplexity4.5612616539001465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.45s/it]
INFO:root:final mean train loss: 15389.010033392136
INFO:root:final train perplexity: 4.5624165534973145
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.05s/it]
INFO:root:eval mean loss: 23465.036969866072
INFO:root:eval perplexity: 11.342202186584473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/193
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [29:09:52<1:03:39, 545.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15400.582114955358
INFO:root:current train perplexity4.542865753173828
INFO:root:current mean train loss 15391.142867476852
INFO:root:current train perplexity4.560568809509277
INFO:root:current mean train loss 15392.535185339097
INFO:root:current train perplexity4.560061454772949

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.17s/it]
INFO:root:final mean train loss: 15387.162133001511
INFO:root:final train perplexity: 4.561585426330566
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.85s/it]
INFO:root:eval mean loss: 23464.69949776786
INFO:root:eval perplexity: 11.341804504394531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/194
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [29:18:52<54:23, 543.92s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15369.567573635057
INFO:root:current train perplexity4.551083564758301
INFO:root:current mean train loss 15396.24105426972
INFO:root:current train perplexity4.559089183807373

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.64s/it]
INFO:root:final mean train loss: 15389.600444178428
INFO:root:final train perplexity: 4.562682628631592
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.86s/it]
INFO:root:eval mean loss: 23466.360909598214
INFO:root:eval perplexity: 11.343753814697266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/195
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [29:27:54<45:16, 543.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15386.632211538461
INFO:root:current train perplexity4.5512237548828125
INFO:root:current mean train loss 15375.672816434353
INFO:root:current train perplexity4.557510852813721
INFO:root:current mean train loss 15390.37586623954
INFO:root:current train perplexity4.5599260330200195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:42<00:00, 462.84s/it]
INFO:root:final mean train loss: 15384.29490218624
INFO:root:final train perplexity: 4.5602946281433105
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.43s/it]
INFO:root:eval mean loss: 23464.681454613095
INFO:root:eval perplexity: 11.341779708862305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/196
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [29:36:56<36:11, 542.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15442.499044900413
INFO:root:current train perplexity4.570693016052246
INFO:root:current mean train loss 15382.245608025196
INFO:root:current train perplexity4.556704998016357

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.71s/it]
INFO:root:final mean train loss: 15380.631709929436
INFO:root:final train perplexity: 4.558648109436035
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.87s/it]
INFO:root:eval mean loss: 23467.584867931546
INFO:root:eval perplexity: 11.345192909240723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/197
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [29:45:54<27:04, 541.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15365.60128997093
INFO:root:current train perplexity4.544344902038574
INFO:root:current mean train loss 15360.522228747815
INFO:root:current train perplexity4.55307149887085
INFO:root:current mean train loss 15391.488932291666
INFO:root:current train perplexity4.558837413787842

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.13s/it]
INFO:root:final mean train loss: 15380.880142704133
INFO:root:final train perplexity: 4.558759689331055
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:25<00:00, 85.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:25<00:00, 85.79s/it]
INFO:root:eval mean loss: 23466.74841889881
INFO:root:eval perplexity: 11.344208717346191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/198
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [29:55:08<18:10, 545.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15397.129594983553
INFO:root:current train perplexity4.559000492095947
INFO:root:current mean train loss 15410.217973758014
INFO:root:current train perplexity4.559861660003662

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.80s/it]
INFO:root:final mean train loss: 15386.48779296875
INFO:root:final train perplexity: 4.561281681060791
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:15<00:00, 75.51s/it]
INFO:root:eval mean loss: 23467.141206287204
INFO:root:eval perplexity: 11.3446683883667
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/199
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [30:04:06<09:03, 543.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15386.188123337766
INFO:root:current train perplexity4.553703784942627
INFO:root:current mean train loss 15369.137675382653
INFO:root:current train perplexity4.549536228179932
INFO:root:current mean train loss 15391.490712772014
INFO:root:current train perplexity4.559084892272949

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.49s/it]
INFO:root:final mean train loss: 15382.690689579133
INFO:root:final train perplexity: 4.559573650360107
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:16<00:00, 76.31s/it]
INFO:root:eval mean loss: 23467.39041573661
INFO:root:eval perplexity: 11.344963073730469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_scratch/200
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [30:13:05<00:00, 541.78s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [30:13:05<00:00, 543.93s/it]
INFO:root:evaluating final model
INFO:root:start evaluating
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:13<00:00, 73.39s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:13<00:00, 73.39s/it]
INFO:root:eval mean loss: 23467.39041573661
INFO:root:eval perplexity: 11.344963073730469
INFO:root:evalaution complete
INFO:root:save model final: small_multiqa_scratch/final
