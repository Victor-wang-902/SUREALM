INFO:root:Output: bert_fair_baseline
INFO:root:Steps per epochs:1983
INFO:root:Total steps:396600
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertLMHeadModelBaseline: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertLMHeadModelBaseline from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertLMHeadModelBaseline from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertLMHeadModelBaseline were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10305.202296401516
INFO:root:current train perplexity3362.8125
INFO:root:current mean train loss 9031.650685065955
INFO:root:current train perplexity1211.308837890625
INFO:root:current mean train loss 8087.060380304139
INFO:root:current train perplexity573.8436279296875
INFO:root:current mean train loss 7397.999720982143
INFO:root:current train perplexity339.5816650390625
INFO:root:current mean train loss 6910.2337986519915
INFO:root:current train perplexity230.79354858398438
INFO:root:current mean train loss 6519.119232330577
INFO:root:current train perplexity171.41578674316406
INFO:root:current mean train loss 6207.830204211932
INFO:root:current train perplexity134.3663330078125
INFO:root:current mean train loss 5958.813772036823
INFO:root:current train perplexity110.31038665771484
INFO:root:current mean train loss 5743.818604601902
INFO:root:current train perplexity93.40878295898438
INFO:root:current mean train loss 5563.9649031355575
INFO:root:current train perplexity80.89501953125
INFO:root:current mean train loss 5409.093325697367
INFO:root:current train perplexity71.55158233642578
INFO:root:current mean train loss 5274.155222125209
INFO:root:current train perplexity64.09430694580078
INFO:root:current mean train loss 5153.936884855839
INFO:root:current train perplexity58.21653366088867
INFO:root:current mean train loss 5046.2491599049545
INFO:root:current train perplexity53.34067153930664
INFO:root:current mean train loss 4945.986366724952
INFO:root:current train perplexity49.25908279418945
INFO:root:current mean train loss 4852.949176609404
INFO:root:current train perplexity45.84067153930664
INFO:root:current mean train loss 4769.938369795882
INFO:root:current train perplexity42.973419189453125
INFO:root:current mean train loss 4695.126359533509
INFO:root:current train perplexity40.471797943115234
INFO:root:current mean train loss 4624.686024228418
INFO:root:current train perplexity38.314613342285156

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.07s/it]
INFO:root:final mean train loss: 4566.2823726405895
INFO:root:final train perplexity: 36.64382553100586
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.53s/it]
INFO:root:eval mean loss: 3031.62447535738
INFO:root:eval perplexity: 11.609223365783691
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it]
INFO:root:eval mean loss: 3378.6411396865306
INFO:root:eval perplexity: 15.84962272644043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/1
  0%|          | 1/200 [08:51<29:22:09, 531.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3289.709259033203
INFO:root:current train perplexity13.146071434020996
INFO:root:current mean train loss 3269.230216190733
INFO:root:current train perplexity13.100628852844238
INFO:root:current mean train loss 3258.506172462746
INFO:root:current train perplexity12.946359634399414
INFO:root:current mean train loss 3241.4314837878264
INFO:root:current train perplexity12.798108100891113
INFO:root:current mean train loss 3220.097722567045
INFO:root:current train perplexity12.637906074523926
INFO:root:current mean train loss 3201.4764986259993
INFO:root:current train perplexity12.487248420715332
INFO:root:current mean train loss 3187.650945886389
INFO:root:current train perplexity12.352825164794922
INFO:root:current mean train loss 3180.0711086848596
INFO:root:current train perplexity12.244114875793457
INFO:root:current mean train loss 3159.9056638829848
INFO:root:current train perplexity12.078069686889648
INFO:root:current mean train loss 3145.348652535651
INFO:root:current train perplexity11.952740669250488
INFO:root:current mean train loss 3137.9052864134783
INFO:root:current train perplexity11.867383003234863
INFO:root:current mean train loss 3125.922380563606
INFO:root:current train perplexity11.74952220916748
INFO:root:current mean train loss 3113.102172048468
INFO:root:current train perplexity11.634970664978027
INFO:root:current mean train loss 3105.336265308879
INFO:root:current train perplexity11.553567886352539
INFO:root:current mean train loss 3094.4117557504082
INFO:root:current train perplexity11.447548866271973
INFO:root:current mean train loss 3085.4452456673093
INFO:root:current train perplexity11.36557388305664
INFO:root:current mean train loss 3073.601670066909
INFO:root:current train perplexity11.27334976196289
INFO:root:current mean train loss 3065.009895235786
INFO:root:current train perplexity11.193497657775879
INFO:root:current mean train loss 3054.6882373961057
INFO:root:current train perplexity11.10991382598877
INFO:root:current mean train loss 3045.9213381709533
INFO:root:current train perplexity11.037572860717773

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 476.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 476.58s/it]
INFO:root:final mean train loss: 3038.888140933777
INFO:root:final train perplexity: 10.986309051513672
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.11s/it]
INFO:root:eval mean loss: 2659.288507556239
INFO:root:eval perplexity: 8.590667724609375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.48s/it]
INFO:root:eval mean loss: 3057.9037337066434
INFO:root:eval perplexity: 12.192702293395996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/2
  1%|          | 2/200 [17:43<29:14:47, 531.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2871.2889811197915
INFO:root:current train perplexity9.436413764953613
INFO:root:current mean train loss 2844.0529381314614
INFO:root:current train perplexity9.331623077392578
INFO:root:current mean train loss 2838.0166885310487
INFO:root:current train perplexity9.395855903625488
INFO:root:current mean train loss 2825.3501871011636
INFO:root:current train perplexity9.343811988830566
INFO:root:current mean train loss 2826.3987498646798
INFO:root:current train perplexity9.313830375671387
INFO:root:current mean train loss 2820.5088541055934
INFO:root:current train perplexity9.261639595031738
INFO:root:current mean train loss 2809.312245445794
INFO:root:current train perplexity9.200844764709473
INFO:root:current mean train loss 2808.6606245470243
INFO:root:current train perplexity9.183672904968262
INFO:root:current mean train loss 2801.2543634641356
INFO:root:current train perplexity9.1371431350708
INFO:root:current mean train loss 2796.1844970441452
INFO:root:current train perplexity9.098164558410645
INFO:root:current mean train loss 2794.3282244997126
INFO:root:current train perplexity9.0736722946167
INFO:root:current mean train loss 2790.1601971914993
INFO:root:current train perplexity9.045571327209473
INFO:root:current mean train loss 2786.861794031643
INFO:root:current train perplexity9.022565841674805
INFO:root:current mean train loss 2780.3809320860487
INFO:root:current train perplexity8.984236717224121
INFO:root:current mean train loss 2777.3965048194345
INFO:root:current train perplexity8.951777458190918
INFO:root:current mean train loss 2771.9081191966834
INFO:root:current train perplexity8.91684341430664
INFO:root:current mean train loss 2765.4533026111835
INFO:root:current train perplexity8.876321792602539
INFO:root:current mean train loss 2761.6466293378985
INFO:root:current train perplexity8.843710899353027
INFO:root:current mean train loss 2758.014745134769
INFO:root:current train perplexity8.808581352233887
INFO:root:current mean train loss 2754.0303137276496
INFO:root:current train perplexity8.772936820983887

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:03<00:00, 483.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:03<00:00, 483.86s/it]
INFO:root:final mean train loss: 2751.3249784422474
INFO:root:final train perplexity: 8.757061004638672
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 2502.6297074987533
INFO:root:eval perplexity: 7.56838846206665
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 2921.243124671016
INFO:root:eval perplexity: 10.903380393981934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/3
  2%|â–         | 3/200 [26:42<29:17:36, 535.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2675.912099609375
INFO:root:current train perplexity8.132176399230957
INFO:root:current mean train loss 2649.2374788411457
INFO:root:current train perplexity8.067150115966797
INFO:root:current mean train loss 2631.0659716796877
INFO:root:current train perplexity8.00535774230957
INFO:root:current mean train loss 2631.7398053850447
INFO:root:current train perplexity7.964803218841553
INFO:root:current mean train loss 2630.3377642144096
INFO:root:current train perplexity7.969639301300049
INFO:root:current mean train loss 2633.522786310369
INFO:root:current train perplexity7.979921817779541
INFO:root:current mean train loss 2634.7617273888222
INFO:root:current train perplexity7.973067760467529
INFO:root:current mean train loss 2632.9556015625
INFO:root:current train perplexity7.9650444984436035
INFO:root:current mean train loss 2629.526920668658
INFO:root:current train perplexity7.947422027587891
INFO:root:current mean train loss 2625.914013928865
INFO:root:current train perplexity7.92909574508667
INFO:root:current mean train loss 2623.3532475353422
INFO:root:current train perplexity7.912827968597412
INFO:root:current mean train loss 2617.602535665761
INFO:root:current train perplexity7.885920524597168
INFO:root:current mean train loss 2615.1151017578127
INFO:root:current train perplexity7.869708061218262
INFO:root:current mean train loss 2613.470488462095
INFO:root:current train perplexity7.852346897125244
INFO:root:current mean train loss 2612.6005953663794
INFO:root:current train perplexity7.846070289611816
INFO:root:current mean train loss 2610.797290669103
INFO:root:current train perplexity7.8329081535339355
INFO:root:current mean train loss 2609.351208570076
INFO:root:current train perplexity7.826179027557373
INFO:root:current mean train loss 2606.25440625
INFO:root:current train perplexity7.807798862457275
INFO:root:current mean train loss 2603.893594673775
INFO:root:current train perplexity7.790457725524902
INFO:root:current mean train loss 2601.59907038762
INFO:root:current train perplexity7.779015064239502

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.71s/it]
INFO:root:final mean train loss: 2599.667676901613
INFO:root:final train perplexity: 7.769876956939697
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2411.0422319993904
INFO:root:eval perplexity: 7.028050422668457
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 2840.9760014960107
INFO:root:eval perplexity: 10.210618019104004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/4
  2%|â–         | 4/200 [35:44<29:16:27, 537.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2537.61230104361
INFO:root:current train perplexity7.397760391235352
INFO:root:current mean train loss 2532.428754795097
INFO:root:current train perplexity7.330799579620361
INFO:root:current mean train loss 2526.4179806369966
INFO:root:current train perplexity7.3347673416137695
INFO:root:current mean train loss 2520.9342742836766
INFO:root:current train perplexity7.3201398849487305
INFO:root:current mean train loss 2515.172263429303
INFO:root:current train perplexity7.290241241455078
INFO:root:current mean train loss 2520.889403866292
INFO:root:current train perplexity7.307243347167969
INFO:root:current mean train loss 2518.614299905711
INFO:root:current train perplexity7.299253463745117
INFO:root:current mean train loss 2520.609094890808
INFO:root:current train perplexity7.303852081298828
INFO:root:current mean train loss 2517.1286004406356
INFO:root:current train perplexity7.281478404998779
INFO:root:current mean train loss 2517.5353887769033
INFO:root:current train perplexity7.273720741271973
INFO:root:current mean train loss 2516.327702616126
INFO:root:current train perplexity7.2595343589782715
INFO:root:current mean train loss 2513.962818658955
INFO:root:current train perplexity7.246862888336182
INFO:root:current mean train loss 2511.6338815546073
INFO:root:current train perplexity7.236226558685303
INFO:root:current mean train loss 2508.004999257041
INFO:root:current train perplexity7.2270307540893555
INFO:root:current mean train loss 2506.1904065548847
INFO:root:current train perplexity7.216551780700684
INFO:root:current mean train loss 2506.1896300373674
INFO:root:current train perplexity7.2113566398620605
INFO:root:current mean train loss 2503.6943311044824
INFO:root:current train perplexity7.205829620361328
INFO:root:current mean train loss 2502.7112023656355
INFO:root:current train perplexity7.197894096374512
INFO:root:current mean train loss 2500.664750199811
INFO:root:current train perplexity7.187199592590332
INFO:root:current mean train loss 2500.1932945852664
INFO:root:current train perplexity7.18003511428833

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.64s/it]
INFO:root:final mean train loss: 2499.1964689361525
INFO:root:final train perplexity: 7.1779704093933105
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.17s/it]
INFO:root:eval mean loss: 2349.458236369681
INFO:root:eval perplexity: 6.686588764190674
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.49s/it]
INFO:root:eval mean loss: 2781.8684125318596
INFO:root:eval perplexity: 9.728777885437012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/5
  2%|â–Ž         | 5/200 [44:45<29:11:38, 538.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2430.596150716146
INFO:root:current train perplexity6.795266628265381
INFO:root:current mean train loss 2422.121010158373
INFO:root:current train perplexity6.8070478439331055
INFO:root:current mean train loss 2426.756018840091
INFO:root:current train perplexity6.841292858123779
INFO:root:current mean train loss 2427.88760471344
INFO:root:current train perplexity6.845768451690674
INFO:root:current mean train loss 2425.791562671504
INFO:root:current train perplexity6.825000762939453
INFO:root:current mean train loss 2433.2508730953687
INFO:root:current train perplexity6.838127613067627
INFO:root:current mean train loss 2434.0551795290226
INFO:root:current train perplexity6.841686725616455
INFO:root:current mean train loss 2434.473978003677
INFO:root:current train perplexity6.831539630889893
INFO:root:current mean train loss 2437.3407886902132
INFO:root:current train perplexity6.834935188293457
INFO:root:current mean train loss 2438.362452933459
INFO:root:current train perplexity6.837640285491943
INFO:root:current mean train loss 2437.678601367007
INFO:root:current train perplexity6.838271141052246
INFO:root:current mean train loss 2437.2503229089684
INFO:root:current train perplexity6.837373733520508
INFO:root:current mean train loss 2435.9126700047764
INFO:root:current train perplexity6.824334144592285
INFO:root:current mean train loss 2433.7156589045003
INFO:root:current train perplexity6.810288429260254
INFO:root:current mean train loss 2432.4478865055385
INFO:root:current train perplexity6.802471160888672
INFO:root:current mean train loss 2432.4395757347647
INFO:root:current train perplexity6.7977190017700195
INFO:root:current mean train loss 2430.2925147557203
INFO:root:current train perplexity6.790465354919434
INFO:root:current mean train loss 2429.553084779748
INFO:root:current train perplexity6.789103031158447
INFO:root:current mean train loss 2429.1124689381595
INFO:root:current train perplexity6.785623073577881

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.60s/it]
INFO:root:final mean train loss: 2426.8270618248275
INFO:root:final train perplexity: 6.779760360717773
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.19s/it]
INFO:root:eval mean loss: 2306.3134743981327
INFO:root:eval perplexity: 6.457298278808594
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it]
INFO:root:eval mean loss: 2748.4560936461103
INFO:root:eval perplexity: 9.466534614562988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/6
  3%|â–Ž         | 6/200 [53:46<29:05:07, 539.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2521.245361328125
INFO:root:current train perplexity7.292139530181885
INFO:root:current mean train loss 2361.5465099976795
INFO:root:current train perplexity6.546647548675537
INFO:root:current mean train loss 2362.2002687976137
INFO:root:current train perplexity6.516423225402832
INFO:root:current mean train loss 2370.9076195396856
INFO:root:current train perplexity6.524409294128418
INFO:root:current mean train loss 2377.6203868989637
INFO:root:current train perplexity6.528565406799316
INFO:root:current mean train loss 2379.660992224535
INFO:root:current train perplexity6.528875827789307
INFO:root:current mean train loss 2372.977735065581
INFO:root:current train perplexity6.507735729217529
INFO:root:current mean train loss 2371.650823356422
INFO:root:current train perplexity6.497618675231934
INFO:root:current mean train loss 2374.2768199601574
INFO:root:current train perplexity6.503963947296143
INFO:root:current mean train loss 2376.1078643629476
INFO:root:current train perplexity6.50009298324585
INFO:root:current mean train loss 2378.4564828482066
INFO:root:current train perplexity6.505083084106445
INFO:root:current mean train loss 2379.015295931256
INFO:root:current train perplexity6.506340026855469
INFO:root:current mean train loss 2375.1752372697233
INFO:root:current train perplexity6.499474048614502
INFO:root:current mean train loss 2373.6075850420048
INFO:root:current train perplexity6.494619369506836
INFO:root:current mean train loss 2372.4742302686977
INFO:root:current train perplexity6.495892524719238
INFO:root:current mean train loss 2374.2771940288508
INFO:root:current train perplexity6.500014781951904
INFO:root:current mean train loss 2373.5330732013194
INFO:root:current train perplexity6.495814800262451
INFO:root:current mean train loss 2371.508671656838
INFO:root:current train perplexity6.489551067352295
INFO:root:current mean train loss 2371.222412854946
INFO:root:current train perplexity6.486853122711182
INFO:root:current mean train loss 2371.2380720416477
INFO:root:current train perplexity6.4845499992370605

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.58s/it]
INFO:root:final mean train loss: 2369.5036071377212
INFO:root:final train perplexity: 6.480082035064697
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2273.239029255319
INFO:root:eval perplexity: 6.286862373352051
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 2716.9328773444427
INFO:root:eval perplexity: 9.225602149963379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/7
  4%|â–Ž         | 7/200 [1:02:48<28:58:47, 540.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2288.9950900607637
INFO:root:current train perplexity6.184993743896484
INFO:root:current mean train loss 2333.854908054158
INFO:root:current train perplexity6.368137359619141
INFO:root:current mean train loss 2326.3522316468966
INFO:root:current train perplexity6.277146339416504
INFO:root:current mean train loss 2332.8076160358933
INFO:root:current train perplexity6.307219505310059
INFO:root:current mean train loss 2326.1933453573565
INFO:root:current train perplexity6.284054756164551
INFO:root:current mean train loss 2328.6505654824746
INFO:root:current train perplexity6.278825283050537
INFO:root:current mean train loss 2328.126475510088
INFO:root:current train perplexity6.27877950668335
INFO:root:current mean train loss 2329.1085888535863
INFO:root:current train perplexity6.273194313049316
INFO:root:current mean train loss 2328.6515040316035
INFO:root:current train perplexity6.2636518478393555
INFO:root:current mean train loss 2326.4501137993175
INFO:root:current train perplexity6.26045560836792
INFO:root:current mean train loss 2327.246496054419
INFO:root:current train perplexity6.256765365600586
INFO:root:current mean train loss 2325.6281572318035
INFO:root:current train perplexity6.250583648681641
INFO:root:current mean train loss 2324.9585002028493
INFO:root:current train perplexity6.247032642364502
INFO:root:current mean train loss 2326.8500966374536
INFO:root:current train perplexity6.251403331756592
INFO:root:current mean train loss 2326.260631308401
INFO:root:current train perplexity6.251286506652832
INFO:root:current mean train loss 2325.0601912788725
INFO:root:current train perplexity6.247739315032959
INFO:root:current mean train loss 2325.1264582800186
INFO:root:current train perplexity6.250773906707764
INFO:root:current mean train loss 2324.9314911279466
INFO:root:current train perplexity6.250636577606201
INFO:root:current mean train loss 2324.948593895034
INFO:root:current train perplexity6.245974063873291
INFO:root:current mean train loss 2324.0778707398863
INFO:root:current train perplexity6.246059417724609

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.54s/it]
INFO:root:final mean train loss: 2322.3971650570375
INFO:root:final train perplexity: 6.2437567710876465
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2244.7510059978945
INFO:root:eval perplexity: 6.143672943115234
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 2693.4603280141846
INFO:root:eval perplexity: 9.050191879272461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/8
  4%|â–         | 8/200 [1:11:50<28:50:33, 540.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2281.8358433314734
INFO:root:current train perplexity6.079009532928467
INFO:root:current mean train loss 2290.111070421007
INFO:root:current train perplexity6.0816731452941895
INFO:root:current mean train loss 2285.1551783784907
INFO:root:current train perplexity6.05778694152832
INFO:root:current mean train loss 2293.8997416482043
INFO:root:current train perplexity6.081096649169922
INFO:root:current mean train loss 2296.7753182246765
INFO:root:current train perplexity6.093076229095459
INFO:root:current mean train loss 2290.868690447941
INFO:root:current train perplexity6.0880303382873535
INFO:root:current mean train loss 2285.797444405143
INFO:root:current train perplexity6.0658650398254395
INFO:root:current mean train loss 2289.8538205516584
INFO:root:current train perplexity6.077037334442139
INFO:root:current mean train loss 2290.551659132906
INFO:root:current train perplexity6.080541610717773
INFO:root:current mean train loss 2289.574073440633
INFO:root:current train perplexity6.072558879852295
INFO:root:current mean train loss 2291.8592045733317
INFO:root:current train perplexity6.077805995941162
INFO:root:current mean train loss 2290.4182507485543
INFO:root:current train perplexity6.072842597961426
INFO:root:current mean train loss 2289.526895203378
INFO:root:current train perplexity6.069450378417969
INFO:root:current mean train loss 2288.595725984609
INFO:root:current train perplexity6.0692057609558105
INFO:root:current mean train loss 2287.386303540805
INFO:root:current train perplexity6.067042827606201
INFO:root:current mean train loss 2288.410387984782
INFO:root:current train perplexity6.065866947174072
INFO:root:current mean train loss 2288.0520488400707
INFO:root:current train perplexity6.065724849700928
INFO:root:current mean train loss 2285.714357509118
INFO:root:current train perplexity6.064065456390381
INFO:root:current mean train loss 2285.29443359375
INFO:root:current train perplexity6.059694766998291
INFO:root:current mean train loss 2284.683442660388
INFO:root:current train perplexity6.056029319763184

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.42s/it]
INFO:root:final mean train loss: 2282.6002753753587
INFO:root:final train perplexity: 6.050831317901611
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.19s/it]
INFO:root:eval mean loss: 2227.309514038952
INFO:root:eval perplexity: 6.057620525360107
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 2682.053390611148
INFO:root:eval perplexity: 8.966155052185059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/9
  4%|â–         | 9/200 [1:20:51<28:41:48, 540.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2252.848895733173
INFO:root:current train perplexity5.8904523849487305
INFO:root:current mean train loss 2253.024559422543
INFO:root:current train perplexity5.885882377624512
INFO:root:current mean train loss 2248.5684548029826
INFO:root:current train perplexity5.881786823272705
INFO:root:current mean train loss 2245.1748435280538
INFO:root:current train perplexity5.889793395996094
INFO:root:current mean train loss 2242.3954014060773
INFO:root:current train perplexity5.893947124481201
INFO:root:current mean train loss 2238.5042094355044
INFO:root:current train perplexity5.882619380950928
INFO:root:current mean train loss 2243.325850223471
INFO:root:current train perplexity5.882711887359619
INFO:root:current mean train loss 2245.8490243465344
INFO:root:current train perplexity5.884441375732422
INFO:root:current mean train loss 2248.6131669165384
INFO:root:current train perplexity5.88938045501709
INFO:root:current mean train loss 2250.01015619871
INFO:root:current train perplexity5.892359256744385
INFO:root:current mean train loss 2247.566167911196
INFO:root:current train perplexity5.887022495269775
INFO:root:current mean train loss 2248.111704296536
INFO:root:current train perplexity5.890272617340088
INFO:root:current mean train loss 2248.557394984431
INFO:root:current train perplexity5.888866424560547
INFO:root:current mean train loss 2248.2667284181134
INFO:root:current train perplexity5.887726783752441
INFO:root:current mean train loss 2250.1227572522544
INFO:root:current train perplexity5.889133930206299
INFO:root:current mean train loss 2249.058895622332
INFO:root:current train perplexity5.888139247894287
INFO:root:current mean train loss 2247.854341003566
INFO:root:current train perplexity5.887706756591797
INFO:root:current mean train loss 2247.591339668727
INFO:root:current train perplexity5.8890204429626465
INFO:root:current mean train loss 2247.866678653989
INFO:root:current train perplexity5.887693405151367
INFO:root:current mean train loss 2246.944465699743
INFO:root:current train perplexity5.881825923919678

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.52s/it]
INFO:root:final mean train loss: 2247.391745763058
INFO:root:final train perplexity: 5.885127544403076
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.19s/it]
INFO:root:eval mean loss: 2205.6278452771776
INFO:root:eval perplexity: 5.952327728271484
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 2663.510688944066
INFO:root:eval perplexity: 8.831212043762207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/10
  5%|â–Œ         | 10/200 [1:29:52<28:33:04, 540.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2230.528948355412
INFO:root:current train perplexity5.780325889587402
INFO:root:current mean train loss 2210.332431409486
INFO:root:current train perplexity5.7136335372924805
INFO:root:current mean train loss 2211.487169457191
INFO:root:current train perplexity5.7188825607299805
INFO:root:current mean train loss 2213.0622250936863
INFO:root:current train perplexity5.7407402992248535
INFO:root:current mean train loss 2216.070785164579
INFO:root:current train perplexity5.741678714752197
INFO:root:current mean train loss 2216.5764035726056
INFO:root:current train perplexity5.745632648468018
INFO:root:current mean train loss 2213.0759155090973
INFO:root:current train perplexity5.727779388427734
INFO:root:current mean train loss 2214.8923419213265
INFO:root:current train perplexity5.726461887359619
INFO:root:current mean train loss 2212.3676814001365
INFO:root:current train perplexity5.726131439208984
INFO:root:current mean train loss 2212.2570348529007
INFO:root:current train perplexity5.732956886291504
INFO:root:current mean train loss 2212.2396579382016
INFO:root:current train perplexity5.733392715454102
INFO:root:current mean train loss 2212.445036719251
INFO:root:current train perplexity5.730226039886475
INFO:root:current mean train loss 2212.438481756981
INFO:root:current train perplexity5.72468376159668
INFO:root:current mean train loss 2212.3886728558427
INFO:root:current train perplexity5.7307658195495605
INFO:root:current mean train loss 2214.5672902418205
INFO:root:current train perplexity5.732456684112549
INFO:root:current mean train loss 2217.5922762868963
INFO:root:current train perplexity5.739233493804932
INFO:root:current mean train loss 2216.891491560253
INFO:root:current train perplexity5.740891933441162
INFO:root:current mean train loss 2217.2281049746725
INFO:root:current train perplexity5.742788791656494
INFO:root:current mean train loss 2217.2879404197597
INFO:root:current train perplexity5.742960453033447
INFO:root:current mean train loss 2217.6300924212997
INFO:root:current train perplexity5.7459211349487305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.78s/it]
INFO:root:final mean train loss: 2216.6906963585
INFO:root:final train perplexity: 5.744343280792236
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it]
INFO:root:eval mean loss: 2192.348088257702
INFO:root:eval perplexity: 5.888741493225098
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 2654.5382872236537
INFO:root:eval perplexity: 8.766647338867188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/11
  6%|â–Œ         | 11/200 [1:38:52<28:23:31, 540.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2180.3738176212755
INFO:root:current train perplexity5.590234279632568
INFO:root:current mean train loss 2192.0684112220683
INFO:root:current train perplexity5.592087745666504
INFO:root:current mean train loss 2188.8766475223993
INFO:root:current train perplexity5.587470054626465
INFO:root:current mean train loss 2185.750352296187
INFO:root:current train perplexity5.583022117614746
INFO:root:current mean train loss 2192.0447289737654
INFO:root:current train perplexity5.6085076332092285
INFO:root:current mean train loss 2189.9178983408437
INFO:root:current train perplexity5.609612941741943
INFO:root:current mean train loss 2190.6351515878396
INFO:root:current train perplexity5.612980842590332
INFO:root:current mean train loss 2190.52161747202
INFO:root:current train perplexity5.615461349487305
INFO:root:current mean train loss 2186.588398608343
INFO:root:current train perplexity5.612448215484619
INFO:root:current mean train loss 2187.1583198717594
INFO:root:current train perplexity5.61859130859375
INFO:root:current mean train loss 2185.445803029322
INFO:root:current train perplexity5.611751079559326
INFO:root:current mean train loss 2186.574550069002
INFO:root:current train perplexity5.6145782470703125
INFO:root:current mean train loss 2186.937143945768
INFO:root:current train perplexity5.614477634429932
INFO:root:current mean train loss 2186.1378265424896
INFO:root:current train perplexity5.611238956451416
INFO:root:current mean train loss 2185.9305346811125
INFO:root:current train perplexity5.6112380027771
INFO:root:current mean train loss 2185.532643110124
INFO:root:current train perplexity5.6100897789001465
INFO:root:current mean train loss 2186.5024584207954
INFO:root:current train perplexity5.6120710372924805
INFO:root:current mean train loss 2188.6136515618437
INFO:root:current train perplexity5.613431930541992
INFO:root:current mean train loss 2189.1640545388927
INFO:root:current train perplexity5.615435600280762

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.11s/it]
INFO:root:final mean train loss: 2188.684939047332
INFO:root:final train perplexity: 5.61885929107666
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2177.2782947729665
INFO:root:eval perplexity: 5.817407608032227
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 2637.2804790523883
INFO:root:eval perplexity: 8.643787384033203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/12
  6%|â–Œ         | 12/200 [1:47:54<28:15:28, 541.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2134.4288330078125
INFO:root:current train perplexity5.228731155395508
INFO:root:current mean train loss 2189.1054177886076
INFO:root:current train perplexity5.519113540649414
INFO:root:current mean train loss 2168.224553451162
INFO:root:current train perplexity5.490662097930908
INFO:root:current mean train loss 2160.1310362359477
INFO:root:current train perplexity5.486367702484131
INFO:root:current mean train loss 2154.887379383627
INFO:root:current train perplexity5.490653991699219
INFO:root:current mean train loss 2158.4662833545603
INFO:root:current train perplexity5.498106002807617
INFO:root:current mean train loss 2156.8421151080533
INFO:root:current train perplexity5.5031328201293945
INFO:root:current mean train loss 2157.9531413223463
INFO:root:current train perplexity5.505734920501709
INFO:root:current mean train loss 2159.1845093533525
INFO:root:current train perplexity5.50649356842041
INFO:root:current mean train loss 2159.293289539426
INFO:root:current train perplexity5.501224040985107
INFO:root:current mean train loss 2159.251599206287
INFO:root:current train perplexity5.4982686042785645
INFO:root:current mean train loss 2160.233452223694
INFO:root:current train perplexity5.500057220458984
INFO:root:current mean train loss 2159.0921276723557
INFO:root:current train perplexity5.497365951538086
INFO:root:current mean train loss 2159.4329471427113
INFO:root:current train perplexity5.4976654052734375
INFO:root:current mean train loss 2162.4005489770802
INFO:root:current train perplexity5.502340316772461
INFO:root:current mean train loss 2162.2041135827303
INFO:root:current train perplexity5.500032424926758
INFO:root:current mean train loss 2163.103574337546
INFO:root:current train perplexity5.503180980682373
INFO:root:current mean train loss 2163.017059953368
INFO:root:current train perplexity5.5009765625
INFO:root:current mean train loss 2162.9243872923385
INFO:root:current train perplexity5.503835201263428
INFO:root:current mean train loss 2163.005411954911
INFO:root:current train perplexity5.5033674240112305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.18s/it]
INFO:root:final mean train loss: 2162.6886832140576
INFO:root:final train perplexity: 5.504832744598389
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2168.1423538965537
INFO:root:eval perplexity: 5.774583339691162
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 2632.2804764551474
INFO:root:eval perplexity: 8.608511924743652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/13
  6%|â–‹         | 13/200 [1:56:56<28:07:08, 541.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2110.7112243652346
INFO:root:current train perplexity5.2992095947265625
INFO:root:current mean train loss 2118.387358601888
INFO:root:current train perplexity5.299580097198486
INFO:root:current mean train loss 2133.664738880504
INFO:root:current train perplexity5.366604328155518
INFO:root:current mean train loss 2136.671765899658
INFO:root:current train perplexity5.3903350830078125
INFO:root:current mean train loss 2133.7713277180987
INFO:root:current train perplexity5.399291515350342
INFO:root:current mean train loss 2135.486447143555
INFO:root:current train perplexity5.401712894439697
INFO:root:current mean train loss 2134.1194125267766
INFO:root:current train perplexity5.39061975479126
INFO:root:current mean train loss 2131.6582171969944
INFO:root:current train perplexity5.383667945861816
INFO:root:current mean train loss 2132.381929723228
INFO:root:current train perplexity5.379805564880371
INFO:root:current mean train loss 2131.827336319633
INFO:root:current train perplexity5.3856377601623535
INFO:root:current mean train loss 2131.856899844899
INFO:root:current train perplexity5.38429594039917
INFO:root:current mean train loss 2134.3751307896205
INFO:root:current train perplexity5.388307094573975
INFO:root:current mean train loss 2134.6271701500064
INFO:root:current train perplexity5.389842510223389
INFO:root:current mean train loss 2135.1104062167083
INFO:root:current train perplexity5.391139984130859
INFO:root:current mean train loss 2134.782439583792
INFO:root:current train perplexity5.392516613006592
INFO:root:current mean train loss 2135.4971474095396
INFO:root:current train perplexity5.393551349639893
INFO:root:current mean train loss 2135.5587993857303
INFO:root:current train perplexity5.3936076164245605
INFO:root:current mean train loss 2137.960190600018
INFO:root:current train perplexity5.39832878112793
INFO:root:current mean train loss 2138.630971451644
INFO:root:current train perplexity5.400091648101807
INFO:root:current mean train loss 2139.4353350957235
INFO:root:current train perplexity5.403169631958008

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.88s/it]
INFO:root:final mean train loss: 2139.337285228889
INFO:root:final train perplexity: 5.404382705688477
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2156.8716538882427
INFO:root:eval perplexity: 5.722187519073486
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 2625.3210656998003
INFO:root:eval perplexity: 8.559653282165527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/14
  7%|â–‹         | 14/200 [2:05:57<27:57:23, 541.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2104.03302166913
INFO:root:current train perplexity5.240789890289307
INFO:root:current mean train loss 2101.8473996350367
INFO:root:current train perplexity5.2634782791137695
INFO:root:current mean train loss 2104.564174475046
INFO:root:current train perplexity5.265592575073242
INFO:root:current mean train loss 2109.025994818713
INFO:root:current train perplexity5.285754203796387
INFO:root:current mean train loss 2111.4616970175734
INFO:root:current train perplexity5.29886531829834
INFO:root:current mean train loss 2114.310534599773
INFO:root:current train perplexity5.307346343994141
INFO:root:current mean train loss 2113.587737510118
INFO:root:current train perplexity5.308130741119385
INFO:root:current mean train loss 2115.396520648268
INFO:root:current train perplexity5.306029319763184
INFO:root:current mean train loss 2117.738368463915
INFO:root:current train perplexity5.31456184387207
INFO:root:current mean train loss 2120.10125426269
INFO:root:current train perplexity5.317370414733887
INFO:root:current mean train loss 2119.978980598707
INFO:root:current train perplexity5.31315803527832
INFO:root:current mean train loss 2119.807971373921
INFO:root:current train perplexity5.315769672393799
INFO:root:current mean train loss 2119.5300602831953
INFO:root:current train perplexity5.314299583435059
INFO:root:current mean train loss 2118.2325969002723
INFO:root:current train perplexity5.312745571136475
INFO:root:current mean train loss 2117.856596350089
INFO:root:current train perplexity5.312796592712402
INFO:root:current mean train loss 2118.2944617088383
INFO:root:current train perplexity5.312549591064453
INFO:root:current mean train loss 2117.9544624044315
INFO:root:current train perplexity5.311474323272705
INFO:root:current mean train loss 2116.204053071702
INFO:root:current train perplexity5.31083345413208
INFO:root:current mean train loss 2117.3902967325294
INFO:root:current train perplexity5.310539722442627
INFO:root:current mean train loss 2117.543840131627
INFO:root:current train perplexity5.309576034545898

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.96s/it]
INFO:root:final mean train loss: 2117.194267915465
INFO:root:final train perplexity: 5.310823440551758
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2151.203530169548
INFO:root:eval perplexity: 5.696016311645508
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 2622.129246921404
INFO:root:eval perplexity: 8.537338256835938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/15
  8%|â–Š         | 15/200 [2:14:59<27:49:47, 541.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2054.2973791051795
INFO:root:current train perplexity5.14276647567749
INFO:root:current mean train loss 2083.603261179738
INFO:root:current train perplexity5.170055866241455
INFO:root:current mean train loss 2076.29136357345
INFO:root:current train perplexity5.159958362579346
INFO:root:current mean train loss 2078.985868809587
INFO:root:current train perplexity5.158217906951904
INFO:root:current mean train loss 2079.081986347484
INFO:root:current train perplexity5.163509845733643
INFO:root:current mean train loss 2082.0398513298173
INFO:root:current train perplexity5.178755760192871
INFO:root:current mean train loss 2085.144757472047
INFO:root:current train perplexity5.187399387359619
INFO:root:current mean train loss 2088.6113661707873
INFO:root:current train perplexity5.196374416351318
INFO:root:current mean train loss 2088.936586616748
INFO:root:current train perplexity5.1959357261657715
INFO:root:current mean train loss 2091.7554728190103
INFO:root:current train perplexity5.201034069061279
INFO:root:current mean train loss 2092.0974978133895
INFO:root:current train perplexity5.201005458831787
INFO:root:current mean train loss 2092.7797156586803
INFO:root:current train perplexity5.209095478057861
INFO:root:current mean train loss 2094.1786719022566
INFO:root:current train perplexity5.213022232055664
INFO:root:current mean train loss 2093.807430115197
INFO:root:current train perplexity5.213364124298096
INFO:root:current mean train loss 2093.6492856955756
INFO:root:current train perplexity5.212413311004639
INFO:root:current mean train loss 2093.8336074809463
INFO:root:current train perplexity5.215003490447998
INFO:root:current mean train loss 2094.1463130042225
INFO:root:current train perplexity5.215537071228027
INFO:root:current mean train loss 2094.9414662412255
INFO:root:current train perplexity5.215932369232178
INFO:root:current mean train loss 2096.341224382353
INFO:root:current train perplexity5.221322059631348
INFO:root:current mean train loss 2096.4872923805137
INFO:root:current train perplexity5.223635196685791

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.29s/it]
INFO:root:final mean train loss: 2096.5170139114603
INFO:root:final train perplexity: 5.22491979598999
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2142.4473374819927
INFO:root:eval perplexity: 5.65582275390625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 2620.2411447078625
INFO:root:eval perplexity: 8.524166107177734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/16
  8%|â–Š         | 16/200 [2:23:59<27:39:16, 541.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2070.3976913237234
INFO:root:current train perplexity5.03723669052124
INFO:root:current mean train loss 2079.64828259206
INFO:root:current train perplexity5.091238498687744
INFO:root:current mean train loss 2076.183486994782
INFO:root:current train perplexity5.112553596496582
INFO:root:current mean train loss 2073.220001631991
INFO:root:current train perplexity5.115312576293945
INFO:root:current mean train loss 2070.9673478760283
INFO:root:current train perplexity5.1064982414245605
INFO:root:current mean train loss 2073.6698570986346
INFO:root:current train perplexity5.106115341186523
INFO:root:current mean train loss 2073.6611024313643
INFO:root:current train perplexity5.119746685028076
INFO:root:current mean train loss 2072.1923620716298
INFO:root:current train perplexity5.113986015319824
INFO:root:current mean train loss 2075.733859950174
INFO:root:current train perplexity5.122123718261719
INFO:root:current mean train loss 2073.4671838290906
INFO:root:current train perplexity5.117153167724609
INFO:root:current mean train loss 2074.417904808408
INFO:root:current train perplexity5.118373870849609
INFO:root:current mean train loss 2073.247552130591
INFO:root:current train perplexity5.122162818908691
INFO:root:current mean train loss 2074.4611248793703
INFO:root:current train perplexity5.126765251159668
INFO:root:current mean train loss 2074.3788778470607
INFO:root:current train perplexity5.129964828491211
INFO:root:current mean train loss 2073.5467035538645
INFO:root:current train perplexity5.130801677703857
INFO:root:current mean train loss 2073.156040126089
INFO:root:current train perplexity5.127530097961426
INFO:root:current mean train loss 2074.6766691270664
INFO:root:current train perplexity5.134940147399902
INFO:root:current mean train loss 2075.6005166655273
INFO:root:current train perplexity5.134535789489746
INFO:root:current mean train loss 2076.2695435809937
INFO:root:current train perplexity5.139803409576416
INFO:root:current mean train loss 2076.6271571329194
INFO:root:current train perplexity5.141397476196289

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.12s/it]
INFO:root:final mean train loss: 2076.14927878791
INFO:root:final train perplexity: 5.141661643981934
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.55s/it]
INFO:root:eval mean loss: 2138.700881416916
INFO:root:eval perplexity: 5.638711929321289
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.84s/it]
INFO:root:eval mean loss: 2619.9900794063055
INFO:root:eval perplexity: 8.522417068481445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/17
  8%|â–Š         | 17/200 [2:32:58<27:27:48, 540.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2035.1215917413886
INFO:root:current train perplexity5.028773307800293
INFO:root:current mean train loss 2031.5674704693733
INFO:root:current train perplexity5.000385284423828
INFO:root:current mean train loss 2030.5662053426106
INFO:root:current train perplexity4.993533134460449
INFO:root:current mean train loss 2038.0806098230107
INFO:root:current train perplexity5.01090669631958
INFO:root:current mean train loss 2040.370888631852
INFO:root:current train perplexity5.027836322784424
INFO:root:current mean train loss 2042.144575469348
INFO:root:current train perplexity5.038030624389648
INFO:root:current mean train loss 2044.791428322016
INFO:root:current train perplexity5.045385360717773
INFO:root:current mean train loss 2048.552078014703
INFO:root:current train perplexity5.0521392822265625
INFO:root:current mean train loss 2049.288434552717
INFO:root:current train perplexity5.0539703369140625
INFO:root:current mean train loss 2049.427706575587
INFO:root:current train perplexity5.050869941711426
INFO:root:current mean train loss 2050.757120917825
INFO:root:current train perplexity5.055139541625977
INFO:root:current mean train loss 2049.697948520031
INFO:root:current train perplexity5.049285888671875
INFO:root:current mean train loss 2050.72626945543
INFO:root:current train perplexity5.053813457489014
INFO:root:current mean train loss 2050.0063001649182
INFO:root:current train perplexity5.05234956741333
INFO:root:current mean train loss 2052.6807291174446
INFO:root:current train perplexity5.057789325714111
INFO:root:current mean train loss 2053.4032681943186
INFO:root:current train perplexity5.057634353637695
INFO:root:current mean train loss 2054.1982586033537
INFO:root:current train perplexity5.060164928436279
INFO:root:current mean train loss 2055.840041738762
INFO:root:current train perplexity5.062664031982422
INFO:root:current mean train loss 2057.6898018788484
INFO:root:current train perplexity5.065511703491211

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.06s/it]
INFO:root:final mean train loss: 2057.496794038389
INFO:root:final train perplexity: 5.066577911376953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.70s/it]
INFO:root:eval mean loss: 2133.1909945873504
INFO:root:eval perplexity: 5.613640785217285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it]
INFO:root:eval mean loss: 2614.6242632493904
INFO:root:eval perplexity: 8.485099792480469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/18
  9%|â–‰         | 18/200 [2:41:50<27:11:56, 538.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2015.8749267578125
INFO:root:current train perplexity4.796076774597168
INFO:root:current mean train loss 2023.949962797619
INFO:root:current train perplexity4.924149513244629
INFO:root:current mean train loss 2027.6782280154343
INFO:root:current train perplexity4.925245761871338
INFO:root:current mean train loss 2031.4729296074538
INFO:root:current train perplexity4.947585105895996
INFO:root:current mean train loss 2031.7776361159335
INFO:root:current train perplexity4.942682266235352
INFO:root:current mean train loss 2032.1593619469368
INFO:root:current train perplexity4.94883918762207
INFO:root:current mean train loss 2029.8405539772727
INFO:root:current train perplexity4.9447922706604
INFO:root:current mean train loss 2033.7945007757091
INFO:root:current train perplexity4.953976154327393
INFO:root:current mean train loss 2035.3169516995827
INFO:root:current train perplexity4.958960056304932
INFO:root:current mean train loss 2034.0176663393474
INFO:root:current train perplexity4.963383674621582
INFO:root:current mean train loss 2036.184325686023
INFO:root:current train perplexity4.96664571762085
INFO:root:current mean train loss 2036.7884767834416
INFO:root:current train perplexity4.968364715576172
INFO:root:current mean train loss 2037.0840947954487
INFO:root:current train perplexity4.9746527671813965
INFO:root:current mean train loss 2036.7095269097222
INFO:root:current train perplexity4.974071502685547
INFO:root:current mean train loss 2037.5804584978314
INFO:root:current train perplexity4.97880220413208
INFO:root:current mean train loss 2039.057683454241
INFO:root:current train perplexity4.983464241027832
INFO:root:current mean train loss 2039.4043896636488
INFO:root:current train perplexity4.986504077911377
INFO:root:current mean train loss 2039.6560569785556
INFO:root:current train perplexity4.989365577697754
INFO:root:current mean train loss 2039.121134733163
INFO:root:current train perplexity4.99091100692749
INFO:root:current mean train loss 2040.1452225332184
INFO:root:current train perplexity4.994168281555176

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:59<00:00, 479.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:59<00:00, 479.06s/it]
INFO:root:final mean train loss: 2039.6034585295815
INFO:root:final train perplexity: 4.995582580566406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it]
INFO:root:eval mean loss: 2129.1936281894114
INFO:root:eval perplexity: 5.595523357391357
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it]
INFO:root:eval mean loss: 2617.782955088514
INFO:root:eval perplexity: 8.507046699523926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/19
 10%|â–‰         | 19/200 [2:50:44<26:59:04, 536.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1998.6388050426137
INFO:root:current train perplexity4.843724727630615
INFO:root:current mean train loss 1994.7514468333761
INFO:root:current train perplexity4.852522373199463
INFO:root:current mean train loss 2002.537544869088
INFO:root:current train perplexity4.864086151123047
INFO:root:current mean train loss 2007.4774431501116
INFO:root:current train perplexity4.885239601135254
INFO:root:current mean train loss 2005.2912505091085
INFO:root:current train perplexity4.883682727813721
INFO:root:current mean train loss 2012.0021577447767
INFO:root:current train perplexity4.900943279266357
INFO:root:current mean train loss 2013.5414236381507
INFO:root:current train perplexity4.902703285217285
INFO:root:current mean train loss 2015.59304547508
INFO:root:current train perplexity4.907548427581787
INFO:root:current mean train loss 2015.7058472273704
INFO:root:current train perplexity4.908331871032715
INFO:root:current mean train loss 2017.101952542452
INFO:root:current train perplexity4.910394191741943
INFO:root:current mean train loss 2018.748630351983
INFO:root:current train perplexity4.911174297332764
INFO:root:current mean train loss 2019.3231352399803
INFO:root:current train perplexity4.910557270050049
INFO:root:current mean train loss 2021.328807874514
INFO:root:current train perplexity4.917904376983643
INFO:root:current mean train loss 2022.368775891464
INFO:root:current train perplexity4.922976970672607
INFO:root:current mean train loss 2022.9691502052017
INFO:root:current train perplexity4.925580024719238
INFO:root:current mean train loss 2022.3315855570127
INFO:root:current train perplexity4.923337936401367
INFO:root:current mean train loss 2022.0481516959194
INFO:root:current train perplexity4.924625396728516
INFO:root:current mean train loss 2021.3932211562455
INFO:root:current train perplexity4.923886299133301
INFO:root:current mean train loss 2022.2558404145727
INFO:root:current train perplexity4.925441265106201
INFO:root:current mean train loss 2022.9210210159094
INFO:root:current train perplexity4.928747177124023

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.77s/it]
INFO:root:final mean train loss: 2022.2091377785396
INFO:root:final train perplexity: 4.92751932144165
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it]
INFO:root:eval mean loss: 2125.3643703595967
INFO:root:eval perplexity: 5.578221321105957
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it]
INFO:root:eval mean loss: 2614.952280463902
INFO:root:eval perplexity: 8.487378120422363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/20
 10%|â–ˆ         | 20/200 [2:59:37<26:47:07, 535.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1967.9142659505208
INFO:root:current train perplexity4.811051845550537
INFO:root:current mean train loss 1980.8280222501687
INFO:root:current train perplexity4.801864147186279
INFO:root:current mean train loss 1980.7744768852967
INFO:root:current train perplexity4.8180389404296875
INFO:root:current mean train loss 1987.748208915238
INFO:root:current train perplexity4.828380107879639
INFO:root:current mean train loss 1991.5777145768081
INFO:root:current train perplexity4.834209442138672
INFO:root:current mean train loss 1992.3157521886596
INFO:root:current train perplexity4.839382648468018
INFO:root:current mean train loss 1993.7036379245526
INFO:root:current train perplexity4.83188009262085
INFO:root:current mean train loss 1993.7859264988053
INFO:root:current train perplexity4.8361077308654785
INFO:root:current mean train loss 1994.6492588193255
INFO:root:current train perplexity4.8351969718933105
INFO:root:current mean train loss 1998.4280475458017
INFO:root:current train perplexity4.841765403747559
INFO:root:current mean train loss 2000.0111665551312
INFO:root:current train perplexity4.845767021179199
INFO:root:current mean train loss 2001.943326794337
INFO:root:current train perplexity4.849090576171875
INFO:root:current mean train loss 2002.2584005853068
INFO:root:current train perplexity4.853297710418701
INFO:root:current mean train loss 2002.4657368962671
INFO:root:current train perplexity4.851813793182373
INFO:root:current mean train loss 2003.327859651885
INFO:root:current train perplexity4.852728843688965
INFO:root:current mean train loss 2003.8858303890513
INFO:root:current train perplexity4.854057312011719
INFO:root:current mean train loss 2004.6154815692448
INFO:root:current train perplexity4.856832027435303
INFO:root:current mean train loss 2003.5179654648416
INFO:root:current train perplexity4.856169700622559
INFO:root:current mean train loss 2003.8275504929013
INFO:root:current train perplexity4.857753276824951
INFO:root:current mean train loss 2005.0662802135041
INFO:root:current train perplexity4.859586715698242

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.62s/it]
INFO:root:final mean train loss: 2004.7613774086572
INFO:root:final train perplexity: 4.860179901123047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.67s/it]
INFO:root:eval mean loss: 2122.8242810837764
INFO:root:eval perplexity: 5.566773414611816
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 27.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 27.00s/it]
INFO:root:eval mean loss: 2612.6652593950853
INFO:root:eval perplexity: 8.471515655517578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/21
 10%|â–ˆ         | 21/200 [3:08:31<26:35:53, 534.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1985.1455753871373
INFO:root:current train perplexity4.727352619171143
INFO:root:current mean train loss 1988.2156747671274
INFO:root:current train perplexity4.764563083648682
INFO:root:current mean train loss 1982.1917643547058
INFO:root:current train perplexity4.7649407386779785
INFO:root:current mean train loss 1985.219882579332
INFO:root:current train perplexity4.7763519287109375
INFO:root:current mean train loss 1981.7449854800575
INFO:root:current train perplexity4.769862651824951
INFO:root:current mean train loss 1980.504891155435
INFO:root:current train perplexity4.7714715003967285
INFO:root:current mean train loss 1980.9962329399295
INFO:root:current train perplexity4.769733428955078
INFO:root:current mean train loss 1979.3930132830585
INFO:root:current train perplexity4.773813724517822
INFO:root:current mean train loss 1978.5564419755312
INFO:root:current train perplexity4.769594669342041
INFO:root:current mean train loss 1979.2773659678185
INFO:root:current train perplexity4.772593975067139
INFO:root:current mean train loss 1981.63701803034
INFO:root:current train perplexity4.777984142303467
INFO:root:current mean train loss 1982.5452658049376
INFO:root:current train perplexity4.782440662384033
INFO:root:current mean train loss 1983.0694599516073
INFO:root:current train perplexity4.782103061676025
INFO:root:current mean train loss 1984.7122399434227
INFO:root:current train perplexity4.785032749176025
INFO:root:current mean train loss 1987.0877978985127
INFO:root:current train perplexity4.790682792663574
INFO:root:current mean train loss 1988.4711961917828
INFO:root:current train perplexity4.79421854019165
INFO:root:current mean train loss 1988.1034072654834
INFO:root:current train perplexity4.796269416809082
INFO:root:current mean train loss 1989.6035031816139
INFO:root:current train perplexity4.800342082977295
INFO:root:current mean train loss 1989.569974899292
INFO:root:current train perplexity4.799905776977539
INFO:root:current mean train loss 1989.9051737093
INFO:root:current train perplexity4.801039218902588

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.86s/it]
INFO:root:final mean train loss: 1989.207202628593
INFO:root:final train perplexity: 4.800924301147461
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it]
INFO:root:eval mean loss: 2119.536483872867
INFO:root:eval perplexity: 5.551991939544678
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it]
INFO:root:eval mean loss: 2612.3233265978224
INFO:root:eval perplexity: 8.469146728515625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/22
 11%|â–ˆ         | 22/200 [3:17:24<26:25:36, 534.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1958.6974395333905
INFO:root:current train perplexity4.649125099182129
INFO:root:current mean train loss 1956.414484454028
INFO:root:current train perplexity4.6709089279174805
INFO:root:current mean train loss 1958.5687094887535
INFO:root:current train perplexity4.685758113861084
INFO:root:current mean train loss 1960.2649449407256
INFO:root:current train perplexity4.686257362365723
INFO:root:current mean train loss 1958.977284598804
INFO:root:current train perplexity4.691037654876709
INFO:root:current mean train loss 1960.3902575108393
INFO:root:current train perplexity4.699342727661133
INFO:root:current mean train loss 1964.074483930976
INFO:root:current train perplexity4.696568965911865
INFO:root:current mean train loss 1964.8998274908029
INFO:root:current train perplexity4.699399471282959
INFO:root:current mean train loss 1966.2680634698506
INFO:root:current train perplexity4.7069315910339355
INFO:root:current mean train loss 1968.316577499719
INFO:root:current train perplexity4.7136335372924805
INFO:root:current mean train loss 1969.213871624352
INFO:root:current train perplexity4.718388080596924
INFO:root:current mean train loss 1971.797136207574
INFO:root:current train perplexity4.723668575286865
INFO:root:current mean train loss 1972.3302025926084
INFO:root:current train perplexity4.725356578826904
INFO:root:current mean train loss 1972.0084567254073
INFO:root:current train perplexity4.724112033843994
INFO:root:current mean train loss 1972.5114535599118
INFO:root:current train perplexity4.728079795837402
INFO:root:current mean train loss 1972.5402217411495
INFO:root:current train perplexity4.7302045822143555
INFO:root:current mean train loss 1973.3333665080506
INFO:root:current train perplexity4.734511852264404
INFO:root:current mean train loss 1973.9701331881433
INFO:root:current train perplexity4.7364044189453125
INFO:root:current mean train loss 1973.8016608340563
INFO:root:current train perplexity4.735139846801758
INFO:root:current mean train loss 1973.5150749102136
INFO:root:current train perplexity4.739151954650879

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.91s/it]
INFO:root:final mean train loss: 1972.9774936939573
INFO:root:final train perplexity: 4.739865779876709
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it]
INFO:root:eval mean loss: 2118.665929483184
INFO:root:eval perplexity: 5.548084259033203
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it]
INFO:root:eval mean loss: 2616.3426985503934
INFO:root:eval perplexity: 8.49703311920166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/23
 12%|â–ˆâ–        | 23/200 [3:26:16<26:14:58, 533.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1965.442919921875
INFO:root:current train perplexity4.656074523925781
INFO:root:current mean train loss 1962.9241724917763
INFO:root:current train perplexity4.674938201904297
INFO:root:current mean train loss 1960.066139379041
INFO:root:current train perplexity4.675779819488525
INFO:root:current mean train loss 1960.3212176983172
INFO:root:current train perplexity4.669428825378418
INFO:root:current mean train loss 1953.9703628228635
INFO:root:current train perplexity4.652768135070801
INFO:root:current mean train loss 1953.9355396335409
INFO:root:current train perplexity4.653275489807129
INFO:root:current mean train loss 1955.1225918534874
INFO:root:current train perplexity4.663372993469238
INFO:root:current mean train loss 1952.6850281534316
INFO:root:current train perplexity4.662461757659912
INFO:root:current mean train loss 1953.137149013562
INFO:root:current train perplexity4.6681389808654785
INFO:root:current mean train loss 1954.113115530303
INFO:root:current train perplexity4.6693339347839355
INFO:root:current mean train loss 1954.2902539734446
INFO:root:current train perplexity4.671573162078857
INFO:root:current mean train loss 1954.106865172827
INFO:root:current train perplexity4.671411991119385
INFO:root:current mean train loss 1953.1935212837634
INFO:root:current train perplexity4.670801639556885
INFO:root:current mean train loss 1954.5678928732013
INFO:root:current train perplexity4.673588275909424
INFO:root:current mean train loss 1956.9222752923133
INFO:root:current train perplexity4.674569129943848
INFO:root:current mean train loss 1956.8512035825718
INFO:root:current train perplexity4.675714492797852
INFO:root:current mean train loss 1956.888449981509
INFO:root:current train perplexity4.677433490753174
INFO:root:current mean train loss 1958.2684997899573
INFO:root:current train perplexity4.6822686195373535
INFO:root:current mean train loss 1958.927842688182
INFO:root:current train perplexity4.683001518249512

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.13s/it]
INFO:root:final mean train loss: 1957.810999236922
INFO:root:final train perplexity: 4.68350887298584
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.69s/it]
INFO:root:eval mean loss: 2117.6141669090757
INFO:root:eval perplexity: 5.5433669090271
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it]
INFO:root:eval mean loss: 2617.2127239687225
INFO:root:eval perplexity: 8.50307846069336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/24
 12%|â–ˆâ–        | 24/200 [3:35:09<26:05:07, 533.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1917.4327043805804
INFO:root:current train perplexity4.589840888977051
INFO:root:current mean train loss 1947.2667863792349
INFO:root:current train perplexity4.637959957122803
INFO:root:current mean train loss 1941.894254675234
INFO:root:current train perplexity4.6352972984313965
INFO:root:current mean train loss 1946.5444105316062
INFO:root:current train perplexity4.622906684875488
INFO:root:current mean train loss 1943.9894047767582
INFO:root:current train perplexity4.628568649291992
INFO:root:current mean train loss 1943.6259086654031
INFO:root:current train perplexity4.617971420288086
INFO:root:current mean train loss 1945.637547701941
INFO:root:current train perplexity4.613931179046631
INFO:root:current mean train loss 1945.3578533512532
INFO:root:current train perplexity4.611212253570557
INFO:root:current mean train loss 1945.904176468595
INFO:root:current train perplexity4.610378742218018
INFO:root:current mean train loss 1941.8663898034815
INFO:root:current train perplexity4.608243942260742
INFO:root:current mean train loss 1942.0392773049591
INFO:root:current train perplexity4.610474109649658
INFO:root:current mean train loss 1941.0029438022245
INFO:root:current train perplexity4.613215923309326
INFO:root:current mean train loss 1940.794534223378
INFO:root:current train perplexity4.610384464263916
INFO:root:current mean train loss 1943.1018513779468
INFO:root:current train perplexity4.616349220275879
INFO:root:current mean train loss 1942.7835277782406
INFO:root:current train perplexity4.618627548217773
INFO:root:current mean train loss 1944.7801431049634
INFO:root:current train perplexity4.6231842041015625
INFO:root:current mean train loss 1943.1758718722047
INFO:root:current train perplexity4.6239728927612305
INFO:root:current mean train loss 1943.3559200597495
INFO:root:current train perplexity4.626410961151123
INFO:root:current mean train loss 1942.372628850045
INFO:root:current train perplexity4.62714147567749
INFO:root:current mean train loss 1942.727304331595
INFO:root:current train perplexity4.627130508422852

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.78s/it]
INFO:root:final mean train loss: 1942.6356927561026
INFO:root:final train perplexity: 4.627789497375488
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.67s/it]
INFO:root:eval mean loss: 2115.885732664284
INFO:root:eval perplexity: 5.535622596740723
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 27.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 27.00s/it]
INFO:root:eval mean loss: 2614.813827622867
INFO:root:eval perplexity: 8.486412048339844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/25
 12%|â–ˆâ–Ž        | 25/200 [3:44:03<25:56:01, 533.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1910.1495259602864
INFO:root:current train perplexity4.515504837036133
INFO:root:current mean train loss 1902.5530789283014
INFO:root:current train perplexity4.502001762390137
INFO:root:current mean train loss 1916.306886945452
INFO:root:current train perplexity4.53720235824585
INFO:root:current mean train loss 1920.1179108796296
INFO:root:current train perplexity4.556417465209961
INFO:root:current mean train loss 1925.0099029541016
INFO:root:current train perplexity4.561710834503174
INFO:root:current mean train loss 1921.531750861015
INFO:root:current train perplexity4.556631565093994
INFO:root:current mean train loss 1918.6736131325747
INFO:root:current train perplexity4.547699451446533
INFO:root:current mean train loss 1921.2409969772423
INFO:root:current train perplexity4.550897598266602
INFO:root:current mean train loss 1921.3615085638842
INFO:root:current train perplexity4.557037830352783
INFO:root:current mean train loss 1920.3797496448863
INFO:root:current train perplexity4.552928924560547
INFO:root:current mean train loss 1920.708708524704
INFO:root:current train perplexity4.556183338165283
INFO:root:current mean train loss 1920.4066157765235
INFO:root:current train perplexity4.554283618927002
INFO:root:current mean train loss 1920.5021858963312
INFO:root:current train perplexity4.551783561706543
INFO:root:current mean train loss 1921.7853644333577
INFO:root:current train perplexity4.553516387939453
INFO:root:current mean train loss 1923.7420621721933
INFO:root:current train perplexity4.55824089050293
INFO:root:current mean train loss 1923.345900007433
INFO:root:current train perplexity4.558300018310547
INFO:root:current mean train loss 1925.3115020150622
INFO:root:current train perplexity4.562967300415039
INFO:root:current mean train loss 1927.0147381492668
INFO:root:current train perplexity4.570004463195801
INFO:root:current mean train loss 1927.1433923955549
INFO:root:current train perplexity4.572081089019775
INFO:root:current mean train loss 1928.2323067837594
INFO:root:current train perplexity4.574168682098389

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.33s/it]
INFO:root:final mean train loss: 1927.999891441757
INFO:root:final train perplexity: 4.574680328369141
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it]
INFO:root:eval mean loss: 2114.7647272204676
INFO:root:eval perplexity: 5.530606269836426
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it]
INFO:root:eval mean loss: 2620.172604824634
INFO:root:eval perplexity: 8.523689270019531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/26
 13%|â–ˆâ–Ž        | 26/200 [3:52:56<25:46:40, 533.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1907.3732850609756
INFO:root:current train perplexity4.505937099456787
INFO:root:current mean train loss 1906.7407702723294
INFO:root:current train perplexity4.513060569763184
INFO:root:current mean train loss 1907.313097688667
INFO:root:current train perplexity4.507031440734863
INFO:root:current mean train loss 1906.1405458869822
INFO:root:current train perplexity4.501560211181641
INFO:root:current mean train loss 1904.615594496262
INFO:root:current train perplexity4.49608850479126
INFO:root:current mean train loss 1904.1563470244628
INFO:root:current train perplexity4.496633052825928
INFO:root:current mean train loss 1906.911418087583
INFO:root:current train perplexity4.505477428436279
INFO:root:current mean train loss 1907.4302284971745
INFO:root:current train perplexity4.509748935699463
INFO:root:current mean train loss 1908.9276963459608
INFO:root:current train perplexity4.519256591796875
INFO:root:current mean train loss 1908.6158486182835
INFO:root:current train perplexity4.520860195159912
INFO:root:current mean train loss 1908.2258231596347
INFO:root:current train perplexity4.51711368560791
INFO:root:current mean train loss 1909.1717435149744
INFO:root:current train perplexity4.520546913146973
INFO:root:current mean train loss 1908.6431992966548
INFO:root:current train perplexity4.520138263702393
INFO:root:current mean train loss 1909.4301568471524
INFO:root:current train perplexity4.522425174713135
INFO:root:current mean train loss 1910.539838294533
INFO:root:current train perplexity4.522278785705566
INFO:root:current mean train loss 1909.7998762186435
INFO:root:current train perplexity4.51811408996582
INFO:root:current mean train loss 1910.375398495225
INFO:root:current train perplexity4.518949031829834
INFO:root:current mean train loss 1911.8129232845931
INFO:root:current train perplexity4.521395683288574
INFO:root:current mean train loss 1913.1181193055957
INFO:root:current train perplexity4.522388935089111
INFO:root:current mean train loss 1913.5662012272185
INFO:root:current train perplexity4.522335052490234

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.66s/it]
INFO:root:final mean train loss: 1913.6110173166248
INFO:root:final train perplexity: 4.523059368133545
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it]
INFO:root:eval mean loss: 2115.8220478896556
INFO:root:eval perplexity: 5.535338401794434
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.00s/it]
INFO:root:eval mean loss: 2622.3019019593585
INFO:root:eval perplexity: 8.538544654846191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/27
 14%|â–ˆâ–Ž        | 27/200 [4:01:49<25:37:43, 533.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1872.039355047818
INFO:root:current train perplexity4.429429531097412
INFO:root:current mean train loss 1874.2611763869659
INFO:root:current train perplexity4.428305625915527
INFO:root:current mean train loss 1874.819693631904
INFO:root:current train perplexity4.409985542297363
INFO:root:current mean train loss 1877.3341023535702
INFO:root:current train perplexity4.422628402709961
INFO:root:current mean train loss 1880.8462886893592
INFO:root:current train perplexity4.426403045654297
INFO:root:current mean train loss 1882.5174645864836
INFO:root:current train perplexity4.429715633392334
INFO:root:current mean train loss 1887.9771641322545
INFO:root:current train perplexity4.440388202667236
INFO:root:current mean train loss 1889.0613918656725
INFO:root:current train perplexity4.443348407745361
INFO:root:current mean train loss 1892.5669538591292
INFO:root:current train perplexity4.451147556304932
INFO:root:current mean train loss 1894.3732521519034
INFO:root:current train perplexity4.455733776092529
INFO:root:current mean train loss 1895.3780975630243
INFO:root:current train perplexity4.456622123718262
INFO:root:current mean train loss 1897.261957619886
INFO:root:current train perplexity4.4583516120910645
INFO:root:current mean train loss 1896.5123234735195
INFO:root:current train perplexity4.459963798522949
INFO:root:current mean train loss 1896.9324034296185
INFO:root:current train perplexity4.460992813110352
INFO:root:current mean train loss 1898.4110117468815
INFO:root:current train perplexity4.465060234069824
INFO:root:current mean train loss 1900.6048306623074
INFO:root:current train perplexity4.469627857208252
INFO:root:current mean train loss 1899.6449943514872
INFO:root:current train perplexity4.4700093269348145
INFO:root:current mean train loss 1899.636827071779
INFO:root:current train perplexity4.470730304718018
INFO:root:current mean train loss 1899.592621802257
INFO:root:current train perplexity4.473646640777588
INFO:root:current mean train loss 1900.2863099329074
INFO:root:current train perplexity4.471860408782959

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.20s/it]
INFO:root:final mean train loss: 1899.3320315270128
INFO:root:final train perplexity: 4.472410678863525
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it]
INFO:root:eval mean loss: 2114.5517080320533
INFO:root:eval perplexity: 5.529653549194336
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 27.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 27.00s/it]
INFO:root:eval mean loss: 2622.444516012855
INFO:root:eval perplexity: 8.53954029083252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/28
 14%|â–ˆâ–        | 28/200 [4:10:42<25:28:25, 533.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1866.5700113932292
INFO:root:current train perplexity4.363060474395752
INFO:root:current mean train loss 1864.0898116629464
INFO:root:current train perplexity4.366528511047363
INFO:root:current mean train loss 1869.4385613458808
INFO:root:current train perplexity4.37730598449707
INFO:root:current mean train loss 1867.345613606771
INFO:root:current train perplexity4.371577739715576
INFO:root:current mean train loss 1866.9171918688323
INFO:root:current train perplexity4.3661699295043945
INFO:root:current mean train loss 1872.5511334493885
INFO:root:current train perplexity4.383642673492432
INFO:root:current mean train loss 1874.8704137731481
INFO:root:current train perplexity4.390589714050293
INFO:root:current mean train loss 1875.0358617376512
INFO:root:current train perplexity4.392535209655762
INFO:root:current mean train loss 1877.3006692243302
INFO:root:current train perplexity4.396983623504639
INFO:root:current mean train loss 1878.9557650991587
INFO:root:current train perplexity4.4051899909973145
INFO:root:current mean train loss 1880.1744281431686
INFO:root:current train perplexity4.409607410430908
INFO:root:current mean train loss 1881.5349952210772
INFO:root:current train perplexity4.413532733917236
INFO:root:current mean train loss 1881.8775345626532
INFO:root:current train perplexity4.4159135818481445
INFO:root:current mean train loss 1881.3836344105114
INFO:root:current train perplexity4.415348052978516
INFO:root:current mean train loss 1880.8052625132416
INFO:root:current train perplexity4.4145402908325195
INFO:root:current mean train loss 1881.3534916759672
INFO:root:current train perplexity4.415524005889893
INFO:root:current mean train loss 1882.833529763293
INFO:root:current train perplexity4.417210102081299
INFO:root:current mean train loss 1884.197452134683
INFO:root:current train perplexity4.4208149909973145
INFO:root:current mean train loss 1885.2767956380208
INFO:root:current train perplexity4.422958850860596
INFO:root:current mean train loss 1886.3658064675633
INFO:root:current train perplexity4.425712585449219

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.29s/it]
INFO:root:final mean train loss: 1886.13861484114
INFO:root:final train perplexity: 4.426115989685059
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it]
INFO:root:eval mean loss: 2116.0200974484706
INFO:root:eval perplexity: 5.536225318908691
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 27.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 27.00s/it]
INFO:root:eval mean loss: 2628.737883006427
INFO:root:eval perplexity: 8.583606719970703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/29
 14%|â–ˆâ–        | 29/200 [4:19:35<25:19:17, 533.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1865.65453570822
INFO:root:current train perplexity4.32330322265625
INFO:root:current mean train loss 1868.6414642333984
INFO:root:current train perplexity4.348880290985107
INFO:root:current mean train loss 1865.8215733358304
INFO:root:current train perplexity4.353652477264404
INFO:root:current mean train loss 1863.9554552350726
INFO:root:current train perplexity4.346096992492676
INFO:root:current mean train loss 1865.2428777431085
INFO:root:current train perplexity4.344645977020264
INFO:root:current mean train loss 1866.109136426771
INFO:root:current train perplexity4.352474212646484
INFO:root:current mean train loss 1867.932280788532
INFO:root:current train perplexity4.3559722900390625
INFO:root:current mean train loss 1866.8834963711824
INFO:root:current train perplexity4.357900619506836
INFO:root:current mean train loss 1867.8530410287626
INFO:root:current train perplexity4.365514278411865
INFO:root:current mean train loss 1868.7972690213112
INFO:root:current train perplexity4.365951061248779
INFO:root:current mean train loss 1872.0226469494048
INFO:root:current train perplexity4.372690200805664
INFO:root:current mean train loss 1871.3006320415727
INFO:root:current train perplexity4.372317790985107
INFO:root:current mean train loss 1873.9011448721399
INFO:root:current train perplexity4.3777618408203125
INFO:root:current mean train loss 1873.151524510877
INFO:root:current train perplexity4.377400875091553
INFO:root:current mean train loss 1871.6969666672776
INFO:root:current train perplexity4.377099990844727
INFO:root:current mean train loss 1872.0052388253523
INFO:root:current train perplexity4.377170562744141
INFO:root:current mean train loss 1872.626433821153
INFO:root:current train perplexity4.378113746643066
INFO:root:current mean train loss 1873.636274269649
INFO:root:current train perplexity4.380171298980713
INFO:root:current mean train loss 1872.4742616810709
INFO:root:current train perplexity4.378194808959961

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.89s/it]
INFO:root:final mean train loss: 1873.021002372707
INFO:root:final train perplexity: 4.380561828613281
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.67s/it]
INFO:root:eval mean loss: 2115.26377100302
INFO:root:eval perplexity: 5.532839298248291
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.00s/it]
INFO:root:eval mean loss: 2628.2273373434728
INFO:root:eval perplexity: 8.580021858215332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/30
 15%|â–ˆâ–Œ        | 30/200 [4:28:27<25:09:53, 532.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1831.4767659505208
INFO:root:current train perplexity4.285431861877441
INFO:root:current mean train loss 1844.8704856382597
INFO:root:current train perplexity4.290664196014404
INFO:root:current mean train loss 1848.490550356048
INFO:root:current train perplexity4.293001651763916
INFO:root:current mean train loss 1850.4665290314017
INFO:root:current train perplexity4.3016276359558105
INFO:root:current mean train loss 1856.4753564214357
INFO:root:current train perplexity4.312697887420654
INFO:root:current mean train loss 1855.9970465699441
INFO:root:current train perplexity4.314320087432861
INFO:root:current mean train loss 1853.3325676377772
INFO:root:current train perplexity4.316718578338623
INFO:root:current mean train loss 1855.9735372567548
INFO:root:current train perplexity4.316770076751709
INFO:root:current mean train loss 1854.362490735331
INFO:root:current train perplexity4.316809177398682
INFO:root:current mean train loss 1854.0293324620548
INFO:root:current train perplexity4.317579746246338
INFO:root:current mean train loss 1853.6240333579813
INFO:root:current train perplexity4.316471576690674
INFO:root:current mean train loss 1854.840655754234
INFO:root:current train perplexity4.321479797363281
INFO:root:current mean train loss 1854.768046010714
INFO:root:current train perplexity4.322258949279785
INFO:root:current mean train loss 1854.587006384585
INFO:root:current train perplexity4.322713851928711
INFO:root:current mean train loss 1855.9693060307065
INFO:root:current train perplexity4.325900554656982
INFO:root:current mean train loss 1856.0215159239874
INFO:root:current train perplexity4.324301242828369
INFO:root:current mean train loss 1856.5770812950348
INFO:root:current train perplexity4.324314117431641
INFO:root:current mean train loss 1858.3943099663088
INFO:root:current train perplexity4.327964782714844
INFO:root:current mean train loss 1858.1529574080553
INFO:root:current train perplexity4.3286566734313965
INFO:root:current mean train loss 1859.443704676041
INFO:root:current train perplexity4.332939624786377

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.76s/it]
INFO:root:final mean train loss: 1859.5128987322416
INFO:root:final train perplexity: 4.334141731262207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.69s/it]
INFO:root:eval mean loss: 2117.3714153749725
INFO:root:eval perplexity: 5.542277812957764
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it]
INFO:root:eval mean loss: 2630.636631309563
INFO:root:eval perplexity: 8.59694766998291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/31
 16%|â–ˆâ–Œ        | 31/200 [4:37:20<25:01:25, 533.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1848.376469538762
INFO:root:current train perplexity4.185976982116699
INFO:root:current mean train loss 1837.4593767438616
INFO:root:current train perplexity4.257659435272217
INFO:root:current mean train loss 1838.394329239837
INFO:root:current train perplexity4.253152847290039
INFO:root:current mean train loss 1835.7291716593174
INFO:root:current train perplexity4.251270771026611
INFO:root:current mean train loss 1832.78261741674
INFO:root:current train perplexity4.256021499633789
INFO:root:current mean train loss 1835.0575046321737
INFO:root:current train perplexity4.257884502410889
INFO:root:current mean train loss 1839.0216610454522
INFO:root:current train perplexity4.261231422424316
INFO:root:current mean train loss 1840.761702776612
INFO:root:current train perplexity4.2664265632629395
INFO:root:current mean train loss 1840.0649943132378
INFO:root:current train perplexity4.270617485046387
INFO:root:current mean train loss 1838.6855489842062
INFO:root:current train perplexity4.272862434387207
INFO:root:current mean train loss 1840.73986054954
INFO:root:current train perplexity4.276314735412598
INFO:root:current mean train loss 1842.5600622797097
INFO:root:current train perplexity4.277472496032715
INFO:root:current mean train loss 1843.74620377259
INFO:root:current train perplexity4.281517028808594
INFO:root:current mean train loss 1845.6298482903528
INFO:root:current train perplexity4.283997058868408
INFO:root:current mean train loss 1846.3664886346205
INFO:root:current train perplexity4.286865234375
INFO:root:current mean train loss 1846.4377618992157
INFO:root:current train perplexity4.287482261657715
INFO:root:current mean train loss 1847.3433014328923
INFO:root:current train perplexity4.289902210235596
INFO:root:current mean train loss 1847.0346979558951
INFO:root:current train perplexity4.29044771194458
INFO:root:current mean train loss 1847.807093207703
INFO:root:current train perplexity4.291157245635986
INFO:root:current mean train loss 1847.7399784456532
INFO:root:current train perplexity4.292203426361084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.98s/it]
INFO:root:final mean train loss: 1847.1781954782152
INFO:root:final train perplexity: 4.292184352874756
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.69s/it]
INFO:root:eval mean loss: 2117.728254169437
INFO:root:eval perplexity: 5.543878078460693
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.00s/it]
INFO:root:eval mean loss: 2636.1160196074356
INFO:root:eval perplexity: 8.6355562210083
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/32
 16%|â–ˆâ–Œ        | 32/200 [4:46:13<24:52:10, 532.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1812.6613968250363
INFO:root:current train perplexity4.165005683898926
INFO:root:current mean train loss 1817.0755743280158
INFO:root:current train perplexity4.187420845031738
INFO:root:current mean train loss 1826.8753948447145
INFO:root:current train perplexity4.205564975738525
INFO:root:current mean train loss 1824.6262196354546
INFO:root:current train perplexity4.213756561279297
INFO:root:current mean train loss 1822.572936873942
INFO:root:current train perplexity4.209752559661865
INFO:root:current mean train loss 1823.1913212728764
INFO:root:current train perplexity4.212898254394531
INFO:root:current mean train loss 1826.0272661034094
INFO:root:current train perplexity4.216533184051514
INFO:root:current mean train loss 1825.3702445152148
INFO:root:current train perplexity4.220420837402344
INFO:root:current mean train loss 1827.4565580284327
INFO:root:current train perplexity4.225602149963379
INFO:root:current mean train loss 1828.184084749677
INFO:root:current train perplexity4.230223178863525
INFO:root:current mean train loss 1830.0907118185598
INFO:root:current train perplexity4.232306003570557
INFO:root:current mean train loss 1831.012841625998
INFO:root:current train perplexity4.234408855438232
INFO:root:current mean train loss 1831.554620326956
INFO:root:current train perplexity4.235751628875732
INFO:root:current mean train loss 1830.3904922951183
INFO:root:current train perplexity4.236586093902588
INFO:root:current mean train loss 1831.9074144475755
INFO:root:current train perplexity4.240729331970215
INFO:root:current mean train loss 1833.6187411077751
INFO:root:current train perplexity4.242183208465576
INFO:root:current mean train loss 1834.2783735093008
INFO:root:current train perplexity4.244210720062256
INFO:root:current mean train loss 1834.266966302711
INFO:root:current train perplexity4.247008800506592
INFO:root:current mean train loss 1834.564801055196
INFO:root:current train perplexity4.246630668640137
INFO:root:current mean train loss 1834.6984680458497
INFO:root:current train perplexity4.2471795082092285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.81s/it]
INFO:root:final mean train loss: 1833.9373326534824
INFO:root:final train perplexity: 4.247596740722656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it]
INFO:root:eval mean loss: 2120.6206781914893
INFO:root:eval perplexity: 5.556861877441406
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 27.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 27.00s/it]
INFO:root:eval mean loss: 2641.430140285627
INFO:root:eval perplexity: 8.673166275024414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/33
 16%|â–ˆâ–‹        | 33/200 [4:55:06<24:43:43, 533.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1814.5248107910156
INFO:root:current train perplexity4.148580074310303
INFO:root:current mean train loss 1804.9535911560058
INFO:root:current train perplexity4.135706901550293
INFO:root:current mean train loss 1809.4423335148738
INFO:root:current train perplexity4.149958610534668
INFO:root:current mean train loss 1809.956979031033
INFO:root:current train perplexity4.158794403076172
INFO:root:current mean train loss 1808.3348754882813
INFO:root:current train perplexity4.159850120544434
INFO:root:current mean train loss 1811.861185346331
INFO:root:current train perplexity4.169066429138184
INFO:root:current mean train loss 1811.9852287523674
INFO:root:current train perplexity4.174217700958252
INFO:root:current mean train loss 1815.1794621517784
INFO:root:current train perplexity4.178895950317383
INFO:root:current mean train loss 1814.2706557162971
INFO:root:current train perplexity4.182300567626953
INFO:root:current mean train loss 1815.8201176961263
INFO:root:current train perplexity4.184630870819092
INFO:root:current mean train loss 1814.2213578134213
INFO:root:current train perplexity4.185227394104004
INFO:root:current mean train loss 1815.083920709018
INFO:root:current train perplexity4.188326835632324
INFO:root:current mean train loss 1816.8178781660777
INFO:root:current train perplexity4.193293571472168
INFO:root:current mean train loss 1817.8794998168946
INFO:root:current train perplexity4.19416618347168
INFO:root:current mean train loss 1817.8376788413689
INFO:root:current train perplexity4.195668697357178
INFO:root:current mean train loss 1819.5689678485578
INFO:root:current train perplexity4.201547622680664
INFO:root:current mean train loss 1819.5572409756212
INFO:root:current train perplexity4.201406002044678
INFO:root:current mean train loss 1819.8144115101206
INFO:root:current train perplexity4.201193809509277
INFO:root:current mean train loss 1820.5585091539608
INFO:root:current train perplexity4.202273368835449
INFO:root:current mean train loss 1821.348579064194
INFO:root:current train perplexity4.203922748565674

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.99s/it]
INFO:root:final mean train loss: 1821.047088853891
INFO:root:final train perplexity: 4.204634189605713
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.66s/it]
INFO:root:eval mean loss: 2120.87864392869
INFO:root:eval perplexity: 5.55802059173584
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.98s/it]
INFO:root:eval mean loss: 2642.65253075133
INFO:root:eval perplexity: 8.681843757629395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/34
 17%|â–ˆâ–‹        | 34/200 [5:03:59<24:34:24, 532.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1798.6707335633116
INFO:root:current train perplexity4.1364312171936035
INFO:root:current mean train loss 1810.1056632349046
INFO:root:current train perplexity4.142959117889404
INFO:root:current mean train loss 1812.1645397640739
INFO:root:current train perplexity4.136683464050293
INFO:root:current mean train loss 1807.914191693779
INFO:root:current train perplexity4.129579544067383
INFO:root:current mean train loss 1803.8280300564236
INFO:root:current train perplexity4.128337860107422
INFO:root:current mean train loss 1801.7403892371642
INFO:root:current train perplexity4.137068748474121
INFO:root:current mean train loss 1802.6791492726989
INFO:root:current train perplexity4.136898517608643
INFO:root:current mean train loss 1803.6103138573842
INFO:root:current train perplexity4.138240337371826
INFO:root:current mean train loss 1805.513466707793
INFO:root:current train perplexity4.142747402191162
INFO:root:current mean train loss 1805.575573518064
INFO:root:current train perplexity4.143990516662598
INFO:root:current mean train loss 1806.2839370203328
INFO:root:current train perplexity4.148488521575928
INFO:root:current mean train loss 1806.679492623095
INFO:root:current train perplexity4.152256011962891
INFO:root:current mean train loss 1807.1700692770532
INFO:root:current train perplexity4.155627727508545
INFO:root:current mean train loss 1806.6299974362576
INFO:root:current train perplexity4.154403209686279
INFO:root:current mean train loss 1807.89295111303
INFO:root:current train perplexity4.157418727874756
INFO:root:current mean train loss 1807.0303757691127
INFO:root:current train perplexity4.1601152420043945
INFO:root:current mean train loss 1806.905971356496
INFO:root:current train perplexity4.159641265869141
INFO:root:current mean train loss 1808.0954080129784
INFO:root:current train perplexity4.160757541656494
INFO:root:current mean train loss 1808.8802819310445
INFO:root:current train perplexity4.163717269897461
INFO:root:current mean train loss 1809.707994969493
INFO:root:current train perplexity4.165339946746826

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.04s/it]
INFO:root:final mean train loss: 1809.068568365777
INFO:root:final train perplexity: 4.16510009765625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.63s/it]
INFO:root:eval mean loss: 2125.0673888727283
INFO:root:eval perplexity: 5.576881408691406
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it]
INFO:root:eval mean loss: 2649.56803298842
INFO:root:eval perplexity: 8.731082916259766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/35
 18%|â–ˆâ–Š        | 35/200 [5:12:51<24:24:22, 532.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1775.7604746717088
INFO:root:current train perplexity4.059091091156006
INFO:root:current mean train loss 1782.3730229643202
INFO:root:current train perplexity4.06791353225708
INFO:root:current mean train loss 1781.0113006384195
INFO:root:current train perplexity4.074887275695801
INFO:root:current mean train loss 1780.9314680535176
INFO:root:current train perplexity4.081112861633301
INFO:root:current mean train loss 1781.6619129258129
INFO:root:current train perplexity4.084194660186768
INFO:root:current mean train loss 1783.0796714294638
INFO:root:current train perplexity4.091024398803711
INFO:root:current mean train loss 1785.0029112186487
INFO:root:current train perplexity4.098928451538086
INFO:root:current mean train loss 1788.5331654584677
INFO:root:current train perplexity4.1029815673828125
INFO:root:current mean train loss 1788.091204956874
INFO:root:current train perplexity4.103188514709473
INFO:root:current mean train loss 1787.911109110719
INFO:root:current train perplexity4.105153560638428
INFO:root:current mean train loss 1786.9011354324368
INFO:root:current train perplexity4.1071248054504395
INFO:root:current mean train loss 1789.4972156927215
INFO:root:current train perplexity4.110405445098877
INFO:root:current mean train loss 1790.5481293809469
INFO:root:current train perplexity4.111374855041504
INFO:root:current mean train loss 1790.9555289269863
INFO:root:current train perplexity4.113208770751953
INFO:root:current mean train loss 1791.9071446103424
INFO:root:current train perplexity4.11488676071167
INFO:root:current mean train loss 1792.5937073443135
INFO:root:current train perplexity4.115566730499268
INFO:root:current mean train loss 1793.0511396063541
INFO:root:current train perplexity4.11582088470459
INFO:root:current mean train loss 1794.6136075193135
INFO:root:current train perplexity4.119992256164551
INFO:root:current mean train loss 1796.0854711321113
INFO:root:current train perplexity4.122622489929199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.80s/it]
INFO:root:final mean train loss: 1796.5116661175657
INFO:root:final train perplexity: 4.124055862426758
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.62s/it]
INFO:root:eval mean loss: 2124.48362439744
INFO:root:eval perplexity: 5.574249744415283
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it]
INFO:root:eval mean loss: 2651.74248877992
INFO:root:eval perplexity: 8.746623992919922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/36
 18%|â–ˆâ–Š        | 36/200 [5:21:43<24:15:18, 532.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1759.301424893466
INFO:root:current train perplexity4.018673896789551
INFO:root:current mean train loss 1766.2137759096988
INFO:root:current train perplexity4.033750534057617
INFO:root:current mean train loss 1765.9140659711936
INFO:root:current train perplexity4.033782958984375
INFO:root:current mean train loss 1772.3757748128517
INFO:root:current train perplexity4.047956466674805
INFO:root:current mean train loss 1771.7198492268287
INFO:root:current train perplexity4.058120250701904
INFO:root:current mean train loss 1773.6435193324976
INFO:root:current train perplexity4.0598883628845215
INFO:root:current mean train loss 1772.6251682212817
INFO:root:current train perplexity4.056149959564209
INFO:root:current mean train loss 1772.4170723658908
INFO:root:current train perplexity4.062111854553223
INFO:root:current mean train loss 1773.7765606034698
INFO:root:current train perplexity4.0609025955200195
INFO:root:current mean train loss 1774.3979866036207
INFO:root:current train perplexity4.0628485679626465
INFO:root:current mean train loss 1776.3331745574076
INFO:root:current train perplexity4.067118167877197
INFO:root:current mean train loss 1778.9442933062837
INFO:root:current train perplexity4.070700168609619
INFO:root:current mean train loss 1780.0792484299197
INFO:root:current train perplexity4.072465419769287
INFO:root:current mean train loss 1781.1620349782193
INFO:root:current train perplexity4.071500778198242
INFO:root:current mean train loss 1781.2019769680744
INFO:root:current train perplexity4.073915958404541
INFO:root:current mean train loss 1782.9453078950974
INFO:root:current train perplexity4.079914569854736
INFO:root:current mean train loss 1784.4596832294335
INFO:root:current train perplexity4.083602428436279
INFO:root:current mean train loss 1784.5895464577777
INFO:root:current train perplexity4.084720134735107
INFO:root:current mean train loss 1785.7343745281655
INFO:root:current train perplexity4.087939739227295
INFO:root:current mean train loss 1785.1109230125344
INFO:root:current train perplexity4.08711051940918

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 476.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 476.07s/it]
INFO:root:final mean train loss: 1785.001070408285
INFO:root:final train perplexity: 4.086787223815918
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it]
INFO:root:eval mean loss: 2129.1268219643453
INFO:root:eval perplexity: 5.595220565795898
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it]
INFO:root:eval mean loss: 2656.6458463195368
INFO:root:eval perplexity: 8.781769752502441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/37
 18%|â–ˆâ–Š        | 37/200 [5:30:33<24:04:53, 531.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1740.5542864118304
INFO:root:current train perplexity3.9732866287231445
INFO:root:current mean train loss 1750.8517007827759
INFO:root:current train perplexity3.9961795806884766
INFO:root:current mean train loss 1763.2136723033168
INFO:root:current train perplexity4.009278774261475
INFO:root:current mean train loss 1766.16235984244
INFO:root:current train perplexity4.024862766265869
INFO:root:current mean train loss 1765.7110299083674
INFO:root:current train perplexity4.025576114654541
INFO:root:current mean train loss 1768.2721777251272
INFO:root:current train perplexity4.032726764678955
INFO:root:current mean train loss 1767.234605728441
INFO:root:current train perplexity4.028840065002441
INFO:root:current mean train loss 1766.8540604140733
INFO:root:current train perplexity4.023308277130127
INFO:root:current mean train loss 1769.0177852612187
INFO:root:current train perplexity4.027041435241699
INFO:root:current mean train loss 1769.616825629925
INFO:root:current train perplexity4.031533241271973
INFO:root:current mean train loss 1771.9154337723432
INFO:root:current train perplexity4.034292221069336
INFO:root:current mean train loss 1771.0811118267952
INFO:root:current train perplexity4.035646915435791
INFO:root:current mean train loss 1771.866567804293
INFO:root:current train perplexity4.0394463539123535
INFO:root:current mean train loss 1773.0014731165875
INFO:root:current train perplexity4.042564392089844
INFO:root:current mean train loss 1772.8035391158417
INFO:root:current train perplexity4.040859222412109
INFO:root:current mean train loss 1772.6909784446837
INFO:root:current train perplexity4.043001174926758
INFO:root:current mean train loss 1772.9855484646134
INFO:root:current train perplexity4.043231010437012
INFO:root:current mean train loss 1773.224441740248
INFO:root:current train perplexity4.0441107749938965
INFO:root:current mean train loss 1772.7482269754555
INFO:root:current train perplexity4.045371055603027
INFO:root:current mean train loss 1772.921130231802
INFO:root:current train perplexity4.047359943389893

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.31s/it]
INFO:root:final mean train loss: 1773.0505646567601
INFO:root:final train perplexity: 4.0484514236450195
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it]
INFO:root:eval mean loss: 2130.82087610123
INFO:root:eval perplexity: 5.602891445159912
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it]
INFO:root:eval mean loss: 2658.956449468085
INFO:root:eval perplexity: 8.798380851745605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/38
 19%|â–ˆâ–‰        | 38/200 [5:39:25<23:55:54, 531.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1753.1982123480902
INFO:root:current train perplexity3.953125238418579
INFO:root:current mean train loss 1754.9096629175647
INFO:root:current train perplexity3.949801445007324
INFO:root:current mean train loss 1748.4116948341837
INFO:root:current train perplexity3.959326982498169
INFO:root:current mean train loss 1751.9691455785778
INFO:root:current train perplexity3.964332342147827
INFO:root:current mean train loss 1751.7167195180828
INFO:root:current train perplexity3.971284866333008
INFO:root:current mean train loss 1752.1803928200259
INFO:root:current train perplexity3.978522539138794
INFO:root:current mean train loss 1753.336922389777
INFO:root:current train perplexity3.9774835109710693
INFO:root:current mean train loss 1755.4791839804425
INFO:root:current train perplexity3.9850120544433594
INFO:root:current mean train loss 1754.8705624191014
INFO:root:current train perplexity3.987144708633423
INFO:root:current mean train loss 1755.0150176194609
INFO:root:current train perplexity3.985814094543457
INFO:root:current mean train loss 1756.1628442499625
INFO:root:current train perplexity3.9873318672180176
INFO:root:current mean train loss 1757.8691278316048
INFO:root:current train perplexity3.9929704666137695
INFO:root:current mean train loss 1757.604154802805
INFO:root:current train perplexity3.9932475090026855
INFO:root:current mean train loss 1758.481291658196
INFO:root:current train perplexity3.9957873821258545
INFO:root:current mean train loss 1758.23098896383
INFO:root:current train perplexity3.9989659786224365
INFO:root:current mean train loss 1759.1959568258242
INFO:root:current train perplexity4.001185417175293
INFO:root:current mean train loss 1759.3050385727347
INFO:root:current train perplexity4.003386497497559
INFO:root:current mean train loss 1760.4342518803726
INFO:root:current train perplexity4.005366325378418
INFO:root:current mean train loss 1761.5358666396723
INFO:root:current train perplexity4.008237361907959
INFO:root:current mean train loss 1761.7328731272091
INFO:root:current train perplexity4.010919094085693

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.06s/it]
INFO:root:final mean train loss: 1761.3890408560655
INFO:root:final train perplexity: 4.011388301849365
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it]
INFO:root:eval mean loss: 2134.5577323318375
INFO:root:eval perplexity: 5.619849681854248
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it]
INFO:root:eval mean loss: 2665.9777866661125
INFO:root:eval perplexity: 8.84904956817627
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/39
 20%|â–ˆâ–‰        | 39/200 [5:48:17<23:46:52, 531.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1730.2833429151965
INFO:root:current train perplexity3.9171946048736572
INFO:root:current mean train loss 1736.2777431158372
INFO:root:current train perplexity3.93127703666687
INFO:root:current mean train loss 1738.1449333365638
INFO:root:current train perplexity3.941873788833618
INFO:root:current mean train loss 1739.1133011454376
INFO:root:current train perplexity3.9454028606414795
INFO:root:current mean train loss 1741.33344166413
INFO:root:current train perplexity3.9452359676361084
INFO:root:current mean train loss 1740.0953918674238
INFO:root:current train perplexity3.9453907012939453
INFO:root:current mean train loss 1739.5624972340563
INFO:root:current train perplexity3.9450323581695557
INFO:root:current mean train loss 1740.3727376942873
INFO:root:current train perplexity3.948514938354492
INFO:root:current mean train loss 1741.5206243599098
INFO:root:current train perplexity3.9484314918518066
INFO:root:current mean train loss 1741.8691614353236
INFO:root:current train perplexity3.9529452323913574
INFO:root:current mean train loss 1743.306149470155
INFO:root:current train perplexity3.9527289867401123
INFO:root:current mean train loss 1744.3277871530765
INFO:root:current train perplexity3.955831527709961
INFO:root:current mean train loss 1745.875612769754
INFO:root:current train perplexity3.9613113403320312
INFO:root:current mean train loss 1747.5965279510542
INFO:root:current train perplexity3.9646613597869873
INFO:root:current mean train loss 1747.2876289670346
INFO:root:current train perplexity3.965272903442383
INFO:root:current mean train loss 1747.9269505304198
INFO:root:current train perplexity3.9691247940063477
INFO:root:current mean train loss 1748.176467840422
INFO:root:current train perplexity3.969944953918457
INFO:root:current mean train loss 1748.9147886867286
INFO:root:current train perplexity3.9718456268310547
INFO:root:current mean train loss 1749.3797055417563
INFO:root:current train perplexity3.973660707473755
INFO:root:current mean train loss 1750.2933217086559
INFO:root:current train perplexity3.9757537841796875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.12s/it]
INFO:root:final mean train loss: 1750.0587305019915
INFO:root:final train perplexity: 3.975703001022339
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it]
INFO:root:eval mean loss: 2137.8258580417496
INFO:root:eval perplexity: 5.63472318649292
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it]
INFO:root:eval mean loss: 2668.9701460168717
INFO:root:eval perplexity: 8.87073040008545
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/40
 20%|â–ˆâ–ˆ        | 40/200 [5:57:08<23:37:53, 531.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1712.9307289606409
INFO:root:current train perplexity3.8614919185638428
INFO:root:current mean train loss 1720.5316564464035
INFO:root:current train perplexity3.868645429611206
INFO:root:current mean train loss 1722.8318404877912
INFO:root:current train perplexity3.8828749656677246
INFO:root:current mean train loss 1727.9083854252556
INFO:root:current train perplexity3.8948559761047363
INFO:root:current mean train loss 1730.579004721751
INFO:root:current train perplexity3.9008960723876953
INFO:root:current mean train loss 1733.075738620264
INFO:root:current train perplexity3.907961130142212
INFO:root:current mean train loss 1736.7925363801892
INFO:root:current train perplexity3.9168925285339355
INFO:root:current mean train loss 1735.0583391103878
INFO:root:current train perplexity3.919342279434204
INFO:root:current mean train loss 1736.3745708791062
INFO:root:current train perplexity3.9228274822235107
INFO:root:current mean train loss 1738.150760950667
INFO:root:current train perplexity3.9273016452789307
INFO:root:current mean train loss 1737.3777191473225
INFO:root:current train perplexity3.9265236854553223
INFO:root:current mean train loss 1737.7157123232414
INFO:root:current train perplexity3.930952310562134
INFO:root:current mean train loss 1738.493961480374
INFO:root:current train perplexity3.9316225051879883
INFO:root:current mean train loss 1737.5271109400494
INFO:root:current train perplexity3.930166006088257
INFO:root:current mean train loss 1737.4365089112152
INFO:root:current train perplexity3.9320409297943115
INFO:root:current mean train loss 1738.4056089569149
INFO:root:current train perplexity3.9357428550720215
INFO:root:current mean train loss 1739.8642040841135
INFO:root:current train perplexity3.9390952587127686
INFO:root:current mean train loss 1740.5130532893522
INFO:root:current train perplexity3.9418785572052
INFO:root:current mean train loss 1740.7465683884795
INFO:root:current train perplexity3.9421331882476807
INFO:root:current mean train loss 1740.2270103173162
INFO:root:current train perplexity3.9436404705047607

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:03<00:00, 483.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:03<00:00, 483.94s/it]
INFO:root:final mean train loss: 1739.771683116303
INFO:root:final train perplexity: 3.9435784816741943
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 2140.146780460439
INFO:root:eval perplexity: 5.645309925079346
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 2674.487799894725
INFO:root:eval perplexity: 8.910850524902344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/41
 20%|â–ˆâ–ˆ        | 41/200 [6:06:08<23:35:17, 534.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1721.6735967000325
INFO:root:current train perplexity3.831573486328125
INFO:root:current mean train loss 1718.6370600486289
INFO:root:current train perplexity3.8487186431884766
INFO:root:current mean train loss 1720.1209997228675
INFO:root:current train perplexity3.858287811279297
INFO:root:current mean train loss 1722.7468924474235
INFO:root:current train perplexity3.8706424236297607
INFO:root:current mean train loss 1723.9436136061145
INFO:root:current train perplexity3.8782882690429688
INFO:root:current mean train loss 1722.2221024276425
INFO:root:current train perplexity3.8742358684539795
INFO:root:current mean train loss 1723.8180278909617
INFO:root:current train perplexity3.880054235458374
INFO:root:current mean train loss 1724.384429318222
INFO:root:current train perplexity3.8837790489196777
INFO:root:current mean train loss 1723.9541948863439
INFO:root:current train perplexity3.885446548461914
INFO:root:current mean train loss 1725.5161674530152
INFO:root:current train perplexity3.888195753097534
INFO:root:current mean train loss 1726.7636745480725
INFO:root:current train perplexity3.89035701751709
INFO:root:current mean train loss 1725.6824256105965
INFO:root:current train perplexity3.8900089263916016
INFO:root:current mean train loss 1726.1851022037458
INFO:root:current train perplexity3.8950564861297607
INFO:root:current mean train loss 1725.744396395533
INFO:root:current train perplexity3.8958938121795654
INFO:root:current mean train loss 1726.1936479864273
INFO:root:current train perplexity3.8976752758026123
INFO:root:current mean train loss 1726.3126630663573
INFO:root:current train perplexity3.898409843444824
INFO:root:current mean train loss 1726.0256067671867
INFO:root:current train perplexity3.9001107215881348
INFO:root:current mean train loss 1727.447122892452
INFO:root:current train perplexity3.9034764766693115
INFO:root:current mean train loss 1727.979625846766
INFO:root:current train perplexity3.9064157009124756

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.18s/it]
INFO:root:final mean train loss: 1727.8608093415614
INFO:root:final train perplexity: 3.906707525253296
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 2142.0225358246066
INFO:root:eval perplexity: 5.653879165649414
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 2677.308542670933
INFO:root:eval perplexity: 8.931428909301758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/42
 21%|â–ˆâ–ˆ        | 42/200 [6:15:09<23:31:47, 536.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1682.062772310697
INFO:root:current train perplexity3.827697515487671
INFO:root:current mean train loss 1698.3472295440404
INFO:root:current train perplexity3.85932993888855
INFO:root:current mean train loss 1701.1186884490537
INFO:root:current train perplexity3.8493309020996094
INFO:root:current mean train loss 1698.7190803308456
INFO:root:current train perplexity3.8473856449127197
INFO:root:current mean train loss 1699.0693702235926
INFO:root:current train perplexity3.846895456314087
INFO:root:current mean train loss 1702.9857327645286
INFO:root:current train perplexity3.8526811599731445
INFO:root:current mean train loss 1706.0962780303705
INFO:root:current train perplexity3.851421594619751
INFO:root:current mean train loss 1702.920708226957
INFO:root:current train perplexity3.8492624759674072
INFO:root:current mean train loss 1704.0495904263241
INFO:root:current train perplexity3.8479788303375244
INFO:root:current mean train loss 1706.4296923132872
INFO:root:current train perplexity3.854081153869629
INFO:root:current mean train loss 1707.9123349580454
INFO:root:current train perplexity3.8553338050842285
INFO:root:current mean train loss 1710.5197215393011
INFO:root:current train perplexity3.8601138591766357
INFO:root:current mean train loss 1710.8474237830405
INFO:root:current train perplexity3.860440492630005
INFO:root:current mean train loss 1711.950394455386
INFO:root:current train perplexity3.862931489944458
INFO:root:current mean train loss 1713.3562437625785
INFO:root:current train perplexity3.865253210067749
INFO:root:current mean train loss 1714.855827296245
INFO:root:current train perplexity3.865823268890381
INFO:root:current mean train loss 1715.1626649349282
INFO:root:current train perplexity3.867582082748413
INFO:root:current mean train loss 1715.7630144198317
INFO:root:current train perplexity3.8701343536376953
INFO:root:current mean train loss 1716.8898244395943
INFO:root:current train perplexity3.8723158836364746
INFO:root:current mean train loss 1718.1028035588122
INFO:root:current train perplexity3.873091459274292

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.92s/it]
INFO:root:final mean train loss: 1716.6209739573485
INFO:root:final train perplexity: 3.872230052947998
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2148.5892927021
INFO:root:eval perplexity: 5.683986663818359
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it]
INFO:root:eval mean loss: 2686.9533184944316
INFO:root:eval perplexity: 9.002157211303711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/43
 22%|â–ˆâ–ˆâ–       | 43/200 [6:24:10<23:27:08, 537.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1720.2941813151042
INFO:root:current train perplexity3.8084566593170166
INFO:root:current mean train loss 1705.7251145582932
INFO:root:current train perplexity3.8061954975128174
INFO:root:current mean train loss 1698.9388533882473
INFO:root:current train perplexity3.797642230987549
INFO:root:current mean train loss 1696.5755012281013
INFO:root:current train perplexity3.812532901763916
INFO:root:current mean train loss 1697.631506063772
INFO:root:current train perplexity3.819629192352295
INFO:root:current mean train loss 1696.7328106574294
INFO:root:current train perplexity3.8168399333953857
INFO:root:current mean train loss 1697.4199402824281
INFO:root:current train perplexity3.811455011367798
INFO:root:current mean train loss 1699.5404731645976
INFO:root:current train perplexity3.8137357234954834
INFO:root:current mean train loss 1701.320879906344
INFO:root:current train perplexity3.8166916370391846
INFO:root:current mean train loss 1701.6848080214634
INFO:root:current train perplexity3.821272373199463
INFO:root:current mean train loss 1700.7639662659285
INFO:root:current train perplexity3.8221375942230225
INFO:root:current mean train loss 1701.8407545241635
INFO:root:current train perplexity3.827071189880371
INFO:root:current mean train loss 1702.4202741917557
INFO:root:current train perplexity3.82673716545105
INFO:root:current mean train loss 1703.7708091334293
INFO:root:current train perplexity3.829035758972168
INFO:root:current mean train loss 1704.3961563217056
INFO:root:current train perplexity3.8319854736328125
INFO:root:current mean train loss 1704.3083149031097
INFO:root:current train perplexity3.832981824874878
INFO:root:current mean train loss 1704.6751242421155
INFO:root:current train perplexity3.8368523120880127
INFO:root:current mean train loss 1704.9810903913024
INFO:root:current train perplexity3.838258981704712
INFO:root:current mean train loss 1705.1618365511868
INFO:root:current train perplexity3.838616371154785
INFO:root:current mean train loss 1706.168733492046
INFO:root:current train perplexity3.8387160301208496

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.80s/it]
INFO:root:final mean train loss: 1705.977560146253
INFO:root:final train perplexity: 3.839862585067749
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 2149.9281317528257
INFO:root:eval perplexity: 5.6901445388793945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.56s/it]
INFO:root:eval mean loss: 2689.021335899407
INFO:root:eval perplexity: 9.017393112182617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/44
 22%|â–ˆâ–ˆâ–       | 44/200 [6:33:12<23:21:07, 538.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1662.352674119016
INFO:root:current train perplexity3.753962993621826
INFO:root:current mean train loss 1678.6225295293898
INFO:root:current train perplexity3.7504029273986816
INFO:root:current mean train loss 1680.8795037520558
INFO:root:current train perplexity3.756474256515503
INFO:root:current mean train loss 1684.5955391919579
INFO:root:current train perplexity3.766693353652954
INFO:root:current mean train loss 1684.7347368415303
INFO:root:current train perplexity3.7647006511688232
INFO:root:current mean train loss 1685.5413003813414
INFO:root:current train perplexity3.774705171585083
INFO:root:current mean train loss 1686.1560326506956
INFO:root:current train perplexity3.77943754196167
INFO:root:current mean train loss 1685.6700473770081
INFO:root:current train perplexity3.7810354232788086
INFO:root:current mean train loss 1686.3061151605853
INFO:root:current train perplexity3.7854366302490234
INFO:root:current mean train loss 1688.1665407722578
INFO:root:current train perplexity3.7894396781921387
INFO:root:current mean train loss 1688.5232492062514
INFO:root:current train perplexity3.790626049041748
INFO:root:current mean train loss 1689.4071088556425
INFO:root:current train perplexity3.792577028274536
INFO:root:current mean train loss 1690.2677614751967
INFO:root:current train perplexity3.792865037918091
INFO:root:current mean train loss 1691.4872939938869
INFO:root:current train perplexity3.794065237045288
INFO:root:current mean train loss 1691.9863174955187
INFO:root:current train perplexity3.7956366539001465
INFO:root:current mean train loss 1692.640546092235
INFO:root:current train perplexity3.7983529567718506
INFO:root:current mean train loss 1693.8157208181542
INFO:root:current train perplexity3.800600051879883
INFO:root:current mean train loss 1694.6519725081166
INFO:root:current train perplexity3.8018746376037598
INFO:root:current mean train loss 1695.1842927297646
INFO:root:current train perplexity3.8036091327667236
INFO:root:current mean train loss 1695.4447572587635
INFO:root:current train perplexity3.8070003986358643

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.62s/it]
INFO:root:final mean train loss: 1695.480529446585
INFO:root:final train perplexity: 3.8082046508789062
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2154.0390070921985
INFO:root:eval perplexity: 5.709094524383545
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it]
INFO:root:eval mean loss: 2692.5410970052085
INFO:root:eval perplexity: 9.043386459350586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [6:42:13<23:14:00, 539.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1665.105136871338
INFO:root:current train perplexity3.703648090362549
INFO:root:current mean train loss 1661.6979734839463
INFO:root:current train perplexity3.723129987716675
INFO:root:current mean train loss 1670.8102597323332
INFO:root:current train perplexity3.744842767715454
INFO:root:current mean train loss 1670.3851227812715
INFO:root:current train perplexity3.7391622066497803
INFO:root:current mean train loss 1668.349554916908
INFO:root:current train perplexity3.7426393032073975
INFO:root:current mean train loss 1671.5491322185976
INFO:root:current train perplexity3.7469983100891113
INFO:root:current mean train loss 1674.3886496302594
INFO:root:current train perplexity3.7470409870147705
INFO:root:current mean train loss 1674.9113715206765
INFO:root:current train perplexity3.7497775554656982
INFO:root:current mean train loss 1675.9333272863316
INFO:root:current train perplexity3.750807046890259
INFO:root:current mean train loss 1676.8962523907546
INFO:root:current train perplexity3.7558090686798096
INFO:root:current mean train loss 1677.417885342935
INFO:root:current train perplexity3.7574310302734375
INFO:root:current mean train loss 1678.081565620973
INFO:root:current train perplexity3.755949020385742
INFO:root:current mean train loss 1679.1470719349536
INFO:root:current train perplexity3.7565624713897705
INFO:root:current mean train loss 1680.5361609137303
INFO:root:current train perplexity3.7599313259124756
INFO:root:current mean train loss 1681.2990133983842
INFO:root:current train perplexity3.7623164653778076
INFO:root:current mean train loss 1682.9318503455434
INFO:root:current train perplexity3.765249013900757
INFO:root:current mean train loss 1682.231976362375
INFO:root:current train perplexity3.768324851989746
INFO:root:current mean train loss 1683.4091043277663
INFO:root:current train perplexity3.7713422775268555
INFO:root:current mean train loss 1683.9345827552893
INFO:root:current train perplexity3.773876428604126
INFO:root:current mean train loss 1684.1912291113083
INFO:root:current train perplexity3.774736166000366

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.39s/it]
INFO:root:final mean train loss: 1684.1618647111286
INFO:root:final train perplexity: 3.7743618488311768
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 2159.8670619667
INFO:root:eval perplexity: 5.736065864562988
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 2704.594330050421
INFO:root:eval perplexity: 9.132974624633789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [6:51:14<23:06:07, 540.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1655.5395251615548
INFO:root:current train perplexity3.6857995986938477
INFO:root:current mean train loss 1658.1424385197254
INFO:root:current train perplexity3.6949033737182617
INFO:root:current mean train loss 1662.1538602890068
INFO:root:current train perplexity3.695906400680542
INFO:root:current mean train loss 1663.9443090243603
INFO:root:current train perplexity3.706113815307617
INFO:root:current mean train loss 1664.097782634648
INFO:root:current train perplexity3.7113640308380127
INFO:root:current mean train loss 1667.0498490194036
INFO:root:current train perplexity3.7160415649414062
INFO:root:current mean train loss 1666.8773899610521
INFO:root:current train perplexity3.714916229248047
INFO:root:current mean train loss 1669.413710824964
INFO:root:current train perplexity3.7201743125915527
INFO:root:current mean train loss 1670.6410223866699
INFO:root:current train perplexity3.724015951156616
INFO:root:current mean train loss 1670.6573368115285
INFO:root:current train perplexity3.7265326976776123
INFO:root:current mean train loss 1670.3186478945638
INFO:root:current train perplexity3.7287757396698
INFO:root:current mean train loss 1670.6942550051929
INFO:root:current train perplexity3.7297067642211914
INFO:root:current mean train loss 1669.709289217256
INFO:root:current train perplexity3.7315452098846436
INFO:root:current mean train loss 1670.6180159163423
INFO:root:current train perplexity3.7339680194854736
INFO:root:current mean train loss 1671.361149594077
INFO:root:current train perplexity3.7364277839660645
INFO:root:current mean train loss 1671.908068932588
INFO:root:current train perplexity3.738386392593384
INFO:root:current mean train loss 1672.4707387802787
INFO:root:current train perplexity3.73995041847229
INFO:root:current mean train loss 1673.366322452603
INFO:root:current train perplexity3.742696523666382
INFO:root:current mean train loss 1674.4384431408037
INFO:root:current train perplexity3.744983434677124
INFO:root:current mean train loss 1675.1364236491788
INFO:root:current train perplexity3.746039390563965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.31s/it]
INFO:root:final mean train loss: 1674.6003063084559
INFO:root:final train perplexity: 3.746007204055786
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 2161.8362487360096
INFO:root:eval perplexity: 5.745208740234375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it]
INFO:root:eval mean loss: 2704.37155692459
INFO:root:eval perplexity: 9.13131332397461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [7:00:16<22:58:37, 540.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1635.039145956234
INFO:root:current train perplexity3.645758628845215
INFO:root:current mean train loss 1638.5525506530146
INFO:root:current train perplexity3.6509339809417725
INFO:root:current mean train loss 1641.229455320627
INFO:root:current train perplexity3.66143536567688
INFO:root:current mean train loss 1642.032666076967
INFO:root:current train perplexity3.6636013984680176
INFO:root:current mean train loss 1645.46892011405
INFO:root:current train perplexity3.673382520675659
INFO:root:current mean train loss 1650.3894741096624
INFO:root:current train perplexity3.677931070327759
INFO:root:current mean train loss 1653.6766163298598
INFO:root:current train perplexity3.6833221912384033
INFO:root:current mean train loss 1654.7809197370868
INFO:root:current train perplexity3.68345308303833
INFO:root:current mean train loss 1654.9669840585416
INFO:root:current train perplexity3.684688091278076
INFO:root:current mean train loss 1656.1859171223307
INFO:root:current train perplexity3.6906394958496094
INFO:root:current mean train loss 1657.0062782829577
INFO:root:current train perplexity3.692439317703247
INFO:root:current mean train loss 1657.6201502015076
INFO:root:current train perplexity3.6954164505004883
INFO:root:current mean train loss 1658.8336176938378
INFO:root:current train perplexity3.69682240486145
INFO:root:current mean train loss 1659.2733677330618
INFO:root:current train perplexity3.698805332183838
INFO:root:current mean train loss 1660.8541339624708
INFO:root:current train perplexity3.703221082687378
INFO:root:current mean train loss 1661.2682730396639
INFO:root:current train perplexity3.70564341545105
INFO:root:current mean train loss 1661.3845288891114
INFO:root:current train perplexity3.7062764167785645
INFO:root:current mean train loss 1662.2041659243778
INFO:root:current train perplexity3.7092485427856445
INFO:root:current mean train loss 1663.32253870748
INFO:root:current train perplexity3.7116804122924805

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.34s/it]
INFO:root:final mean train loss: 1663.6887450802524
INFO:root:final train perplexity: 3.713909387588501
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 2166.3176745692044
INFO:root:eval perplexity: 5.766068458557129
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it]
INFO:root:eval mean loss: 2711.283200527759
INFO:root:eval perplexity: 9.183073043823242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/48
 24%|â–ˆâ–ˆâ–       | 48/200 [7:09:17<22:49:56, 540.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1607.8696858723958
INFO:root:current train perplexity3.5698318481445312
INFO:root:current mean train loss 1626.081194802989
INFO:root:current train perplexity3.6233692169189453
INFO:root:current mean train loss 1630.9741500499636
INFO:root:current train perplexity3.6444191932678223
INFO:root:current mean train loss 1636.0097706628223
INFO:root:current train perplexity3.6360249519348145
INFO:root:current mean train loss 1639.2911465196723
INFO:root:current train perplexity3.64363169670105
INFO:root:current mean train loss 1641.8793267407464
INFO:root:current train perplexity3.6504757404327393
INFO:root:current mean train loss 1643.5552809800558
INFO:root:current train perplexity3.6541078090667725
INFO:root:current mean train loss 1645.3734859866695
INFO:root:current train perplexity3.65862774848938
INFO:root:current mean train loss 1647.4060404584452
INFO:root:current train perplexity3.6576762199401855
INFO:root:current mean train loss 1647.2381360997267
INFO:root:current train perplexity3.6601881980895996
INFO:root:current mean train loss 1649.4998110616148
INFO:root:current train perplexity3.6640748977661133
INFO:root:current mean train loss 1650.6276597095712
INFO:root:current train perplexity3.666635751724243
INFO:root:current mean train loss 1650.0997787663966
INFO:root:current train perplexity3.669796943664551
INFO:root:current mean train loss 1650.3526079417181
INFO:root:current train perplexity3.671684741973877
INFO:root:current mean train loss 1649.9900940157079
INFO:root:current train perplexity3.6727209091186523
INFO:root:current mean train loss 1650.5619607151145
INFO:root:current train perplexity3.6766419410705566
INFO:root:current mean train loss 1652.0786345963138
INFO:root:current train perplexity3.678922176361084
INFO:root:current mean train loss 1653.7425471625593
INFO:root:current train perplexity3.681013345718384
INFO:root:current mean train loss 1653.8288034150094
INFO:root:current train perplexity3.6836371421813965
INFO:root:current mean train loss 1653.7609270459368
INFO:root:current train perplexity3.6839146614074707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.57s/it]
INFO:root:final mean train loss: 1654.0404922862397
INFO:root:final train perplexity: 3.6857564449310303
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 2168.4948916604335
INFO:root:eval perplexity: 5.77623176574707
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 2716.0153592157026
INFO:root:eval perplexity: 9.21867847442627
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/49
 24%|â–ˆâ–ˆâ–       | 49/200 [7:18:20<22:42:03, 541.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1658.6170692443848
INFO:root:current train perplexity3.6338107585906982
INFO:root:current mean train loss 1632.6312561035156
INFO:root:current train perplexity3.634272575378418
INFO:root:current mean train loss 1631.6194668473868
INFO:root:current train perplexity3.6369540691375732
INFO:root:current mean train loss 1632.5939628876836
INFO:root:current train perplexity3.6269261837005615
INFO:root:current mean train loss 1633.0056087352611
INFO:root:current train perplexity3.6279189586639404
INFO:root:current mean train loss 1635.0818846279517
INFO:root:current train perplexity3.633452892303467
INFO:root:current mean train loss 1636.5389921936808
INFO:root:current train perplexity3.6364047527313232
INFO:root:current mean train loss 1638.767266111947
INFO:root:current train perplexity3.6412179470062256
INFO:root:current mean train loss 1638.2519060281606
INFO:root:current train perplexity3.6423676013946533
INFO:root:current mean train loss 1639.5891686959328
INFO:root:current train perplexity3.646981716156006
INFO:root:current mean train loss 1639.7886250813801
INFO:root:current train perplexity3.6460366249084473
INFO:root:current mean train loss 1639.9609658608588
INFO:root:current train perplexity3.647819995880127
INFO:root:current mean train loss 1639.7531432114638
INFO:root:current train perplexity3.647981882095337
INFO:root:current mean train loss 1639.0745622331315
INFO:root:current train perplexity3.648937225341797
INFO:root:current mean train loss 1639.933728180784
INFO:root:current train perplexity3.6484763622283936
INFO:root:current mean train loss 1640.9034761672854
INFO:root:current train perplexity3.648355007171631
INFO:root:current mean train loss 1642.1081268460143
INFO:root:current train perplexity3.6516165733337402
INFO:root:current mean train loss 1642.709209768106
INFO:root:current train perplexity3.6542344093322754
INFO:root:current mean train loss 1643.3415816527788
INFO:root:current train perplexity3.6541991233825684
INFO:root:current mean train loss 1643.6726839369621
INFO:root:current train perplexity3.6548688411712646

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.72s/it]
INFO:root:final mean train loss: 1643.74965893567
INFO:root:final train perplexity: 3.6559643745422363
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 2174.507401270224
INFO:root:eval perplexity: 5.804387092590332
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 2723.7722228571033
INFO:root:eval perplexity: 9.277348518371582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [7:27:21<22:33:09, 541.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1620.772159498565
INFO:root:current train perplexity3.5748603343963623
INFO:root:current mean train loss 1621.5108413184248
INFO:root:current train perplexity3.569370985031128
INFO:root:current mean train loss 1620.134308719252
INFO:root:current train perplexity3.5795483589172363
INFO:root:current mean train loss 1628.8839314195693
INFO:root:current train perplexity3.5962915420532227
INFO:root:current mean train loss 1626.1340832274848
INFO:root:current train perplexity3.5984673500061035
INFO:root:current mean train loss 1625.3704496011926
INFO:root:current train perplexity3.599287271499634
INFO:root:current mean train loss 1627.4550301620884
INFO:root:current train perplexity3.603846788406372
INFO:root:current mean train loss 1627.7142837585532
INFO:root:current train perplexity3.6077382564544678
INFO:root:current mean train loss 1626.6484062994607
INFO:root:current train perplexity3.6071860790252686
INFO:root:current mean train loss 1626.8289761477954
INFO:root:current train perplexity3.6102676391601562
INFO:root:current mean train loss 1627.13068877912
INFO:root:current train perplexity3.6113076210021973
INFO:root:current mean train loss 1627.8216623915498
INFO:root:current train perplexity3.6116225719451904
INFO:root:current mean train loss 1628.5053086414443
INFO:root:current train perplexity3.6124184131622314
INFO:root:current mean train loss 1629.3923463814342
INFO:root:current train perplexity3.6166489124298096
INFO:root:current mean train loss 1629.9277224965224
INFO:root:current train perplexity3.6185638904571533
INFO:root:current mean train loss 1630.0165553034467
INFO:root:current train perplexity3.6192357540130615
INFO:root:current mean train loss 1631.7332247704576
INFO:root:current train perplexity3.6220178604125977
INFO:root:current mean train loss 1632.6315235380039
INFO:root:current train perplexity3.6243040561676025
INFO:root:current mean train loss 1633.0801520669957
INFO:root:current train perplexity3.6254146099090576
INFO:root:current mean train loss 1633.4959197575279
INFO:root:current train perplexity3.626215934753418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.00s/it]
INFO:root:final mean train loss: 1633.2574392406254
INFO:root:final train perplexity: 3.6258368492126465
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 2178.454182509835
INFO:root:eval perplexity: 5.822944164276123
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it]
INFO:root:eval mean loss: 2727.578793789478
INFO:root:eval perplexity: 9.306276321411133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [7:36:23<22:24:25, 541.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1613.1838915275805
INFO:root:current train perplexity3.5574450492858887
INFO:root:current mean train loss 1600.876012595303
INFO:root:current train perplexity3.559542417526245
INFO:root:current mean train loss 1604.3813903349683
INFO:root:current train perplexity3.556859016418457
INFO:root:current mean train loss 1606.115838389579
INFO:root:current train perplexity3.5606560707092285
INFO:root:current mean train loss 1606.5132983293656
INFO:root:current train perplexity3.5565292835235596
INFO:root:current mean train loss 1607.8918692113655
INFO:root:current train perplexity3.5597927570343018
INFO:root:current mean train loss 1610.4552249392948
INFO:root:current train perplexity3.5630807876586914
INFO:root:current mean train loss 1611.4541578168346
INFO:root:current train perplexity3.566119909286499
INFO:root:current mean train loss 1611.4247616950688
INFO:root:current train perplexity3.5684216022491455
INFO:root:current mean train loss 1613.2468729275847
INFO:root:current train perplexity3.572848320007324
INFO:root:current mean train loss 1615.448969456313
INFO:root:current train perplexity3.576362133026123
INFO:root:current mean train loss 1615.972438701021
INFO:root:current train perplexity3.580906391143799
INFO:root:current mean train loss 1616.3220815553107
INFO:root:current train perplexity3.583333969116211
INFO:root:current mean train loss 1618.7866832012662
INFO:root:current train perplexity3.5890414714813232
INFO:root:current mean train loss 1618.9580219679933
INFO:root:current train perplexity3.591123580932617
INFO:root:current mean train loss 1620.4758927502394
INFO:root:current train perplexity3.5920886993408203
INFO:root:current mean train loss 1621.558752822418
INFO:root:current train perplexity3.593707323074341
INFO:root:current mean train loss 1622.6934099035382
INFO:root:current train perplexity3.5949785709381104
INFO:root:current mean train loss 1623.3349292751038
INFO:root:current train perplexity3.596647024154663
INFO:root:current mean train loss 1623.7251630998458
INFO:root:current train perplexity3.5969045162200928

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.51s/it]
INFO:root:final mean train loss: 1623.262034913956
INFO:root:final train perplexity: 3.5973663330078125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 2183.5621831366357
INFO:root:eval perplexity: 5.847047805786133
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 2734.8927300635805
INFO:root:eval perplexity: 9.36210823059082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [7:45:24<22:15:13, 541.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1594.7417742258094
INFO:root:current train perplexity3.499722719192505
INFO:root:current mean train loss 1601.7030703018272
INFO:root:current train perplexity3.5161216259002686
INFO:root:current mean train loss 1602.8102768537433
INFO:root:current train perplexity3.5242533683776855
INFO:root:current mean train loss 1602.2271769949411
INFO:root:current train perplexity3.530412197113037
INFO:root:current mean train loss 1604.162286035763
INFO:root:current train perplexity3.533047914505005
INFO:root:current mean train loss 1603.8925192883657
INFO:root:current train perplexity3.5375213623046875
INFO:root:current mean train loss 1603.7921696630788
INFO:root:current train perplexity3.540005683898926
INFO:root:current mean train loss 1606.4358460486012
INFO:root:current train perplexity3.54514217376709
INFO:root:current mean train loss 1605.9970401750957
INFO:root:current train perplexity3.547213077545166
INFO:root:current mean train loss 1607.751276460572
INFO:root:current train perplexity3.54948091506958
INFO:root:current mean train loss 1608.095493362441
INFO:root:current train perplexity3.551766872406006
INFO:root:current mean train loss 1609.6515075219252
INFO:root:current train perplexity3.554455280303955
INFO:root:current mean train loss 1610.5004648757185
INFO:root:current train perplexity3.5563206672668457
INFO:root:current mean train loss 1610.4295159130966
INFO:root:current train perplexity3.55906081199646
INFO:root:current mean train loss 1610.8013438599703
INFO:root:current train perplexity3.562147855758667
INFO:root:current mean train loss 1610.8162541826239
INFO:root:current train perplexity3.563920259475708
INFO:root:current mean train loss 1611.9693496169182
INFO:root:current train perplexity3.565256357192993
INFO:root:current mean train loss 1612.693893458291
INFO:root:current train perplexity3.5677719116210938
INFO:root:current mean train loss 1613.7672584602572
INFO:root:current train perplexity3.569145917892456
INFO:root:current mean train loss 1613.718428819034
INFO:root:current train perplexity3.570391893386841

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.64s/it]
INFO:root:final mean train loss: 1613.718428819034
INFO:root:final train perplexity: 3.570391893386841
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it]
INFO:root:eval mean loss: 2188.0296734749004
INFO:root:eval perplexity: 5.86821174621582
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it]
INFO:root:eval mean loss: 2742.3451832439882
INFO:root:eval perplexity: 9.419343948364258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [7:54:25<22:06:08, 541.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1588.2225341796875
INFO:root:current train perplexity3.488654613494873
INFO:root:current mean train loss 1591.415629272461
INFO:root:current train perplexity3.499929666519165
INFO:root:current mean train loss 1589.4505635579428
INFO:root:current train perplexity3.5057811737060547
INFO:root:current mean train loss 1595.0694738769532
INFO:root:current train perplexity3.5067880153656006
INFO:root:current mean train loss 1597.7994829101563
INFO:root:current train perplexity3.5143444538116455
INFO:root:current mean train loss 1594.6404227701823
INFO:root:current train perplexity3.512192964553833
INFO:root:current mean train loss 1593.982684326172
INFO:root:current train perplexity3.514216184616089
INFO:root:current mean train loss 1596.230870361328
INFO:root:current train perplexity3.5186097621917725
INFO:root:current mean train loss 1597.8526135253906
INFO:root:current train perplexity3.5199501514434814
INFO:root:current mean train loss 1598.299314819336
INFO:root:current train perplexity3.523642063140869
INFO:root:current mean train loss 1597.5939386541193
INFO:root:current train perplexity3.5279524326324463
INFO:root:current mean train loss 1598.5000126139323
INFO:root:current train perplexity3.5308709144592285
INFO:root:current mean train loss 1599.1599489182693
INFO:root:current train perplexity3.5349717140197754
INFO:root:current mean train loss 1599.5078782435826
INFO:root:current train perplexity3.535752773284912
INFO:root:current mean train loss 1599.9611013997396
INFO:root:current train perplexity3.5370516777038574
INFO:root:current mean train loss 1601.1255255889891
INFO:root:current train perplexity3.538578748703003
INFO:root:current mean train loss 1601.8852208754595
INFO:root:current train perplexity3.5394318103790283
INFO:root:current mean train loss 1603.1662055121528
INFO:root:current train perplexity3.540560722351074
INFO:root:current mean train loss 1603.95395051655
INFO:root:current train perplexity3.5412051677703857

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.60s/it]
INFO:root:final mean train loss: 1603.8628080197795
INFO:root:final train perplexity: 3.542747974395752
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2193.1168416341147
INFO:root:eval perplexity: 5.892404079437256
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 2749.533261995789
INFO:root:eval perplexity: 9.47488021850586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [8:03:26<21:57:05, 541.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1578.0630313648896
INFO:root:current train perplexity3.4765212535858154
INFO:root:current mean train loss 1586.045434152978
INFO:root:current train perplexity3.473574638366699
INFO:root:current mean train loss 1575.520523563508
INFO:root:current train perplexity3.4756903648376465
INFO:root:current mean train loss 1579.9219200543425
INFO:root:current train perplexity3.48897385597229
INFO:root:current mean train loss 1579.4915188942596
INFO:root:current train perplexity3.491215944290161
INFO:root:current mean train loss 1581.4202040297841
INFO:root:current train perplexity3.493069887161255
INFO:root:current mean train loss 1582.2557653986655
INFO:root:current train perplexity3.493253469467163
INFO:root:current mean train loss 1581.6675269474044
INFO:root:current train perplexity3.495384931564331
INFO:root:current mean train loss 1585.1088103687748
INFO:root:current train perplexity3.499877452850342
INFO:root:current mean train loss 1586.5587163527894
INFO:root:current train perplexity3.502530097961426
INFO:root:current mean train loss 1587.858753845755
INFO:root:current train perplexity3.504134178161621
INFO:root:current mean train loss 1588.628148037083
INFO:root:current train perplexity3.5048441886901855
INFO:root:current mean train loss 1588.9854821586766
INFO:root:current train perplexity3.503929376602173
INFO:root:current mean train loss 1590.0836084318053
INFO:root:current train perplexity3.5057995319366455
INFO:root:current mean train loss 1590.515118197143
INFO:root:current train perplexity3.5084798336029053
INFO:root:current mean train loss 1591.1766662396485
INFO:root:current train perplexity3.511098623275757
INFO:root:current mean train loss 1592.0682926402094
INFO:root:current train perplexity3.513545036315918
INFO:root:current mean train loss 1592.587794077834
INFO:root:current train perplexity3.5138487815856934
INFO:root:current mean train loss 1594.168969766872
INFO:root:current train perplexity3.517368793487549
INFO:root:current mean train loss 1594.8678792317708
INFO:root:current train perplexity3.5175302028656006

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.71s/it]
INFO:root:final mean train loss: 1595.020982181551
INFO:root:final train perplexity: 3.518130302429199
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 2195.5740754688886
INFO:root:eval perplexity: 5.9041266441345215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 2753.8155699384974
INFO:root:eval perplexity: 9.508118629455566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [8:12:28<21:48:09, 541.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1553.0225578756892
INFO:root:current train perplexity3.4273293018341064
INFO:root:current mean train loss 1563.0481530943914
INFO:root:current train perplexity3.4579763412475586
INFO:root:current mean train loss 1570.2025647285657
INFO:root:current train perplexity3.4681291580200195
INFO:root:current mean train loss 1569.0993590212154
INFO:root:current train perplexity3.4615626335144043
INFO:root:current mean train loss 1571.2687625445528
INFO:root:current train perplexity3.4635462760925293
INFO:root:current mean train loss 1574.8579771349046
INFO:root:current train perplexity3.4692797660827637
INFO:root:current mean train loss 1576.4340577712194
INFO:root:current train perplexity3.474381685256958
INFO:root:current mean train loss 1577.3617339173195
INFO:root:current train perplexity3.475306272506714
INFO:root:current mean train loss 1579.0031272833296
INFO:root:current train perplexity3.476909875869751
INFO:root:current mean train loss 1578.8060038727917
INFO:root:current train perplexity3.4764933586120605
INFO:root:current mean train loss 1580.1837207786812
INFO:root:current train perplexity3.476674795150757
INFO:root:current mean train loss 1581.0266325343432
INFO:root:current train perplexity3.4803643226623535
INFO:root:current mean train loss 1582.5209013260358
INFO:root:current train perplexity3.479816198348999
INFO:root:current mean train loss 1583.014572212185
INFO:root:current train perplexity3.4829695224761963
INFO:root:current mean train loss 1583.1163386261114
INFO:root:current train perplexity3.4836692810058594
INFO:root:current mean train loss 1583.4338705965563
INFO:root:current train perplexity3.4861178398132324
INFO:root:current mean train loss 1583.4195828572044
INFO:root:current train perplexity3.487736463546753
INFO:root:current mean train loss 1584.245462701395
INFO:root:current train perplexity3.489353656768799
INFO:root:current mean train loss 1584.1379503023404
INFO:root:current train perplexity3.4899251461029053
INFO:root:current mean train loss 1585.4748787628457
INFO:root:current train perplexity3.492655038833618

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.58s/it]
INFO:root:final mean train loss: 1585.5614616328637
INFO:root:final train perplexity: 3.491981029510498
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2202.052319249363
INFO:root:eval perplexity: 5.9351396560668945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 2759.907661600316
INFO:root:eval perplexity: 9.555610656738281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [8:21:29<21:39:02, 541.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1582.1242843328737
INFO:root:current train perplexity3.4940431118011475
INFO:root:current mean train loss 1554.0777636395385
INFO:root:current train perplexity3.4497976303100586
INFO:root:current mean train loss 1559.3847101827066
INFO:root:current train perplexity3.438359260559082
INFO:root:current mean train loss 1562.095474634415
INFO:root:current train perplexity3.4417970180511475
INFO:root:current mean train loss 1563.6012035970414
INFO:root:current train perplexity3.447148084640503
INFO:root:current mean train loss 1563.1978633485992
INFO:root:current train perplexity3.4463531970977783
INFO:root:current mean train loss 1563.1109572262624
INFO:root:current train perplexity3.4453630447387695
INFO:root:current mean train loss 1565.0518129148115
INFO:root:current train perplexity3.4469218254089355
INFO:root:current mean train loss 1567.809516090904
INFO:root:current train perplexity3.450218915939331
INFO:root:current mean train loss 1569.2049794161985
INFO:root:current train perplexity3.452920913696289
INFO:root:current mean train loss 1570.3064137902518
INFO:root:current train perplexity3.4548003673553467
INFO:root:current mean train loss 1571.6280876046983
INFO:root:current train perplexity3.4549899101257324
INFO:root:current mean train loss 1572.9328840638427
INFO:root:current train perplexity3.4555306434631348
INFO:root:current mean train loss 1573.1085590896212
INFO:root:current train perplexity3.4575576782226562
INFO:root:current mean train loss 1572.4724711675137
INFO:root:current train perplexity3.458106279373169
INFO:root:current mean train loss 1573.901975256639
INFO:root:current train perplexity3.460764169692993
INFO:root:current mean train loss 1574.842595322792
INFO:root:current train perplexity3.462946891784668
INFO:root:current mean train loss 1575.1356231149164
INFO:root:current train perplexity3.4641425609588623
INFO:root:current mean train loss 1576.3758459848561
INFO:root:current train perplexity3.466827869415283
INFO:root:current mean train loss 1576.930704544044
INFO:root:current train perplexity3.4674363136291504

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.15s/it]
INFO:root:final mean train loss: 1576.5325672574795
INFO:root:final train perplexity: 3.4672038555145264
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 2206.1672666292666
INFO:root:eval perplexity: 5.954926013946533
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 2768.043699873255
INFO:root:eval perplexity: 9.619403839111328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [8:30:30<21:29:43, 541.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1563.6908587287453
INFO:root:current train perplexity3.412494659423828
INFO:root:current mean train loss 1550.5130251929872
INFO:root:current train perplexity3.405888795852661
INFO:root:current mean train loss 1555.1900042633513
INFO:root:current train perplexity3.4084200859069824
INFO:root:current mean train loss 1555.7340940392535
INFO:root:current train perplexity3.4126455783843994
INFO:root:current mean train loss 1560.122063009148
INFO:root:current train perplexity3.4184420108795166
INFO:root:current mean train loss 1560.5632672377035
INFO:root:current train perplexity3.419801712036133
INFO:root:current mean train loss 1560.676121329119
INFO:root:current train perplexity3.4199626445770264
INFO:root:current mean train loss 1560.3926607767742
INFO:root:current train perplexity3.420365810394287
INFO:root:current mean train loss 1560.5730683638753
INFO:root:current train perplexity3.4198033809661865
INFO:root:current mean train loss 1562.464294685805
INFO:root:current train perplexity3.42384934425354
INFO:root:current mean train loss 1563.3862790454193
INFO:root:current train perplexity3.4260807037353516
INFO:root:current mean train loss 1563.7731055690817
INFO:root:current train perplexity3.4283268451690674
INFO:root:current mean train loss 1563.5751787540664
INFO:root:current train perplexity3.430884599685669
INFO:root:current mean train loss 1563.8812851041382
INFO:root:current train perplexity3.4315648078918457
INFO:root:current mean train loss 1564.8700843416052
INFO:root:current train perplexity3.4333672523498535
INFO:root:current mean train loss 1565.6591458223304
INFO:root:current train perplexity3.4355528354644775
INFO:root:current mean train loss 1566.8616002949593
INFO:root:current train perplexity3.4367377758026123
INFO:root:current mean train loss 1567.4027138964623
INFO:root:current train perplexity3.438420057296753
INFO:root:current mean train loss 1567.360495981874
INFO:root:current train perplexity3.439790964126587
INFO:root:current mean train loss 1567.285188628406
INFO:root:current train perplexity3.4411308765411377

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.34s/it]
INFO:root:final mean train loss: 1567.0400621161218
INFO:root:final train perplexity: 3.4413442611694336
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2211.366584507286
INFO:root:eval perplexity: 5.980017185211182
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 2773.819328145778
INFO:root:eval perplexity: 9.664948463439941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [8:39:32<21:21:18, 541.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1543.838215188419
INFO:root:current train perplexity3.3725757598876953
INFO:root:current mean train loss 1546.8873119457348
INFO:root:current train perplexity3.384143352508545
INFO:root:current mean train loss 1546.502858586897
INFO:root:current train perplexity3.3797199726104736
INFO:root:current mean train loss 1549.6416056843548
INFO:root:current train perplexity3.393008232116699
INFO:root:current mean train loss 1552.8579826433634
INFO:root:current train perplexity3.3941662311553955
INFO:root:current mean train loss 1551.4154042301016
INFO:root:current train perplexity3.3931477069854736
INFO:root:current mean train loss 1550.9737725250911
INFO:root:current train perplexity3.393002510070801
INFO:root:current mean train loss 1551.3967572837878
INFO:root:current train perplexity3.396901845932007
INFO:root:current mean train loss 1550.2520121601342
INFO:root:current train perplexity3.4000399112701416
INFO:root:current mean train loss 1552.0499820302587
INFO:root:current train perplexity3.400878667831421
INFO:root:current mean train loss 1551.80111640895
INFO:root:current train perplexity3.4004769325256348
INFO:root:current mean train loss 1553.4109358517933
INFO:root:current train perplexity3.403853416442871
INFO:root:current mean train loss 1554.1041188518361
INFO:root:current train perplexity3.405959129333496
INFO:root:current mean train loss 1554.0671020067125
INFO:root:current train perplexity3.4084770679473877
INFO:root:current mean train loss 1554.5971883549032
INFO:root:current train perplexity3.410214900970459
INFO:root:current mean train loss 1555.41652416145
INFO:root:current train perplexity3.4125638008117676
INFO:root:current mean train loss 1556.3832387680823
INFO:root:current train perplexity3.414346933364868
INFO:root:current mean train loss 1556.3787111426602
INFO:root:current train perplexity3.414412021636963
INFO:root:current mean train loss 1557.3562937121808
INFO:root:current train perplexity3.415360927581787

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.07s/it]
INFO:root:final mean train loss: 1557.8209586477738
INFO:root:final train perplexity: 3.4164135456085205
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2215.6567426099846
INFO:root:eval perplexity: 6.000802516937256
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 2782.3828064397717
INFO:root:eval perplexity: 9.73287296295166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [8:48:32<21:11:47, 541.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1552.8955688476562
INFO:root:current train perplexity3.2631986141204834
INFO:root:current mean train loss 1524.3384973862592
INFO:root:current train perplexity3.338447332382202
INFO:root:current mean train loss 1527.5140102877476
INFO:root:current train perplexity3.345813751220703
INFO:root:current mean train loss 1533.7263175509622
INFO:root:current train perplexity3.3535358905792236
INFO:root:current mean train loss 1537.4211966291589
INFO:root:current train perplexity3.3533143997192383
INFO:root:current mean train loss 1539.7461739954244
INFO:root:current train perplexity3.359461784362793
INFO:root:current mean train loss 1541.7726965615916
INFO:root:current train perplexity3.3632333278656006
INFO:root:current mean train loss 1542.104396374477
INFO:root:current train perplexity3.365933656692505
INFO:root:current mean train loss 1543.4566029384546
INFO:root:current train perplexity3.369014263153076
INFO:root:current mean train loss 1545.1639547749792
INFO:root:current train perplexity3.3743319511413574
INFO:root:current mean train loss 1545.8559835894616
INFO:root:current train perplexity3.3773937225341797
INFO:root:current mean train loss 1546.477391403946
INFO:root:current train perplexity3.3793106079101562
INFO:root:current mean train loss 1546.9322471174344
INFO:root:current train perplexity3.38063907623291
INFO:root:current mean train loss 1546.7216348721317
INFO:root:current train perplexity3.3816633224487305
INFO:root:current mean train loss 1546.7604568633815
INFO:root:current train perplexity3.3825204372406006
INFO:root:current mean train loss 1547.2210833959668
INFO:root:current train perplexity3.383484363555908
INFO:root:current mean train loss 1547.6446944676088
INFO:root:current train perplexity3.3852555751800537
INFO:root:current mean train loss 1549.146892973455
INFO:root:current train perplexity3.3880560398101807
INFO:root:current mean train loss 1549.2018034296746
INFO:root:current train perplexity3.389491319656372
INFO:root:current mean train loss 1549.5505120791847
INFO:root:current train perplexity3.390285015106201

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.66s/it]
INFO:root:final mean train loss: 1549.0169529070834
INFO:root:final train perplexity: 3.3927743434906006
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2220.0460975592864
INFO:root:eval perplexity: 6.0221428871154785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 2784.4924125941934
INFO:root:eval perplexity: 9.749680519104004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [8:57:35<21:03:32, 541.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1536.1738088507402
INFO:root:current train perplexity3.3627262115478516
INFO:root:current mean train loss 1530.1668116465337
INFO:root:current train perplexity3.328747034072876
INFO:root:current mean train loss 1531.7184267087614
INFO:root:current train perplexity3.337289571762085
INFO:root:current mean train loss 1530.6376516886266
INFO:root:current train perplexity3.3344907760620117
INFO:root:current mean train loss 1531.3761312625857
INFO:root:current train perplexity3.341538667678833
INFO:root:current mean train loss 1530.537682799705
INFO:root:current train perplexity3.3390960693359375
INFO:root:current mean train loss 1530.9692931044276
INFO:root:current train perplexity3.342031955718994
INFO:root:current mean train loss 1531.1617068315911
INFO:root:current train perplexity3.343379497528076
INFO:root:current mean train loss 1532.9043222131602
INFO:root:current train perplexity3.3451504707336426
INFO:root:current mean train loss 1533.6328297678353
INFO:root:current train perplexity3.34906268119812
INFO:root:current mean train loss 1535.1600103406372
INFO:root:current train perplexity3.349301815032959
INFO:root:current mean train loss 1536.2052930298396
INFO:root:current train perplexity3.351165771484375
INFO:root:current mean train loss 1536.209045159807
INFO:root:current train perplexity3.354707956314087
INFO:root:current mean train loss 1537.566397180333
INFO:root:current train perplexity3.358093738555908
INFO:root:current mean train loss 1538.597159366191
INFO:root:current train perplexity3.3584935665130615
INFO:root:current mean train loss 1538.728633355749
INFO:root:current train perplexity3.3615829944610596
INFO:root:current mean train loss 1538.8852710217293
INFO:root:current train perplexity3.362659454345703
INFO:root:current mean train loss 1539.755964260312
INFO:root:current train perplexity3.3643596172332764
INFO:root:current mean train loss 1539.6031861895058
INFO:root:current train perplexity3.3644936084747314
INFO:root:current mean train loss 1540.1356018607103
INFO:root:current train perplexity3.3672690391540527

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.27s/it]
INFO:root:final mean train loss: 1539.803201541718
INFO:root:final train perplexity: 3.3682100772857666
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 2224.703229322501
INFO:root:eval perplexity: 6.04486608505249
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 2791.2629217053136
INFO:root:eval perplexity: 9.803814888000488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [9:06:36<20:54:06, 541.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1528.5798475477432
INFO:root:current train perplexity3.329657793045044
INFO:root:current mean train loss 1527.7379563275506
INFO:root:current train perplexity3.3073348999023438
INFO:root:current mean train loss 1527.4928464727886
INFO:root:current train perplexity3.3079609870910645
INFO:root:current mean train loss 1526.087543669201
INFO:root:current train perplexity3.3080315589904785
INFO:root:current mean train loss 1526.5200422094504
INFO:root:current train perplexity3.312052011489868
INFO:root:current mean train loss 1526.4390037878236
INFO:root:current train perplexity3.3142433166503906
INFO:root:current mean train loss 1524.6936290429073
INFO:root:current train perplexity3.3136589527130127
INFO:root:current mean train loss 1523.9963529835577
INFO:root:current train perplexity3.315894842147827
INFO:root:current mean train loss 1525.6597218490674
INFO:root:current train perplexity3.318601131439209
INFO:root:current mean train loss 1525.1426190759382
INFO:root:current train perplexity3.322444438934326
INFO:root:current mean train loss 1525.358063804597
INFO:root:current train perplexity3.324415683746338
INFO:root:current mean train loss 1526.5685904059612
INFO:root:current train perplexity3.3276734352111816
INFO:root:current mean train loss 1526.6518009519114
INFO:root:current train perplexity3.328068494796753
INFO:root:current mean train loss 1527.2655798632227
INFO:root:current train perplexity3.330717086791992
INFO:root:current mean train loss 1527.725753656669
INFO:root:current train perplexity3.3331680297851562
INFO:root:current mean train loss 1528.5525546073914
INFO:root:current train perplexity3.335665225982666
INFO:root:current mean train loss 1529.7819711549942
INFO:root:current train perplexity3.338583469390869
INFO:root:current mean train loss 1531.0271484093732
INFO:root:current train perplexity3.3404784202575684
INFO:root:current mean train loss 1531.365466414973
INFO:root:current train perplexity3.342505931854248
INFO:root:current mean train loss 1531.7756746780774
INFO:root:current train perplexity3.344980478286743

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.14s/it]
INFO:root:final mean train loss: 1531.3449767666277
INFO:root:final train perplexity: 3.3458168506622314
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.17s/it]
INFO:root:eval mean loss: 2232.2293458762742
INFO:root:eval perplexity: 6.0817718505859375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.49s/it]
INFO:root:eval mean loss: 2802.2834580874614
INFO:root:eval perplexity: 9.89257526397705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [9:15:36<20:44:41, 541.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1498.2307865934552
INFO:root:current train perplexity3.2562830448150635
INFO:root:current mean train loss 1506.8631089154412
INFO:root:current train perplexity3.285720109939575
INFO:root:current mean train loss 1507.4444488404768
INFO:root:current train perplexity3.2859134674072266
INFO:root:current mean train loss 1508.7530444958393
INFO:root:current train perplexity3.2943174839019775
INFO:root:current mean train loss 1508.6289315802635
INFO:root:current train perplexity3.300581216812134
INFO:root:current mean train loss 1511.0744216118756
INFO:root:current train perplexity3.3008625507354736
INFO:root:current mean train loss 1512.8361569648498
INFO:root:current train perplexity3.3051559925079346
INFO:root:current mean train loss 1513.369920221458
INFO:root:current train perplexity3.3072519302368164
INFO:root:current mean train loss 1516.12138225381
INFO:root:current train perplexity3.3081068992614746
INFO:root:current mean train loss 1517.2010354585439
INFO:root:current train perplexity3.312119245529175
INFO:root:current mean train loss 1517.7415670628561
INFO:root:current train perplexity3.311300039291382
INFO:root:current mean train loss 1518.714078401961
INFO:root:current train perplexity3.312653064727783
INFO:root:current mean train loss 1518.1099965551427
INFO:root:current train perplexity3.3130717277526855
INFO:root:current mean train loss 1519.4419047263316
INFO:root:current train perplexity3.315967559814453
INFO:root:current mean train loss 1519.638173848288
INFO:root:current train perplexity3.315976858139038
INFO:root:current mean train loss 1520.7331855022285
INFO:root:current train perplexity3.318058490753174
INFO:root:current mean train loss 1520.435069006281
INFO:root:current train perplexity3.317871332168579
INFO:root:current mean train loss 1521.7791822556421
INFO:root:current train perplexity3.319018602371216
INFO:root:current mean train loss 1522.2989158074533
INFO:root:current train perplexity3.3204662799835205
INFO:root:current mean train loss 1522.6577788478462
INFO:root:current train perplexity3.322179079055786

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.12s/it]
INFO:root:final mean train loss: 1522.5620206139392
INFO:root:final train perplexity: 3.322720527648926
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.17s/it]
INFO:root:eval mean loss: 2235.812153701241
INFO:root:eval perplexity: 6.099419116973877
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.49s/it]
INFO:root:eval mean loss: 2805.858056034602
INFO:root:eval perplexity: 9.921538352966309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [9:24:37<20:35:21, 541.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1505.7877685546875
INFO:root:current train perplexity3.279629707336426
INFO:root:current mean train loss 1506.8714721679687
INFO:root:current train perplexity3.273193359375
INFO:root:current mean train loss 1502.3782570167823
INFO:root:current train perplexity3.261505365371704
INFO:root:current mean train loss 1502.368328692462
INFO:root:current train perplexity3.267204761505127
INFO:root:current mean train loss 1503.8131965799535
INFO:root:current train perplexity3.2655651569366455
INFO:root:current mean train loss 1504.9706817091558
INFO:root:current train perplexity3.270038604736328
INFO:root:current mean train loss 1506.6978444569147
INFO:root:current train perplexity3.2751452922821045
INFO:root:current mean train loss 1508.7742127257509
INFO:root:current train perplexity3.2805182933807373
INFO:root:current mean train loss 1510.6668374247934
INFO:root:current train perplexity3.2816848754882812
INFO:root:current mean train loss 1511.127313547036
INFO:root:current train perplexity3.2861266136169434
INFO:root:current mean train loss 1512.5714806102146
INFO:root:current train perplexity3.2872087955474854
INFO:root:current mean train loss 1512.2798500517495
INFO:root:current train perplexity3.2876923084259033
INFO:root:current mean train loss 1513.079292838029
INFO:root:current train perplexity3.2889597415924072
INFO:root:current mean train loss 1512.5337249978616
INFO:root:current train perplexity3.290501356124878
INFO:root:current mean train loss 1512.3998849051338
INFO:root:current train perplexity3.2924063205718994
INFO:root:current mean train loss 1512.998053250647
INFO:root:current train perplexity3.2945826053619385
INFO:root:current mean train loss 1513.461556403794
INFO:root:current train perplexity3.297219753265381
INFO:root:current mean train loss 1514.3624716548597
INFO:root:current train perplexity3.299717426300049
INFO:root:current mean train loss 1514.8465503713026
INFO:root:current train perplexity3.302112579345703
INFO:root:current mean train loss 1515.6515870999565
INFO:root:current train perplexity3.303680419921875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.28s/it]
INFO:root:final mean train loss: 1515.3694849519254
INFO:root:final train perplexity: 3.3039262294769287
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.12s/it]
INFO:root:eval mean loss: 2240.509910637605
INFO:root:eval perplexity: 6.122636795043945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.45s/it]
INFO:root:eval mean loss: 2812.702255790115
INFO:root:eval perplexity: 9.977229118347168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [9:33:38<20:26:10, 540.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1496.0354831739403
INFO:root:current train perplexity3.2356133460998535
INFO:root:current mean train loss 1496.3277561779328
INFO:root:current train perplexity3.2270262241363525
INFO:root:current mean train loss 1497.206804122659
INFO:root:current train perplexity3.2310028076171875
INFO:root:current mean train loss 1495.3108402222626
INFO:root:current train perplexity3.2375102043151855
INFO:root:current mean train loss 1498.1133231098402
INFO:root:current train perplexity3.242213487625122
INFO:root:current mean train loss 1499.3071251630377
INFO:root:current train perplexity3.2471351623535156
INFO:root:current mean train loss 1498.776770890193
INFO:root:current train perplexity3.2516047954559326
INFO:root:current mean train loss 1499.390912726086
INFO:root:current train perplexity3.253504753112793
INFO:root:current mean train loss 1500.1633968245756
INFO:root:current train perplexity3.258420467376709
INFO:root:current mean train loss 1500.6874649990898
INFO:root:current train perplexity3.2611725330352783
INFO:root:current mean train loss 1501.273514425634
INFO:root:current train perplexity3.2624142169952393
INFO:root:current mean train loss 1501.2540162881082
INFO:root:current train perplexity3.2628302574157715
INFO:root:current mean train loss 1502.7140098399864
INFO:root:current train perplexity3.2634830474853516
INFO:root:current mean train loss 1503.3671371580974
INFO:root:current train perplexity3.2654104232788086
INFO:root:current mean train loss 1503.2762025937027
INFO:root:current train perplexity3.2683563232421875
INFO:root:current mean train loss 1504.0154459327741
INFO:root:current train perplexity3.2715132236480713
INFO:root:current mean train loss 1504.9625747762068
INFO:root:current train perplexity3.2727725505828857
INFO:root:current mean train loss 1505.4663100965743
INFO:root:current train perplexity3.274510622024536
INFO:root:current mean train loss 1505.898522696927
INFO:root:current train perplexity3.27600359916687

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.10s/it]
INFO:root:final mean train loss: 1505.5486556999142
INFO:root:final train perplexity: 3.278435707092285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it]
INFO:root:eval mean loss: 2247.0461611916835
INFO:root:eval perplexity: 6.155086040496826
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it]
INFO:root:eval mean loss: 2819.6869454891125
INFO:root:eval perplexity: 10.034381866455078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [9:42:40<20:17:43, 541.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1441.6969604492188
INFO:root:current train perplexity3.0535244941711426
INFO:root:current mean train loss 1478.385044978215
INFO:root:current train perplexity3.2010936737060547
INFO:root:current mean train loss 1473.821153229358
INFO:root:current train perplexity3.207122325897217
INFO:root:current mean train loss 1479.2720995451275
INFO:root:current train perplexity3.2155067920684814
INFO:root:current mean train loss 1482.177119491124
INFO:root:current train perplexity3.2203471660614014
INFO:root:current mean train loss 1482.4678833976625
INFO:root:current train perplexity3.2225983142852783
INFO:root:current mean train loss 1482.2283001830247
INFO:root:current train perplexity3.2254984378814697
INFO:root:current mean train loss 1486.0769341208718
INFO:root:current train perplexity3.2276358604431152
INFO:root:current mean train loss 1488.9654914514342
INFO:root:current train perplexity3.231430768966675
INFO:root:current mean train loss 1491.5986931724885
INFO:root:current train perplexity3.236475944519043
INFO:root:current mean train loss 1491.5947900293359
INFO:root:current train perplexity3.2369883060455322
INFO:root:current mean train loss 1492.3833755272021
INFO:root:current train perplexity3.23836350440979
INFO:root:current mean train loss 1493.5746163910014
INFO:root:current train perplexity3.2424652576446533
INFO:root:current mean train loss 1494.3290459568516
INFO:root:current train perplexity3.2466044425964355
INFO:root:current mean train loss 1495.002384457493
INFO:root:current train perplexity3.2484445571899414
INFO:root:current mean train loss 1495.1830399695864
INFO:root:current train perplexity3.249934673309326
INFO:root:current mean train loss 1495.6581794567537
INFO:root:current train perplexity3.2511560916900635
INFO:root:current mean train loss 1496.796123665823
INFO:root:current train perplexity3.253718852996826
INFO:root:current mean train loss 1496.3148097272988
INFO:root:current train perplexity3.2540054321289062
INFO:root:current mean train loss 1496.675776185108
INFO:root:current train perplexity3.255680799484253

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.79s/it]
INFO:root:final mean train loss: 1497.1654535352252
INFO:root:final train perplexity: 3.256831169128418
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2251.9262418273493
INFO:root:eval perplexity: 6.179429054260254
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 2826.6634508498173
INFO:root:eval perplexity: 10.09179973602295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [9:51:42<20:09:32, 541.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1460.9434814453125
INFO:root:current train perplexity3.1506075859069824
INFO:root:current mean train loss 1469.1352942600722
INFO:root:current train perplexity3.1751763820648193
INFO:root:current mean train loss 1470.7899700182056
INFO:root:current train perplexity3.185805320739746
INFO:root:current mean train loss 1474.385198004892
INFO:root:current train perplexity3.19401216506958
INFO:root:current mean train loss 1478.0478361949786
INFO:root:current train perplexity3.199613094329834
INFO:root:current mean train loss 1479.2464815165397
INFO:root:current train perplexity3.203026056289673
INFO:root:current mean train loss 1483.519321705792
INFO:root:current train perplexity3.211674690246582
INFO:root:current mean train loss 1483.1609074649466
INFO:root:current train perplexity3.214632987976074
INFO:root:current mean train loss 1484.3507042906897
INFO:root:current train perplexity3.2164528369903564
INFO:root:current mean train loss 1485.950598104769
INFO:root:current train perplexity3.219937801361084
INFO:root:current mean train loss 1486.2869977063694
INFO:root:current train perplexity3.222113847732544
INFO:root:current mean train loss 1486.0603694864728
INFO:root:current train perplexity3.225449323654175
INFO:root:current mean train loss 1485.7601454326307
INFO:root:current train perplexity3.225811004638672
INFO:root:current mean train loss 1486.5020806473551
INFO:root:current train perplexity3.2262356281280518
INFO:root:current mean train loss 1486.8704724885645
INFO:root:current train perplexity3.2260591983795166
INFO:root:current mean train loss 1487.319874539648
INFO:root:current train perplexity3.229339599609375
INFO:root:current mean train loss 1487.323772715169
INFO:root:current train perplexity3.2299230098724365
INFO:root:current mean train loss 1488.0940183277119
INFO:root:current train perplexity3.232769250869751
INFO:root:current mean train loss 1488.7965158277132
INFO:root:current train perplexity3.2343461513519287
INFO:root:current mean train loss 1489.4089415201229
INFO:root:current train perplexity3.2361867427825928

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.53s/it]
INFO:root:final mean train loss: 1489.3837455714886
INFO:root:final train perplexity: 3.236905097961426
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2257.7355788210607
INFO:root:eval perplexity: 6.2085280418396
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 2834.3701686994405
INFO:root:eval perplexity: 10.15560531616211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [10:00:43<20:00:14, 541.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1461.5752884714227
INFO:root:current train perplexity3.1869375705718994
INFO:root:current mean train loss 1466.9249886775362
INFO:root:current train perplexity3.179788827896118
INFO:root:current mean train loss 1472.027400169052
INFO:root:current train perplexity3.1785504817962646
INFO:root:current mean train loss 1468.194293321237
INFO:root:current train perplexity3.183295726776123
INFO:root:current mean train loss 1470.3037703004602
INFO:root:current train perplexity3.1914100646972656
INFO:root:current mean train loss 1470.7661112391816
INFO:root:current train perplexity3.1931605339050293
INFO:root:current mean train loss 1473.591318160389
INFO:root:current train perplexity3.198080539703369
INFO:root:current mean train loss 1475.1655519893823
INFO:root:current train perplexity3.1981332302093506
INFO:root:current mean train loss 1475.1884563145604
INFO:root:current train perplexity3.1984102725982666
INFO:root:current mean train loss 1475.5461755032732
INFO:root:current train perplexity3.2006351947784424
INFO:root:current mean train loss 1476.5629097234767
INFO:root:current train perplexity3.2039642333984375
INFO:root:current mean train loss 1477.4111686398148
INFO:root:current train perplexity3.2078468799591064
INFO:root:current mean train loss 1478.2419588400205
INFO:root:current train perplexity3.2111268043518066
INFO:root:current mean train loss 1478.5579946201478
INFO:root:current train perplexity3.2117276191711426
INFO:root:current mean train loss 1479.871571674798
INFO:root:current train perplexity3.2135555744171143
INFO:root:current mean train loss 1480.4521264521447
INFO:root:current train perplexity3.2127740383148193
INFO:root:current mean train loss 1480.0735332037211
INFO:root:current train perplexity3.2132248878479004
INFO:root:current mean train loss 1480.6425989148806
INFO:root:current train perplexity3.2145049571990967
INFO:root:current mean train loss 1481.1160191981137
INFO:root:current train perplexity3.2153680324554443
INFO:root:current mean train loss 1481.664979098136
INFO:root:current train perplexity3.2168593406677246

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.79s/it]
INFO:root:final mean train loss: 1481.7164298945825
INFO:root:final train perplexity: 3.217391014099121
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2260.7439869549257
INFO:root:eval perplexity: 6.223651885986328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 2838.225230981272
INFO:root:eval perplexity: 10.18767261505127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [10:09:45<19:51:11, 541.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1442.4677823153409
INFO:root:current train perplexity3.1650357246398926
INFO:root:current mean train loss 1452.3163944367438
INFO:root:current train perplexity3.1669273376464844
INFO:root:current mean train loss 1457.615349743413
INFO:root:current train perplexity3.1722047328948975
INFO:root:current mean train loss 1461.7016089211047
INFO:root:current train perplexity3.1748528480529785
INFO:root:current mean train loss 1463.5025310139079
INFO:root:current train perplexity3.1774702072143555
INFO:root:current mean train loss 1464.4207418355857
INFO:root:current train perplexity3.175585985183716
INFO:root:current mean train loss 1463.6445349773378
INFO:root:current train perplexity3.176482677459717
INFO:root:current mean train loss 1464.5492906987272
INFO:root:current train perplexity3.1785666942596436
INFO:root:current mean train loss 1465.1428685238486
INFO:root:current train perplexity3.1811203956604004
INFO:root:current mean train loss 1465.7403540166886
INFO:root:current train perplexity3.182178258895874
INFO:root:current mean train loss 1466.6716315536137
INFO:root:current train perplexity3.1810309886932373
INFO:root:current mean train loss 1467.1140840604708
INFO:root:current train perplexity3.182493209838867
INFO:root:current mean train loss 1468.9696540011828
INFO:root:current train perplexity3.1872031688690186
INFO:root:current mean train loss 1469.7641566427872
INFO:root:current train perplexity3.188265323638916
INFO:root:current mean train loss 1470.5482020846757
INFO:root:current train perplexity3.189085006713867
INFO:root:current mean train loss 1471.3147015832244
INFO:root:current train perplexity3.189786434173584
INFO:root:current mean train loss 1471.9144542313775
INFO:root:current train perplexity3.190324544906616
INFO:root:current mean train loss 1472.1085671101541
INFO:root:current train perplexity3.193408727645874
INFO:root:current mean train loss 1472.556764340465
INFO:root:current train perplexity3.1942129135131836
INFO:root:current mean train loss 1473.8608277928188
INFO:root:current train perplexity3.1959786415100098

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.00s/it]
INFO:root:final mean train loss: 1473.2756484623696
INFO:root:final train perplexity: 3.1960439682006836
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2268.2767961650875
INFO:root:eval perplexity: 6.261683940887451
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 2847.5782682811114
INFO:root:eval perplexity: 10.265901565551758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [10:18:46<19:42:17, 541.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1442.922863430447
INFO:root:current train perplexity3.1288421154022217
INFO:root:current mean train loss 1445.0654878838118
INFO:root:current train perplexity3.1306564807891846
INFO:root:current mean train loss 1450.658421235926
INFO:root:current train perplexity3.129986047744751
INFO:root:current mean train loss 1452.9792975969212
INFO:root:current train perplexity3.1369714736938477
INFO:root:current mean train loss 1455.755151263738
INFO:root:current train perplexity3.140235185623169
INFO:root:current mean train loss 1457.855313387784
INFO:root:current train perplexity3.1481869220733643
INFO:root:current mean train loss 1458.3977895464216
INFO:root:current train perplexity3.1498725414276123
INFO:root:current mean train loss 1459.070547153295
INFO:root:current train perplexity3.1529746055603027
INFO:root:current mean train loss 1460.2555714178523
INFO:root:current train perplexity3.1588706970214844
INFO:root:current mean train loss 1461.7630715703767
INFO:root:current train perplexity3.160905361175537
INFO:root:current mean train loss 1463.65495083937
INFO:root:current train perplexity3.1624300479888916
INFO:root:current mean train loss 1464.2511360246574
INFO:root:current train perplexity3.164217472076416
INFO:root:current mean train loss 1463.9417050919442
INFO:root:current train perplexity3.167036771774292
INFO:root:current mean train loss 1464.7725048899304
INFO:root:current train perplexity3.1695363521575928
INFO:root:current mean train loss 1465.558306818423
INFO:root:current train perplexity3.172473907470703
INFO:root:current mean train loss 1464.8031474882714
INFO:root:current train perplexity3.1719841957092285
INFO:root:current mean train loss 1465.5560657555977
INFO:root:current train perplexity3.174358606338501
INFO:root:current mean train loss 1466.1770771104111
INFO:root:current train perplexity3.176572799682617
INFO:root:current mean train loss 1466.4168736384465
INFO:root:current train perplexity3.176651954650879
INFO:root:current mean train loss 1466.5018935754865
INFO:root:current train perplexity3.17777419090271

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.41s/it]
INFO:root:final mean train loss: 1466.1938269110683
INFO:root:final train perplexity: 3.178243398666382
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2273.8432560913952
INFO:root:eval perplexity: 6.289937496185303
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 2853.7166838950297
INFO:root:eval perplexity: 10.317564964294434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [10:27:47<19:32:58, 541.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1446.96713428283
INFO:root:current train perplexity3.112905979156494
INFO:root:current mean train loss 1444.3429504071594
INFO:root:current train perplexity3.116128444671631
INFO:root:current mean train loss 1444.3765666394086
INFO:root:current train perplexity3.1151859760284424
INFO:root:current mean train loss 1444.8300800078325
INFO:root:current train perplexity3.118079662322998
INFO:root:current mean train loss 1446.714712193651
INFO:root:current train perplexity3.1216020584106445
INFO:root:current mean train loss 1446.881148696148
INFO:root:current train perplexity3.125849962234497
INFO:root:current mean train loss 1448.902070907792
INFO:root:current train perplexity3.1300785541534424
INFO:root:current mean train loss 1450.2337281356445
INFO:root:current train perplexity3.1315248012542725
INFO:root:current mean train loss 1451.0147904180435
INFO:root:current train perplexity3.1335771083831787
INFO:root:current mean train loss 1451.144227493641
INFO:root:current train perplexity3.1347334384918213
INFO:root:current mean train loss 1451.9713678421288
INFO:root:current train perplexity3.137888193130493
INFO:root:current mean train loss 1452.1965491164121
INFO:root:current train perplexity3.140211343765259
INFO:root:current mean train loss 1452.1374700174856
INFO:root:current train perplexity3.143195152282715
INFO:root:current mean train loss 1451.9755702942202
INFO:root:current train perplexity3.1462061405181885
INFO:root:current mean train loss 1453.9664632926617
INFO:root:current train perplexity3.149074077606201
INFO:root:current mean train loss 1455.3903994503225
INFO:root:current train perplexity3.1510393619537354
INFO:root:current mean train loss 1456.139498180437
INFO:root:current train perplexity3.1518163681030273
INFO:root:current mean train loss 1456.9626804648196
INFO:root:current train perplexity3.1538138389587402
INFO:root:current mean train loss 1457.236326057107
INFO:root:current train perplexity3.154517889022827

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.91s/it]
INFO:root:final mean train loss: 1457.4739028384333
INFO:root:final train perplexity: 3.156461000442505
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it]
INFO:root:eval mean loss: 2279.2698948636967
INFO:root:eval perplexity: 6.317601680755615
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 2861.2892789367243
INFO:root:eval perplexity: 10.381664276123047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [10:36:48<19:23:23, 541.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1473.470703125
INFO:root:current train perplexity3.1314244270324707
INFO:root:current mean train loss 1432.6083846182194
INFO:root:current train perplexity3.0982697010040283
INFO:root:current mean train loss 1434.562931394114
INFO:root:current train perplexity3.1062750816345215
INFO:root:current mean train loss 1439.1023296281403
INFO:root:current train perplexity3.1088919639587402
INFO:root:current mean train loss 1438.8909491177262
INFO:root:current train perplexity3.1086010932922363
INFO:root:current mean train loss 1440.224634705796
INFO:root:current train perplexity3.1122336387634277
INFO:root:current mean train loss 1439.6048428878532
INFO:root:current train perplexity3.1111130714416504
INFO:root:current mean train loss 1439.2874562206755
INFO:root:current train perplexity3.1163835525512695
INFO:root:current mean train loss 1440.859141006659
INFO:root:current train perplexity3.1169044971466064
INFO:root:current mean train loss 1443.1643256383227
INFO:root:current train perplexity3.12080454826355
INFO:root:current mean train loss 1443.4231972665957
INFO:root:current train perplexity3.1243274211883545
INFO:root:current mean train loss 1444.6621404996185
INFO:root:current train perplexity3.125725269317627
INFO:root:current mean train loss 1444.2609397673093
INFO:root:current train perplexity3.126579761505127
INFO:root:current mean train loss 1446.395809436465
INFO:root:current train perplexity3.1263561248779297
INFO:root:current mean train loss 1447.9656270489754
INFO:root:current train perplexity3.128143310546875
INFO:root:current mean train loss 1448.839141967287
INFO:root:current train perplexity3.130220413208008
INFO:root:current mean train loss 1449.3353151390295
INFO:root:current train perplexity3.1316285133361816
INFO:root:current mean train loss 1449.225266737228
INFO:root:current train perplexity3.1332180500030518
INFO:root:current mean train loss 1449.5447202494506
INFO:root:current train perplexity3.1337924003601074
INFO:root:current mean train loss 1449.6399349120582
INFO:root:current train perplexity3.136465311050415

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.25s/it]
INFO:root:final mean train loss: 1449.6871761104644
INFO:root:final train perplexity: 3.137136459350586
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.13s/it]
INFO:root:eval mean loss: 2285.2220883200353
INFO:root:eval perplexity: 6.348086833953857
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.47s/it]
INFO:root:eval mean loss: 2867.4549625477894
INFO:root:eval perplexity: 10.434144020080566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [10:45:50<19:14:48, 541.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1424.297655188519
INFO:root:current train perplexity3.0766494274139404
INFO:root:current mean train loss 1422.963773897993
INFO:root:current train perplexity3.0739619731903076
INFO:root:current mean train loss 1428.6699246120024
INFO:root:current train perplexity3.0776150226593018
INFO:root:current mean train loss 1428.6555844711445
INFO:root:current train perplexity3.0858311653137207
INFO:root:current mean train loss 1427.8505891119053
INFO:root:current train perplexity3.087806463241577
INFO:root:current mean train loss 1429.6750387917514
INFO:root:current train perplexity3.0907046794891357
INFO:root:current mean train loss 1432.3348453331912
INFO:root:current train perplexity3.093693971633911
INFO:root:current mean train loss 1431.9596440274356
INFO:root:current train perplexity3.0962510108947754
INFO:root:current mean train loss 1433.192411587276
INFO:root:current train perplexity3.10208797454834
INFO:root:current mean train loss 1434.043739790002
INFO:root:current train perplexity3.1045892238616943
INFO:root:current mean train loss 1434.9772618686231
INFO:root:current train perplexity3.1032919883728027
INFO:root:current mean train loss 1436.0638096198797
INFO:root:current train perplexity3.1057186126708984
INFO:root:current mean train loss 1436.7259175136064
INFO:root:current train perplexity3.1068902015686035
INFO:root:current mean train loss 1437.1187715537603
INFO:root:current train perplexity3.1087677478790283
INFO:root:current mean train loss 1437.482368431708
INFO:root:current train perplexity3.110649824142456
INFO:root:current mean train loss 1438.8106314345403
INFO:root:current train perplexity3.1124281883239746
INFO:root:current mean train loss 1439.90997243001
INFO:root:current train perplexity3.113931179046631
INFO:root:current mean train loss 1441.2413197593223
INFO:root:current train perplexity3.115394115447998
INFO:root:current mean train loss 1441.6709901743777
INFO:root:current train perplexity3.1162004470825195
INFO:root:current mean train loss 1442.434557743638
INFO:root:current train perplexity3.119067430496216

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.85s/it]
INFO:root:final mean train loss: 1442.7028871691114
INFO:root:final train perplexity: 3.1199045181274414
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2290.7340282683676
INFO:root:eval perplexity: 6.376447677612305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 2874.4432035405584
INFO:root:eval perplexity: 10.49394702911377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [10:54:50<19:05:16, 541.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1397.6854583740235
INFO:root:current train perplexity3.037374973297119
INFO:root:current mean train loss 1408.7736511230469
INFO:root:current train perplexity3.08223557472229
INFO:root:current mean train loss 1419.2258285522462
INFO:root:current train perplexity3.0806307792663574
INFO:root:current mean train loss 1427.16957469267
INFO:root:current train perplexity3.0822057723999023
INFO:root:current mean train loss 1426.5935810435901
INFO:root:current train perplexity3.0845017433166504
INFO:root:current mean train loss 1427.8500427246095
INFO:root:current train perplexity3.0874807834625244
INFO:root:current mean train loss 1427.0908548355103
INFO:root:current train perplexity3.0882928371429443
INFO:root:current mean train loss 1428.2103002599767
INFO:root:current train perplexity3.085596799850464
INFO:root:current mean train loss 1429.6660188220796
INFO:root:current train perplexity3.086329936981201
INFO:root:current mean train loss 1429.7503953000332
INFO:root:current train perplexity3.087263822555542
INFO:root:current mean train loss 1430.6467053926908
INFO:root:current train perplexity3.087636709213257
INFO:root:current mean train loss 1430.4943012438323
INFO:root:current train perplexity3.089240789413452
INFO:root:current mean train loss 1431.4740633072392
INFO:root:current train perplexity3.0917506217956543
INFO:root:current mean train loss 1432.5705097255423
INFO:root:current train perplexity3.0946366786956787
INFO:root:current mean train loss 1433.203628540039
INFO:root:current train perplexity3.0969126224517822
INFO:root:current mean train loss 1432.5325114460734
INFO:root:current train perplexity3.0984482765197754
INFO:root:current mean train loss 1433.9914989192312
INFO:root:current train perplexity3.101127862930298
INFO:root:current mean train loss 1434.9509896113955
INFO:root:current train perplexity3.101966619491577
INFO:root:current mean train loss 1435.2463195137357
INFO:root:current train perplexity3.101776361465454
INFO:root:current mean train loss 1435.6784308050096
INFO:root:current train perplexity3.102715253829956

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.77s/it]
INFO:root:final mean train loss: 1435.85006219861
INFO:root:final train perplexity: 3.1030876636505127
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it]
INFO:root:eval mean loss: 2294.39088861993
INFO:root:eval perplexity: 6.395333766937256
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.48s/it]
INFO:root:eval mean loss: 2880.614364732242
INFO:root:eval perplexity: 10.54704475402832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [11:03:51<18:56:24, 541.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1429.2016665810033
INFO:root:current train perplexity3.060763359069824
INFO:root:current mean train loss 1414.6123458959494
INFO:root:current train perplexity3.047667980194092
INFO:root:current mean train loss 1415.5914539381688
INFO:root:current train perplexity3.0559887886047363
INFO:root:current mean train loss 1416.4040982115503
INFO:root:current train perplexity3.0533411502838135
INFO:root:current mean train loss 1416.6208683072348
INFO:root:current train perplexity3.055835008621216
INFO:root:current mean train loss 1417.6066660033523
INFO:root:current train perplexity3.059730291366577
INFO:root:current mean train loss 1417.5017593360565
INFO:root:current train perplexity3.05934739112854
INFO:root:current mean train loss 1418.1867093649378
INFO:root:current train perplexity3.0624051094055176
INFO:root:current mean train loss 1420.0675290974602
INFO:root:current train perplexity3.066312074661255
INFO:root:current mean train loss 1421.389030942847
INFO:root:current train perplexity3.068699598312378
INFO:root:current mean train loss 1422.8574039744337
INFO:root:current train perplexity3.068589448928833
INFO:root:current mean train loss 1423.6573930507914
INFO:root:current train perplexity3.070998430252075
INFO:root:current mean train loss 1424.150319247371
INFO:root:current train perplexity3.072432041168213
INFO:root:current mean train loss 1424.1059484854286
INFO:root:current train perplexity3.073403835296631
INFO:root:current mean train loss 1424.8411560268048
INFO:root:current train perplexity3.0731759071350098
INFO:root:current mean train loss 1425.5776099056177
INFO:root:current train perplexity3.075968027114868
INFO:root:current mean train loss 1425.8419608632412
INFO:root:current train perplexity3.077526807785034
INFO:root:current mean train loss 1426.6677308622652
INFO:root:current train perplexity3.0782809257507324
INFO:root:current mean train loss 1426.8836449708872
INFO:root:current train perplexity3.0814318656921387
INFO:root:current mean train loss 1427.2758083587164
INFO:root:current train perplexity3.0821242332458496

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.54s/it]
INFO:root:final mean train loss: 1427.586036116561
INFO:root:final train perplexity: 3.0829293727874756
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.11s/it]
INFO:root:eval mean loss: 2299.66194618171
INFO:root:eval perplexity: 6.422654151916504
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.44s/it]
INFO:root:eval mean loss: 2886.2116339933787
INFO:root:eval perplexity: 10.595433235168457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [11:12:51<18:46:40, 540.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1400.1009966876056
INFO:root:current train perplexity3.051051378250122
INFO:root:current mean train loss 1402.6896923547504
INFO:root:current train perplexity3.034712314605713
INFO:root:current mean train loss 1406.6467744033703
INFO:root:current train perplexity3.040090322494507
INFO:root:current mean train loss 1407.110247443704
INFO:root:current train perplexity3.040895700454712
INFO:root:current mean train loss 1408.5454181397515
INFO:root:current train perplexity3.03946590423584
INFO:root:current mean train loss 1409.0560255947844
INFO:root:current train perplexity3.0387725830078125
INFO:root:current mean train loss 1410.9311668328078
INFO:root:current train perplexity3.04197096824646
INFO:root:current mean train loss 1412.106989108931
INFO:root:current train perplexity3.0451369285583496
INFO:root:current mean train loss 1413.3782958984375
INFO:root:current train perplexity3.047764539718628
INFO:root:current mean train loss 1412.4936187556148
INFO:root:current train perplexity3.0484671592712402
INFO:root:current mean train loss 1413.2327766063272
INFO:root:current train perplexity3.0493216514587402
INFO:root:current mean train loss 1413.6552364212894
INFO:root:current train perplexity3.050138235092163
INFO:root:current mean train loss 1415.294825196079
INFO:root:current train perplexity3.052781820297241
INFO:root:current mean train loss 1416.7355586555848
INFO:root:current train perplexity3.053370237350464
INFO:root:current mean train loss 1417.8837479859226
INFO:root:current train perplexity3.0554234981536865
INFO:root:current mean train loss 1418.8326400504784
INFO:root:current train perplexity3.0573389530181885
INFO:root:current mean train loss 1419.2441792003856
INFO:root:current train perplexity3.060393810272217
INFO:root:current mean train loss 1419.4606387924314
INFO:root:current train perplexity3.061771869659424
INFO:root:current mean train loss 1419.6104721997565
INFO:root:current train perplexity3.062980890274048
INFO:root:current mean train loss 1420.9241953253625
INFO:root:current train perplexity3.0656991004943848

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.32s/it]
INFO:root:final mean train loss: 1420.591853262497
INFO:root:final train perplexity: 3.0659706592559814
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it]
INFO:root:eval mean loss: 2305.1056639759254
INFO:root:eval perplexity: 6.45099401473999
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.50s/it]
INFO:root:eval mean loss: 2891.902560619598
INFO:root:eval perplexity: 10.644861221313477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [11:21:52<18:37:42, 540.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1393.5836557241587
INFO:root:current train perplexity3.0105302333831787
INFO:root:current mean train loss 1401.2418078677192
INFO:root:current train perplexity3.020156145095825
INFO:root:current mean train loss 1403.5522830084838
INFO:root:current train perplexity3.021820545196533
INFO:root:current mean train loss 1404.9044127013067
INFO:root:current train perplexity3.0255985260009766
INFO:root:current mean train loss 1404.2937757565874
INFO:root:current train perplexity3.031113386154175
INFO:root:current mean train loss 1405.1521293523954
INFO:root:current train perplexity3.0312678813934326
INFO:root:current mean train loss 1405.871978450615
INFO:root:current train perplexity3.034808397293091
INFO:root:current mean train loss 1406.5801114589917
INFO:root:current train perplexity3.033437728881836
INFO:root:current mean train loss 1408.9091921548384
INFO:root:current train perplexity3.034641981124878
INFO:root:current mean train loss 1409.4160349640908
INFO:root:current train perplexity3.0364630222320557
INFO:root:current mean train loss 1409.399324775507
INFO:root:current train perplexity3.035332679748535
INFO:root:current mean train loss 1409.3017746215103
INFO:root:current train perplexity3.0365140438079834
INFO:root:current mean train loss 1409.5847844981483
INFO:root:current train perplexity3.037705898284912
INFO:root:current mean train loss 1410.1908778636941
INFO:root:current train perplexity3.039314031600952
INFO:root:current mean train loss 1411.4281818842744
INFO:root:current train perplexity3.0413706302642822
INFO:root:current mean train loss 1411.8300363863136
INFO:root:current train perplexity3.0422616004943848
INFO:root:current mean train loss 1412.2470483672753
INFO:root:current train perplexity3.04351806640625
INFO:root:current mean train loss 1413.1761749966195
INFO:root:current train perplexity3.0462088584899902
INFO:root:current mean train loss 1413.4930738815235
INFO:root:current train perplexity3.0472521781921387

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.58s/it]
INFO:root:final mean train loss: 1413.5510861795476
INFO:root:final train perplexity: 3.0489935874938965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.14s/it]
INFO:root:eval mean loss: 2311.5810888845026
INFO:root:eval perplexity: 6.484867095947266
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.50s/it]
INFO:root:eval mean loss: 2899.6860083180964
INFO:root:eval perplexity: 10.71284008026123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [11:30:54<18:28:52, 540.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1399.8659973144531
INFO:root:current train perplexity2.9960315227508545
INFO:root:current mean train loss 1403.2667541503906
INFO:root:current train perplexity3.0081138610839844
INFO:root:current mean train loss 1400.338147676908
INFO:root:current train perplexity3.011368751525879
INFO:root:current mean train loss 1400.8707663796165
INFO:root:current train perplexity3.0162038803100586
INFO:root:current mean train loss 1399.7968824797986
INFO:root:current train perplexity3.012981653213501
INFO:root:current mean train loss 1401.0335003710168
INFO:root:current train perplexity3.018339157104492
INFO:root:current mean train loss 1402.1559048702843
INFO:root:current train perplexity3.022160053253174
INFO:root:current mean train loss 1401.2085683359264
INFO:root:current train perplexity3.018310546875
INFO:root:current mean train loss 1400.7832226139485
INFO:root:current train perplexity3.0181572437286377
INFO:root:current mean train loss 1401.6279931425522
INFO:root:current train perplexity3.0186245441436768
INFO:root:current mean train loss 1401.3941560775515
INFO:root:current train perplexity3.019552707672119
INFO:root:current mean train loss 1401.9039280199402
INFO:root:current train perplexity3.020205020904541
INFO:root:current mean train loss 1402.4868416691459
INFO:root:current train perplexity3.0226211547851562
INFO:root:current mean train loss 1402.8418061142668
INFO:root:current train perplexity3.024465799331665
INFO:root:current mean train loss 1402.6012412851508
INFO:root:current train perplexity3.0245182514190674
INFO:root:current mean train loss 1402.93865586339
INFO:root:current train perplexity3.0258240699768066
INFO:root:current mean train loss 1403.3530941483987
INFO:root:current train perplexity3.027677059173584
INFO:root:current mean train loss 1404.4913978308648
INFO:root:current train perplexity3.0281286239624023
INFO:root:current mean train loss 1405.3807080024112
INFO:root:current train perplexity3.028369903564453
INFO:root:current mean train loss 1406.2640756411122
INFO:root:current train perplexity3.0304691791534424

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.19s/it]
INFO:root:final mean train loss: 1406.2232931640133
INFO:root:final train perplexity: 3.031423807144165
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.10s/it]
INFO:root:eval mean loss: 2317.279776498781
INFO:root:eval perplexity: 6.514821529388428
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it]
INFO:root:eval mean loss: 2907.6184021428967
INFO:root:eval perplexity: 10.782564163208008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [11:39:54<18:19:39, 540.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1390.5906787109375
INFO:root:current train perplexity2.9834909439086914
INFO:root:current mean train loss 1395.8505927734375
INFO:root:current train perplexity2.9930038452148438
INFO:root:current mean train loss 1386.4613406032986
INFO:root:current train perplexity2.994138479232788
INFO:root:current mean train loss 1386.4781768329326
INFO:root:current train perplexity2.9903030395507812
INFO:root:current mean train loss 1388.2502596507352
INFO:root:current train perplexity2.9928011894226074
INFO:root:current mean train loss 1390.5281908017114
INFO:root:current train perplexity2.9950196743011475
INFO:root:current mean train loss 1389.7855931640624
INFO:root:current train perplexity2.992152214050293
INFO:root:current mean train loss 1391.0520002693966
INFO:root:current train perplexity2.99503493309021
INFO:root:current mean train loss 1391.6193409682764
INFO:root:current train perplexity2.996706008911133
INFO:root:current mean train loss 1393.6646362964527
INFO:root:current train perplexity2.999934196472168
INFO:root:current mean train loss 1393.7590310594512
INFO:root:current train perplexity3.0023021697998047
INFO:root:current mean train loss 1394.4342497829862
INFO:root:current train perplexity3.003410577774048
INFO:root:current mean train loss 1395.2588160674427
INFO:root:current train perplexity3.005383014678955
INFO:root:current mean train loss 1395.8744040204895
INFO:root:current train perplexity3.005800724029541
INFO:root:current mean train loss 1396.928349609375
INFO:root:current train perplexity3.0085747241973877
INFO:root:current mean train loss 1397.5051536084784
INFO:root:current train perplexity3.009586811065674
INFO:root:current mean train loss 1397.7287056790865
INFO:root:current train perplexity3.0119829177856445
INFO:root:current mean train loss 1398.1540885416666
INFO:root:current train perplexity3.0127274990081787
INFO:root:current mean train loss 1398.8911164249787
INFO:root:current train perplexity3.0131044387817383
INFO:root:current mean train loss 1399.7425481939936
INFO:root:current train perplexity3.0143957138061523

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.58s/it]
INFO:root:final mean train loss: 1399.5798804917483
INFO:root:final train perplexity: 3.0155818462371826
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.86s/it]
INFO:root:eval mean loss: 2323.320720699662
INFO:root:eval perplexity: 6.546728134155273
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it]
INFO:root:eval mean loss: 2914.2693676238364
INFO:root:eval perplexity: 10.841370582580566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [11:48:51<18:08:02, 539.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1376.2165149507068
INFO:root:current train perplexity2.9882771968841553
INFO:root:current mean train loss 1382.23525442204
INFO:root:current train perplexity2.979074478149414
INFO:root:current mean train loss 1380.968072560208
INFO:root:current train perplexity2.9721219539642334
INFO:root:current mean train loss 1380.5857251262107
INFO:root:current train perplexity2.9734930992126465
INFO:root:current mean train loss 1382.6083730291996
INFO:root:current train perplexity2.9782025814056396
INFO:root:current mean train loss 1383.2145277635639
INFO:root:current train perplexity2.9806578159332275
INFO:root:current mean train loss 1385.52759207372
INFO:root:current train perplexity2.9839882850646973
INFO:root:current mean train loss 1386.8755809033335
INFO:root:current train perplexity2.9850993156433105
INFO:root:current mean train loss 1387.714562350384
INFO:root:current train perplexity2.9859752655029297
INFO:root:current mean train loss 1388.3736044849306
INFO:root:current train perplexity2.987853527069092
INFO:root:current mean train loss 1388.4501436493447
INFO:root:current train perplexity2.98728346824646
INFO:root:current mean train loss 1389.0830221359868
INFO:root:current train perplexity2.9901018142700195
INFO:root:current mean train loss 1389.700332911886
INFO:root:current train perplexity2.9909799098968506
INFO:root:current mean train loss 1390.379210425205
INFO:root:current train perplexity2.9938130378723145
INFO:root:current mean train loss 1390.5229945930132
INFO:root:current train perplexity2.995753765106201
INFO:root:current mean train loss 1391.0832395244356
INFO:root:current train perplexity2.996304750442505
INFO:root:current mean train loss 1391.6144986077145
INFO:root:current train perplexity2.9966487884521484
INFO:root:current mean train loss 1392.1125360745102
INFO:root:current train perplexity2.997126579284668
INFO:root:current mean train loss 1392.470970128957
INFO:root:current train perplexity2.9974470138549805
INFO:root:current mean train loss 1392.629801474197
INFO:root:current train perplexity2.998706340789795

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.00s/it]
INFO:root:final mean train loss: 1392.6316524011224
INFO:root:final train perplexity: 2.9991025924682617
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it]
INFO:root:eval mean loss: 2327.257076182264
INFO:root:eval perplexity: 6.567602634429932
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 2921.1605341485206
INFO:root:eval perplexity: 10.902642250061035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [11:57:46<17:56:23, 538.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1360.0359321206304
INFO:root:current train perplexity2.932943820953369
INFO:root:current mean train loss 1363.0807813728381
INFO:root:current train perplexity2.95200777053833
INFO:root:current mean train loss 1369.1018221939853
INFO:root:current train perplexity2.9472970962524414
INFO:root:current mean train loss 1372.887795961003
INFO:root:current train perplexity2.957519292831421
INFO:root:current mean train loss 1375.2874106945296
INFO:root:current train perplexity2.9594597816467285
INFO:root:current mean train loss 1378.6356685959163
INFO:root:current train perplexity2.965775489807129
INFO:root:current mean train loss 1378.8885599926498
INFO:root:current train perplexity2.9682607650756836
INFO:root:current mean train loss 1380.0890230322073
INFO:root:current train perplexity2.967259645462036
INFO:root:current mean train loss 1380.6008918948723
INFO:root:current train perplexity2.9676852226257324
INFO:root:current mean train loss 1381.5247577432547
INFO:root:current train perplexity2.9684391021728516
INFO:root:current mean train loss 1383.322046613108
INFO:root:current train perplexity2.973034620285034
INFO:root:current mean train loss 1383.260345116682
INFO:root:current train perplexity2.9737179279327393
INFO:root:current mean train loss 1384.8196028632906
INFO:root:current train perplexity2.9752984046936035
INFO:root:current mean train loss 1384.474904894741
INFO:root:current train perplexity2.977017879486084
INFO:root:current mean train loss 1385.3924905255365
INFO:root:current train perplexity2.9786629676818848
INFO:root:current mean train loss 1386.1305668447321
INFO:root:current train perplexity2.9807207584381104
INFO:root:current mean train loss 1386.113996895485
INFO:root:current train perplexity2.9810962677001953
INFO:root:current mean train loss 1385.5951527329316
INFO:root:current train perplexity2.981480121612549
INFO:root:current mean train loss 1385.9316196780233
INFO:root:current train perplexity2.9821348190307617
INFO:root:current mean train loss 1386.0157106174627
INFO:root:current train perplexity2.9831020832061768

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.82s/it]
INFO:root:final mean train loss: 1385.9530172727953
INFO:root:final train perplexity: 2.9833474159240723
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it]
INFO:root:eval mean loss: 2337.274779840564
INFO:root:eval perplexity: 6.621028423309326
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2930.6613012002713
INFO:root:eval perplexity: 10.987689018249512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [12:06:43<17:46:39, 537.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1358.4286948756169
INFO:root:current train perplexity2.9323489665985107
INFO:root:current mean train loss 1365.7710945822976
INFO:root:current train perplexity2.933849811553955
INFO:root:current mean train loss 1367.7730151190274
INFO:root:current train perplexity2.9370923042297363
INFO:root:current mean train loss 1369.8056913335272
INFO:root:current train perplexity2.9384589195251465
INFO:root:current mean train loss 1372.2989889192982
INFO:root:current train perplexity2.9430251121520996
INFO:root:current mean train loss 1371.7062861124675
INFO:root:current train perplexity2.9418046474456787
INFO:root:current mean train loss 1372.0944439588918
INFO:root:current train perplexity2.942868232727051
INFO:root:current mean train loss 1372.329345860432
INFO:root:current train perplexity2.94452166557312
INFO:root:current mean train loss 1372.2902019622663
INFO:root:current train perplexity2.9467296600341797
INFO:root:current mean train loss 1373.1444652119621
INFO:root:current train perplexity2.947676658630371
INFO:root:current mean train loss 1374.350384680312
INFO:root:current train perplexity2.9493801593780518
INFO:root:current mean train loss 1375.002038034452
INFO:root:current train perplexity2.9514617919921875
INFO:root:current mean train loss 1375.701314991918
INFO:root:current train perplexity2.954878330230713
INFO:root:current mean train loss 1376.2054183427679
INFO:root:current train perplexity2.958052635192871
INFO:root:current mean train loss 1377.2704748965214
INFO:root:current train perplexity2.9605143070220947
INFO:root:current mean train loss 1377.6870168308317
INFO:root:current train perplexity2.9614574909210205
INFO:root:current mean train loss 1378.4085374345075
INFO:root:current train perplexity2.964151620864868
INFO:root:current mean train loss 1378.6688897072731
INFO:root:current train perplexity2.9656145572662354
INFO:root:current mean train loss 1379.0703897374526
INFO:root:current train perplexity2.966337203979492
INFO:root:current mean train loss 1379.519733691505
INFO:root:current train perplexity2.967266321182251

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.13s/it]
INFO:root:final mean train loss: 1379.1262654868628
INFO:root:final train perplexity: 2.967327833175659
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it]
INFO:root:eval mean loss: 2341.7157350364305
INFO:root:eval perplexity: 6.64484977722168
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it]
INFO:root:eval mean loss: 2936.448595412234
INFO:root:eval perplexity: 11.039815902709961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [12:15:39<17:36:41, 537.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1353.249026062668
INFO:root:current train perplexity2.944427728652954
INFO:root:current mean train loss 1359.4315824360428
INFO:root:current train perplexity2.934434413909912
INFO:root:current mean train loss 1365.4805391591563
INFO:root:current train perplexity2.92978835105896
INFO:root:current mean train loss 1363.633500504433
INFO:root:current train perplexity2.9306819438934326
INFO:root:current mean train loss 1364.591122393192
INFO:root:current train perplexity2.9308834075927734
INFO:root:current mean train loss 1365.3595330944352
INFO:root:current train perplexity2.929622173309326
INFO:root:current mean train loss 1364.6203944438807
INFO:root:current train perplexity2.9293742179870605
INFO:root:current mean train loss 1365.5125644679028
INFO:root:current train perplexity2.932790994644165
INFO:root:current mean train loss 1366.1193590666119
INFO:root:current train perplexity2.935805320739746
INFO:root:current mean train loss 1366.0038564630145
INFO:root:current train perplexity2.9368410110473633
INFO:root:current mean train loss 1366.5342879090306
INFO:root:current train perplexity2.939537286758423
INFO:root:current mean train loss 1367.5722843499516
INFO:root:current train perplexity2.9416985511779785
INFO:root:current mean train loss 1368.3832678326505
INFO:root:current train perplexity2.942108392715454
INFO:root:current mean train loss 1369.2595605679064
INFO:root:current train perplexity2.943817615509033
INFO:root:current mean train loss 1370.399688945548
INFO:root:current train perplexity2.9460041522979736
INFO:root:current mean train loss 1370.8914327483767
INFO:root:current train perplexity2.947902202606201
INFO:root:current mean train loss 1371.390004554023
INFO:root:current train perplexity2.949354648590088
INFO:root:current mean train loss 1372.223324879414
INFO:root:current train perplexity2.950202465057373
INFO:root:current mean train loss 1372.8753994207689
INFO:root:current train perplexity2.951437473297119

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.09s/it]
INFO:root:final mean train loss: 1372.9366367049608
INFO:root:final train perplexity: 2.952878475189209
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it]
INFO:root:eval mean loss: 2344.0761917871787
INFO:root:eval perplexity: 6.657547950744629
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it]
INFO:root:eval mean loss: 2939.4931268353835
INFO:root:eval perplexity: 11.067337036132812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [12:24:35<17:27:04, 536.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1369.42431640625
INFO:root:current train perplexity2.8871047496795654
INFO:root:current mean train loss 1351.693485884233
INFO:root:current train perplexity2.9011385440826416
INFO:root:current mean train loss 1355.7374128069196
INFO:root:current train perplexity2.902845859527588
INFO:root:current mean train loss 1357.4740777784777
INFO:root:current train perplexity2.910954236984253
INFO:root:current mean train loss 1354.9129814334033
INFO:root:current train perplexity2.9158976078033447
INFO:root:current mean train loss 1355.6623034907323
INFO:root:current train perplexity2.9212517738342285
INFO:root:current mean train loss 1356.2077144435195
INFO:root:current train perplexity2.923819065093994
INFO:root:current mean train loss 1357.677177149813
INFO:root:current train perplexity2.925316095352173
INFO:root:current mean train loss 1358.5107230480805
INFO:root:current train perplexity2.9256575107574463
INFO:root:current mean train loss 1359.9832330389338
INFO:root:current train perplexity2.9272735118865967
INFO:root:current mean train loss 1361.4313144192838
INFO:root:current train perplexity2.928399085998535
INFO:root:current mean train loss 1363.0020656276395
INFO:root:current train perplexity2.930482864379883
INFO:root:current mean train loss 1363.850946599787
INFO:root:current train perplexity2.930650234222412
INFO:root:current mean train loss 1363.9516746928673
INFO:root:current train perplexity2.9308080673217773
INFO:root:current mean train loss 1364.3340455833056
INFO:root:current train perplexity2.9317538738250732
INFO:root:current mean train loss 1364.651036304196
INFO:root:current train perplexity2.9323627948760986
INFO:root:current mean train loss 1364.6898108440896
INFO:root:current train perplexity2.932049036026001
INFO:root:current mean train loss 1365.3426835623402
INFO:root:current train perplexity2.93350887298584
INFO:root:current mean train loss 1365.9833129208391
INFO:root:current train perplexity2.93565034866333
INFO:root:current mean train loss 1366.3953261130766
INFO:root:current train perplexity2.936159372329712

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.79s/it]
INFO:root:final mean train loss: 1366.2776588674633
INFO:root:final train perplexity: 2.937411308288574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it]
INFO:root:eval mean loss: 2351.4984719567265
INFO:root:eval perplexity: 6.697631359100342
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it]
INFO:root:eval mean loss: 2949.760589383173
INFO:root:eval perplexity: 11.160661697387695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [12:33:32<17:18:05, 536.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1343.339269567419
INFO:root:current train perplexity2.909355401992798
INFO:root:current mean train loss 1345.3165312038632
INFO:root:current train perplexity2.8986730575561523
INFO:root:current mean train loss 1352.2278746214206
INFO:root:current train perplexity2.903203248977661
INFO:root:current mean train loss 1353.298024028813
INFO:root:current train perplexity2.8989198207855225
INFO:root:current mean train loss 1354.230505342506
INFO:root:current train perplexity2.8965115547180176
INFO:root:current mean train loss 1353.4107033658977
INFO:root:current train perplexity2.901360034942627
INFO:root:current mean train loss 1353.2485851914498
INFO:root:current train perplexity2.903460741043091
INFO:root:current mean train loss 1353.8122125386865
INFO:root:current train perplexity2.904327392578125
INFO:root:current mean train loss 1353.7728702494426
INFO:root:current train perplexity2.9061028957366943
INFO:root:current mean train loss 1354.0276554440989
INFO:root:current train perplexity2.9074771404266357
INFO:root:current mean train loss 1355.2492514130204
INFO:root:current train perplexity2.907724618911743
INFO:root:current mean train loss 1355.2898601271352
INFO:root:current train perplexity2.911010980606079
INFO:root:current mean train loss 1356.0566285870964
INFO:root:current train perplexity2.911761999130249
INFO:root:current mean train loss 1357.0429078528282
INFO:root:current train perplexity2.9138102531433105
INFO:root:current mean train loss 1357.784432468
INFO:root:current train perplexity2.915666103363037
INFO:root:current mean train loss 1358.445985605456
INFO:root:current train perplexity2.917638063430786
INFO:root:current mean train loss 1358.707906524902
INFO:root:current train perplexity2.9190502166748047
INFO:root:current mean train loss 1359.9554774157905
INFO:root:current train perplexity2.920764923095703
INFO:root:current mean train loss 1360.330350461395
INFO:root:current train perplexity2.9227311611175537
INFO:root:current mean train loss 1360.9302906299665
INFO:root:current train perplexity2.9237751960754395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.73s/it]
INFO:root:final mean train loss: 1360.4060547983051
INFO:root:final train perplexity: 2.9238405227661133
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.86s/it]
INFO:root:eval mean loss: 2359.089628611896
INFO:root:eval perplexity: 6.738876819610596
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it]
INFO:root:eval mean loss: 2957.329975101119
INFO:root:eval perplexity: 11.229966163635254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [12:42:28<17:08:29, 536.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1339.7148465243254
INFO:root:current train perplexity2.8544726371765137
INFO:root:current mean train loss 1345.6112238566081
INFO:root:current train perplexity2.871387481689453
INFO:root:current mean train loss 1344.507007536341
INFO:root:current train perplexity2.8759396076202393
INFO:root:current mean train loss 1343.064953471339
INFO:root:current train perplexity2.8778269290924072
INFO:root:current mean train loss 1343.548880637229
INFO:root:current train perplexity2.8824565410614014
INFO:root:current mean train loss 1345.880002414479
INFO:root:current train perplexity2.8847148418426514
INFO:root:current mean train loss 1345.4853773413238
INFO:root:current train perplexity2.888292074203491
INFO:root:current mean train loss 1346.4595438639324
INFO:root:current train perplexity2.889997720718384
INFO:root:current mean train loss 1347.6187175732653
INFO:root:current train perplexity2.8915956020355225
INFO:root:current mean train loss 1348.6139487573655
INFO:root:current train perplexity2.8942580223083496
INFO:root:current mean train loss 1349.5544039554522
INFO:root:current train perplexity2.8962364196777344
INFO:root:current mean train loss 1350.1727800702715
INFO:root:current train perplexity2.8975989818573
INFO:root:current mean train loss 1350.7311787988594
INFO:root:current train perplexity2.899176597595215
INFO:root:current mean train loss 1351.639113925752
INFO:root:current train perplexity2.900195360183716
INFO:root:current mean train loss 1352.428407283371
INFO:root:current train perplexity2.90114426612854
INFO:root:current mean train loss 1352.3228121742684
INFO:root:current train perplexity2.9028966426849365
INFO:root:current mean train loss 1352.7551102464217
INFO:root:current train perplexity2.9049551486968994
INFO:root:current mean train loss 1352.9892804207059
INFO:root:current train perplexity2.9069132804870605
INFO:root:current mean train loss 1353.5311626839793
INFO:root:current train perplexity2.9080567359924316
INFO:root:current mean train loss 1354.0885412271132
INFO:root:current train perplexity2.908952474594116

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.23s/it]
INFO:root:final mean train loss: 1354.023068611272
INFO:root:final train perplexity: 2.9091591835021973
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.88s/it]
INFO:root:eval mean loss: 2360.5884568234706
INFO:root:eval perplexity: 6.747049331665039
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.31s/it]
INFO:root:eval mean loss: 2961.428545146969
INFO:root:eval perplexity: 11.267671585083008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [12:51:24<16:59:22, 536.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1326.70367331583
INFO:root:current train perplexity2.8552470207214355
INFO:root:current mean train loss 1332.6073134523
INFO:root:current train perplexity2.864889144897461
INFO:root:current mean train loss 1334.0101921695402
INFO:root:current train perplexity2.8630387783050537
INFO:root:current mean train loss 1333.5707967235112
INFO:root:current train perplexity2.8675389289855957
INFO:root:current mean train loss 1337.0295412804196
INFO:root:current train perplexity2.8692073822021484
INFO:root:current mean train loss 1339.4789371048491
INFO:root:current train perplexity2.8712339401245117
INFO:root:current mean train loss 1340.0357437018367
INFO:root:current train perplexity2.8755340576171875
INFO:root:current mean train loss 1339.9833086091492
INFO:root:current train perplexity2.8764243125915527
INFO:root:current mean train loss 1340.579420845129
INFO:root:current train perplexity2.876978874206543
INFO:root:current mean train loss 1341.4581655766292
INFO:root:current train perplexity2.8784279823303223
INFO:root:current mean train loss 1342.0312175552986
INFO:root:current train perplexity2.8805530071258545
INFO:root:current mean train loss 1343.1113887921579
INFO:root:current train perplexity2.8807899951934814
INFO:root:current mean train loss 1343.627846532545
INFO:root:current train perplexity2.8838493824005127
INFO:root:current mean train loss 1344.5757624326955
INFO:root:current train perplexity2.884997606277466
INFO:root:current mean train loss 1344.7295034670976
INFO:root:current train perplexity2.887172222137451
INFO:root:current mean train loss 1345.6457915223614
INFO:root:current train perplexity2.888826847076416
INFO:root:current mean train loss 1346.1452121539405
INFO:root:current train perplexity2.8914971351623535
INFO:root:current mean train loss 1347.01425581612
INFO:root:current train perplexity2.892228126525879
INFO:root:current mean train loss 1347.6026028198046
INFO:root:current train perplexity2.893178701400757
INFO:root:current mean train loss 1348.4465817573544
INFO:root:current train perplexity2.8953609466552734

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.44s/it]
INFO:root:final mean train loss: 1348.089232074932
INFO:root:final train perplexity: 2.8955767154693604
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it]
INFO:root:eval mean loss: 2365.318920811863
INFO:root:eval perplexity: 6.772911548614502
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.25s/it]
INFO:root:eval mean loss: 2966.7731457432956
INFO:root:eval perplexity: 11.31702995300293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [13:00:21<16:50:28, 536.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1328.2879419571314
INFO:root:current train perplexity2.8469393253326416
INFO:root:current mean train loss 1329.3116036747278
INFO:root:current train perplexity2.854818344116211
INFO:root:current mean train loss 1332.978773377782
INFO:root:current train perplexity2.8596339225769043
INFO:root:current mean train loss 1333.8393031529017
INFO:root:current train perplexity2.8605873584747314
INFO:root:current mean train loss 1333.514049067158
INFO:root:current train perplexity2.8649609088897705
INFO:root:current mean train loss 1332.4628739406494
INFO:root:current train perplexity2.865586757659912
INFO:root:current mean train loss 1333.6424468724074
INFO:root:current train perplexity2.867276430130005
INFO:root:current mean train loss 1335.563685870722
INFO:root:current train perplexity2.8688607215881348
INFO:root:current mean train loss 1335.358857939075
INFO:root:current train perplexity2.8677289485931396
INFO:root:current mean train loss 1335.7535600096658
INFO:root:current train perplexity2.868086338043213
INFO:root:current mean train loss 1335.6288255114723
INFO:root:current train perplexity2.868143320083618
INFO:root:current mean train loss 1336.5999641871817
INFO:root:current train perplexity2.871297597885132
INFO:root:current mean train loss 1336.9181112608812
INFO:root:current train perplexity2.8727529048919678
INFO:root:current mean train loss 1338.4220578397133
INFO:root:current train perplexity2.874680519104004
INFO:root:current mean train loss 1339.5992702540912
INFO:root:current train perplexity2.8758552074432373
INFO:root:current mean train loss 1340.4370611502643
INFO:root:current train perplexity2.8758180141448975
INFO:root:current mean train loss 1341.140601357061
INFO:root:current train perplexity2.877901554107666
INFO:root:current mean train loss 1341.4850076647524
INFO:root:current train perplexity2.8800525665283203
INFO:root:current mean train loss 1341.9456985359882
INFO:root:current train perplexity2.8807485103607178
INFO:root:current mean train loss 1342.1509069861247
INFO:root:current train perplexity2.8813316822052

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.87s/it]
INFO:root:final mean train loss: 1341.8495529259446
INFO:root:final train perplexity: 2.8813626766204834
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.86s/it]
INFO:root:eval mean loss: 2373.624619071365
INFO:root:eval perplexity: 6.818560600280762
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.15s/it]
INFO:root:eval mean loss: 2976.529487772191
INFO:root:eval perplexity: 11.40769100189209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [13:09:16<16:41:08, 536.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1318.836800986842
INFO:root:current train perplexity2.8266234397888184
INFO:root:current mean train loss 1319.1557116386218
INFO:root:current train perplexity2.8278579711914062
INFO:root:current mean train loss 1324.0066236592957
INFO:root:current train perplexity2.83575439453125
INFO:root:current mean train loss 1324.994124864023
INFO:root:current train perplexity2.843345880508423
INFO:root:current mean train loss 1324.4467457780934
INFO:root:current train perplexity2.8473589420318604
INFO:root:current mean train loss 1325.9646026867779
INFO:root:current train perplexity2.847287178039551
INFO:root:current mean train loss 1325.455098850607
INFO:root:current train perplexity2.8471226692199707
INFO:root:current mean train loss 1327.3724449685535
INFO:root:current train perplexity2.850637912750244
INFO:root:current mean train loss 1328.7098941057088
INFO:root:current train perplexity2.8528201580047607
INFO:root:current mean train loss 1329.719625716473
INFO:root:current train perplexity2.852574586868286
INFO:root:current mean train loss 1330.146571440675
INFO:root:current train perplexity2.8542022705078125
INFO:root:current mean train loss 1331.1681675356301
INFO:root:current train perplexity2.8560025691986084
INFO:root:current mean train loss 1330.711750139509
INFO:root:current train perplexity2.8572051525115967
INFO:root:current mean train loss 1331.3512706688227
INFO:root:current train perplexity2.8581180572509766
INFO:root:current mean train loss 1331.8659347074886
INFO:root:current train perplexity2.8589959144592285
INFO:root:current mean train loss 1332.3461826049422
INFO:root:current train perplexity2.8613710403442383
INFO:root:current mean train loss 1333.2625999608222
INFO:root:current train perplexity2.862309455871582
INFO:root:current mean train loss 1334.3896910090964
INFO:root:current train perplexity2.8635337352752686
INFO:root:current mean train loss 1335.1729586236395
INFO:root:current train perplexity2.8652894496917725

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.50s/it]
INFO:root:final mean train loss: 1335.4371672152752
INFO:root:final train perplexity: 2.8668272495269775
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it]
INFO:root:eval mean loss: 2377.4119409872287
INFO:root:eval perplexity: 6.839477062225342
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it]
INFO:root:eval mean loss: 2982.658832090121
INFO:root:eval perplexity: 11.465015411376953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [13:18:12<16:31:44, 536.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1314.5760091145833
INFO:root:current train perplexity2.8228719234466553
INFO:root:current mean train loss 1311.7920750209264
INFO:root:current train perplexity2.825515031814575
INFO:root:current mean train loss 1312.8988019835274
INFO:root:current train perplexity2.8294522762298584
INFO:root:current mean train loss 1316.834463657477
INFO:root:current train perplexity2.8305912017822266
INFO:root:current mean train loss 1319.8122188234793
INFO:root:current train perplexity2.8323886394500732
INFO:root:current mean train loss 1319.9358921051025
INFO:root:current train perplexity2.830152988433838
INFO:root:current mean train loss 1320.6597966212853
INFO:root:current train perplexity2.8369009494781494
INFO:root:current mean train loss 1321.148324173488
INFO:root:current train perplexity2.8377463817596436
INFO:root:current mean train loss 1324.0145624470829
INFO:root:current train perplexity2.8413660526275635
INFO:root:current mean train loss 1325.1564715201393
INFO:root:current train perplexity2.8417840003967285
INFO:root:current mean train loss 1325.5340808973954
INFO:root:current train perplexity2.8413894176483154
INFO:root:current mean train loss 1326.5263598325441
INFO:root:current train perplexity2.844287872314453
INFO:root:current mean train loss 1327.5998427387906
INFO:root:current train perplexity2.8469648361206055
INFO:root:current mean train loss 1327.4312602717703
INFO:root:current train perplexity2.848869800567627
INFO:root:current mean train loss 1327.482914219497
INFO:root:current train perplexity2.8488121032714844
INFO:root:current mean train loss 1327.872822352818
INFO:root:current train perplexity2.849557399749756
INFO:root:current mean train loss 1328.8114241607136
INFO:root:current train perplexity2.8515541553497314
INFO:root:current mean train loss 1329.015241961613
INFO:root:current train perplexity2.8518259525299072
INFO:root:current mean train loss 1329.1272553366014
INFO:root:current train perplexity2.8525867462158203
INFO:root:current mean train loss 1329.2863589490307
INFO:root:current train perplexity2.8524746894836426

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.26s/it]
INFO:root:final mean train loss: 1329.570538450117
INFO:root:final train perplexity: 2.8535943031311035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it]
INFO:root:eval mean loss: 2382.194069720329
INFO:root:eval perplexity: 6.8659796714782715
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2986.5941733502327
INFO:root:eval perplexity: 11.501974105834961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [13:27:07<16:22:21, 535.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1319.8838479929957
INFO:root:current train perplexity2.8148107528686523
INFO:root:current mean train loss 1316.297117248062
INFO:root:current train perplexity2.8002896308898926
INFO:root:current mean train loss 1309.6070540648882
INFO:root:current train perplexity2.806621551513672
INFO:root:current mean train loss 1314.1268896781203
INFO:root:current train perplexity2.8105227947235107
INFO:root:current mean train loss 1314.6594027717074
INFO:root:current train perplexity2.8121635913848877
INFO:root:current mean train loss 1316.233267367675
INFO:root:current train perplexity2.814026117324829
INFO:root:current mean train loss 1317.2728812940927
INFO:root:current train perplexity2.8180718421936035
INFO:root:current mean train loss 1317.226519967957
INFO:root:current train perplexity2.817986011505127
INFO:root:current mean train loss 1318.982609618846
INFO:root:current train perplexity2.8193612098693848
INFO:root:current mean train loss 1319.5599829075284
INFO:root:current train perplexity2.8220725059509277
INFO:root:current mean train loss 1319.7602007599914
INFO:root:current train perplexity2.824737071990967
INFO:root:current mean train loss 1320.521838584339
INFO:root:current train perplexity2.8280539512634277
INFO:root:current mean train loss 1321.7986412948471
INFO:root:current train perplexity2.8300788402557373
INFO:root:current mean train loss 1322.4892513829125
INFO:root:current train perplexity2.8310043811798096
INFO:root:current mean train loss 1323.1499338650553
INFO:root:current train perplexity2.833009719848633
INFO:root:current mean train loss 1323.4082682717462
INFO:root:current train perplexity2.8349273204803467
INFO:root:current mean train loss 1323.1918952056717
INFO:root:current train perplexity2.8352887630462646
INFO:root:current mean train loss 1323.6603107264857
INFO:root:current train perplexity2.8381474018096924
INFO:root:current mean train loss 1324.5087924663196
INFO:root:current train perplexity2.8395650386810303
INFO:root:current mean train loss 1324.5466016232504
INFO:root:current train perplexity2.8410696983337402

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.22s/it]
INFO:root:final mean train loss: 1324.1551065218912
INFO:root:final train perplexity: 2.841432809829712
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.96s/it]
INFO:root:eval mean loss: 2389.731480808123
INFO:root:eval perplexity: 6.907961845397949
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.15s/it]
INFO:root:eval mean loss: 2996.4268798828125
INFO:root:eval perplexity: 11.594841957092285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [13:36:04<16:14:14, 536.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1315.974168860394
INFO:root:current train perplexity2.7849864959716797
INFO:root:current mean train loss 1310.2848243190817
INFO:root:current train perplexity2.801527261734009
INFO:root:current mean train loss 1307.7584109422637
INFO:root:current train perplexity2.8026785850524902
INFO:root:current mean train loss 1307.4937123204932
INFO:root:current train perplexity2.8044307231903076
INFO:root:current mean train loss 1309.4981161211638
INFO:root:current train perplexity2.8110930919647217
INFO:root:current mean train loss 1310.639172899854
INFO:root:current train perplexity2.8107826709747314
INFO:root:current mean train loss 1310.0042592335042
INFO:root:current train perplexity2.8114898204803467
INFO:root:current mean train loss 1312.3936749578481
INFO:root:current train perplexity2.8155863285064697
INFO:root:current mean train loss 1313.059627163213
INFO:root:current train perplexity2.818629741668701
INFO:root:current mean train loss 1313.8617218211136
INFO:root:current train perplexity2.8183345794677734
INFO:root:current mean train loss 1314.8046667270405
INFO:root:current train perplexity2.8200247287750244
INFO:root:current mean train loss 1314.7351578051714
INFO:root:current train perplexity2.820038318634033
INFO:root:current mean train loss 1315.490733824802
INFO:root:current train perplexity2.8197312355041504
INFO:root:current mean train loss 1316.2252008627995
INFO:root:current train perplexity2.821465253829956
INFO:root:current mean train loss 1316.8293705224003
INFO:root:current train perplexity2.822326898574829
INFO:root:current mean train loss 1317.3513359671886
INFO:root:current train perplexity2.824295997619629
INFO:root:current mean train loss 1317.5637955323748
INFO:root:current train perplexity2.8245606422424316
INFO:root:current mean train loss 1317.7851958214758
INFO:root:current train perplexity2.825411081314087
INFO:root:current mean train loss 1318.0744747934723
INFO:root:current train perplexity2.8276164531707764
INFO:root:current mean train loss 1318.402626970689
INFO:root:current train perplexity2.8279902935028076

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.11s/it]
INFO:root:final mean train loss: 1318.2409366332577
INFO:root:final train perplexity: 2.8282105922698975
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.86s/it]
INFO:root:eval mean loss: 2394.037356112866
INFO:root:eval perplexity: 6.932057857513428
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.25s/it]
INFO:root:eval mean loss: 3000.7999284893062
INFO:root:eval perplexity: 11.636384963989258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [13:45:01<16:05:13, 536.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1305.8421592106895
INFO:root:current train perplexity2.778327465057373
INFO:root:current mean train loss 1304.208156843127
INFO:root:current train perplexity2.7929248809814453
INFO:root:current mean train loss 1305.2911576535764
INFO:root:current train perplexity2.8000779151916504
INFO:root:current mean train loss 1303.4224191040375
INFO:root:current train perplexity2.8000078201293945
INFO:root:current mean train loss 1305.4100753092096
INFO:root:current train perplexity2.799792528152466
INFO:root:current mean train loss 1306.200035732127
INFO:root:current train perplexity2.8006033897399902
INFO:root:current mean train loss 1305.9517174169848
INFO:root:current train perplexity2.800431489944458
INFO:root:current mean train loss 1306.3511842900148
INFO:root:current train perplexity2.801377296447754
INFO:root:current mean train loss 1305.2131011008112
INFO:root:current train perplexity2.801103115081787
INFO:root:current mean train loss 1306.3709189473407
INFO:root:current train perplexity2.8017923831939697
INFO:root:current mean train loss 1307.1677613567879
INFO:root:current train perplexity2.8046958446502686
INFO:root:current mean train loss 1307.6000868452077
INFO:root:current train perplexity2.807368040084839
INFO:root:current mean train loss 1308.3324023901425
INFO:root:current train perplexity2.8093814849853516
INFO:root:current mean train loss 1309.1918622000815
INFO:root:current train perplexity2.8117010593414307
INFO:root:current mean train loss 1309.4841102501014
INFO:root:current train perplexity2.8120646476745605
INFO:root:current mean train loss 1310.179111200041
INFO:root:current train perplexity2.811863899230957
INFO:root:current mean train loss 1311.3188296723495
INFO:root:current train perplexity2.813235282897949
INFO:root:current mean train loss 1311.828933516755
INFO:root:current train perplexity2.8151981830596924
INFO:root:current mean train loss 1312.2734998128649
INFO:root:current train perplexity2.8155806064605713
INFO:root:current mean train loss 1312.8606714451732
INFO:root:current train perplexity2.8158493041992188

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.68s/it]
INFO:root:final mean train loss: 1312.8725542538825
INFO:root:final train perplexity: 2.8162615299224854
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 27.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 27.00s/it]
INFO:root:eval mean loss: 2398.6877813677415
INFO:root:eval perplexity: 6.958178997039795
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.30s/it]
INFO:root:eval mean loss: 3008.552413182901
INFO:root:eval perplexity: 11.710391998291016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [13:53:56<15:56:05, 536.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1302.9225830078126
INFO:root:current train perplexity2.776050090789795
INFO:root:current mean train loss 1295.2646321614584
INFO:root:current train perplexity2.780538558959961
INFO:root:current mean train loss 1296.7647770472936
INFO:root:current train perplexity2.7819817066192627
INFO:root:current mean train loss 1296.272511693051
INFO:root:current train perplexity2.782454013824463
INFO:root:current mean train loss 1295.7822003682454
INFO:root:current train perplexity2.782461643218994
INFO:root:current mean train loss 1296.5020070043104
INFO:root:current train perplexity2.78212571144104
INFO:root:current mean train loss 1297.357496732824
INFO:root:current train perplexity2.785639524459839
INFO:root:current mean train loss 1298.4672092535557
INFO:root:current train perplexity2.789984703063965
INFO:root:current mean train loss 1299.6172040072354
INFO:root:current train perplexity2.7929999828338623
INFO:root:current mean train loss 1299.858114188058
INFO:root:current train perplexity2.7915589809417725
INFO:root:current mean train loss 1301.1275162308305
INFO:root:current train perplexity2.7913687229156494
INFO:root:current mean train loss 1301.2598236601232
INFO:root:current train perplexity2.793290138244629
INFO:root:current mean train loss 1302.4398041725158
INFO:root:current train perplexity2.7927017211914062
INFO:root:current mean train loss 1302.990276126585
INFO:root:current train perplexity2.794912815093994
INFO:root:current mean train loss 1304.3683959960938
INFO:root:current train perplexity2.7976059913635254
INFO:root:current mean train loss 1305.1665760668018
INFO:root:current train perplexity2.7974531650543213
INFO:root:current mean train loss 1305.284697105771
INFO:root:current train perplexity2.7977042198181152
INFO:root:current mean train loss 1305.950235431114
INFO:root:current train perplexity2.799823760986328
INFO:root:current mean train loss 1306.7680649777676
INFO:root:current train perplexity2.801905632019043
INFO:root:current mean train loss 1307.6761466594658
INFO:root:current train perplexity2.803990364074707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.12s/it]
INFO:root:final mean train loss: 1307.351637385797
INFO:root:final train perplexity: 2.804025888442993
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it]
INFO:root:eval mean loss: 2403.5965394365026
INFO:root:eval perplexity: 6.985857963562012
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.17s/it]
INFO:root:eval mean loss: 3013.4343369937114
INFO:root:eval perplexity: 11.757242202758789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [14:02:53<15:47:10, 536.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1289.5825535095844
INFO:root:current train perplexity2.746183395385742
INFO:root:current mean train loss 1292.0021786762372
INFO:root:current train perplexity2.754861831665039
INFO:root:current mean train loss 1292.1807142058608
INFO:root:current train perplexity2.7643702030181885
INFO:root:current mean train loss 1293.215532509446
INFO:root:current train perplexity2.7679479122161865
INFO:root:current mean train loss 1294.7606807839222
INFO:root:current train perplexity2.7718214988708496
INFO:root:current mean train loss 1294.0684432088829
INFO:root:current train perplexity2.7728612422943115
INFO:root:current mean train loss 1293.087703929228
INFO:root:current train perplexity2.7739248275756836
INFO:root:current mean train loss 1294.0778130084987
INFO:root:current train perplexity2.7751097679138184
INFO:root:current mean train loss 1295.6520998815497
INFO:root:current train perplexity2.7770743370056152
INFO:root:current mean train loss 1296.4141913043818
INFO:root:current train perplexity2.7791855335235596
INFO:root:current mean train loss 1297.8272915390696
INFO:root:current train perplexity2.781750440597534
INFO:root:current mean train loss 1298.1828617360459
INFO:root:current train perplexity2.7835934162139893
INFO:root:current mean train loss 1298.834182586317
INFO:root:current train perplexity2.786097526550293
INFO:root:current mean train loss 1299.2425163121588
INFO:root:current train perplexity2.7873237133026123
INFO:root:current mean train loss 1300.0531943607266
INFO:root:current train perplexity2.7888221740722656
INFO:root:current mean train loss 1300.2275991421905
INFO:root:current train perplexity2.7893247604370117
INFO:root:current mean train loss 1300.6606487033644
INFO:root:current train perplexity2.7903130054473877
INFO:root:current mean train loss 1301.5792781806483
INFO:root:current train perplexity2.791855573654175
INFO:root:current mean train loss 1302.0350751057385
INFO:root:current train perplexity2.7916665077209473

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.32s/it]
INFO:root:final mean train loss: 1302.170767287323
INFO:root:final train perplexity: 2.7925922870635986
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2410.326010846077
INFO:root:eval perplexity: 7.023982048034668
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 3021.4254059487203
INFO:root:eval perplexity: 11.834331512451172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [14:11:51<15:39:12, 536.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1286.5685860770088
INFO:root:current train perplexity2.7547619342803955
INFO:root:current mean train loss 1284.9850892184074
INFO:root:current train perplexity2.761314630508423
INFO:root:current mean train loss 1282.610320759711
INFO:root:current train perplexity2.7607243061065674
INFO:root:current mean train loss 1284.40853862398
INFO:root:current train perplexity2.7612409591674805
INFO:root:current mean train loss 1285.5704516719504
INFO:root:current train perplexity2.7629261016845703
INFO:root:current mean train loss 1286.5246506034168
INFO:root:current train perplexity2.7641873359680176
INFO:root:current mean train loss 1287.320027205377
INFO:root:current train perplexity2.7665607929229736
INFO:root:current mean train loss 1288.232702944459
INFO:root:current train perplexity2.7686729431152344
INFO:root:current mean train loss 1289.7310162668439
INFO:root:current train perplexity2.770455837249756
INFO:root:current mean train loss 1290.683448440919
INFO:root:current train perplexity2.772401809692383
INFO:root:current mean train loss 1290.3074432312853
INFO:root:current train perplexity2.7724573612213135
INFO:root:current mean train loss 1290.822471194036
INFO:root:current train perplexity2.7714879512786865
INFO:root:current mean train loss 1291.394697362155
INFO:root:current train perplexity2.773164987564087
INFO:root:current mean train loss 1292.3002609183254
INFO:root:current train perplexity2.7735769748687744
INFO:root:current mean train loss 1293.1118634559814
INFO:root:current train perplexity2.773742437362671
INFO:root:current mean train loss 1293.7373462913845
INFO:root:current train perplexity2.775033712387085
INFO:root:current mean train loss 1294.4629434918825
INFO:root:current train perplexity2.776329755783081
INFO:root:current mean train loss 1295.186135647038
INFO:root:current train perplexity2.7769997119903564
INFO:root:current mean train loss 1295.7797649009226
INFO:root:current train perplexity2.7777271270751953
INFO:root:current mean train loss 1296.6761417847317
INFO:root:current train perplexity2.778939723968506

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.96s/it]
INFO:root:final mean train loss: 1296.3294730366808
INFO:root:final train perplexity: 2.779756784439087
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2414.9837997111867
INFO:root:eval perplexity: 7.050491809844971
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3028.1939801155254
INFO:root:eval perplexity: 11.900022506713867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [14:20:52<15:32:50, 538.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1270.7623566658267
INFO:root:current train perplexity2.7318825721740723
INFO:root:current mean train loss 1279.1250596374045
INFO:root:current train perplexity2.7230536937713623
INFO:root:current mean train loss 1278.7439229065205
INFO:root:current train perplexity2.731405019760132
INFO:root:current mean train loss 1280.280204104513
INFO:root:current train perplexity2.7363224029541016
INFO:root:current mean train loss 1282.888367407283
INFO:root:current train perplexity2.7383275032043457
INFO:root:current mean train loss 1282.2755818914784
INFO:root:current train perplexity2.7415125370025635
INFO:root:current mean train loss 1284.0046266776446
INFO:root:current train perplexity2.7485480308532715
INFO:root:current mean train loss 1284.6621659848986
INFO:root:current train perplexity2.753445863723755
INFO:root:current mean train loss 1284.8870549942183
INFO:root:current train perplexity2.7545478343963623
INFO:root:current mean train loss 1285.3738482646347
INFO:root:current train perplexity2.7560367584228516
INFO:root:current mean train loss 1286.12162394482
INFO:root:current train perplexity2.757702112197876
INFO:root:current mean train loss 1286.2770866576177
INFO:root:current train perplexity2.7583327293395996
INFO:root:current mean train loss 1287.184802057683
INFO:root:current train perplexity2.7600128650665283
INFO:root:current mean train loss 1288.0925118713608
INFO:root:current train perplexity2.7610204219818115
INFO:root:current mean train loss 1288.583470246577
INFO:root:current train perplexity2.762871503829956
INFO:root:current mean train loss 1289.1699119881816
INFO:root:current train perplexity2.7637779712677
INFO:root:current mean train loss 1289.619125132324
INFO:root:current train perplexity2.764345645904541
INFO:root:current mean train loss 1290.4103146381697
INFO:root:current train perplexity2.7663509845733643
INFO:root:current mean train loss 1290.6957651801868
INFO:root:current train perplexity2.7664525508880615
INFO:root:current mean train loss 1291.0140818947032
INFO:root:current train perplexity2.7676944732666016

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.57s/it]
INFO:root:final mean train loss: 1290.8849521777393
INFO:root:final train perplexity: 2.7678463459014893
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2422.2231440983765
INFO:root:eval perplexity: 7.091890335083008
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3033.526594013187
INFO:root:eval perplexity: 11.952033996582031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [14:29:52<15:24:56, 538.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1279.4430872599285
INFO:root:current train perplexity2.7273685932159424
INFO:root:current mean train loss 1272.7022449390308
INFO:root:current train perplexity2.74039626121521
INFO:root:current mean train loss 1275.9349749165196
INFO:root:current train perplexity2.7430455684661865
INFO:root:current mean train loss 1275.6517902242726
INFO:root:current train perplexity2.7464311122894287
INFO:root:current mean train loss 1276.1071660178047
INFO:root:current train perplexity2.7430505752563477
INFO:root:current mean train loss 1277.6855709326528
INFO:root:current train perplexity2.7418019771575928
INFO:root:current mean train loss 1276.8132015275366
INFO:root:current train perplexity2.74178409576416
INFO:root:current mean train loss 1277.8324407077728
INFO:root:current train perplexity2.743072986602783
INFO:root:current mean train loss 1279.3146596944557
INFO:root:current train perplexity2.745187282562256
INFO:root:current mean train loss 1280.003482995657
INFO:root:current train perplexity2.7477617263793945
INFO:root:current mean train loss 1280.7046109265043
INFO:root:current train perplexity2.749330520629883
INFO:root:current mean train loss 1281.322608123673
INFO:root:current train perplexity2.7499148845672607
INFO:root:current mean train loss 1282.0727136073967
INFO:root:current train perplexity2.751464366912842
INFO:root:current mean train loss 1282.665465131358
INFO:root:current train perplexity2.751804828643799
INFO:root:current mean train loss 1283.422383092385
INFO:root:current train perplexity2.753507137298584
INFO:root:current mean train loss 1284.3154733741621
INFO:root:current train perplexity2.7540769577026367
INFO:root:current mean train loss 1284.5157402557077
INFO:root:current train perplexity2.7549636363983154
INFO:root:current mean train loss 1284.9961758751072
INFO:root:current train perplexity2.7553482055664062
INFO:root:current mean train loss 1285.0697658258084
INFO:root:current train perplexity2.7551991939544678
INFO:root:current mean train loss 1286.0172181178411
INFO:root:current train perplexity2.755842685699463

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.62s/it]
INFO:root:final mean train loss: 1285.5423025957455
INFO:root:final train perplexity: 2.7562084197998047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2425.129913979388
INFO:root:eval perplexity: 7.108582496643066
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 3039.8165525612258
INFO:root:eval perplexity: 12.013671875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [14:38:54<15:17:13, 539.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1261.5872915414664
INFO:root:current train perplexity2.716763973236084
INFO:root:current mean train loss 1260.057404119318
INFO:root:current train perplexity2.7289137840270996
INFO:root:current mean train loss 1264.6996420806308
INFO:root:current train perplexity2.725524425506592
INFO:root:current mean train loss 1265.2250414704624
INFO:root:current train perplexity2.7260501384735107
INFO:root:current mean train loss 1269.1363178868448
INFO:root:current train perplexity2.7257344722747803
INFO:root:current mean train loss 1270.1043370609789
INFO:root:current train perplexity2.7278244495391846
INFO:root:current mean train loss 1272.1595514053688
INFO:root:current train perplexity2.7295660972595215
INFO:root:current mean train loss 1272.7782781862745
INFO:root:current train perplexity2.7308175563812256
INFO:root:current mean train loss 1272.9379648550398
INFO:root:current train perplexity2.731421709060669
INFO:root:current mean train loss 1274.0662227017892
INFO:root:current train perplexity2.7346901893615723
INFO:root:current mean train loss 1275.7083941965595
INFO:root:current train perplexity2.73713755607605
INFO:root:current mean train loss 1276.90939166024
INFO:root:current train perplexity2.737104892730713
INFO:root:current mean train loss 1277.8948051120924
INFO:root:current train perplexity2.7392449378967285
INFO:root:current mean train loss 1278.5477053464115
INFO:root:current train perplexity2.7401351928710938
INFO:root:current mean train loss 1278.7369268111402
INFO:root:current train perplexity2.7409892082214355
INFO:root:current mean train loss 1279.1792142727886
INFO:root:current train perplexity2.742421865463257
INFO:root:current mean train loss 1279.8182683171453
INFO:root:current train perplexity2.7441751956939697
INFO:root:current mean train loss 1280.6350751233845
INFO:root:current train perplexity2.745195150375366
INFO:root:current mean train loss 1281.3825277783596
INFO:root:current train perplexity2.7457830905914307
INFO:root:current mean train loss 1281.8284544966602
INFO:root:current train perplexity2.7472405433654785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.68s/it]
INFO:root:final mean train loss: 1281.523769238232
INFO:root:final train perplexity: 2.7474868297576904
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2432.2995298128603
INFO:root:eval perplexity: 7.149919509887695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3047.2713198830897
INFO:root:eval perplexity: 12.087141036987305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [14:47:54<15:08:37, 539.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1265.175764874714
INFO:root:current train perplexity2.7105696201324463
INFO:root:current mean train loss 1265.9686762212398
INFO:root:current train perplexity2.717165470123291
INFO:root:current mean train loss 1263.4039246038342
INFO:root:current train perplexity2.7209861278533936
INFO:root:current mean train loss 1266.6514457982248
INFO:root:current train perplexity2.7180898189544678
INFO:root:current mean train loss 1268.8110964446641
INFO:root:current train perplexity2.7195048332214355
INFO:root:current mean train loss 1267.9547857435298
INFO:root:current train perplexity2.7200284004211426
INFO:root:current mean train loss 1268.3912496706607
INFO:root:current train perplexity2.722646951675415
INFO:root:current mean train loss 1269.082981587676
INFO:root:current train perplexity2.723660469055176
INFO:root:current mean train loss 1269.1636032831102
INFO:root:current train perplexity2.722764253616333
INFO:root:current mean train loss 1269.620305140975
INFO:root:current train perplexity2.7230188846588135
INFO:root:current mean train loss 1270.4677755810637
INFO:root:current train perplexity2.7236130237579346
INFO:root:current mean train loss 1270.6708616718222
INFO:root:current train perplexity2.723430871963501
INFO:root:current mean train loss 1271.3706278451334
INFO:root:current train perplexity2.7247557640075684
INFO:root:current mean train loss 1272.0851314119595
INFO:root:current train perplexity2.727384567260742
INFO:root:current mean train loss 1273.6014263446514
INFO:root:current train perplexity2.7303924560546875
INFO:root:current mean train loss 1274.465122304885
INFO:root:current train perplexity2.7310616970062256
INFO:root:current mean train loss 1274.6437305355184
INFO:root:current train perplexity2.7325785160064697
INFO:root:current mean train loss 1275.0086808980648
INFO:root:current train perplexity2.7329092025756836
INFO:root:current mean train loss 1275.570222017489
INFO:root:current train perplexity2.73366117477417
INFO:root:current mean train loss 1275.8198878406636
INFO:root:current train perplexity2.7344319820404053

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.11s/it]
INFO:root:final mean train loss: 1275.4760279576103
INFO:root:final train perplexity: 2.7344141006469727
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2435.5936188393453
INFO:root:eval perplexity: 7.16899299621582
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 3053.278131146803
INFO:root:eval perplexity: 12.1466703414917
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [14:56:56<15:00:35, 540.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1257.411349826389
INFO:root:current train perplexity2.689903497695923
INFO:root:current mean train loss 1259.717678971027
INFO:root:current train perplexity2.6978983879089355
INFO:root:current mean train loss 1260.7014029512438
INFO:root:current train perplexity2.7036235332489014
INFO:root:current mean train loss 1262.1208184034303
INFO:root:current train perplexity2.70561146736145
INFO:root:current mean train loss 1263.7738859065787
INFO:root:current train perplexity2.708021640777588
INFO:root:current mean train loss 1263.029769668197
INFO:root:current train perplexity2.709606170654297
INFO:root:current mean train loss 1264.0465306185176
INFO:root:current train perplexity2.7104599475860596
INFO:root:current mean train loss 1265.2588303127934
INFO:root:current train perplexity2.7108957767486572
INFO:root:current mean train loss 1265.8099431768806
INFO:root:current train perplexity2.7110588550567627
INFO:root:current mean train loss 1266.0779942540196
INFO:root:current train perplexity2.711351156234741
INFO:root:current mean train loss 1267.0400472819751
INFO:root:current train perplexity2.713632106781006
INFO:root:current mean train loss 1267.4901787866843
INFO:root:current train perplexity2.71457576751709
INFO:root:current mean train loss 1267.8257235320739
INFO:root:current train perplexity2.7153117656707764
INFO:root:current mean train loss 1268.492076511124
INFO:root:current train perplexity2.717038154602051
INFO:root:current mean train loss 1268.9047992444182
INFO:root:current train perplexity2.7186782360076904
INFO:root:current mean train loss 1269.6641700653972
INFO:root:current train perplexity2.719841480255127
INFO:root:current mean train loss 1270.0798585565037
INFO:root:current train perplexity2.720970869064331
INFO:root:current mean train loss 1270.6787732279652
INFO:root:current train perplexity2.7223353385925293
INFO:root:current mean train loss 1271.1051913116278
INFO:root:current train perplexity2.724106550216675

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.73s/it]
INFO:root:final mean train loss: 1270.93655003073
INFO:root:final train perplexity: 2.724642038345337
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2444.2344014052806
INFO:root:eval perplexity: 7.219266414642334
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 3061.2611828526706
INFO:root:eval perplexity: 12.22623062133789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [15:05:57<14:52:06, 540.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1259.5090560913086
INFO:root:current train perplexity2.6585607528686523
INFO:root:current mean train loss 1257.019952182112
INFO:root:current train perplexity2.6874470710754395
INFO:root:current mean train loss 1255.6326904296875
INFO:root:current train perplexity2.6883816719055176
INFO:root:current mean train loss 1256.0451250679885
INFO:root:current train perplexity2.689915895462036
INFO:root:current mean train loss 1258.7845353346604
INFO:root:current train perplexity2.692488670349121
INFO:root:current mean train loss 1259.5033763323643
INFO:root:current train perplexity2.6923162937164307
INFO:root:current mean train loss 1260.161977594549
INFO:root:current train perplexity2.6936049461364746
INFO:root:current mean train loss 1260.3932394528522
INFO:root:current train perplexity2.6961588859558105
INFO:root:current mean train loss 1260.2709922042548
INFO:root:current train perplexity2.696422576904297
INFO:root:current mean train loss 1261.3355639595131
INFO:root:current train perplexity2.698146343231201
INFO:root:current mean train loss 1261.6923687551905
INFO:root:current train perplexity2.6995277404785156
INFO:root:current mean train loss 1261.5276287994932
INFO:root:current train perplexity2.7012362480163574
INFO:root:current mean train loss 1262.2783311542712
INFO:root:current train perplexity2.700591802597046
INFO:root:current mean train loss 1263.3721242052443
INFO:root:current train perplexity2.7032010555267334
INFO:root:current mean train loss 1263.1667793403237
INFO:root:current train perplexity2.704075336456299
INFO:root:current mean train loss 1263.252874610921
INFO:root:current train perplexity2.705430746078491
INFO:root:current mean train loss 1263.7819109623974
INFO:root:current train perplexity2.706418037414551
INFO:root:current mean train loss 1264.3246691866077
INFO:root:current train perplexity2.7079832553863525
INFO:root:current mean train loss 1265.1967464900752
INFO:root:current train perplexity2.7106528282165527
INFO:root:current mean train loss 1265.2783210770322
INFO:root:current train perplexity2.7115092277526855

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.71s/it]
INFO:root:final mean train loss: 1265.3365079309383
INFO:root:final train perplexity: 2.712634801864624
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2447.6397847926364
INFO:root:eval perplexity: 7.239176273345947
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3066.4139694322084
INFO:root:eval perplexity: 12.277860641479492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [15:14:59<14:43:27, 540.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1231.6847034801137
INFO:root:current train perplexity2.6781675815582275
INFO:root:current mean train loss 1239.6873164356202
INFO:root:current train perplexity2.6959478855133057
INFO:root:current mean train loss 1246.5976850648806
INFO:root:current train perplexity2.6859302520751953
INFO:root:current mean train loss 1250.7046243020363
INFO:root:current train perplexity2.6852540969848633
INFO:root:current mean train loss 1252.850889280817
INFO:root:current train perplexity2.6862165927886963
INFO:root:current mean train loss 1253.8370269718134
INFO:root:current train perplexity2.6851401329040527
INFO:root:current mean train loss 1255.311323651017
INFO:root:current train perplexity2.684964418411255
INFO:root:current mean train loss 1256.1749707231093
INFO:root:current train perplexity2.687877655029297
INFO:root:current mean train loss 1256.309966564751
INFO:root:current train perplexity2.6896955966949463
INFO:root:current mean train loss 1256.9771278438589
INFO:root:current train perplexity2.691526174545288
INFO:root:current mean train loss 1257.1831118499667
INFO:root:current train perplexity2.691606283187866
INFO:root:current mean train loss 1258.2695725147216
INFO:root:current train perplexity2.6951496601104736
INFO:root:current mean train loss 1258.552198077447
INFO:root:current train perplexity2.6962451934814453
INFO:root:current mean train loss 1259.3794963633486
INFO:root:current train perplexity2.6961517333984375
INFO:root:current mean train loss 1259.5989668234527
INFO:root:current train perplexity2.697211980819702
INFO:root:current mean train loss 1259.7960142967986
INFO:root:current train perplexity2.6993746757507324
INFO:root:current mean train loss 1259.9326811006151
INFO:root:current train perplexity2.700584888458252
INFO:root:current mean train loss 1260.6933224651075
INFO:root:current train perplexity2.7019357681274414
INFO:root:current mean train loss 1261.016141384726
INFO:root:current train perplexity2.7026426792144775
INFO:root:current mean train loss 1261.6139879063874
INFO:root:current train perplexity2.7033448219299316

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.63s/it]
INFO:root:final mean train loss: 1261.309836152462
INFO:root:final train perplexity: 2.7040340900421143
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2453.4008698159078
INFO:root:eval perplexity: 7.272983074188232
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 3071.7410165773217
INFO:root:eval perplexity: 12.331464767456055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [15:24:00<14:34:38, 541.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1246.1893823242187
INFO:root:current train perplexity2.6703524589538574
INFO:root:current mean train loss 1245.0158414713542
INFO:root:current train perplexity2.665548324584961
INFO:root:current mean train loss 1249.9660942382814
INFO:root:current train perplexity2.677922487258911
INFO:root:current mean train loss 1249.5091793387278
INFO:root:current train perplexity2.6792330741882324
INFO:root:current mean train loss 1249.017122124566
INFO:root:current train perplexity2.6796767711639404
INFO:root:current mean train loss 1249.4748564009233
INFO:root:current train perplexity2.678720712661743
INFO:root:current mean train loss 1249.6755572040265
INFO:root:current train perplexity2.6793227195739746
INFO:root:current mean train loss 1249.3220901692707
INFO:root:current train perplexity2.680445909500122
INFO:root:current mean train loss 1250.9005906767004
INFO:root:current train perplexity2.679363250732422
INFO:root:current mean train loss 1251.6697848992599
INFO:root:current train perplexity2.6791067123413086
INFO:root:current mean train loss 1252.7485073707217
INFO:root:current train perplexity2.6822774410247803
INFO:root:current mean train loss 1253.413364788553
INFO:root:current train perplexity2.683807134628296
INFO:root:current mean train loss 1253.5070205078125
INFO:root:current train perplexity2.6854002475738525
INFO:root:current mean train loss 1253.1967964228877
INFO:root:current train perplexity2.6859705448150635
INFO:root:current mean train loss 1252.9407722420528
INFO:root:current train perplexity2.686605453491211
INFO:root:current mean train loss 1253.561741982737
INFO:root:current train perplexity2.6872823238372803
INFO:root:current mean train loss 1253.9219369229404
INFO:root:current train perplexity2.688370704650879
INFO:root:current mean train loss 1254.5951565987723
INFO:root:current train perplexity2.6891112327575684
INFO:root:current mean train loss 1255.5107503035263
INFO:root:current train perplexity2.690610408782959
INFO:root:current mean train loss 1256.2503352238582
INFO:root:current train perplexity2.69195818901062

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.43s/it]
INFO:root:final mean train loss: 1255.8633020875193
INFO:root:final train perplexity: 2.692444086074829
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2457.3210505492298
INFO:root:eval perplexity: 7.296077728271484
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 3075.91461224928
INFO:root:eval perplexity: 12.373626708984375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [15:33:01<14:25:39, 541.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1238.7472342875467
INFO:root:current train perplexity2.661835193634033
INFO:root:current mean train loss 1239.6852186739802
INFO:root:current train perplexity2.6645734310150146
INFO:root:current mean train loss 1239.1170206248537
INFO:root:current train perplexity2.660999298095703
INFO:root:current mean train loss 1241.4646591477563
INFO:root:current train perplexity2.663787364959717
INFO:root:current mean train loss 1244.4279173497725
INFO:root:current train perplexity2.665743112564087
INFO:root:current mean train loss 1244.1424244068287
INFO:root:current train perplexity2.665146589279175
INFO:root:current mean train loss 1243.519608481892
INFO:root:current train perplexity2.667236566543579
INFO:root:current mean train loss 1245.5586771461458
INFO:root:current train perplexity2.669243335723877
INFO:root:current mean train loss 1246.0737472234987
INFO:root:current train perplexity2.670349597930908
INFO:root:current mean train loss 1247.8521097335106
INFO:root:current train perplexity2.6711981296539307
INFO:root:current mean train loss 1248.976393294759
INFO:root:current train perplexity2.6723062992095947
INFO:root:current mean train loss 1249.2976627562325
INFO:root:current train perplexity2.6724843978881836
INFO:root:current mean train loss 1249.5406389123546
INFO:root:current train perplexity2.674459218978882
INFO:root:current mean train loss 1249.9095260742902
INFO:root:current train perplexity2.675300359725952
INFO:root:current mean train loss 1250.487329733965
INFO:root:current train perplexity2.6759798526763916
INFO:root:current mean train loss 1250.5468210148522
INFO:root:current train perplexity2.6774775981903076
INFO:root:current mean train loss 1250.7034945061769
INFO:root:current train perplexity2.6791348457336426
INFO:root:current mean train loss 1251.0230566433884
INFO:root:current train perplexity2.6805665493011475
INFO:root:current mean train loss 1251.9263436757249
INFO:root:current train perplexity2.6827147006988525
INFO:root:current mean train loss 1252.1888155294787
INFO:root:current train perplexity2.683590888977051

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.00s/it]
INFO:root:final mean train loss: 1251.876881871149
INFO:root:final train perplexity: 2.683992385864258
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 2460.6884951760585
INFO:root:eval perplexity: 7.315976142883301
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it]
INFO:root:eval mean loss: 3079.5334476984985
INFO:root:eval perplexity: 12.410303115844727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [15:42:02<14:16:26, 540.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1239.281735374814
INFO:root:current train perplexity2.6710729598999023
INFO:root:current mean train loss 1238.3922875445821
INFO:root:current train perplexity2.667780637741089
INFO:root:current mean train loss 1238.8072324940856
INFO:root:current train perplexity2.662329912185669
INFO:root:current mean train loss 1238.6290677388508
INFO:root:current train perplexity2.661970853805542
INFO:root:current mean train loss 1239.0513320796747
INFO:root:current train perplexity2.6596972942352295
INFO:root:current mean train loss 1241.0046836121442
INFO:root:current train perplexity2.6613457202911377
INFO:root:current mean train loss 1240.9093076471697
INFO:root:current train perplexity2.6623878479003906
INFO:root:current mean train loss 1241.0763362962373
INFO:root:current train perplexity2.6631979942321777
INFO:root:current mean train loss 1241.8133816956395
INFO:root:current train perplexity2.6663966178894043
INFO:root:current mean train loss 1242.5401162248318
INFO:root:current train perplexity2.6676971912384033
INFO:root:current mean train loss 1243.6232161293171
INFO:root:current train perplexity2.6689083576202393
INFO:root:current mean train loss 1244.5070550248429
INFO:root:current train perplexity2.6703310012817383
INFO:root:current mean train loss 1244.803682416399
INFO:root:current train perplexity2.6701645851135254
INFO:root:current mean train loss 1245.6681985138468
INFO:root:current train perplexity2.6695613861083984
INFO:root:current mean train loss 1246.192292246857
INFO:root:current train perplexity2.6694490909576416
INFO:root:current mean train loss 1246.2152383207072
INFO:root:current train perplexity2.6708061695098877
INFO:root:current mean train loss 1246.7240086643826
INFO:root:current train perplexity2.6712136268615723
INFO:root:current mean train loss 1246.97725715124
INFO:root:current train perplexity2.6719729900360107
INFO:root:current mean train loss 1247.4754793527527
INFO:root:current train perplexity2.672961473464966

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.35s/it]
INFO:root:final mean train loss: 1247.2806439267465
INFO:root:final train perplexity: 2.674281358718872
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2465.654613305491
INFO:root:eval perplexity: 7.3454179763793945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 3085.2976602324356
INFO:root:eval perplexity: 12.46894645690918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [15:51:03<14:07:28, 540.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1187.3060302734375
INFO:root:current train perplexity2.7492659091949463
INFO:root:current mean train loss 1226.9148819422958
INFO:root:current train perplexity2.6356027126312256
INFO:root:current mean train loss 1231.0307671845849
INFO:root:current train perplexity2.6411895751953125
INFO:root:current mean train loss 1230.998973149398
INFO:root:current train perplexity2.6465847492218018
INFO:root:current mean train loss 1232.4558692989206
INFO:root:current train perplexity2.6476404666900635
INFO:root:current mean train loss 1232.4856354186159
INFO:root:current train perplexity2.6472086906433105
INFO:root:current mean train loss 1234.5687006031615
INFO:root:current train perplexity2.6483075618743896
INFO:root:current mean train loss 1236.4740247957716
INFO:root:current train perplexity2.651481866836548
INFO:root:current mean train loss 1238.081062002575
INFO:root:current train perplexity2.6541566848754883
INFO:root:current mean train loss 1238.4406632604398
INFO:root:current train perplexity2.6554741859436035
INFO:root:current mean train loss 1238.8333174393965
INFO:root:current train perplexity2.6556129455566406
INFO:root:current mean train loss 1239.1696400378207
INFO:root:current train perplexity2.654985189437866
INFO:root:current mean train loss 1239.7049343036076
INFO:root:current train perplexity2.6565890312194824
INFO:root:current mean train loss 1239.8977306931868
INFO:root:current train perplexity2.6582729816436768
INFO:root:current mean train loss 1239.8086175367205
INFO:root:current train perplexity2.659895420074463
INFO:root:current mean train loss 1240.3059685470103
INFO:root:current train perplexity2.6606080532073975
INFO:root:current mean train loss 1240.7650857099811
INFO:root:current train perplexity2.6612236499786377
INFO:root:current mean train loss 1241.4146467295204
INFO:root:current train perplexity2.661334276199341
INFO:root:current mean train loss 1242.0906408332175
INFO:root:current train perplexity2.6620635986328125
INFO:root:current mean train loss 1242.5435997141717
INFO:root:current train perplexity2.664238691329956

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.66s/it]
INFO:root:final mean train loss: 1242.698819420642
INFO:root:final train perplexity: 2.6646347045898438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2469.3570019877548
INFO:root:eval perplexity: 7.367443561553955
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3093.0118970938606
INFO:root:eval perplexity: 12.547859191894531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [16:00:04<13:58:35, 541.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1216.6148613823784
INFO:root:current train perplexity2.6155002117156982
INFO:root:current mean train loss 1225.1116901979608
INFO:root:current train perplexity2.625251293182373
INFO:root:current mean train loss 1228.498640987851
INFO:root:current train perplexity2.625300168991089
INFO:root:current mean train loss 1229.3079880048645
INFO:root:current train perplexity2.631821632385254
INFO:root:current mean train loss 1230.7823699513121
INFO:root:current train perplexity2.632756233215332
INFO:root:current mean train loss 1230.8593455428781
INFO:root:current train perplexity2.6329963207244873
INFO:root:current mean train loss 1231.8237229628085
INFO:root:current train perplexity2.636401891708374
INFO:root:current mean train loss 1231.9846660645892
INFO:root:current train perplexity2.6385974884033203
INFO:root:current mean train loss 1233.3013519063263
INFO:root:current train perplexity2.639892101287842
INFO:root:current mean train loss 1234.3780806132131
INFO:root:current train perplexity2.6422903537750244
INFO:root:current mean train loss 1234.756467807972
INFO:root:current train perplexity2.644035577774048
INFO:root:current mean train loss 1235.381028832178
INFO:root:current train perplexity2.6447391510009766
INFO:root:current mean train loss 1235.3745468966479
INFO:root:current train perplexity2.6474263668060303
INFO:root:current mean train loss 1235.5793868254457
INFO:root:current train perplexity2.6483242511749268
INFO:root:current mean train loss 1235.958575465279
INFO:root:current train perplexity2.650104522705078
INFO:root:current mean train loss 1236.6966471514997
INFO:root:current train perplexity2.6509222984313965
INFO:root:current mean train loss 1237.483562681672
INFO:root:current train perplexity2.6525001525878906
INFO:root:current mean train loss 1237.483509210269
INFO:root:current train perplexity2.65356707572937
INFO:root:current mean train loss 1238.2568177411003
INFO:root:current train perplexity2.6539711952209473
INFO:root:current mean train loss 1238.6071098256036
INFO:root:current train perplexity2.6557438373565674

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.44s/it]
INFO:root:final mean train loss: 1238.3785065820707
INFO:root:final train perplexity: 2.655571222305298
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2476.412121062583
INFO:root:eval perplexity: 7.409601211547852
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 3099.452538456477
INFO:root:eval perplexity: 12.614128112792969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [16:09:05<13:49:36, 541.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1216.554377092634
INFO:root:current train perplexity2.6342384815216064
INFO:root:current mean train loss 1216.609654405382
INFO:root:current train perplexity2.6289093494415283
INFO:root:current mean train loss 1220.4265604222076
INFO:root:current train perplexity2.6313953399658203
INFO:root:current mean train loss 1222.6019822761193
INFO:root:current train perplexity2.6298129558563232
INFO:root:current mean train loss 1223.2712438824533
INFO:root:current train perplexity2.6294987201690674
INFO:root:current mean train loss 1224.2504891939252
INFO:root:current train perplexity2.6317930221557617
INFO:root:current mean train loss 1226.1579628291092
INFO:root:current train perplexity2.633969306945801
INFO:root:current mean train loss 1227.5133139681654
INFO:root:current train perplexity2.6341073513031006
INFO:root:current mean train loss 1227.7042541869387
INFO:root:current train perplexity2.6357033252716064
INFO:root:current mean train loss 1227.584033203125
INFO:root:current train perplexity2.636235237121582
INFO:root:current mean train loss 1228.5177058565444
INFO:root:current train perplexity2.6366376876831055
INFO:root:current mean train loss 1228.4720443927245
INFO:root:current train perplexity2.63773250579834
INFO:root:current mean train loss 1229.2480583407137
INFO:root:current train perplexity2.6401784420013428
INFO:root:current mean train loss 1229.8111417734667
INFO:root:current train perplexity2.638587474822998
INFO:root:current mean train loss 1230.5541229992377
INFO:root:current train perplexity2.6388180255889893
INFO:root:current mean train loss 1231.2997821820286
INFO:root:current train perplexity2.6391522884368896
INFO:root:current mean train loss 1231.7758741279624
INFO:root:current train perplexity2.6404473781585693
INFO:root:current mean train loss 1232.497104365544
INFO:root:current train perplexity2.640986204147339
INFO:root:current mean train loss 1232.7417902226669
INFO:root:current train perplexity2.6423747539520264
INFO:root:current mean train loss 1233.071467594275
INFO:root:current train perplexity2.644221067428589

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.68s/it]
INFO:root:final mean train loss: 1232.909053554333
INFO:root:final train perplexity: 2.64414119720459
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2481.1041480531085
INFO:root:eval perplexity: 7.437771797180176
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3104.269064179549
INFO:root:eval perplexity: 12.663911819458008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [16:18:06<13:40:42, 541.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1219.4059471717248
INFO:root:current train perplexity2.609541177749634
INFO:root:current mean train loss 1216.5332794189453
INFO:root:current train perplexity2.6080307960510254
INFO:root:current mean train loss 1221.2037629627046
INFO:root:current train perplexity2.6208181381225586
INFO:root:current mean train loss 1222.0993402654474
INFO:root:current train perplexity2.622236490249634
INFO:root:current mean train loss 1221.8955142941095
INFO:root:current train perplexity2.62371826171875
INFO:root:current mean train loss 1221.9970198921535
INFO:root:current train perplexity2.624453067779541
INFO:root:current mean train loss 1222.3957783517662
INFO:root:current train perplexity2.6279423236846924
INFO:root:current mean train loss 1223.2259820167055
INFO:root:current train perplexity2.6282355785369873
INFO:root:current mean train loss 1223.5292934363997
INFO:root:current train perplexity2.628643751144409
INFO:root:current mean train loss 1224.1329920151654
INFO:root:current train perplexity2.6294801235198975
INFO:root:current mean train loss 1225.6939017292211
INFO:root:current train perplexity2.630981922149658
INFO:root:current mean train loss 1225.6562032699585
INFO:root:current train perplexity2.6324942111968994
INFO:root:current mean train loss 1225.7730804540859
INFO:root:current train perplexity2.6329400539398193
INFO:root:current mean train loss 1226.306609475401
INFO:root:current train perplexity2.633802652359009
INFO:root:current mean train loss 1227.2345940876269
INFO:root:current train perplexity2.6342005729675293
INFO:root:current mean train loss 1227.6644110138884
INFO:root:current train perplexity2.6352052688598633
INFO:root:current mean train loss 1228.11099331835
INFO:root:current train perplexity2.635646343231201
INFO:root:current mean train loss 1228.6484051708762
INFO:root:current train perplexity2.6360623836517334
INFO:root:current mean train loss 1228.9258805145198
INFO:root:current train perplexity2.6367881298065186
INFO:root:current mean train loss 1230.0103332644603
INFO:root:current train perplexity2.637361764907837

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.70s/it]
INFO:root:final mean train loss: 1229.841220842247
INFO:root:final train perplexity: 2.637751340866089
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.88s/it]
INFO:root:eval mean loss: 2487.4858220959386
INFO:root:eval perplexity: 7.476259231567383
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 3112.174486092642
INFO:root:eval perplexity: 12.746051788330078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/110
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [16:27:04<13:30:08, 540.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1212.735004812047
INFO:root:current train perplexity2.5983221530914307
INFO:root:current mean train loss 1214.7307150575537
INFO:root:current train perplexity2.601652145385742
INFO:root:current mean train loss 1214.299069089074
INFO:root:current train perplexity2.6028177738189697
INFO:root:current mean train loss 1216.1573678200161
INFO:root:current train perplexity2.60978102684021
INFO:root:current mean train loss 1217.8817890874866
INFO:root:current train perplexity2.6132864952087402
INFO:root:current mean train loss 1218.151031225972
INFO:root:current train perplexity2.61568284034729
INFO:root:current mean train loss 1219.0426315512893
INFO:root:current train perplexity2.616034984588623
INFO:root:current mean train loss 1220.5768234987097
INFO:root:current train perplexity2.6167140007019043
INFO:root:current mean train loss 1221.3838928714308
INFO:root:current train perplexity2.616658926010132
INFO:root:current mean train loss 1222.8453312451625
INFO:root:current train perplexity2.6183698177337646
INFO:root:current mean train loss 1223.5370769447206
INFO:root:current train perplexity2.618759870529175
INFO:root:current mean train loss 1223.9671535834582
INFO:root:current train perplexity2.620734453201294
INFO:root:current mean train loss 1224.7216278388803
INFO:root:current train perplexity2.6214234828948975
INFO:root:current mean train loss 1224.7040520745354
INFO:root:current train perplexity2.6219654083251953
INFO:root:current mean train loss 1224.5677554219494
INFO:root:current train perplexity2.6241555213928223
INFO:root:current mean train loss 1224.463804946423
INFO:root:current train perplexity2.6242799758911133
INFO:root:current mean train loss 1224.1478594030857
INFO:root:current train perplexity2.6248652935028076
INFO:root:current mean train loss 1224.7870946768787
INFO:root:current train perplexity2.626326322555542
INFO:root:current mean train loss 1225.1665163810653
INFO:root:current train perplexity2.627286195755005
INFO:root:current mean train loss 1225.770202171748
INFO:root:current train perplexity2.628305435180664

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.32s/it]
INFO:root:final mean train loss: 1225.3632242469191
INFO:root:final train perplexity: 2.6284520626068115
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it]
INFO:root:eval mean loss: 2489.0577015978224
INFO:root:eval perplexity: 7.485767841339111
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it]
INFO:root:eval mean loss: 3115.33603662802
INFO:root:eval perplexity: 12.779054641723633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/111
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [16:35:59<13:18:57, 538.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1220.4508780545966
INFO:root:current train perplexity2.591329336166382
INFO:root:current mean train loss 1217.7941310431368
INFO:root:current train perplexity2.6020355224609375
INFO:root:current mean train loss 1213.841475053267
INFO:root:current train perplexity2.6043078899383545
INFO:root:current mean train loss 1214.9310957360144
INFO:root:current train perplexity2.605323314666748
INFO:root:current mean train loss 1214.6667271994759
INFO:root:current train perplexity2.603884220123291
INFO:root:current mean train loss 1213.8803679690834
INFO:root:current train perplexity2.604686737060547
INFO:root:current mean train loss 1214.6668140644929
INFO:root:current train perplexity2.6039953231811523
INFO:root:current mean train loss 1215.2471068093491
INFO:root:current train perplexity2.6058945655822754
INFO:root:current mean train loss 1216.139245991244
INFO:root:current train perplexity2.6062638759613037
INFO:root:current mean train loss 1216.5414483184504
INFO:root:current train perplexity2.609060525894165
INFO:root:current mean train loss 1216.973416997583
INFO:root:current train perplexity2.6098010540008545
INFO:root:current mean train loss 1217.2384256552684
INFO:root:current train perplexity2.610637664794922
INFO:root:current mean train loss 1217.7747554986695
INFO:root:current train perplexity2.6113903522491455
INFO:root:current mean train loss 1218.4579536471017
INFO:root:current train perplexity2.613640785217285
INFO:root:current mean train loss 1218.3404088386135
INFO:root:current train perplexity2.6140429973602295
INFO:root:current mean train loss 1218.7982335517565
INFO:root:current train perplexity2.614590644836426
INFO:root:current mean train loss 1219.6326032572936
INFO:root:current train perplexity2.61562442779541
INFO:root:current mean train loss 1220.713010576511
INFO:root:current train perplexity2.6169188022613525
INFO:root:current mean train loss 1220.849730344997
INFO:root:current train perplexity2.6181721687316895

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.65s/it]
INFO:root:final mean train loss: 1220.9344331603788
INFO:root:final train perplexity: 2.6192872524261475
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it]
INFO:root:eval mean loss: 2496.564780377327
INFO:root:eval perplexity: 7.5313544273376465
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it]
INFO:root:eval mean loss: 3123.057870851341
INFO:root:eval perplexity: 12.86000919342041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/112
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [16:44:55<13:08:37, 537.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1191.788330078125
INFO:root:current train perplexity2.7677714824676514
INFO:root:current mean train loss 1219.2111911218144
INFO:root:current train perplexity2.6025688648223877
INFO:root:current mean train loss 1214.3874403479065
INFO:root:current train perplexity2.5934646129608154
INFO:root:current mean train loss 1212.7558823387221
INFO:root:current train perplexity2.598942279815674
INFO:root:current mean train loss 1211.4832748526676
INFO:root:current train perplexity2.6014628410339355
INFO:root:current mean train loss 1212.331028962941
INFO:root:current train perplexity2.5991008281707764
INFO:root:current mean train loss 1212.7853799443537
INFO:root:current train perplexity2.601069688796997
INFO:root:current mean train loss 1212.603425157528
INFO:root:current train perplexity2.60050630569458
INFO:root:current mean train loss 1213.142704147776
INFO:root:current train perplexity2.6014320850372314
INFO:root:current mean train loss 1213.1338312396178
INFO:root:current train perplexity2.6008551120758057
INFO:root:current mean train loss 1213.1225576201084
INFO:root:current train perplexity2.604085922241211
INFO:root:current mean train loss 1213.4060147130695
INFO:root:current train perplexity2.6023142337799072
INFO:root:current mean train loss 1213.6913399890573
INFO:root:current train perplexity2.603464126586914
INFO:root:current mean train loss 1214.2598983752937
INFO:root:current train perplexity2.603496789932251
INFO:root:current mean train loss 1214.4547094778766
INFO:root:current train perplexity2.6051993370056152
INFO:root:current mean train loss 1214.6701854266728
INFO:root:current train perplexity2.606132745742798
INFO:root:current mean train loss 1215.5479811717776
INFO:root:current train perplexity2.60733962059021
INFO:root:current mean train loss 1215.6699209431656
INFO:root:current train perplexity2.6081180572509766
INFO:root:current mean train loss 1215.9817847803574
INFO:root:current train perplexity2.608290910720825
INFO:root:current mean train loss 1216.8271658852798
INFO:root:current train perplexity2.6096816062927246

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.26s/it]
INFO:root:final mean train loss: 1216.8758821934687
INFO:root:final train perplexity: 2.610917329788208
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.84s/it]
INFO:root:eval mean loss: 2496.809442181959
INFO:root:eval perplexity: 7.5328450202941895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.17s/it]
INFO:root:eval mean loss: 3123.825495726673
INFO:root:eval perplexity: 12.868087768554688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/113
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [16:53:51<12:58:59, 537.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1200.64677734375
INFO:root:current train perplexity2.581132650375366
INFO:root:current mean train loss 1201.9407541910807
INFO:root:current train perplexity2.576603889465332
INFO:root:current mean train loss 1202.822793301669
INFO:root:current train perplexity2.5776219367980957
INFO:root:current mean train loss 1204.3924213409423
INFO:root:current train perplexity2.5826094150543213
INFO:root:current mean train loss 1205.064141845703
INFO:root:current train perplexity2.5845816135406494
INFO:root:current mean train loss 1205.397022658128
INFO:root:current train perplexity2.586254358291626
INFO:root:current mean train loss 1204.2658844978578
INFO:root:current train perplexity2.5889883041381836
INFO:root:current mean train loss 1205.5651345147028
INFO:root:current train perplexity2.5902099609375
INFO:root:current mean train loss 1206.512868443931
INFO:root:current train perplexity2.5915849208831787
INFO:root:current mean train loss 1207.7988382090693
INFO:root:current train perplexity2.5934040546417236
INFO:root:current mean train loss 1207.6776348039216
INFO:root:current train perplexity2.596181869506836
INFO:root:current mean train loss 1208.470889718192
INFO:root:current train perplexity2.596949815750122
INFO:root:current mean train loss 1208.709019595287
INFO:root:current train perplexity2.5977370738983154
INFO:root:current mean train loss 1209.8609150279651
INFO:root:current train perplexity2.5988821983337402
INFO:root:current mean train loss 1210.5281513052928
INFO:root:current train perplexity2.5997862815856934
INFO:root:current mean train loss 1210.9974471242804
INFO:root:current train perplexity2.601437568664551
INFO:root:current mean train loss 1211.8969468858506
INFO:root:current train perplexity2.6023037433624268
INFO:root:current mean train loss 1212.7188854838525
INFO:root:current train perplexity2.603177547454834
INFO:root:current mean train loss 1213.127710028009
INFO:root:current train perplexity2.6034367084503174
INFO:root:current mean train loss 1213.5595104853312
INFO:root:current train perplexity2.6036853790283203

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.95s/it]
INFO:root:final mean train loss: 1213.5956019537653
INFO:root:final train perplexity: 2.6041715145111084
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.84s/it]
INFO:root:eval mean loss: 2503.2681767889794
INFO:root:eval perplexity: 7.572296142578125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it]
INFO:root:eval mean loss: 3131.2607768173757
INFO:root:eval perplexity: 12.946572303771973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/114
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [17:02:47<12:49:28, 536.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1204.2500164959881
INFO:root:current train perplexity2.5937280654907227
INFO:root:current mean train loss 1201.2479354969776
INFO:root:current train perplexity2.5818700790405273
INFO:root:current mean train loss 1201.069646006395
INFO:root:current train perplexity2.5815086364746094
INFO:root:current mean train loss 1201.731103008508
INFO:root:current train perplexity2.5806045532226562
INFO:root:current mean train loss 1203.8101929548948
INFO:root:current train perplexity2.5850963592529297
INFO:root:current mean train loss 1204.2452810845118
INFO:root:current train perplexity2.583577871322632
INFO:root:current mean train loss 1205.0428164016507
INFO:root:current train perplexity2.585700273513794
INFO:root:current mean train loss 1205.9588507104922
INFO:root:current train perplexity2.5868847370147705
INFO:root:current mean train loss 1206.0973381671427
INFO:root:current train perplexity2.5884909629821777
INFO:root:current mean train loss 1205.7052261205977
INFO:root:current train perplexity2.5864102840423584
INFO:root:current mean train loss 1206.577355851088
INFO:root:current train perplexity2.5884642601013184
INFO:root:current mean train loss 1207.024920595248
INFO:root:current train perplexity2.5887386798858643
INFO:root:current mean train loss 1207.204914410652
INFO:root:current train perplexity2.59031343460083
INFO:root:current mean train loss 1207.3497272454363
INFO:root:current train perplexity2.592789649963379
INFO:root:current mean train loss 1207.5049387083006
INFO:root:current train perplexity2.5921332836151123
INFO:root:current mean train loss 1207.838722005632
INFO:root:current train perplexity2.592869997024536
INFO:root:current mean train loss 1207.9854887704262
INFO:root:current train perplexity2.5921669006347656
INFO:root:current mean train loss 1208.7604217968526
INFO:root:current train perplexity2.593395233154297
INFO:root:current mean train loss 1209.1586684806878
INFO:root:current train perplexity2.594428539276123
INFO:root:current mean train loss 1209.4862848930773
INFO:root:current train perplexity2.595053195953369

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.30s/it]
INFO:root:final mean train loss: 1209.2610277877093
INFO:root:final train perplexity: 2.5952842235565186
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.85s/it]
INFO:root:eval mean loss: 2508.0844181141956
INFO:root:eval perplexity: 7.601849555969238
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it]
INFO:root:eval mean loss: 3138.164834313359
INFO:root:eval perplexity: 13.019878387451172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/115
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [17:11:42<12:39:50, 536.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1200.0597647207755
INFO:root:current train perplexity2.579393148422241
INFO:root:current mean train loss 1199.8105413263495
INFO:root:current train perplexity2.5694711208343506
INFO:root:current mean train loss 1197.0786233736774
INFO:root:current train perplexity2.5697851181030273
INFO:root:current mean train loss 1197.0284147963011
INFO:root:current train perplexity2.5725457668304443
INFO:root:current mean train loss 1197.0368404976598
INFO:root:current train perplexity2.573737144470215
INFO:root:current mean train loss 1196.7895007632699
INFO:root:current train perplexity2.574700355529785
INFO:root:current mean train loss 1196.9765966572893
INFO:root:current train perplexity2.5752995014190674
INFO:root:current mean train loss 1197.14033309977
INFO:root:current train perplexity2.5740175247192383
INFO:root:current mean train loss 1198.2756910837786
INFO:root:current train perplexity2.574144124984741
INFO:root:current mean train loss 1198.8420891271946
INFO:root:current train perplexity2.5758819580078125
INFO:root:current mean train loss 1199.3931251250815
INFO:root:current train perplexity2.5780677795410156
INFO:root:current mean train loss 1199.714992159574
INFO:root:current train perplexity2.579026699066162
INFO:root:current mean train loss 1200.862515438877
INFO:root:current train perplexity2.579554557800293
INFO:root:current mean train loss 1201.7504345486752
INFO:root:current train perplexity2.581230878829956
INFO:root:current mean train loss 1202.0422431284655
INFO:root:current train perplexity2.5826380252838135
INFO:root:current mean train loss 1202.8313032270553
INFO:root:current train perplexity2.584742307662964
INFO:root:current mean train loss 1203.326466939758
INFO:root:current train perplexity2.585533380508423
INFO:root:current mean train loss 1203.940796872773
INFO:root:current train perplexity2.5853936672210693
INFO:root:current mean train loss 1204.6106773466997
INFO:root:current train perplexity2.587209463119507
INFO:root:current mean train loss 1205.8051382980425
INFO:root:current train perplexity2.587839365005493

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.77s/it]
INFO:root:final mean train loss: 1205.600782062571
INFO:root:final train perplexity: 2.5878028869628906
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.84s/it]
INFO:root:eval mean loss: 2510.9891115012742
INFO:root:eval perplexity: 7.619726657867432
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.15s/it]
INFO:root:eval mean loss: 3141.400132199551
INFO:root:eval perplexity: 13.054377555847168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/116
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [17:20:38<12:30:36, 536.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1190.4219970703125
INFO:root:current train perplexity2.548945665359497
INFO:root:current mean train loss 1188.1395049513433
INFO:root:current train perplexity2.5584380626678467
INFO:root:current mean train loss 1188.5938788269718
INFO:root:current train perplexity2.5581512451171875
INFO:root:current mean train loss 1192.5991664999578
INFO:root:current train perplexity2.5657999515533447
INFO:root:current mean train loss 1193.2593864554306
INFO:root:current train perplexity2.5655429363250732
INFO:root:current mean train loss 1194.722171389284
INFO:root:current train perplexity2.5663466453552246
INFO:root:current mean train loss 1195.6748072344217
INFO:root:current train perplexity2.567732572555542
INFO:root:current mean train loss 1196.971852739188
INFO:root:current train perplexity2.568814992904663
INFO:root:current mean train loss 1197.1572198353185
INFO:root:current train perplexity2.5694172382354736
INFO:root:current mean train loss 1197.255248269141
INFO:root:current train perplexity2.5723445415496826
INFO:root:current mean train loss 1198.2414864220427
INFO:root:current train perplexity2.573570966720581
INFO:root:current mean train loss 1198.737935679474
INFO:root:current train perplexity2.5754761695861816
INFO:root:current mean train loss 1199.1951538374067
INFO:root:current train perplexity2.575748920440674
INFO:root:current mean train loss 1199.6238599647838
INFO:root:current train perplexity2.575549840927124
INFO:root:current mean train loss 1199.7905436087271
INFO:root:current train perplexity2.576284170150757
INFO:root:current mean train loss 1200.073359984186
INFO:root:current train perplexity2.577265739440918
INFO:root:current mean train loss 1200.3956710112302
INFO:root:current train perplexity2.5780131816864014
INFO:root:current mean train loss 1201.0082162074084
INFO:root:current train perplexity2.578824281692505
INFO:root:current mean train loss 1201.403710467748
INFO:root:current train perplexity2.5784389972686768
INFO:root:current mean train loss 1201.6202269331081
INFO:root:current train perplexity2.5791378021240234

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.09s/it]
INFO:root:final mean train loss: 1201.346944296294
INFO:root:final train perplexity: 2.5791358947753906
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2516.813737152316
INFO:root:eval perplexity: 7.655705451965332
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 3148.00803716132
INFO:root:eval perplexity: 13.125110626220703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/117
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [17:29:37<12:23:10, 537.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1189.456015846946
INFO:root:current train perplexity2.5522243976593018
INFO:root:current mean train loss 1188.903797555477
INFO:root:current train perplexity2.552574396133423
INFO:root:current mean train loss 1187.4241231282551
INFO:root:current train perplexity2.5551705360412598
INFO:root:current mean train loss 1188.415911173083
INFO:root:current train perplexity2.5552351474761963
INFO:root:current mean train loss 1190.2241170914447
INFO:root:current train perplexity2.5574328899383545
INFO:root:current mean train loss 1191.7938979791136
INFO:root:current train perplexity2.5566155910491943
INFO:root:current mean train loss 1192.3135179031726
INFO:root:current train perplexity2.5597856044769287
INFO:root:current mean train loss 1192.9218675642448
INFO:root:current train perplexity2.5591249465942383
INFO:root:current mean train loss 1194.1250633720879
INFO:root:current train perplexity2.559305429458618
INFO:root:current mean train loss 1194.576551058997
INFO:root:current train perplexity2.5611863136291504
INFO:root:current mean train loss 1194.7550579519832
INFO:root:current train perplexity2.563511848449707
INFO:root:current mean train loss 1195.396856648352
INFO:root:current train perplexity2.563509464263916
INFO:root:current mean train loss 1195.909523436742
INFO:root:current train perplexity2.5643258094787598
INFO:root:current mean train loss 1195.9596893574387
INFO:root:current train perplexity2.565300703048706
INFO:root:current mean train loss 1196.5781470678187
INFO:root:current train perplexity2.5669305324554443
INFO:root:current mean train loss 1197.006274014336
INFO:root:current train perplexity2.568369150161743
INFO:root:current mean train loss 1197.574487044348
INFO:root:current train perplexity2.569213390350342
INFO:root:current mean train loss 1198.2232971191406
INFO:root:current train perplexity2.571073055267334
INFO:root:current mean train loss 1198.6100080457784
INFO:root:current train perplexity2.5726208686828613

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.22s/it]
INFO:root:final mean train loss: 1198.4475963782975
INFO:root:final train perplexity: 2.5732452869415283
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2522.2545079440933
INFO:root:eval perplexity: 7.689465045928955
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3154.505637310921
INFO:root:eval perplexity: 13.195048332214355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/118
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [17:38:38<12:15:44, 538.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1194.0486572265625
INFO:root:current train perplexity2.552184581756592
INFO:root:current mean train loss 1187.615363420759
INFO:root:current train perplexity2.549065113067627
INFO:root:current mean train loss 1186.2306563214559
INFO:root:current train perplexity2.549236536026001
INFO:root:current mean train loss 1186.806548171747
INFO:root:current train perplexity2.547607898712158
INFO:root:current mean train loss 1187.2561734423225
INFO:root:current train perplexity2.5492539405822754
INFO:root:current mean train loss 1187.4785835492728
INFO:root:current train perplexity2.5513699054718018
INFO:root:current mean train loss 1187.684798109827
INFO:root:current train perplexity2.551990509033203
INFO:root:current mean train loss 1187.6246485067597
INFO:root:current train perplexity2.552123785018921
INFO:root:current mean train loss 1188.4763593022128
INFO:root:current train perplexity2.5527548789978027
INFO:root:current mean train loss 1188.6916510650467
INFO:root:current train perplexity2.554173231124878
INFO:root:current mean train loss 1189.4812902042522
INFO:root:current train perplexity2.5550365447998047
INFO:root:current mean train loss 1190.1561929970305
INFO:root:current train perplexity2.5562925338745117
INFO:root:current mean train loss 1190.6112493111384
INFO:root:current train perplexity2.556269407272339
INFO:root:current mean train loss 1191.151916644217
INFO:root:current train perplexity2.5579144954681396
INFO:root:current mean train loss 1191.758026752947
INFO:root:current train perplexity2.559028148651123
INFO:root:current mean train loss 1192.1977774281042
INFO:root:current train perplexity2.5607857704162598
INFO:root:current mean train loss 1193.0535249799211
INFO:root:current train perplexity2.5626890659332275
INFO:root:current mean train loss 1193.4291660700376
INFO:root:current train perplexity2.563483238220215
INFO:root:current mean train loss 1193.9368754463512
INFO:root:current train perplexity2.5643362998962402
INFO:root:current mean train loss 1194.4404432081487
INFO:root:current train perplexity2.564661979675293

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.35s/it]
INFO:root:final mean train loss: 1194.559280464761
INFO:root:final train perplexity: 2.565366268157959
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 2527.4727627368684
INFO:root:eval perplexity: 7.72198486328125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 3160.081582360234
INFO:root:eval perplexity: 13.255352020263672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/119
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [17:47:40<12:08:14, 539.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1175.0767933238637
INFO:root:current train perplexity2.576669454574585
INFO:root:current mean train loss 1182.2231875560324
INFO:root:current train perplexity2.535076856613159
INFO:root:current mean train loss 1184.5672244510135
INFO:root:current train perplexity2.536275625228882
INFO:root:current mean train loss 1182.323504904042
INFO:root:current train perplexity2.5356826782226562
INFO:root:current mean train loss 1182.0271574626038
INFO:root:current train perplexity2.5379252433776855
INFO:root:current mean train loss 1183.1325012440882
INFO:root:current train perplexity2.5368757247924805
INFO:root:current mean train loss 1184.321615237515
INFO:root:current train perplexity2.5402932167053223
INFO:root:current mean train loss 1184.5390631762898
INFO:root:current train perplexity2.5428929328918457
INFO:root:current mean train loss 1185.1300007246996
INFO:root:current train perplexity2.543795108795166
INFO:root:current mean train loss 1186.6113842614561
INFO:root:current train perplexity2.546403646469116
INFO:root:current mean train loss 1187.185922760786
INFO:root:current train perplexity2.5464913845062256
INFO:root:current mean train loss 1187.5451482817025
INFO:root:current train perplexity2.547278642654419
INFO:root:current mean train loss 1187.8362434749322
INFO:root:current train perplexity2.548549175262451
INFO:root:current mean train loss 1187.83478789683
INFO:root:current train perplexity2.5497019290924072
INFO:root:current mean train loss 1188.6986971612387
INFO:root:current train perplexity2.5507822036743164
INFO:root:current mean train loss 1188.960220397067
INFO:root:current train perplexity2.551231861114502
INFO:root:current mean train loss 1189.1808029908582
INFO:root:current train perplexity2.552560806274414
INFO:root:current mean train loss 1189.2541272100257
INFO:root:current train perplexity2.553115129470825
INFO:root:current mean train loss 1189.719653467708
INFO:root:current train perplexity2.554824113845825
INFO:root:current mean train loss 1189.996665930773
INFO:root:current train perplexity2.5559496879577637

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.57s/it]
INFO:root:final mean train loss: 1190.0059103761366
INFO:root:final train perplexity: 2.5561704635620117
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2531.99735774047
INFO:root:eval perplexity: 7.750293254852295
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3164.904208135943
INFO:root:eval perplexity: 13.30773639678955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/120
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [17:56:42<11:59:57, 539.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1167.1145864633413
INFO:root:current train perplexity2.504058599472046
INFO:root:current mean train loss 1173.532616484937
INFO:root:current train perplexity2.525315761566162
INFO:root:current mean train loss 1178.5679323842835
INFO:root:current train perplexity2.5262887477874756
INFO:root:current mean train loss 1179.993481661366
INFO:root:current train perplexity2.5258572101593018
INFO:root:current mean train loss 1180.4067544089905
INFO:root:current train perplexity2.5306975841522217
INFO:root:current mean train loss 1181.9831653941762
INFO:root:current train perplexity2.5336005687713623
INFO:root:current mean train loss 1182.646924515845
INFO:root:current train perplexity2.5355770587921143
INFO:root:current mean train loss 1182.5664647248182
INFO:root:current train perplexity2.5388333797454834
INFO:root:current mean train loss 1182.4577270071327
INFO:root:current train perplexity2.54003643989563
INFO:root:current mean train loss 1182.933750790402
INFO:root:current train perplexity2.539328098297119
INFO:root:current mean train loss 1183.618423006647
INFO:root:current train perplexity2.5412588119506836
INFO:root:current mean train loss 1184.102582682006
INFO:root:current train perplexity2.5417373180389404
INFO:root:current mean train loss 1184.8734533819486
INFO:root:current train perplexity2.5441834926605225
INFO:root:current mean train loss 1185.0732597823994
INFO:root:current train perplexity2.5461268424987793
INFO:root:current mean train loss 1185.1540041268079
INFO:root:current train perplexity2.546680212020874
INFO:root:current mean train loss 1185.7920406507624
INFO:root:current train perplexity2.5479350090026855
INFO:root:current mean train loss 1186.436772344751
INFO:root:current train perplexity2.548851490020752
INFO:root:current mean train loss 1187.0362063775876
INFO:root:current train perplexity2.5499141216278076
INFO:root:current mean train loss 1187.4711259569144
INFO:root:current train perplexity2.550980567932129
INFO:root:current mean train loss 1187.8487248531378
INFO:root:current train perplexity2.5512773990631104

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.97s/it]
INFO:root:final mean train loss: 1187.7005132308707
INFO:root:final train perplexity: 2.5515270233154297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 2536.5312158029974
INFO:root:eval perplexity: 7.778764724731445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 3170.494832789644
INFO:root:eval perplexity: 13.36872386932373
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/121
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [18:05:43<11:51:39, 540.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1173.5573076520648
INFO:root:current train perplexity2.5222556591033936
INFO:root:current mean train loss 1171.340582431891
INFO:root:current train perplexity2.5259528160095215
INFO:root:current mean train loss 1171.5769772529602
INFO:root:current train perplexity2.5270566940307617
INFO:root:current mean train loss 1172.2986076440704
INFO:root:current train perplexity2.5290329456329346
INFO:root:current mean train loss 1174.591716565584
INFO:root:current train perplexity2.5291121006011963
INFO:root:current mean train loss 1175.4524004819582
INFO:root:current train perplexity2.532223701477051
INFO:root:current mean train loss 1175.7328727536085
INFO:root:current train perplexity2.533132314682007
INFO:root:current mean train loss 1176.454840281653
INFO:root:current train perplexity2.5348641872406006
INFO:root:current mean train loss 1177.068752823589
INFO:root:current train perplexity2.5356311798095703
INFO:root:current mean train loss 1178.0295845574415
INFO:root:current train perplexity2.535768985748291
INFO:root:current mean train loss 1179.0425542195637
INFO:root:current train perplexity2.5371346473693848
INFO:root:current mean train loss 1180.056920668658
INFO:root:current train perplexity2.5374107360839844
INFO:root:current mean train loss 1180.1381856347346
INFO:root:current train perplexity2.539196014404297
INFO:root:current mean train loss 1180.1245796856276
INFO:root:current train perplexity2.5404956340789795
INFO:root:current mean train loss 1180.730827163864
INFO:root:current train perplexity2.5413126945495605
INFO:root:current mean train loss 1181.2910062108372
INFO:root:current train perplexity2.5419862270355225
INFO:root:current mean train loss 1181.5965817953654
INFO:root:current train perplexity2.5422914028167725
INFO:root:current mean train loss 1182.2291588576888
INFO:root:current train perplexity2.5423057079315186
INFO:root:current mean train loss 1182.5555513316187
INFO:root:current train perplexity2.542201280593872
INFO:root:current mean train loss 1183.064521461908
INFO:root:current train perplexity2.5419604778289795

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.49s/it]
INFO:root:final mean train loss: 1182.999202911023
INFO:root:final train perplexity: 2.542084217071533
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2541.629691915309
INFO:root:eval perplexity: 7.810904502868652
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3176.0309599747893
INFO:root:eval perplexity: 13.429388999938965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/122
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [18:14:44<11:42:54, 540.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1175.0895594766696
INFO:root:current train perplexity2.5074057579040527
INFO:root:current mean train loss 1173.9167198225252
INFO:root:current train perplexity2.511220932006836
INFO:root:current mean train loss 1175.4544878949175
INFO:root:current train perplexity2.5120575428009033
INFO:root:current mean train loss 1174.6692712696884
INFO:root:current train perplexity2.5187935829162598
INFO:root:current mean train loss 1175.4867720170455
INFO:root:current train perplexity2.522372007369995
INFO:root:current mean train loss 1175.6822545981947
INFO:root:current train perplexity2.5247642993927
INFO:root:current mean train loss 1175.9362802037867
INFO:root:current train perplexity2.52451753616333
INFO:root:current mean train loss 1176.4142087317068
INFO:root:current train perplexity2.5263102054595947
INFO:root:current mean train loss 1176.233896366919
INFO:root:current train perplexity2.5277748107910156
INFO:root:current mean train loss 1176.5111120367098
INFO:root:current train perplexity2.529446601867676
INFO:root:current mean train loss 1177.3045997868492
INFO:root:current train perplexity2.531642436981201
INFO:root:current mean train loss 1178.2002445360788
INFO:root:current train perplexity2.5321202278137207
INFO:root:current mean train loss 1178.7216637694546
INFO:root:current train perplexity2.5329043865203857
INFO:root:current mean train loss 1179.5532659543142
INFO:root:current train perplexity2.533219575881958
INFO:root:current mean train loss 1180.208501231808
INFO:root:current train perplexity2.5336925983428955
INFO:root:current mean train loss 1180.3794486984962
INFO:root:current train perplexity2.535156726837158
INFO:root:current mean train loss 1180.4021760036471
INFO:root:current train perplexity2.5348219871520996
INFO:root:current mean train loss 1180.5386221380604
INFO:root:current train perplexity2.5347814559936523
INFO:root:current mean train loss 1180.8856033023767
INFO:root:current train perplexity2.535904884338379
INFO:root:current mean train loss 1180.824733944877
INFO:root:current train perplexity2.5369036197662354

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.94s/it]
INFO:root:final mean train loss: 1180.5029822891552
INFO:root:final train perplexity: 2.5370848178863525
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it]
INFO:root:eval mean loss: 2544.1561261981938
INFO:root:eval perplexity: 7.82688045501709
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.71s/it]
INFO:root:eval mean loss: 3179.602590141567
INFO:root:eval perplexity: 13.468671798706055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/123
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [18:23:45<11:34:00, 540.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1164.2496704101563
INFO:root:current train perplexity2.513904571533203
INFO:root:current mean train loss 1164.4696468955592
INFO:root:current train perplexity2.5141172409057617
INFO:root:current mean train loss 1165.8856020171067
INFO:root:current train perplexity2.5177998542785645
INFO:root:current mean train loss 1167.98818359375
INFO:root:current train perplexity2.51983904838562
INFO:root:current mean train loss 1169.7330905213648
INFO:root:current train perplexity2.5169870853424072
INFO:root:current mean train loss 1170.3000790353549
INFO:root:current train perplexity2.51792049407959
INFO:root:current mean train loss 1170.5697904282722
INFO:root:current train perplexity2.5179502964019775
INFO:root:current mean train loss 1170.4752107644383
INFO:root:current train perplexity2.5194385051727295
INFO:root:current mean train loss 1171.1485332360428
INFO:root:current train perplexity2.5213754177093506
INFO:root:current mean train loss 1172.3903721048375
INFO:root:current train perplexity2.5226430892944336
INFO:root:current mean train loss 1172.6959072847978
INFO:root:current train perplexity2.5236129760742188
INFO:root:current mean train loss 1173.8502785049566
INFO:root:current train perplexity2.5240068435668945
INFO:root:current mean train loss 1174.5528108345445
INFO:root:current train perplexity2.525146245956421
INFO:root:current mean train loss 1175.5121275538163
INFO:root:current train perplexity2.5265026092529297
INFO:root:current mean train loss 1176.0165188987783
INFO:root:current train perplexity2.5277786254882812
INFO:root:current mean train loss 1176.3552887154824
INFO:root:current train perplexity2.528062343597412
INFO:root:current mean train loss 1176.453885519716
INFO:root:current train perplexity2.528414249420166
INFO:root:current mean train loss 1176.8749101180604
INFO:root:current train perplexity2.5295822620391846
INFO:root:current mean train loss 1177.2443072606648
INFO:root:current train perplexity2.531019449234009

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.48s/it]
INFO:root:final mean train loss: 1177.5835233333432
INFO:root:final train perplexity: 2.53125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.02s/it]
INFO:root:eval mean loss: 2549.0073315775985
INFO:root:eval perplexity: 7.8576507568359375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.33s/it]
INFO:root:eval mean loss: 3186.2240475052636
INFO:root:eval perplexity: 13.541805267333984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/124
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [18:32:46<11:24:59, 540.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1153.3901541573662
INFO:root:current train perplexity2.527596950531006
INFO:root:current mean train loss 1167.0710780063523
INFO:root:current train perplexity2.5146050453186035
INFO:root:current mean train loss 1168.9168536052612
INFO:root:current train perplexity2.511094570159912
INFO:root:current mean train loss 1169.2647565910017
INFO:root:current train perplexity2.5109877586364746
INFO:root:current mean train loss 1168.6020158397478
INFO:root:current train perplexity2.5117475986480713
INFO:root:current mean train loss 1168.8206795536319
INFO:root:current train perplexity2.5131988525390625
INFO:root:current mean train loss 1168.2946000075615
INFO:root:current train perplexity2.5143003463745117
INFO:root:current mean train loss 1169.0743303744089
INFO:root:current train perplexity2.5146539211273193
INFO:root:current mean train loss 1170.18469578626
INFO:root:current train perplexity2.5156209468841553
INFO:root:current mean train loss 1171.2153999303378
INFO:root:current train perplexity2.5169053077697754
INFO:root:current mean train loss 1171.7861254785835
INFO:root:current train perplexity2.5186095237731934
INFO:root:current mean train loss 1172.6887013505145
INFO:root:current train perplexity2.51922345161438
INFO:root:current mean train loss 1173.0446146765128
INFO:root:current train perplexity2.5210041999816895
INFO:root:current mean train loss 1173.8452478597067
INFO:root:current train perplexity2.5219027996063232
INFO:root:current mean train loss 1174.1270728961915
INFO:root:current train perplexity2.523195505142212
INFO:root:current mean train loss 1174.1644204892143
INFO:root:current train perplexity2.5239880084991455
INFO:root:current mean train loss 1174.2352963004264
INFO:root:current train perplexity2.5249979496002197
INFO:root:current mean train loss 1174.6093395659989
INFO:root:current train perplexity2.5251071453094482
INFO:root:current mean train loss 1174.4551530087529
INFO:root:current train perplexity2.525277614593506
INFO:root:current mean train loss 1174.7774367910065
INFO:root:current train perplexity2.525116443634033

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:03<00:00, 483.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:03<00:00, 483.98s/it]
INFO:root:final mean train loss: 1174.7185296516977
INFO:root:final train perplexity: 2.5255372524261475
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it]
INFO:root:eval mean loss: 2553.231557426723
INFO:root:eval perplexity: 7.884538650512695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.37s/it]
INFO:root:eval mean loss: 3190.4525852068095
INFO:root:eval perplexity: 13.588717460632324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/125
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [18:41:46<11:15:28, 540.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1150.7625122070312
INFO:root:current train perplexity2.48423171043396
INFO:root:current mean train loss 1163.1498816705518
INFO:root:current train perplexity2.500859498977661
INFO:root:current mean train loss 1162.8725199018206
INFO:root:current train perplexity2.5089330673217773
INFO:root:current mean train loss 1163.3142112449364
INFO:root:current train perplexity2.51218581199646
INFO:root:current mean train loss 1163.260958401662
INFO:root:current train perplexity2.509103536605835
INFO:root:current mean train loss 1163.6126114939916
INFO:root:current train perplexity2.509023427963257
INFO:root:current mean train loss 1163.95522073599
INFO:root:current train perplexity2.5086512565612793
INFO:root:current mean train loss 1165.349921126392
INFO:root:current train perplexity2.5086731910705566
INFO:root:current mean train loss 1166.05467964839
INFO:root:current train perplexity2.5104503631591797
INFO:root:current mean train loss 1166.6183462431936
INFO:root:current train perplexity2.5097405910491943
INFO:root:current mean train loss 1166.065103650093
INFO:root:current train perplexity2.5109875202178955
INFO:root:current mean train loss 1166.8781509127905
INFO:root:current train perplexity2.5114645957946777
INFO:root:current mean train loss 1167.6797439475465
INFO:root:current train perplexity2.5127451419830322
INFO:root:current mean train loss 1167.5764034766805
INFO:root:current train perplexity2.513913154602051
INFO:root:current mean train loss 1167.9780177427142
INFO:root:current train perplexity2.5149085521698
INFO:root:current mean train loss 1168.616550155199
INFO:root:current train perplexity2.515117645263672
INFO:root:current mean train loss 1169.2214920720444
INFO:root:current train perplexity2.5160088539123535
INFO:root:current mean train loss 1169.7687906853837
INFO:root:current train perplexity2.5170881748199463
INFO:root:current mean train loss 1170.4163479721337
INFO:root:current train perplexity2.5182878971099854
INFO:root:current mean train loss 1171.1930553412487
INFO:root:current train perplexity2.5177009105682373

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.26s/it]
INFO:root:final mean train loss: 1171.0086912769773
INFO:root:final train perplexity: 2.518158435821533
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 2556.987349273465
INFO:root:eval perplexity: 7.908524036407471
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.57s/it]
INFO:root:eval mean loss: 3195.230992526873
INFO:root:eval perplexity: 13.641924858093262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/126
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [18:50:47<11:06:40, 540.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1164.192746046113
INFO:root:current train perplexity2.5060267448425293
INFO:root:current mean train loss 1163.5915146415116
INFO:root:current train perplexity2.4895784854888916
INFO:root:current mean train loss 1161.5490494724131
INFO:root:current train perplexity2.4941439628601074
INFO:root:current mean train loss 1163.3569590101495
INFO:root:current train perplexity2.4985904693603516
INFO:root:current mean train loss 1163.788113064236
INFO:root:current train perplexity2.495121955871582
INFO:root:current mean train loss 1164.638186075771
INFO:root:current train perplexity2.4971814155578613
INFO:root:current mean train loss 1165.1313663191058
INFO:root:current train perplexity2.4989070892333984
INFO:root:current mean train loss 1165.0102796052631
INFO:root:current train perplexity2.499159812927246
INFO:root:current mean train loss 1164.6662903920649
INFO:root:current train perplexity2.5007822513580322
INFO:root:current mean train loss 1164.658571800694
INFO:root:current train perplexity2.5016422271728516
INFO:root:current mean train loss 1165.0023710487212
INFO:root:current train perplexity2.5020604133605957
INFO:root:current mean train loss 1165.2194662670834
INFO:root:current train perplexity2.5035452842712402
INFO:root:current mean train loss 1165.2197775152977
INFO:root:current train perplexity2.5043914318084717
INFO:root:current mean train loss 1165.4544643143236
INFO:root:current train perplexity2.5055792331695557
INFO:root:current mean train loss 1165.984180754874
INFO:root:current train perplexity2.5060625076293945
INFO:root:current mean train loss 1166.7453322562205
INFO:root:current train perplexity2.5071051120758057
INFO:root:current mean train loss 1167.0404487902765
INFO:root:current train perplexity2.5075559616088867
INFO:root:current mean train loss 1167.1503112547566
INFO:root:current train perplexity2.5082972049713135
INFO:root:current mean train loss 1167.3863941795603
INFO:root:current train perplexity2.5100784301757812
INFO:root:current mean train loss 1167.6407043677148
INFO:root:current train perplexity2.5105459690093994

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.25s/it]
INFO:root:final mean train loss: 1167.568054491621
INFO:root:final train perplexity: 2.5113348960876465
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2558.885636133505
INFO:root:eval perplexity: 7.9206743240356445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it]
INFO:root:eval mean loss: 3197.5951944986978
INFO:root:eval perplexity: 13.66832160949707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/127
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [18:59:49<10:58:11, 540.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1153.5503476899246
INFO:root:current train perplexity2.480916738510132
INFO:root:current mean train loss 1157.7110078063192
INFO:root:current train perplexity2.4833128452301025
INFO:root:current mean train loss 1158.5662964813469
INFO:root:current train perplexity2.486098051071167
INFO:root:current mean train loss 1161.7047337366882
INFO:root:current train perplexity2.4920995235443115
INFO:root:current mean train loss 1160.4995980741676
INFO:root:current train perplexity2.494814872741699
INFO:root:current mean train loss 1160.8761627306649
INFO:root:current train perplexity2.495615005493164
INFO:root:current mean train loss 1161.3895031775385
INFO:root:current train perplexity2.497150182723999
INFO:root:current mean train loss 1162.5026415822374
INFO:root:current train perplexity2.4984376430511475
INFO:root:current mean train loss 1162.6009749121322
INFO:root:current train perplexity2.499556303024292
INFO:root:current mean train loss 1162.4306513202962
INFO:root:current train perplexity2.499602794647217
INFO:root:current mean train loss 1162.2884940307847
INFO:root:current train perplexity2.5012636184692383
INFO:root:current mean train loss 1162.2189101250472
INFO:root:current train perplexity2.5006892681121826
INFO:root:current mean train loss 1162.7218774452876
INFO:root:current train perplexity2.5018715858459473
INFO:root:current mean train loss 1163.505758968123
INFO:root:current train perplexity2.5026509761810303
INFO:root:current mean train loss 1163.7803765023523
INFO:root:current train perplexity2.5016543865203857
INFO:root:current mean train loss 1164.2919412595775
INFO:root:current train perplexity2.502039909362793
INFO:root:current mean train loss 1164.3377935135752
INFO:root:current train perplexity2.503474712371826
INFO:root:current mean train loss 1164.6606821661246
INFO:root:current train perplexity2.5042521953582764
INFO:root:current mean train loss 1165.0459418650978
INFO:root:current train perplexity2.5053648948669434
INFO:root:current mean train loss 1165.2454058420183
INFO:root:current train perplexity2.5056674480438232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.84s/it]
INFO:root:final mean train loss: 1164.9194131871395
INFO:root:final train perplexity: 2.506094455718994
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2564.7744136296265
INFO:root:eval perplexity: 7.9584879875183105
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3205.295618801252
INFO:root:eval perplexity: 13.754673957824707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/128
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [19:08:50<10:49:21, 541.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1160.5358642578126
INFO:root:current train perplexity2.4799752235412598
INFO:root:current mean train loss 1154.5539453125
INFO:root:current train perplexity2.4778594970703125
INFO:root:current mean train loss 1152.8771169211648
INFO:root:current train perplexity2.479463815689087
INFO:root:current mean train loss 1152.1830400390625
INFO:root:current train perplexity2.4838452339172363
INFO:root:current mean train loss 1152.2517840254934
INFO:root:current train perplexity2.4864723682403564
INFO:root:current mean train loss 1153.6862321671197
INFO:root:current train perplexity2.4866912364959717
INFO:root:current mean train loss 1154.5713527199075
INFO:root:current train perplexity2.4896724224090576
INFO:root:current mean train loss 1154.6440828188004
INFO:root:current train perplexity2.489680767059326
INFO:root:current mean train loss 1155.0246803850446
INFO:root:current train perplexity2.4913291931152344
INFO:root:current mean train loss 1155.7823691656652
INFO:root:current train perplexity2.4930007457733154
INFO:root:current mean train loss 1156.4701771438954
INFO:root:current train perplexity2.492513656616211
INFO:root:current mean train loss 1157.4181875415559
INFO:root:current train perplexity2.493434429168701
INFO:root:current mean train loss 1157.7592365579044
INFO:root:current train perplexity2.493817090988159
INFO:root:current mean train loss 1158.492540571733
INFO:root:current train perplexity2.493809938430786
INFO:root:current mean train loss 1158.5104679224046
INFO:root:current train perplexity2.494415760040283
INFO:root:current mean train loss 1159.1052088758681
INFO:root:current train perplexity2.495112180709839
INFO:root:current mean train loss 1159.483565546292
INFO:root:current train perplexity2.496217727661133
INFO:root:current mean train loss 1159.8339863006163
INFO:root:current train perplexity2.4965012073516846
INFO:root:current mean train loss 1160.668867578125
INFO:root:current train perplexity2.497007369995117
INFO:root:current mean train loss 1160.9409857100475
INFO:root:current train perplexity2.497844696044922

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.38s/it]
INFO:root:final mean train loss: 1160.708463067667
INFO:root:final train perplexity: 2.4977855682373047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 2570.422243375305
INFO:root:eval perplexity: 7.994922161102295
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 3210.3156231819316
INFO:root:eval perplexity: 13.811260223388672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/129
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [19:17:51<10:40:19, 541.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1145.430228855299
INFO:root:current train perplexity2.4857633113861084
INFO:root:current mean train loss 1147.819216410319
INFO:root:current train perplexity2.4802842140197754
INFO:root:current mean train loss 1149.5525650651487
INFO:root:current train perplexity2.4795594215393066
INFO:root:current mean train loss 1151.2496300522162
INFO:root:current train perplexity2.481051445007324
INFO:root:current mean train loss 1150.230323605421
INFO:root:current train perplexity2.4842491149902344
INFO:root:current mean train loss 1151.5242482778187
INFO:root:current train perplexity2.4839165210723877
INFO:root:current mean train loss 1152.2533142442649
INFO:root:current train perplexity2.4839072227478027
INFO:root:current mean train loss 1153.372758807558
INFO:root:current train perplexity2.485518217086792
INFO:root:current mean train loss 1154.0665300993642
INFO:root:current train perplexity2.4867823123931885
INFO:root:current mean train loss 1154.719132823329
INFO:root:current train perplexity2.487752914428711
INFO:root:current mean train loss 1155.428954183837
INFO:root:current train perplexity2.4886467456817627
INFO:root:current mean train loss 1155.656349233333
INFO:root:current train perplexity2.4896016120910645
INFO:root:current mean train loss 1156.1355819465944
INFO:root:current train perplexity2.489316701889038
INFO:root:current mean train loss 1156.8995264864516
INFO:root:current train perplexity2.4903268814086914
INFO:root:current mean train loss 1157.4606209517165
INFO:root:current train perplexity2.4907541275024414
INFO:root:current mean train loss 1157.5761637472028
INFO:root:current train perplexity2.4911422729492188
INFO:root:current mean train loss 1157.8907464210024
INFO:root:current train perplexity2.4910969734191895
INFO:root:current mean train loss 1158.4007107189723
INFO:root:current train perplexity2.491271495819092
INFO:root:current mean train loss 1158.6779893548494
INFO:root:current train perplexity2.492438554763794

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.46s/it]
INFO:root:final mean train loss: 1158.3626227905459
INFO:root:final train perplexity: 2.493168592453003
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.85s/it]
INFO:root:eval mean loss: 2573.9735800019394
INFO:root:eval perplexity: 8.017916679382324
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.14s/it]
INFO:root:eval mean loss: 3213.7324798800423
INFO:root:eval perplexity: 13.849913597106934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/130
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [19:26:49<10:30:00, 540.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1128.5525987413193
INFO:root:current train perplexity2.456183433532715
INFO:root:current mean train loss 1146.9344628010322
INFO:root:current train perplexity2.4814984798431396
INFO:root:current mean train loss 1147.780406021045
INFO:root:current train perplexity2.4821736812591553
INFO:root:current mean train loss 1149.0685343819528
INFO:root:current train perplexity2.4787352085113525
INFO:root:current mean train loss 1149.1595757444798
INFO:root:current train perplexity2.4768362045288086
INFO:root:current mean train loss 1150.5261628576252
INFO:root:current train perplexity2.4812726974487305
INFO:root:current mean train loss 1149.4071185232579
INFO:root:current train perplexity2.4819822311401367
INFO:root:current mean train loss 1150.047962785944
INFO:root:current train perplexity2.480091094970703
INFO:root:current mean train loss 1150.9313614778082
INFO:root:current train perplexity2.478935956954956
INFO:root:current mean train loss 1151.2583418742265
INFO:root:current train perplexity2.4806339740753174
INFO:root:current mean train loss 1151.8288519777084
INFO:root:current train perplexity2.4809412956237793
INFO:root:current mean train loss 1152.3434297993335
INFO:root:current train perplexity2.4830522537231445
INFO:root:current mean train loss 1153.1423684144631
INFO:root:current train perplexity2.4842870235443115
INFO:root:current mean train loss 1153.707091958765
INFO:root:current train perplexity2.4853765964508057
INFO:root:current mean train loss 1154.2271816884481
INFO:root:current train perplexity2.4855880737304688
INFO:root:current mean train loss 1154.2086307836573
INFO:root:current train perplexity2.4863507747650146
INFO:root:current mean train loss 1154.4772316486367
INFO:root:current train perplexity2.4862852096557617
INFO:root:current mean train loss 1154.8387666169908
INFO:root:current train perplexity2.4869136810302734
INFO:root:current mean train loss 1155.2019211667357
INFO:root:current train perplexity2.487945795059204
INFO:root:current mean train loss 1155.591589054929
INFO:root:current train perplexity2.4875731468200684

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:59<00:00, 479.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:59<00:00, 479.76s/it]
INFO:root:final mean train loss: 1155.6531318360605
INFO:root:final train perplexity: 2.487846612930298
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it]
INFO:root:eval mean loss: 2576.1021087862923
INFO:root:eval perplexity: 8.031730651855469
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it]
INFO:root:eval mean loss: 3214.8995218479886
INFO:root:eval perplexity: 13.863134384155273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/131
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [19:35:44<10:19:20, 538.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1140.6770489032451
INFO:root:current train perplexity2.4873650074005127
INFO:root:current mean train loss 1143.9559151785713
INFO:root:current train perplexity2.4719738960266113
INFO:root:current mean train loss 1145.8217611397263
INFO:root:current train perplexity2.4678843021392822
INFO:root:current mean train loss 1146.747884364216
INFO:root:current train perplexity2.4634742736816406
INFO:root:current mean train loss 1146.1614225145797
INFO:root:current train perplexity2.4659886360168457
INFO:root:current mean train loss 1147.1274741285201
INFO:root:current train perplexity2.4679768085479736
INFO:root:current mean train loss 1147.6192845353685
INFO:root:current train perplexity2.468747854232788
INFO:root:current mean train loss 1148.693044615186
INFO:root:current train perplexity2.468804121017456
INFO:root:current mean train loss 1149.530737925384
INFO:root:current train perplexity2.469341278076172
INFO:root:current mean train loss 1149.739988916121
INFO:root:current train perplexity2.470423460006714
INFO:root:current mean train loss 1149.6485487434134
INFO:root:current train perplexity2.472270965576172
INFO:root:current mean train loss 1149.8775707400714
INFO:root:current train perplexity2.4732911586761475
INFO:root:current mean train loss 1149.8222245034347
INFO:root:current train perplexity2.4746952056884766
INFO:root:current mean train loss 1149.8988322492457
INFO:root:current train perplexity2.4763758182525635
INFO:root:current mean train loss 1150.8175541047126
INFO:root:current train perplexity2.4781455993652344
INFO:root:current mean train loss 1151.4981445472488
INFO:root:current train perplexity2.4789624214172363
INFO:root:current mean train loss 1152.1112682159537
INFO:root:current train perplexity2.4802794456481934
INFO:root:current mean train loss 1152.5007786049075
INFO:root:current train perplexity2.4803810119628906
INFO:root:current mean train loss 1152.9097498614842
INFO:root:current train perplexity2.480710506439209
INFO:root:current mean train loss 1153.0496205679476
INFO:root:current train perplexity2.481414794921875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.85s/it]
INFO:root:final mean train loss: 1152.8214404346122
INFO:root:final train perplexity: 2.482296943664551
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2581.633615480247
INFO:root:eval perplexity: 8.067742347717285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 3221.3746913612313
INFO:root:eval perplexity: 13.936741828918457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/132
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [19:44:45<10:11:22, 539.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1139.5074860328853
INFO:root:current train perplexity2.4865870475769043
INFO:root:current mean train loss 1140.4549808102054
INFO:root:current train perplexity2.469409704208374
INFO:root:current mean train loss 1141.1352270306875
INFO:root:current train perplexity2.475226402282715
INFO:root:current mean train loss 1143.1014893645795
INFO:root:current train perplexity2.4706151485443115
INFO:root:current mean train loss 1143.1542129688823
INFO:root:current train perplexity2.470311164855957
INFO:root:current mean train loss 1143.8932884033652
INFO:root:current train perplexity2.4697868824005127
INFO:root:current mean train loss 1144.2597241438752
INFO:root:current train perplexity2.468783140182495
INFO:root:current mean train loss 1145.7976497275351
INFO:root:current train perplexity2.4693193435668945
INFO:root:current mean train loss 1146.3185652147974
INFO:root:current train perplexity2.470550775527954
INFO:root:current mean train loss 1146.2098784138263
INFO:root:current train perplexity2.4707043170928955
INFO:root:current mean train loss 1145.5382754800419
INFO:root:current train perplexity2.4711596965789795
INFO:root:current mean train loss 1146.311144677777
INFO:root:current train perplexity2.4711410999298096
INFO:root:current mean train loss 1146.8753835443326
INFO:root:current train perplexity2.4716525077819824
INFO:root:current mean train loss 1147.7577097446103
INFO:root:current train perplexity2.4725797176361084
INFO:root:current mean train loss 1148.6225517838677
INFO:root:current train perplexity2.4737138748168945
INFO:root:current mean train loss 1149.0606434315887
INFO:root:current train perplexity2.4746253490448
INFO:root:current mean train loss 1149.1140291628428
INFO:root:current train perplexity2.4748353958129883
INFO:root:current mean train loss 1149.4082596779417
INFO:root:current train perplexity2.475412130355835
INFO:root:current mean train loss 1149.6484590593525
INFO:root:current train perplexity2.4760899543762207
INFO:root:current mean train loss 1150.2811499500913
INFO:root:current train perplexity2.4767956733703613

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 485.00s/it]
INFO:root:final mean train loss: 1150.0617487412537
INFO:root:final train perplexity: 2.476900339126587
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2585.42750971368
INFO:root:eval perplexity: 8.092534065246582
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3226.025694502161
INFO:root:eval perplexity: 13.989853858947754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/133
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [19:53:46<10:02:46, 539.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1146.918477376302
INFO:root:current train perplexity2.458134889602661
INFO:root:current mean train loss 1140.975461578369
INFO:root:current train perplexity2.453852653503418
INFO:root:current mean train loss 1139.502936260517
INFO:root:current train perplexity2.452932834625244
INFO:root:current mean train loss 1139.7740129258898
INFO:root:current train perplexity2.455195665359497
INFO:root:current mean train loss 1141.0050221318784
INFO:root:current train perplexity2.4561808109283447
INFO:root:current mean train loss 1141.3133856637137
INFO:root:current train perplexity2.4562580585479736
INFO:root:current mean train loss 1142.5063924153646
INFO:root:current train perplexity2.4599838256835938
INFO:root:current mean train loss 1142.3710164923416
INFO:root:current train perplexity2.4626238346099854
INFO:root:current mean train loss 1142.5084736668787
INFO:root:current train perplexity2.4634151458740234
INFO:root:current mean train loss 1143.1389474232992
INFO:root:current train perplexity2.464599609375
INFO:root:current mean train loss 1143.6507933418707
INFO:root:current train perplexity2.4657819271087646
INFO:root:current mean train loss 1144.3317578545932
INFO:root:current train perplexity2.4668238162994385
INFO:root:current mean train loss 1144.807900565011
INFO:root:current train perplexity2.466933488845825
INFO:root:current mean train loss 1145.5306095796473
INFO:root:current train perplexity2.4655921459198
INFO:root:current mean train loss 1145.6146659119488
INFO:root:current train perplexity2.465545654296875
INFO:root:current mean train loss 1145.7458183875451
INFO:root:current train perplexity2.466336727142334
INFO:root:current mean train loss 1146.032098168063
INFO:root:current train perplexity2.4674413204193115
INFO:root:current mean train loss 1146.16502012773
INFO:root:current train perplexity2.4678409099578857
INFO:root:current mean train loss 1146.6844357726395
INFO:root:current train perplexity2.4690823554992676
INFO:root:current mean train loss 1146.8085265490474
INFO:root:current train perplexity2.47013521194458

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.49s/it]
INFO:root:final mean train loss: 1146.5170440750776
INFO:root:final train perplexity: 2.4699854850769043
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2587.202141944398
INFO:root:eval perplexity: 8.104157447814941
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 3228.7919657822194
INFO:root:eval perplexity: 14.021543502807617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/134
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [20:02:47<9:54:13, 540.21s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1136.6590496905437
INFO:root:current train perplexity2.4576594829559326
INFO:root:current mean train loss 1137.7164472159693
INFO:root:current train perplexity2.4711251258850098
INFO:root:current mean train loss 1139.4094066413302
INFO:root:current train perplexity2.4659218788146973
INFO:root:current mean train loss 1140.482115889734
INFO:root:current train perplexity2.4600446224212646
INFO:root:current mean train loss 1139.7954498227039
INFO:root:current train perplexity2.4568073749542236
INFO:root:current mean train loss 1140.406372493433
INFO:root:current train perplexity2.4584057331085205
INFO:root:current mean train loss 1140.5679242853928
INFO:root:current train perplexity2.4600536823272705
INFO:root:current mean train loss 1140.0798614776886
INFO:root:current train perplexity2.4590251445770264
INFO:root:current mean train loss 1140.9814286096066
INFO:root:current train perplexity2.459846019744873
INFO:root:current mean train loss 1140.9847273421508
INFO:root:current train perplexity2.4616615772247314
INFO:root:current mean train loss 1142.340057061354
INFO:root:current train perplexity2.462628126144409
INFO:root:current mean train loss 1142.1577036427357
INFO:root:current train perplexity2.46262264251709
INFO:root:current mean train loss 1142.9881039278155
INFO:root:current train perplexity2.4625205993652344
INFO:root:current mean train loss 1143.2658030081245
INFO:root:current train perplexity2.462583541870117
INFO:root:current mean train loss 1143.3541833339063
INFO:root:current train perplexity2.463294267654419
INFO:root:current mean train loss 1143.4691855673104
INFO:root:current train perplexity2.463621139526367
INFO:root:current mean train loss 1143.5531444060496
INFO:root:current train perplexity2.4634063243865967
INFO:root:current mean train loss 1143.9042486513874
INFO:root:current train perplexity2.463740110397339
INFO:root:current mean train loss 1144.2471428913325
INFO:root:current train perplexity2.464564323425293
INFO:root:current mean train loss 1144.5374671885868
INFO:root:current train perplexity2.4655652046203613

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.59s/it]
INFO:root:final mean train loss: 1144.2726634030864
INFO:root:final train perplexity: 2.4656174182891846
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2589.9695590404754
INFO:root:eval perplexity: 8.122315406799316
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 3233.0652872721353
INFO:root:eval perplexity: 14.070627212524414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/135
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [20:11:48<9:45:35, 540.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1131.9626036299037
INFO:root:current train perplexity2.457232713699341
INFO:root:current mean train loss 1134.5300349599308
INFO:root:current train perplexity2.452927350997925
INFO:root:current mean train loss 1136.5461483909971
INFO:root:current train perplexity2.452456474304199
INFO:root:current mean train loss 1135.3526137298738
INFO:root:current train perplexity2.4536235332489014
INFO:root:current mean train loss 1135.9409024010786
INFO:root:current train perplexity2.4537582397460938
INFO:root:current mean train loss 1136.3135201296823
INFO:root:current train perplexity2.4533298015594482
INFO:root:current mean train loss 1136.5603794240815
INFO:root:current train perplexity2.4542653560638428
INFO:root:current mean train loss 1137.3056828188955
INFO:root:current train perplexity2.454066514968872
INFO:root:current mean train loss 1137.5849941176857
INFO:root:current train perplexity2.4531309604644775
INFO:root:current mean train loss 1137.8207447811872
INFO:root:current train perplexity2.4556546211242676
INFO:root:current mean train loss 1138.6407825532735
INFO:root:current train perplexity2.45619797706604
INFO:root:current mean train loss 1138.934268203812
INFO:root:current train perplexity2.4565913677215576
INFO:root:current mean train loss 1139.0199541566544
INFO:root:current train perplexity2.4578053951263428
INFO:root:current mean train loss 1139.4421714224466
INFO:root:current train perplexity2.4570717811584473
INFO:root:current mean train loss 1140.4307326964106
INFO:root:current train perplexity2.458557367324829
INFO:root:current mean train loss 1141.0385095076997
INFO:root:current train perplexity2.4584100246429443
INFO:root:current mean train loss 1141.6841339147359
INFO:root:current train perplexity2.4591028690338135
INFO:root:current mean train loss 1141.7772216796875
INFO:root:current train perplexity2.4592983722686768
INFO:root:current mean train loss 1141.7040721728154
INFO:root:current train perplexity2.459800958633423

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.46s/it]
INFO:root:final mean train loss: 1141.6579039819421
INFO:root:final train perplexity: 2.460538387298584
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 2593.6466748393173
INFO:root:eval perplexity: 8.146507263183594
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3236.3733637383643
INFO:root:eval perplexity: 14.108748435974121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/136
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [20:20:49<9:36:46, 540.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1136.3019020774148
INFO:root:current train perplexity2.4634597301483154
INFO:root:current mean train loss 1130.8942211254223
INFO:root:current train perplexity2.428248405456543
INFO:root:current mean train loss 1131.0789667644772
INFO:root:current train perplexity2.436631917953491
INFO:root:current mean train loss 1133.9109326328878
INFO:root:current train perplexity2.4389452934265137
INFO:root:current mean train loss 1134.7413142963048
INFO:root:current train perplexity2.4415340423583984
INFO:root:current mean train loss 1135.7457263446368
INFO:root:current train perplexity2.4441258907318115
INFO:root:current mean train loss 1134.8374618804983
INFO:root:current train perplexity2.444143772125244
INFO:root:current mean train loss 1135.3194911436358
INFO:root:current train perplexity2.443970203399658
INFO:root:current mean train loss 1135.791247272609
INFO:root:current train perplexity2.444274663925171
INFO:root:current mean train loss 1135.648527009296
INFO:root:current train perplexity2.446138381958008
INFO:root:current mean train loss 1136.411013639999
INFO:root:current train perplexity2.4481313228607178
INFO:root:current mean train loss 1136.4943423541572
INFO:root:current train perplexity2.449012517929077
INFO:root:current mean train loss 1136.7074943309378
INFO:root:current train perplexity2.449219226837158
INFO:root:current mean train loss 1137.5374084519212
INFO:root:current train perplexity2.4505932331085205
INFO:root:current mean train loss 1137.670749721081
INFO:root:current train perplexity2.4512197971343994
INFO:root:current mean train loss 1138.4879712673467
INFO:root:current train perplexity2.4518723487854004
INFO:root:current mean train loss 1138.6845138616106
INFO:root:current train perplexity2.4522860050201416
INFO:root:current mean train loss 1138.5935540168623
INFO:root:current train perplexity2.4527299404144287
INFO:root:current mean train loss 1138.8600845042017
INFO:root:current train perplexity2.453514575958252
INFO:root:current mean train loss 1139.1746311956274
INFO:root:current train perplexity2.4546515941619873

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.24s/it]
INFO:root:final mean train loss: 1139.190770474817
INFO:root:final train perplexity: 2.4557552337646484
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 2599.1172121737864
INFO:root:eval perplexity: 8.18262767791748
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 3243.1553678039118
INFO:root:eval perplexity: 14.187220573425293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/137
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [20:29:50<9:27:49, 540.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1127.8089904785156
INFO:root:current train perplexity2.4292056560516357
INFO:root:current mean train loss 1129.7611532211304
INFO:root:current train perplexity2.4277303218841553
INFO:root:current mean train loss 1130.5217076351769
INFO:root:current train perplexity2.437932014465332
INFO:root:current mean train loss 1129.3430261379335
INFO:root:current train perplexity2.4389054775238037
INFO:root:current mean train loss 1130.6791310533185
INFO:root:current train perplexity2.437006711959839
INFO:root:current mean train loss 1131.1595884380918
INFO:root:current train perplexity2.4410369396209717
INFO:root:current mean train loss 1132.1978695620396
INFO:root:current train perplexity2.443340301513672
INFO:root:current mean train loss 1133.3356635125128
INFO:root:current train perplexity2.4438867568969727
INFO:root:current mean train loss 1133.6011143191424
INFO:root:current train perplexity2.4437527656555176
INFO:root:current mean train loss 1134.1761206265153
INFO:root:current train perplexity2.4438977241516113
INFO:root:current mean train loss 1134.196420394957
INFO:root:current train perplexity2.443889856338501
INFO:root:current mean train loss 1134.1179642914035
INFO:root:current train perplexity2.445295572280884
INFO:root:current mean train loss 1134.1791286406378
INFO:root:current train perplexity2.4457578659057617
INFO:root:current mean train loss 1134.2194396788816
INFO:root:current train perplexity2.445970058441162
INFO:root:current mean train loss 1134.0236188958006
INFO:root:current train perplexity2.4473319053649902
INFO:root:current mean train loss 1134.6839973489652
INFO:root:current train perplexity2.4483819007873535
INFO:root:current mean train loss 1134.8314272718874
INFO:root:current train perplexity2.449376106262207
INFO:root:current mean train loss 1135.5066932395653
INFO:root:current train perplexity2.449756145477295
INFO:root:current mean train loss 1135.9850953350442
INFO:root:current train perplexity2.4500019550323486
INFO:root:current mean train loss 1136.720763590326
INFO:root:current train perplexity2.450624465942383

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.88s/it]
INFO:root:final mean train loss: 1136.6852262172804
INFO:root:final train perplexity: 2.4509074687957764
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2603.3992283597904
INFO:root:eval perplexity: 8.211015701293945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it]
INFO:root:eval mean loss: 3247.350933534879
INFO:root:eval perplexity: 14.235981941223145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/138
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [20:38:51<9:18:44, 540.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1122.9248996310764
INFO:root:current train perplexity2.432694673538208
INFO:root:current mean train loss 1128.1116598195042
INFO:root:current train perplexity2.441589832305908
INFO:root:current mean train loss 1131.0856111487565
INFO:root:current train perplexity2.443214178085327
INFO:root:current mean train loss 1130.234868588655
INFO:root:current train perplexity2.4371495246887207
INFO:root:current mean train loss 1128.9938652124297
INFO:root:current train perplexity2.438607931137085
INFO:root:current mean train loss 1128.1022552770212
INFO:root:current train perplexity2.4398856163024902
INFO:root:current mean train loss 1128.1211187318313
INFO:root:current train perplexity2.438786029815674
INFO:root:current mean train loss 1129.318588605023
INFO:root:current train perplexity2.438948392868042
INFO:root:current mean train loss 1130.0652808917346
INFO:root:current train perplexity2.440152168273926
INFO:root:current mean train loss 1130.7303110274058
INFO:root:current train perplexity2.441612720489502
INFO:root:current mean train loss 1131.3920036352422
INFO:root:current train perplexity2.442866802215576
INFO:root:current mean train loss 1131.925202455479
INFO:root:current train perplexity2.4429008960723877
INFO:root:current mean train loss 1131.917818735881
INFO:root:current train perplexity2.442656993865967
INFO:root:current mean train loss 1132.03621494903
INFO:root:current train perplexity2.442075729370117
INFO:root:current mean train loss 1132.6211494208208
INFO:root:current train perplexity2.4418153762817383
INFO:root:current mean train loss 1132.9419989823523
INFO:root:current train perplexity2.4424374103546143
INFO:root:current mean train loss 1133.6362154789608
INFO:root:current train perplexity2.443363904953003
INFO:root:current mean train loss 1133.6193130624329
INFO:root:current train perplexity2.444734811782837
INFO:root:current mean train loss 1134.1754457385882
INFO:root:current train perplexity2.4456417560577393
INFO:root:current mean train loss 1134.5653973655405
INFO:root:current train perplexity2.4461166858673096

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.57s/it]
INFO:root:final mean train loss: 1134.3555751229198
INFO:root:final train perplexity: 2.44640851020813
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2608.1480461824026
INFO:root:eval perplexity: 8.2426118850708
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3253.4367853259364
INFO:root:eval perplexity: 14.307014465332031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/139
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [20:47:52<9:09:52, 540.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1126.5474636939264
INFO:root:current train perplexity2.430410623550415
INFO:root:current mean train loss 1126.1053594895352
INFO:root:current train perplexity2.4285659790039062
INFO:root:current mean train loss 1124.2342384862536
INFO:root:current train perplexity2.4280600547790527
INFO:root:current mean train loss 1122.7713768047522
INFO:root:current train perplexity2.4252800941467285
INFO:root:current mean train loss 1123.490092223857
INFO:root:current train perplexity2.4271857738494873
INFO:root:current mean train loss 1125.4892334853203
INFO:root:current train perplexity2.4290497303009033
INFO:root:current mean train loss 1126.4367954219576
INFO:root:current train perplexity2.4289536476135254
INFO:root:current mean train loss 1127.497575254265
INFO:root:current train perplexity2.4290871620178223
INFO:root:current mean train loss 1127.9839408148746
INFO:root:current train perplexity2.4297235012054443
INFO:root:current mean train loss 1128.3753173574341
INFO:root:current train perplexity2.4297869205474854
INFO:root:current mean train loss 1128.44780838961
INFO:root:current train perplexity2.4292681217193604
INFO:root:current mean train loss 1128.948887101139
INFO:root:current train perplexity2.432119607925415
INFO:root:current mean train loss 1129.0351015988697
INFO:root:current train perplexity2.432981014251709
INFO:root:current mean train loss 1129.2098229137987
INFO:root:current train perplexity2.4345386028289795
INFO:root:current mean train loss 1129.3226215660002
INFO:root:current train perplexity2.4351956844329834
INFO:root:current mean train loss 1129.9315208991877
INFO:root:current train perplexity2.4351484775543213
INFO:root:current mean train loss 1130.3707595623214
INFO:root:current train perplexity2.4363760948181152
INFO:root:current mean train loss 1130.9222165474691
INFO:root:current train perplexity2.4371135234832764
INFO:root:current mean train loss 1131.0868709248707
INFO:root:current train perplexity2.4390010833740234
INFO:root:current mean train loss 1131.6120833184011
INFO:root:current train perplexity2.4405324459075928

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.90s/it]
INFO:root:final mean train loss: 1131.4156376717972
INFO:root:final train perplexity: 2.4407424926757812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 2608.4047847233765
INFO:root:eval perplexity: 8.244319915771484
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it]
INFO:root:eval mean loss: 3253.6022719795824
INFO:root:eval perplexity: 14.308948516845703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/140
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [20:56:53<9:00:48, 540.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1119.5177388251582
INFO:root:current train perplexity2.4168379306793213
INFO:root:current mean train loss 1117.9191158017632
INFO:root:current train perplexity2.4225783348083496
INFO:root:current mean train loss 1119.4319643957213
INFO:root:current train perplexity2.4224905967712402
INFO:root:current mean train loss 1121.3621678012657
INFO:root:current train perplexity2.4259095191955566
INFO:root:current mean train loss 1122.1554699222827
INFO:root:current train perplexity2.425441265106201
INFO:root:current mean train loss 1123.7170241492606
INFO:root:current train perplexity2.4244954586029053
INFO:root:current mean train loss 1123.6557992926753
INFO:root:current train perplexity2.426220655441284
INFO:root:current mean train loss 1124.6795840771422
INFO:root:current train perplexity2.4257864952087402
INFO:root:current mean train loss 1124.8622659416328
INFO:root:current train perplexity2.4272093772888184
INFO:root:current mean train loss 1125.3262887083838
INFO:root:current train perplexity2.428342819213867
INFO:root:current mean train loss 1125.506711038867
INFO:root:current train perplexity2.429792881011963
INFO:root:current mean train loss 1126.9015588347845
INFO:root:current train perplexity2.4306728839874268
INFO:root:current mean train loss 1127.1476450451098
INFO:root:current train perplexity2.432379722595215
INFO:root:current mean train loss 1127.4978639908336
INFO:root:current train perplexity2.433137893676758
INFO:root:current mean train loss 1127.784296475527
INFO:root:current train perplexity2.4333503246307373
INFO:root:current mean train loss 1127.9317694211625
INFO:root:current train perplexity2.4336888790130615
INFO:root:current mean train loss 1128.271121653863
INFO:root:current train perplexity2.434997797012329
INFO:root:current mean train loss 1128.6423285636022
INFO:root:current train perplexity2.4351563453674316
INFO:root:current mean train loss 1128.7208057706061
INFO:root:current train perplexity2.435150623321533
INFO:root:current mean train loss 1129.0061701947598
INFO:root:current train perplexity2.435554265975952

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.06s/it]
INFO:root:final mean train loss: 1128.7430400223186
INFO:root:final train perplexity: 2.435603618621826
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 2612.5893667234595
INFO:root:eval perplexity: 8.272271156311035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3258.1332674499945
INFO:root:eval perplexity: 14.362068176269531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/141
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [21:05:54<8:51:46, 540.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1118.4758059183757
INFO:root:current train perplexity2.425732374191284
INFO:root:current mean train loss 1121.3425255600287
INFO:root:current train perplexity2.415292263031006
INFO:root:current mean train loss 1122.6019584037163
INFO:root:current train perplexity2.4180104732513428
INFO:root:current mean train loss 1122.928248858211
INFO:root:current train perplexity2.419267177581787
INFO:root:current mean train loss 1122.6179991691342
INFO:root:current train perplexity2.4188497066497803
INFO:root:current mean train loss 1123.0607119566641
INFO:root:current train perplexity2.4189610481262207
INFO:root:current mean train loss 1123.4547327852797
INFO:root:current train perplexity2.419759750366211
INFO:root:current mean train loss 1123.7560047552215
INFO:root:current train perplexity2.421025514602661
INFO:root:current mean train loss 1123.9664966038295
INFO:root:current train perplexity2.421308755874634
INFO:root:current mean train loss 1124.3072965690887
INFO:root:current train perplexity2.4208099842071533
INFO:root:current mean train loss 1124.6785288344336
INFO:root:current train perplexity2.4217357635498047
INFO:root:current mean train loss 1124.9540261361112
INFO:root:current train perplexity2.424013376235962
INFO:root:current mean train loss 1125.0897276136611
INFO:root:current train perplexity2.424187660217285
INFO:root:current mean train loss 1125.5823296052338
INFO:root:current train perplexity2.4251868724823
INFO:root:current mean train loss 1125.450721944717
INFO:root:current train perplexity2.4264278411865234
INFO:root:current mean train loss 1125.4562949656245
INFO:root:current train perplexity2.427597999572754
INFO:root:current mean train loss 1126.0562365190037
INFO:root:current train perplexity2.4285032749176025
INFO:root:current mean train loss 1126.2812546557998
INFO:root:current train perplexity2.429556131362915
INFO:root:current mean train loss 1126.4078701035382
INFO:root:current train perplexity2.4306485652923584

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.74s/it]
INFO:root:final mean train loss: 1126.5764978883005
INFO:root:final train perplexity: 2.431445360183716
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 2614.9461488115026
INFO:root:eval perplexity: 8.288052558898926
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3260.8920738274323
INFO:root:eval perplexity: 14.394515037536621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/142
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [21:14:54<8:42:38, 540.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1110.4456787109375
INFO:root:current train perplexity2.4264936447143555
INFO:root:current mean train loss 1115.5713884471793
INFO:root:current train perplexity2.4115147590637207
INFO:root:current mean train loss 1116.9736161925982
INFO:root:current train perplexity2.410879135131836
INFO:root:current mean train loss 1119.2758399061502
INFO:root:current train perplexity2.4085323810577393
INFO:root:current mean train loss 1121.524754558868
INFO:root:current train perplexity2.412824869155884
INFO:root:current mean train loss 1120.646975273742
INFO:root:current train perplexity2.4137606620788574
INFO:root:current mean train loss 1120.943961761126
INFO:root:current train perplexity2.4151816368103027
INFO:root:current mean train loss 1120.7260617206675
INFO:root:current train perplexity2.418201446533203
INFO:root:current mean train loss 1120.773478340252
INFO:root:current train perplexity2.4192054271698
INFO:root:current mean train loss 1121.4459566782757
INFO:root:current train perplexity2.4209237098693848
INFO:root:current mean train loss 1122.3848801035754
INFO:root:current train perplexity2.421595811843872
INFO:root:current mean train loss 1122.1945894006556
INFO:root:current train perplexity2.4228646755218506
INFO:root:current mean train loss 1122.6598086565464
INFO:root:current train perplexity2.4227609634399414
INFO:root:current mean train loss 1123.54108860687
INFO:root:current train perplexity2.4235525131225586
INFO:root:current mean train loss 1123.9946679549275
INFO:root:current train perplexity2.423854112625122
INFO:root:current mean train loss 1124.2846609495052
INFO:root:current train perplexity2.4247336387634277
INFO:root:current mean train loss 1124.4877454423047
INFO:root:current train perplexity2.425530195236206
INFO:root:current mean train loss 1124.520358235392
INFO:root:current train perplexity2.425898551940918
INFO:root:current mean train loss 1124.69188261374
INFO:root:current train perplexity2.4272823333740234
INFO:root:current mean train loss 1124.7380217947514
INFO:root:current train perplexity2.427083969116211

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.68s/it]
INFO:root:final mean train loss: 1124.230920573286
INFO:root:final train perplexity: 2.4269518852233887
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2619.0764328976893
INFO:root:eval perplexity: 8.31578254699707
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 3267.000796487145
INFO:root:eval perplexity: 14.466607093811035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/143
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [21:23:56<8:34:09, 541.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1110.1658365885417
INFO:root:current train perplexity2.426510810852051
INFO:root:current mean train loss 1117.3143366887018
INFO:root:current train perplexity2.406296968460083
INFO:root:current mean train loss 1116.186091414742
INFO:root:current train perplexity2.4127304553985596
INFO:root:current mean train loss 1115.2742405746922
INFO:root:current train perplexity2.4145400524139404
INFO:root:current mean train loss 1115.4005087209302
INFO:root:current train perplexity2.4160335063934326
INFO:root:current mean train loss 1115.3501206883843
INFO:root:current train perplexity2.41912841796875
INFO:root:current mean train loss 1116.453420487661
INFO:root:current train perplexity2.418405055999756
INFO:root:current mean train loss 1117.0366442536654
INFO:root:current train perplexity2.417675256729126
INFO:root:current mean train loss 1117.8264413856598
INFO:root:current train perplexity2.416621685028076
INFO:root:current mean train loss 1118.8906934512559
INFO:root:current train perplexity2.41845440864563
INFO:root:current mean train loss 1119.353267514127
INFO:root:current train perplexity2.4192919731140137
INFO:root:current mean train loss 1119.6124221666723
INFO:root:current train perplexity2.419485092163086
INFO:root:current mean train loss 1119.7154362872363
INFO:root:current train perplexity2.419060230255127
INFO:root:current mean train loss 1120.1454441615513
INFO:root:current train perplexity2.4200429916381836
INFO:root:current mean train loss 1120.6429722926
INFO:root:current train perplexity2.4207253456115723
INFO:root:current mean train loss 1120.9772494048075
INFO:root:current train perplexity2.4216573238372803
INFO:root:current mean train loss 1121.6813419271832
INFO:root:current train perplexity2.4221084117889404
INFO:root:current mean train loss 1122.0731607249706
INFO:root:current train perplexity2.4219605922698975
INFO:root:current mean train loss 1122.3140767415364
INFO:root:current train perplexity2.4226789474487305
INFO:root:current mean train loss 1122.598695144258
INFO:root:current train perplexity2.4232444763183594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.58s/it]
INFO:root:final mean train loss: 1122.413215702613
INFO:root:final train perplexity: 2.423475503921509
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it]
INFO:root:eval mean loss: 2620.432460920185
INFO:root:eval perplexity: 8.324908256530762
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it]
INFO:root:eval mean loss: 3267.4655012847684
INFO:root:eval perplexity: 14.472105979919434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/144
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [21:32:59<8:25:28, 541.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1111.4312120802858
INFO:root:current train perplexity2.4089555740356445
INFO:root:current mean train loss 1117.5905662069515
INFO:root:current train perplexity2.4064855575561523
INFO:root:current mean train loss 1115.6135468888378
INFO:root:current train perplexity2.4079477787017822
INFO:root:current mean train loss 1114.2333066209248
INFO:root:current train perplexity2.409984827041626
INFO:root:current mean train loss 1114.436773039884
INFO:root:current train perplexity2.4099230766296387
INFO:root:current mean train loss 1114.2823472938328
INFO:root:current train perplexity2.4103357791900635
INFO:root:current mean train loss 1115.2401477748865
INFO:root:current train perplexity2.409013271331787
INFO:root:current mean train loss 1115.8126349800243
INFO:root:current train perplexity2.4098806381225586
INFO:root:current mean train loss 1115.4516945290593
INFO:root:current train perplexity2.411137342453003
INFO:root:current mean train loss 1116.0494653526555
INFO:root:current train perplexity2.4111034870147705
INFO:root:current mean train loss 1116.5183676179524
INFO:root:current train perplexity2.4110851287841797
INFO:root:current mean train loss 1116.8173885062765
INFO:root:current train perplexity2.412400960922241
INFO:root:current mean train loss 1117.3255250589696
INFO:root:current train perplexity2.412461042404175
INFO:root:current mean train loss 1117.9607962627454
INFO:root:current train perplexity2.413402557373047
INFO:root:current mean train loss 1118.6211188473862
INFO:root:current train perplexity2.414783239364624
INFO:root:current mean train loss 1118.825226836152
INFO:root:current train perplexity2.4155914783477783
INFO:root:current mean train loss 1119.018218827378
INFO:root:current train perplexity2.416111946105957
INFO:root:current mean train loss 1119.2334559090696
INFO:root:current train perplexity2.4173548221588135
INFO:root:current mean train loss 1119.7564402499197
INFO:root:current train perplexity2.4177560806274414
INFO:root:current mean train loss 1120.297698206576
INFO:root:current train perplexity2.4186742305755615

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.54s/it]
INFO:root:final mean train loss: 1119.952623499083
INFO:root:final train perplexity: 2.4187772274017334
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2626.685028725482
INFO:root:eval perplexity: 8.367110252380371
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3274.854566641733
INFO:root:eval perplexity: 14.55982494354248
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/145
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [21:42:00<8:16:20, 541.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1108.129955291748
INFO:root:current train perplexity2.3998804092407227
INFO:root:current mean train loss 1109.5762366318122
INFO:root:current train perplexity2.4078450202941895
INFO:root:current mean train loss 1112.1523289535985
INFO:root:current train perplexity2.4102747440338135
INFO:root:current mean train loss 1112.3804472200163
INFO:root:current train perplexity2.413079261779785
INFO:root:current mean train loss 1114.4838721176673
INFO:root:current train perplexity2.4127068519592285
INFO:root:current mean train loss 1114.2619049938012
INFO:root:current train perplexity2.4108922481536865
INFO:root:current mean train loss 1114.388079999441
INFO:root:current train perplexity2.411236524581909
INFO:root:current mean train loss 1114.4225638823984
INFO:root:current train perplexity2.4110934734344482
INFO:root:current mean train loss 1114.86958277667
INFO:root:current train perplexity2.4115865230560303
INFO:root:current mean train loss 1115.4310231189015
INFO:root:current train perplexity2.411146402359009
INFO:root:current mean train loss 1115.5503345575548
INFO:root:current train perplexity2.411407709121704
INFO:root:current mean train loss 1116.5440185651746
INFO:root:current train perplexity2.4120874404907227
INFO:root:current mean train loss 1116.6721237279191
INFO:root:current train perplexity2.411991834640503
INFO:root:current mean train loss 1116.795803528727
INFO:root:current train perplexity2.411970853805542
INFO:root:current mean train loss 1116.8229872489887
INFO:root:current train perplexity2.4123117923736572
INFO:root:current mean train loss 1117.1129880549047
INFO:root:current train perplexity2.412529706954956
INFO:root:current mean train loss 1117.5401621965261
INFO:root:current train perplexity2.413325071334839
INFO:root:current mean train loss 1117.768418534813
INFO:root:current train perplexity2.4143996238708496
INFO:root:current mean train loss 1117.938689104989
INFO:root:current train perplexity2.414659261703491
INFO:root:current mean train loss 1118.251083622639
INFO:root:current train perplexity2.414933204650879

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.26s/it]
INFO:root:final mean train loss: 1117.9366007086849
INFO:root:final train perplexity: 2.4149341583251953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2629.2110920358214
INFO:root:eval perplexity: 8.384222030639648
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3277.7392669028422
INFO:root:eval perplexity: 14.59421443939209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/146
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [21:51:01<8:07:09, 541.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1099.8997757523148
INFO:root:current train perplexity2.4063613414764404
INFO:root:current mean train loss 1105.4000132861058
INFO:root:current train perplexity2.401449203491211
INFO:root:current mean train loss 1106.8584199409893
INFO:root:current train perplexity2.3981120586395264
INFO:root:current mean train loss 1107.490884936075
INFO:root:current train perplexity2.396308183670044
INFO:root:current mean train loss 1109.2062975592028
INFO:root:current train perplexity2.3974225521087646
INFO:root:current mean train loss 1109.7783427936074
INFO:root:current train perplexity2.3997840881347656
INFO:root:current mean train loss 1110.8434714430755
INFO:root:current train perplexity2.4030354022979736
INFO:root:current mean train loss 1111.362967555868
INFO:root:current train perplexity2.4043612480163574
INFO:root:current mean train loss 1112.1939138180824
INFO:root:current train perplexity2.4047913551330566
INFO:root:current mean train loss 1112.588974263447
INFO:root:current train perplexity2.4050333499908447
INFO:root:current mean train loss 1113.3052580460258
INFO:root:current train perplexity2.40483021736145
INFO:root:current mean train loss 1113.3090108666352
INFO:root:current train perplexity2.405349016189575
INFO:root:current mean train loss 1113.9470267731356
INFO:root:current train perplexity2.4053165912628174
INFO:root:current mean train loss 1114.6785292463144
INFO:root:current train perplexity2.4066553115844727
INFO:root:current mean train loss 1114.9698584825103
INFO:root:current train perplexity2.407761573791504
INFO:root:current mean train loss 1115.1665004703684
INFO:root:current train perplexity2.4082348346710205
INFO:root:current mean train loss 1115.5395967845475
INFO:root:current train perplexity2.4085240364074707
INFO:root:current mean train loss 1115.9496194024491
INFO:root:current train perplexity2.4086270332336426
INFO:root:current mean train loss 1115.954435098051
INFO:root:current train perplexity2.410259246826172
INFO:root:current mean train loss 1116.106208104187
INFO:root:current train perplexity2.410857915878296

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.91s/it]
INFO:root:final mean train loss: 1115.7950087492957
INFO:root:final train perplexity: 2.4108588695526123
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2630.54934151291
INFO:root:eval perplexity: 8.39330005645752
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 3278.543126748809
INFO:root:eval perplexity: 14.603811264038086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/147
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [22:00:02<7:57:56, 541.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1104.5739609076052
INFO:root:current train perplexity2.382124423980713
INFO:root:current mean train loss 1109.0834165630918
INFO:root:current train perplexity2.388880491256714
INFO:root:current mean train loss 1109.1316946144873
INFO:root:current train perplexity2.3881335258483887
INFO:root:current mean train loss 1109.9412847931062
INFO:root:current train perplexity2.3925118446350098
INFO:root:current mean train loss 1110.1543130529933
INFO:root:current train perplexity2.3948912620544434
INFO:root:current mean train loss 1109.506735300938
INFO:root:current train perplexity2.394653797149658
INFO:root:current mean train loss 1109.814325283455
INFO:root:current train perplexity2.39481258392334
INFO:root:current mean train loss 1110.576349320567
INFO:root:current train perplexity2.395970582962036
INFO:root:current mean train loss 1110.802819878593
INFO:root:current train perplexity2.3973522186279297
INFO:root:current mean train loss 1111.5409830892254
INFO:root:current train perplexity2.3978030681610107
INFO:root:current mean train loss 1111.0069252111439
INFO:root:current train perplexity2.3996524810791016
INFO:root:current mean train loss 1111.5693450061626
INFO:root:current train perplexity2.40047025680542
INFO:root:current mean train loss 1112.2562064007727
INFO:root:current train perplexity2.401183843612671
INFO:root:current mean train loss 1112.2208303470638
INFO:root:current train perplexity2.4027743339538574
INFO:root:current mean train loss 1112.575287761612
INFO:root:current train perplexity2.40362811088562
INFO:root:current mean train loss 1112.9956945006331
INFO:root:current train perplexity2.4043171405792236
INFO:root:current mean train loss 1113.0852405561575
INFO:root:current train perplexity2.4045329093933105
INFO:root:current mean train loss 1113.1697572701764
INFO:root:current train perplexity2.4052436351776123
INFO:root:current mean train loss 1113.5884142474706
INFO:root:current train perplexity2.406114339828491

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.86s/it]
INFO:root:final mean train loss: 1113.6219060746816
INFO:root:final train perplexity: 2.4067306518554688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 2635.144835560034
INFO:root:eval perplexity: 8.424553871154785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3285.488022824551
INFO:root:eval perplexity: 14.686994552612305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/148
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [22:09:03<7:49:02, 541.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1098.0798502604166
INFO:root:current train perplexity2.4100239276885986
INFO:root:current mean train loss 1103.522748598845
INFO:root:current train perplexity2.3937759399414062
INFO:root:current mean train loss 1103.8307038063226
INFO:root:current train perplexity2.394815683364868
INFO:root:current mean train loss 1105.0350903707838
INFO:root:current train perplexity2.3932807445526123
INFO:root:current mean train loss 1106.1193877070782
INFO:root:current train perplexity2.393770456314087
INFO:root:current mean train loss 1106.9947384139866
INFO:root:current train perplexity2.395200729370117
INFO:root:current mean train loss 1107.7427214335619
INFO:root:current train perplexity2.39664888381958
INFO:root:current mean train loss 1108.2669496763003
INFO:root:current train perplexity2.3963890075683594
INFO:root:current mean train loss 1108.6595595283743
INFO:root:current train perplexity2.3970894813537598
INFO:root:current mean train loss 1108.5970804516735
INFO:root:current train perplexity2.398087739944458
INFO:root:current mean train loss 1109.0009080106988
INFO:root:current train perplexity2.3987433910369873
INFO:root:current mean train loss 1109.5458384424046
INFO:root:current train perplexity2.3981235027313232
INFO:root:current mean train loss 1109.193230070891
INFO:root:current train perplexity2.3976974487304688
INFO:root:current mean train loss 1109.7426440336858
INFO:root:current train perplexity2.398036003112793
INFO:root:current mean train loss 1110.306712918231
INFO:root:current train perplexity2.3986282348632812
INFO:root:current mean train loss 1110.392764574309
INFO:root:current train perplexity2.3983981609344482
INFO:root:current mean train loss 1110.5738477771865
INFO:root:current train perplexity2.3991405963897705
INFO:root:current mean train loss 1110.9873632670144
INFO:root:current train perplexity2.4005239009857178
INFO:root:current mean train loss 1111.1760201446282
INFO:root:current train perplexity2.400996208190918
INFO:root:current mean train loss 1111.2349885387769
INFO:root:current train perplexity2.4014692306518555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.49s/it]
INFO:root:final mean train loss: 1111.1821267978746
INFO:root:final train perplexity: 2.402103900909424
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2636.7246881579676
INFO:root:eval perplexity: 8.435324668884277
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 3286.7116625630265
INFO:root:eval perplexity: 14.701698303222656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/149
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [22:18:04<7:40:00, 541.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1109.552921295166
INFO:root:current train perplexity2.404531955718994
INFO:root:current mean train loss 1101.9767437559185
INFO:root:current train perplexity2.392239570617676
INFO:root:current mean train loss 1102.3720913591055
INFO:root:current train perplexity2.4001410007476807
INFO:root:current mean train loss 1104.8037440288497
INFO:root:current train perplexity2.397440195083618
INFO:root:current mean train loss 1105.580376236527
INFO:root:current train perplexity2.3964293003082275
INFO:root:current mean train loss 1105.0804703791339
INFO:root:current train perplexity2.3975486755371094
INFO:root:current mean train loss 1105.8434679055515
INFO:root:current train perplexity2.3977513313293457
INFO:root:current mean train loss 1105.8993482746062
INFO:root:current train perplexity2.3959901332855225
INFO:root:current mean train loss 1106.2341715739324
INFO:root:current train perplexity2.397265911102295
INFO:root:current mean train loss 1106.7278215138185
INFO:root:current train perplexity2.397061824798584
INFO:root:current mean train loss 1107.682699336562
INFO:root:current train perplexity2.397010326385498
INFO:root:current mean train loss 1107.9036856068317
INFO:root:current train perplexity2.3972673416137695
INFO:root:current mean train loss 1107.9560811922147
INFO:root:current train perplexity2.3978657722473145
INFO:root:current mean train loss 1108.4280481195306
INFO:root:current train perplexity2.398575782775879
INFO:root:current mean train loss 1108.4943678445657
INFO:root:current train perplexity2.3995816707611084
INFO:root:current mean train loss 1108.5860659447414
INFO:root:current train perplexity2.399348020553589
INFO:root:current mean train loss 1108.9733412499522
INFO:root:current train perplexity2.398874044418335
INFO:root:current mean train loss 1109.2768240349396
INFO:root:current train perplexity2.3994061946868896
INFO:root:current mean train loss 1109.6330295879247
INFO:root:current train perplexity2.3990862369537354
INFO:root:current mean train loss 1110.0717695090095
INFO:root:current train perplexity2.399778127670288

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.04s/it]
INFO:root:final mean train loss: 1109.8573219503228
INFO:root:final train perplexity: 2.3995954990386963
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2639.1425967385585
INFO:root:eval perplexity: 8.451833724975586
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 3288.6186804805243
INFO:root:eval perplexity: 14.72464656829834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/150
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [22:27:05<7:30:51, 541.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1101.2175018933356
INFO:root:current train perplexity2.416902542114258
INFO:root:current mean train loss 1102.4499331480704
INFO:root:current train perplexity2.3996524810791016
INFO:root:current mean train loss 1103.333395348974
INFO:root:current train perplexity2.397627353668213
INFO:root:current mean train loss 1104.2033420333207
INFO:root:current train perplexity2.395263910293579
INFO:root:current mean train loss 1103.9665014865934
INFO:root:current train perplexity2.391936779022217
INFO:root:current mean train loss 1104.4364617352928
INFO:root:current train perplexity2.3899102210998535
INFO:root:current mean train loss 1104.5667928686862
INFO:root:current train perplexity2.3898210525512695
INFO:root:current mean train loss 1106.1600634341883
INFO:root:current train perplexity2.389604091644287
INFO:root:current mean train loss 1106.2437283321601
INFO:root:current train perplexity2.3905274868011475
INFO:root:current mean train loss 1106.4775061974158
INFO:root:current train perplexity2.3912301063537598
INFO:root:current mean train loss 1106.1048871995836
INFO:root:current train perplexity2.391187906265259
INFO:root:current mean train loss 1106.5465655745995
INFO:root:current train perplexity2.391268730163574
INFO:root:current mean train loss 1106.6102680484232
INFO:root:current train perplexity2.392402410507202
INFO:root:current mean train loss 1106.6534353698776
INFO:root:current train perplexity2.3940529823303223
INFO:root:current mean train loss 1106.8656355895364
INFO:root:current train perplexity2.394076347351074
INFO:root:current mean train loss 1107.6212113677802
INFO:root:current train perplexity2.3951094150543213
INFO:root:current mean train loss 1107.7296170338202
INFO:root:current train perplexity2.3948869705200195
INFO:root:current mean train loss 1108.1603090647222
INFO:root:current train perplexity2.395510673522949
INFO:root:current mean train loss 1108.3632454343458
INFO:root:current train perplexity2.396075487136841
INFO:root:current mean train loss 1108.5543856437296
INFO:root:current train perplexity2.3962929248809814

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.78s/it]
INFO:root:final mean train loss: 1108.2140722693184
INFO:root:final train perplexity: 2.3964879512786865
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2641.3834747963765
INFO:root:eval perplexity: 8.46716594696045
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3291.4164541258033
INFO:root:eval perplexity: 14.758373260498047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/151
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [22:36:06<7:21:56, 541.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1102.9631458629262
INFO:root:current train perplexity2.3794803619384766
INFO:root:current mean train loss 1099.3461998629282
INFO:root:current train perplexity2.3858554363250732
INFO:root:current mean train loss 1100.301699760265
INFO:root:current train perplexity2.3816895484924316
INFO:root:current mean train loss 1101.3979970796513
INFO:root:current train perplexity2.3850343227386475
INFO:root:current mean train loss 1102.753792693175
INFO:root:current train perplexity2.388249635696411
INFO:root:current mean train loss 1102.3044533881198
INFO:root:current train perplexity2.3885672092437744
INFO:root:current mean train loss 1101.8085995235958
INFO:root:current train perplexity2.3903002738952637
INFO:root:current mean train loss 1102.4768988308022
INFO:root:current train perplexity2.390394449234009
INFO:root:current mean train loss 1102.7095852118441
INFO:root:current train perplexity2.3910863399505615
INFO:root:current mean train loss 1103.285242558513
INFO:root:current train perplexity2.39003849029541
INFO:root:current mean train loss 1103.6726234536234
INFO:root:current train perplexity2.390434503555298
INFO:root:current mean train loss 1103.9589232351523
INFO:root:current train perplexity2.3905646800994873
INFO:root:current mean train loss 1104.3277429276357
INFO:root:current train perplexity2.390127182006836
INFO:root:current mean train loss 1104.3842225640271
INFO:root:current train perplexity2.3905091285705566
INFO:root:current mean train loss 1104.769398021828
INFO:root:current train perplexity2.3909265995025635
INFO:root:current mean train loss 1104.967916515443
INFO:root:current train perplexity2.391594409942627
INFO:root:current mean train loss 1105.3622163587115
INFO:root:current train perplexity2.392137289047241
INFO:root:current mean train loss 1105.8027015072573
INFO:root:current train perplexity2.391869068145752
INFO:root:current mean train loss 1106.357350405645
INFO:root:current train perplexity2.3921072483062744
INFO:root:current mean train loss 1106.4157754271343
INFO:root:current train perplexity2.3927645683288574

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.26s/it]
INFO:root:final mean train loss: 1106.1972606233799
INFO:root:final train perplexity: 2.392679214477539
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2643.485076254987
INFO:root:eval perplexity: 8.481568336486816
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3293.904640576518
INFO:root:eval perplexity: 14.788439750671387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/152
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [22:45:07<7:12:52, 541.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1104.7441737163497
INFO:root:current train perplexity2.3821609020233154
INFO:root:current mean train loss 1101.1983996115096
INFO:root:current train perplexity2.3822853565216064
INFO:root:current mean train loss 1100.2169566879004
INFO:root:current train perplexity2.384829044342041
INFO:root:current mean train loss 1100.1744472414023
INFO:root:current train perplexity2.3869521617889404
INFO:root:current mean train loss 1100.5974223450844
INFO:root:current train perplexity2.3853774070739746
INFO:root:current mean train loss 1100.7977179761203
INFO:root:current train perplexity2.3838319778442383
INFO:root:current mean train loss 1100.4332721313656
INFO:root:current train perplexity2.3832478523254395
INFO:root:current mean train loss 1100.917004737513
INFO:root:current train perplexity2.384854316711426
INFO:root:current mean train loss 1101.136521543544
INFO:root:current train perplexity2.3839075565338135
INFO:root:current mean train loss 1101.5397841801841
INFO:root:current train perplexity2.3847224712371826
INFO:root:current mean train loss 1101.9520074874301
INFO:root:current train perplexity2.3853566646575928
INFO:root:current mean train loss 1102.3904106804403
INFO:root:current train perplexity2.3849472999572754
INFO:root:current mean train loss 1102.722704821235
INFO:root:current train perplexity2.3862242698669434
INFO:root:current mean train loss 1103.0680140387037
INFO:root:current train perplexity2.3870091438293457
INFO:root:current mean train loss 1103.5814853907436
INFO:root:current train perplexity2.3873143196105957
INFO:root:current mean train loss 1103.9271771159265
INFO:root:current train perplexity2.3879318237304688
INFO:root:current mean train loss 1104.2791708517273
INFO:root:current train perplexity2.3882691860198975
INFO:root:current mean train loss 1104.2394830914475
INFO:root:current train perplexity2.3888638019561768
INFO:root:current mean train loss 1104.3225511580279
INFO:root:current train perplexity2.388810157775879
INFO:root:current mean train loss 1104.1477578952345
INFO:root:current train perplexity2.388814687728882

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.18s/it]
INFO:root:final mean train loss: 1104.1477578952345
INFO:root:final train perplexity: 2.388814687728882
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2650.477987952266
INFO:root:eval perplexity: 8.529671669006348
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 3301.949130010943
INFO:root:eval perplexity: 14.886055946350098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/153
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [22:54:08<7:03:48, 541.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1098.3067468261718
INFO:root:current train perplexity2.358783483505249
INFO:root:current mean train loss 1097.6952178955078
INFO:root:current train perplexity2.3699917793273926
INFO:root:current mean train loss 1096.8364841715495
INFO:root:current train perplexity2.3693134784698486
INFO:root:current mean train loss 1098.5667350769043
INFO:root:current train perplexity2.3703575134277344
INFO:root:current mean train loss 1098.9947796630859
INFO:root:current train perplexity2.3750159740448
INFO:root:current mean train loss 1099.7862541707357
INFO:root:current train perplexity2.3764498233795166
INFO:root:current mean train loss 1099.2883659144811
INFO:root:current train perplexity2.3758485317230225
INFO:root:current mean train loss 1099.4043413543702
INFO:root:current train perplexity2.376786470413208
INFO:root:current mean train loss 1100.0292392985027
INFO:root:current train perplexity2.376434564590454
INFO:root:current mean train loss 1099.3831997680663
INFO:root:current train perplexity2.3771400451660156
INFO:root:current mean train loss 1099.8322427645596
INFO:root:current train perplexity2.378160238265991
INFO:root:current mean train loss 1100.3745781453451
INFO:root:current train perplexity2.3789074420928955
INFO:root:current mean train loss 1100.9891105769232
INFO:root:current train perplexity2.379969358444214
INFO:root:current mean train loss 1101.7043803187778
INFO:root:current train perplexity2.3803436756134033
INFO:root:current mean train loss 1102.1215960286459
INFO:root:current train perplexity2.381369113922119
INFO:root:current mean train loss 1102.0215824890138
INFO:root:current train perplexity2.3826165199279785
INFO:root:current mean train loss 1101.8461504408892
INFO:root:current train perplexity2.3830666542053223
INFO:root:current mean train loss 1102.1736410183378
INFO:root:current train perplexity2.3836429119110107
INFO:root:current mean train loss 1102.2975449090254
INFO:root:current train perplexity2.3846237659454346

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.02s/it]
INFO:root:final mean train loss: 1102.1868182714695
INFO:root:final train perplexity: 2.3851232528686523
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2651.525837350399
INFO:root:eval perplexity: 8.53690242767334
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3302.7935319183566
INFO:root:eval perplexity: 14.896333694458008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/154
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [23:03:09<6:54:42, 540.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1115.4180692784926
INFO:root:current train perplexity2.388009786605835
INFO:root:current mean train loss 1097.1146000267095
INFO:root:current train perplexity2.375641345977783
INFO:root:current mean train loss 1097.081761513987
INFO:root:current train perplexity2.3731844425201416
INFO:root:current mean train loss 1098.3853006934519
INFO:root:current train perplexity2.370882272720337
INFO:root:current mean train loss 1099.4316355021451
INFO:root:current train perplexity2.369884967803955
INFO:root:current mean train loss 1099.1676782132117
INFO:root:current train perplexity2.3732762336730957
INFO:root:current mean train loss 1099.3506782321529
INFO:root:current train perplexity2.374309778213501
INFO:root:current mean train loss 1099.028852603758
INFO:root:current train perplexity2.376037120819092
INFO:root:current mean train loss 1099.8810989585324
INFO:root:current train perplexity2.3781139850616455
INFO:root:current mean train loss 1099.9884237541107
INFO:root:current train perplexity2.3791635036468506
INFO:root:current mean train loss 1099.5314140207297
INFO:root:current train perplexity2.3795394897460938
INFO:root:current mean train loss 1099.6838698562171
INFO:root:current train perplexity2.380516290664673
INFO:root:current mean train loss 1099.5035298581777
INFO:root:current train perplexity2.380781650543213
INFO:root:current mean train loss 1099.5454130759272
INFO:root:current train perplexity2.3803799152374268
INFO:root:current mean train loss 1099.9106220899541
INFO:root:current train perplexity2.3810410499572754
INFO:root:current mean train loss 1100.0520975896222
INFO:root:current train perplexity2.3810901641845703
INFO:root:current mean train loss 1100.601009182526
INFO:root:current train perplexity2.381640911102295
INFO:root:current mean train loss 1100.9319191401132
INFO:root:current train perplexity2.381023406982422
INFO:root:current mean train loss 1101.252101362834
INFO:root:current train perplexity2.3812191486358643
INFO:root:current mean train loss 1101.4746779878126
INFO:root:current train perplexity2.382620096206665

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.42s/it]
INFO:root:final mean train loss: 1101.2258421281824
INFO:root:final train perplexity: 2.3833162784576416
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2650.9885145687886
INFO:root:eval perplexity: 8.533196449279785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 3303.9874869272217
INFO:root:eval perplexity: 14.91089153289795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/155
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [23:12:09<6:45:29, 540.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1092.1585944680608
INFO:root:current train perplexity2.3733224868774414
INFO:root:current mean train loss 1092.0263644545826
INFO:root:current train perplexity2.3854820728302
INFO:root:current mean train loss 1092.546918298444
INFO:root:current train perplexity2.379321813583374
INFO:root:current mean train loss 1092.046095248468
INFO:root:current train perplexity2.376950979232788
INFO:root:current mean train loss 1092.789548390472
INFO:root:current train perplexity2.373612642288208
INFO:root:current mean train loss 1092.4300289082616
INFO:root:current train perplexity2.3744423389434814
INFO:root:current mean train loss 1093.462083786444
INFO:root:current train perplexity2.3772342205047607
INFO:root:current mean train loss 1094.2517144725498
INFO:root:current train perplexity2.3762142658233643
INFO:root:current mean train loss 1094.7921419212287
INFO:root:current train perplexity2.37599515914917
INFO:root:current mean train loss 1095.2273860171724
INFO:root:current train perplexity2.3772826194763184
INFO:root:current mean train loss 1095.1424759471902
INFO:root:current train perplexity2.3760485649108887
INFO:root:current mean train loss 1095.7560090564546
INFO:root:current train perplexity2.377054452896118
INFO:root:current mean train loss 1096.4291869029041
INFO:root:current train perplexity2.3771729469299316
INFO:root:current mean train loss 1096.7922123075425
INFO:root:current train perplexity2.3772616386413574
INFO:root:current mean train loss 1097.1758138957216
INFO:root:current train perplexity2.376859664916992
INFO:root:current mean train loss 1097.7324274851414
INFO:root:current train perplexity2.3771326541900635
INFO:root:current mean train loss 1098.0702161660538
INFO:root:current train perplexity2.3776979446411133
INFO:root:current mean train loss 1098.4072249785427
INFO:root:current train perplexity2.377976417541504
INFO:root:current mean train loss 1098.9807097290438
INFO:root:current train perplexity2.3786780834198
INFO:root:current mean train loss 1098.9814518452183
INFO:root:current train perplexity2.3790805339813232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.19s/it]
INFO:root:final mean train loss: 1098.7143084689096
INFO:root:final train perplexity: 2.3786001205444336
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2656.631965366661
INFO:root:eval perplexity: 8.572234153747559
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3309.629334361841
INFO:root:eval perplexity: 14.97984790802002
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/156
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [23:21:10<6:36:31, 540.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1099.184040144378
INFO:root:current train perplexity2.355506420135498
INFO:root:current mean train loss 1095.2235936044858
INFO:root:current train perplexity2.3565845489501953
INFO:root:current mean train loss 1096.5734257793047
INFO:root:current train perplexity2.3581581115722656
INFO:root:current mean train loss 1095.24269664797
INFO:root:current train perplexity2.3610081672668457
INFO:root:current mean train loss 1095.3824207111368
INFO:root:current train perplexity2.36419415473938
INFO:root:current mean train loss 1094.6197063356044
INFO:root:current train perplexity2.3645334243774414
INFO:root:current mean train loss 1094.74559374925
INFO:root:current train perplexity2.365511655807495
INFO:root:current mean train loss 1094.8304167847818
INFO:root:current train perplexity2.364258289337158
INFO:root:current mean train loss 1094.5655159686903
INFO:root:current train perplexity2.3667361736297607
INFO:root:current mean train loss 1094.6844616558024
INFO:root:current train perplexity2.3690567016601562
INFO:root:current mean train loss 1095.0807829039309
INFO:root:current train perplexity2.3704147338867188
INFO:root:current mean train loss 1094.6594548494686
INFO:root:current train perplexity2.370357036590576
INFO:root:current mean train loss 1095.1325875334887
INFO:root:current train perplexity2.3713607788085938
INFO:root:current mean train loss 1095.5636514456162
INFO:root:current train perplexity2.3721323013305664
INFO:root:current mean train loss 1095.9438453006546
INFO:root:current train perplexity2.3725199699401855
INFO:root:current mean train loss 1096.0533240273412
INFO:root:current train perplexity2.3732857704162598
INFO:root:current mean train loss 1096.4403328297717
INFO:root:current train perplexity2.3738303184509277
INFO:root:current mean train loss 1096.7646753822034
INFO:root:current train perplexity2.374340057373047
INFO:root:current mean train loss 1096.9324432818198
INFO:root:current train perplexity2.374843120574951
INFO:root:current mean train loss 1097.16544613039
INFO:root:current train perplexity2.3755409717559814

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.63s/it]
INFO:root:final mean train loss: 1097.0180633744988
INFO:root:final train perplexity: 2.375420331954956
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2656.9269088853334
INFO:root:eval perplexity: 8.574275970458984
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3310.3012379314882
INFO:root:eval perplexity: 14.988081932067871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/157
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [23:30:11<6:27:39, 540.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1089.8190666647517
INFO:root:current train perplexity2.3530619144439697
INFO:root:current mean train loss 1086.725192478725
INFO:root:current train perplexity2.3615400791168213
INFO:root:current mean train loss 1089.193247780871
INFO:root:current train perplexity2.3584699630737305
INFO:root:current mean train loss 1089.6367549066958
INFO:root:current train perplexity2.356968641281128
INFO:root:current mean train loss 1089.9757552187666
INFO:root:current train perplexity2.3590121269226074
INFO:root:current mean train loss 1089.842132460903
INFO:root:current train perplexity2.359844207763672
INFO:root:current mean train loss 1090.6874564165128
INFO:root:current train perplexity2.3607711791992188
INFO:root:current mean train loss 1092.09490052859
INFO:root:current train perplexity2.360818386077881
INFO:root:current mean train loss 1093.272000994001
INFO:root:current train perplexity2.3641836643218994
INFO:root:current mean train loss 1093.569009134592
INFO:root:current train perplexity2.364912748336792
INFO:root:current mean train loss 1094.0347287753102
INFO:root:current train perplexity2.3661367893218994
INFO:root:current mean train loss 1094.5676910191366
INFO:root:current train perplexity2.365570545196533
INFO:root:current mean train loss 1094.7867739223154
INFO:root:current train perplexity2.366952896118164
INFO:root:current mean train loss 1094.714938782809
INFO:root:current train perplexity2.367020845413208
INFO:root:current mean train loss 1094.9217671490494
INFO:root:current train perplexity2.369533061981201
INFO:root:current mean train loss 1094.7202726870166
INFO:root:current train perplexity2.370375633239746
INFO:root:current mean train loss 1094.6911203215163
INFO:root:current train perplexity2.3715100288391113
INFO:root:current mean train loss 1094.76619157748
INFO:root:current train perplexity2.371629238128662
INFO:root:current mean train loss 1095.0544631598593
INFO:root:current train perplexity2.371563196182251
INFO:root:current mean train loss 1095.3975058764945
INFO:root:current train perplexity2.3717808723449707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.99s/it]
INFO:root:final mean train loss: 1095.1699773699
INFO:root:final train perplexity: 2.3719606399536133
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2660.1681064037566
INFO:root:eval perplexity: 8.596781730651855
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 3314.388107408023
INFO:root:eval perplexity: 15.03825855255127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/158
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [23:39:12<6:18:34, 540.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1081.0351332720588
INFO:root:current train perplexity2.3573355674743652
INFO:root:current mean train loss 1087.2731577280406
INFO:root:current train perplexity2.3580968379974365
INFO:root:current mean train loss 1088.2056692023027
INFO:root:current train perplexity2.3610126972198486
INFO:root:current mean train loss 1090.161145178064
INFO:root:current train perplexity2.3606925010681152
INFO:root:current mean train loss 1090.7699987667122
INFO:root:current train perplexity2.3616905212402344
INFO:root:current mean train loss 1090.2905844142294
INFO:root:current train perplexity2.365901231765747
INFO:root:current mean train loss 1090.7520217338617
INFO:root:current train perplexity2.3660476207733154
INFO:root:current mean train loss 1091.5300584537968
INFO:root:current train perplexity2.3673698902130127
INFO:root:current mean train loss 1092.0604892881577
INFO:root:current train perplexity2.3685765266418457
INFO:root:current mean train loss 1092.4203419951618
INFO:root:current train perplexity2.366813898086548
INFO:root:current mean train loss 1092.2773766021025
INFO:root:current train perplexity2.3667056560516357
INFO:root:current mean train loss 1092.9614398940203
INFO:root:current train perplexity2.367827892303467
INFO:root:current mean train loss 1093.0086071919839
INFO:root:current train perplexity2.3686749935150146
INFO:root:current mean train loss 1093.3003325865157
INFO:root:current train perplexity2.368436574935913
INFO:root:current mean train loss 1093.4461734039614
INFO:root:current train perplexity2.368349313735962
INFO:root:current mean train loss 1093.7998703436144
INFO:root:current train perplexity2.368922710418701
INFO:root:current mean train loss 1093.80248838702
INFO:root:current train perplexity2.369011878967285
INFO:root:current mean train loss 1093.8560757506127
INFO:root:current train perplexity2.368968963623047
INFO:root:current mean train loss 1094.2566219097107
INFO:root:current train perplexity2.3691458702087402

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.25s/it]
INFO:root:final mean train loss: 1093.9941086915785
INFO:root:final train perplexity: 2.3697621822357178
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2661.97594998407
INFO:root:eval perplexity: 8.609356880187988
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 3315.650773718002
INFO:root:eval perplexity: 15.05379867553711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/159
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [23:48:13<6:09:35, 540.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1096.8121948242188
INFO:root:current train perplexity2.3758020401000977
INFO:root:current mean train loss 1085.1968383789062
INFO:root:current train perplexity2.357771635055542
INFO:root:current mean train loss 1085.9364820423693
INFO:root:current train perplexity2.360828399658203
INFO:root:current mean train loss 1086.8806441351278
INFO:root:current train perplexity2.359067440032959
INFO:root:current mean train loss 1086.805989279676
INFO:root:current train perplexity2.3602049350738525
INFO:root:current mean train loss 1087.3356494675595
INFO:root:current train perplexity2.3601207733154297
INFO:root:current mean train loss 1087.2253335845035
INFO:root:current train perplexity2.3602311611175537
INFO:root:current mean train loss 1088.2389768073363
INFO:root:current train perplexity2.3624167442321777
INFO:root:current mean train loss 1088.6270270216792
INFO:root:current train perplexity2.363739490509033
INFO:root:current mean train loss 1089.4612765766828
INFO:root:current train perplexity2.364701509475708
INFO:root:current mean train loss 1089.264942648882
INFO:root:current train perplexity2.363483190536499
INFO:root:current mean train loss 1090.0023640322815
INFO:root:current train perplexity2.3617491722106934
INFO:root:current mean train loss 1090.314193192417
INFO:root:current train perplexity2.3635787963867188
INFO:root:current mean train loss 1090.7310074251002
INFO:root:current train perplexity2.3638429641723633
INFO:root:current mean train loss 1091.0195698649668
INFO:root:current train perplexity2.364323377609253
INFO:root:current mean train loss 1091.2360414791997
INFO:root:current train perplexity2.3634791374206543
INFO:root:current mean train loss 1091.6211217911205
INFO:root:current train perplexity2.3641655445098877
INFO:root:current mean train loss 1091.505110385415
INFO:root:current train perplexity2.3656153678894043
INFO:root:current mean train loss 1091.911458581719
INFO:root:current train perplexity2.3650317192077637
INFO:root:current mean train loss 1092.107758563149
INFO:root:current train perplexity2.3652751445770264

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.23s/it]
INFO:root:final mean train loss: 1092.015327796032
INFO:root:final train perplexity: 2.3660666942596436
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2665.809348248421
INFO:root:eval perplexity: 8.636091232299805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3320.760935249058
INFO:root:eval perplexity: 15.116843223571777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/160
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [23:57:14<6:00:34, 540.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1093.591706928454
INFO:root:current train perplexity2.348240852355957
INFO:root:current mean train loss 1088.7693568638392
INFO:root:current train perplexity2.3533051013946533
INFO:root:current mean train loss 1088.7700304005243
INFO:root:current train perplexity2.3560972213745117
INFO:root:current mean train loss 1086.554637562145
INFO:root:current train perplexity2.3573951721191406
INFO:root:current mean train loss 1087.1459031571637
INFO:root:current train perplexity2.3558719158172607
INFO:root:current mean train loss 1086.7544012345331
INFO:root:current train perplexity2.357668161392212
INFO:root:current mean train loss 1086.800708579709
INFO:root:current train perplexity2.357822895050049
INFO:root:current mean train loss 1087.7265432302079
INFO:root:current train perplexity2.360157012939453
INFO:root:current mean train loss 1087.731446281312
INFO:root:current train perplexity2.3592445850372314
INFO:root:current mean train loss 1088.3274583287287
INFO:root:current train perplexity2.35864520072937
INFO:root:current mean train loss 1088.867094300095
INFO:root:current train perplexity2.3575215339660645
INFO:root:current mean train loss 1088.917167056768
INFO:root:current train perplexity2.357290267944336
INFO:root:current mean train loss 1088.9679293550362
INFO:root:current train perplexity2.358064889907837
INFO:root:current mean train loss 1089.4348788199957
INFO:root:current train perplexity2.359018087387085
INFO:root:current mean train loss 1089.528160347915
INFO:root:current train perplexity2.3602232933044434
INFO:root:current mean train loss 1089.8233600789736
INFO:root:current train perplexity2.3618087768554688
INFO:root:current mean train loss 1090.0972371846528
INFO:root:current train perplexity2.362689971923828
INFO:root:current mean train loss 1090.62728624416
INFO:root:current train perplexity2.3632562160491943
INFO:root:current mean train loss 1090.7064907919123
INFO:root:current train perplexity2.363642930984497
INFO:root:current mean train loss 1091.011423084126
INFO:root:current train perplexity2.363828659057617

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.68s/it]
INFO:root:final mean train loss: 1090.804019976071
INFO:root:final train perplexity: 2.3638076782226562
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 2667.527539841672
INFO:root:eval perplexity: 8.648098945617676
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3322.0402827702515
INFO:root:eval perplexity: 15.13266658782959
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/161
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [24:06:15<5:51:39, 541.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1080.4218343098958
INFO:root:current train perplexity2.3618569374084473
INFO:root:current mean train loss 1086.604372809915
INFO:root:current train perplexity2.3503050804138184
INFO:root:current mean train loss 1085.502879255909
INFO:root:current train perplexity2.349378824234009
INFO:root:current mean train loss 1085.55875596546
INFO:root:current train perplexity2.348489284515381
INFO:root:current mean train loss 1086.6259326059883
INFO:root:current train perplexity2.3453831672668457
INFO:root:current mean train loss 1086.66303048205
INFO:root:current train perplexity2.345984697341919
INFO:root:current mean train loss 1085.7763095111966
INFO:root:current train perplexity2.349639654159546
INFO:root:current mean train loss 1086.0709269979725
INFO:root:current train perplexity2.3510825634002686
INFO:root:current mean train loss 1086.091421464984
INFO:root:current train perplexity2.3534865379333496
INFO:root:current mean train loss 1086.4414429623857
INFO:root:current train perplexity2.3540186882019043
INFO:root:current mean train loss 1086.9221873044048
INFO:root:current train perplexity2.353834867477417
INFO:root:current mean train loss 1087.122361411511
INFO:root:current train perplexity2.3533473014831543
INFO:root:current mean train loss 1087.5618481682343
INFO:root:current train perplexity2.3543031215667725
INFO:root:current mean train loss 1087.5609095225077
INFO:root:current train perplexity2.3557801246643066
INFO:root:current mean train loss 1087.9830630416657
INFO:root:current train perplexity2.3562867641448975
INFO:root:current mean train loss 1088.5799127022426
INFO:root:current train perplexity2.3572804927825928
INFO:root:current mean train loss 1088.7727454822045
INFO:root:current train perplexity2.357930898666382
INFO:root:current mean train loss 1088.5204373900242
INFO:root:current train perplexity2.3581066131591797
INFO:root:current mean train loss 1088.8850354628885
INFO:root:current train perplexity2.358501434326172
INFO:root:current mean train loss 1089.0919817459485
INFO:root:current train perplexity2.359837293624878

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.30s/it]
INFO:root:final mean train loss: 1088.8059159748734
INFO:root:final train perplexity: 2.3600852489471436
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2670.360674053219
INFO:root:eval perplexity: 8.667936325073242
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3324.5832277122117
INFO:root:eval perplexity: 15.16417121887207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/162
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [24:15:16<5:42:37, 540.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1085.2375580409787
INFO:root:current train perplexity2.344180107116699
INFO:root:current mean train loss 1085.6323321972018
INFO:root:current train perplexity2.3406126499176025
INFO:root:current mean train loss 1084.167804461694
INFO:root:current train perplexity2.343505382537842
INFO:root:current mean train loss 1082.7381783720455
INFO:root:current train perplexity2.346923828125
INFO:root:current mean train loss 1082.7282095060707
INFO:root:current train perplexity2.3483145236968994
INFO:root:current mean train loss 1083.8216187406406
INFO:root:current train perplexity2.348278284072876
INFO:root:current mean train loss 1084.4602592900555
INFO:root:current train perplexity2.350017786026001
INFO:root:current mean train loss 1084.7135684961975
INFO:root:current train perplexity2.3510000705718994
INFO:root:current mean train loss 1084.9076764195074
INFO:root:current train perplexity2.3517234325408936
INFO:root:current mean train loss 1085.0721217792907
INFO:root:current train perplexity2.352980375289917
INFO:root:current mean train loss 1085.1874579767443
INFO:root:current train perplexity2.353632926940918
INFO:root:current mean train loss 1085.678760379682
INFO:root:current train perplexity2.3550450801849365
INFO:root:current mean train loss 1086.1893496623727
INFO:root:current train perplexity2.3546650409698486
INFO:root:current mean train loss 1086.48674323624
INFO:root:current train perplexity2.355146646499634
INFO:root:current mean train loss 1086.608294681935
INFO:root:current train perplexity2.3567333221435547
INFO:root:current mean train loss 1086.7590021549772
INFO:root:current train perplexity2.3559367656707764
INFO:root:current mean train loss 1087.1277471358892
INFO:root:current train perplexity2.356501817703247
INFO:root:current mean train loss 1087.2269349084604
INFO:root:current train perplexity2.3569302558898926
INFO:root:current mean train loss 1087.493802082455
INFO:root:current train perplexity2.357793092727661
INFO:root:current mean train loss 1087.807405673963
INFO:root:current train perplexity2.3575613498687744

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.87s/it]
INFO:root:final mean train loss: 1087.5734379432206
INFO:root:final train perplexity: 2.357792615890503
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.19s/it]
INFO:root:eval mean loss: 2672.483450382314
INFO:root:eval perplexity: 8.682832717895508
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 3327.903151491855
INFO:root:eval perplexity: 15.205399513244629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/163
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [24:24:16<5:33:31, 540.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1077.478133719308
INFO:root:current train perplexity2.3289601802825928
INFO:root:current mean train loss 1082.2962736241957
INFO:root:current train perplexity2.343398332595825
INFO:root:current mean train loss 1083.6885794180412
INFO:root:current train perplexity2.3443334102630615
INFO:root:current mean train loss 1082.5003544987858
INFO:root:current train perplexity2.3440840244293213
INFO:root:current mean train loss 1082.1967894209192
INFO:root:current train perplexity2.347484588623047
INFO:root:current mean train loss 1082.4171343887062
INFO:root:current train perplexity2.349869966506958
INFO:root:current mean train loss 1082.459056706215
INFO:root:current train perplexity2.3509140014648438
INFO:root:current mean train loss 1083.150902131316
INFO:root:current train perplexity2.350973129272461
INFO:root:current mean train loss 1083.6528100726248
INFO:root:current train perplexity2.3526430130004883
INFO:root:current mean train loss 1083.9060758924975
INFO:root:current train perplexity2.353405475616455
INFO:root:current mean train loss 1084.1259583660376
INFO:root:current train perplexity2.3537676334381104
INFO:root:current mean train loss 1084.491339685163
INFO:root:current train perplexity2.353672504425049
INFO:root:current mean train loss 1084.4884423924243
INFO:root:current train perplexity2.3546273708343506
INFO:root:current mean train loss 1085.0933660131302
INFO:root:current train perplexity2.353961706161499
INFO:root:current mean train loss 1085.661854023836
INFO:root:current train perplexity2.3536760807037354
INFO:root:current mean train loss 1085.9521245288242
INFO:root:current train perplexity2.353750228881836
INFO:root:current mean train loss 1085.9697140996327
INFO:root:current train perplexity2.3537561893463135
INFO:root:current mean train loss 1086.212598173497
INFO:root:current train perplexity2.3546342849731445
INFO:root:current mean train loss 1086.5640951064818
INFO:root:current train perplexity2.3554201126098633
INFO:root:current mean train loss 1086.7283712784047
INFO:root:current train perplexity2.355930805206299

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.27s/it]
INFO:root:final mean train loss: 1086.5284964003108
INFO:root:final train perplexity: 2.3558502197265625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 2674.9624750664893
INFO:root:eval perplexity: 8.700258255004883
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 3331.1636023555243
INFO:root:eval perplexity: 15.24599838256836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/164
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [24:33:17<5:24:31, 540.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1074.661409224587
INFO:root:current train perplexity2.340329885482788
INFO:root:current mean train loss 1078.5383228975184
INFO:root:current train perplexity2.343339443206787
INFO:root:current mean train loss 1079.1055293598242
INFO:root:current train perplexity2.3430051803588867
INFO:root:current mean train loss 1080.5562624278302
INFO:root:current train perplexity2.3446035385131836
INFO:root:current mean train loss 1081.3102201426543
INFO:root:current train perplexity2.346907377243042
INFO:root:current mean train loss 1082.106315859741
INFO:root:current train perplexity2.348343849182129
INFO:root:current mean train loss 1082.892453655926
INFO:root:current train perplexity2.350062370300293
INFO:root:current mean train loss 1083.2226563275542
INFO:root:current train perplexity2.3506741523742676
INFO:root:current mean train loss 1083.8445098085629
INFO:root:current train perplexity2.3513946533203125
INFO:root:current mean train loss 1084.0731450383303
INFO:root:current train perplexity2.3509180545806885
INFO:root:current mean train loss 1084.139145220324
INFO:root:current train perplexity2.3515100479125977
INFO:root:current mean train loss 1084.0856931022765
INFO:root:current train perplexity2.3515100479125977
INFO:root:current mean train loss 1084.3137014962576
INFO:root:current train perplexity2.3512086868286133
INFO:root:current mean train loss 1084.621394129219
INFO:root:current train perplexity2.3516130447387695
INFO:root:current mean train loss 1084.476108492022
INFO:root:current train perplexity2.352142810821533
INFO:root:current mean train loss 1084.5716596578154
INFO:root:current train perplexity2.3518853187561035
INFO:root:current mean train loss 1084.4220333947328
INFO:root:current train perplexity2.352281093597412
INFO:root:current mean train loss 1084.5486929391307
INFO:root:current train perplexity2.352590560913086
INFO:root:current mean train loss 1084.8013447982391
INFO:root:current train perplexity2.3523857593536377

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.97s/it]
INFO:root:final mean train loss: 1084.8116136359495
INFO:root:final train perplexity: 2.3526623249053955
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 2677.3299404712434
INFO:root:eval perplexity: 8.716931343078613
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3334.311569754959
INFO:root:eval perplexity: 15.285303115844727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/165
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [24:42:18<5:15:27, 540.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1067.517333984375
INFO:root:current train perplexity2.3644704818725586
INFO:root:current mean train loss 1079.4609603881836
INFO:root:current train perplexity2.337695837020874
INFO:root:current mean train loss 1075.2137971765856
INFO:root:current train perplexity2.340991258621216
INFO:root:current mean train loss 1077.5035591125488
INFO:root:current train perplexity2.3443222045898438
INFO:root:current mean train loss 1080.494270853477
INFO:root:current train perplexity2.3470652103424072
INFO:root:current mean train loss 1080.6924290732732
INFO:root:current train perplexity2.345722198486328
INFO:root:current mean train loss 1080.7704972020838
INFO:root:current train perplexity2.346618175506592
INFO:root:current mean train loss 1080.5017392418602
INFO:root:current train perplexity2.3473057746887207
INFO:root:current mean train loss 1080.940806981936
INFO:root:current train perplexity2.3462305068969727
INFO:root:current mean train loss 1081.0730177617706
INFO:root:current train perplexity2.347564935684204
INFO:root:current mean train loss 1081.0546819679291
INFO:root:current train perplexity2.3478012084960938
INFO:root:current mean train loss 1080.9895775283592
INFO:root:current train perplexity2.3474104404449463
INFO:root:current mean train loss 1081.4366191978074
INFO:root:current train perplexity2.347705125808716
INFO:root:current mean train loss 1081.80552467393
INFO:root:current train perplexity2.348813533782959
INFO:root:current mean train loss 1082.2842182474599
INFO:root:current train perplexity2.348912239074707
INFO:root:current mean train loss 1082.8933619641243
INFO:root:current train perplexity2.34993314743042
INFO:root:current mean train loss 1083.1969187443988
INFO:root:current train perplexity2.3506662845611572
INFO:root:current mean train loss 1083.3845153235493
INFO:root:current train perplexity2.350847005844116
INFO:root:current mean train loss 1083.4679188527448
INFO:root:current train perplexity2.351077079772949
INFO:root:current mean train loss 1083.8145801640358
INFO:root:current train perplexity2.3508310317993164

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:05<00:00, 485.41s/it]
INFO:root:final mean train loss: 1083.7813661299267
INFO:root:final train perplexity: 2.3507518768310547
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 2677.7603015223294
INFO:root:eval perplexity: 8.719965934753418
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 3334.395801300698
INFO:root:eval perplexity: 15.286352157592773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/166
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [24:51:19<5:06:30, 540.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1073.5304071335565
INFO:root:current train perplexity2.3276426792144775
INFO:root:current mean train loss 1077.3336383409737
INFO:root:current train perplexity2.3415637016296387
INFO:root:current mean train loss 1076.0799927862522
INFO:root:current train perplexity2.343487024307251
INFO:root:current mean train loss 1076.7976958372883
INFO:root:current train perplexity2.3401432037353516
INFO:root:current mean train loss 1078.0822163851415
INFO:root:current train perplexity2.3408799171447754
INFO:root:current mean train loss 1078.9710919458898
INFO:root:current train perplexity2.3422794342041016
INFO:root:current mean train loss 1079.2844719879101
INFO:root:current train perplexity2.3438422679901123
INFO:root:current mean train loss 1079.8312162909858
INFO:root:current train perplexity2.3456671237945557
INFO:root:current mean train loss 1080.7154821286683
INFO:root:current train perplexity2.3470029830932617
INFO:root:current mean train loss 1081.065244925268
INFO:root:current train perplexity2.3463563919067383
INFO:root:current mean train loss 1081.3916667224612
INFO:root:current train perplexity2.3455591201782227
INFO:root:current mean train loss 1081.7601341771613
INFO:root:current train perplexity2.346562623977661
INFO:root:current mean train loss 1081.8934414150478
INFO:root:current train perplexity2.3467907905578613
INFO:root:current mean train loss 1082.1869028627104
INFO:root:current train perplexity2.347668170928955
INFO:root:current mean train loss 1082.3293583740406
INFO:root:current train perplexity2.347342014312744
INFO:root:current mean train loss 1082.3977694439309
INFO:root:current train perplexity2.3486220836639404
INFO:root:current mean train loss 1082.669050175492
INFO:root:current train perplexity2.3485360145568848
INFO:root:current mean train loss 1082.791771063619
INFO:root:current train perplexity2.347744941711426
INFO:root:current mean train loss 1082.5759776082423
INFO:root:current train perplexity2.3474676609039307
INFO:root:current mean train loss 1082.7089223866658
INFO:root:current train perplexity2.3477132320404053

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:03<00:00, 483.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:03<00:00, 483.68s/it]
INFO:root:final mean train loss: 1082.4602668212028
INFO:root:final train perplexity: 2.348304033279419
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.92s/it]
INFO:root:eval mean loss: 2679.425726275072
INFO:root:eval perplexity: 8.731718063354492
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it]
INFO:root:eval mean loss: 3336.492387487533
INFO:root:eval perplexity: 15.312582969665527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/167
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [25:00:18<4:57:08, 540.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1069.9900175395765
INFO:root:current train perplexity2.3352887630462646
INFO:root:current mean train loss 1073.7800810440726
INFO:root:current train perplexity2.34169602394104
INFO:root:current mean train loss 1077.5428930971802
INFO:root:current train perplexity2.339304208755493
INFO:root:current mean train loss 1076.4191276956592
INFO:root:current train perplexity2.3415029048919678
INFO:root:current mean train loss 1077.0515028026007
INFO:root:current train perplexity2.342344284057617
INFO:root:current mean train loss 1077.0641015488861
INFO:root:current train perplexity2.3391458988189697
INFO:root:current mean train loss 1078.5804353432968
INFO:root:current train perplexity2.33797550201416
INFO:root:current mean train loss 1078.33568798365
INFO:root:current train perplexity2.337172746658325
INFO:root:current mean train loss 1078.373070181981
INFO:root:current train perplexity2.337920665740967
INFO:root:current mean train loss 1078.8224581004715
INFO:root:current train perplexity2.338979482650757
INFO:root:current mean train loss 1079.201790341063
INFO:root:current train perplexity2.33882474899292
INFO:root:current mean train loss 1079.4709036614229
INFO:root:current train perplexity2.33902645111084
INFO:root:current mean train loss 1079.5544856106908
INFO:root:current train perplexity2.3399507999420166
INFO:root:current mean train loss 1079.680723592305
INFO:root:current train perplexity2.340749502182007
INFO:root:current mean train loss 1080.1615276310142
INFO:root:current train perplexity2.34158992767334
INFO:root:current mean train loss 1080.250233346371
INFO:root:current train perplexity2.34257173538208
INFO:root:current mean train loss 1080.4764649108215
INFO:root:current train perplexity2.342276096343994
INFO:root:current mean train loss 1080.7384215816942
INFO:root:current train perplexity2.3427767753601074
INFO:root:current mean train loss 1080.7986500006375
INFO:root:current train perplexity2.3438057899475098
INFO:root:current mean train loss 1081.0564866198845
INFO:root:current train perplexity2.344947576522827

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.76s/it]
INFO:root:final mean train loss: 1080.7574603859366
INFO:root:final train perplexity: 2.3451523780822754
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it]
INFO:root:eval mean loss: 2682.205304950687
INFO:root:eval perplexity: 8.75136947631836
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 3339.4326747596688
INFO:root:eval perplexity: 15.34945297241211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/168
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [25:09:15<4:47:35, 539.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1066.849746981534
INFO:root:current train perplexity2.3328371047973633
INFO:root:current mean train loss 1072.61272484564
INFO:root:current train perplexity2.3244121074676514
INFO:root:current mean train loss 1075.3308490827972
INFO:root:current train perplexity2.3271124362945557
INFO:root:current mean train loss 1075.7054850833517
INFO:root:current train perplexity2.3314409255981445
INFO:root:current mean train loss 1075.2028944078384
INFO:root:current train perplexity2.3323283195495605
INFO:root:current mean train loss 1075.4551165056657
INFO:root:current train perplexity2.334146022796631
INFO:root:current mean train loss 1076.0217395112716
INFO:root:current train perplexity2.335277795791626
INFO:root:current mean train loss 1076.9311580834799
INFO:root:current train perplexity2.337434768676758
INFO:root:current mean train loss 1077.477233101471
INFO:root:current train perplexity2.3372442722320557
INFO:root:current mean train loss 1077.9436131662098
INFO:root:current train perplexity2.337641954421997
INFO:root:current mean train loss 1077.8796527880627
INFO:root:current train perplexity2.338001251220703
INFO:root:current mean train loss 1077.289468925443
INFO:root:current train perplexity2.33901309967041
INFO:root:current mean train loss 1077.4211628583323
INFO:root:current train perplexity2.3395276069641113
INFO:root:current mean train loss 1077.792280156322
INFO:root:current train perplexity2.33992075920105
INFO:root:current mean train loss 1078.0059249406008
INFO:root:current train perplexity2.339916944503784
INFO:root:current mean train loss 1078.262275563329
INFO:root:current train perplexity2.340789794921875
INFO:root:current mean train loss 1078.5391085621814
INFO:root:current train perplexity2.3412575721740723
INFO:root:current mean train loss 1078.7304839479277
INFO:root:current train perplexity2.3415281772613525
INFO:root:current mean train loss 1079.0189129029966
INFO:root:current train perplexity2.3412110805511475
INFO:root:current mean train loss 1079.3336716439717
INFO:root:current train perplexity2.342280387878418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.03s/it]
INFO:root:final mean train loss: 1079.2175069511748
INFO:root:final train perplexity: 2.342305898666382
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it]
INFO:root:eval mean loss: 2683.9903408618684
INFO:root:eval perplexity: 8.764012336730957
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it]
INFO:root:eval mean loss: 3342.298329454787
INFO:root:eval perplexity: 15.385464668273926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/169
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [25:18:12<4:38:15, 538.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1076.8517761230469
INFO:root:current train perplexity2.335054636001587
INFO:root:current mean train loss 1075.7510553404343
INFO:root:current train perplexity2.3371973037719727
INFO:root:current mean train loss 1076.0513956406537
INFO:root:current train perplexity2.3363192081451416
INFO:root:current mean train loss 1076.254643758138
INFO:root:current train perplexity2.338493824005127
INFO:root:current mean train loss 1076.3850054983366
INFO:root:current train perplexity2.3368020057678223
INFO:root:current mean train loss 1075.6799037906674
INFO:root:current train perplexity2.3358609676361084
INFO:root:current mean train loss 1075.9926015763056
INFO:root:current train perplexity2.3378002643585205
INFO:root:current mean train loss 1076.044314053392
INFO:root:current train perplexity2.3404173851013184
INFO:root:current mean train loss 1076.1583179858847
INFO:root:current train perplexity2.339545726776123
INFO:root:current mean train loss 1076.8148166358226
INFO:root:current train perplexity2.3390841484069824
INFO:root:current mean train loss 1076.7334437583809
INFO:root:current train perplexity2.3397066593170166
INFO:root:current mean train loss 1077.0277750060827
INFO:root:current train perplexity2.339879035949707
INFO:root:current mean train loss 1077.230904537177
INFO:root:current train perplexity2.3404347896575928
INFO:root:current mean train loss 1077.5525702206803
INFO:root:current train perplexity2.3403866291046143
INFO:root:current mean train loss 1077.8000548818836
INFO:root:current train perplexity2.3406310081481934
INFO:root:current mean train loss 1077.8831853890845
INFO:root:current train perplexity2.3406789302825928
INFO:root:current mean train loss 1078.4199794057454
INFO:root:current train perplexity2.340912103652954
INFO:root:current mean train loss 1078.227804868539
INFO:root:current train perplexity2.3405673503875732
INFO:root:current mean train loss 1078.2221994970598
INFO:root:current train perplexity2.3410301208496094
INFO:root:current mean train loss 1078.5174099688113
INFO:root:current train perplexity2.3405580520629883

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.19s/it]
INFO:root:final mean train loss: 1078.2873074699398
INFO:root:final train perplexity: 2.340588092803955
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it]
INFO:root:eval mean loss: 2686.890243638492
INFO:root:eval perplexity: 8.784588813781738
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 3344.8079937874004
INFO:root:eval perplexity: 15.41707706451416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/170
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [25:27:09<4:29:05, 538.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1071.2942052262554
INFO:root:current train perplexity2.324925661087036
INFO:root:current mean train loss 1070.6416387002935
INFO:root:current train perplexity2.324331521987915
INFO:root:current mean train loss 1071.1329850457532
INFO:root:current train perplexity2.321815013885498
INFO:root:current mean train loss 1072.5675373616746
INFO:root:current train perplexity2.321052312850952
INFO:root:current mean train loss 1073.3492952124473
INFO:root:current train perplexity2.3247056007385254
INFO:root:current mean train loss 1074.1362052878621
INFO:root:current train perplexity2.3270468711853027
INFO:root:current mean train loss 1074.6679973629978
INFO:root:current train perplexity2.3280446529388428
INFO:root:current mean train loss 1075.1881342550648
INFO:root:current train perplexity2.3299834728240967
INFO:root:current mean train loss 1075.1917181540662
INFO:root:current train perplexity2.3314805030822754
INFO:root:current mean train loss 1075.1527490876201
INFO:root:current train perplexity2.332960844039917
INFO:root:current mean train loss 1075.568973313569
INFO:root:current train perplexity2.334392786026001
INFO:root:current mean train loss 1075.6315903082127
INFO:root:current train perplexity2.334104299545288
INFO:root:current mean train loss 1075.651193220732
INFO:root:current train perplexity2.3340253829956055
INFO:root:current mean train loss 1076.059951551532
INFO:root:current train perplexity2.335202217102051
INFO:root:current mean train loss 1076.0204927279215
INFO:root:current train perplexity2.3357632160186768
INFO:root:current mean train loss 1076.0878914700431
INFO:root:current train perplexity2.3362514972686768
INFO:root:current mean train loss 1076.5374753691162
INFO:root:current train perplexity2.3367767333984375
INFO:root:current mean train loss 1076.8559002265908
INFO:root:current train perplexity2.3380930423736572
INFO:root:current mean train loss 1077.0996759676189
INFO:root:current train perplexity2.3384695053100586

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.99s/it]
INFO:root:final mean train loss: 1077.0063161999062
INFO:root:final train perplexity: 2.3382246494293213
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it]
INFO:root:eval mean loss: 2688.9018667234595
INFO:root:eval perplexity: 8.798892974853516
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 3346.8553557700297
INFO:root:eval perplexity: 15.442913055419922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/171
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [25:36:05<4:19:48, 537.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1061.7439778645833
INFO:root:current train perplexity2.3440825939178467
INFO:root:current mean train loss 1069.6705028605911
INFO:root:current train perplexity2.335087776184082
INFO:root:current mean train loss 1069.2290279055105
INFO:root:current train perplexity2.3307008743286133
INFO:root:current mean train loss 1071.1044510984732
INFO:root:current train perplexity2.3265652656555176
INFO:root:current mean train loss 1073.4711046641683
INFO:root:current train perplexity2.3297927379608154
INFO:root:current mean train loss 1073.8415328316066
INFO:root:current train perplexity2.3309578895568848
INFO:root:current mean train loss 1074.394242894138
INFO:root:current train perplexity2.331782817840576
INFO:root:current mean train loss 1074.2304157548856
INFO:root:current train perplexity2.3322997093200684
INFO:root:current mean train loss 1074.2931055111565
INFO:root:current train perplexity2.333200693130493
INFO:root:current mean train loss 1074.5538474918728
INFO:root:current train perplexity2.3333139419555664
INFO:root:current mean train loss 1074.5768985331176
INFO:root:current train perplexity2.331756591796875
INFO:root:current mean train loss 1074.8229452343573
INFO:root:current train perplexity2.332805633544922
INFO:root:current mean train loss 1074.852826929804
INFO:root:current train perplexity2.3335025310516357
INFO:root:current mean train loss 1075.3791299676823
INFO:root:current train perplexity2.3342125415802
INFO:root:current mean train loss 1075.741896649682
INFO:root:current train perplexity2.333983898162842
INFO:root:current mean train loss 1075.839407101412
INFO:root:current train perplexity2.3339157104492188
INFO:root:current mean train loss 1075.9701410390965
INFO:root:current train perplexity2.3340578079223633
INFO:root:current mean train loss 1076.1308131156466
INFO:root:current train perplexity2.3353352546691895
INFO:root:current mean train loss 1075.928086864856
INFO:root:current train perplexity2.335197925567627
INFO:root:current mean train loss 1076.0446202857547
INFO:root:current train perplexity2.3358073234558105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.45s/it]
INFO:root:final mean train loss: 1075.744288688348
INFO:root:final train perplexity: 2.3358986377716064
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it]
INFO:root:eval mean loss: 2690.115301037511
INFO:root:eval perplexity: 8.807531356811523
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 3348.343033161569
INFO:root:eval perplexity: 15.461716651916504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/172
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [25:45:02<4:10:42, 537.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1071.0543743631115
INFO:root:current train perplexity2.3304762840270996
INFO:root:current mean train loss 1069.7760605230565
INFO:root:current train perplexity2.3320813179016113
INFO:root:current mean train loss 1072.8072151218294
INFO:root:current train perplexity2.326378345489502
INFO:root:current mean train loss 1072.4957660875823
INFO:root:current train perplexity2.325587272644043
INFO:root:current mean train loss 1072.943852562149
INFO:root:current train perplexity2.3254692554473877
INFO:root:current mean train loss 1073.447248469803
INFO:root:current train perplexity2.3242483139038086
INFO:root:current mean train loss 1073.6094100731716
INFO:root:current train perplexity2.3255927562713623
INFO:root:current mean train loss 1073.6372614817005
INFO:root:current train perplexity2.328007459640503
INFO:root:current mean train loss 1073.6030658337208
INFO:root:current train perplexity2.328591823577881
INFO:root:current mean train loss 1073.8128445874315
INFO:root:current train perplexity2.3303263187408447
INFO:root:current mean train loss 1073.9194136663382
INFO:root:current train perplexity2.330915689468384
INFO:root:current mean train loss 1073.9561111572484
INFO:root:current train perplexity2.3312885761260986
INFO:root:current mean train loss 1073.9689770228338
INFO:root:current train perplexity2.3313183784484863
INFO:root:current mean train loss 1074.18473145823
INFO:root:current train perplexity2.332051992416382
INFO:root:current mean train loss 1074.4619439152539
INFO:root:current train perplexity2.333491325378418
INFO:root:current mean train loss 1074.4633761410328
INFO:root:current train perplexity2.3329927921295166
INFO:root:current mean train loss 1074.5513172537474
INFO:root:current train perplexity2.333193302154541
INFO:root:current mean train loss 1074.7342853070136
INFO:root:current train perplexity2.3341193199157715
INFO:root:current mean train loss 1074.972674999143
INFO:root:current train perplexity2.3337717056274414
INFO:root:current mean train loss 1075.1521819417699
INFO:root:current train perplexity2.334223508834839

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.87s/it]
INFO:root:final mean train loss: 1074.9450063238946
INFO:root:final train perplexity: 2.3344266414642334
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it]
INFO:root:eval mean loss: 2690.57380578873
INFO:root:eval perplexity: 8.810797691345215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.25s/it]
INFO:root:eval mean loss: 3348.258721101369
INFO:root:eval perplexity: 15.460651397705078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/173
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [25:53:59<4:01:43, 537.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1073.8444549560547
INFO:root:current train perplexity2.330026865005493
INFO:root:current mean train loss 1068.7935407366072
INFO:root:current train perplexity2.3141884803771973
INFO:root:current mean train loss 1071.3030151367188
INFO:root:current train perplexity2.3223464488983154
INFO:root:current mean train loss 1072.9729445513558
INFO:root:current train perplexity2.325434446334839
INFO:root:current mean train loss 1073.1546526822176
INFO:root:current train perplexity2.3238518238067627
INFO:root:current mean train loss 1073.363597841616
INFO:root:current train perplexity2.32631516456604
INFO:root:current mean train loss 1072.8929737091064
INFO:root:current train perplexity2.32647442817688
INFO:root:current mean train loss 1072.3099977235536
INFO:root:current train perplexity2.3297488689422607
INFO:root:current mean train loss 1072.7599605741955
INFO:root:current train perplexity2.3292059898376465
INFO:root:current mean train loss 1073.3136559669008
INFO:root:current train perplexity2.3300435543060303
INFO:root:current mean train loss 1073.610459606464
INFO:root:current train perplexity2.32993483543396
INFO:root:current mean train loss 1073.39873186078
INFO:root:current train perplexity2.330476999282837
INFO:root:current mean train loss 1073.1999646586758
INFO:root:current train perplexity2.3308072090148926
INFO:root:current mean train loss 1073.3097633931175
INFO:root:current train perplexity2.3310394287109375
INFO:root:current mean train loss 1073.253348965115
INFO:root:current train perplexity2.3314640522003174
INFO:root:current mean train loss 1073.5266742656756
INFO:root:current train perplexity2.3323020935058594
INFO:root:current mean train loss 1073.7962759250547
INFO:root:current train perplexity2.3321683406829834
INFO:root:current mean train loss 1073.8382461021686
INFO:root:current train perplexity2.3319973945617676
INFO:root:current mean train loss 1074.0686612668244
INFO:root:current train perplexity2.3314528465270996
INFO:root:current mean train loss 1074.1183625526035
INFO:root:current train perplexity2.3317220211029053

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.83s/it]
INFO:root:final mean train loss: 1073.5463801781698
INFO:root:final train perplexity: 2.331853151321411
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it]
INFO:root:eval mean loss: 2693.977200988337
INFO:root:eval perplexity: 8.835084915161133
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.25s/it]
INFO:root:eval mean loss: 3352.784934185921
INFO:root:eval perplexity: 15.517984390258789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/174
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [26:02:55<3:52:44, 537.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1075.8097780461896
INFO:root:current train perplexity2.327582836151123
INFO:root:current mean train loss 1071.5073078908738
INFO:root:current train perplexity2.32814359664917
INFO:root:current mean train loss 1068.2695884853022
INFO:root:current train perplexity2.331514835357666
INFO:root:current mean train loss 1069.3549645688354
INFO:root:current train perplexity2.3298556804656982
INFO:root:current mean train loss 1069.5833442404182
INFO:root:current train perplexity2.331974983215332
INFO:root:current mean train loss 1070.2355162588012
INFO:root:current train perplexity2.3319005966186523
INFO:root:current mean train loss 1070.9915957283938
INFO:root:current train perplexity2.3315038681030273
INFO:root:current mean train loss 1070.614269019748
INFO:root:current train perplexity2.330894947052002
INFO:root:current mean train loss 1071.2479525090932
INFO:root:current train perplexity2.330631971359253
INFO:root:current mean train loss 1071.1870459673173
INFO:root:current train perplexity2.330998182296753
INFO:root:current mean train loss 1071.3656527862981
INFO:root:current train perplexity2.330928325653076
INFO:root:current mean train loss 1071.9376493435846
INFO:root:current train perplexity2.3311171531677246
INFO:root:current mean train loss 1072.3155870581772
INFO:root:current train perplexity2.330270290374756
INFO:root:current mean train loss 1072.2452512219625
INFO:root:current train perplexity2.329129219055176
INFO:root:current mean train loss 1072.808909607981
INFO:root:current train perplexity2.3287768363952637
INFO:root:current mean train loss 1072.8616332615807
INFO:root:current train perplexity2.3282792568206787
INFO:root:current mean train loss 1072.9108522054871
INFO:root:current train perplexity2.328735589981079
INFO:root:current mean train loss 1073.0298390005826
INFO:root:current train perplexity2.3291401863098145
INFO:root:current mean train loss 1072.9371431891996
INFO:root:current train perplexity2.3302979469299316
INFO:root:current mean train loss 1073.0988913308495
INFO:root:current train perplexity2.3307700157165527

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.17s/it]
INFO:root:final mean train loss: 1072.8399358259808
INFO:root:final train perplexity: 2.330554485321045
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it]
INFO:root:eval mean loss: 2692.98630301834
INFO:root:eval perplexity: 8.82800579071045
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 3351.8137596617353
INFO:root:eval perplexity: 15.505664825439453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/175
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [26:11:53<3:43:48, 537.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1068.4908991633235
INFO:root:current train perplexity2.3172969818115234
INFO:root:current mean train loss 1067.4704140849497
INFO:root:current train perplexity2.3295321464538574
INFO:root:current mean train loss 1069.715386383725
INFO:root:current train perplexity2.3273842334747314
INFO:root:current mean train loss 1069.4068619835186
INFO:root:current train perplexity2.323533773422241
INFO:root:current mean train loss 1068.9220865627885
INFO:root:current train perplexity2.320000648498535
INFO:root:current mean train loss 1069.1698775341285
INFO:root:current train perplexity2.3223838806152344
INFO:root:current mean train loss 1070.1821791651694
INFO:root:current train perplexity2.32083797454834
INFO:root:current mean train loss 1070.1432969835068
INFO:root:current train perplexity2.3221821784973145
INFO:root:current mean train loss 1070.7114534356228
INFO:root:current train perplexity2.323745012283325
INFO:root:current mean train loss 1071.0459467517767
INFO:root:current train perplexity2.3233227729797363
INFO:root:current mean train loss 1070.6929308786516
INFO:root:current train perplexity2.32368803024292
INFO:root:current mean train loss 1070.6016492697408
INFO:root:current train perplexity2.3244285583496094
INFO:root:current mean train loss 1070.5750809075132
INFO:root:current train perplexity2.325662136077881
INFO:root:current mean train loss 1070.5903408711308
INFO:root:current train perplexity2.3258721828460693
INFO:root:current mean train loss 1070.4846942130391
INFO:root:current train perplexity2.3270206451416016
INFO:root:current mean train loss 1070.8855689314148
INFO:root:current train perplexity2.328320026397705
INFO:root:current mean train loss 1071.1264967832942
INFO:root:current train perplexity2.3278632164001465
INFO:root:current mean train loss 1071.4092977323821
INFO:root:current train perplexity2.3279404640197754
INFO:root:current mean train loss 1071.5878113835192
INFO:root:current train perplexity2.3280982971191406
INFO:root:current mean train loss 1071.9011652211168
INFO:root:current train perplexity2.3283138275146484

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.93s/it]
INFO:root:final mean train loss: 1071.5772936383823
INFO:root:final train perplexity: 2.3282344341278076
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.95s/it]
INFO:root:eval mean loss: 2694.35345285835
INFO:root:eval perplexity: 8.837773323059082
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.25s/it]
INFO:root:eval mean loss: 3354.147517211048
INFO:root:eval perplexity: 15.535286903381348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/176
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [26:20:50<3:34:50, 537.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1072.9922780466604
INFO:root:current train perplexity2.3283016681671143
INFO:root:current mean train loss 1070.2088543157927
INFO:root:current train perplexity2.321504592895508
INFO:root:current mean train loss 1068.590449487221
INFO:root:current train perplexity2.3245906829833984
INFO:root:current mean train loss 1070.0437807829483
INFO:root:current train perplexity2.3261592388153076
INFO:root:current mean train loss 1069.6531542372072
INFO:root:current train perplexity2.3276870250701904
INFO:root:current mean train loss 1069.9883939223444
INFO:root:current train perplexity2.3265013694763184
INFO:root:current mean train loss 1069.600079637188
INFO:root:current train perplexity2.32637619972229
INFO:root:current mean train loss 1069.4948564570411
INFO:root:current train perplexity2.3249690532684326
INFO:root:current mean train loss 1069.354716325582
INFO:root:current train perplexity2.3255796432495117
INFO:root:current mean train loss 1069.6585025113718
INFO:root:current train perplexity2.3256471157073975
INFO:root:current mean train loss 1069.5667496356912
INFO:root:current train perplexity2.326085329055786
INFO:root:current mean train loss 1069.4141781644396
INFO:root:current train perplexity2.3262500762939453
INFO:root:current mean train loss 1069.5718883984223
INFO:root:current train perplexity2.3259525299072266
INFO:root:current mean train loss 1069.927310156531
INFO:root:current train perplexity2.325862407684326
INFO:root:current mean train loss 1069.9203647176025
INFO:root:current train perplexity2.326796293258667
INFO:root:current mean train loss 1069.8893422642868
INFO:root:current train perplexity2.326922655105591
INFO:root:current mean train loss 1070.094687328192
INFO:root:current train perplexity2.3265488147735596
INFO:root:current mean train loss 1070.09348070921
INFO:root:current train perplexity2.3267242908477783
INFO:root:current mean train loss 1070.407264745784
INFO:root:current train perplexity2.32608699798584

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.69s/it]
INFO:root:final mean train loss: 1070.4104319393064
INFO:root:final train perplexity: 2.3260929584503174
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it]
INFO:root:eval mean loss: 2697.320729357131
INFO:root:eval perplexity: 8.859004020690918
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it]
INFO:root:eval mean loss: 3357.3904756586603
INFO:root:eval perplexity: 15.576547622680664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/177
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [26:29:46<3:25:50, 537.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1063.5530090332031
INFO:root:current train perplexity2.3026885986328125
INFO:root:current mean train loss 1069.5770987051505
INFO:root:current train perplexity2.3216800689697266
INFO:root:current mean train loss 1066.1192210270808
INFO:root:current train perplexity2.3248541355133057
INFO:root:current mean train loss 1066.5330071387352
INFO:root:current train perplexity2.3209502696990967
INFO:root:current mean train loss 1066.8280537923176
INFO:root:current train perplexity2.3216958045959473
INFO:root:current mean train loss 1066.9285804568312
INFO:root:current train perplexity2.3199613094329834
INFO:root:current mean train loss 1066.7610098186292
INFO:root:current train perplexity2.320542097091675
INFO:root:current mean train loss 1067.0588003040034
INFO:root:current train perplexity2.3217732906341553
INFO:root:current mean train loss 1067.5484613852925
INFO:root:current train perplexity2.3232109546661377
INFO:root:current mean train loss 1067.523338217042
INFO:root:current train perplexity2.323587656021118
INFO:root:current mean train loss 1067.888652983166
INFO:root:current train perplexity2.3245623111724854
INFO:root:current mean train loss 1068.0321729639377
INFO:root:current train perplexity2.3243048191070557
INFO:root:current mean train loss 1068.1637712188115
INFO:root:current train perplexity2.323580741882324
INFO:root:current mean train loss 1068.2901889906018
INFO:root:current train perplexity2.3231546878814697
INFO:root:current mean train loss 1068.3966390436347
INFO:root:current train perplexity2.3229317665100098
INFO:root:current mean train loss 1068.593416047033
INFO:root:current train perplexity2.3227977752685547
INFO:root:current mean train loss 1068.6923922258823
INFO:root:current train perplexity2.322861909866333
INFO:root:current mean train loss 1068.9313979495046
INFO:root:current train perplexity2.32247257232666
INFO:root:current mean train loss 1069.0271914659347
INFO:root:current train perplexity2.323291778564453
INFO:root:current mean train loss 1069.1160424190498
INFO:root:current train perplexity2.3230414390563965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.10s/it]
INFO:root:final mean train loss: 1069.0340509996593
INFO:root:final train perplexity: 2.3235692977905273
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it]
INFO:root:eval mean loss: 2699.2317708333335
INFO:root:eval perplexity: 8.872708320617676
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it]
INFO:root:eval mean loss: 3358.4256725987643
INFO:root:eval perplexity: 15.589740753173828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/178
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [26:38:43<3:16:48, 536.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1065.5216528320314
INFO:root:current train perplexity2.3185150623321533
INFO:root:current mean train loss 1068.0557119140626
INFO:root:current train perplexity2.326676845550537
INFO:root:current mean train loss 1069.213687608507
INFO:root:current train perplexity2.3217999935150146
INFO:root:current mean train loss 1069.0037736628606
INFO:root:current train perplexity2.322869300842285
INFO:root:current mean train loss 1069.0395593979779
INFO:root:current train perplexity2.3244476318359375
INFO:root:current mean train loss 1068.3620153227307
INFO:root:current train perplexity2.323615074157715
INFO:root:current mean train loss 1068.40531171875
INFO:root:current train perplexity2.3254573345184326
INFO:root:current mean train loss 1068.9835651266164
INFO:root:current train perplexity2.3251914978027344
INFO:root:current mean train loss 1068.9516830906723
INFO:root:current train perplexity2.3268234729766846
INFO:root:current mean train loss 1069.4482554502745
INFO:root:current train perplexity2.327393054962158
INFO:root:current mean train loss 1068.917563655202
INFO:root:current train perplexity2.326853036880493
INFO:root:current mean train loss 1068.8245290256077
INFO:root:current train perplexity2.32580828666687
INFO:root:current mean train loss 1069.1116914959343
INFO:root:current train perplexity2.324317693710327
INFO:root:current mean train loss 1069.1360727446934
INFO:root:current train perplexity2.32401967048645
INFO:root:current mean train loss 1069.1474418773985
INFO:root:current train perplexity2.323944091796875
INFO:root:current mean train loss 1069.5751680568007
INFO:root:current train perplexity2.3237802982330322
INFO:root:current mean train loss 1069.7054112454928
INFO:root:current train perplexity2.3245723247528076
INFO:root:current mean train loss 1069.9871122409986
INFO:root:current train perplexity2.324655532836914
INFO:root:current mean train loss 1069.9032992093858
INFO:root:current train perplexity2.3247053623199463
INFO:root:current mean train loss 1069.8938471172382
INFO:root:current train perplexity2.3245506286621094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.31s/it]
INFO:root:final mean train loss: 1069.491746434045
INFO:root:final train perplexity: 2.3244080543518066
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it]
INFO:root:eval mean loss: 2700.042161008145
INFO:root:eval perplexity: 8.878525733947754
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it]
INFO:root:eval mean loss: 3359.4118262757647
INFO:root:eval perplexity: 15.602315902709961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/179
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [26:47:39<3:07:49, 536.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1069.5225335984003
INFO:root:current train perplexity2.3438363075256348
INFO:root:current mean train loss 1066.7851141271458
INFO:root:current train perplexity2.329882860183716
INFO:root:current mean train loss 1065.5473486529895
INFO:root:current train perplexity2.32613468170166
INFO:root:current mean train loss 1065.9238350851494
INFO:root:current train perplexity2.323565721511841
INFO:root:current mean train loss 1067.1470005501449
INFO:root:current train perplexity2.32222580909729
INFO:root:current mean train loss 1066.3343043028208
INFO:root:current train perplexity2.321486473083496
INFO:root:current mean train loss 1066.696113752799
INFO:root:current train perplexity2.3216946125030518
INFO:root:current mean train loss 1066.2283761160713
INFO:root:current train perplexity2.3222386837005615
INFO:root:current mean train loss 1065.583497978446
INFO:root:current train perplexity2.3223013877868652
INFO:root:current mean train loss 1065.6175003861672
INFO:root:current train perplexity2.320939302444458
INFO:root:current mean train loss 1065.9424917034362
INFO:root:current train perplexity2.3211472034454346
INFO:root:current mean train loss 1066.307221955468
INFO:root:current train perplexity2.3219707012176514
INFO:root:current mean train loss 1066.6442082354413
INFO:root:current train perplexity2.320957899093628
INFO:root:current mean train loss 1066.9921286024387
INFO:root:current train perplexity2.320751428604126
INFO:root:current mean train loss 1067.1259071466495
INFO:root:current train perplexity2.320624828338623
INFO:root:current mean train loss 1067.148522363408
INFO:root:current train perplexity2.3213460445404053
INFO:root:current mean train loss 1067.3749269585371
INFO:root:current train perplexity2.3217358589172363
INFO:root:current mean train loss 1067.6044738629382
INFO:root:current train perplexity2.322042465209961
INFO:root:current mean train loss 1067.7742641585658
INFO:root:current train perplexity2.3219711780548096
INFO:root:current mean train loss 1067.9671473714277
INFO:root:current train perplexity2.3218026161193848

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.19s/it]
INFO:root:final mean train loss: 1067.9266290784904
INFO:root:final train perplexity: 2.3215408325195312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it]
INFO:root:eval mean loss: 2700.0163357782026
INFO:root:eval perplexity: 8.878340721130371
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 3360.001319831145
INFO:root:eval perplexity: 15.60983943939209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/180
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [26:56:36<2:58:56, 536.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1070.529648603019
INFO:root:current train perplexity2.303929567337036
INFO:root:current mean train loss 1066.071972349155
INFO:root:current train perplexity2.3109233379364014
INFO:root:current mean train loss 1063.5334590484738
INFO:root:current train perplexity2.309382438659668
INFO:root:current mean train loss 1063.3441242016127
INFO:root:current train perplexity2.3145029544830322
INFO:root:current mean train loss 1063.8723484945194
INFO:root:current train perplexity2.3124330043792725
INFO:root:current mean train loss 1064.8271356627
INFO:root:current train perplexity2.312793254852295
INFO:root:current mean train loss 1065.007103232585
INFO:root:current train perplexity2.3119876384735107
INFO:root:current mean train loss 1065.2544851592093
INFO:root:current train perplexity2.3138115406036377
INFO:root:current mean train loss 1065.7117774261724
INFO:root:current train perplexity2.3139970302581787
INFO:root:current mean train loss 1065.994792981988
INFO:root:current train perplexity2.3145623207092285
INFO:root:current mean train loss 1066.4240586061992
INFO:root:current train perplexity2.3163657188415527
INFO:root:current mean train loss 1066.6595286779923
INFO:root:current train perplexity2.31589412689209
INFO:root:current mean train loss 1066.541632763633
INFO:root:current train perplexity2.316167116165161
INFO:root:current mean train loss 1066.8681430886825
INFO:root:current train perplexity2.3171420097351074
INFO:root:current mean train loss 1066.8733988206955
INFO:root:current train perplexity2.317681312561035
INFO:root:current mean train loss 1066.9217788471176
INFO:root:current train perplexity2.317599296569824
INFO:root:current mean train loss 1067.0702335479534
INFO:root:current train perplexity2.3182549476623535
INFO:root:current mean train loss 1067.0708364168984
INFO:root:current train perplexity2.3191401958465576
INFO:root:current mean train loss 1067.098471967298
INFO:root:current train perplexity2.319368839263916
INFO:root:current mean train loss 1067.0759189171472
INFO:root:current train perplexity2.319780111312866

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.41s/it]
INFO:root:final mean train loss: 1066.7916258226664
INFO:root:final train perplexity: 2.3194637298583984
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it]
INFO:root:eval mean loss: 2703.6243662732713
INFO:root:eval perplexity: 8.90428638458252
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 3363.1491240372893
INFO:root:eval perplexity: 15.650077819824219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/181
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [27:05:33<2:49:57, 536.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1061.082520334344
INFO:root:current train perplexity2.311755418777466
INFO:root:current mean train loss 1064.2743745283647
INFO:root:current train perplexity2.3183140754699707
INFO:root:current mean train loss 1062.8598296676857
INFO:root:current train perplexity2.3202860355377197
INFO:root:current mean train loss 1063.7137959257086
INFO:root:current train perplexity2.317629098892212
INFO:root:current mean train loss 1064.5329755254152
INFO:root:current train perplexity2.313988447189331
INFO:root:current mean train loss 1064.8099384307861
INFO:root:current train perplexity2.3128488063812256
INFO:root:current mean train loss 1064.49732655181
INFO:root:current train perplexity2.3117241859436035
INFO:root:current mean train loss 1064.3574375270568
INFO:root:current train perplexity2.31215238571167
INFO:root:current mean train loss 1064.6143667839433
INFO:root:current train perplexity2.3125476837158203
INFO:root:current mean train loss 1065.0957175708209
INFO:root:current train perplexity2.3140406608581543
INFO:root:current mean train loss 1065.0452345950896
INFO:root:current train perplexity2.313844919204712
INFO:root:current mean train loss 1065.1263396593988
INFO:root:current train perplexity2.314624309539795
INFO:root:current mean train loss 1065.3482721980463
INFO:root:current train perplexity2.3154618740081787
INFO:root:current mean train loss 1065.326592378838
INFO:root:current train perplexity2.3157057762145996
INFO:root:current mean train loss 1065.634211511793
INFO:root:current train perplexity2.316991090774536
INFO:root:current mean train loss 1065.7141840978322
INFO:root:current train perplexity2.3169021606445312
INFO:root:current mean train loss 1066.1730306984985
INFO:root:current train perplexity2.317488193511963
INFO:root:current mean train loss 1066.2135066470585
INFO:root:current train perplexity2.317831516265869
INFO:root:current mean train loss 1066.3889218068073
INFO:root:current train perplexity2.318246841430664
INFO:root:current mean train loss 1066.4215731910365
INFO:root:current train perplexity2.318120241165161

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.02s/it]
INFO:root:final mean train loss: 1066.1362658186627
INFO:root:final train perplexity: 2.318265199661255
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.86s/it]
INFO:root:eval mean loss: 2704.8346925559617
INFO:root:eval perplexity: 8.913004875183105
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 3364.0912458271
INFO:root:eval perplexity: 15.662137985229492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/182
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [27:14:29<2:40:57, 536.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1065.199429419733
INFO:root:current train perplexity2.3045055866241455
INFO:root:current mean train loss 1063.235630806246
INFO:root:current train perplexity2.3084640502929688
INFO:root:current mean train loss 1061.5211621177075
INFO:root:current train perplexity2.306354522705078
INFO:root:current mean train loss 1062.1178568677442
INFO:root:current train perplexity2.30944561958313
INFO:root:current mean train loss 1062.2773427595714
INFO:root:current train perplexity2.3127055168151855
INFO:root:current mean train loss 1062.6200083946499
INFO:root:current train perplexity2.3133702278137207
INFO:root:current mean train loss 1063.3397276687072
INFO:root:current train perplexity2.313478946685791
INFO:root:current mean train loss 1063.942420526531
INFO:root:current train perplexity2.3120226860046387
INFO:root:current mean train loss 1064.0861318146128
INFO:root:current train perplexity2.3133084774017334
INFO:root:current mean train loss 1064.4089375752337
INFO:root:current train perplexity2.3136837482452393
INFO:root:current mean train loss 1064.703477138788
INFO:root:current train perplexity2.31425404548645
INFO:root:current mean train loss 1064.8619576619637
INFO:root:current train perplexity2.3159728050231934
INFO:root:current mean train loss 1064.936509323415
INFO:root:current train perplexity2.3153414726257324
INFO:root:current mean train loss 1065.1399940989124
INFO:root:current train perplexity2.3152523040771484
INFO:root:current mean train loss 1065.4213872093205
INFO:root:current train perplexity2.3158211708068848
INFO:root:current mean train loss 1065.832530335967
INFO:root:current train perplexity2.315903425216675
INFO:root:current mean train loss 1065.853363343547
INFO:root:current train perplexity2.31656551361084
INFO:root:current mean train loss 1065.7912678332948
INFO:root:current train perplexity2.316384792327881
INFO:root:current mean train loss 1066.0419772914397
INFO:root:current train perplexity2.3174009323120117

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.10s/it]
INFO:root:final mean train loss: 1065.6795886679845
INFO:root:final train perplexity: 2.3174304962158203
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it]
INFO:root:eval mean loss: 2705.147807236259
INFO:root:eval perplexity: 8.915264129638672
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 3364.749645043772
INFO:root:eval perplexity: 15.670572280883789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/183
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [27:23:25<2:31:58, 536.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1053.2904724121095
INFO:root:current train perplexity2.279989719390869
INFO:root:current mean train loss 1060.5804942737925
INFO:root:current train perplexity2.3096272945404053
INFO:root:current mean train loss 1062.7237388974145
INFO:root:current train perplexity2.309357166290283
INFO:root:current mean train loss 1062.9343562956778
INFO:root:current train perplexity2.3086600303649902
INFO:root:current mean train loss 1064.2578656452458
INFO:root:current train perplexity2.3100850582122803
INFO:root:current mean train loss 1063.420774452359
INFO:root:current train perplexity2.30940580368042
INFO:root:current mean train loss 1063.351680367892
INFO:root:current train perplexity2.3099262714385986
INFO:root:current mean train loss 1063.0723950883032
INFO:root:current train perplexity2.310133695602417
INFO:root:current mean train loss 1063.243933708285
INFO:root:current train perplexity2.3120365142822266
INFO:root:current mean train loss 1063.1830470493862
INFO:root:current train perplexity2.3129723072052
INFO:root:current mean train loss 1063.4634139561417
INFO:root:current train perplexity2.314617872238159
INFO:root:current mean train loss 1063.8985336166245
INFO:root:current train perplexity2.3148486614227295
INFO:root:current mean train loss 1064.02665107664
INFO:root:current train perplexity2.315398931503296
INFO:root:current mean train loss 1064.1020427674737
INFO:root:current train perplexity2.3151607513427734
INFO:root:current mean train loss 1064.5225314525849
INFO:root:current train perplexity2.314995288848877
INFO:root:current mean train loss 1064.8505866246508
INFO:root:current train perplexity2.3148140907287598
INFO:root:current mean train loss 1065.2436835816188
INFO:root:current train perplexity2.3146204948425293
INFO:root:current mean train loss 1065.3900277834887
INFO:root:current train perplexity2.315044641494751
INFO:root:current mean train loss 1065.5233993614577
INFO:root:current train perplexity2.3154754638671875
INFO:root:current mean train loss 1065.369122474231
INFO:root:current train perplexity2.3163089752197266

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.71s/it]
INFO:root:final mean train loss: 1065.0585321300389
INFO:root:final train perplexity: 2.316295862197876
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it]
INFO:root:eval mean loss: 2705.3205233093695
INFO:root:eval perplexity: 8.916507720947266
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 3365.2410667906415
INFO:root:eval perplexity: 15.676872253417969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/184
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [27:32:22<2:23:03, 536.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1062.4376876265915
INFO:root:current train perplexity2.3034303188323975
INFO:root:current mean train loss 1063.0317546213705
INFO:root:current train perplexity2.313061237335205
INFO:root:current mean train loss 1064.386905888629
INFO:root:current train perplexity2.304091215133667
INFO:root:current mean train loss 1062.3320390893778
INFO:root:current train perplexity2.3052308559417725
INFO:root:current mean train loss 1062.1651805725812
INFO:root:current train perplexity2.306840658187866
INFO:root:current mean train loss 1063.1007122930132
INFO:root:current train perplexity2.3084030151367188
INFO:root:current mean train loss 1063.5834279524272
INFO:root:current train perplexity2.3073220252990723
INFO:root:current mean train loss 1063.849989606393
INFO:root:current train perplexity2.3092358112335205
INFO:root:current mean train loss 1064.2637574127825
INFO:root:current train perplexity2.3105552196502686
INFO:root:current mean train loss 1064.4584195858195
INFO:root:current train perplexity2.3104705810546875
INFO:root:current mean train loss 1064.6865314011914
INFO:root:current train perplexity2.3114285469055176
INFO:root:current mean train loss 1064.2347347662317
INFO:root:current train perplexity2.3121140003204346
INFO:root:current mean train loss 1063.9843036679592
INFO:root:current train perplexity2.313042402267456
INFO:root:current mean train loss 1063.733074173859
INFO:root:current train perplexity2.3134288787841797
INFO:root:current mean train loss 1063.886252367839
INFO:root:current train perplexity2.3144373893737793
INFO:root:current mean train loss 1063.9681671082622
INFO:root:current train perplexity2.3144876956939697
INFO:root:current mean train loss 1064.0549489720584
INFO:root:current train perplexity2.313776731491089
INFO:root:current mean train loss 1064.0205498691507
INFO:root:current train perplexity2.3149573802948
INFO:root:current mean train loss 1063.9906676344096
INFO:root:current train perplexity2.3141767978668213
INFO:root:current mean train loss 1064.1951191956105
INFO:root:current train perplexity2.31413197517395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.55s/it]
INFO:root:final mean train loss: 1064.08559643567
INFO:root:final train perplexity: 2.314519166946411
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it]
INFO:root:eval mean loss: 2705.5866348591258
INFO:root:eval perplexity: 8.918429374694824
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 3365.9178873697915
INFO:root:eval perplexity: 15.68554973602295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/185
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [27:41:17<2:14:03, 536.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1061.3393124667082
INFO:root:current train perplexity2.288961172103882
INFO:root:current mean train loss 1060.3572387695312
INFO:root:current train perplexity2.300126075744629
INFO:root:current mean train loss 1060.2422582907755
INFO:root:current train perplexity2.301006317138672
INFO:root:current mean train loss 1060.6346527809321
INFO:root:current train perplexity2.3055412769317627
INFO:root:current mean train loss 1060.9681612306888
INFO:root:current train perplexity2.3043692111968994
INFO:root:current mean train loss 1061.0834487466252
INFO:root:current train perplexity2.309102773666382
INFO:root:current mean train loss 1060.7364872523717
INFO:root:current train perplexity2.3098833560943604
INFO:root:current mean train loss 1061.4461372949743
INFO:root:current train perplexity2.3072636127471924
INFO:root:current mean train loss 1061.7577505970453
INFO:root:current train perplexity2.306684970855713
INFO:root:current mean train loss 1062.2372066045211
INFO:root:current train perplexity2.3068947792053223
INFO:root:current mean train loss 1062.5136856137565
INFO:root:current train perplexity2.3081982135772705
INFO:root:current mean train loss 1062.2282240007307
INFO:root:current train perplexity2.3086190223693848
INFO:root:current mean train loss 1062.278812322586
INFO:root:current train perplexity2.3094770908355713
INFO:root:current mean train loss 1062.5746819632393
INFO:root:current train perplexity2.3100314140319824
INFO:root:current mean train loss 1062.5199185104582
INFO:root:current train perplexity2.3107380867004395
INFO:root:current mean train loss 1062.6315068852716
INFO:root:current train perplexity2.3112289905548096
INFO:root:current mean train loss 1062.6561996942598
INFO:root:current train perplexity2.31200909614563
INFO:root:current mean train loss 1062.6954870311492
INFO:root:current train perplexity2.3121042251586914
INFO:root:current mean train loss 1062.8097181671872
INFO:root:current train perplexity2.311493396759033
INFO:root:current mean train loss 1062.7068440001688
INFO:root:current train perplexity2.3110265731811523

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.94s/it]
INFO:root:final mean train loss: 1062.4866800697778
INFO:root:final train perplexity: 2.3116021156311035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it]
INFO:root:eval mean loss: 2706.9759945700353
INFO:root:eval perplexity: 8.928452491760254
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 3366.5619472206063
INFO:root:eval perplexity: 15.693817138671875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/186
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [27:50:14<2:05:10, 536.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1064.5834940925974
INFO:root:current train perplexity2.3178038597106934
INFO:root:current mean train loss 1060.950343919837
INFO:root:current train perplexity2.3138341903686523
INFO:root:current mean train loss 1060.4273307478747
INFO:root:current train perplexity2.311617374420166
INFO:root:current mean train loss 1062.2389096923152
INFO:root:current train perplexity2.3116514682769775
INFO:root:current mean train loss 1062.9482771403877
INFO:root:current train perplexity2.312588691711426
INFO:root:current mean train loss 1062.5288642978499
INFO:root:current train perplexity2.3122406005859375
INFO:root:current mean train loss 1062.8688756160766
INFO:root:current train perplexity2.313397169113159
INFO:root:current mean train loss 1063.1234324952775
INFO:root:current train perplexity2.31249737739563
INFO:root:current mean train loss 1063.374269350342
INFO:root:current train perplexity2.313249349594116
INFO:root:current mean train loss 1063.3254755915266
INFO:root:current train perplexity2.313471794128418
INFO:root:current mean train loss 1063.515726533507
INFO:root:current train perplexity2.3123199939727783
INFO:root:current mean train loss 1063.0905042019103
INFO:root:current train perplexity2.31349515914917
INFO:root:current mean train loss 1063.0590730768456
INFO:root:current train perplexity2.3142271041870117
INFO:root:current mean train loss 1063.1750352846884
INFO:root:current train perplexity2.314345598220825
INFO:root:current mean train loss 1063.2983596457104
INFO:root:current train perplexity2.3142824172973633
INFO:root:current mean train loss 1063.3496768616621
INFO:root:current train perplexity2.314117908477783
INFO:root:current mean train loss 1063.4456280381619
INFO:root:current train perplexity2.313443899154663
INFO:root:current mean train loss 1063.8108885817605
INFO:root:current train perplexity2.3127615451812744
INFO:root:current mean train loss 1063.6210371096374
INFO:root:current train perplexity2.3132381439208984
INFO:root:current mean train loss 1063.6615265997498
INFO:root:current train perplexity2.313020944595337

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.91s/it]
INFO:root:final mean train loss: 1063.2177603101707
INFO:root:final train perplexity: 2.3129355907440186
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it]
INFO:root:eval mean loss: 2708.3533900917
INFO:root:eval perplexity: 8.93840503692627
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 3368.389038518811
INFO:root:eval perplexity: 15.717287063598633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/187
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [27:59:10<1:56:11, 536.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1061.079364483173
INFO:root:current train perplexity2.306053638458252
INFO:root:current mean train loss 1060.6021330758426
INFO:root:current train perplexity2.305081605911255
INFO:root:current mean train loss 1059.6416057339675
INFO:root:current train perplexity2.3049004077911377
INFO:root:current mean train loss 1061.087467900029
INFO:root:current train perplexity2.3062965869903564
INFO:root:current mean train loss 1062.0277457137488
INFO:root:current train perplexity2.302716016769409
INFO:root:current mean train loss 1062.2866160250865
INFO:root:current train perplexity2.300374746322632
INFO:root:current mean train loss 1062.1429129181358
INFO:root:current train perplexity2.30159854888916
INFO:root:current mean train loss 1061.5108162455815
INFO:root:current train perplexity2.3043558597564697
INFO:root:current mean train loss 1061.3043593838981
INFO:root:current train perplexity2.3052854537963867
INFO:root:current mean train loss 1061.5197793223376
INFO:root:current train perplexity2.3052785396575928
INFO:root:current mean train loss 1061.5586820188391
INFO:root:current train perplexity2.304699182510376
INFO:root:current mean train loss 1061.6405081109401
INFO:root:current train perplexity2.3045451641082764
INFO:root:current mean train loss 1061.591097788445
INFO:root:current train perplexity2.305650472640991
INFO:root:current mean train loss 1061.5579258181015
INFO:root:current train perplexity2.306028366088867
INFO:root:current mean train loss 1061.2931525162012
INFO:root:current train perplexity2.3083736896514893
INFO:root:current mean train loss 1061.3208662257903
INFO:root:current train perplexity2.3090169429779053
INFO:root:current mean train loss 1061.3147089415995
INFO:root:current train perplexity2.3084237575531006
INFO:root:current mean train loss 1061.6021193685629
INFO:root:current train perplexity2.309159994125366
INFO:root:current mean train loss 1061.7644446619784
INFO:root:current train perplexity2.3093481063842773
INFO:root:current mean train loss 1061.9736711986145
INFO:root:current train perplexity2.3102641105651855

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.88s/it]
INFO:root:final mean train loss: 1061.7140685758143
INFO:root:final train perplexity: 2.310194253921509
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it]
INFO:root:eval mean loss: 2708.8478177117963
INFO:root:eval perplexity: 8.94198226928711
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.17s/it]
INFO:root:eval mean loss: 3368.9255994431514
INFO:root:eval perplexity: 15.724180221557617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/188
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [28:08:07<1:47:17, 536.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1060.567136744449
INFO:root:current train perplexity2.309990644454956
INFO:root:current mean train loss 1059.6732522035256
INFO:root:current train perplexity2.3128292560577393
INFO:root:current mean train loss 1060.3940758656647
INFO:root:current train perplexity2.308549642562866
INFO:root:current mean train loss 1061.7840644160403
INFO:root:current train perplexity2.307401657104492
INFO:root:current mean train loss 1061.5240226976798
INFO:root:current train perplexity2.3059639930725098
INFO:root:current mean train loss 1060.7522541975775
INFO:root:current train perplexity2.306849718093872
INFO:root:current mean train loss 1060.37502854162
INFO:root:current train perplexity2.3049352169036865
INFO:root:current mean train loss 1060.856027970224
INFO:root:current train perplexity2.304837942123413
INFO:root:current mean train loss 1060.8527363526755
INFO:root:current train perplexity2.306297540664673
INFO:root:current mean train loss 1061.077682357098
INFO:root:current train perplexity2.3067986965179443
INFO:root:current mean train loss 1060.767616752729
INFO:root:current train perplexity2.3080391883850098
INFO:root:current mean train loss 1061.3346885521541
INFO:root:current train perplexity2.3080222606658936
INFO:root:current mean train loss 1061.3621268607474
INFO:root:current train perplexity2.307201623916626
INFO:root:current mean train loss 1061.2929797757056
INFO:root:current train perplexity2.3072826862335205
INFO:root:current mean train loss 1061.1920255016723
INFO:root:current train perplexity2.306487798690796
INFO:root:current mean train loss 1061.3235761014646
INFO:root:current train perplexity2.307208299636841
INFO:root:current mean train loss 1061.1915871229144
INFO:root:current train perplexity2.307778835296631
INFO:root:current mean train loss 1061.19316430052
INFO:root:current train perplexity2.308722496032715
INFO:root:current mean train loss 1061.3245344257607
INFO:root:current train perplexity2.3088912963867188

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:00<00:00, 480.85s/it]
INFO:root:final mean train loss: 1061.1124806983628
INFO:root:final train perplexity: 2.309098482131958
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.06s/it]
INFO:root:eval mean loss: 2710.953284297429
INFO:root:eval perplexity: 8.957221031188965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.38s/it]
INFO:root:eval mean loss: 3370.925577366606
INFO:root:eval perplexity: 15.749922752380371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/189
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [28:17:03<1:38:20, 536.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1058.3136545817058
INFO:root:current train perplexity2.339367389678955
INFO:root:current mean train loss 1055.3658349173409
INFO:root:current train perplexity2.3047738075256348
INFO:root:current mean train loss 1055.3089945091392
INFO:root:current train perplexity2.305250406265259
INFO:root:current mean train loss 1056.951341482309
INFO:root:current train perplexity2.3054466247558594
INFO:root:current mean train loss 1057.9497824363339
INFO:root:current train perplexity2.3073861598968506
INFO:root:current mean train loss 1057.8246375322342
INFO:root:current train perplexity2.305844783782959
INFO:root:current mean train loss 1058.7980098350374
INFO:root:current train perplexity2.305601119995117
INFO:root:current mean train loss 1059.9466226984946
INFO:root:current train perplexity2.306995153427124
INFO:root:current mean train loss 1059.903216582801
INFO:root:current train perplexity2.306579351425171
INFO:root:current mean train loss 1060.1736749347888
INFO:root:current train perplexity2.3081400394439697
INFO:root:current mean train loss 1060.118129805614
INFO:root:current train perplexity2.3090267181396484
INFO:root:current mean train loss 1060.4482506402105
INFO:root:current train perplexity2.3089568614959717
INFO:root:current mean train loss 1060.499280318962
INFO:root:current train perplexity2.3082504272460938
INFO:root:current mean train loss 1060.697240178178
INFO:root:current train perplexity2.3085951805114746
INFO:root:current mean train loss 1060.8087396378558
INFO:root:current train perplexity2.308424711227417
INFO:root:current mean train loss 1061.014685696395
INFO:root:current train perplexity2.3083043098449707
INFO:root:current mean train loss 1061.0840479848403
INFO:root:current train perplexity2.307950735092163
INFO:root:current mean train loss 1060.898353933174
INFO:root:current train perplexity2.3082334995269775
INFO:root:current mean train loss 1061.000158314147
INFO:root:current train perplexity2.3088464736938477
INFO:root:current mean train loss 1061.2278232015826
INFO:root:current train perplexity2.3090953826904297

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.37s/it]
INFO:root:final mean train loss: 1060.9232545699726
INFO:root:final train perplexity: 2.308753728866577
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it]
INFO:root:eval mean loss: 2710.160887373255
INFO:root:eval perplexity: 8.951482772827148
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it]
INFO:root:eval mean loss: 3370.306544094221
INFO:root:eval perplexity: 15.741949081420898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/190
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [28:26:01<1:29:27, 536.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1059.718051252694
INFO:root:current train perplexity2.293128252029419
INFO:root:current mean train loss 1061.9520296791727
INFO:root:current train perplexity2.299102544784546
INFO:root:current mean train loss 1060.696205105844
INFO:root:current train perplexity2.308964967727661
INFO:root:current mean train loss 1059.149664881744
INFO:root:current train perplexity2.308933734893799
INFO:root:current mean train loss 1059.1324218180907
INFO:root:current train perplexity2.3054726123809814
INFO:root:current mean train loss 1059.6787281288766
INFO:root:current train perplexity2.3071584701538086
INFO:root:current mean train loss 1059.9526275004037
INFO:root:current train perplexity2.3061130046844482
INFO:root:current mean train loss 1059.8040453331298
INFO:root:current train perplexity2.3060901165008545
INFO:root:current mean train loss 1059.8849580808485
INFO:root:current train perplexity2.3076016902923584
INFO:root:current mean train loss 1059.6587375275415
INFO:root:current train perplexity2.307025909423828
INFO:root:current mean train loss 1059.8035175112177
INFO:root:current train perplexity2.306487560272217
INFO:root:current mean train loss 1059.7721010517294
INFO:root:current train perplexity2.3069050312042236
INFO:root:current mean train loss 1059.6879636486726
INFO:root:current train perplexity2.3066914081573486
INFO:root:current mean train loss 1059.897325686533
INFO:root:current train perplexity2.3070898056030273
INFO:root:current mean train loss 1059.8340964507522
INFO:root:current train perplexity2.30734920501709
INFO:root:current mean train loss 1059.6973689736067
INFO:root:current train perplexity2.3076164722442627
INFO:root:current mean train loss 1059.7456541020422
INFO:root:current train perplexity2.3076233863830566
INFO:root:current mean train loss 1059.9240943286513
INFO:root:current train perplexity2.3068137168884277
INFO:root:current mean train loss 1060.1336922538678
INFO:root:current train perplexity2.3070123195648193
INFO:root:current mean train loss 1060.3872887278667
INFO:root:current train perplexity2.3076066970825195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.61s/it]
INFO:root:final mean train loss: 1060.1459386751499
INFO:root:final train perplexity: 2.3073387145996094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.02s/it]
INFO:root:eval mean loss: 2712.02505298371
INFO:root:eval perplexity: 8.964987754821777
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.33s/it]
INFO:root:eval mean loss: 3372.7668634509364
INFO:root:eval perplexity: 15.77365779876709
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/191
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [28:34:59<1:20:33, 537.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1070.6063816236413
INFO:root:current train perplexity2.301023483276367
INFO:root:current mean train loss 1059.8721451432737
INFO:root:current train perplexity2.3051459789276123
INFO:root:current mean train loss 1057.4991122610202
INFO:root:current train perplexity2.31154727935791
INFO:root:current mean train loss 1057.9754165914017
INFO:root:current train perplexity2.306649684906006
INFO:root:current mean train loss 1057.7764274015556
INFO:root:current train perplexity2.306157350540161
INFO:root:current mean train loss 1057.391576857794
INFO:root:current train perplexity2.304155111312866
INFO:root:current mean train loss 1057.9767278429156
INFO:root:current train perplexity2.303912878036499
INFO:root:current mean train loss 1058.3609171604023
INFO:root:current train perplexity2.3034427165985107
INFO:root:current mean train loss 1058.2017610157636
INFO:root:current train perplexity2.303741693496704
INFO:root:current mean train loss 1058.586071119248
INFO:root:current train perplexity2.303974151611328
INFO:root:current mean train loss 1058.6558008722775
INFO:root:current train perplexity2.305568218231201
INFO:root:current mean train loss 1058.6216910530343
INFO:root:current train perplexity2.306978702545166
INFO:root:current mean train loss 1059.10690185155
INFO:root:current train perplexity2.307595729827881
INFO:root:current mean train loss 1059.3690941911218
INFO:root:current train perplexity2.3071322441101074
INFO:root:current mean train loss 1059.2874987590362
INFO:root:current train perplexity2.3084092140197754
INFO:root:current mean train loss 1059.5487195566432
INFO:root:current train perplexity2.3078691959381104
INFO:root:current mean train loss 1059.7773948845568
INFO:root:current train perplexity2.3073818683624268
INFO:root:current mean train loss 1059.5595274900106
INFO:root:current train perplexity2.30676007270813
INFO:root:current mean train loss 1059.6623736182116
INFO:root:current train perplexity2.3066978454589844
INFO:root:current mean train loss 1059.8537178000345
INFO:root:current train perplexity2.3063127994537354

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:04<00:00, 484.14s/it]
INFO:root:final mean train loss: 1059.6669881246455
INFO:root:final train perplexity: 2.306467294692993
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.05s/it]
INFO:root:eval mean loss: 2711.837336979859
INFO:root:eval perplexity: 8.96362590789795
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it]
INFO:root:eval mean loss: 3372.5111114285514
INFO:root:eval perplexity: 15.770359992980957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/192
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [28:43:58<1:11:42, 537.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1056.9190896654886
INFO:root:current train perplexity2.3068103790283203
INFO:root:current mean train loss 1058.982815046252
INFO:root:current train perplexity2.3044657707214355
INFO:root:current mean train loss 1060.1971488923627
INFO:root:current train perplexity2.305208206176758
INFO:root:current mean train loss 1057.7098042301566
INFO:root:current train perplexity2.3088555335998535
INFO:root:current mean train loss 1057.8617471979194
INFO:root:current train perplexity2.3067586421966553
INFO:root:current mean train loss 1057.9321493958496
INFO:root:current train perplexity2.30544114112854
INFO:root:current mean train loss 1058.3625607958027
INFO:root:current train perplexity2.306519031524658
INFO:root:current mean train loss 1058.0535872673145
INFO:root:current train perplexity2.308156967163086
INFO:root:current mean train loss 1058.507993554461
INFO:root:current train perplexity2.306436061859131
INFO:root:current mean train loss 1058.588280413381
INFO:root:current train perplexity2.3071603775024414
INFO:root:current mean train loss 1058.9669056243754
INFO:root:current train perplexity2.3061957359313965
INFO:root:current mean train loss 1059.030466829203
INFO:root:current train perplexity2.3063018321990967
INFO:root:current mean train loss 1058.7454557079034
INFO:root:current train perplexity2.3054089546203613
INFO:root:current mean train loss 1059.1612439117096
INFO:root:current train perplexity2.304753065109253
INFO:root:current mean train loss 1059.3096683942856
INFO:root:current train perplexity2.3048181533813477
INFO:root:current mean train loss 1059.4933053063644
INFO:root:current train perplexity2.30543851852417
INFO:root:current mean train loss 1059.4770527631492
INFO:root:current train perplexity2.3061983585357666
INFO:root:current mean train loss 1059.3618368667023
INFO:root:current train perplexity2.3062615394592285
INFO:root:current mean train loss 1059.5446675127064
INFO:root:current train perplexity2.3063714504241943
INFO:root:current mean train loss 1059.7999829735857
INFO:root:current train perplexity2.3062453269958496

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.59s/it]
INFO:root:final mean train loss: 1059.5472611096911
INFO:root:final train perplexity: 2.3062498569488525
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it]
INFO:root:eval mean loss: 2712.568612173094
INFO:root:eval perplexity: 8.968929290771484
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it]
INFO:root:eval mean loss: 3373.424131136414
INFO:root:eval perplexity: 15.782140731811523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/193
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [28:52:56<1:02:44, 537.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1055.4783020019531
INFO:root:current train perplexity2.295790195465088
INFO:root:current mean train loss 1054.1904195149739
INFO:root:current train perplexity2.297348737716675
INFO:root:current mean train loss 1056.0748014177595
INFO:root:current train perplexity2.2982962131500244
INFO:root:current mean train loss 1056.1749447471218
INFO:root:current train perplexity2.300286293029785
INFO:root:current mean train loss 1057.954318745931
INFO:root:current train perplexity2.3015193939208984
INFO:root:current mean train loss 1058.7572848615976
INFO:root:current train perplexity2.3029017448425293
INFO:root:current mean train loss 1058.3391824161306
INFO:root:current train perplexity2.3042314052581787
INFO:root:current mean train loss 1059.1231662848056
INFO:root:current train perplexity2.302860975265503
INFO:root:current mean train loss 1059.1926246643065
INFO:root:current train perplexity2.3038783073425293
INFO:root:current mean train loss 1058.734145557637
INFO:root:current train perplexity2.3041810989379883
INFO:root:current mean train loss 1059.0451706497759
INFO:root:current train perplexity2.303671360015869
INFO:root:current mean train loss 1058.9879736948822
INFO:root:current train perplexity2.3045709133148193
INFO:root:current mean train loss 1059.2181677818298
INFO:root:current train perplexity2.303966760635376
INFO:root:current mean train loss 1059.2966301959493
INFO:root:current train perplexity2.3044049739837646
INFO:root:current mean train loss 1059.1388289168074
INFO:root:current train perplexity2.3042166233062744
INFO:root:current mean train loss 1059.1917851701567
INFO:root:current train perplexity2.3051512241363525
INFO:root:current mean train loss 1059.4097233726866
INFO:root:current train perplexity2.3057284355163574
INFO:root:current mean train loss 1059.5381589053723
INFO:root:current train perplexity2.3054561614990234
INFO:root:current mean train loss 1059.310612552724
INFO:root:current train perplexity2.3055403232574463
INFO:root:current mean train loss 1059.39490714025
INFO:root:current train perplexity2.305351495742798

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.65s/it]
INFO:root:final mean train loss: 1059.071191523211
INFO:root:final train perplexity: 2.3053841590881348
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.00s/it]
INFO:root:eval mean loss: 2712.4291697833555
INFO:root:eval perplexity: 8.967916488647461
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it]
INFO:root:eval mean loss: 3373.334027662345
INFO:root:eval perplexity: 15.780978202819824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/194
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [29:01:54<53:47, 537.86s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1061.3906533152788
INFO:root:current train perplexity2.3097686767578125
INFO:root:current mean train loss 1060.0783734781487
INFO:root:current train perplexity2.305563449859619
INFO:root:current mean train loss 1057.5423216129393
INFO:root:current train perplexity2.305109739303589
INFO:root:current mean train loss 1058.2492681930887
INFO:root:current train perplexity2.3036739826202393
INFO:root:current mean train loss 1058.9534546144052
INFO:root:current train perplexity2.3045735359191895
INFO:root:current mean train loss 1058.384193305394
INFO:root:current train perplexity2.3026888370513916
INFO:root:current mean train loss 1058.174387686906
INFO:root:current train perplexity2.3014702796936035
INFO:root:current mean train loss 1057.8087969963044
INFO:root:current train perplexity2.3025174140930176
INFO:root:current mean train loss 1057.7131918542493
INFO:root:current train perplexity2.302521228790283
INFO:root:current mean train loss 1057.670394790328
INFO:root:current train perplexity2.301673173904419
INFO:root:current mean train loss 1057.9815837960953
INFO:root:current train perplexity2.301738977432251
INFO:root:current mean train loss 1058.0213817829078
INFO:root:current train perplexity2.301898717880249
INFO:root:current mean train loss 1058.0374927153105
INFO:root:current train perplexity2.3017828464508057
INFO:root:current mean train loss 1058.346855584092
INFO:root:current train perplexity2.302560806274414
INFO:root:current mean train loss 1058.2796999842785
INFO:root:current train perplexity2.302103281021118
INFO:root:current mean train loss 1058.4301649271583
INFO:root:current train perplexity2.3021533489227295
INFO:root:current mean train loss 1058.4055655574405
INFO:root:current train perplexity2.3025407791137695
INFO:root:current mean train loss 1058.364189746583
INFO:root:current train perplexity2.302483558654785
INFO:root:current mean train loss 1058.4275477625033
INFO:root:current train perplexity2.303189277648926

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.16s/it]
INFO:root:final mean train loss: 1058.0094253609293
INFO:root:final train perplexity: 2.3034543991088867
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.86s/it]
INFO:root:eval mean loss: 2713.2693516075187
INFO:root:eval perplexity: 8.974014282226562
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.27s/it]
INFO:root:eval mean loss: 3374.408038200216
INFO:root:eval perplexity: 15.794840812683105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/195
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [29:10:51<44:48, 537.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1054.7599225725446
INFO:root:current train perplexity2.2741382122039795
INFO:root:current mean train loss 1052.4098633883293
INFO:root:current train perplexity2.2912919521331787
INFO:root:current mean train loss 1055.278862783842
INFO:root:current train perplexity2.2974305152893066
INFO:root:current mean train loss 1056.1915380392863
INFO:root:current train perplexity2.29715633392334
INFO:root:current mean train loss 1057.7845976456351
INFO:root:current train perplexity2.2952728271484375
INFO:root:current mean train loss 1057.5369894421053
INFO:root:current train perplexity2.2959351539611816
INFO:root:current mean train loss 1058.5346259201
INFO:root:current train perplexity2.2983906269073486
INFO:root:current mean train loss 1058.7440925833223
INFO:root:current train perplexity2.2997846603393555
INFO:root:current mean train loss 1058.818716888053
INFO:root:current train perplexity2.301365852355957
INFO:root:current mean train loss 1058.9004853163037
INFO:root:current train perplexity2.299948215484619
INFO:root:current mean train loss 1058.77741050344
INFO:root:current train perplexity2.300786018371582
INFO:root:current mean train loss 1058.3967194754089
INFO:root:current train perplexity2.3007330894470215
INFO:root:current mean train loss 1058.3958460699394
INFO:root:current train perplexity2.3011562824249268
INFO:root:current mean train loss 1058.5184774877819
INFO:root:current train perplexity2.3012847900390625
INFO:root:current mean train loss 1058.4716496447356
INFO:root:current train perplexity2.3017969131469727
INFO:root:current mean train loss 1058.443575255622
INFO:root:current train perplexity2.3014211654663086
INFO:root:current mean train loss 1058.185416749862
INFO:root:current train perplexity2.3015153408050537
INFO:root:current mean train loss 1058.1886275835604
INFO:root:current train perplexity2.3021931648254395
INFO:root:current mean train loss 1057.9631655860237
INFO:root:current train perplexity2.3030877113342285
INFO:root:current mean train loss 1057.9425313186248
INFO:root:current train perplexity2.3028221130371094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.76s/it]
INFO:root:final mean train loss: 1057.6319427105495
INFO:root:final train perplexity: 2.3027687072753906
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it]
INFO:root:eval mean loss: 2713.6555374903037
INFO:root:eval perplexity: 8.97681713104248
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.27s/it]
INFO:root:eval mean loss: 3374.757567493628
INFO:root:eval perplexity: 15.799356460571289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/196
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [29:19:48<35:49, 537.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1057.025372905116
INFO:root:current train perplexity2.3111135959625244
INFO:root:current mean train loss 1059.4850128406786
INFO:root:current train perplexity2.305875539779663
INFO:root:current mean train loss 1060.2023883505817
INFO:root:current train perplexity2.3044567108154297
INFO:root:current mean train loss 1060.4329961217782
INFO:root:current train perplexity2.3069889545440674
INFO:root:current mean train loss 1059.3531242069678
INFO:root:current train perplexity2.3029189109802246
INFO:root:current mean train loss 1058.990907255988
INFO:root:current train perplexity2.3035807609558105
INFO:root:current mean train loss 1058.6253284871484
INFO:root:current train perplexity2.3036484718322754
INFO:root:current mean train loss 1059.2980646428266
INFO:root:current train perplexity2.3034095764160156
INFO:root:current mean train loss 1059.096433196544
INFO:root:current train perplexity2.302682638168335
INFO:root:current mean train loss 1059.2247345921305
INFO:root:current train perplexity2.302692174911499
INFO:root:current mean train loss 1059.0186825002083
INFO:root:current train perplexity2.3035829067230225
INFO:root:current mean train loss 1058.5326281749074
INFO:root:current train perplexity2.303718328475952
INFO:root:current mean train loss 1058.885877000327
INFO:root:current train perplexity2.304046392440796
INFO:root:current mean train loss 1059.3058756449275
INFO:root:current train perplexity2.3041093349456787
INFO:root:current mean train loss 1059.1567763269238
INFO:root:current train perplexity2.3037307262420654
INFO:root:current mean train loss 1058.9173886568854
INFO:root:current train perplexity2.3037452697753906
INFO:root:current mean train loss 1058.5971837233794
INFO:root:current train perplexity2.3036181926727295
INFO:root:current mean train loss 1058.7845196649562
INFO:root:current train perplexity2.3037612438201904
INFO:root:current mean train loss 1058.6034241556015
INFO:root:current train perplexity2.304199695587158
INFO:root:current mean train loss 1058.4442262891534
INFO:root:current train perplexity2.30367374420166

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:03<00:00, 483.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:03<00:00, 483.74s/it]
INFO:root:final mean train loss: 1058.0735824977396
INFO:root:final train perplexity: 2.3035709857940674
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.92s/it]
INFO:root:eval mean loss: 2713.7488896796044
INFO:root:eval perplexity: 8.977493286132812
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.28s/it]
INFO:root:eval mean loss: 3374.685458135943
INFO:root:eval perplexity: 15.798434257507324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/197
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [29:28:47<26:53, 537.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1055.6350275675456
INFO:root:current train perplexity2.3110015392303467
INFO:root:current mean train loss 1057.8566746067356
INFO:root:current train perplexity2.303208112716675
INFO:root:current mean train loss 1057.9247507895193
INFO:root:current train perplexity2.298983573913574
INFO:root:current mean train loss 1058.2633125042094
INFO:root:current train perplexity2.2994754314422607
INFO:root:current mean train loss 1057.4378140313286
INFO:root:current train perplexity2.3010218143463135
INFO:root:current mean train loss 1058.4081853045163
INFO:root:current train perplexity2.300530195236206
INFO:root:current mean train loss 1057.6242908430688
INFO:root:current train perplexity2.3006370067596436
INFO:root:current mean train loss 1057.6510815135935
INFO:root:current train perplexity2.30072283744812
INFO:root:current mean train loss 1057.5906277062759
INFO:root:current train perplexity2.301208019256592
INFO:root:current mean train loss 1057.6908557746983
INFO:root:current train perplexity2.3013522624969482
INFO:root:current mean train loss 1057.661293553942
INFO:root:current train perplexity2.3016750812530518
INFO:root:current mean train loss 1057.6005867349977
INFO:root:current train perplexity2.302154064178467
INFO:root:current mean train loss 1057.8936366056785
INFO:root:current train perplexity2.30153226852417
INFO:root:current mean train loss 1057.6132458876432
INFO:root:current train perplexity2.301802635192871
INFO:root:current mean train loss 1057.7466252785362
INFO:root:current train perplexity2.301085948944092
INFO:root:current mean train loss 1057.5870904651415
INFO:root:current train perplexity2.3016200065612793
INFO:root:current mean train loss 1057.4495138520176
INFO:root:current train perplexity2.302057981491089
INFO:root:current mean train loss 1057.4849161807133
INFO:root:current train perplexity2.3019468784332275
INFO:root:current mean train loss 1057.2807107900644
INFO:root:current train perplexity2.3022305965423584
INFO:root:current mean train loss 1057.192930781621
INFO:root:current train perplexity2.3016514778137207

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.85s/it]
INFO:root:final mean train loss: 1056.9122672876924
INFO:root:final train perplexity: 2.301462173461914
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.95s/it]
INFO:root:eval mean loss: 2714.4105350142677
INFO:root:eval perplexity: 8.982297897338867
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it]
INFO:root:eval mean loss: 3375.527543737533
INFO:root:eval perplexity: 15.809311866760254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/198
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [29:37:44<17:55, 537.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1052.6040752704328
INFO:root:current train perplexity2.302826166152954
INFO:root:current mean train loss 1058.22519420277
INFO:root:current train perplexity2.3006153106689453
INFO:root:current mean train loss 1056.3344192216982
INFO:root:current train perplexity2.299318790435791
INFO:root:current mean train loss 1056.488288106004
INFO:root:current train perplexity2.2972562313079834
INFO:root:current mean train loss 1055.4121519027217
INFO:root:current train perplexity2.2991743087768555
INFO:root:current mean train loss 1055.284766921322
INFO:root:current train perplexity2.299204111099243
INFO:root:current mean train loss 1056.1590613802573
INFO:root:current train perplexity2.299518585205078
INFO:root:current mean train loss 1056.4366506140216
INFO:root:current train perplexity2.3002779483795166
INFO:root:current mean train loss 1056.7746050707867
INFO:root:current train perplexity2.3009183406829834
INFO:root:current mean train loss 1057.120185496276
INFO:root:current train perplexity2.300191879272461
INFO:root:current mean train loss 1056.754061961286
INFO:root:current train perplexity2.2999584674835205
INFO:root:current mean train loss 1057.0601290592308
INFO:root:current train perplexity2.2998547554016113
INFO:root:current mean train loss 1057.1676947914093
INFO:root:current train perplexity2.301053047180176
INFO:root:current mean train loss 1056.8695299532824
INFO:root:current train perplexity2.301009178161621
INFO:root:current mean train loss 1057.2560166498906
INFO:root:current train perplexity2.3018016815185547
INFO:root:current mean train loss 1057.3066848901133
INFO:root:current train perplexity2.3005566596984863
INFO:root:current mean train loss 1057.0455913921735
INFO:root:current train perplexity2.300808906555176
INFO:root:current mean train loss 1057.0740841614288
INFO:root:current train perplexity2.3012139797210693
INFO:root:current mean train loss 1057.2163911630257
INFO:root:current train perplexity2.301203966140747
INFO:root:current mean train loss 1057.124549240617
INFO:root:current train perplexity2.301088809967041

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:02<00:00, 482.54s/it]
INFO:root:final mean train loss: 1056.8043324157438
INFO:root:final train perplexity: 2.3012661933898926
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it]
INFO:root:eval mean loss: 2714.4215676598515
INFO:root:eval perplexity: 8.982378959655762
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.30s/it]
INFO:root:eval mean loss: 3375.5670330507537
INFO:root:eval perplexity: 15.809821128845215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/199
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [29:46:42<08:57, 537.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1057.2505761123284
INFO:root:current train perplexity2.3007078170776367
INFO:root:current mean train loss 1058.7369210379463
INFO:root:current train perplexity2.300628900527954
INFO:root:current mean train loss 1058.9997653825908
INFO:root:current train perplexity2.2997169494628906
INFO:root:current mean train loss 1058.898968921282
INFO:root:current train perplexity2.303605318069458
INFO:root:current mean train loss 1057.0265623227194
INFO:root:current train perplexity2.3028104305267334
INFO:root:current mean train loss 1057.4030474371107
INFO:root:current train perplexity2.3017172813415527
INFO:root:current mean train loss 1056.6389294397795
INFO:root:current train perplexity2.3019840717315674
INFO:root:current mean train loss 1056.2185805532938
INFO:root:current train perplexity2.302584409713745
INFO:root:current mean train loss 1057.0947561112662
INFO:root:current train perplexity2.303238868713379
INFO:root:current mean train loss 1057.189060063566
INFO:root:current train perplexity2.3032429218292236
INFO:root:current mean train loss 1056.7269870384343
INFO:root:current train perplexity2.3034377098083496
INFO:root:current mean train loss 1056.5516813378244
INFO:root:current train perplexity2.303732395172119
INFO:root:current mean train loss 1056.5260998135238
INFO:root:current train perplexity2.3035688400268555
INFO:root:current mean train loss 1056.832025111153
INFO:root:current train perplexity2.302783727645874
INFO:root:current mean train loss 1056.545804701997
INFO:root:current train perplexity2.3020453453063965
INFO:root:current mean train loss 1056.5920992729486
INFO:root:current train perplexity2.30111026763916
INFO:root:current mean train loss 1056.441204892044
INFO:root:current train perplexity2.300576686859131
INFO:root:current mean train loss 1056.3679072147802
INFO:root:current train perplexity2.3012027740478516
INFO:root:current mean train loss 1056.3746852895026
INFO:root:current train perplexity2.300567388534546
INFO:root:current mean train loss 1056.4815103201765
INFO:root:current train perplexity2.3001153469085693

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.92s/it]
INFO:root:final mean train loss: 1056.186042974167
INFO:root:final train perplexity: 2.3001441955566406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.97s/it]
INFO:root:eval mean loss: 2714.531345665032
INFO:root:eval perplexity: 8.983176231384277
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.33s/it]
INFO:root:eval mean loss: 3375.678785391733
INFO:root:eval perplexity: 15.811264991760254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: bert_fair_baseline/200
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [29:55:39<00:00, 537.52s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [29:55:39<00:00, 538.70s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.02s/it]
INFO:root:eval mean loss: 2714.531345665032
INFO:root:eval perplexity: 8.983176231384277
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it]
INFO:root:eval mean loss: 3375.678785391733
INFO:root:eval perplexity: 15.811264991760254
INFO:root:evalaution complete
INFO:root:save model final: bert_fair_baseline/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x14b6c6fadf06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x14b6c6fa58e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x14b6c6ecae09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x14b6c6faea3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x14b6c6ec8948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x14b6c6faea3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x14b6c6e83b46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x14b6c68e846a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x14b7c3144a27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x14b7c3144be0]
python(+0x24a989) [0x558ae64c6989]
python(+0x24a9bd) [0x558ae64c69bd]
python(+0x24aa14) [0x558ae64c6a14]
python(+0x108f75) [0x558ae6384f75]
python(Py_RunMain+0x313) [0x558ae64c9983]
python(Py_BytesMain+0x39) [0x558ae64c9bc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x14b7c31220b3]
python(+0x1d6e13) [0x558ae6452e13]
/opt/slurm/data/slurmd/job30151614/slurm_script: line 262: 3084218 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path bert-base-uncased --data_config data_config.json --data_folder fast_processed_data_opt_allmini --output bert_fair_baseline --epochs 200 --save_head  --save_epochs 1 --external_embedding --test_eval --fair_baseline --not_retrieval --not_cross_attention --lr 1e-5
"
