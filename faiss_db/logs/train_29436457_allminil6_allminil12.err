INFO:root:Output: allminil16_allminilml12
INFO:root:Steps per epochs:1983
INFO:root:Total steps:396600
Downloading:   0%|          | 0.00/352 [00:00<?, ?B/s]Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 352/352 [00:00<00:00, 595kB/s]
Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 232k/232k [00:00<00:00, 2.68MB/s]
Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]Downloading:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 295k/466k [00:00<00:00, 2.81MB/s]Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 466k/466k [00:00<00:00, 3.35MB/s]
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L12-v2 and are newly initialized: ['encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'cls.predictions.decoder.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.10.crossattention.self.query.weight', 'cls.predictions.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.8.crossattention.self.key.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.7.crossattention.self.query.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.key.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11591.231859611742
INFO:root:current train perplexity9773.7744140625
INFO:root:current mean train loss 9658.466666830245
INFO:root:current train perplexity2099.646484375
INFO:root:current mean train loss 8513.016941236414
INFO:root:current train perplexity847.4592895507812
INFO:root:current mean train loss 7703.804256735589
INFO:root:current train perplexity439.7745666503906
INFO:root:current mean train loss 7087.612915283692
INFO:root:current train perplexity270.2633056640625
INFO:root:current mean train loss 6612.410752947621
INFO:root:current train perplexity185.74757385253906
INFO:root:current mean train loss 6239.289929391318
INFO:root:current train perplexity138.01132202148438
INFO:root:current mean train loss 5943.184673285455
INFO:root:current train perplexity108.6535873413086
INFO:root:current mean train loss 5692.938789410108
INFO:root:current train perplexity89.25138854980469
INFO:root:current mean train loss 5480.006067835414
INFO:root:current train perplexity75.53822326660156
INFO:root:current mean train loss 5299.213310040378
INFO:root:current train perplexity65.37313842773438
INFO:root:current mean train loss 5142.2262607348575
INFO:root:current train perplexity57.76073455810547
INFO:root:current mean train loss 5003.373596426338
INFO:root:current train perplexity51.74726486206055
INFO:root:current mean train loss 4880.546415862055
INFO:root:current train perplexity46.97761154174805
INFO:root:current mean train loss 4769.790036782334
INFO:root:current train perplexity43.076881408691406
INFO:root:current mean train loss 4671.069706347229
INFO:root:current train perplexity39.81157302856445
INFO:root:current mean train loss 4580.608855823968
INFO:root:current train perplexity37.06352996826172
INFO:root:current mean train loss 4499.578453958797
INFO:root:current train perplexity34.75772476196289
INFO:root:current mean train loss 4425.047471273943
INFO:root:current train perplexity32.76327896118164

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.32s/it]
INFO:root:final mean train loss: 4365.118765795886
INFO:root:final train perplexity: 31.267993927001953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.70s/it]
INFO:root:eval mean loss: 2829.0926600246567
INFO:root:eval perplexity: 9.855246543884277
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it]
INFO:root:eval mean loss: 3131.0082098778257
INFO:root:eval perplexity: 12.943899154663086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/1
  0%|          | 1/200 [10:33<35:00:14, 633.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2979.915267944336
INFO:root:current train perplexity10.487738609313965
INFO:root:current mean train loss 3020.5037231445312
INFO:root:current train perplexity10.685741424560547
INFO:root:current mean train loss 3001.791005452474
INFO:root:current train perplexity10.564556121826172
INFO:root:current mean train loss 2985.4541880933543
INFO:root:current train perplexity10.433653831481934
INFO:root:current mean train loss 2964.978949913612
INFO:root:current train perplexity10.275208473205566
INFO:root:current mean train loss 2950.1695187590844
INFO:root:current train perplexity10.18696117401123
INFO:root:current mean train loss 2938.898300765397
INFO:root:current train perplexity10.110361099243164
INFO:root:current mean train loss 2924.4969993889663
INFO:root:current train perplexity10.00908374786377
INFO:root:current mean train loss 2910.9692311006434
INFO:root:current train perplexity9.915492057800293
INFO:root:current mean train loss 2904.761017778555
INFO:root:current train perplexity9.85344409942627
INFO:root:current mean train loss 2892.593237929457
INFO:root:current train perplexity9.763504981994629
INFO:root:current mean train loss 2881.9575785975303
INFO:root:current train perplexity9.687931060791016
INFO:root:current mean train loss 2872.4794871681615
INFO:root:current train perplexity9.624517440795898
INFO:root:current mean train loss 2864.4303034170784
INFO:root:current train perplexity9.559194564819336
INFO:root:current mean train loss 2858.3386582196767
INFO:root:current train perplexity9.50271987915039
INFO:root:current mean train loss 2848.8159343950983
INFO:root:current train perplexity9.442517280578613
INFO:root:current mean train loss 2840.187664371906
INFO:root:current train perplexity9.384480476379395
INFO:root:current mean train loss 2832.6309659375456
INFO:root:current train perplexity9.32127857208252
INFO:root:current mean train loss 2823.225942199976
INFO:root:current train perplexity9.255428314208984
INFO:root:current mean train loss 2816.3994158464084
INFO:root:current train perplexity9.210075378417969

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.13s/it]
INFO:root:final mean train loss: 2810.7967926348574
INFO:root:final train perplexity: 9.177579879760742
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.51s/it]
INFO:root:eval mean loss: 2518.8694756690493
INFO:root:eval perplexity: 7.66844367980957
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it]
INFO:root:eval mean loss: 2864.7886599276926
INFO:root:eval perplexity: 10.411416053771973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/2
  1%|          | 2/200 [21:27<35:31:10, 645.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2637.370058001894
INFO:root:current train perplexity8.056883811950684
INFO:root:current mean train loss 2645.58622753172
INFO:root:current train perplexity8.05765438079834
INFO:root:current mean train loss 2634.174829835032
INFO:root:current train perplexity8.019914627075195
INFO:root:current mean train loss 2637.0673952761354
INFO:root:current train perplexity7.9907050132751465
INFO:root:current mean train loss 2634.829358671334
INFO:root:current train perplexity7.985014915466309
INFO:root:current mean train loss 2631.015302990883
INFO:root:current train perplexity7.951857089996338
INFO:root:current mean train loss 2625.66976412853
INFO:root:current train perplexity7.928957939147949
INFO:root:current mean train loss 2624.31663873316
INFO:root:current train perplexity7.909548282623291
INFO:root:current mean train loss 2620.6690115499323
INFO:root:current train perplexity7.886409282684326
INFO:root:current mean train loss 2614.822399863093
INFO:root:current train perplexity7.855414390563965
INFO:root:current mean train loss 2608.6558531828564
INFO:root:current train perplexity7.825022220611572
INFO:root:current mean train loss 2602.645170799316
INFO:root:current train perplexity7.790056228637695
INFO:root:current mean train loss 2599.1524003795366
INFO:root:current train perplexity7.771244525909424
INFO:root:current mean train loss 2595.370593563918
INFO:root:current train perplexity7.74449348449707
INFO:root:current mean train loss 2592.115927867264
INFO:root:current train perplexity7.72162389755249
INFO:root:current mean train loss 2587.2291960495404
INFO:root:current train perplexity7.693124771118164
INFO:root:current mean train loss 2584.0538726264685
INFO:root:current train perplexity7.668862342834473
INFO:root:current mean train loss 2581.191929539297
INFO:root:current train perplexity7.650866508483887
INFO:root:current mean train loss 2579.000145245691
INFO:root:current train perplexity7.638521671295166
INFO:root:current mean train loss 2576.079492654815
INFO:root:current train perplexity7.619755744934082

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.47s/it]
INFO:root:final mean train loss: 2573.857814432934
INFO:root:final train perplexity: 7.61331844329834
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.58s/it]
INFO:root:eval mean loss: 2379.7962633498173
INFO:root:eval perplexity: 6.852678298950195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it]
INFO:root:eval mean loss: 2746.5572903680463
INFO:root:eval perplexity: 9.451844215393066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/3
  2%|â–         | 3/200 [32:09<35:13:37, 643.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2456.0371630859377
INFO:root:current train perplexity7.023101329803467
INFO:root:current mean train loss 2470.9420540364586
INFO:root:current train perplexity7.094452381134033
INFO:root:current mean train loss 2481.5138544921874
INFO:root:current train perplexity7.082645893096924
INFO:root:current mean train loss 2484.8181556919644
INFO:root:current train perplexity7.059553623199463
INFO:root:current mean train loss 2484.7538471137154
INFO:root:current train perplexity7.061921119689941
INFO:root:current mean train loss 2478.8367764559657
INFO:root:current train perplexity7.045706748962402
INFO:root:current mean train loss 2474.1624365234375
INFO:root:current train perplexity7.034705638885498
INFO:root:current mean train loss 2469.3938756510415
INFO:root:current train perplexity7.025065898895264
INFO:root:current mean train loss 2468.2410486557906
INFO:root:current train perplexity7.0051984786987305
INFO:root:current mean train loss 2465.0305320980674
INFO:root:current train perplexity6.987045764923096
INFO:root:current mean train loss 2459.466141764323
INFO:root:current train perplexity6.973888874053955
INFO:root:current mean train loss 2459.2645769998303
INFO:root:current train perplexity6.96981143951416
INFO:root:current mean train loss 2459.4326006835936
INFO:root:current train perplexity6.964737415313721
INFO:root:current mean train loss 2457.646151349103
INFO:root:current train perplexity6.952242374420166
INFO:root:current mean train loss 2456.357252239359
INFO:root:current train perplexity6.936580657958984
INFO:root:current mean train loss 2454.517368715348
INFO:root:current train perplexity6.930994510650635
INFO:root:current mean train loss 2452.976911917022
INFO:root:current train perplexity6.918359756469727
INFO:root:current mean train loss 2451.0836875697546
INFO:root:current train perplexity6.905879497528076
INFO:root:current mean train loss 2448.346679225612
INFO:root:current train perplexity6.895873069763184
INFO:root:current mean train loss 2446.2478364758613
INFO:root:current train perplexity6.881443023681641

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.06s/it]
INFO:root:final mean train loss: 2444.917711743669
INFO:root:final train perplexity: 6.8771843910217285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it]
INFO:root:eval mean loss: 2290.953647045379
INFO:root:eval perplexity: 6.377579689025879
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.48s/it]
INFO:root:eval mean loss: 2667.280102452488
INFO:root:eval perplexity: 8.858476638793945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/4
  2%|â–         | 4/200 [42:46<34:55:11, 641.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2399.7018387068565
INFO:root:current train perplexity6.567407608032227
INFO:root:current mean train loss 2377.78857421875
INFO:root:current train perplexity6.478880882263184
INFO:root:current mean train loss 2377.0288209379387
INFO:root:current train perplexity6.504711627960205
INFO:root:current mean train loss 2371.498972547152
INFO:root:current train perplexity6.484298229217529
INFO:root:current mean train loss 2374.7152567502008
INFO:root:current train perplexity6.510962963104248
INFO:root:current mean train loss 2376.5043256379518
INFO:root:current train perplexity6.505729675292969
INFO:root:current mean train loss 2373.3034430050598
INFO:root:current train perplexity6.499704837799072
INFO:root:current mean train loss 2376.2445787730708
INFO:root:current train perplexity6.502751350402832
INFO:root:current mean train loss 2373.9075854520347
INFO:root:current train perplexity6.499017715454102
INFO:root:current mean train loss 2372.593749873764
INFO:root:current train perplexity6.488793849945068
INFO:root:current mean train loss 2372.120668734807
INFO:root:current train perplexity6.485018730163574
INFO:root:current mean train loss 2369.463703485667
INFO:root:current train perplexity6.470096111297607
INFO:root:current mean train loss 2369.9179296335465
INFO:root:current train perplexity6.4665608406066895
INFO:root:current mean train loss 2367.2225960631745
INFO:root:current train perplexity6.460268974304199
INFO:root:current mean train loss 2365.010658976653
INFO:root:current train perplexity6.447505950927734
INFO:root:current mean train loss 2364.5770208362414
INFO:root:current train perplexity6.442583084106445
INFO:root:current mean train loss 2361.4951599523847
INFO:root:current train perplexity6.43510103225708
INFO:root:current mean train loss 2361.813795796747
INFO:root:current train perplexity6.430326461791992
INFO:root:current mean train loss 2360.2809434184815
INFO:root:current train perplexity6.427126407623291
INFO:root:current mean train loss 2358.7713632355744
INFO:root:current train perplexity6.421165943145752

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.56s/it]
INFO:root:final mean train loss: 2357.5735039338283
INFO:root:final train perplexity: 6.419397354125977
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.64s/it]
INFO:root:eval mean loss: 2232.4542392162566
INFO:root:eval perplexity: 6.082878112792969
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.28s/it]
INFO:root:eval mean loss: 2618.350053070285
INFO:root:eval perplexity: 8.510993003845215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/5
  2%|â–Ž         | 5/200 [53:17<34:32:02, 637.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2305.868416922433
INFO:root:current train perplexity6.218420505523682
INFO:root:current mean train loss 2324.1151806375256
INFO:root:current train perplexity6.219157695770264
INFO:root:current mean train loss 2313.952980578785
INFO:root:current train perplexity6.191126823425293
INFO:root:current mean train loss 2313.0758730570474
INFO:root:current train perplexity6.19822883605957
INFO:root:current mean train loss 2307.5307158162773
INFO:root:current train perplexity6.186759948730469
INFO:root:current mean train loss 2310.855996954931
INFO:root:current train perplexity6.182898998260498
INFO:root:current mean train loss 2306.428008854738
INFO:root:current train perplexity6.174236297607422
INFO:root:current mean train loss 2303.6824924702546
INFO:root:current train perplexity6.161593437194824
INFO:root:current mean train loss 2303.172220221472
INFO:root:current train perplexity6.153687000274658
INFO:root:current mean train loss 2300.3789191517403
INFO:root:current train perplexity6.14629602432251
INFO:root:current mean train loss 2299.585398318583
INFO:root:current train perplexity6.138993263244629
INFO:root:current mean train loss 2299.305072165824
INFO:root:current train perplexity6.1329522132873535
INFO:root:current mean train loss 2298.99339841088
INFO:root:current train perplexity6.1258344650268555
INFO:root:current mean train loss 2297.9263381517003
INFO:root:current train perplexity6.121025562286377
INFO:root:current mean train loss 2295.4518722986595
INFO:root:current train perplexity6.118061542510986
INFO:root:current mean train loss 2293.72301444622
INFO:root:current train perplexity6.111376762390137
INFO:root:current mean train loss 2293.6353480685634
INFO:root:current train perplexity6.10752010345459
INFO:root:current mean train loss 2293.3648075394567
INFO:root:current train perplexity6.1024169921875
INFO:root:current mean train loss 2292.574603103022
INFO:root:current train perplexity6.099706649780273

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.59s/it]
INFO:root:final mean train loss: 2292.6422963106324
INFO:root:final train perplexity: 6.098943710327148
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.06s/it]
INFO:root:eval mean loss: 2189.730953135389
INFO:root:eval perplexity: 5.876291751861572
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it]
INFO:root:eval mean loss: 2581.2731587294993
INFO:root:eval perplexity: 8.256793022155762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/6
  3%|â–Ž         | 6/200 [1:04:01<34:28:22, 639.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2306.49462890625
INFO:root:current train perplexity6.1305341720581055
INFO:root:current mean train loss 2233.5220862662436
INFO:root:current train perplexity5.854073524475098
INFO:root:current mean train loss 2238.359065876671
INFO:root:current train perplexity5.876931667327881
INFO:root:current mean train loss 2239.6163078637614
INFO:root:current train perplexity5.8601861000061035
INFO:root:current mean train loss 2242.1482216699465
INFO:root:current train perplexity5.871465682983398
INFO:root:current mean train loss 2247.7546467124344
INFO:root:current train perplexity5.874610424041748
INFO:root:current mean train loss 2249.6181059724677
INFO:root:current train perplexity5.879497051239014
INFO:root:current mean train loss 2251.512818079362
INFO:root:current train perplexity5.887050628662109
INFO:root:current mean train loss 2250.0034924910756
INFO:root:current train perplexity5.8801140785217285
INFO:root:current mean train loss 2250.1276169924045
INFO:root:current train perplexity5.880815029144287
INFO:root:current mean train loss 2247.5311848795736
INFO:root:current train perplexity5.878995418548584
INFO:root:current mean train loss 2248.1170060021786
INFO:root:current train perplexity5.878159523010254
INFO:root:current mean train loss 2246.992587760525
INFO:root:current train perplexity5.876518726348877
INFO:root:current mean train loss 2245.242784058837
INFO:root:current train perplexity5.869466304779053
INFO:root:current mean train loss 2245.7790115214857
INFO:root:current train perplexity5.87071418762207
INFO:root:current mean train loss 2245.1337008237997
INFO:root:current train perplexity5.871115684509277
INFO:root:current mean train loss 2244.2020394053034
INFO:root:current train perplexity5.867886543273926
INFO:root:current mean train loss 2241.678101447104
INFO:root:current train perplexity5.861149311065674
INFO:root:current mean train loss 2241.150491548207
INFO:root:current train perplexity5.857707977294922
INFO:root:current mean train loss 2241.868099591909
INFO:root:current train perplexity5.855289459228516

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.85s/it]
INFO:root:final mean train loss: 2240.4498262390966
INFO:root:final train perplexity: 5.852994918823242
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.77s/it]
INFO:root:eval mean loss: 2156.2164752500275
INFO:root:eval perplexity: 5.719155311584473
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it]
INFO:root:eval mean loss: 2550.711818830341
INFO:root:eval perplexity: 8.052979469299316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/7
  4%|â–Ž         | 7/200 [1:14:38<34:14:27, 638.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2301.39892578125
INFO:root:current train perplexity5.7616448402404785
INFO:root:current mean train loss 2214.5935379286943
INFO:root:current train perplexity5.707266807556152
INFO:root:current mean train loss 2210.139295665496
INFO:root:current train perplexity5.668874263763428
INFO:root:current mean train loss 2199.2354268008057
INFO:root:current train perplexity5.651358127593994
INFO:root:current mean train loss 2209.6999824195386
INFO:root:current train perplexity5.687183856964111
INFO:root:current mean train loss 2208.372091050314
INFO:root:current train perplexity5.6782307624816895
INFO:root:current mean train loss 2208.793974546167
INFO:root:current train perplexity5.678226947784424
INFO:root:current mean train loss 2210.2767770921287
INFO:root:current train perplexity5.684978485107422
INFO:root:current mean train loss 2204.791792219017
INFO:root:current train perplexity5.678953170776367
INFO:root:current mean train loss 2206.2565102836925
INFO:root:current train perplexity5.679785251617432
INFO:root:current mean train loss 2204.5350012039153
INFO:root:current train perplexity5.675967216491699
INFO:root:current mean train loss 2203.402907369815
INFO:root:current train perplexity5.677188873291016
INFO:root:current mean train loss 2201.3842288363353
INFO:root:current train perplexity5.673583507537842
INFO:root:current mean train loss 2202.6321347226503
INFO:root:current train perplexity5.674764156341553
INFO:root:current mean train loss 2202.8408317619724
INFO:root:current train perplexity5.676517486572266
INFO:root:current mean train loss 2202.3408304448185
INFO:root:current train perplexity5.675932884216309
INFO:root:current mean train loss 2200.862446750787
INFO:root:current train perplexity5.669459819793701
INFO:root:current mean train loss 2201.26036546061
INFO:root:current train perplexity5.669283390045166
INFO:root:current mean train loss 2200.163927672064
INFO:root:current train perplexity5.667105674743652
INFO:root:current mean train loss 2199.2377584097408
INFO:root:current train perplexity5.664992332458496

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.43s/it]
INFO:root:final mean train loss: 2198.251065083483
INFO:root:final train perplexity: 5.661409378051758
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.46s/it]
INFO:root:eval mean loss: 2129.3059770300033
INFO:root:eval perplexity: 5.596031665802002
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it]
INFO:root:eval mean loss: 2530.1692894468915
INFO:root:eval perplexity: 7.918818473815918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/8
  4%|â–         | 8/200 [1:25:09<33:56:45, 636.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2117.92626953125
INFO:root:current train perplexity5.3451032638549805
INFO:root:current mean train loss 2152.1087981047453
INFO:root:current train perplexity5.4782938957214355
INFO:root:current mean train loss 2147.0079621010636
INFO:root:current train perplexity5.4816813468933105
INFO:root:current mean train loss 2159.200824247901
INFO:root:current train perplexity5.494338512420654
INFO:root:current mean train loss 2165.5114002447017
INFO:root:current train perplexity5.516953468322754
INFO:root:current mean train loss 2163.701634373175
INFO:root:current train perplexity5.505281448364258
INFO:root:current mean train loss 2163.378812438484
INFO:root:current train perplexity5.497824192047119
INFO:root:current mean train loss 2162.5815298482676
INFO:root:current train perplexity5.500465393066406
INFO:root:current mean train loss 2161.0129488094126
INFO:root:current train perplexity5.499985218048096
INFO:root:current mean train loss 2163.8528896066596
INFO:root:current train perplexity5.5000901222229
INFO:root:current mean train loss 2164.563427380548
INFO:root:current train perplexity5.501631259918213
INFO:root:current mean train loss 2165.2302412797703
INFO:root:current train perplexity5.506997108459473
INFO:root:current mean train loss 2162.9339718220203
INFO:root:current train perplexity5.505807876586914
INFO:root:current mean train loss 2161.2031844349835
INFO:root:current train perplexity5.50223970413208
INFO:root:current mean train loss 2161.4869201022157
INFO:root:current train perplexity5.5003581047058105
INFO:root:current mean train loss 2162.40711912472
INFO:root:current train perplexity5.503325939178467
INFO:root:current mean train loss 2163.1336210011705
INFO:root:current train perplexity5.504234313964844
INFO:root:current mean train loss 2163.128249954971
INFO:root:current train perplexity5.505249977111816
INFO:root:current mean train loss 2162.3128125266094
INFO:root:current train perplexity5.5027666091918945
INFO:root:current mean train loss 2162.9050006560883
INFO:root:current train perplexity5.502686023712158

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.67s/it]
INFO:root:final mean train loss: 2161.941304678636
INFO:root:final train perplexity: 5.501589775085449
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.35s/it]
INFO:root:eval mean loss: 2106.7979749314327
INFO:root:eval perplexity: 5.495087146759033
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 2512.8352721735096
INFO:root:eval perplexity: 7.807352066040039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/9
  4%|â–         | 9/200 [1:35:51<33:51:13, 638.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2094.8924419696514
INFO:root:current train perplexity5.344917297363281
INFO:root:current mean train loss 2131.886738827354
INFO:root:current train perplexity5.4116435050964355
INFO:root:current mean train loss 2142.9180666000125
INFO:root:current train perplexity5.40726375579834
INFO:root:current mean train loss 2137.07365694913
INFO:root:current train perplexity5.399301528930664
INFO:root:current mean train loss 2134.3547357879906
INFO:root:current train perplexity5.392754077911377
INFO:root:current mean train loss 2131.5611085753508
INFO:root:current train perplexity5.3821258544921875
INFO:root:current mean train loss 2131.7764250398413
INFO:root:current train perplexity5.382460594177246
INFO:root:current mean train loss 2131.418425377379
INFO:root:current train perplexity5.379014015197754
INFO:root:current mean train loss 2134.8448287175856
INFO:root:current train perplexity5.382887363433838
INFO:root:current mean train loss 2133.0568080870044
INFO:root:current train perplexity5.379182815551758
INFO:root:current mean train loss 2133.1242061948597
INFO:root:current train perplexity5.376776695251465
INFO:root:current mean train loss 2134.5666581259834
INFO:root:current train perplexity5.380162715911865
INFO:root:current mean train loss 2132.2383639302116
INFO:root:current train perplexity5.377288341522217
INFO:root:current mean train loss 2133.1367861053645
INFO:root:current train perplexity5.374063014984131
INFO:root:current mean train loss 2133.516853185396
INFO:root:current train perplexity5.374053001403809
INFO:root:current mean train loss 2132.837546437057
INFO:root:current train perplexity5.372811317443848
INFO:root:current mean train loss 2133.9130326610502
INFO:root:current train perplexity5.374847412109375
INFO:root:current mean train loss 2134.0790223422114
INFO:root:current train perplexity5.375046730041504
INFO:root:current mean train loss 2132.7454820801836
INFO:root:current train perplexity5.371499061584473
INFO:root:current mean train loss 2132.9538616743243
INFO:root:current train perplexity5.37144136428833

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.54s/it]
INFO:root:final mean train loss: 2131.0378327170106
INFO:root:final train perplexity: 5.369123458862305
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.90s/it]
INFO:root:eval mean loss: 2089.8404895971853
INFO:root:eval perplexity: 5.420240879058838
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 2496.6503555622508
INFO:root:eval perplexity: 7.704690933227539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/10
  5%|â–Œ         | 10/200 [1:46:34<33:45:33, 639.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2115.4508074331975
INFO:root:current train perplexity5.287112236022949
INFO:root:current mean train loss 2123.3236856855583
INFO:root:current train perplexity5.290028095245361
INFO:root:current mean train loss 2119.4812674256505
INFO:root:current train perplexity5.275815963745117
INFO:root:current mean train loss 2113.655695555979
INFO:root:current train perplexity5.261425018310547
INFO:root:current mean train loss 2112.491506352862
INFO:root:current train perplexity5.263974189758301
INFO:root:current mean train loss 2107.8897848816455
INFO:root:current train perplexity5.261034965515137
INFO:root:current mean train loss 2105.535772440501
INFO:root:current train perplexity5.252501964569092
INFO:root:current mean train loss 2107.177551983857
INFO:root:current train perplexity5.260673999786377
INFO:root:current mean train loss 2105.915000994543
INFO:root:current train perplexity5.2600932121276855
INFO:root:current mean train loss 2105.4184780691676
INFO:root:current train perplexity5.258985996246338
INFO:root:current mean train loss 2104.529420543988
INFO:root:current train perplexity5.256762504577637
INFO:root:current mean train loss 2105.903425153042
INFO:root:current train perplexity5.255661964416504
INFO:root:current mean train loss 2105.6299635193495
INFO:root:current train perplexity5.258362770080566
INFO:root:current mean train loss 2105.5006066065275
INFO:root:current train perplexity5.2545928955078125
INFO:root:current mean train loss 2106.2431574146954
INFO:root:current train perplexity5.259261131286621
INFO:root:current mean train loss 2105.249330052606
INFO:root:current train perplexity5.256307125091553
INFO:root:current mean train loss 2104.0709416484888
INFO:root:current train perplexity5.252838611602783
INFO:root:current mean train loss 2104.129322213733
INFO:root:current train perplexity5.251195430755615
INFO:root:current mean train loss 2103.5431294203954
INFO:root:current train perplexity5.248680591583252
INFO:root:current mean train loss 2104.115843052668
INFO:root:current train perplexity5.254427909851074

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.31s/it]
INFO:root:final mean train loss: 2103.4581452724133
INFO:root:final train perplexity: 5.253599643707275
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.31s/it]
INFO:root:eval mean loss: 2075.6350443955007
INFO:root:eval perplexity: 5.358326435089111
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 38.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.08s/it]
INFO:root:eval mean loss: 2486.301039675449
INFO:root:eval perplexity: 7.639754772186279
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/11
  6%|â–Œ         | 11/200 [1:57:09<33:30:26, 638.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2087.0405131495277
INFO:root:current train perplexity5.12320613861084
INFO:root:current mean train loss 2070.239559706821
INFO:root:current train perplexity5.115417003631592
INFO:root:current mean train loss 2069.7685367610907
INFO:root:current train perplexity5.11549186706543
INFO:root:current mean train loss 2073.6539379376823
INFO:root:current train perplexity5.131563186645508
INFO:root:current mean train loss 2069.336624208301
INFO:root:current train perplexity5.139522552490234
INFO:root:current mean train loss 2073.219075381959
INFO:root:current train perplexity5.141067028045654
INFO:root:current mean train loss 2075.071868451622
INFO:root:current train perplexity5.134190559387207
INFO:root:current mean train loss 2075.4497630966225
INFO:root:current train perplexity5.132133960723877
INFO:root:current mean train loss 2076.079687803109
INFO:root:current train perplexity5.1348114013671875
INFO:root:current mean train loss 2078.1798868237356
INFO:root:current train perplexity5.139700889587402
INFO:root:current mean train loss 2079.3516163413256
INFO:root:current train perplexity5.145784854888916
INFO:root:current mean train loss 2080.1567393105106
INFO:root:current train perplexity5.147966384887695
INFO:root:current mean train loss 2080.0772795254484
INFO:root:current train perplexity5.147665023803711
INFO:root:current mean train loss 2079.7079401718074
INFO:root:current train perplexity5.149289131164551
INFO:root:current mean train loss 2078.46368038542
INFO:root:current train perplexity5.151091575622559
INFO:root:current mean train loss 2080.238958871079
INFO:root:current train perplexity5.1541748046875
INFO:root:current mean train loss 2079.291731321939
INFO:root:current train perplexity5.154470920562744
INFO:root:current mean train loss 2079.697118744204
INFO:root:current train perplexity5.155612945556641
INFO:root:current mean train loss 2079.678433140161
INFO:root:current train perplexity5.157578945159912

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.72s/it]
INFO:root:final mean train loss: 2079.977369715334
INFO:root:final train perplexity: 5.157207489013672
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.65s/it]
INFO:root:eval mean loss: 2062.9104267959056
INFO:root:eval perplexity: 5.303466796875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 2475.449571974734
INFO:root:eval perplexity: 7.572254657745361
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/12
  6%|â–Œ         | 12/200 [2:07:48<33:20:21, 638.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2124.815673828125
INFO:root:current train perplexity4.963059425354004
INFO:root:current mean train loss 2059.1411405396693
INFO:root:current train perplexity5.0756306648254395
INFO:root:current mean train loss 2050.8335844894937
INFO:root:current train perplexity5.041467189788818
INFO:root:current mean train loss 2055.553210972953
INFO:root:current train perplexity5.047318458557129
INFO:root:current mean train loss 2053.9017521784854
INFO:root:current train perplexity5.044371128082275
INFO:root:current mean train loss 2054.9036350743195
INFO:root:current train perplexity5.051088333129883
INFO:root:current mean train loss 2058.492467877086
INFO:root:current train perplexity5.067663669586182
INFO:root:current mean train loss 2055.6915574921654
INFO:root:current train perplexity5.055354595184326
INFO:root:current mean train loss 2055.7555495626752
INFO:root:current train perplexity5.055789470672607
INFO:root:current mean train loss 2056.6014092023984
INFO:root:current train perplexity5.061158180236816
INFO:root:current mean train loss 2055.4068428260143
INFO:root:current train perplexity5.055781364440918
INFO:root:current mean train loss 2055.4422937221993
INFO:root:current train perplexity5.061429023742676
INFO:root:current mean train loss 2054.515804604699
INFO:root:current train perplexity5.061520576477051
INFO:root:current mean train loss 2055.016137920154
INFO:root:current train perplexity5.062811374664307
INFO:root:current mean train loss 2056.021435825296
INFO:root:current train perplexity5.0609283447265625
INFO:root:current mean train loss 2055.868747693415
INFO:root:current train perplexity5.059598445892334
INFO:root:current mean train loss 2057.162541685146
INFO:root:current train perplexity5.065340518951416
INFO:root:current mean train loss 2057.8003526778343
INFO:root:current train perplexity5.067080497741699
INFO:root:current mean train loss 2058.08251817717
INFO:root:current train perplexity5.067051410675049
INFO:root:current mean train loss 2059.055484388856
INFO:root:current train perplexity5.0690789222717285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.20s/it]
INFO:root:final mean train loss: 2058.0597361200576
INFO:root:final train perplexity: 5.068828105926514
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it]
INFO:root:eval mean loss: 2052.9323617921655
INFO:root:eval perplexity: 5.2608418464660645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 2469.1123194051975
INFO:root:eval perplexity: 7.533109188079834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/13
  6%|â–‹         | 13/200 [2:18:23<33:06:01, 637.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2000.3863098144532
INFO:root:current train perplexity4.912159442901611
INFO:root:current mean train loss 2024.2852661132813
INFO:root:current train perplexity4.923859596252441
INFO:root:current mean train loss 2025.7938837224788
INFO:root:current train perplexity4.961117267608643
INFO:root:current mean train loss 2028.07092628479
INFO:root:current train perplexity4.953212738037109
INFO:root:current mean train loss 2029.3750886462983
INFO:root:current train perplexity4.955815315246582
INFO:root:current mean train loss 2034.662910578801
INFO:root:current train perplexity4.964730262756348
INFO:root:current mean train loss 2031.5265875047253
INFO:root:current train perplexity4.956876754760742
INFO:root:current mean train loss 2030.0892791748047
INFO:root:current train perplexity4.957549095153809
INFO:root:current mean train loss 2029.7198069502667
INFO:root:current train perplexity4.964561462402344
INFO:root:current mean train loss 2029.386234581989
INFO:root:current train perplexity4.967553615570068
INFO:root:current mean train loss 2031.2258474312578
INFO:root:current train perplexity4.971096515655518
INFO:root:current mean train loss 2032.0042388916015
INFO:root:current train perplexity4.974586486816406
INFO:root:current mean train loss 2032.62032940974
INFO:root:current train perplexity4.972620964050293
INFO:root:current mean train loss 2034.8467944520892
INFO:root:current train perplexity4.97461462020874
INFO:root:current mean train loss 2035.1670666331977
INFO:root:current train perplexity4.979656219482422
INFO:root:current mean train loss 2034.2378189086915
INFO:root:current train perplexity4.9809746742248535
INFO:root:current mean train loss 2034.95159271617
INFO:root:current train perplexity4.982686996459961
INFO:root:current mean train loss 2036.9068697197492
INFO:root:current train perplexity4.984304904937744
INFO:root:current mean train loss 2036.3165984772063
INFO:root:current train perplexity4.984395503997803
INFO:root:current mean train loss 2036.986681175232
INFO:root:current train perplexity4.987707614898682

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.92s/it]
INFO:root:final mean train loss: 2037.7431780054783
INFO:root:final train perplexity: 4.988258361816406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it]
INFO:root:eval mean loss: 2041.2870305920324
INFO:root:eval perplexity: 5.2115278244018555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it]
INFO:root:eval mean loss: 2461.6016313268783
INFO:root:eval perplexity: 7.4869794845581055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/14
  7%|â–‹         | 14/200 [2:28:59<32:54:37, 636.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2043.3982989336994
INFO:root:current train perplexity4.821986198425293
INFO:root:current mean train loss 2030.5794766836793
INFO:root:current train perplexity4.895514488220215
INFO:root:current mean train loss 2020.0408271113529
INFO:root:current train perplexity4.8900017738342285
INFO:root:current mean train loss 2018.3767129688658
INFO:root:current train perplexity4.883870601654053
INFO:root:current mean train loss 2019.2338618577483
INFO:root:current train perplexity4.889338493347168
INFO:root:current mean train loss 2021.5699080994675
INFO:root:current train perplexity4.899580001831055
INFO:root:current mean train loss 2018.3255414019575
INFO:root:current train perplexity4.8965067863464355
INFO:root:current mean train loss 2017.2397184333129
INFO:root:current train perplexity4.897404670715332
INFO:root:current mean train loss 2017.7005269587253
INFO:root:current train perplexity4.896633148193359
INFO:root:current mean train loss 2015.1790695923241
INFO:root:current train perplexity4.893148422241211
INFO:root:current mean train loss 2014.9059080383242
INFO:root:current train perplexity4.896907806396484
INFO:root:current mean train loss 2015.457923211439
INFO:root:current train perplexity4.90000581741333
INFO:root:current mean train loss 2015.7091706876515
INFO:root:current train perplexity4.900887966156006
INFO:root:current mean train loss 2017.1018808688705
INFO:root:current train perplexity4.905209064483643
INFO:root:current mean train loss 2015.9373487075668
INFO:root:current train perplexity4.90139627456665
INFO:root:current mean train loss 2017.7837246837132
INFO:root:current train perplexity4.905881404876709
INFO:root:current mean train loss 2018.1170566304836
INFO:root:current train perplexity4.907406806945801
INFO:root:current mean train loss 2018.689067166361
INFO:root:current train perplexity4.910305500030518
INFO:root:current mean train loss 2018.7756519099585
INFO:root:current train perplexity4.911794185638428
INFO:root:current mean train loss 2019.265040990921
INFO:root:current train perplexity4.91496467590332

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.85s/it]
INFO:root:final mean train loss: 2019.6915564525025
INFO:root:final train perplexity: 4.917745590209961
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it]
INFO:root:eval mean loss: 2033.1580542165336
INFO:root:eval perplexity: 5.177379608154297
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.66s/it]
INFO:root:eval mean loss: 2454.1591831504875
INFO:root:eval perplexity: 7.441547870635986
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/15
  8%|â–Š         | 15/200 [2:39:31<32:39:28, 635.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1973.9157149703415
INFO:root:current train perplexity4.800504207611084
INFO:root:current mean train loss 1991.2420765269887
INFO:root:current train perplexity4.844903469085693
INFO:root:current mean train loss 1998.9091912217027
INFO:root:current train perplexity4.851870059967041
INFO:root:current mean train loss 1995.7381309035134
INFO:root:current train perplexity4.842015743255615
INFO:root:current mean train loss 1997.3007532867566
INFO:root:current train perplexity4.8346943855285645
INFO:root:current mean train loss 2001.8395932194128
INFO:root:current train perplexity4.849050521850586
INFO:root:current mean train loss 2005.087004775301
INFO:root:current train perplexity4.854103088378906
INFO:root:current mean train loss 2002.3051153936817
INFO:root:current train perplexity4.8437418937683105
INFO:root:current mean train loss 2002.605027924656
INFO:root:current train perplexity4.847778797149658
INFO:root:current mean train loss 2002.358262164038
INFO:root:current train perplexity4.849416255950928
INFO:root:current mean train loss 2005.3862932411498
INFO:root:current train perplexity4.852516174316406
INFO:root:current mean train loss 2002.8384257668638
INFO:root:current train perplexity4.8488006591796875
INFO:root:current mean train loss 2003.88111120586
INFO:root:current train perplexity4.852097988128662
INFO:root:current mean train loss 2005.215299485177
INFO:root:current train perplexity4.850908279418945
INFO:root:current mean train loss 2005.4385225697429
INFO:root:current train perplexity4.851883411407471
INFO:root:current mean train loss 2004.5316069417631
INFO:root:current train perplexity4.851882457733154
INFO:root:current mean train loss 2003.383158784103
INFO:root:current train perplexity4.850123882293701
INFO:root:current mean train loss 2003.3856955585893
INFO:root:current train perplexity4.851446151733398
INFO:root:current mean train loss 2003.8312070449451
INFO:root:current train perplexity4.852419853210449
INFO:root:current mean train loss 2002.8064899425058
INFO:root:current train perplexity4.850860595703125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.78s/it]
INFO:root:final mean train loss: 2002.479810475221
INFO:root:final train perplexity: 4.851443290710449
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.36s/it]
INFO:root:eval mean loss: 2028.5488255277594
INFO:root:eval perplexity: 5.158114433288574
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it]
INFO:root:eval mean loss: 2452.476567694481
INFO:root:eval perplexity: 7.431315898895264
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/16
  8%|â–Š         | 16/200 [2:50:15<32:36:43, 638.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2011.8045946577904
INFO:root:current train perplexity4.803556442260742
INFO:root:current mean train loss 1991.3237797251918
INFO:root:current train perplexity4.784648895263672
INFO:root:current mean train loss 1988.7470031963503
INFO:root:current train perplexity4.790149211883545
INFO:root:current mean train loss 1989.0682297369863
INFO:root:current train perplexity4.788522720336914
INFO:root:current mean train loss 1987.1872118000265
INFO:root:current train perplexity4.793224334716797
INFO:root:current mean train loss 1986.390744077345
INFO:root:current train perplexity4.7897515296936035
INFO:root:current mean train loss 1985.8157582403828
INFO:root:current train perplexity4.7816948890686035
INFO:root:current mean train loss 1986.1630870457907
INFO:root:current train perplexity4.784241676330566
INFO:root:current mean train loss 1985.8840486195825
INFO:root:current train perplexity4.784869194030762
INFO:root:current mean train loss 1985.3134036471743
INFO:root:current train perplexity4.785777568817139
INFO:root:current mean train loss 1984.7315649892769
INFO:root:current train perplexity4.786941051483154
INFO:root:current mean train loss 1983.9774059422703
INFO:root:current train perplexity4.783475875854492
INFO:root:current mean train loss 1983.6331972471849
INFO:root:current train perplexity4.7798380851745605
INFO:root:current mean train loss 1984.9831095110492
INFO:root:current train perplexity4.783369064331055
INFO:root:current mean train loss 1985.9070950319458
INFO:root:current train perplexity4.786519527435303
INFO:root:current mean train loss 1985.5963654594009
INFO:root:current train perplexity4.788341045379639
INFO:root:current mean train loss 1985.4011425518263
INFO:root:current train perplexity4.78821325302124
INFO:root:current mean train loss 1984.6270412141357
INFO:root:current train perplexity4.7848358154296875
INFO:root:current mean train loss 1984.8329294552336
INFO:root:current train perplexity4.785764217376709
INFO:root:current mean train loss 1985.9686314598791
INFO:root:current train perplexity4.786392688751221

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.49s/it]
INFO:root:final mean train loss: 1985.726991623625
INFO:root:final train perplexity: 4.7877655029296875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.65s/it]
INFO:root:eval mean loss: 2020.327825884447
INFO:root:eval perplexity: 5.1239333152771
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it]
INFO:root:eval mean loss: 2447.6605666140294
INFO:root:eval perplexity: 7.402102470397949
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/17
  8%|â–Š         | 17/200 [3:00:47<32:20:16, 636.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1976.3193498091264
INFO:root:current train perplexity4.723999977111816
INFO:root:current mean train loss 1954.9354254539976
INFO:root:current train perplexity4.691540718078613
INFO:root:current mean train loss 1959.529884338379
INFO:root:current train perplexity4.706788063049316
INFO:root:current mean train loss 1968.7532726169861
INFO:root:current train perplexity4.718111038208008
INFO:root:current mean train loss 1964.3676009881692
INFO:root:current train perplexity4.7065277099609375
INFO:root:current mean train loss 1969.4860875136187
INFO:root:current train perplexity4.7203450202941895
INFO:root:current mean train loss 1966.3233667418015
INFO:root:current train perplexity4.71673059463501
INFO:root:current mean train loss 1966.1010844429131
INFO:root:current train perplexity4.719159126281738
INFO:root:current mean train loss 1967.4547073776657
INFO:root:current train perplexity4.724091529846191
INFO:root:current mean train loss 1967.0812012212962
INFO:root:current train perplexity4.723021030426025
INFO:root:current mean train loss 1967.4383893854479
INFO:root:current train perplexity4.724002838134766
INFO:root:current mean train loss 1968.2331214159829
INFO:root:current train perplexity4.725651741027832
INFO:root:current mean train loss 1969.5829240313228
INFO:root:current train perplexity4.729642868041992
INFO:root:current mean train loss 1969.3620472668915
INFO:root:current train perplexity4.731125831604004
INFO:root:current mean train loss 1969.1830340969948
INFO:root:current train perplexity4.731176376342773
INFO:root:current mean train loss 1968.66754211887
INFO:root:current train perplexity4.729645729064941
INFO:root:current mean train loss 1968.8000478156935
INFO:root:current train perplexity4.730562686920166
INFO:root:current mean train loss 1969.701821482955
INFO:root:current train perplexity4.729756832122803
INFO:root:current mean train loss 1971.7381338345801
INFO:root:current train perplexity4.732501029968262

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.26s/it]
INFO:root:final mean train loss: 1970.9189634106704
INFO:root:final train perplexity: 4.732176780700684
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.56s/it]
INFO:root:eval mean loss: 2015.658860226895
INFO:root:eval perplexity: 5.104621887207031
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.22s/it]
INFO:root:eval mean loss: 2446.6120852206614
INFO:root:eval perplexity: 7.395758628845215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/18
  9%|â–‰         | 18/200 [3:11:22<32:08:57, 635.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1865.5741455078125
INFO:root:current train perplexity4.415377616882324
INFO:root:current mean train loss 1925.0177432105654
INFO:root:current train perplexity4.6377434730529785
INFO:root:current mean train loss 1936.1354331411967
INFO:root:current train perplexity4.634361743927002
INFO:root:current mean train loss 1946.3424100281761
INFO:root:current train perplexity4.648569583892822
INFO:root:current mean train loss 1942.6058060257524
INFO:root:current train perplexity4.648931980133057
INFO:root:current mean train loss 1944.3597300916615
INFO:root:current train perplexity4.64501953125
INFO:root:current mean train loss 1943.175077681108
INFO:root:current train perplexity4.642143249511719
INFO:root:current mean train loss 1945.228474588597
INFO:root:current train perplexity4.646084308624268
INFO:root:current mean train loss 1947.910986328125
INFO:root:current train perplexity4.655489921569824
INFO:root:current mean train loss 1952.2399526016488
INFO:root:current train perplexity4.663788795471191
INFO:root:current mean train loss 1952.4294150584965
INFO:root:current train perplexity4.664501667022705
INFO:root:current mean train loss 1953.2156544957227
INFO:root:current train perplexity4.666624069213867
INFO:root:current mean train loss 1953.041273948068
INFO:root:current train perplexity4.667471885681152
INFO:root:current mean train loss 1952.8549235961445
INFO:root:current train perplexity4.667140960693359
INFO:root:current mean train loss 1953.8916465677826
INFO:root:current train perplexity4.667372226715088
INFO:root:current mean train loss 1955.2265183762458
INFO:root:current train perplexity4.669752597808838
INFO:root:current mean train loss 1956.0419419903621
INFO:root:current train perplexity4.671728610992432
INFO:root:current mean train loss 1956.6299912080738
INFO:root:current train perplexity4.67429256439209
INFO:root:current mean train loss 1956.7539462187283
INFO:root:current train perplexity4.676581382751465
INFO:root:current mean train loss 1957.5436507417774
INFO:root:current train perplexity4.679676532745361

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.29s/it]
INFO:root:final mean train loss: 1956.7262587092828
INFO:root:final train perplexity: 4.679503440856934
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.74s/it]
INFO:root:eval mean loss: 2011.8828804611314
INFO:root:eval perplexity: 5.0890583992004395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it]
INFO:root:eval mean loss: 2442.5827796881927
INFO:root:eval perplexity: 7.371427536010742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/19
 10%|â–‰         | 19/200 [3:22:01<32:01:17, 636.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1910.59882701527
INFO:root:current train perplexity4.6209211349487305
INFO:root:current mean train loss 1926.8625868500255
INFO:root:current train perplexity4.610385417938232
INFO:root:current mean train loss 1945.0778198242188
INFO:root:current train perplexity4.643953323364258
INFO:root:current mean train loss 1936.6449281680657
INFO:root:current train perplexity4.623079776763916
INFO:root:current mean train loss 1933.281526249167
INFO:root:current train perplexity4.611125469207764
INFO:root:current mean train loss 1939.0841663112128
INFO:root:current train perplexity4.623126983642578
INFO:root:current mean train loss 1938.1406895677376
INFO:root:current train perplexity4.618758678436279
INFO:root:current mean train loss 1941.0694781274346
INFO:root:current train perplexity4.629228591918945
INFO:root:current mean train loss 1939.532599753127
INFO:root:current train perplexity4.629480838775635
INFO:root:current mean train loss 1940.8392058597988
INFO:root:current train perplexity4.628726482391357
INFO:root:current mean train loss 1942.0925474521466
INFO:root:current train perplexity4.62865686416626
INFO:root:current mean train loss 1943.8273544991505
INFO:root:current train perplexity4.630374908447266
INFO:root:current mean train loss 1943.7234601958878
INFO:root:current train perplexity4.627606391906738
INFO:root:current mean train loss 1943.1114529654405
INFO:root:current train perplexity4.625969409942627
INFO:root:current mean train loss 1942.2260612562907
INFO:root:current train perplexity4.622819900512695
INFO:root:current mean train loss 1942.0528879654391
INFO:root:current train perplexity4.622684955596924
INFO:root:current mean train loss 1943.19179044787
INFO:root:current train perplexity4.625311374664307
INFO:root:current mean train loss 1942.8440716219557
INFO:root:current train perplexity4.625295162200928
INFO:root:current mean train loss 1943.3706689828314
INFO:root:current train perplexity4.626600742340088
INFO:root:current mean train loss 1943.4580849797371
INFO:root:current train perplexity4.628663063049316

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.29s/it]
INFO:root:final mean train loss: 1942.9469376726097
INFO:root:final train perplexity: 4.628925800323486
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it]
INFO:root:eval mean loss: 2007.5526222607768
INFO:root:eval perplexity: 5.0712666511535645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 2441.612964819509
INFO:root:eval perplexity: 7.36558198928833
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/20
 10%|â–ˆ         | 20/200 [3:32:42<31:54:34, 638.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1889.5975529597356
INFO:root:current train perplexity4.489716053009033
INFO:root:current mean train loss 1914.9308370686263
INFO:root:current train perplexity4.535478591918945
INFO:root:current mean train loss 1925.7943299105975
INFO:root:current train perplexity4.545413494110107
INFO:root:current mean train loss 1924.9487574754562
INFO:root:current train perplexity4.538778781890869
INFO:root:current mean train loss 1927.219685965084
INFO:root:current train perplexity4.561112403869629
INFO:root:current mean train loss 1922.3969266817166
INFO:root:current train perplexity4.5554962158203125
INFO:root:current mean train loss 1925.7153551462857
INFO:root:current train perplexity4.560981273651123
INFO:root:current mean train loss 1925.258451263056
INFO:root:current train perplexity4.555598258972168
INFO:root:current mean train loss 1927.20996239245
INFO:root:current train perplexity4.56215238571167
INFO:root:current mean train loss 1928.5624516398761
INFO:root:current train perplexity4.565992832183838
INFO:root:current mean train loss 1929.6232719825252
INFO:root:current train perplexity4.568729877471924
INFO:root:current mean train loss 1929.743226544495
INFO:root:current train perplexity4.5724077224731445
INFO:root:current mean train loss 1928.3161276262358
INFO:root:current train perplexity4.571652412414551
INFO:root:current mean train loss 1929.5493229701503
INFO:root:current train perplexity4.570993423461914
INFO:root:current mean train loss 1930.7502261566735
INFO:root:current train perplexity4.572437286376953
INFO:root:current mean train loss 1930.3299617655794
INFO:root:current train perplexity4.574790954589844
INFO:root:current mean train loss 1931.0705021968188
INFO:root:current train perplexity4.575425148010254
INFO:root:current mean train loss 1932.1337589485472
INFO:root:current train perplexity4.578680038452148
INFO:root:current mean train loss 1930.7970462568821
INFO:root:current train perplexity4.576500415802002
INFO:root:current mean train loss 1929.4041692646217
INFO:root:current train perplexity4.577990531921387

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.29s/it]
INFO:root:final mean train loss: 1929.3965205097825
INFO:root:final train perplexity: 4.579721450805664
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.81s/it]
INFO:root:eval mean loss: 2003.4949942514406
INFO:root:eval perplexity: 5.054651737213135
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it]
INFO:root:eval mean loss: 2439.7363874286625
INFO:root:eval perplexity: 7.354287624359131
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/21
 10%|â–ˆ         | 21/200 [3:43:22<31:44:42, 638.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1917.3826599121094
INFO:root:current train perplexity4.528965473175049
INFO:root:current mean train loss 1921.971188276242
INFO:root:current train perplexity4.5143866539001465
INFO:root:current mean train loss 1916.9527382850647
INFO:root:current train perplexity4.516186237335205
INFO:root:current mean train loss 1916.1675853943557
INFO:root:current train perplexity4.516224384307861
INFO:root:current mean train loss 1911.2848944413035
INFO:root:current train perplexity4.52229118347168
INFO:root:current mean train loss 1910.4608999567924
INFO:root:current train perplexity4.517148971557617
INFO:root:current mean train loss 1911.468833737257
INFO:root:current train perplexity4.519040584564209
INFO:root:current mean train loss 1915.2031719873821
INFO:root:current train perplexity4.522706985473633
INFO:root:current mean train loss 1911.0120552989924
INFO:root:current train perplexity4.513592720031738
INFO:root:current mean train loss 1913.374945476963
INFO:root:current train perplexity4.51861572265625
INFO:root:current mean train loss 1913.117339625503
INFO:root:current train perplexity4.519683837890625
INFO:root:current mean train loss 1913.3506348289834
INFO:root:current train perplexity4.5224714279174805
INFO:root:current mean train loss 1914.2013359312798
INFO:root:current train perplexity4.5238776206970215
INFO:root:current mean train loss 1914.1700416047313
INFO:root:current train perplexity4.52209997177124
INFO:root:current mean train loss 1914.4600488851358
INFO:root:current train perplexity4.521790504455566
INFO:root:current mean train loss 1915.9140433578686
INFO:root:current train perplexity4.525673866271973
INFO:root:current mean train loss 1917.7551646946708
INFO:root:current train perplexity4.529227256774902
INFO:root:current mean train loss 1917.1531991458971
INFO:root:current train perplexity4.530137062072754
INFO:root:current mean train loss 1917.8010326911663
INFO:root:current train perplexity4.533112525939941
INFO:root:current mean train loss 1918.0565577469965
INFO:root:current train perplexity4.536383628845215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.75s/it]
INFO:root:final mean train loss: 1917.2586280564979
INFO:root:final train perplexity: 4.53609037399292
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it]
INFO:root:eval mean loss: 2000.6485318664118
INFO:root:eval perplexity: 5.04302978515625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it]
INFO:root:eval mean loss: 2437.930212575493
INFO:root:eval perplexity: 7.34343147277832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/22
 11%|â–ˆ         | 22/200 [3:53:52<31:27:15, 636.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1909.7834104773117
INFO:root:current train perplexity4.467836856842041
INFO:root:current mean train loss 1905.6938215487264
INFO:root:current train perplexity4.463455677032471
INFO:root:current mean train loss 1911.0624575213199
INFO:root:current train perplexity4.464820384979248
INFO:root:current mean train loss 1907.0209686033847
INFO:root:current train perplexity4.461250305175781
INFO:root:current mean train loss 1904.051142299402
INFO:root:current train perplexity4.4586381912231445
INFO:root:current mean train loss 1901.5740276556364
INFO:root:current train perplexity4.45993709564209
INFO:root:current mean train loss 1899.6591546567377
INFO:root:current train perplexity4.455056190490723
INFO:root:current mean train loss 1901.5008786535818
INFO:root:current train perplexity4.462532997131348
INFO:root:current mean train loss 1899.6324225182113
INFO:root:current train perplexity4.465951442718506
INFO:root:current mean train loss 1901.3558777420028
INFO:root:current train perplexity4.473618507385254
INFO:root:current mean train loss 1903.4035186056544
INFO:root:current train perplexity4.477344512939453
INFO:root:current mean train loss 1903.2021612377118
INFO:root:current train perplexity4.477871894836426
INFO:root:current mean train loss 1904.180835613002
INFO:root:current train perplexity4.48113489151001
INFO:root:current mean train loss 1904.3649454248794
INFO:root:current train perplexity4.479914665222168
INFO:root:current mean train loss 1904.3992706112367
INFO:root:current train perplexity4.480770111083984
INFO:root:current mean train loss 1905.1996731185186
INFO:root:current train perplexity4.4819560050964355
INFO:root:current mean train loss 1905.6086525013543
INFO:root:current train perplexity4.484952449798584
INFO:root:current mean train loss 1906.2162391933693
INFO:root:current train perplexity4.4909138679504395
INFO:root:current mean train loss 1906.7252965663374
INFO:root:current train perplexity4.495680809020996
INFO:root:current mean train loss 1906.504516539692
INFO:root:current train perplexity4.495693206787109

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.74s/it]
INFO:root:final mean train loss: 1905.8036529494848
INFO:root:final train perplexity: 4.495295524597168
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 1999.3525455556016
INFO:root:eval perplexity: 5.037746906280518
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 2437.394553326546
INFO:root:eval perplexity: 7.34021520614624
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/23
 12%|â–ˆâ–        | 23/200 [4:04:24<31:12:33, 634.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1869.2294460720486
INFO:root:current train perplexity4.376112461090088
INFO:root:current mean train loss 1880.606187679893
INFO:root:current train perplexity4.409504413604736
INFO:root:current mean train loss 1880.0133999528557
INFO:root:current train perplexity4.414620399475098
INFO:root:current mean train loss 1884.8917471078726
INFO:root:current train perplexity4.420523643493652
INFO:root:current mean train loss 1885.0693857621172
INFO:root:current train perplexity4.4226484298706055
INFO:root:current mean train loss 1888.0630693855933
INFO:root:current train perplexity4.4243621826171875
INFO:root:current mean train loss 1888.3191761846128
INFO:root:current train perplexity4.4285383224487305
INFO:root:current mean train loss 1888.6132282498518
INFO:root:current train perplexity4.435394287109375
INFO:root:current mean train loss 1889.7385211387377
INFO:root:current train perplexity4.438190937042236
INFO:root:current mean train loss 1887.6915704900568
INFO:root:current train perplexity4.434972763061523
INFO:root:current mean train loss 1887.8257106955991
INFO:root:current train perplexity4.430781841278076
INFO:root:current mean train loss 1888.6539818515296
INFO:root:current train perplexity4.435549259185791
INFO:root:current mean train loss 1889.2547434252363
INFO:root:current train perplexity4.440062999725342
INFO:root:current mean train loss 1889.812571924882
INFO:root:current train perplexity4.442840099334717
INFO:root:current mean train loss 1890.982918922373
INFO:root:current train perplexity4.446688175201416
INFO:root:current mean train loss 1890.7467837927477
INFO:root:current train perplexity4.4473347663879395
INFO:root:current mean train loss 1890.786674689118
INFO:root:current train perplexity4.448373794555664
INFO:root:current mean train loss 1892.369165857411
INFO:root:current train perplexity4.448962211608887
INFO:root:current mean train loss 1893.0372686476935
INFO:root:current train perplexity4.450479984283447

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.61s/it]
INFO:root:final mean train loss: 1893.9291486793013
INFO:root:final train perplexity: 4.453393459320068
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 1994.0988366958943
INFO:root:eval perplexity: 5.016387939453125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 36.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 36.00s/it]
INFO:root:eval mean loss: 2436.6547721700467
INFO:root:eval perplexity: 7.335777282714844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/24
 12%|â–ˆâ–        | 24/200 [4:14:53<30:56:55, 633.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1873.2922188895088
INFO:root:current train perplexity4.364664554595947
INFO:root:current mean train loss 1869.031953900774
INFO:root:current train perplexity4.359328746795654
INFO:root:current mean train loss 1872.1245070010568
INFO:root:current train perplexity4.360685348510742
INFO:root:current mean train loss 1869.9789168267762
INFO:root:current train perplexity4.365960121154785
INFO:root:current mean train loss 1864.3540500950169
INFO:root:current train perplexity4.355153560638428
INFO:root:current mean train loss 1865.927568966115
INFO:root:current train perplexity4.363411903381348
INFO:root:current mean train loss 1871.027581857496
INFO:root:current train perplexity4.375357151031494
INFO:root:current mean train loss 1872.062116177787
INFO:root:current train perplexity4.381762504577637
INFO:root:current mean train loss 1874.497771422659
INFO:root:current train perplexity4.388408184051514
INFO:root:current mean train loss 1875.9104950052113
INFO:root:current train perplexity4.393381118774414
INFO:root:current mean train loss 1877.4716727778596
INFO:root:current train perplexity4.398423671722412
INFO:root:current mean train loss 1877.768441328619
INFO:root:current train perplexity4.398067951202393
INFO:root:current mean train loss 1878.5153786343983
INFO:root:current train perplexity4.398940563201904
INFO:root:current mean train loss 1877.653233546379
INFO:root:current train perplexity4.398139953613281
INFO:root:current mean train loss 1878.915494288463
INFO:root:current train perplexity4.403085231781006
INFO:root:current mean train loss 1880.5652377122906
INFO:root:current train perplexity4.406561851501465
INFO:root:current mean train loss 1881.5533486765664
INFO:root:current train perplexity4.410341262817383
INFO:root:current mean train loss 1881.5773579665074
INFO:root:current train perplexity4.411043167114258
INFO:root:current mean train loss 1882.0328733932927
INFO:root:current train perplexity4.412907123565674
INFO:root:current mean train loss 1882.457800414591
INFO:root:current train perplexity4.413074493408203

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.66s/it]
INFO:root:final mean train loss: 1883.030339181874
INFO:root:final train perplexity: 4.415278434753418
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 1994.0926639205175
INFO:root:eval perplexity: 5.01636266708374
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.79s/it]
INFO:root:eval mean loss: 2437.30918245789
INFO:root:eval perplexity: 7.339702129364014
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/25
 12%|â–ˆâ–Ž        | 25/200 [4:25:35<30:54:07, 635.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1852.059341430664
INFO:root:current train perplexity4.336950302124023
INFO:root:current mean train loss 1876.7841344033518
INFO:root:current train perplexity4.367569923400879
INFO:root:current mean train loss 1869.9271806989398
INFO:root:current train perplexity4.343059062957764
INFO:root:current mean train loss 1868.5865580240886
INFO:root:current train perplexity4.34475040435791
INFO:root:current mean train loss 1874.3005031369767
INFO:root:current train perplexity4.368237495422363
INFO:root:current mean train loss 1869.8518413514582
INFO:root:current train perplexity4.36093807220459
INFO:root:current mean train loss 1870.0129959888948
INFO:root:current train perplexity4.361027240753174
INFO:root:current mean train loss 1865.9238171656486
INFO:root:current train perplexity4.362551689147949
INFO:root:current mean train loss 1867.7863699903767
INFO:root:current train perplexity4.364558219909668
INFO:root:current mean train loss 1867.8700665890913
INFO:root:current train perplexity4.366950511932373
INFO:root:current mean train loss 1870.705382823944
INFO:root:current train perplexity4.370903968811035
INFO:root:current mean train loss 1870.3815466178269
INFO:root:current train perplexity4.367232322692871
INFO:root:current mean train loss 1872.4114883522582
INFO:root:current train perplexity4.371912002563477
INFO:root:current mean train loss 1873.3722194890602
INFO:root:current train perplexity4.3729681968688965
INFO:root:current mean train loss 1873.1166954469145
INFO:root:current train perplexity4.376441955566406
INFO:root:current mean train loss 1872.7684659382178
INFO:root:current train perplexity4.3740553855896
INFO:root:current mean train loss 1873.620317280586
INFO:root:current train perplexity4.376282691955566
INFO:root:current mean train loss 1874.2059700029909
INFO:root:current train perplexity4.3776702880859375
INFO:root:current mean train loss 1872.9500033729955
INFO:root:current train perplexity4.377111434936523
INFO:root:current mean train loss 1872.9434731973183
INFO:root:current train perplexity4.377107620239258

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.78s/it]
INFO:root:final mean train loss: 1872.1948909480584
INFO:root:final train perplexity: 4.37770938873291
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 1990.5919942652924
INFO:root:eval perplexity: 5.0021796226501465
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.30s/it]
INFO:root:eval mean loss: 2435.7717133650544
INFO:root:eval perplexity: 7.330479145050049
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/26
 13%|â–ˆâ–Ž        | 26/200 [4:36:06<30:39:46, 634.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1827.6908643769054
INFO:root:current train perplexity4.300647258758545
INFO:root:current mean train loss 1841.206078928413
INFO:root:current train perplexity4.287321090698242
INFO:root:current mean train loss 1845.4781235817557
INFO:root:current train perplexity4.298284530639648
INFO:root:current mean train loss 1845.1245510962701
INFO:root:current train perplexity4.307467460632324
INFO:root:current mean train loss 1848.7385372931724
INFO:root:current train perplexity4.314878940582275
INFO:root:current mean train loss 1850.88053693789
INFO:root:current train perplexity4.313712120056152
INFO:root:current mean train loss 1855.7541223963412
INFO:root:current train perplexity4.3301801681518555
INFO:root:current mean train loss 1856.7491293635605
INFO:root:current train perplexity4.327945709228516
INFO:root:current mean train loss 1858.6031781535653
INFO:root:current train perplexity4.32982873916626
INFO:root:current mean train loss 1859.399443899027
INFO:root:current train perplexity4.331049919128418
INFO:root:current mean train loss 1859.3386099134696
INFO:root:current train perplexity4.332608699798584
INFO:root:current mean train loss 1859.2717900322154
INFO:root:current train perplexity4.334286689758301
INFO:root:current mean train loss 1857.7691585470072
INFO:root:current train perplexity4.330626010894775
INFO:root:current mean train loss 1859.8814189322043
INFO:root:current train perplexity4.335073947906494
INFO:root:current mean train loss 1859.4943258059182
INFO:root:current train perplexity4.33477258682251
INFO:root:current mean train loss 1860.7685261701006
INFO:root:current train perplexity4.337527275085449
INFO:root:current mean train loss 1860.9768181707277
INFO:root:current train perplexity4.336653232574463
INFO:root:current mean train loss 1861.8729612645166
INFO:root:current train perplexity4.339058876037598
INFO:root:current mean train loss 1861.7934004054778
INFO:root:current train perplexity4.339553356170654
INFO:root:current mean train loss 1862.6119499226197
INFO:root:current train perplexity4.342320919036865

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:30<00:00, 570.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:30<00:00, 570.57s/it]
INFO:root:final mean train loss: 1862.0474791341637
INFO:root:final train perplexity: 4.342813968658447
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it]
INFO:root:eval mean loss: 1990.5202623732546
INFO:root:eval perplexity: 5.001891136169434
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.91s/it]
INFO:root:eval mean loss: 2439.9096415634694
INFO:root:eval perplexity: 7.355329990386963
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/27
 14%|â–ˆâ–Ž        | 27/200 [4:46:55<30:41:35, 638.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1841.9322972790949
INFO:root:current train perplexity4.235498428344727
INFO:root:current mean train loss 1839.64472903481
INFO:root:current train perplexity4.26304817199707
INFO:root:current mean train loss 1841.0804225714633
INFO:root:current train perplexity4.280393600463867
INFO:root:current mean train loss 1837.4849686436146
INFO:root:current train perplexity4.274414539337158
INFO:root:current mean train loss 1839.5606337634756
INFO:root:current train perplexity4.27891206741333
INFO:root:current mean train loss 1841.3555383169523
INFO:root:current train perplexity4.281557559967041
INFO:root:current mean train loss 1841.4562876970936
INFO:root:current train perplexity4.281795024871826
INFO:root:current mean train loss 1843.990317634039
INFO:root:current train perplexity4.283233642578125
INFO:root:current mean train loss 1844.5518898419289
INFO:root:current train perplexity4.287139892578125
INFO:root:current mean train loss 1847.2694725084405
INFO:root:current train perplexity4.289393424987793
INFO:root:current mean train loss 1846.3725257109154
INFO:root:current train perplexity4.287744522094727
INFO:root:current mean train loss 1845.4790518699738
INFO:root:current train perplexity4.285935878753662
INFO:root:current mean train loss 1845.8625347580175
INFO:root:current train perplexity4.289246082305908
INFO:root:current mean train loss 1846.4387180963215
INFO:root:current train perplexity4.293043613433838
INFO:root:current mean train loss 1847.6567714361497
INFO:root:current train perplexity4.298402786254883
INFO:root:current mean train loss 1849.127592936407
INFO:root:current train perplexity4.300539016723633
INFO:root:current mean train loss 1849.7450457712134
INFO:root:current train perplexity4.303859233856201
INFO:root:current mean train loss 1851.134434896389
INFO:root:current train perplexity4.307750701904297
INFO:root:current mean train loss 1851.7475335621089
INFO:root:current train perplexity4.309922695159912
INFO:root:current mean train loss 1853.4007401899858
INFO:root:current train perplexity4.310853004455566

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.28s/it]
INFO:root:final mean train loss: 1852.5691148504968
INFO:root:final train perplexity: 4.31047248840332
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it]
INFO:root:eval mean loss: 1991.656998871066
INFO:root:eval perplexity: 5.006490707397461
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.10s/it]
INFO:root:eval mean loss: 2442.394377147052
INFO:root:eval perplexity: 7.370292663574219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/28
 14%|â–ˆâ–        | 28/200 [4:57:31<30:28:50, 637.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1831.908916015625
INFO:root:current train perplexity4.245580673217773
INFO:root:current mean train loss 1831.3739871651785
INFO:root:current train perplexity4.2296977043151855
INFO:root:current mean train loss 1831.1739009232954
INFO:root:current train perplexity4.229220867156982
INFO:root:current mean train loss 1834.124699544271
INFO:root:current train perplexity4.236386775970459
INFO:root:current mean train loss 1837.2157326788652
INFO:root:current train perplexity4.250357627868652
INFO:root:current mean train loss 1838.2160047978941
INFO:root:current train perplexity4.250808238983154
INFO:root:current mean train loss 1836.1347025101272
INFO:root:current train perplexity4.251461029052734
INFO:root:current mean train loss 1839.2289601184475
INFO:root:current train perplexity4.2596917152404785
INFO:root:current mean train loss 1841.3636964285715
INFO:root:current train perplexity4.262012004852295
INFO:root:current mean train loss 1842.5901029146635
INFO:root:current train perplexity4.26913595199585
INFO:root:current mean train loss 1843.219152548147
INFO:root:current train perplexity4.266146183013916
INFO:root:current mean train loss 1840.3708223902925
INFO:root:current train perplexity4.263172626495361
INFO:root:current mean train loss 1840.3594294768689
INFO:root:current train perplexity4.265324592590332
INFO:root:current mean train loss 1840.3211858132101
INFO:root:current train perplexity4.2670440673828125
INFO:root:current mean train loss 1841.6529894398834
INFO:root:current train perplexity4.270691871643066
INFO:root:current mean train loss 1842.0008113994295
INFO:root:current train perplexity4.270469665527344
INFO:root:current mean train loss 1842.7286632754199
INFO:root:current train perplexity4.271739959716797
INFO:root:current mean train loss 1842.7616272832306
INFO:root:current train perplexity4.27277135848999
INFO:root:current mean train loss 1842.4532282552084
INFO:root:current train perplexity4.272948265075684
INFO:root:current mean train loss 1842.9002845628956
INFO:root:current train perplexity4.275723934173584

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.15s/it]
INFO:root:final mean train loss: 1842.2860610046232
INFO:root:final train perplexity: 4.275655746459961
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.10s/it]
INFO:root:eval mean loss: 1989.4162831407912
INFO:root:eval perplexity: 4.997426509857178
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.49s/it]
INFO:root:eval mean loss: 2441.66259635763
INFO:root:eval perplexity: 7.365882396697998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/29
 14%|â–ˆâ–        | 29/200 [5:08:02<30:12:17, 635.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1825.439161217731
INFO:root:current train perplexity4.199883937835693
INFO:root:current mean train loss 1827.7132263183594
INFO:root:current train perplexity4.211047649383545
INFO:root:current mean train loss 1823.8826716174817
INFO:root:current train perplexity4.212005615234375
INFO:root:current mean train loss 1823.7543742899993
INFO:root:current train perplexity4.219942569732666
INFO:root:current mean train loss 1825.014716915968
INFO:root:current train perplexity4.223345756530762
INFO:root:current mean train loss 1827.6837684012748
INFO:root:current train perplexity4.219904899597168
INFO:root:current mean train loss 1825.328747170509
INFO:root:current train perplexity4.219226837158203
INFO:root:current mean train loss 1826.747584795711
INFO:root:current train perplexity4.223196506500244
INFO:root:current mean train loss 1828.2316274600178
INFO:root:current train perplexity4.2259626388549805
INFO:root:current mean train loss 1830.268125103366
INFO:root:current train perplexity4.234804630279541
INFO:root:current mean train loss 1830.8492640680445
INFO:root:current train perplexity4.234261512756348
INFO:root:current mean train loss 1831.9277929523648
INFO:root:current train perplexity4.235875606536865
INFO:root:current mean train loss 1832.3269073202882
INFO:root:current train perplexity4.238357067108154
INFO:root:current mean train loss 1832.6992245378165
INFO:root:current train perplexity4.239084720611572
INFO:root:current mean train loss 1831.880941437013
INFO:root:current train perplexity4.238958835601807
INFO:root:current mean train loss 1832.059097520071
INFO:root:current train perplexity4.242464065551758
INFO:root:current mean train loss 1832.7938435872395
INFO:root:current train perplexity4.243647575378418
INFO:root:current mean train loss 1833.543404511043
INFO:root:current train perplexity4.243536949157715
INFO:root:current mean train loss 1833.4662842054952
INFO:root:current train perplexity4.243447303771973

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:29<00:00, 569.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:29<00:00, 569.10s/it]
INFO:root:final mean train loss: 1833.0190076034476
INFO:root:final train perplexity: 4.2445220947265625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.76s/it]
INFO:root:eval mean loss: 1987.8767916632037
INFO:root:eval perplexity: 4.991208553314209
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.90s/it]
INFO:root:eval mean loss: 2438.6043237997287
INFO:root:eval perplexity: 7.347482204437256
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/30
 15%|â–ˆâ–Œ        | 30/200 [5:18:49<30:11:07, 639.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1846.0812174479167
INFO:root:current train perplexity4.176999568939209
INFO:root:current mean train loss 1804.6478719448824
INFO:root:current train perplexity4.1518049240112305
INFO:root:current mean train loss 1800.24351391952
INFO:root:current train perplexity4.142815113067627
INFO:root:current mean train loss 1809.646587482934
INFO:root:current train perplexity4.163219928741455
INFO:root:current mean train loss 1810.8161442017497
INFO:root:current train perplexity4.164768695831299
INFO:root:current mean train loss 1812.2073962618185
INFO:root:current train perplexity4.165497303009033
INFO:root:current mean train loss 1812.7369182317323
INFO:root:current train perplexity4.176028728485107
INFO:root:current mean train loss 1814.2878507498458
INFO:root:current train perplexity4.176232814788818
INFO:root:current mean train loss 1814.2628412234915
INFO:root:current train perplexity4.181669235229492
INFO:root:current mean train loss 1817.6710374284498
INFO:root:current train perplexity4.189305782318115
INFO:root:current mean train loss 1818.4097458808226
INFO:root:current train perplexity4.192195892333984
INFO:root:current mean train loss 1817.9921030744547
INFO:root:current train perplexity4.198160648345947
INFO:root:current mean train loss 1818.7325386949765
INFO:root:current train perplexity4.200490951538086
INFO:root:current mean train loss 1819.444563105782
INFO:root:current train perplexity4.204704761505127
INFO:root:current mean train loss 1820.372995673045
INFO:root:current train perplexity4.205953121185303
INFO:root:current mean train loss 1820.3751062958188
INFO:root:current train perplexity4.206184387207031
INFO:root:current mean train loss 1821.634495461928
INFO:root:current train perplexity4.208908557891846
INFO:root:current mean train loss 1822.0789550638394
INFO:root:current train perplexity4.206950664520264
INFO:root:current mean train loss 1822.6217779240733
INFO:root:current train perplexity4.20828104019165
INFO:root:current mean train loss 1823.4149811926034
INFO:root:current train perplexity4.210086822509766

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.51s/it]
INFO:root:final mean train loss: 1823.3146932643288
INFO:root:final train perplexity: 4.212160110473633
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.03s/it]
INFO:root:eval mean loss: 1987.185681931516
INFO:root:eval perplexity: 4.988420009613037
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it]
INFO:root:eval mean loss: 2439.962429614777
INFO:root:eval perplexity: 7.35564661026001
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/31
 16%|â–ˆâ–Œ        | 31/200 [5:29:19<29:52:11, 636.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1803.6354135366587
INFO:root:current train perplexity4.1418070793151855
INFO:root:current mean train loss 1820.8722321041046
INFO:root:current train perplexity4.16122579574585
INFO:root:current mean train loss 1812.9825790540308
INFO:root:current train perplexity4.152522563934326
INFO:root:current mean train loss 1808.9290134921396
INFO:root:current train perplexity4.1559858322143555
INFO:root:current mean train loss 1812.9233255162485
INFO:root:current train perplexity4.156880855560303
INFO:root:current mean train loss 1812.5774540774269
INFO:root:current train perplexity4.157332897186279
INFO:root:current mean train loss 1809.7569905728958
INFO:root:current train perplexity4.156949043273926
INFO:root:current mean train loss 1808.5122520930183
INFO:root:current train perplexity4.156935214996338
INFO:root:current mean train loss 1810.5496571981878
INFO:root:current train perplexity4.158374786376953
INFO:root:current mean train loss 1810.6466978003089
INFO:root:current train perplexity4.165431499481201
INFO:root:current mean train loss 1810.8000545390169
INFO:root:current train perplexity4.166618824005127
INFO:root:current mean train loss 1810.5596042450113
INFO:root:current train perplexity4.170664310455322
INFO:root:current mean train loss 1811.0145347308958
INFO:root:current train perplexity4.172989368438721
INFO:root:current mean train loss 1811.6783567862992
INFO:root:current train perplexity4.173999309539795
INFO:root:current mean train loss 1811.242268994346
INFO:root:current train perplexity4.174264430999756
INFO:root:current mean train loss 1812.1545760528445
INFO:root:current train perplexity4.1776204109191895
INFO:root:current mean train loss 1813.3354196395967
INFO:root:current train perplexity4.1794281005859375
INFO:root:current mean train loss 1813.39893108558
INFO:root:current train perplexity4.17730188369751
INFO:root:current mean train loss 1814.2499106867813
INFO:root:current train perplexity4.181607246398926
INFO:root:current mean train loss 1813.935448382131
INFO:root:current train perplexity4.181297779083252

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.76s/it]
INFO:root:final mean train loss: 1814.3404735540178
INFO:root:final train perplexity: 4.182453632354736
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.66s/it]
INFO:root:eval mean loss: 1987.031843469498
INFO:root:eval perplexity: 4.987798690795898
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.82s/it]
INFO:root:eval mean loss: 2444.283074994459
INFO:root:eval perplexity: 7.381684303283691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/32
 16%|â–ˆâ–Œ        | 32/200 [5:39:58<29:44:19, 637.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1788.6299112009447
INFO:root:current train perplexity4.094882488250732
INFO:root:current mean train loss 1802.7904581990276
INFO:root:current train perplexity4.13161563873291
INFO:root:current mean train loss 1806.9464709121014
INFO:root:current train perplexity4.118656635284424
INFO:root:current mean train loss 1799.338887829127
INFO:root:current train perplexity4.11092472076416
INFO:root:current mean train loss 1797.2733958913834
INFO:root:current train perplexity4.124028205871582
INFO:root:current mean train loss 1798.415489126525
INFO:root:current train perplexity4.130324840545654
INFO:root:current mean train loss 1800.425038006962
INFO:root:current train perplexity4.1385111808776855
INFO:root:current mean train loss 1801.2793259550072
INFO:root:current train perplexity4.1436991691589355
INFO:root:current mean train loss 1802.882843632998
INFO:root:current train perplexity4.148879528045654
INFO:root:current mean train loss 1803.112298215055
INFO:root:current train perplexity4.145451068878174
INFO:root:current mean train loss 1802.512264379719
INFO:root:current train perplexity4.145946502685547
INFO:root:current mean train loss 1801.4383287538276
INFO:root:current train perplexity4.143802165985107
INFO:root:current mean train loss 1802.448345304015
INFO:root:current train perplexity4.144958019256592
INFO:root:current mean train loss 1803.5402684783367
INFO:root:current train perplexity4.146422863006592
INFO:root:current mean train loss 1804.6403801826166
INFO:root:current train perplexity4.1501970291137695
INFO:root:current mean train loss 1804.3197384609932
INFO:root:current train perplexity4.150601387023926
INFO:root:current mean train loss 1805.1045693080018
INFO:root:current train perplexity4.151888847351074
INFO:root:current mean train loss 1804.989823481986
INFO:root:current train perplexity4.150249004364014
INFO:root:current mean train loss 1806.43611139224
INFO:root:current train perplexity4.153602600097656
INFO:root:current mean train loss 1806.003658842439
INFO:root:current train perplexity4.152152061462402

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.99s/it]
INFO:root:final mean train loss: 1805.5801350665224
INFO:root:final train perplexity: 4.153656959533691
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it]
INFO:root:eval mean loss: 1987.0498142107158
INFO:root:eval perplexity: 4.987870216369629
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.04s/it]
INFO:root:eval mean loss: 2443.5694597393062
INFO:root:eval perplexity: 7.377378463745117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/33
 16%|â–ˆâ–‹        | 33/200 [5:50:29<29:28:13, 635.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1780.1926411946615
INFO:root:current train perplexity4.085457801818848
INFO:root:current mean train loss 1788.955584716797
INFO:root:current train perplexity4.122045040130615
INFO:root:current mean train loss 1791.8397573617788
INFO:root:current train perplexity4.120323657989502
INFO:root:current mean train loss 1788.3915269639756
INFO:root:current train perplexity4.114467144012451
INFO:root:current mean train loss 1789.2675985585088
INFO:root:current train perplexity4.117769241333008
INFO:root:current mean train loss 1785.899478149414
INFO:root:current train perplexity4.1055779457092285
INFO:root:current mean train loss 1784.7381308815695
INFO:root:current train perplexity4.106066703796387
INFO:root:current mean train loss 1788.2114365427117
INFO:root:current train perplexity4.10569953918457
INFO:root:current mean train loss 1787.2341126907704
INFO:root:current train perplexity4.103107452392578
INFO:root:current mean train loss 1788.88912785848
INFO:root:current train perplexity4.106419563293457
INFO:root:current mean train loss 1790.1826097020562
INFO:root:current train perplexity4.107313632965088
INFO:root:current mean train loss 1791.104470088564
INFO:root:current train perplexity4.107856273651123
INFO:root:current mean train loss 1791.658973233662
INFO:root:current train perplexity4.110139846801758
INFO:root:current mean train loss 1793.4226499669692
INFO:root:current train perplexity4.112873077392578
INFO:root:current mean train loss 1795.1641711091343
INFO:root:current train perplexity4.114993572235107
INFO:root:current mean train loss 1796.2938075138973
INFO:root:current train perplexity4.117037773132324
INFO:root:current mean train loss 1797.1979747358575
INFO:root:current train perplexity4.1204514503479
INFO:root:current mean train loss 1797.3232090343129
INFO:root:current train perplexity4.121590614318848
INFO:root:current mean train loss 1797.072410206128
INFO:root:current train perplexity4.123199939727783
INFO:root:current mean train loss 1796.9142300975566
INFO:root:current train perplexity4.124053001403809

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.58s/it]
INFO:root:final mean train loss: 1796.5839356823035
INFO:root:final train perplexity: 4.12429141998291
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.72s/it]
INFO:root:eval mean loss: 1986.4894387536015
INFO:root:eval perplexity: 4.985611915588379
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it]
INFO:root:eval mean loss: 2446.2904147966533
INFO:root:eval perplexity: 7.3938140869140625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/34
 17%|â–ˆâ–‹        | 34/200 [6:01:07<29:19:47, 636.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1783.2701733081371
INFO:root:current train perplexity4.055655479431152
INFO:root:current mean train loss 1779.6819937323446
INFO:root:current train perplexity4.078516006469727
INFO:root:current mean train loss 1780.2252849482456
INFO:root:current train perplexity4.078577041625977
INFO:root:current mean train loss 1780.640839999171
INFO:root:current train perplexity4.079518795013428
INFO:root:current mean train loss 1781.5579718823703
INFO:root:current train perplexity4.077611446380615
INFO:root:current mean train loss 1781.6805536280058
INFO:root:current train perplexity4.082559108734131
INFO:root:current mean train loss 1780.9379446460719
INFO:root:current train perplexity4.08146858215332
INFO:root:current mean train loss 1781.8596813540662
INFO:root:current train perplexity4.0795392990112305
INFO:root:current mean train loss 1784.32271632474
INFO:root:current train perplexity4.0849456787109375
INFO:root:current mean train loss 1785.7159766174755
INFO:root:current train perplexity4.087210178375244
INFO:root:current mean train loss 1784.7138073424444
INFO:root:current train perplexity4.085938930511475
INFO:root:current mean train loss 1784.8558916920003
INFO:root:current train perplexity4.091475009918213
INFO:root:current mean train loss 1785.3439602056517
INFO:root:current train perplexity4.09197473526001
INFO:root:current mean train loss 1785.3162835591413
INFO:root:current train perplexity4.0919928550720215
INFO:root:current mean train loss 1786.1439518912387
INFO:root:current train perplexity4.0921735763549805
INFO:root:current mean train loss 1787.25244976617
INFO:root:current train perplexity4.093103885650635
INFO:root:current mean train loss 1787.2909207056873
INFO:root:current train perplexity4.092780113220215
INFO:root:current mean train loss 1787.6795252433437
INFO:root:current train perplexity4.093899250030518
INFO:root:current mean train loss 1788.7193995675445
INFO:root:current train perplexity4.095830917358398
INFO:root:current mean train loss 1788.6984619387606
INFO:root:current train perplexity4.097187042236328

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.12s/it]
INFO:root:final mean train loss: 1788.1551047674766
INFO:root:final train perplexity: 4.096965789794922
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 1988.8977994445368
INFO:root:eval perplexity: 4.995331764221191
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 2451.946630599651
INFO:root:eval perplexity: 7.428095817565918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/35
 18%|â–ˆâ–Š        | 35/200 [6:11:39<29:05:40, 634.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1787.509626672623
INFO:root:current train perplexity4.039077281951904
INFO:root:current mean train loss 1779.4975208400451
INFO:root:current train perplexity4.038079261779785
INFO:root:current mean train loss 1777.8630765538637
INFO:root:current train perplexity4.050662994384766
INFO:root:current mean train loss 1774.053657647922
INFO:root:current train perplexity4.04818058013916
INFO:root:current mean train loss 1775.260324825642
INFO:root:current train perplexity4.0548224449157715
INFO:root:current mean train loss 1775.02995798644
INFO:root:current train perplexity4.055447578430176
INFO:root:current mean train loss 1778.8527464413162
INFO:root:current train perplexity4.065990924835205
INFO:root:current mean train loss 1781.8582789807836
INFO:root:current train perplexity4.06747579574585
INFO:root:current mean train loss 1780.8367552618586
INFO:root:current train perplexity4.061143398284912
INFO:root:current mean train loss 1778.797552035848
INFO:root:current train perplexity4.0559515953063965
INFO:root:current mean train loss 1777.825165966529
INFO:root:current train perplexity4.05849027633667
INFO:root:current mean train loss 1777.4699748948192
INFO:root:current train perplexity4.059902191162109
INFO:root:current mean train loss 1778.3781188304495
INFO:root:current train perplexity4.062893867492676
INFO:root:current mean train loss 1779.0943339059138
INFO:root:current train perplexity4.06368350982666
INFO:root:current mean train loss 1780.1381447012006
INFO:root:current train perplexity4.065740585327148
INFO:root:current mean train loss 1780.8260625171542
INFO:root:current train perplexity4.066895961761475
INFO:root:current mean train loss 1781.6417321359393
INFO:root:current train perplexity4.067543029785156
INFO:root:current mean train loss 1781.9174312731893
INFO:root:current train perplexity4.068650245666504
INFO:root:current mean train loss 1781.363374897394
INFO:root:current train perplexity4.071139335632324

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.08s/it]
INFO:root:final mean train loss: 1780.20446266409
INFO:root:final train perplexity: 4.071356296539307
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.36s/it]
INFO:root:eval mean loss: 1990.2098025058178
INFO:root:eval perplexity: 5.00063419342041
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it]
INFO:root:eval mean loss: 2450.6623383650544
INFO:root:eval perplexity: 7.420296669006348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/36
 18%|â–ˆâ–Š        | 36/200 [6:22:24<29:03:45, 637.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1803.4918989701705
INFO:root:current train perplexity4.0509161949157715
INFO:root:current mean train loss 1756.1848034557995
INFO:root:current train perplexity3.994565963745117
INFO:root:current mean train loss 1761.318563018365
INFO:root:current train perplexity4.01346492767334
INFO:root:current mean train loss 1763.5178701517284
INFO:root:current train perplexity4.01628303527832
INFO:root:current mean train loss 1767.75577977684
INFO:root:current train perplexity4.019513130187988
INFO:root:current mean train loss 1768.2673349399156
INFO:root:current train perplexity4.022550106048584
INFO:root:current mean train loss 1768.369690840451
INFO:root:current train perplexity4.0223798751831055
INFO:root:current mean train loss 1766.7013825364254
INFO:root:current train perplexity4.023083209991455
INFO:root:current mean train loss 1766.9710834846544
INFO:root:current train perplexity4.0239691734313965
INFO:root:current mean train loss 1769.460087563675
INFO:root:current train perplexity4.027586460113525
INFO:root:current mean train loss 1770.2712658317105
INFO:root:current train perplexity4.031563758850098
INFO:root:current mean train loss 1769.3351271772685
INFO:root:current train perplexity4.032904148101807
INFO:root:current mean train loss 1769.7105624185526
INFO:root:current train perplexity4.034180641174316
INFO:root:current mean train loss 1770.0530370833035
INFO:root:current train perplexity4.035120964050293
INFO:root:current mean train loss 1770.3266708839033
INFO:root:current train perplexity4.037710189819336
INFO:root:current mean train loss 1770.8728382002037
INFO:root:current train perplexity4.039515018463135
INFO:root:current mean train loss 1770.1774056717004
INFO:root:current train perplexity4.038417816162109
INFO:root:current mean train loss 1770.8588163731463
INFO:root:current train perplexity4.039290904998779
INFO:root:current mean train loss 1771.9284891753089
INFO:root:current train perplexity4.041514873504639
INFO:root:current mean train loss 1771.8093692893324
INFO:root:current train perplexity4.04225492477417

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.54s/it]
INFO:root:final mean train loss: 1771.3650590566692
INFO:root:final train perplexity: 4.043072700500488
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 1991.6126120276485
INFO:root:eval perplexity: 5.006310939788818
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.80s/it]
INFO:root:eval mean loss: 2454.0165366314827
INFO:root:eval perplexity: 7.440680503845215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/37
 18%|â–ˆâ–Š        | 37/200 [6:33:11<29:00:31, 640.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1724.9165518624443
INFO:root:current train perplexity3.99942684173584
INFO:root:current mean train loss 1768.7196626663208
INFO:root:current train perplexity4.00678014755249
INFO:root:current mean train loss 1763.583222506339
INFO:root:current train perplexity4.012120723724365
INFO:root:current mean train loss 1756.904657131288
INFO:root:current train perplexity4.006913661956787
INFO:root:current mean train loss 1754.7116493866822
INFO:root:current train perplexity4.003965854644775
INFO:root:current mean train loss 1756.0389515269887
INFO:root:current train perplexity3.9979629516601562
INFO:root:current mean train loss 1758.0559750696657
INFO:root:current train perplexity4.001744270324707
INFO:root:current mean train loss 1757.7625861534705
INFO:root:current train perplexity4.002682685852051
INFO:root:current mean train loss 1759.5936450313254
INFO:root:current train perplexity4.004362106323242
INFO:root:current mean train loss 1761.7978553771973
INFO:root:current train perplexity4.005736827850342
INFO:root:current mean train loss 1763.4686149864344
INFO:root:current train perplexity4.006831645965576
INFO:root:current mean train loss 1764.0945570925448
INFO:root:current train perplexity4.012375831604004
INFO:root:current mean train loss 1763.3532068706102
INFO:root:current train perplexity4.01509428024292
INFO:root:current mean train loss 1763.2227309812981
INFO:root:current train perplexity4.012262344360352
INFO:root:current mean train loss 1764.1213877274542
INFO:root:current train perplexity4.014201641082764
INFO:root:current mean train loss 1764.4225011695742
INFO:root:current train perplexity4.013896942138672
INFO:root:current mean train loss 1763.815392421563
INFO:root:current train perplexity4.013619899749756
INFO:root:current mean train loss 1764.7988654242622
INFO:root:current train perplexity4.014506816864014
INFO:root:current mean train loss 1764.0950024227084
INFO:root:current train perplexity4.016472816467285
INFO:root:current mean train loss 1764.09937675761
INFO:root:current train perplexity4.017960548400879

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.18s/it]
INFO:root:final mean train loss: 1763.903001286078
INFO:root:final train perplexity: 4.019349098205566
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.52s/it]
INFO:root:eval mean loss: 1991.3154050137134
INFO:root:eval perplexity: 5.005107879638672
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 2455.8912924908577
INFO:root:eval perplexity: 7.4520978927612305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/38
 19%|â–ˆâ–‰        | 38/200 [6:43:42<28:42:17, 637.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1748.4644911024307
INFO:root:current train perplexity3.9719364643096924
INFO:root:current mean train loss 1750.7897006330818
INFO:root:current train perplexity3.9791946411132812
INFO:root:current mean train loss 1753.4241853675064
INFO:root:current train perplexity3.9788591861724854
INFO:root:current mean train loss 1758.0648313660552
INFO:root:current train perplexity3.985422134399414
INFO:root:current mean train loss 1754.962103340063
INFO:root:current train perplexity3.9883108139038086
INFO:root:current mean train loss 1751.9496797054185
INFO:root:current train perplexity3.9851784706115723
INFO:root:current mean train loss 1752.4775322492733
INFO:root:current train perplexity3.980736494064331
INFO:root:current mean train loss 1752.2663675807466
INFO:root:current train perplexity3.9827537536621094
INFO:root:current mean train loss 1752.5418335683246
INFO:root:current train perplexity3.9828929901123047
INFO:root:current mean train loss 1750.6415228949652
INFO:root:current train perplexity3.978097677230835
INFO:root:current mean train loss 1750.3710469077078
INFO:root:current train perplexity3.9789042472839355
INFO:root:current mean train loss 1750.9259507624863
INFO:root:current train perplexity3.980461835861206
INFO:root:current mean train loss 1750.443380357367
INFO:root:current train perplexity3.9818334579467773
INFO:root:current mean train loss 1752.1038641380112
INFO:root:current train perplexity3.984057903289795
INFO:root:current mean train loss 1752.8786740207343
INFO:root:current train perplexity3.9855806827545166
INFO:root:current mean train loss 1753.7081429984578
INFO:root:current train perplexity3.9879276752471924
INFO:root:current mean train loss 1754.9059896822757
INFO:root:current train perplexity3.989335060119629
INFO:root:current mean train loss 1755.7488875861836
INFO:root:current train perplexity3.9911577701568604
INFO:root:current mean train loss 1756.336642464325
INFO:root:current train perplexity3.992974281311035
INFO:root:current mean train loss 1756.5391639219151
INFO:root:current train perplexity3.9937591552734375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.66s/it]
INFO:root:final mean train loss: 1756.382071829299
INFO:root:final train perplexity: 3.995579242706299
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.51s/it]
INFO:root:eval mean loss: 1991.7463855067044
INFO:root:eval perplexity: 5.006852626800537
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.38s/it]
INFO:root:eval mean loss: 2459.107110206117
INFO:root:eval perplexity: 7.4717206954956055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/39
 20%|â–ˆâ–‰        | 39/200 [6:54:21<28:32:27, 638.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1735.4295811806955
INFO:root:current train perplexity3.919142484664917
INFO:root:current mean train loss 1742.8438148027585
INFO:root:current train perplexity3.9225594997406006
INFO:root:current mean train loss 1735.2728765356633
INFO:root:current train perplexity3.920234441757202
INFO:root:current mean train loss 1735.2150116809823
INFO:root:current train perplexity3.9224460124969482
INFO:root:current mean train loss 1736.9469416894954
INFO:root:current train perplexity3.923586130142212
INFO:root:current mean train loss 1736.7348098483374
INFO:root:current train perplexity3.9309794902801514
INFO:root:current mean train loss 1739.9211517979372
INFO:root:current train perplexity3.9405038356781006
INFO:root:current mean train loss 1743.4552682791482
INFO:root:current train perplexity3.945274591445923
INFO:root:current mean train loss 1744.2759770439839
INFO:root:current train perplexity3.945652723312378
INFO:root:current mean train loss 1746.1785952117984
INFO:root:current train perplexity3.9491145610809326
INFO:root:current mean train loss 1749.01915860221
INFO:root:current train perplexity3.958029270172119
INFO:root:current mean train loss 1748.1480512241487
INFO:root:current train perplexity3.9562625885009766
INFO:root:current mean train loss 1747.2054696785856
INFO:root:current train perplexity3.9548866748809814
INFO:root:current mean train loss 1748.0944407458871
INFO:root:current train perplexity3.9568235874176025
INFO:root:current mean train loss 1749.0033175237527
INFO:root:current train perplexity3.9609053134918213
INFO:root:current mean train loss 1749.8068510829717
INFO:root:current train perplexity3.9636173248291016
INFO:root:current mean train loss 1748.8901278315611
INFO:root:current train perplexity3.9632375240325928
INFO:root:current mean train loss 1749.0948051253458
INFO:root:current train perplexity3.9646806716918945
INFO:root:current mean train loss 1748.7892810071705
INFO:root:current train perplexity3.966557025909424
INFO:root:current mean train loss 1748.24445843089
INFO:root:current train perplexity3.967337131500244

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.30s/it]
INFO:root:final mean train loss: 1747.5231535310884
INFO:root:final train perplexity: 3.9677610397338867
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 1992.4683067375886
INFO:root:eval perplexity: 5.0097761154174805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it]
INFO:root:eval mean loss: 2459.601319657995
INFO:root:eval perplexity: 7.474740982055664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/40
 20%|â–ˆâ–ˆ        | 40/200 [7:04:52<28:16:12, 636.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1730.0100962964793
INFO:root:current train perplexity3.9254214763641357
INFO:root:current mean train loss 1725.346165491882
INFO:root:current train perplexity3.921147108078003
INFO:root:current mean train loss 1727.0966188711077
INFO:root:current train perplexity3.9186015129089355
INFO:root:current mean train loss 1730.2784021221553
INFO:root:current train perplexity3.924353837966919
INFO:root:current mean train loss 1729.2578433361332
INFO:root:current train perplexity3.9231464862823486
INFO:root:current mean train loss 1729.4101859769673
INFO:root:current train perplexity3.9216651916503906
INFO:root:current mean train loss 1728.9392337939526
INFO:root:current train perplexity3.9204623699188232
INFO:root:current mean train loss 1731.8579502717828
INFO:root:current train perplexity3.9235477447509766
INFO:root:current mean train loss 1735.9961959613197
INFO:root:current train perplexity3.930239200592041
INFO:root:current mean train loss 1736.2177441356375
INFO:root:current train perplexity3.9333906173706055
INFO:root:current mean train loss 1736.9925737354465
INFO:root:current train perplexity3.9370028972625732
INFO:root:current mean train loss 1739.3096852387484
INFO:root:current train perplexity3.9381768703460693
INFO:root:current mean train loss 1738.4787626288849
INFO:root:current train perplexity3.9354474544525146
INFO:root:current mean train loss 1739.285799531335
INFO:root:current train perplexity3.9380311965942383
INFO:root:current mean train loss 1739.3804086474972
INFO:root:current train perplexity3.938204050064087
INFO:root:current mean train loss 1740.1499716122744
INFO:root:current train perplexity3.9405934810638428
INFO:root:current mean train loss 1739.5084146359904
INFO:root:current train perplexity3.94043231010437
INFO:root:current mean train loss 1740.2317752248455
INFO:root:current train perplexity3.942089796066284
INFO:root:current mean train loss 1740.453910433783
INFO:root:current train perplexity3.9441332817077637
INFO:root:current mean train loss 1740.5474161434317
INFO:root:current train perplexity3.9447059631347656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.56s/it]
INFO:root:final mean train loss: 1740.1572595578039
INFO:root:final train perplexity: 3.9447779655456543
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.60s/it]
INFO:root:eval mean loss: 1994.1455446067432
INFO:root:eval perplexity: 5.016577243804932
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.11s/it]
INFO:root:eval mean loss: 2461.8952515514184
INFO:root:eval perplexity: 7.488779067993164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/41
 20%|â–ˆâ–ˆ        | 41/200 [7:15:38<28:13:05, 638.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1721.3034083048503
INFO:root:current train perplexity3.8750016689300537
INFO:root:current mean train loss 1731.089540442642
INFO:root:current train perplexity3.90519380569458
INFO:root:current mean train loss 1739.096139856287
INFO:root:current train perplexity3.9101014137268066
INFO:root:current mean train loss 1736.4442560985835
INFO:root:current train perplexity3.9042699337005615
INFO:root:current mean train loss 1731.38784322431
INFO:root:current train perplexity3.9064924716949463
INFO:root:current mean train loss 1733.3701352113046
INFO:root:current train perplexity3.906726360321045
INFO:root:current mean train loss 1734.6107949443247
INFO:root:current train perplexity3.908860206604004
INFO:root:current mean train loss 1733.2517497767155
INFO:root:current train perplexity3.904358386993408
INFO:root:current mean train loss 1732.8000060490199
INFO:root:current train perplexity3.907425880432129
INFO:root:current mean train loss 1732.6507750974602
INFO:root:current train perplexity3.9094274044036865
INFO:root:current mean train loss 1733.1617314693701
INFO:root:current train perplexity3.9122443199157715
INFO:root:current mean train loss 1733.5771427218333
INFO:root:current train perplexity3.91345477104187
INFO:root:current mean train loss 1734.3270247659566
INFO:root:current train perplexity3.914738655090332
INFO:root:current mean train loss 1735.1281169902288
INFO:root:current train perplexity3.917513608932495
INFO:root:current mean train loss 1734.4111615349266
INFO:root:current train perplexity3.91884446144104
INFO:root:current mean train loss 1734.0719399511963
INFO:root:current train perplexity3.918203830718994
INFO:root:current mean train loss 1733.3014836581249
INFO:root:current train perplexity3.91866397857666
INFO:root:current mean train loss 1732.643179708706
INFO:root:current train perplexity3.9199812412261963
INFO:root:current mean train loss 1732.9453276300228
INFO:root:current train perplexity3.9200053215026855

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.14s/it]
INFO:root:final mean train loss: 1732.947969760789
INFO:root:final train perplexity: 3.922412872314453
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.23s/it]
INFO:root:eval mean loss: 1994.7038119701629
INFO:root:eval perplexity: 5.018842697143555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it]
INFO:root:eval mean loss: 2465.8783829060008
INFO:root:eval perplexity: 7.513212203979492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/42
 21%|â–ˆâ–ˆ        | 42/200 [7:26:14<28:00:06, 638.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1704.447049654447
INFO:root:current train perplexity3.884692668914795
INFO:root:current mean train loss 1720.0310739162749
INFO:root:current train perplexity3.84309458732605
INFO:root:current mean train loss 1708.8428467943074
INFO:root:current train perplexity3.8581674098968506
INFO:root:current mean train loss 1709.261014798198
INFO:root:current train perplexity3.8583500385284424
INFO:root:current mean train loss 1712.8904260815489
INFO:root:current train perplexity3.860863447189331
INFO:root:current mean train loss 1713.662566246345
INFO:root:current train perplexity3.867177724838257
INFO:root:current mean train loss 1716.7250811279696
INFO:root:current train perplexity3.8747055530548096
INFO:root:current mean train loss 1718.2211165889616
INFO:root:current train perplexity3.8778748512268066
INFO:root:current mean train loss 1717.0647595770392
INFO:root:current train perplexity3.874833822250366
INFO:root:current mean train loss 1716.6114120901218
INFO:root:current train perplexity3.875938892364502
INFO:root:current mean train loss 1717.3702051552475
INFO:root:current train perplexity3.8762965202331543
INFO:root:current mean train loss 1719.0120676319982
INFO:root:current train perplexity3.879368782043457
INFO:root:current mean train loss 1720.5026138947212
INFO:root:current train perplexity3.8801205158233643
INFO:root:current mean train loss 1719.751711773491
INFO:root:current train perplexity3.879906177520752
INFO:root:current mean train loss 1720.19434379907
INFO:root:current train perplexity3.8826324939727783
INFO:root:current mean train loss 1720.156282998518
INFO:root:current train perplexity3.8819446563720703
INFO:root:current mean train loss 1722.0035127946035
INFO:root:current train perplexity3.8874711990356445
INFO:root:current mean train loss 1723.559154931384
INFO:root:current train perplexity3.8913798332214355
INFO:root:current mean train loss 1724.681496402932
INFO:root:current train perplexity3.8950819969177246
INFO:root:current mean train loss 1726.3581492558114
INFO:root:current train perplexity3.899384021759033

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.17s/it]
INFO:root:final mean train loss: 1725.4771314843158
INFO:root:final train perplexity: 3.8993701934814453
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.50s/it]
INFO:root:eval mean loss: 1998.3342397703348
INFO:root:eval perplexity: 5.033599853515625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it]
INFO:root:eval mean loss: 2468.897205109292
INFO:root:eval perplexity: 7.531783580780029
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/43
 22%|â–ˆâ–ˆâ–       | 43/200 [7:36:51<27:49:05, 637.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1712.248429361979
INFO:root:current train perplexity3.8218390941619873
INFO:root:current mean train loss 1703.266938664363
INFO:root:current train perplexity3.8280608654022217
INFO:root:current mean train loss 1707.0956903872282
INFO:root:current train perplexity3.8304550647735596
INFO:root:current mean train loss 1710.6228197502367
INFO:root:current train perplexity3.8439743518829346
INFO:root:current mean train loss 1709.9558852084847
INFO:root:current train perplexity3.841024875640869
INFO:root:current mean train loss 1712.097096338812
INFO:root:current train perplexity3.8471293449401855
INFO:root:current mean train loss 1711.384353686136
INFO:root:current train perplexity3.8465423583984375
INFO:root:current mean train loss 1712.454107916845
INFO:root:current train perplexity3.854121208190918
INFO:root:current mean train loss 1713.9978899484656
INFO:root:current train perplexity3.859102964401245
INFO:root:current mean train loss 1713.008520376554
INFO:root:current train perplexity3.8581604957580566
INFO:root:current mean train loss 1711.5523456462379
INFO:root:current train perplexity3.8593766689300537
INFO:root:current mean train loss 1711.370902110412
INFO:root:current train perplexity3.8582613468170166
INFO:root:current mean train loss 1711.6870120164824
INFO:root:current train perplexity3.8580400943756104
INFO:root:current mean train loss 1712.2490733670113
INFO:root:current train perplexity3.8629369735717773
INFO:root:current mean train loss 1713.5030159903572
INFO:root:current train perplexity3.8647210597991943
INFO:root:current mean train loss 1715.5091181736366
INFO:root:current train perplexity3.866323232650757
INFO:root:current mean train loss 1715.9578527158023
INFO:root:current train perplexity3.868830919265747
INFO:root:current mean train loss 1717.7576462585803
INFO:root:current train perplexity3.8710010051727295
INFO:root:current mean train loss 1718.5640083354679
INFO:root:current train perplexity3.87290358543396
INFO:root:current mean train loss 1718.276747376437
INFO:root:current train perplexity3.8745853900909424

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.66s/it]
INFO:root:final mean train loss: 1717.8797916445055
INFO:root:final train perplexity: 3.8760762214660645
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 37.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.00s/it]
INFO:root:eval mean loss: 2000.3392013658024
INFO:root:eval perplexity: 5.0417680740356445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.40s/it]
INFO:root:eval mean loss: 2473.906158230829
INFO:root:eval perplexity: 7.562701225280762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/44
 22%|â–ˆâ–ˆâ–       | 44/200 [7:47:34<27:41:58, 639.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1679.2799773520612
INFO:root:current train perplexity3.788943290710449
INFO:root:current mean train loss 1700.2300601881377
INFO:root:current train perplexity3.8174190521240234
INFO:root:current mean train loss 1701.8925336459388
INFO:root:current train perplexity3.826828956604004
INFO:root:current mean train loss 1700.0812450046155
INFO:root:current train perplexity3.8277623653411865
INFO:root:current mean train loss 1701.4266687858292
INFO:root:current train perplexity3.830713987350464
INFO:root:current mean train loss 1699.0986165215809
INFO:root:current train perplexity3.8315958976745605
INFO:root:current mean train loss 1702.1770266690614
INFO:root:current train perplexity3.8333635330200195
INFO:root:current mean train loss 1703.2723965523553
INFO:root:current train perplexity3.837019205093384
INFO:root:current mean train loss 1704.477144603887
INFO:root:current train perplexity3.8398854732513428
INFO:root:current mean train loss 1704.7494698255593
INFO:root:current train perplexity3.8428802490234375
INFO:root:current mean train loss 1705.6171243079184
INFO:root:current train perplexity3.844562292098999
INFO:root:current mean train loss 1706.9805328182895
INFO:root:current train perplexity3.845942497253418
INFO:root:current mean train loss 1706.721356157121
INFO:root:current train perplexity3.844900131225586
INFO:root:current mean train loss 1707.7334877926062
INFO:root:current train perplexity3.846329927444458
INFO:root:current mean train loss 1708.6953469192727
INFO:root:current train perplexity3.846571207046509
INFO:root:current mean train loss 1710.1643614815216
INFO:root:current train perplexity3.8507273197174072
INFO:root:current mean train loss 1710.5626334101776
INFO:root:current train perplexity3.8524436950683594
INFO:root:current mean train loss 1711.2415319397985
INFO:root:current train perplexity3.852233409881592
INFO:root:current mean train loss 1711.1280062210255
INFO:root:current train perplexity3.8530688285827637
INFO:root:current mean train loss 1711.7899287164548
INFO:root:current train perplexity3.855403423309326

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.48s/it]
INFO:root:final mean train loss: 1711.1365855376166
INFO:root:final train perplexity: 3.8555173873901367
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.35s/it]
INFO:root:eval mean loss: 1999.243442833001
INFO:root:eval perplexity: 5.037302017211914
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.09s/it]
INFO:root:eval mean loss: 2474.5128186814327
INFO:root:eval perplexity: 7.566452503204346
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [7:58:11<27:29:45, 638.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1716.3166275024414
INFO:root:current train perplexity3.8378453254699707
INFO:root:current mean train loss 1701.7566096608232
INFO:root:current train perplexity3.7965481281280518
INFO:root:current mean train loss 1695.2058359781902
INFO:root:current train perplexity3.795428514480591
INFO:root:current mean train loss 1691.1643572796831
INFO:root:current train perplexity3.785820722579956
INFO:root:current mean train loss 1688.9677968518488
INFO:root:current train perplexity3.7904765605926514
INFO:root:current mean train loss 1692.8145957568013
INFO:root:current train perplexity3.7996952533721924
INFO:root:current mean train loss 1695.5479317171028
INFO:root:current train perplexity3.8008065223693848
INFO:root:current mean train loss 1694.9414239853465
INFO:root:current train perplexity3.807887315750122
INFO:root:current mean train loss 1698.3341889558014
INFO:root:current train perplexity3.812772512435913
INFO:root:current mean train loss 1699.9057961618257
INFO:root:current train perplexity3.814436435699463
INFO:root:current mean train loss 1700.1353895144355
INFO:root:current train perplexity3.8179757595062256
INFO:root:current mean train loss 1701.011860221522
INFO:root:current train perplexity3.819852352142334
INFO:root:current mean train loss 1700.321880485438
INFO:root:current train perplexity3.819725275039673
INFO:root:current mean train loss 1700.3433209640189
INFO:root:current train perplexity3.8229222297668457
INFO:root:current mean train loss 1700.367129049666
INFO:root:current train perplexity3.824827194213867
INFO:root:current mean train loss 1700.4057685091063
INFO:root:current train perplexity3.826282262802124
INFO:root:current mean train loss 1701.983498426584
INFO:root:current train perplexity3.8296756744384766
INFO:root:current mean train loss 1702.7643995912167
INFO:root:current train perplexity3.8301072120666504
INFO:root:current mean train loss 1703.7965357047806
INFO:root:current train perplexity3.832050323486328
INFO:root:current mean train loss 1704.4553039302166
INFO:root:current train perplexity3.83396315574646

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.15s/it]
INFO:root:final mean train loss: 1704.1844129384435
INFO:root:final train perplexity: 3.8344361782073975
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.94s/it]
INFO:root:eval mean loss: 2001.4135439176086
INFO:root:eval perplexity: 5.046151161193848
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.74s/it]
INFO:root:eval mean loss: 2478.5613463922596
INFO:root:eval perplexity: 7.59154748916626
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [8:09:00<27:27:14, 641.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1679.5024640118634
INFO:root:current train perplexity3.7657082080841064
INFO:root:current mean train loss 1684.3109764815695
INFO:root:current train perplexity3.775005340576172
INFO:root:current mean train loss 1678.877997456072
INFO:root:current train perplexity3.772099733352661
INFO:root:current mean train loss 1682.651298943467
INFO:root:current train perplexity3.773536443710327
INFO:root:current mean train loss 1682.0791505428956
INFO:root:current train perplexity3.7848668098449707
INFO:root:current mean train loss 1684.9816337756158
INFO:root:current train perplexity3.784804582595825
INFO:root:current mean train loss 1685.8873999059288
INFO:root:current train perplexity3.785074472427368
INFO:root:current mean train loss 1686.8806117957747
INFO:root:current train perplexity3.788630247116089
INFO:root:current mean train loss 1687.2635762694204
INFO:root:current train perplexity3.794327974319458
INFO:root:current mean train loss 1688.8913372634747
INFO:root:current train perplexity3.7970659732818604
INFO:root:current mean train loss 1690.0221335722495
INFO:root:current train perplexity3.8000102043151855
INFO:root:current mean train loss 1691.6377638413883
INFO:root:current train perplexity3.803082227706909
INFO:root:current mean train loss 1692.7708221840542
INFO:root:current train perplexity3.80395245552063
INFO:root:current mean train loss 1693.9994212046297
INFO:root:current train perplexity3.8045637607574463
INFO:root:current mean train loss 1694.7896599933797
INFO:root:current train perplexity3.8037469387054443
INFO:root:current mean train loss 1696.0404576995868
INFO:root:current train perplexity3.805664539337158
INFO:root:current mean train loss 1697.3399274781798
INFO:root:current train perplexity3.8082966804504395
INFO:root:current mean train loss 1697.5287831652906
INFO:root:current train perplexity3.8086295127868652
INFO:root:current mean train loss 1696.9978542621943
INFO:root:current train perplexity3.811002492904663
INFO:root:current mean train loss 1697.7047371784886
INFO:root:current train perplexity3.8136579990386963

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.54s/it]
INFO:root:final mean train loss: 1697.320889148337
INFO:root:final train perplexity: 3.8137366771698
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it]
INFO:root:eval mean loss: 2004.0909947604998
INFO:root:eval perplexity: 5.057089805603027
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.28s/it]
INFO:root:eval mean loss: 2483.2333547172816
INFO:root:eval perplexity: 7.620611667633057
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [8:19:34<27:10:30, 639.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1690.260205327248
INFO:root:current train perplexity3.768317222595215
INFO:root:current mean train loss 1679.0071565261994
INFO:root:current train perplexity3.7536604404449463
INFO:root:current mean train loss 1674.6648854505295
INFO:root:current train perplexity3.7448372840881348
INFO:root:current mean train loss 1675.8751180830911
INFO:root:current train perplexity3.75962233543396
INFO:root:current mean train loss 1676.3830468357805
INFO:root:current train perplexity3.7637524604797363
INFO:root:current mean train loss 1679.251896172463
INFO:root:current train perplexity3.7695581912994385
INFO:root:current mean train loss 1681.3493391763857
INFO:root:current train perplexity3.7729403972625732
INFO:root:current mean train loss 1682.2579884158638
INFO:root:current train perplexity3.774822235107422
INFO:root:current mean train loss 1685.3660669815301
INFO:root:current train perplexity3.7807204723358154
INFO:root:current mean train loss 1685.8233602214193
INFO:root:current train perplexity3.7773916721343994
INFO:root:current mean train loss 1686.7062849312315
INFO:root:current train perplexity3.7790467739105225
INFO:root:current mean train loss 1689.1893473579012
INFO:root:current train perplexity3.7823612689971924
INFO:root:current mean train loss 1689.5188195180085
INFO:root:current train perplexity3.7815277576446533
INFO:root:current mean train loss 1689.4570558736252
INFO:root:current train perplexity3.7840659618377686
INFO:root:current mean train loss 1689.9528909639937
INFO:root:current train perplexity3.7873623371124268
INFO:root:current mean train loss 1690.49211890229
INFO:root:current train perplexity3.789219617843628
INFO:root:current mean train loss 1690.4747566789283
INFO:root:current train perplexity3.791574716567993
INFO:root:current mean train loss 1691.3719789294962
INFO:root:current train perplexity3.791835069656372
INFO:root:current mean train loss 1691.0901958115862
INFO:root:current train perplexity3.7930920124053955

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.13s/it]
INFO:root:final mean train loss: 1690.7224407340323
INFO:root:final train perplexity: 3.7939417362213135
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.27s/it]
INFO:root:eval mean loss: 2003.2993267952127
INFO:root:eval perplexity: 5.0538530349731445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.66s/it]
INFO:root:eval mean loss: 2483.7677811426474
INFO:root:eval perplexity: 7.6239423751831055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/48
 24%|â–ˆâ–ˆâ–       | 48/200 [8:30:22<27:06:40, 642.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1658.4511067708333
INFO:root:current train perplexity3.7076821327209473
INFO:root:current mean train loss 1677.9286047894022
INFO:root:current train perplexity3.7386350631713867
INFO:root:current mean train loss 1668.301443836301
INFO:root:current train perplexity3.7358927726745605
INFO:root:current mean train loss 1674.798998248388
INFO:root:current train perplexity3.7472336292266846
INFO:root:current mean train loss 1674.8306287650603
INFO:root:current train perplexity3.744065523147583
INFO:root:current mean train loss 1674.2733955457372
INFO:root:current train perplexity3.7440900802612305
INFO:root:current mean train loss 1674.2920886528202
INFO:root:current train perplexity3.7449355125427246
INFO:root:current mean train loss 1675.6521670468203
INFO:root:current train perplexity3.748056173324585
INFO:root:current mean train loss 1674.137973153518
INFO:root:current train perplexity3.7486093044281006
INFO:root:current mean train loss 1674.4226259658897
INFO:root:current train perplexity3.7502026557922363
INFO:root:current mean train loss 1675.054564106758
INFO:root:current train perplexity3.754277229309082
INFO:root:current mean train loss 1676.6576386455997
INFO:root:current train perplexity3.7565934658050537
INFO:root:current mean train loss 1677.5637776692708
INFO:root:current train perplexity3.7571558952331543
INFO:root:current mean train loss 1678.374554327323
INFO:root:current train perplexity3.760021686553955
INFO:root:current mean train loss 1680.8289692262035
INFO:root:current train perplexity3.764782667160034
INFO:root:current mean train loss 1681.3191286999793
INFO:root:current train perplexity3.7672605514526367
INFO:root:current mean train loss 1681.409118161039
INFO:root:current train perplexity3.767237901687622
INFO:root:current mean train loss 1682.0675473049153
INFO:root:current train perplexity3.7690370082855225
INFO:root:current mean train loss 1682.6052679224777
INFO:root:current train perplexity3.771317958831787
INFO:root:current mean train loss 1683.5405402838405
INFO:root:current train perplexity3.771465301513672

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.58s/it]
INFO:root:final mean train loss: 1683.7590146432665
INFO:root:final train perplexity: 3.773163080215454
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 2007.5039127431016
INFO:root:eval perplexity: 5.071066379547119
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.28s/it]
INFO:root:eval mean loss: 2490.171145175366
INFO:root:eval perplexity: 7.663970947265625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/49
 24%|â–ˆâ–ˆâ–       | 49/200 [8:41:05<26:56:38, 642.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1663.446933746338
INFO:root:current train perplexity3.7517752647399902
INFO:root:current mean train loss 1668.7010414817116
INFO:root:current train perplexity3.7216131687164307
INFO:root:current mean train loss 1672.0168357059874
INFO:root:current train perplexity3.720125198364258
INFO:root:current mean train loss 1669.23949423181
INFO:root:current train perplexity3.7159371376037598
INFO:root:current mean train loss 1672.69551482024
INFO:root:current train perplexity3.724778652191162
INFO:root:current mean train loss 1673.4699110447016
INFO:root:current train perplexity3.7208826541900635
INFO:root:current mean train loss 1676.3488107029395
INFO:root:current train perplexity3.7306129932403564
INFO:root:current mean train loss 1676.828441182121
INFO:root:current train perplexity3.7341907024383545
INFO:root:current mean train loss 1676.7402785374568
INFO:root:current train perplexity3.7358217239379883
INFO:root:current mean train loss 1677.7050246864942
INFO:root:current train perplexity3.739678144454956
INFO:root:current mean train loss 1676.9635149342146
INFO:root:current train perplexity3.741340398788452
INFO:root:current mean train loss 1676.5086673156954
INFO:root:current train perplexity3.742319107055664
INFO:root:current mean train loss 1676.335738541244
INFO:root:current train perplexity3.7420949935913086
INFO:root:current mean train loss 1676.113466096712
INFO:root:current train perplexity3.7437455654144287
INFO:root:current mean train loss 1676.4058458552015
INFO:root:current train perplexity3.7456324100494385
INFO:root:current mean train loss 1676.4065752552322
INFO:root:current train perplexity3.7462782859802246
INFO:root:current mean train loss 1675.7524531495337
INFO:root:current train perplexity3.749044895172119
INFO:root:current mean train loss 1676.2648422558368
INFO:root:current train perplexity3.7496931552886963
INFO:root:current mean train loss 1677.189215780866
INFO:root:current train perplexity3.7517175674438477
INFO:root:current mean train loss 1677.5723678557276
INFO:root:current train perplexity3.7529096603393555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.53s/it]
INFO:root:final mean train loss: 1677.1391025991436
INFO:root:final train perplexity: 3.7535150051116943
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it]
INFO:root:eval mean loss: 2009.3306365317487
INFO:root:eval perplexity: 5.078563690185547
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it]
INFO:root:eval mean loss: 2493.8531416223404
INFO:root:eval perplexity: 7.687083721160889
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [8:51:39<26:39:04, 639.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1646.0330561423789
INFO:root:current train perplexity3.6888628005981445
INFO:root:current mean train loss 1660.6028864303692
INFO:root:current train perplexity3.693319320678711
INFO:root:current mean train loss 1658.1312285273907
INFO:root:current train perplexity3.691009759902954
INFO:root:current mean train loss 1658.4519179379702
INFO:root:current train perplexity3.700852155685425
INFO:root:current mean train loss 1660.617851410252
INFO:root:current train perplexity3.7068870067596436
INFO:root:current mean train loss 1659.800197580473
INFO:root:current train perplexity3.7076656818389893
INFO:root:current mean train loss 1662.1121196070878
INFO:root:current train perplexity3.709038019180298
INFO:root:current mean train loss 1663.007521747747
INFO:root:current train perplexity3.709205150604248
INFO:root:current mean train loss 1663.1556709927581
INFO:root:current train perplexity3.708261251449585
INFO:root:current mean train loss 1663.1755059808022
INFO:root:current train perplexity3.710273504257202
INFO:root:current mean train loss 1663.928411987421
INFO:root:current train perplexity3.7154648303985596
INFO:root:current mean train loss 1663.8246627289695
INFO:root:current train perplexity3.7157812118530273
INFO:root:current mean train loss 1666.264063887829
INFO:root:current train perplexity3.7212491035461426
INFO:root:current mean train loss 1666.6186350602588
INFO:root:current train perplexity3.7242720127105713
INFO:root:current mean train loss 1666.5518010299397
INFO:root:current train perplexity3.7246077060699463
INFO:root:current mean train loss 1667.3141557115982
INFO:root:current train perplexity3.727485179901123
INFO:root:current mean train loss 1668.0912336045283
INFO:root:current train perplexity3.7294692993164062
INFO:root:current mean train loss 1669.041417570643
INFO:root:current train perplexity3.7313730716705322
INFO:root:current mean train loss 1669.6727035464694
INFO:root:current train perplexity3.731720447540283
INFO:root:current mean train loss 1671.035213433271
INFO:root:current train perplexity3.734776020050049

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.40s/it]
INFO:root:final mean train loss: 1670.7215858724944
INFO:root:final train perplexity: 3.7345659732818604
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it]
INFO:root:eval mean loss: 2009.7444652800864
INFO:root:eval perplexity: 5.080264568328857
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.57s/it]
INFO:root:eval mean loss: 2494.952566160378
INFO:root:eval perplexity: 7.693999767303467
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [9:02:21<26:30:44, 640.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1633.795145670573
INFO:root:current train perplexity3.647580862045288
INFO:root:current mean train loss 1649.2613172416227
INFO:root:current train perplexity3.661390542984009
INFO:root:current mean train loss 1649.5171784135632
INFO:root:current train perplexity3.670902967453003
INFO:root:current mean train loss 1646.367622417179
INFO:root:current train perplexity3.667813539505005
INFO:root:current mean train loss 1653.5120833892167
INFO:root:current train perplexity3.675114393234253
INFO:root:current mean train loss 1655.1448605810374
INFO:root:current train perplexity3.681311845779419
INFO:root:current mean train loss 1655.2639755844712
INFO:root:current train perplexity3.6858978271484375
INFO:root:current mean train loss 1656.8157450623673
INFO:root:current train perplexity3.6876564025878906
INFO:root:current mean train loss 1657.0854845994063
INFO:root:current train perplexity3.6884095668792725
INFO:root:current mean train loss 1658.7856598216308
INFO:root:current train perplexity3.693575143814087
INFO:root:current mean train loss 1661.7213299663608
INFO:root:current train perplexity3.6971852779388428
INFO:root:current mean train loss 1662.213043998077
INFO:root:current train perplexity3.700329542160034
INFO:root:current mean train loss 1662.9814950662767
INFO:root:current train perplexity3.704025983810425
INFO:root:current mean train loss 1663.6337248102639
INFO:root:current train perplexity3.7057812213897705
INFO:root:current mean train loss 1664.4888986793092
INFO:root:current train perplexity3.708414077758789
INFO:root:current mean train loss 1664.7448695391074
INFO:root:current train perplexity3.7089650630950928
INFO:root:current mean train loss 1663.374013252762
INFO:root:current train perplexity3.708865165710449
INFO:root:current mean train loss 1664.6071446247036
INFO:root:current train perplexity3.710987091064453
INFO:root:current mean train loss 1664.4704985623703
INFO:root:current train perplexity3.7114737033843994
INFO:root:current mean train loss 1664.1907767745024
INFO:root:current train perplexity3.714113712310791

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.94s/it]
INFO:root:final mean train loss: 1663.818957753453
INFO:root:final train perplexity: 3.7142903804779053
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it]
INFO:root:eval mean loss: 2015.1801857373393
INFO:root:eval perplexity: 5.102646827697754
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.08s/it]
INFO:root:eval mean loss: 2499.734898776873
INFO:root:eval perplexity: 7.72415018081665
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [9:12:48<26:09:28, 636.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1619.1628256188817
INFO:root:current train perplexity3.6329076290130615
INFO:root:current mean train loss 1632.9226521142846
INFO:root:current train perplexity3.6564316749572754
INFO:root:current mean train loss 1636.2122354136761
INFO:root:current train perplexity3.658048629760742
INFO:root:current mean train loss 1640.2182572566498
INFO:root:current train perplexity3.656487464904785
INFO:root:current mean train loss 1641.0065298771513
INFO:root:current train perplexity3.6589128971099854
INFO:root:current mean train loss 1644.0052107063411
INFO:root:current train perplexity3.661863088607788
INFO:root:current mean train loss 1645.0199646621636
INFO:root:current train perplexity3.665351390838623
INFO:root:current mean train loss 1647.6398701284124
INFO:root:current train perplexity3.665922164916992
INFO:root:current mean train loss 1649.1363459033037
INFO:root:current train perplexity3.6697185039520264
INFO:root:current mean train loss 1650.6999798577776
INFO:root:current train perplexity3.6744003295898438
INFO:root:current mean train loss 1651.7173665364583
INFO:root:current train perplexity3.675489902496338
INFO:root:current mean train loss 1652.3356148340092
INFO:root:current train perplexity3.677419900894165
INFO:root:current mean train loss 1653.4882983759987
INFO:root:current train perplexity3.678877830505371
INFO:root:current mean train loss 1653.7092613501559
INFO:root:current train perplexity3.681889295578003
INFO:root:current mean train loss 1654.9142047370196
INFO:root:current train perplexity3.6850531101226807
INFO:root:current mean train loss 1655.5900147101281
INFO:root:current train perplexity3.6866371631622314
INFO:root:current mean train loss 1655.8616479158543
INFO:root:current train perplexity3.688614845275879
INFO:root:current mean train loss 1657.0836857374773
INFO:root:current train perplexity3.6915652751922607
INFO:root:current mean train loss 1657.4773763453018
INFO:root:current train perplexity3.6910736560821533
INFO:root:current mean train loss 1656.8418805636484
INFO:root:current train perplexity3.693908452987671

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.51s/it]
INFO:root:final mean train loss: 1656.8418805636484
INFO:root:final train perplexity: 3.693908452987671
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 2013.7835338403147
INFO:root:eval perplexity: 5.096886157989502
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.26s/it]
INFO:root:eval mean loss: 2501.8136700569316
INFO:root:eval perplexity: 7.737293720245361
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [9:23:28<26:02:16, 637.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1615.8048571777344
INFO:root:current train perplexity3.6196844577789307
INFO:root:current mean train loss 1622.60728515625
INFO:root:current train perplexity3.6195108890533447
INFO:root:current mean train loss 1630.7881669108074
INFO:root:current train perplexity3.6291465759277344
INFO:root:current mean train loss 1631.3041104125978
INFO:root:current train perplexity3.6382510662078857
INFO:root:current mean train loss 1635.9727438964844
INFO:root:current train perplexity3.6456668376922607
INFO:root:current mean train loss 1638.2801261393229
INFO:root:current train perplexity3.643359422683716
INFO:root:current mean train loss 1639.569753766741
INFO:root:current train perplexity3.646250009536743
INFO:root:current mean train loss 1639.9160572814942
INFO:root:current train perplexity3.647768259048462
INFO:root:current mean train loss 1641.4891289605034
INFO:root:current train perplexity3.6512582302093506
INFO:root:current mean train loss 1642.7558305664063
INFO:root:current train perplexity3.6531755924224854
INFO:root:current mean train loss 1642.6468118563566
INFO:root:current train perplexity3.654573440551758
INFO:root:current mean train loss 1644.8104933675131
INFO:root:current train perplexity3.659557342529297
INFO:root:current mean train loss 1645.1341952749399
INFO:root:current train perplexity3.660416841506958
INFO:root:current mean train loss 1646.633244280134
INFO:root:current train perplexity3.663914203643799
INFO:root:current mean train loss 1647.129896484375
INFO:root:current train perplexity3.6659107208251953
INFO:root:current mean train loss 1648.5791954803467
INFO:root:current train perplexity3.6699635982513428
INFO:root:current mean train loss 1649.9460896570542
INFO:root:current train perplexity3.671386957168579
INFO:root:current mean train loss 1650.3832905409072
INFO:root:current train perplexity3.672086477279663
INFO:root:current mean train loss 1651.0627728592722
INFO:root:current train perplexity3.6740598678588867

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.05s/it]
INFO:root:final mean train loss: 1650.4417370340768
INFO:root:final train perplexity: 3.6753106117248535
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.04s/it]
INFO:root:eval mean loss: 2017.1057817175033
INFO:root:eval perplexity: 5.110599040985107
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.55s/it]
INFO:root:eval mean loss: 2504.889618569232
INFO:root:eval perplexity: 7.756782054901123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [9:33:57<25:45:15, 635.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1605.5421286190258
INFO:root:current train perplexity3.6045656204223633
INFO:root:current mean train loss 1634.9173239683494
INFO:root:current train perplexity3.616453170776367
INFO:root:current mean train loss 1634.2533071491575
INFO:root:current train perplexity3.6178014278411865
INFO:root:current mean train loss 1632.7885322450463
INFO:root:current train perplexity3.6204211711883545
INFO:root:current mean train loss 1631.4535090677457
INFO:root:current train perplexity3.6229026317596436
INFO:root:current mean train loss 1636.9299953910784
INFO:root:current train perplexity3.6322433948516846
INFO:root:current mean train loss 1639.5317192881382
INFO:root:current train perplexity3.6353349685668945
INFO:root:current mean train loss 1640.3348056681486
INFO:root:current train perplexity3.6377604007720947
INFO:root:current mean train loss 1641.452448757363
INFO:root:current train perplexity3.6394357681274414
INFO:root:current mean train loss 1642.636398598308
INFO:root:current train perplexity3.642133951187134
INFO:root:current mean train loss 1641.6851333723191
INFO:root:current train perplexity3.643171787261963
INFO:root:current mean train loss 1642.4527310309072
INFO:root:current train perplexity3.645402669906616
INFO:root:current mean train loss 1641.857515057679
INFO:root:current train perplexity3.6454107761383057
INFO:root:current mean train loss 1642.6048560812335
INFO:root:current train perplexity3.6482791900634766
INFO:root:current mean train loss 1642.5473748249492
INFO:root:current train perplexity3.6488749980926514
INFO:root:current mean train loss 1642.8269710050417
INFO:root:current train perplexity3.6508522033691406
INFO:root:current mean train loss 1642.2681305743179
INFO:root:current train perplexity3.651500701904297
INFO:root:current mean train loss 1642.4770726785455
INFO:root:current train perplexity3.653064250946045
INFO:root:current mean train loss 1643.2322313458826
INFO:root:current train perplexity3.6553826332092285
INFO:root:current mean train loss 1644.8172190969165
INFO:root:current train perplexity3.6579067707061768

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.21s/it]
INFO:root:final mean train loss: 1644.7480567243445
INFO:root:final train perplexity: 3.658843755722046
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it]
INFO:root:eval mean loss: 2019.5594954253934
INFO:root:eval perplexity: 5.120751857757568
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.67s/it]
INFO:root:eval mean loss: 2510.5975640479555
INFO:root:eval perplexity: 7.793076992034912
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [9:44:24<25:28:12, 632.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1613.88426657284
INFO:root:current train perplexity3.612277030944824
INFO:root:current mean train loss 1624.2695257841651
INFO:root:current train perplexity3.6197521686553955
INFO:root:current mean train loss 1628.777308276576
INFO:root:current train perplexity3.613889217376709
INFO:root:current mean train loss 1630.0005441996866
INFO:root:current train perplexity3.6096043586730957
INFO:root:current mean train loss 1628.393828079997
INFO:root:current train perplexity3.6118576526641846
INFO:root:current mean train loss 1629.4397082382375
INFO:root:current train perplexity3.6102077960968018
INFO:root:current mean train loss 1629.5732770372265
INFO:root:current train perplexity3.6148953437805176
INFO:root:current mean train loss 1630.3732055331445
INFO:root:current train perplexity3.6198410987854004
INFO:root:current mean train loss 1632.1171217810906
INFO:root:current train perplexity3.624208927154541
INFO:root:current mean train loss 1634.19426523082
INFO:root:current train perplexity3.628481388092041
INFO:root:current mean train loss 1635.2454666344295
INFO:root:current train perplexity3.631702184677124
INFO:root:current mean train loss 1635.7767129457397
INFO:root:current train perplexity3.6321113109588623
INFO:root:current mean train loss 1636.1075686759268
INFO:root:current train perplexity3.633864402770996
INFO:root:current mean train loss 1636.908236708062
INFO:root:current train perplexity3.636167287826538
INFO:root:current mean train loss 1637.1836316309548
INFO:root:current train perplexity3.6368350982666016
INFO:root:current mean train loss 1638.3030392324754
INFO:root:current train perplexity3.6390247344970703
INFO:root:current mean train loss 1638.431117530552
INFO:root:current train perplexity3.640103816986084
INFO:root:current mean train loss 1639.091905147284
INFO:root:current train perplexity3.640984535217285
INFO:root:current mean train loss 1638.4663095255844
INFO:root:current train perplexity3.6414215564727783
INFO:root:current mean train loss 1638.725814109258
INFO:root:current train perplexity3.6420414447784424

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.25s/it]
INFO:root:final mean train loss: 1638.8376377430818
INFO:root:final train perplexity: 3.6418282985687256
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it]
INFO:root:eval mean loss: 2022.3766968639184
INFO:root:eval perplexity: 5.1324310302734375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it]
INFO:root:eval mean loss: 2517.340621623587
INFO:root:eval perplexity: 7.8361735343933105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [9:54:47<25:11:12, 629.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1609.422856349571
INFO:root:current train perplexity3.571272850036621
INFO:root:current mean train loss 1604.1731142966164
INFO:root:current train perplexity3.5661120414733887
INFO:root:current mean train loss 1615.8595812064243
INFO:root:current train perplexity3.580143928527832
INFO:root:current mean train loss 1624.4112475794605
INFO:root:current train perplexity3.5928826332092285
INFO:root:current mean train loss 1626.0151827319498
INFO:root:current train perplexity3.597059726715088
INFO:root:current mean train loss 1624.5159163293301
INFO:root:current train perplexity3.594668388366699
INFO:root:current mean train loss 1626.3606063913091
INFO:root:current train perplexity3.599034070968628
INFO:root:current mean train loss 1627.2403884664197
INFO:root:current train perplexity3.600315809249878
INFO:root:current mean train loss 1626.921228931037
INFO:root:current train perplexity3.602933645248413
INFO:root:current mean train loss 1626.9405838478
INFO:root:current train perplexity3.603649616241455
INFO:root:current mean train loss 1627.4743562910696
INFO:root:current train perplexity3.606100559234619
INFO:root:current mean train loss 1629.0398619491882
INFO:root:current train perplexity3.607426404953003
INFO:root:current mean train loss 1629.24848724536
INFO:root:current train perplexity3.6092545986175537
INFO:root:current mean train loss 1630.5841700556011
INFO:root:current train perplexity3.6129863262176514
INFO:root:current mean train loss 1631.8117850768328
INFO:root:current train perplexity3.615384101867676
INFO:root:current mean train loss 1632.5309695767096
INFO:root:current train perplexity3.616574287414551
INFO:root:current mean train loss 1633.1018233504315
INFO:root:current train perplexity3.6189842224121094
INFO:root:current mean train loss 1634.1181964100872
INFO:root:current train perplexity3.6224207878112793
INFO:root:current mean train loss 1633.6469972549678
INFO:root:current train perplexity3.623241662979126
INFO:root:current mean train loss 1633.2894697555942
INFO:root:current train perplexity3.6246142387390137

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.84s/it]
INFO:root:final mean train loss: 1632.9285754474556
INFO:root:final train perplexity: 3.624896287918091
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it]
INFO:root:eval mean loss: 2024.555167123781
INFO:root:eval perplexity: 5.141481876373291
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it]
INFO:root:eval mean loss: 2518.405263914284
INFO:root:eval perplexity: 7.8429975509643555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [10:05:28<25:09:11, 633.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1606.6541640337775
INFO:root:current train perplexity3.55757474899292
INFO:root:current mean train loss 1614.5130673363096
INFO:root:current train perplexity3.5653774738311768
INFO:root:current mean train loss 1614.767458787605
INFO:root:current train perplexity3.576629400253296
INFO:root:current mean train loss 1619.3487303360648
INFO:root:current train perplexity3.5909528732299805
INFO:root:current mean train loss 1619.476537981604
INFO:root:current train perplexity3.587789535522461
INFO:root:current mean train loss 1620.6132292411696
INFO:root:current train perplexity3.5851330757141113
INFO:root:current mean train loss 1620.689113045881
INFO:root:current train perplexity3.5850136280059814
INFO:root:current mean train loss 1618.310947418213
INFO:root:current train perplexity3.5850698947906494
INFO:root:current mean train loss 1618.141819123299
INFO:root:current train perplexity3.5854926109313965
INFO:root:current mean train loss 1620.274147979484
INFO:root:current train perplexity3.591668128967285
INFO:root:current mean train loss 1622.5137784007784
INFO:root:current train perplexity3.5949501991271973
INFO:root:current mean train loss 1623.0995094612854
INFO:root:current train perplexity3.599104404449463
INFO:root:current mean train loss 1623.7809088192528
INFO:root:current train perplexity3.6007726192474365
INFO:root:current mean train loss 1623.429940653126
INFO:root:current train perplexity3.600851058959961
INFO:root:current mean train loss 1624.0869747650395
INFO:root:current train perplexity3.601534128189087
INFO:root:current mean train loss 1624.672515246333
INFO:root:current train perplexity3.6021065711975098
INFO:root:current mean train loss 1624.9513443688409
INFO:root:current train perplexity3.602318286895752
INFO:root:current mean train loss 1625.7231945883634
INFO:root:current train perplexity3.6026742458343506
INFO:root:current mean train loss 1626.0926135959667
INFO:root:current train perplexity3.6033811569213867
INFO:root:current mean train loss 1626.6270011343606
INFO:root:current train perplexity3.6050641536712646

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.58s/it]
INFO:root:final mean train loss: 1626.1736817391184
INFO:root:final train perplexity: 3.6056365966796875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 2025.9175038439162
INFO:root:eval perplexity: 5.14715051651001
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it]
INFO:root:eval mean loss: 2519.137934258644
INFO:root:eval perplexity: 7.847698211669922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [10:15:58<24:56:21, 632.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1607.027942612592
INFO:root:current train perplexity3.548712968826294
INFO:root:current mean train loss 1607.0977519267315
INFO:root:current train perplexity3.562859296798706
INFO:root:current mean train loss 1610.8366823430647
INFO:root:current train perplexity3.5705690383911133
INFO:root:current mean train loss 1611.373403573965
INFO:root:current train perplexity3.5751852989196777
INFO:root:current mean train loss 1612.0877431338595
INFO:root:current train perplexity3.5731136798858643
INFO:root:current mean train loss 1613.069898086939
INFO:root:current train perplexity3.5731852054595947
INFO:root:current mean train loss 1613.400465292826
INFO:root:current train perplexity3.5747556686401367
INFO:root:current mean train loss 1613.98037109375
INFO:root:current train perplexity3.578671932220459
INFO:root:current mean train loss 1615.3779600326625
INFO:root:current train perplexity3.576385021209717
INFO:root:current mean train loss 1615.6122416075111
INFO:root:current train perplexity3.576289176940918
INFO:root:current mean train loss 1614.5552432855702
INFO:root:current train perplexity3.5751290321350098
INFO:root:current mean train loss 1615.8404265971124
INFO:root:current train perplexity3.5773043632507324
INFO:root:current mean train loss 1617.7231819598128
INFO:root:current train perplexity3.5792534351348877
INFO:root:current mean train loss 1617.7845491595217
INFO:root:current train perplexity3.5808768272399902
INFO:root:current mean train loss 1618.2618182969013
INFO:root:current train perplexity3.582786798477173
INFO:root:current mean train loss 1619.5209146108537
INFO:root:current train perplexity3.584817409515381
INFO:root:current mean train loss 1620.1793696825157
INFO:root:current train perplexity3.587989568710327
INFO:root:current mean train loss 1620.9171753955488
INFO:root:current train perplexity3.5889530181884766
INFO:root:current mean train loss 1620.9462262464772
INFO:root:current train perplexity3.590507745742798

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:29<00:00, 569.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:29<00:00, 569.00s/it]
INFO:root:final mean train loss: 1621.0482871497572
INFO:root:final train perplexity: 3.5910916328430176
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.61s/it]
INFO:root:eval mean loss: 2028.776665437306
INFO:root:eval perplexity: 5.1590657234191895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.58s/it]
INFO:root:eval mean loss: 2521.980884741384
INFO:root:eval perplexity: 7.865963935852051
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [10:26:46<24:56:31, 636.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1608.5955200195312
INFO:root:current train perplexity3.4581079483032227
INFO:root:current mean train loss 1581.4850068933824
INFO:root:current train perplexity3.4873435497283936
INFO:root:current mean train loss 1592.363674654819
INFO:root:current train perplexity3.5173842906951904
INFO:root:current mean train loss 1595.8191261544132
INFO:root:current train perplexity3.520887613296509
INFO:root:current mean train loss 1598.7464660340875
INFO:root:current train perplexity3.5282740592956543
INFO:root:current mean train loss 1600.633835750747
INFO:root:current train perplexity3.536393165588379
INFO:root:current mean train loss 1604.5651883857195
INFO:root:current train perplexity3.5469746589660645
INFO:root:current mean train loss 1606.3168762728699
INFO:root:current train perplexity3.5510077476501465
INFO:root:current mean train loss 1607.696098042248
INFO:root:current train perplexity3.5519447326660156
INFO:root:current mean train loss 1609.0412877795436
INFO:root:current train perplexity3.554119825363159
INFO:root:current mean train loss 1609.7229262178766
INFO:root:current train perplexity3.558640718460083
INFO:root:current mean train loss 1612.0956068644723
INFO:root:current train perplexity3.5617971420288086
INFO:root:current mean train loss 1612.5462152922214
INFO:root:current train perplexity3.561920166015625
INFO:root:current mean train loss 1612.6279873474402
INFO:root:current train perplexity3.565696954727173
INFO:root:current mean train loss 1612.8361908699069
INFO:root:current train perplexity3.5684568881988525
INFO:root:current mean train loss 1613.257911082749
INFO:root:current train perplexity3.569613218307495
INFO:root:current mean train loss 1613.1167184208216
INFO:root:current train perplexity3.5712509155273438
INFO:root:current mean train loss 1613.4219150924234
INFO:root:current train perplexity3.5710701942443848
INFO:root:current mean train loss 1614.0610423368566
INFO:root:current train perplexity3.5715575218200684
INFO:root:current mean train loss 1614.2244428921447
INFO:root:current train perplexity3.572162628173828

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.05s/it]
INFO:root:final mean train loss: 1614.8941124066282
INFO:root:final train perplexity: 3.5737040042877197
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.00s/it]
INFO:root:eval mean loss: 2031.7995536208998
INFO:root:eval perplexity: 5.171692848205566
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 2527.994587350399
INFO:root:eval perplexity: 7.9047465324401855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [10:37:15<24:40:51, 634.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1600.067447060033
INFO:root:current train perplexity3.5553884506225586
INFO:root:current mean train loss 1599.6832634420955
INFO:root:current train perplexity3.536853551864624
INFO:root:current mean train loss 1604.3754002122573
INFO:root:current train perplexity3.5336451530456543
INFO:root:current mean train loss 1601.6846365136412
INFO:root:current train perplexity3.5326364040374756
INFO:root:current mean train loss 1597.0368800925753
INFO:root:current train perplexity3.5249710083007812
INFO:root:current mean train loss 1601.2287527095375
INFO:root:current train perplexity3.532374382019043
INFO:root:current mean train loss 1600.8105119695956
INFO:root:current train perplexity3.5383379459381104
INFO:root:current mean train loss 1602.6735590270232
INFO:root:current train perplexity3.5435242652893066
INFO:root:current mean train loss 1602.8577454582094
INFO:root:current train perplexity3.5437862873077393
INFO:root:current mean train loss 1603.4152951577803
INFO:root:current train perplexity3.5459647178649902
INFO:root:current mean train loss 1603.914900460585
INFO:root:current train perplexity3.547123908996582
INFO:root:current mean train loss 1604.357850593792
INFO:root:current train perplexity3.5482468605041504
INFO:root:current mean train loss 1605.2716486041325
INFO:root:current train perplexity3.549473762512207
INFO:root:current mean train loss 1605.6467112092198
INFO:root:current train perplexity3.550609588623047
INFO:root:current mean train loss 1606.3178494153012
INFO:root:current train perplexity3.5509870052337646
INFO:root:current mean train loss 1606.9761515272692
INFO:root:current train perplexity3.5518722534179688
INFO:root:current mean train loss 1607.8826984219377
INFO:root:current train perplexity3.554025173187256
INFO:root:current mean train loss 1608.365534686432
INFO:root:current train perplexity3.555140495300293
INFO:root:current mean train loss 1608.6977414911826
INFO:root:current train perplexity3.557178020477295
INFO:root:current mean train loss 1609.0441204983472
INFO:root:current train perplexity3.556891679763794

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.02s/it]
INFO:root:final mean train loss: 1609.1539048095333
INFO:root:final train perplexity: 3.5575625896453857
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.46s/it]
INFO:root:eval mean loss: 2034.6506893076796
INFO:root:eval perplexity: 5.1836323738098145
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.84s/it]
INFO:root:eval mean loss: 2530.5402044201574
INFO:root:eval perplexity: 7.921220302581787
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [10:47:42<24:24:43, 632.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1573.186014811198
INFO:root:current train perplexity3.467785120010376
INFO:root:current mean train loss 1574.9134772805608
INFO:root:current train perplexity3.4736573696136475
INFO:root:current mean train loss 1584.083221952794
INFO:root:current train perplexity3.5009891986846924
INFO:root:current mean train loss 1590.5003858293805
INFO:root:current train perplexity3.508657693862915
INFO:root:current mean train loss 1589.4132592437463
INFO:root:current train perplexity3.5097343921661377
INFO:root:current mean train loss 1590.4328073530055
INFO:root:current train perplexity3.5106253623962402
INFO:root:current mean train loss 1591.1596856267197
INFO:root:current train perplexity3.5116958618164062
INFO:root:current mean train loss 1594.62351210221
INFO:root:current train perplexity3.5169193744659424
INFO:root:current mean train loss 1595.5490959203985
INFO:root:current train perplexity3.521714210510254
INFO:root:current mean train loss 1595.7586128691323
INFO:root:current train perplexity3.5207557678222656
INFO:root:current mean train loss 1595.7206933452355
INFO:root:current train perplexity3.520190477371216
INFO:root:current mean train loss 1595.5714901131644
INFO:root:current train perplexity3.520376443862915
INFO:root:current mean train loss 1596.4572580084446
INFO:root:current train perplexity3.525414228439331
INFO:root:current mean train loss 1598.6624412308197
INFO:root:current train perplexity3.5300726890563965
INFO:root:current mean train loss 1598.4664726576102
INFO:root:current train perplexity3.5318410396575928
INFO:root:current mean train loss 1600.2086850802104
INFO:root:current train perplexity3.536348819732666
INFO:root:current mean train loss 1601.1528318074047
INFO:root:current train perplexity3.5376596450805664
INFO:root:current mean train loss 1602.2062616304318
INFO:root:current train perplexity3.539944887161255
INFO:root:current mean train loss 1602.9954419769751
INFO:root:current train perplexity3.5398309230804443
INFO:root:current mean train loss 1603.647415035027
INFO:root:current train perplexity3.5404818058013916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:05<00:00, 545.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:05<00:00, 545.88s/it]
INFO:root:final mean train loss: 1602.8674180669973
INFO:root:final train perplexity: 3.5399677753448486
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.90s/it]
INFO:root:eval mean loss: 2035.8490280259587
INFO:root:eval perplexity: 5.188657760620117
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it]
INFO:root:eval mean loss: 2536.076448481134
INFO:root:eval perplexity: 7.957167148590088
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [10:58:06<24:08:25, 629.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1585.1571090986145
INFO:root:current train perplexity3.473741292953491
INFO:root:current mean train loss 1589.31700543173
INFO:root:current train perplexity3.499601364135742
INFO:root:current mean train loss 1595.7540813943615
INFO:root:current train perplexity3.510671854019165
INFO:root:current mean train loss 1596.0019026369955
INFO:root:current train perplexity3.5148420333862305
INFO:root:current mean train loss 1596.9005784462092
INFO:root:current train perplexity3.5177512168884277
INFO:root:current mean train loss 1596.497947541111
INFO:root:current train perplexity3.5176854133605957
INFO:root:current mean train loss 1596.7237810540894
INFO:root:current train perplexity3.515171766281128
INFO:root:current mean train loss 1596.6038330402348
INFO:root:current train perplexity3.5106000900268555
INFO:root:current mean train loss 1595.6402268761906
INFO:root:current train perplexity3.5093729496002197
INFO:root:current mean train loss 1594.6813092546972
INFO:root:current train perplexity3.509629011154175
INFO:root:current mean train loss 1595.3054116911132
INFO:root:current train perplexity3.5128867626190186
INFO:root:current mean train loss 1595.2135199276345
INFO:root:current train perplexity3.5145375728607178
INFO:root:current mean train loss 1595.7357568398345
INFO:root:current train perplexity3.5162837505340576
INFO:root:current mean train loss 1596.5469181260971
INFO:root:current train perplexity3.5201494693756104
INFO:root:current mean train loss 1596.4969827713674
INFO:root:current train perplexity3.520820379257202
INFO:root:current mean train loss 1596.1925374244154
INFO:root:current train perplexity3.5229032039642334
INFO:root:current mean train loss 1596.7994487413982
INFO:root:current train perplexity3.5225677490234375
INFO:root:current mean train loss 1596.8479529651179
INFO:root:current train perplexity3.5230112075805664
INFO:root:current mean train loss 1597.360311970348
INFO:root:current train perplexity3.524752378463745
INFO:root:current mean train loss 1598.036594467046
INFO:root:current train perplexity3.526167154312134

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.34s/it]
INFO:root:final mean train loss: 1598.0066507082663
INFO:root:final train perplexity: 3.526423931121826
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it]
INFO:root:eval mean loss: 2038.4834685629987
INFO:root:eval perplexity: 5.1997246742248535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it]
INFO:root:eval mean loss: 2541.248245563913
INFO:root:eval perplexity: 7.990893840789795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [11:08:46<24:04:42, 632.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1589.670370047433
INFO:root:current train perplexity3.478804111480713
INFO:root:current mean train loss 1587.7620842428769
INFO:root:current train perplexity3.4717555046081543
INFO:root:current mean train loss 1583.8452921549479
INFO:root:current train perplexity3.4735960960388184
INFO:root:current mean train loss 1579.2424890466639
INFO:root:current train perplexity3.4747705459594727
INFO:root:current mean train loss 1582.5876740151264
INFO:root:current train perplexity3.4815731048583984
INFO:root:current mean train loss 1583.9553162691886
INFO:root:current train perplexity3.487746000289917
INFO:root:current mean train loss 1584.2793557238224
INFO:root:current train perplexity3.487990379333496
INFO:root:current mean train loss 1585.415284471388
INFO:root:current train perplexity3.4904627799987793
INFO:root:current mean train loss 1586.1070254972612
INFO:root:current train perplexity3.4955716133117676
INFO:root:current mean train loss 1585.7957061452964
INFO:root:current train perplexity3.4940943717956543
INFO:root:current mean train loss 1585.5847015095649
INFO:root:current train perplexity3.4966278076171875
INFO:root:current mean train loss 1586.3795282869257
INFO:root:current train perplexity3.499939203262329
INFO:root:current mean train loss 1586.4939406027006
INFO:root:current train perplexity3.50128436088562
INFO:root:current mean train loss 1588.2091992900318
INFO:root:current train perplexity3.5037214756011963
INFO:root:current mean train loss 1589.1734193970558
INFO:root:current train perplexity3.5049262046813965
INFO:root:current mean train loss 1589.6208237957803
INFO:root:current train perplexity3.5066819190979004
INFO:root:current mean train loss 1590.3068822803612
INFO:root:current train perplexity3.5070149898529053
INFO:root:current mean train loss 1590.9578616729564
INFO:root:current train perplexity3.5069403648376465
INFO:root:current mean train loss 1591.9361437792447
INFO:root:current train perplexity3.508312225341797
INFO:root:current mean train loss 1593.0525758694876
INFO:root:current train perplexity3.511035919189453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.47s/it]
INFO:root:final mean train loss: 1592.4806788796075
INFO:root:final train perplexity: 3.5110881328582764
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it]
INFO:root:eval mean loss: 2040.8538220994017
INFO:root:eval perplexity: 5.209702968597412
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it]
INFO:root:eval mean loss: 2544.63828402039
INFO:root:eval perplexity: 8.013079643249512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [11:19:11<23:49:10, 630.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1571.9330507475754
INFO:root:current train perplexity3.4268248081207275
INFO:root:current mean train loss 1572.690645758481
INFO:root:current train perplexity3.453138589859009
INFO:root:current mean train loss 1577.2180350167412
INFO:root:current train perplexity3.470517873764038
INFO:root:current mean train loss 1575.7173107058502
INFO:root:current train perplexity3.4654457569122314
INFO:root:current mean train loss 1575.4174641759978
INFO:root:current train perplexity3.4688899517059326
INFO:root:current mean train loss 1577.8378500735332
INFO:root:current train perplexity3.4668996334075928
INFO:root:current mean train loss 1576.4467643726687
INFO:root:current train perplexity3.468527317047119
INFO:root:current mean train loss 1577.2104529413516
INFO:root:current train perplexity3.471853494644165
INFO:root:current mean train loss 1578.2136189182286
INFO:root:current train perplexity3.4740118980407715
INFO:root:current mean train loss 1578.844744866863
INFO:root:current train perplexity3.4781041145324707
INFO:root:current mean train loss 1579.8149591496808
INFO:root:current train perplexity3.4821743965148926
INFO:root:current mean train loss 1580.9778604354794
INFO:root:current train perplexity3.4843194484710693
INFO:root:current mean train loss 1582.1286976776478
INFO:root:current train perplexity3.487241506576538
INFO:root:current mean train loss 1581.9894167591362
INFO:root:current train perplexity3.488114356994629
INFO:root:current mean train loss 1583.2052158748213
INFO:root:current train perplexity3.489149808883667
INFO:root:current mean train loss 1583.9048185390575
INFO:root:current train perplexity3.4901466369628906
INFO:root:current mean train loss 1584.8432093305423
INFO:root:current train perplexity3.491037368774414
INFO:root:current mean train loss 1584.5456204833301
INFO:root:current train perplexity3.491887331008911
INFO:root:current mean train loss 1585.7721651741356
INFO:root:current train perplexity3.493117332458496

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.55s/it]
INFO:root:final mean train loss: 1586.3573014359852
INFO:root:final train perplexity: 3.494173526763916
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.30s/it]
INFO:root:eval mean loss: 2044.0928716997728
INFO:root:eval perplexity: 5.2233662605285645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.77s/it]
INFO:root:eval mean loss: 2546.8643625678747
INFO:root:eval perplexity: 8.027681350708008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [11:29:39<23:36:53, 629.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1527.11865234375
INFO:root:current train perplexity3.4239776134490967
INFO:root:current mean train loss 1559.1864154522236
INFO:root:current train perplexity3.435241937637329
INFO:root:current mean train loss 1561.9443060183057
INFO:root:current train perplexity3.4437942504882812
INFO:root:current mean train loss 1562.894093162135
INFO:root:current train perplexity3.4505810737609863
INFO:root:current mean train loss 1566.7511049780514
INFO:root:current train perplexity3.454695701599121
INFO:root:current mean train loss 1569.0582512749565
INFO:root:current train perplexity3.456831932067871
INFO:root:current mean train loss 1571.434411055205
INFO:root:current train perplexity3.4572806358337402
INFO:root:current mean train loss 1573.5923914475875
INFO:root:current train perplexity3.4625158309936523
INFO:root:current mean train loss 1575.5297074199316
INFO:root:current train perplexity3.4665145874023438
INFO:root:current mean train loss 1576.5817849488385
INFO:root:current train perplexity3.4697580337524414
INFO:root:current mean train loss 1577.3827835630136
INFO:root:current train perplexity3.4717116355895996
INFO:root:current mean train loss 1579.0782009622326
INFO:root:current train perplexity3.4739348888397217
INFO:root:current mean train loss 1579.0368222461586
INFO:root:current train perplexity3.472429037094116
INFO:root:current mean train loss 1579.6249897026578
INFO:root:current train perplexity3.47393798828125
INFO:root:current mean train loss 1579.9372688141304
INFO:root:current train perplexity3.4749176502227783
INFO:root:current mean train loss 1581.0666085912826
INFO:root:current train perplexity3.4768776893615723
INFO:root:current mean train loss 1581.0559366659036
INFO:root:current train perplexity3.4770519733428955
INFO:root:current mean train loss 1580.8130880722977
INFO:root:current train perplexity3.477238178253174
INFO:root:current mean train loss 1580.5899139877963
INFO:root:current train perplexity3.477135419845581
INFO:root:current mean train loss 1581.020498516179
INFO:root:current train perplexity3.4785022735595703

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.17s/it]
INFO:root:final mean train loss: 1580.9151871720169
INFO:root:final train perplexity: 3.479208469390869
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it]
INFO:root:eval mean loss: 2045.9110709115969
INFO:root:eval perplexity: 5.231053829193115
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 2552.0710873434728
INFO:root:eval perplexity: 8.061935424804688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [11:40:20<23:33:54, 633.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1579.0575706845239
INFO:root:current train perplexity3.4610891342163086
INFO:root:current mean train loss 1571.558839908316
INFO:root:current train perplexity3.4505581855773926
INFO:root:current mean train loss 1579.122975621288
INFO:root:current train perplexity3.4584858417510986
INFO:root:current mean train loss 1571.5498643916715
INFO:root:current train perplexity3.449043035507202
INFO:root:current mean train loss 1568.5260760744507
INFO:root:current train perplexity3.444571018218994
INFO:root:current mean train loss 1569.0138131579145
INFO:root:current train perplexity3.4473252296447754
INFO:root:current mean train loss 1568.682916171309
INFO:root:current train perplexity3.447882652282715
INFO:root:current mean train loss 1568.9901681759818
INFO:root:current train perplexity3.445781707763672
INFO:root:current mean train loss 1569.2538214996002
INFO:root:current train perplexity3.446751356124878
INFO:root:current mean train loss 1569.0812688738463
INFO:root:current train perplexity3.4495222568511963
INFO:root:current mean train loss 1568.5797037840123
INFO:root:current train perplexity3.4506144523620605
INFO:root:current mean train loss 1569.9757254308722
INFO:root:current train perplexity3.4510068893432617
INFO:root:current mean train loss 1569.8591162629248
INFO:root:current train perplexity3.4528937339782715
INFO:root:current mean train loss 1569.6853554990596
INFO:root:current train perplexity3.4536631107330322
INFO:root:current mean train loss 1570.8466214442403
INFO:root:current train perplexity3.4549481868743896
INFO:root:current mean train loss 1573.1272355480307
INFO:root:current train perplexity3.456993341445923
INFO:root:current mean train loss 1574.2127080090174
INFO:root:current train perplexity3.45854115486145
INFO:root:current mean train loss 1574.7672959659628
INFO:root:current train perplexity3.461379289627075
INFO:root:current mean train loss 1575.1937066821329
INFO:root:current train perplexity3.462865114212036
INFO:root:current mean train loss 1575.2296467929505
INFO:root:current train perplexity3.4626290798187256

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.90s/it]
INFO:root:final mean train loss: 1575.2168752080674
INFO:root:final train perplexity: 3.4636077880859375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it]
INFO:root:eval mean loss: 2048.722562749335
INFO:root:eval perplexity: 5.242961406707764
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it]
INFO:root:eval mean loss: 2556.8437989146996
INFO:root:eval perplexity: 8.093469619750977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [11:50:48<23:20:04, 631.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1535.088433516653
INFO:root:current train perplexity3.397533655166626
INFO:root:current mean train loss 1545.1267169454823
INFO:root:current train perplexity3.3865883350372314
INFO:root:current mean train loss 1551.7061982996324
INFO:root:current train perplexity3.39951753616333
INFO:root:current mean train loss 1555.678540833603
INFO:root:current train perplexity3.4086554050445557
INFO:root:current mean train loss 1555.0714953000142
INFO:root:current train perplexity3.4100701808929443
INFO:root:current mean train loss 1557.5911606572374
INFO:root:current train perplexity3.414722204208374
INFO:root:current mean train loss 1560.3089247557064
INFO:root:current train perplexity3.4224255084991455
INFO:root:current mean train loss 1560.703476820535
INFO:root:current train perplexity3.4283902645111084
INFO:root:current mean train loss 1562.757262746588
INFO:root:current train perplexity3.433363199234009
INFO:root:current mean train loss 1563.7490967057154
INFO:root:current train perplexity3.4351272583007812
INFO:root:current mean train loss 1562.0260070918382
INFO:root:current train perplexity3.4313361644744873
INFO:root:current mean train loss 1562.5176406619
INFO:root:current train perplexity3.4314029216766357
INFO:root:current mean train loss 1564.4138646041056
INFO:root:current train perplexity3.4342613220214844
INFO:root:current mean train loss 1566.1151365727765
INFO:root:current train perplexity3.438472032546997
INFO:root:current mean train loss 1567.3102875392526
INFO:root:current train perplexity3.440120220184326
INFO:root:current mean train loss 1568.2501946934178
INFO:root:current train perplexity3.442361354827881
INFO:root:current mean train loss 1569.0596432714963
INFO:root:current train perplexity3.4444761276245117
INFO:root:current mean train loss 1569.000223842397
INFO:root:current train perplexity3.446139097213745
INFO:root:current mean train loss 1568.7804192842934
INFO:root:current train perplexity3.4466118812561035
INFO:root:current mean train loss 1569.7775563967364
INFO:root:current train perplexity3.4475953578948975

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.89s/it]
INFO:root:final mean train loss: 1569.7673508821565
INFO:root:final train perplexity: 3.448754072189331
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it]
INFO:root:eval mean loss: 2051.48983396706
INFO:root:eval perplexity: 5.254708290100098
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it]
INFO:root:eval mean loss: 2559.844767252604
INFO:root:eval perplexity: 8.113353729248047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [12:01:10<23:03:13, 628.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1562.3848499644887
INFO:root:current train perplexity3.409640073776245
INFO:root:current mean train loss 1559.3778572328629
INFO:root:current train perplexity3.4076590538024902
INFO:root:current mean train loss 1557.4967701631433
INFO:root:current train perplexity3.4052162170410156
INFO:root:current mean train loss 1555.3591380804357
INFO:root:current train perplexity3.4033865928649902
INFO:root:current mean train loss 1557.9253085293612
INFO:root:current train perplexity3.4041080474853516
INFO:root:current mean train loss 1557.426710743947
INFO:root:current train perplexity3.400658130645752
INFO:root:current mean train loss 1557.7158382037214
INFO:root:current train perplexity3.4070539474487305
INFO:root:current mean train loss 1559.6984735552048
INFO:root:current train perplexity3.4130523204803467
INFO:root:current mean train loss 1560.109289907712
INFO:root:current train perplexity3.4154231548309326
INFO:root:current mean train loss 1560.4191743700917
INFO:root:current train perplexity3.416445255279541
INFO:root:current mean train loss 1561.6497014773402
INFO:root:current train perplexity3.4183669090270996
INFO:root:current mean train loss 1560.5130108986066
INFO:root:current train perplexity3.4170916080474854
INFO:root:current mean train loss 1561.7773456953437
INFO:root:current train perplexity3.4224467277526855
INFO:root:current mean train loss 1561.5787211175334
INFO:root:current train perplexity3.423736810684204
INFO:root:current mean train loss 1561.9264524269759
INFO:root:current train perplexity3.4236865043640137
INFO:root:current mean train loss 1562.9110219679462
INFO:root:current train perplexity3.4257254600524902
INFO:root:current mean train loss 1562.894627873631
INFO:root:current train perplexity3.4268367290496826
INFO:root:current mean train loss 1564.178974901509
INFO:root:current train perplexity3.4292495250701904
INFO:root:current mean train loss 1563.6478306361607
INFO:root:current train perplexity3.430738687515259
INFO:root:current mean train loss 1564.8125513257273
INFO:root:current train perplexity3.4344635009765625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.58s/it]
INFO:root:final mean train loss: 1564.6674210341123
INFO:root:final train perplexity: 3.434910535812378
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.55s/it]
INFO:root:eval mean loss: 2054.678987543634
INFO:root:eval perplexity: 5.268279552459717
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.78s/it]
INFO:root:eval mean loss: 2564.06353803053
INFO:root:eval perplexity: 8.14139461517334
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [12:11:37<22:51:44, 628.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1567.8370734320747
INFO:root:current train perplexity3.41705584526062
INFO:root:current mean train loss 1558.364584989326
INFO:root:current train perplexity3.3988051414489746
INFO:root:current mean train loss 1558.696107303395
INFO:root:current train perplexity3.4082348346710205
INFO:root:current mean train loss 1557.2721596994709
INFO:root:current train perplexity3.4061803817749023
INFO:root:current mean train loss 1552.665538205939
INFO:root:current train perplexity3.400716543197632
INFO:root:current mean train loss 1550.8281977726863
INFO:root:current train perplexity3.397937536239624
INFO:root:current mean train loss 1551.861613500686
INFO:root:current train perplexity3.3999650478363037
INFO:root:current mean train loss 1553.5393738425457
INFO:root:current train perplexity3.4031903743743896
INFO:root:current mean train loss 1553.662729525785
INFO:root:current train perplexity3.4050984382629395
INFO:root:current mean train loss 1555.5029368459443
INFO:root:current train perplexity3.4077351093292236
INFO:root:current mean train loss 1554.649926940007
INFO:root:current train perplexity3.4103643894195557
INFO:root:current mean train loss 1554.8494128334644
INFO:root:current train perplexity3.409878730773926
INFO:root:current mean train loss 1554.133296942561
INFO:root:current train perplexity3.4104275703430176
INFO:root:current mean train loss 1555.5071730544198
INFO:root:current train perplexity3.4131076335906982
INFO:root:current mean train loss 1556.5576002701468
INFO:root:current train perplexity3.415342092514038
INFO:root:current mean train loss 1556.7726901687738
INFO:root:current train perplexity3.4155726432800293
INFO:root:current mean train loss 1557.1300616834724
INFO:root:current train perplexity3.415093421936035
INFO:root:current mean train loss 1558.282934115649
INFO:root:current train perplexity3.4164936542510986
INFO:root:current mean train loss 1559.3010947072607
INFO:root:current train perplexity3.4187393188476562
INFO:root:current mean train loss 1559.7812350816707
INFO:root:current train perplexity3.4205873012542725

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.43s/it]
INFO:root:final mean train loss: 1559.4017543590737
INFO:root:final train perplexity: 3.420675277709961
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it]
INFO:root:eval mean loss: 2056.237964819509
INFO:root:eval perplexity: 5.274925708770752
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it]
INFO:root:eval mean loss: 2566.9996848681294
INFO:root:eval perplexity: 8.160968780517578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [12:21:59<22:36:46, 626.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1525.5017665905898
INFO:root:current train perplexity3.3660714626312256
INFO:root:current mean train loss 1529.2607331452546
INFO:root:current train perplexity3.362074851989746
INFO:root:current mean train loss 1540.7440464323367
INFO:root:current train perplexity3.367464780807495
INFO:root:current mean train loss 1541.067760320433
INFO:root:current train perplexity3.3751449584960938
INFO:root:current mean train loss 1541.834680849789
INFO:root:current train perplexity3.377267360687256
INFO:root:current mean train loss 1543.6493599702223
INFO:root:current train perplexity3.382652759552002
INFO:root:current mean train loss 1545.1376467678474
INFO:root:current train perplexity3.3854923248291016
INFO:root:current mean train loss 1546.9779332768933
INFO:root:current train perplexity3.386381149291992
INFO:root:current mean train loss 1548.0635119889798
INFO:root:current train perplexity3.3898138999938965
INFO:root:current mean train loss 1549.7657502794411
INFO:root:current train perplexity3.394211769104004
INFO:root:current mean train loss 1548.136157159306
INFO:root:current train perplexity3.3915212154388428
INFO:root:current mean train loss 1548.4146403063237
INFO:root:current train perplexity3.3919990062713623
INFO:root:current mean train loss 1548.2336042239926
INFO:root:current train perplexity3.3917670249938965
INFO:root:current mean train loss 1549.250989569272
INFO:root:current train perplexity3.395303964614868
INFO:root:current mean train loss 1550.4071281848137
INFO:root:current train perplexity3.3973898887634277
INFO:root:current mean train loss 1551.24825237411
INFO:root:current train perplexity3.3997976779937744
INFO:root:current mean train loss 1551.67656137253
INFO:root:current train perplexity3.400743246078491
INFO:root:current mean train loss 1552.7316307720357
INFO:root:current train perplexity3.401524543762207
INFO:root:current mean train loss 1553.8302619736178
INFO:root:current train perplexity3.404690980911255

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.38s/it]
INFO:root:final mean train loss: 1553.6239716976625
INFO:root:final train perplexity: 3.4051239490509033
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it]
INFO:root:eval mean loss: 2060.059477677582
INFO:root:eval perplexity: 5.291254043579102
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.87s/it]
INFO:root:eval mean loss: 2572.3196887293607
INFO:root:eval perplexity: 8.196553230285645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [12:32:34<22:32:02, 628.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1578.6663614908855
INFO:root:current train perplexity3.3697075843811035
INFO:root:current mean train loss 1528.2854982771964
INFO:root:current train perplexity3.349365234375
INFO:root:current mean train loss 1538.6672588459496
INFO:root:current train perplexity3.351331949234009
INFO:root:current mean train loss 1539.3511651731005
INFO:root:current train perplexity3.354344367980957
INFO:root:current mean train loss 1542.3893288297606
INFO:root:current train perplexity3.3599772453308105
INFO:root:current mean train loss 1539.8956023808053
INFO:root:current train perplexity3.362205743789673
INFO:root:current mean train loss 1540.218351357841
INFO:root:current train perplexity3.362056255340576
INFO:root:current mean train loss 1539.4135513954054
INFO:root:current train perplexity3.3631863594055176
INFO:root:current mean train loss 1539.2149049366083
INFO:root:current train perplexity3.3687827587127686
INFO:root:current mean train loss 1539.8829543764227
INFO:root:current train perplexity3.3729372024536133
INFO:root:current mean train loss 1541.6667702525083
INFO:root:current train perplexity3.3744895458221436
INFO:root:current mean train loss 1543.3832175615253
INFO:root:current train perplexity3.3774967193603516
INFO:root:current mean train loss 1544.5146905446725
INFO:root:current train perplexity3.379854202270508
INFO:root:current mean train loss 1545.2735953688805
INFO:root:current train perplexity3.3828277587890625
INFO:root:current mean train loss 1546.0263641487654
INFO:root:current train perplexity3.3843727111816406
INFO:root:current mean train loss 1546.5791493044749
INFO:root:current train perplexity3.385195016860962
INFO:root:current mean train loss 1547.2138620949029
INFO:root:current train perplexity3.3867990970611572
INFO:root:current mean train loss 1548.076147976123
INFO:root:current train perplexity3.387221336364746
INFO:root:current mean train loss 1548.3148283932032
INFO:root:current train perplexity3.388206720352173
INFO:root:current mean train loss 1548.802626138469
INFO:root:current train perplexity3.3895976543426514

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.69s/it]
INFO:root:final mean train loss: 1548.8103742036806
INFO:root:final train perplexity: 3.392221450805664
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it]
INFO:root:eval mean loss: 2066.140027634641
INFO:root:eval perplexity: 5.317337989807129
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.95s/it]
INFO:root:eval mean loss: 2579.740960303773
INFO:root:eval perplexity: 8.246453285217285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [12:43:02<22:21:24, 628.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1555.145215905231
INFO:root:current train perplexity3.347815990447998
INFO:root:current mean train loss 1542.9543605897484
INFO:root:current train perplexity3.3552393913269043
INFO:root:current mean train loss 1537.1440227149312
INFO:root:current train perplexity3.3480939865112305
INFO:root:current mean train loss 1536.7750538923424
INFO:root:current train perplexity3.3490514755249023
INFO:root:current mean train loss 1538.4639780031027
INFO:root:current train perplexity3.3515520095825195
INFO:root:current mean train loss 1537.9908503282595
INFO:root:current train perplexity3.35408878326416
INFO:root:current mean train loss 1537.667314507988
INFO:root:current train perplexity3.3550539016723633
INFO:root:current mean train loss 1537.4407288695106
INFO:root:current train perplexity3.358701467514038
INFO:root:current mean train loss 1537.0012150668288
INFO:root:current train perplexity3.3593080043792725
INFO:root:current mean train loss 1538.165586857987
INFO:root:current train perplexity3.3627586364746094
INFO:root:current mean train loss 1537.2147336122694
INFO:root:current train perplexity3.3636858463287354
INFO:root:current mean train loss 1538.138327730201
INFO:root:current train perplexity3.3651838302612305
INFO:root:current mean train loss 1538.6153171193082
INFO:root:current train perplexity3.366213083267212
INFO:root:current mean train loss 1539.168393458729
INFO:root:current train perplexity3.36740779876709
INFO:root:current mean train loss 1539.6674466699424
INFO:root:current train perplexity3.368824005126953
INFO:root:current mean train loss 1541.8261778863416
INFO:root:current train perplexity3.37233829498291
INFO:root:current mean train loss 1541.6279358549464
INFO:root:current train perplexity3.373478412628174
INFO:root:current mean train loss 1541.8622405704757
INFO:root:current train perplexity3.3738770484924316
INFO:root:current mean train loss 1542.6270830297758
INFO:root:current train perplexity3.376558303833008
INFO:root:current mean train loss 1543.6839461224934
INFO:root:current train perplexity3.3783984184265137

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.65s/it]
INFO:root:final mean train loss: 1543.7875561966657
INFO:root:final train perplexity: 3.378810405731201
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.55s/it]
INFO:root:eval mean loss: 2066.5828762189717
INFO:root:eval perplexity: 5.319242477416992
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it]
INFO:root:eval mean loss: 2579.4695581747287
INFO:root:eval perplexity: 8.244621276855469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [12:53:37<22:14:40, 630.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1528.2535491943358
INFO:root:current train perplexity3.3352861404418945
INFO:root:current mean train loss 1525.186319405692
INFO:root:current train perplexity3.3216943740844727
INFO:root:current mean train loss 1534.987831624349
INFO:root:current train perplexity3.3344693183898926
INFO:root:current mean train loss 1531.9872720157398
INFO:root:current train perplexity3.3396177291870117
INFO:root:current mean train loss 1532.6415150035511
INFO:root:current train perplexity3.341305732727051
INFO:root:current mean train loss 1534.9596263744213
INFO:root:current train perplexity3.3438503742218018
INFO:root:current mean train loss 1534.6500984191894
INFO:root:current train perplexity3.346330165863037
INFO:root:current mean train loss 1533.740525694151
INFO:root:current train perplexity3.345571517944336
INFO:root:current mean train loss 1534.4228842599052
INFO:root:current train perplexity3.347033977508545
INFO:root:current mean train loss 1535.3201351084608
INFO:root:current train perplexity3.3494391441345215
INFO:root:current mean train loss 1534.3583597036509
INFO:root:current train perplexity3.3493940830230713
INFO:root:current mean train loss 1534.7255905419065
INFO:root:current train perplexity3.3507254123687744
INFO:root:current mean train loss 1536.1834992439517
INFO:root:current train perplexity3.3547163009643555
INFO:root:current mean train loss 1537.0848638278335
INFO:root:current train perplexity3.3577089309692383
INFO:root:current mean train loss 1537.4792847527399
INFO:root:current train perplexity3.3589212894439697
INFO:root:current mean train loss 1537.613505415483
INFO:root:current train perplexity3.359719753265381
INFO:root:current mean train loss 1537.095645439334
INFO:root:current train perplexity3.360057830810547
INFO:root:current mean train loss 1538.0255912693067
INFO:root:current train perplexity3.3605501651763916
INFO:root:current mean train loss 1539.0691276218581
INFO:root:current train perplexity3.3632547855377197
INFO:root:current mean train loss 1539.4282534884424
INFO:root:current train perplexity3.3649191856384277

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.66s/it]
INFO:root:final mean train loss: 1539.047697635714
INFO:root:final train perplexity: 3.3662033081054688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 2070.0438059272497
INFO:root:eval perplexity: 5.3341522216796875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it]
INFO:root:eval mean loss: 2583.9402833762742
INFO:root:eval perplexity: 8.274821281433105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [13:04:16<22:09:19, 633.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1496.753358004386
INFO:root:current train perplexity3.30495548248291
INFO:root:current mean train loss 1519.223143753732
INFO:root:current train perplexity3.3178346157073975
INFO:root:current mean train loss 1525.0365213475802
INFO:root:current train perplexity3.324075698852539
INFO:root:current mean train loss 1521.7873675349047
INFO:root:current train perplexity3.3250792026519775
INFO:root:current mean train loss 1525.5265774048653
INFO:root:current train perplexity3.3283207416534424
INFO:root:current mean train loss 1522.2374462627638
INFO:root:current train perplexity3.3289101123809814
INFO:root:current mean train loss 1524.3533575095723
INFO:root:current train perplexity3.3311479091644287
INFO:root:current mean train loss 1525.7900919542603
INFO:root:current train perplexity3.3344433307647705
INFO:root:current mean train loss 1526.6557899216928
INFO:root:current train perplexity3.3387184143066406
INFO:root:current mean train loss 1528.5028373375458
INFO:root:current train perplexity3.3404781818389893
INFO:root:current mean train loss 1528.596140014302
INFO:root:current train perplexity3.3395495414733887
INFO:root:current mean train loss 1529.334940258346
INFO:root:current train perplexity3.342353105545044
INFO:root:current mean train loss 1530.236610625031
INFO:root:current train perplexity3.34375262260437
INFO:root:current mean train loss 1530.5274077986828
INFO:root:current train perplexity3.3438379764556885
INFO:root:current mean train loss 1531.295110133059
INFO:root:current train perplexity3.3452281951904297
INFO:root:current mean train loss 1531.829439078682
INFO:root:current train perplexity3.347499132156372
INFO:root:current mean train loss 1532.2979036468155
INFO:root:current train perplexity3.3488454818725586
INFO:root:current mean train loss 1532.6886131534131
INFO:root:current train perplexity3.3489129543304443
INFO:root:current mean train loss 1534.0067132755705
INFO:root:current train perplexity3.3514111042022705
INFO:root:current mean train loss 1534.316927528284
INFO:root:current train perplexity3.3526065349578857

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.40s/it]
INFO:root:final mean train loss: 1533.8700551674094
INFO:root:final train perplexity: 3.352485418319702
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.22s/it]
INFO:root:eval mean loss: 2070.184609703984
INFO:root:eval perplexity: 5.3347601890563965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it]
INFO:root:eval mean loss: 2587.8049506870566
INFO:root:eval perplexity: 8.30101490020752
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [13:14:37<21:51:10, 629.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1518.847004658467
INFO:root:current train perplexity3.305999994277954
INFO:root:current mean train loss 1514.6766771338453
INFO:root:current train perplexity3.304346799850464
INFO:root:current mean train loss 1514.5584057438982
INFO:root:current train perplexity3.312572717666626
INFO:root:current mean train loss 1515.695492667948
INFO:root:current train perplexity3.313142776489258
INFO:root:current mean train loss 1516.5604072924907
INFO:root:current train perplexity3.3119919300079346
INFO:root:current mean train loss 1519.3686159778556
INFO:root:current train perplexity3.313265085220337
INFO:root:current mean train loss 1520.72755536269
INFO:root:current train perplexity3.31695818901062
INFO:root:current mean train loss 1521.1098154940346
INFO:root:current train perplexity3.315293073654175
INFO:root:current mean train loss 1520.7178900607391
INFO:root:current train perplexity3.3176071643829346
INFO:root:current mean train loss 1522.1510516094231
INFO:root:current train perplexity3.3183071613311768
INFO:root:current mean train loss 1523.6260753326133
INFO:root:current train perplexity3.31994891166687
INFO:root:current mean train loss 1523.510662228326
INFO:root:current train perplexity3.322375774383545
INFO:root:current mean train loss 1523.8842040440725
INFO:root:current train perplexity3.325568914413452
INFO:root:current mean train loss 1525.7410058878047
INFO:root:current train perplexity3.328256845474243
INFO:root:current mean train loss 1526.1348312978344
INFO:root:current train perplexity3.3299002647399902
INFO:root:current mean train loss 1526.7431568499594
INFO:root:current train perplexity3.3325693607330322
INFO:root:current mean train loss 1527.7368929736504
INFO:root:current train perplexity3.333974838256836
INFO:root:current mean train loss 1528.5822889463475
INFO:root:current train perplexity3.3354761600494385
INFO:root:current mean train loss 1528.508969953246
INFO:root:current train perplexity3.3361518383026123
INFO:root:current mean train loss 1528.3384221935949
INFO:root:current train perplexity3.336920738220215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.13s/it]
INFO:root:final mean train loss: 1528.0281043964026
INFO:root:final train perplexity: 3.33707594871521
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it]
INFO:root:eval mean loss: 2074.8464013498724
INFO:root:eval perplexity: 5.354909896850586
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it]
INFO:root:eval mean loss: 2592.331990559896
INFO:root:eval perplexity: 8.331808090209961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [13:25:10<21:43:26, 630.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1493.6987707117103
INFO:root:current train perplexity3.3085343837738037
INFO:root:current mean train loss 1511.105140246646
INFO:root:current train perplexity3.312694549560547
INFO:root:current mean train loss 1508.8850718494953
INFO:root:current train perplexity3.3159821033477783
INFO:root:current mean train loss 1507.9484057804507
INFO:root:current train perplexity3.3020436763763428
INFO:root:current mean train loss 1508.7572608217445
INFO:root:current train perplexity3.3055472373962402
INFO:root:current mean train loss 1508.461329116434
INFO:root:current train perplexity3.302170515060425
INFO:root:current mean train loss 1511.4710772855237
INFO:root:current train perplexity3.302659749984741
INFO:root:current mean train loss 1512.0432713794346
INFO:root:current train perplexity3.305732488632202
INFO:root:current mean train loss 1514.273130748676
INFO:root:current train perplexity3.309861421585083
INFO:root:current mean train loss 1515.2787477433621
INFO:root:current train perplexity3.3098552227020264
INFO:root:current mean train loss 1515.7460370225494
INFO:root:current train perplexity3.3117287158966064
INFO:root:current mean train loss 1517.7290893862169
INFO:root:current train perplexity3.3144750595092773
INFO:root:current mean train loss 1518.472532572255
INFO:root:current train perplexity3.3163437843322754
INFO:root:current mean train loss 1519.9305197896074
INFO:root:current train perplexity3.3172566890716553
INFO:root:current mean train loss 1520.8813268609051
INFO:root:current train perplexity3.3189620971679688
INFO:root:current mean train loss 1522.0733334908764
INFO:root:current train perplexity3.322214126586914
INFO:root:current mean train loss 1522.7404100811743
INFO:root:current train perplexity3.324528694152832
INFO:root:current mean train loss 1523.9525575195858
INFO:root:current train perplexity3.325427293777466
INFO:root:current mean train loss 1523.9577118355658
INFO:root:current train perplexity3.3264882564544678

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.97s/it]
INFO:root:final mean train loss: 1524.117926200832
INFO:root:final train perplexity: 3.3268003463745117
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it]
INFO:root:eval mean loss: 2076.799364888076
INFO:root:eval perplexity: 5.363375186920166
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it]
INFO:root:eval mean loss: 2595.743346735095
INFO:root:eval perplexity: 8.355083465576172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [13:35:32<21:27:33, 628.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1471.5364837646484
INFO:root:current train perplexity3.259202480316162
INFO:root:current mean train loss 1508.9871701841
INFO:root:current train perplexity3.2754569053649902
INFO:root:current mean train loss 1507.829116821289
INFO:root:current train perplexity3.2872495651245117
INFO:root:current mean train loss 1505.363171069653
INFO:root:current train perplexity3.289034605026245
INFO:root:current mean train loss 1506.6328837076824
INFO:root:current train perplexity3.2875571250915527
INFO:root:current mean train loss 1507.8060362808349
INFO:root:current train perplexity3.2900595664978027
INFO:root:current mean train loss 1507.7376285352204
INFO:root:current train perplexity3.2923269271850586
INFO:root:current mean train loss 1507.780521026439
INFO:root:current train perplexity3.2930092811584473
INFO:root:current mean train loss 1511.0736147436764
INFO:root:current train perplexity3.2952797412872314
INFO:root:current mean train loss 1512.5676202311915
INFO:root:current train perplexity3.297497272491455
INFO:root:current mean train loss 1513.9743382287404
INFO:root:current train perplexity3.301218271255493
INFO:root:current mean train loss 1514.8724340996587
INFO:root:current train perplexity3.3025624752044678
INFO:root:current mean train loss 1515.6194171021316
INFO:root:current train perplexity3.304213285446167
INFO:root:current mean train loss 1517.066866533472
INFO:root:current train perplexity3.3066136837005615
INFO:root:current mean train loss 1517.4743800596757
INFO:root:current train perplexity3.3083431720733643
INFO:root:current mean train loss 1518.08647167904
INFO:root:current train perplexity3.309626579284668
INFO:root:current mean train loss 1519.1797814060799
INFO:root:current train perplexity3.3105950355529785
INFO:root:current mean train loss 1519.0721662105943
INFO:root:current train perplexity3.311023712158203
INFO:root:current mean train loss 1519.1695189349418
INFO:root:current train perplexity3.312613010406494
INFO:root:current mean train loss 1519.3855155768883
INFO:root:current train perplexity3.3138229846954346

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.98s/it]
INFO:root:final mean train loss: 1519.2328316385074
INFO:root:final train perplexity: 3.3140077590942383
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.09s/it]
INFO:root:eval mean loss: 2080.9346845910904
INFO:root:eval perplexity: 5.381342887878418
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it]
INFO:root:eval mean loss: 2600.448271190021
INFO:root:eval perplexity: 8.38729476928711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [13:46:08<21:21:51, 630.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1501.5267041015625
INFO:root:current train perplexity3.273477077484131
INFO:root:current mean train loss 1495.993341796875
INFO:root:current train perplexity3.2891781330108643
INFO:root:current mean train loss 1497.8311648220485
INFO:root:current train perplexity3.2750871181488037
INFO:root:current mean train loss 1500.7759630408655
INFO:root:current train perplexity3.2779042720794678
INFO:root:current mean train loss 1503.1519752412685
INFO:root:current train perplexity3.284031867980957
INFO:root:current mean train loss 1505.2931940569197
INFO:root:current train perplexity3.2852444648742676
INFO:root:current mean train loss 1503.54682265625
INFO:root:current train perplexity3.289187431335449
INFO:root:current mean train loss 1503.7322306034482
INFO:root:current train perplexity3.2866218090057373
INFO:root:current mean train loss 1506.2899741062974
INFO:root:current train perplexity3.2869858741760254
INFO:root:current mean train loss 1507.517974556588
INFO:root:current train perplexity3.2899255752563477
INFO:root:current mean train loss 1507.2602901105183
INFO:root:current train perplexity3.2924630641937256
INFO:root:current mean train loss 1508.7663462456596
INFO:root:current train perplexity3.292569160461426
INFO:root:current mean train loss 1510.7790847217793
INFO:root:current train perplexity3.2950620651245117
INFO:root:current mean train loss 1511.486619711822
INFO:root:current train perplexity3.2959609031677246
INFO:root:current mean train loss 1512.5369924444901
INFO:root:current train perplexity3.2974748611450195
INFO:root:current mean train loss 1512.9512127785604
INFO:root:current train perplexity3.2975220680236816
INFO:root:current mean train loss 1512.8888697415866
INFO:root:current train perplexity3.298521041870117
INFO:root:current mean train loss 1513.4910510076993
INFO:root:current train perplexity3.298095941543579
INFO:root:current mean train loss 1514.6357734241224
INFO:root:current train perplexity3.2997453212738037
INFO:root:current mean train loss 1515.2491781021713
INFO:root:current train perplexity3.30204439163208

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.62s/it]
INFO:root:final mean train loss: 1514.937587751503
INFO:root:final train perplexity: 3.3028006553649902
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it]
INFO:root:eval mean loss: 2082.8527018229165
INFO:root:eval perplexity: 5.3896965980529785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it]
INFO:root:eval mean loss: 2605.939073927859
INFO:root:eval perplexity: 8.425041198730469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [13:56:31<21:06:41, 628.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1515.3868175688244
INFO:root:current train perplexity3.2903943061828613
INFO:root:current mean train loss 1515.2464633995378
INFO:root:current train perplexity3.2803914546966553
INFO:root:current mean train loss 1511.7534527739217
INFO:root:current train perplexity3.2785379886627197
INFO:root:current mean train loss 1507.7629526595624
INFO:root:current train perplexity3.275298833847046
INFO:root:current mean train loss 1506.1124621084912
INFO:root:current train perplexity3.2791926860809326
INFO:root:current mean train loss 1503.98630650369
INFO:root:current train perplexity3.2734124660491943
INFO:root:current mean train loss 1505.7150544258664
INFO:root:current train perplexity3.2748818397521973
INFO:root:current mean train loss 1506.6150978273458
INFO:root:current train perplexity3.2775118350982666
INFO:root:current mean train loss 1505.2758281644337
INFO:root:current train perplexity3.2769594192504883
INFO:root:current mean train loss 1506.0958235106903
INFO:root:current train perplexity3.2808709144592285
INFO:root:current mean train loss 1507.77529221899
INFO:root:current train perplexity3.28226900100708
INFO:root:current mean train loss 1506.3878174897043
INFO:root:current train perplexity3.2822444438934326
INFO:root:current mean train loss 1507.1338651353035
INFO:root:current train perplexity3.2845075130462646
INFO:root:current mean train loss 1507.0935519768477
INFO:root:current train perplexity3.284947633743286
INFO:root:current mean train loss 1508.1329297450643
INFO:root:current train perplexity3.287619113922119
INFO:root:current mean train loss 1509.1041748996838
INFO:root:current train perplexity3.288283348083496
INFO:root:current mean train loss 1509.5478360249267
INFO:root:current train perplexity3.2884724140167236
INFO:root:current mean train loss 1509.4767703418754
INFO:root:current train perplexity3.288998603820801
INFO:root:current mean train loss 1510.319470135319
INFO:root:current train perplexity3.2896242141723633
INFO:root:current mean train loss 1510.398610045318
INFO:root:current train perplexity3.290480375289917

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.02s/it]
INFO:root:final mean train loss: 1510.413744981759
INFO:root:final train perplexity: 3.2910382747650146
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.98s/it]
INFO:root:eval mean loss: 2085.2907680213875
INFO:root:eval perplexity: 5.400333404541016
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.09s/it]
INFO:root:eval mean loss: 2608.7390197321033
INFO:root:eval perplexity: 8.444356918334961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [14:06:57<20:55:10, 627.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1493.0899327164989
INFO:root:current train perplexity3.2348575592041016
INFO:root:current mean train loss 1489.830632431702
INFO:root:current train perplexity3.2342348098754883
INFO:root:current mean train loss 1491.0390643852559
INFO:root:current train perplexity3.2461819648742676
INFO:root:current mean train loss 1496.2278161859115
INFO:root:current train perplexity3.2524712085723877
INFO:root:current mean train loss 1496.4564945661425
INFO:root:current train perplexity3.2553720474243164
INFO:root:current mean train loss 1497.4184201262717
INFO:root:current train perplexity3.251763343811035
INFO:root:current mean train loss 1499.0568436433043
INFO:root:current train perplexity3.255242347717285
INFO:root:current mean train loss 1498.9496304759552
INFO:root:current train perplexity3.257556438446045
INFO:root:current mean train loss 1498.4498933341367
INFO:root:current train perplexity3.259760856628418
INFO:root:current mean train loss 1499.8722878496887
INFO:root:current train perplexity3.262941837310791
INFO:root:current mean train loss 1500.502117383919
INFO:root:current train perplexity3.2641406059265137
INFO:root:current mean train loss 1501.002078460351
INFO:root:current train perplexity3.2656354904174805
INFO:root:current mean train loss 1502.4898127039999
INFO:root:current train perplexity3.2677290439605713
INFO:root:current mean train loss 1503.5176065990906
INFO:root:current train perplexity3.2702085971832275
INFO:root:current mean train loss 1504.2672078143742
INFO:root:current train perplexity3.271543264389038
INFO:root:current mean train loss 1504.5830410118665
INFO:root:current train perplexity3.2739813327789307
INFO:root:current mean train loss 1505.5352154088494
INFO:root:current train perplexity3.2750086784362793
INFO:root:current mean train loss 1505.8305818125089
INFO:root:current train perplexity3.277501344680786
INFO:root:current mean train loss 1505.56522192501
INFO:root:current train perplexity3.2778048515319824
INFO:root:current mean train loss 1506.3104908560051
INFO:root:current train perplexity3.280191659927368

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.16s/it]
INFO:root:final mean train loss: 1506.3923264742498
INFO:root:final train perplexity: 3.2806174755096436
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.09s/it]
INFO:root:eval mean loss: 2086.5185070714206
INFO:root:eval perplexity: 5.405698776245117
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it]
INFO:root:eval mean loss: 2611.262511341284
INFO:root:eval perplexity: 8.46180248260498
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [14:17:28<20:46:42, 628.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1485.594731381065
INFO:root:current train perplexity3.2404632568359375
INFO:root:current mean train loss 1492.3714356855912
INFO:root:current train perplexity3.241640329360962
INFO:root:current mean train loss 1489.2874264924424
INFO:root:current train perplexity3.236948251724243
INFO:root:current mean train loss 1490.162315855635
INFO:root:current train perplexity3.2405149936676025
INFO:root:current mean train loss 1492.1960680023963
INFO:root:current train perplexity3.239586353302002
INFO:root:current mean train loss 1495.4128108554416
INFO:root:current train perplexity3.2429139614105225
INFO:root:current mean train loss 1496.0322234926844
INFO:root:current train perplexity3.2465224266052246
INFO:root:current mean train loss 1496.4977243954374
INFO:root:current train perplexity3.247589588165283
INFO:root:current mean train loss 1497.44845873689
INFO:root:current train perplexity3.2504019737243652
INFO:root:current mean train loss 1498.234901928511
INFO:root:current train perplexity3.251560688018799
INFO:root:current mean train loss 1498.0910154434828
INFO:root:current train perplexity3.2535312175750732
INFO:root:current mean train loss 1498.8219528717248
INFO:root:current train perplexity3.2559854984283447
INFO:root:current mean train loss 1500.3606045044328
INFO:root:current train perplexity3.2596516609191895
INFO:root:current mean train loss 1500.0264301743618
INFO:root:current train perplexity3.2595057487487793
INFO:root:current mean train loss 1499.0828261956935
INFO:root:current train perplexity3.259988307952881
INFO:root:current mean train loss 1499.9202663208628
INFO:root:current train perplexity3.2621867656707764
INFO:root:current mean train loss 1499.9422056066107
INFO:root:current train perplexity3.26320481300354
INFO:root:current mean train loss 1499.8849585593284
INFO:root:current train perplexity3.26399827003479
INFO:root:current mean train loss 1500.9197640815523
INFO:root:current train perplexity3.2660319805145264
INFO:root:current mean train loss 1501.6811451159026
INFO:root:current train perplexity3.2675938606262207

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.68s/it]
INFO:root:final mean train loss: 1501.338877744766
INFO:root:final train perplexity: 3.267568588256836
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.22s/it]
INFO:root:eval mean loss: 2091.0555324689717
INFO:root:eval perplexity: 5.425570011138916
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.72s/it]
INFO:root:eval mean loss: 2616.8417869189107
INFO:root:eval perplexity: 8.500500679016113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [14:28:07<20:42:17, 631.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1479.9864278813843
INFO:root:current train perplexity3.212830066680908
INFO:root:current mean train loss 1483.678764066548
INFO:root:current train perplexity3.2263994216918945
INFO:root:current mean train loss 1485.9733061806742
INFO:root:current train perplexity3.2311487197875977
INFO:root:current mean train loss 1488.5038254910146
INFO:root:current train perplexity3.231961250305176
INFO:root:current mean train loss 1489.6053684691144
INFO:root:current train perplexity3.2334845066070557
INFO:root:current mean train loss 1493.5995572944114
INFO:root:current train perplexity3.241534948348999
INFO:root:current mean train loss 1491.6182109177714
INFO:root:current train perplexity3.242946147918701
INFO:root:current mean train loss 1492.3162710952279
INFO:root:current train perplexity3.2455461025238037
INFO:root:current mean train loss 1492.1650318175655
INFO:root:current train perplexity3.243720531463623
INFO:root:current mean train loss 1493.32938651616
INFO:root:current train perplexity3.2445342540740967
INFO:root:current mean train loss 1494.2930215764025
INFO:root:current train perplexity3.2458577156066895
INFO:root:current mean train loss 1494.3159704600075
INFO:root:current train perplexity3.247663974761963
INFO:root:current mean train loss 1493.3681639680915
INFO:root:current train perplexity3.2468600273132324
INFO:root:current mean train loss 1493.5290995294554
INFO:root:current train perplexity3.2477118968963623
INFO:root:current mean train loss 1493.745404498336
INFO:root:current train perplexity3.24768328666687
INFO:root:current mean train loss 1494.8023121481187
INFO:root:current train perplexity3.247527599334717
INFO:root:current mean train loss 1494.9044929950533
INFO:root:current train perplexity3.2498347759246826
INFO:root:current mean train loss 1495.0882646653217
INFO:root:current train perplexity3.250821590423584
INFO:root:current mean train loss 1495.7051276495642
INFO:root:current train perplexity3.2516324520111084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:29<00:00, 569.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:29<00:00, 569.74s/it]
INFO:root:final mean train loss: 1495.5760490659866
INFO:root:final train perplexity: 3.252751350402832
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it]
INFO:root:eval mean loss: 2094.085236245013
INFO:root:eval perplexity: 5.43887996673584
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.97s/it]
INFO:root:eval mean loss: 2622.3751324592754
INFO:root:eval perplexity: 8.539055824279785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [14:38:54<20:40:54, 636.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1454.4430053710937
INFO:root:current train perplexity3.1773998737335205
INFO:root:current mean train loss 1472.5617353959517
INFO:root:current train perplexity3.1976025104522705
INFO:root:current mean train loss 1477.4960199265254
INFO:root:current train perplexity3.2032439708709717
INFO:root:current mean train loss 1478.9255540417087
INFO:root:current train perplexity3.2043848037719727
INFO:root:current mean train loss 1476.9476482112234
INFO:root:current train perplexity3.203512191772461
INFO:root:current mean train loss 1478.795412310432
INFO:root:current train perplexity3.207756996154785
INFO:root:current mean train loss 1478.6985459624743
INFO:root:current train perplexity3.212327480316162
INFO:root:current mean train loss 1479.467178215779
INFO:root:current train perplexity3.2166192531585693
INFO:root:current mean train loss 1480.3008608217592
INFO:root:current train perplexity3.2196173667907715
INFO:root:current mean train loss 1481.0962882576407
INFO:root:current train perplexity3.222365379333496
INFO:root:current mean train loss 1483.7004531104967
INFO:root:current train perplexity3.224249839782715
INFO:root:current mean train loss 1484.5887362093538
INFO:root:current train perplexity3.2266721725463867
INFO:root:current mean train loss 1485.552282210421
INFO:root:current train perplexity3.2280426025390625
INFO:root:current mean train loss 1485.9526055022961
INFO:root:current train perplexity3.230489492416382
INFO:root:current mean train loss 1486.8648416722074
INFO:root:current train perplexity3.2335197925567627
INFO:root:current mean train loss 1487.8174473238307
INFO:root:current train perplexity3.2346527576446533
INFO:root:current mean train loss 1488.4807202451718
INFO:root:current train perplexity3.2360968589782715
INFO:root:current mean train loss 1488.3528392412509
INFO:root:current train perplexity3.2370810508728027
INFO:root:current mean train loss 1490.0827066832485
INFO:root:current train perplexity3.23983097076416
INFO:root:current mean train loss 1491.3308086295403
INFO:root:current train perplexity3.2411880493164062

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:29<00:00, 569.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:29<00:00, 569.88s/it]
INFO:root:final mean train loss: 1492.0469478851487
INFO:root:final train perplexity: 3.24371075630188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it]
INFO:root:eval mean loss: 2096.4398219331783
INFO:root:eval perplexity: 5.449246406555176
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.21s/it]
INFO:root:eval mean loss: 2623.254497555131
INFO:root:eval perplexity: 8.545198440551758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [14:49:39<20:35:03, 638.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1464.1699987340855
INFO:root:current train perplexity3.2025766372680664
INFO:root:current mean train loss 1475.5073271023007
INFO:root:current train perplexity3.202336072921753
INFO:root:current mean train loss 1480.8611490526914
INFO:root:current train perplexity3.206615447998047
INFO:root:current mean train loss 1477.2206732607033
INFO:root:current train perplexity3.2084856033325195
INFO:root:current mean train loss 1478.489108583687
INFO:root:current train perplexity3.2088427543640137
INFO:root:current mean train loss 1479.2776008620433
INFO:root:current train perplexity3.2082066535949707
INFO:root:current mean train loss 1480.3069657564542
INFO:root:current train perplexity3.209963321685791
INFO:root:current mean train loss 1482.703924753643
INFO:root:current train perplexity3.21399188041687
INFO:root:current mean train loss 1483.2452616939522
INFO:root:current train perplexity3.2156903743743896
INFO:root:current mean train loss 1481.8869784292408
INFO:root:current train perplexity3.213353157043457
INFO:root:current mean train loss 1482.3932091583877
INFO:root:current train perplexity3.2146501541137695
INFO:root:current mean train loss 1484.6276202333006
INFO:root:current train perplexity3.2171738147735596
INFO:root:current mean train loss 1484.7472972419073
INFO:root:current train perplexity3.2190191745758057
INFO:root:current mean train loss 1485.4608507537266
INFO:root:current train perplexity3.2214536666870117
INFO:root:current mean train loss 1486.027689259455
INFO:root:current train perplexity3.2223124504089355
INFO:root:current mean train loss 1486.23014786576
INFO:root:current train perplexity3.2247262001037598
INFO:root:current mean train loss 1485.7048121512705
INFO:root:current train perplexity3.224154233932495
INFO:root:current mean train loss 1486.1390460024836
INFO:root:current train perplexity3.2264859676361084
INFO:root:current mean train loss 1486.8247153830775
INFO:root:current train perplexity3.2288315296173096
INFO:root:current mean train loss 1487.5930854231196
INFO:root:current train perplexity3.230564594268799

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.25s/it]
INFO:root:final mean train loss: 1487.1964184890417
INFO:root:final train perplexity: 3.23132586479187
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.66s/it]
INFO:root:eval mean loss: 2100.79209261414
INFO:root:eval perplexity: 5.468461036682129
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.33s/it]
INFO:root:eval mean loss: 2629.3034702598625
INFO:root:eval perplexity: 8.587577819824219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [15:00:19<20:24:48, 639.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1469.2270757501776
INFO:root:current train perplexity3.1909496784210205
INFO:root:current mean train loss 1474.1333847045898
INFO:root:current train perplexity3.208312749862671
INFO:root:current mean train loss 1476.8775399630188
INFO:root:current train perplexity3.214299440383911
INFO:root:current mean train loss 1477.4163910621821
INFO:root:current train perplexity3.2085883617401123
INFO:root:current mean train loss 1479.3272256937114
INFO:root:current train perplexity3.2114615440368652
INFO:root:current mean train loss 1478.8203946281883
INFO:root:current train perplexity3.20912504196167
INFO:root:current mean train loss 1480.5496134313737
INFO:root:current train perplexity3.210818290710449
INFO:root:current mean train loss 1482.7019166023501
INFO:root:current train perplexity3.2131035327911377
INFO:root:current mean train loss 1482.8623707848137
INFO:root:current train perplexity3.212307929992676
INFO:root:current mean train loss 1481.9053571022164
INFO:root:current train perplexity3.209529161453247
INFO:root:current mean train loss 1481.3184910332106
INFO:root:current train perplexity3.2102150917053223
INFO:root:current mean train loss 1481.5022818825462
INFO:root:current train perplexity3.212162971496582
INFO:root:current mean train loss 1482.532206544539
INFO:root:current train perplexity3.2134509086608887
INFO:root:current mean train loss 1482.9075298309326
INFO:root:current train perplexity3.2144250869750977
INFO:root:current mean train loss 1483.8218841975415
INFO:root:current train perplexity3.2163846492767334
INFO:root:current mean train loss 1483.700088896282
INFO:root:current train perplexity3.2166388034820557
INFO:root:current mean train loss 1483.484684482398
INFO:root:current train perplexity3.217529296875
INFO:root:current mean train loss 1483.3761707970855
INFO:root:current train perplexity3.219067096710205
INFO:root:current mean train loss 1483.2906794682501
INFO:root:current train perplexity3.220233917236328
INFO:root:current mean train loss 1483.5323188687548
INFO:root:current train perplexity3.221616506576538

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.85s/it]
INFO:root:final mean train loss: 1483.412405040008
INFO:root:final train perplexity: 3.2216970920562744
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it]
INFO:root:eval mean loss: 2101.6377602435173
INFO:root:eval perplexity: 5.472203254699707
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.19s/it]
INFO:root:eval mean loss: 2635.843282929549
INFO:root:eval perplexity: 8.633630752563477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [15:10:57<20:13:50, 638.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1460.8958380026895
INFO:root:current train perplexity3.160914897918701
INFO:root:current mean train loss 1463.0967418599573
INFO:root:current train perplexity3.1798408031463623
INFO:root:current mean train loss 1466.0485970800407
INFO:root:current train perplexity3.186572313308716
INFO:root:current mean train loss 1467.6417209276533
INFO:root:current train perplexity3.1887288093566895
INFO:root:current mean train loss 1468.3159600710921
INFO:root:current train perplexity3.1901679039001465
INFO:root:current mean train loss 1468.0748506433824
INFO:root:current train perplexity3.1933434009552
INFO:root:current mean train loss 1468.7575932905281
INFO:root:current train perplexity3.1908645629882812
INFO:root:current mean train loss 1471.6270673353317
INFO:root:current train perplexity3.1972618103027344
INFO:root:current mean train loss 1472.4972089707644
INFO:root:current train perplexity3.198951005935669
INFO:root:current mean train loss 1472.8611341589572
INFO:root:current train perplexity3.200749158859253
INFO:root:current mean train loss 1473.4564185973948
INFO:root:current train perplexity3.2012102603912354
INFO:root:current mean train loss 1474.7985000807494
INFO:root:current train perplexity3.2025346755981445
INFO:root:current mean train loss 1474.9875039108965
INFO:root:current train perplexity3.2032766342163086
INFO:root:current mean train loss 1476.0401869640027
INFO:root:current train perplexity3.203291416168213
INFO:root:current mean train loss 1477.0563940613504
INFO:root:current train perplexity3.2049736976623535
INFO:root:current mean train loss 1476.9335512873608
INFO:root:current train perplexity3.20379638671875
INFO:root:current mean train loss 1476.6924286715457
INFO:root:current train perplexity3.204298496246338
INFO:root:current mean train loss 1477.4578143438787
INFO:root:current train perplexity3.2062900066375732
INFO:root:current mean train loss 1478.6145089060822
INFO:root:current train perplexity3.21042799949646
INFO:root:current mean train loss 1479.8801714611686
INFO:root:current train perplexity3.21134614944458

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.69s/it]
INFO:root:final mean train loss: 1479.320641344987
INFO:root:final train perplexity: 3.211317539215088
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.34s/it]
INFO:root:eval mean loss: 2104.9293195575688
INFO:root:eval perplexity: 5.486789226531982
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.46s/it]
INFO:root:eval mean loss: 2636.221295728751
INFO:root:eval perplexity: 8.636301040649414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [15:21:44<20:07:40, 641.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1457.5973307291667
INFO:root:current train perplexity3.150033950805664
INFO:root:current mean train loss 1473.7928734254301
INFO:root:current train perplexity3.180886745452881
INFO:root:current mean train loss 1467.6314363548224
INFO:root:current train perplexity3.173069953918457
INFO:root:current mean train loss 1468.6289750356523
INFO:root:current train perplexity3.1734988689422607
INFO:root:current mean train loss 1468.9551649532557
INFO:root:current train perplexity3.1771771907806396
INFO:root:current mean train loss 1468.6753043732429
INFO:root:current train perplexity3.1760873794555664
INFO:root:current mean train loss 1469.2856342687016
INFO:root:current train perplexity3.177947998046875
INFO:root:current mean train loss 1469.846960229555
INFO:root:current train perplexity3.180222511291504
INFO:root:current mean train loss 1469.6090959622811
INFO:root:current train perplexity3.1843442916870117
INFO:root:current mean train loss 1471.1673817390802
INFO:root:current train perplexity3.1889350414276123
INFO:root:current mean train loss 1470.4397970280975
INFO:root:current train perplexity3.189908742904663
INFO:root:current mean train loss 1471.862786854872
INFO:root:current train perplexity3.1905548572540283
INFO:root:current mean train loss 1472.0450027776249
INFO:root:current train perplexity3.1919009685516357
INFO:root:current mean train loss 1472.5526610265103
INFO:root:current train perplexity3.192481279373169
INFO:root:current mean train loss 1473.286770088908
INFO:root:current train perplexity3.192814350128174
INFO:root:current mean train loss 1472.9209149146714
INFO:root:current train perplexity3.192772388458252
INFO:root:current mean train loss 1474.0408798781566
INFO:root:current train perplexity3.1953070163726807
INFO:root:current mean train loss 1474.1817104481202
INFO:root:current train perplexity3.1959357261657715
INFO:root:current mean train loss 1474.3729001046243
INFO:root:current train perplexity3.197377920150757
INFO:root:current mean train loss 1474.8030813311664
INFO:root:current train perplexity3.1989591121673584

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.08s/it]
INFO:root:final mean train loss: 1474.4615785384262
INFO:root:final train perplexity: 3.1990346908569336
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it]
INFO:root:eval mean loss: 2106.9111921161625
INFO:root:eval perplexity: 5.4955902099609375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it]
INFO:root:eval mean loss: 2637.9705014059728
INFO:root:eval perplexity: 8.648664474487305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [15:32:22<19:55:07, 640.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1462.4192819695725
INFO:root:current train perplexity3.1679611206054688
INFO:root:current mean train loss 1457.8042211288061
INFO:root:current train perplexity3.1586763858795166
INFO:root:current mean train loss 1460.2012020822299
INFO:root:current train perplexity3.159583568572998
INFO:root:current mean train loss 1457.1758294600475
INFO:root:current train perplexity3.1613337993621826
INFO:root:current mean train loss 1459.9407769097222
INFO:root:current train perplexity3.163419485092163
INFO:root:current mean train loss 1461.2721435546875
INFO:root:current train perplexity3.165099859237671
INFO:root:current mean train loss 1462.3754647453911
INFO:root:current train perplexity3.169203042984009
INFO:root:current mean train loss 1463.344446952388
INFO:root:current train perplexity3.170287847518921
INFO:root:current mean train loss 1465.7435385933136
INFO:root:current train perplexity3.170586585998535
INFO:root:current mean train loss 1465.384761944488
INFO:root:current train perplexity3.174118757247925
INFO:root:current mean train loss 1466.8488718250571
INFO:root:current train perplexity3.1753714084625244
INFO:root:current mean train loss 1467.0760949553805
INFO:root:current train perplexity3.178393602371216
INFO:root:current mean train loss 1467.3203683978343
INFO:root:current train perplexity3.1784915924072266
INFO:root:current mean train loss 1468.3813508064516
INFO:root:current train perplexity3.179706335067749
INFO:root:current mean train loss 1468.3427424095944
INFO:root:current train perplexity3.1807923316955566
INFO:root:current mean train loss 1468.2388642027086
INFO:root:current train perplexity3.1829371452331543
INFO:root:current mean train loss 1468.6531755565543
INFO:root:current train perplexity3.183039426803589
INFO:root:current mean train loss 1468.8254006898503
INFO:root:current train perplexity3.183887243270874
INFO:root:current mean train loss 1469.1074214884977
INFO:root:current train perplexity3.1849749088287354

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.86s/it]
INFO:root:final mean train loss: 1469.5711679155636
INFO:root:final train perplexity: 3.1867198944091797
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it]
INFO:root:eval mean loss: 2111.462164696227
INFO:root:eval perplexity: 5.51585578918457
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.68s/it]
INFO:root:eval mean loss: 2647.217380821282
INFO:root:eval perplexity: 8.714314460754395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [15:42:55<19:40:39, 638.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1488.5982869466145
INFO:root:current train perplexity3.139914035797119
INFO:root:current mean train loss 1452.6211776733398
INFO:root:current train perplexity3.1317408084869385
INFO:root:current mean train loss 1454.9280637345223
INFO:root:current train perplexity3.137563467025757
INFO:root:current mean train loss 1454.0116389347957
INFO:root:current train perplexity3.1437339782714844
INFO:root:current mean train loss 1455.282928763084
INFO:root:current train perplexity3.1493380069732666
INFO:root:current mean train loss 1457.819084405899
INFO:root:current train perplexity3.1560428142547607
INFO:root:current mean train loss 1459.8932521047157
INFO:root:current train perplexity3.1572306156158447
INFO:root:current mean train loss 1459.1544033436294
INFO:root:current train perplexity3.1582565307617188
INFO:root:current mean train loss 1459.1009168202067
INFO:root:current train perplexity3.162665367126465
INFO:root:current mean train loss 1460.702218440541
INFO:root:current train perplexity3.1668548583984375
INFO:root:current mean train loss 1461.7205606694279
INFO:root:current train perplexity3.1673946380615234
INFO:root:current mean train loss 1462.2902488434058
INFO:root:current train perplexity3.166959524154663
INFO:root:current mean train loss 1463.3168917111439
INFO:root:current train perplexity3.168522834777832
INFO:root:current mean train loss 1463.3771406034143
INFO:root:current train perplexity3.168869972229004
INFO:root:current mean train loss 1464.0698690009185
INFO:root:current train perplexity3.1706020832061768
INFO:root:current mean train loss 1464.6405084196222
INFO:root:current train perplexity3.1722822189331055
INFO:root:current mean train loss 1465.1627105637165
INFO:root:current train perplexity3.175013780593872
INFO:root:current mean train loss 1465.6938636993693
INFO:root:current train perplexity3.1765570640563965
INFO:root:current mean train loss 1465.7653654321666
INFO:root:current train perplexity3.176044464111328
INFO:root:current mean train loss 1466.0166411459695
INFO:root:current train perplexity3.177152156829834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.95s/it]
INFO:root:final mean train loss: 1465.7209334149843
INFO:root:final train perplexity: 3.177058219909668
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.32s/it]
INFO:root:eval mean loss: 2113.6815930089206
INFO:root:eval perplexity: 5.525764465332031
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.67s/it]
INFO:root:eval mean loss: 2649.444645442016
INFO:root:eval perplexity: 8.730202674865723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [15:53:28<19:27:14, 636.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1427.781839304957
INFO:root:current train perplexity3.1386826038360596
INFO:root:current mean train loss 1450.7384960558988
INFO:root:current train perplexity3.1475746631622314
INFO:root:current mean train loss 1452.7829056785617
INFO:root:current train perplexity3.157644271850586
INFO:root:current mean train loss 1450.4924205095936
INFO:root:current train perplexity3.1524131298065186
INFO:root:current mean train loss 1454.3685220215982
INFO:root:current train perplexity3.1519417762756348
INFO:root:current mean train loss 1454.3760487893578
INFO:root:current train perplexity3.145087242126465
INFO:root:current mean train loss 1455.1496954646511
INFO:root:current train perplexity3.146658420562744
INFO:root:current mean train loss 1455.217170621142
INFO:root:current train perplexity3.148334264755249
INFO:root:current mean train loss 1455.2984038975328
INFO:root:current train perplexity3.148420572280884
INFO:root:current mean train loss 1455.9841637092977
INFO:root:current train perplexity3.149165153503418
INFO:root:current mean train loss 1456.9088189335444
INFO:root:current train perplexity3.1524529457092285
INFO:root:current mean train loss 1457.078294319849
INFO:root:current train perplexity3.15450119972229
INFO:root:current mean train loss 1458.2695255884803
INFO:root:current train perplexity3.1574385166168213
INFO:root:current mean train loss 1458.4691615854554
INFO:root:current train perplexity3.1590163707733154
INFO:root:current mean train loss 1459.6700875113443
INFO:root:current train perplexity3.1617541313171387
INFO:root:current mean train loss 1460.5753847649862
INFO:root:current train perplexity3.1629159450531006
INFO:root:current mean train loss 1461.5283079481037
INFO:root:current train perplexity3.1639111042022705
INFO:root:current mean train loss 1461.5325002852308
INFO:root:current train perplexity3.1639344692230225
INFO:root:current mean train loss 1461.4250501629563
INFO:root:current train perplexity3.164971113204956
INFO:root:current mean train loss 1462.0327187039309
INFO:root:current train perplexity3.166790723800659

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.40s/it]
INFO:root:final mean train loss: 1461.7488278048963
INFO:root:final train perplexity: 3.167120933532715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it]
INFO:root:eval mean loss: 2116.1847088320037
INFO:root:eval perplexity: 5.536961555480957
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it]
INFO:root:eval mean loss: 2652.5319356715427
INFO:root:eval perplexity: 8.752272605895996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [16:04:03<19:15:24, 636.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1431.6277970023777
INFO:root:current train perplexity3.0997846126556396
INFO:root:current mean train loss 1436.571535711419
INFO:root:current train perplexity3.1184866428375244
INFO:root:current mean train loss 1438.6067157528264
INFO:root:current train perplexity3.1158125400543213
INFO:root:current mean train loss 1439.7601533570041
INFO:root:current train perplexity3.1223626136779785
INFO:root:current mean train loss 1442.9736210433891
INFO:root:current train perplexity3.12488055229187
INFO:root:current mean train loss 1445.9762655963827
INFO:root:current train perplexity3.134476661682129
INFO:root:current mean train loss 1447.3072214982826
INFO:root:current train perplexity3.134871244430542
INFO:root:current mean train loss 1450.015598982333
INFO:root:current train perplexity3.1389784812927246
INFO:root:current mean train loss 1449.8463019332705
INFO:root:current train perplexity3.140974998474121
INFO:root:current mean train loss 1450.3169869227338
INFO:root:current train perplexity3.1427061557769775
INFO:root:current mean train loss 1452.6825591865963
INFO:root:current train perplexity3.1446080207824707
INFO:root:current mean train loss 1452.4501615461047
INFO:root:current train perplexity3.1456058025360107
INFO:root:current mean train loss 1453.22474437732
INFO:root:current train perplexity3.1462225914001465
INFO:root:current mean train loss 1454.1773815863553
INFO:root:current train perplexity3.1477224826812744
INFO:root:current mean train loss 1455.2099175459782
INFO:root:current train perplexity3.1489293575286865
INFO:root:current mean train loss 1455.4403067486408
INFO:root:current train perplexity3.1500046253204346
INFO:root:current mean train loss 1456.400722499027
INFO:root:current train perplexity3.152496814727783
INFO:root:current mean train loss 1456.3739420572917
INFO:root:current train perplexity3.153193235397339
INFO:root:current mean train loss 1456.6332255949308
INFO:root:current train perplexity3.1542372703552246
INFO:root:current mean train loss 1457.649283461066
INFO:root:current train perplexity3.15644907951355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.91s/it]
INFO:root:final mean train loss: 1457.7300929667308
INFO:root:final train perplexity: 3.157099723815918
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.74s/it]
INFO:root:eval mean loss: 2120.7136195838875
INFO:root:eval perplexity: 5.557278633117676
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.51s/it]
INFO:root:eval mean loss: 2657.9171978023883
INFO:root:eval perplexity: 8.790905952453613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [16:14:39<19:05:01, 636.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1435.9619876922122
INFO:root:current train perplexity3.1267592906951904
INFO:root:current mean train loss 1439.8886396724022
INFO:root:current train perplexity3.1357696056365967
INFO:root:current mean train loss 1444.0993954038438
INFO:root:current train perplexity3.1354384422302246
INFO:root:current mean train loss 1445.4317025008609
INFO:root:current train perplexity3.135810136795044
INFO:root:current mean train loss 1443.9523954782835
INFO:root:current train perplexity3.129368543624878
INFO:root:current mean train loss 1443.7325101212116
INFO:root:current train perplexity3.129873275756836
INFO:root:current mean train loss 1445.5855957767722
INFO:root:current train perplexity3.1334195137023926
INFO:root:current mean train loss 1446.660153690203
INFO:root:current train perplexity3.13342547416687
INFO:root:current mean train loss 1447.9925150954157
INFO:root:current train perplexity3.1348507404327393
INFO:root:current mean train loss 1448.701097339856
INFO:root:current train perplexity3.13495135307312
INFO:root:current mean train loss 1450.581530566498
INFO:root:current train perplexity3.136836290359497
INFO:root:current mean train loss 1451.269944798608
INFO:root:current train perplexity3.1382594108581543
INFO:root:current mean train loss 1452.1975438834559
INFO:root:current train perplexity3.140603542327881
INFO:root:current mean train loss 1452.8354692801954
INFO:root:current train perplexity3.1414289474487305
INFO:root:current mean train loss 1452.7413907471537
INFO:root:current train perplexity3.1428236961364746
INFO:root:current mean train loss 1453.1716150831735
INFO:root:current train perplexity3.14327335357666
INFO:root:current mean train loss 1453.1289018457794
INFO:root:current train perplexity3.1450133323669434
INFO:root:current mean train loss 1453.6621859545608
INFO:root:current train perplexity3.1462574005126953
INFO:root:current mean train loss 1454.1594297252416
INFO:root:current train perplexity3.1470742225646973
INFO:root:current mean train loss 1454.4204545567611
INFO:root:current train perplexity3.1475486755371094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.26s/it]
INFO:root:final mean train loss: 1454.0598215938996
INFO:root:final train perplexity: 3.1479735374450684
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it]
INFO:root:eval mean loss: 2123.3035914644283
INFO:root:eval perplexity: 5.568931579589844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.70s/it]
INFO:root:eval mean loss: 2661.215586560838
INFO:root:eval perplexity: 8.814650535583496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [16:25:02<18:47:29, 632.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1433.2820571899415
INFO:root:current train perplexity3.099984645843506
INFO:root:current mean train loss 1441.3542622884115
INFO:root:current train perplexity3.1056692600250244
INFO:root:current mean train loss 1442.5738237653459
INFO:root:current train perplexity3.111423969268799
INFO:root:current mean train loss 1443.1060688219573
INFO:root:current train perplexity3.1111843585968018
INFO:root:current mean train loss 1442.1481493631998
INFO:root:current train perplexity3.115363121032715
INFO:root:current mean train loss 1442.6652930950297
INFO:root:current train perplexity3.1176681518554688
INFO:root:current mean train loss 1443.6663981718175
INFO:root:current train perplexity3.119014263153076
INFO:root:current mean train loss 1444.168823868189
INFO:root:current train perplexity3.1197001934051514
INFO:root:current mean train loss 1444.0829900568183
INFO:root:current train perplexity3.122264862060547
INFO:root:current mean train loss 1445.8158842125717
INFO:root:current train perplexity3.125230073928833
INFO:root:current mean train loss 1446.2751609519676
INFO:root:current train perplexity3.1271231174468994
INFO:root:current mean train loss 1447.3121779619637
INFO:root:current train perplexity3.1291003227233887
INFO:root:current mean train loss 1447.5292353630066
INFO:root:current train perplexity3.1306021213531494
INFO:root:current mean train loss 1448.089755204795
INFO:root:current train perplexity3.1306912899017334
INFO:root:current mean train loss 1448.509213091876
INFO:root:current train perplexity3.1331777572631836
INFO:root:current mean train loss 1449.5510535131527
INFO:root:current train perplexity3.1350810527801514
INFO:root:current mean train loss 1450.1492105393183
INFO:root:current train perplexity3.136610269546509
INFO:root:current mean train loss 1450.5389443386807
INFO:root:current train perplexity3.137657403945923
INFO:root:current mean train loss 1450.5590151523022
INFO:root:current train perplexity3.137953996658325
INFO:root:current mean train loss 1450.7591045957622
INFO:root:current train perplexity3.138845920562744

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.62s/it]
INFO:root:final mean train loss: 1450.4279967984705
INFO:root:final train perplexity: 3.138969898223877
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.16s/it]
INFO:root:eval mean loss: 2125.582335560034
INFO:root:eval perplexity: 5.579204082489014
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.47s/it]
INFO:root:eval mean loss: 2664.0107023631426
INFO:root:eval perplexity: 8.834821701049805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [16:35:32<18:35:31, 631.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1433.4567317372746
INFO:root:current train perplexity3.1102190017700195
INFO:root:current mean train loss 1437.2367265575429
INFO:root:current train perplexity3.113323450088501
INFO:root:current mean train loss 1435.7047230113637
INFO:root:current train perplexity3.111968755722046
INFO:root:current mean train loss 1435.1478794203597
INFO:root:current train perplexity3.1080100536346436
INFO:root:current mean train loss 1434.524794764682
INFO:root:current train perplexity3.1109068393707275
INFO:root:current mean train loss 1435.6212704145728
INFO:root:current train perplexity3.1137819290161133
INFO:root:current mean train loss 1436.5997379253722
INFO:root:current train perplexity3.114779472351074
INFO:root:current mean train loss 1440.0156504249333
INFO:root:current train perplexity3.118976593017578
INFO:root:current mean train loss 1442.0398899108138
INFO:root:current train perplexity3.1213362216949463
INFO:root:current mean train loss 1442.3590035242446
INFO:root:current train perplexity3.122088670730591
INFO:root:current mean train loss 1443.262071941588
INFO:root:current train perplexity3.12259578704834
INFO:root:current mean train loss 1443.976755446559
INFO:root:current train perplexity3.1229958534240723
INFO:root:current mean train loss 1444.4886484962292
INFO:root:current train perplexity3.1241655349731445
INFO:root:current mean train loss 1444.5883159924167
INFO:root:current train perplexity3.1228413581848145
INFO:root:current mean train loss 1444.9310043426697
INFO:root:current train perplexity3.1229376792907715
INFO:root:current mean train loss 1445.717846358651
INFO:root:current train perplexity3.1242690086364746
INFO:root:current mean train loss 1445.2887396646656
INFO:root:current train perplexity3.125493049621582
INFO:root:current mean train loss 1446.2582145100776
INFO:root:current train perplexity3.1279187202453613
INFO:root:current mean train loss 1446.332596621516
INFO:root:current train perplexity3.1277005672454834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.66s/it]
INFO:root:final mean train loss: 1446.0311341778654
INFO:root:final train perplexity: 3.1281044483184814
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it]
INFO:root:eval mean loss: 2129.5965225544383
INFO:root:eval perplexity: 5.597347259521484
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.71s/it]
INFO:root:eval mean loss: 2669.0175837523548
INFO:root:eval perplexity: 8.871075630187988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [16:45:55<18:20:28, 628.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1461.967529296875
INFO:root:current train perplexity3.1115810871124268
INFO:root:current mean train loss 1431.889926843476
INFO:root:current train perplexity3.1123721599578857
INFO:root:current mean train loss 1435.9492216021101
INFO:root:current train perplexity3.0967869758605957
INFO:root:current mean train loss 1435.3563671719496
INFO:root:current train perplexity3.1009418964385986
INFO:root:current mean train loss 1435.5099357568124
INFO:root:current train perplexity3.0961101055145264
INFO:root:current mean train loss 1435.7061268847276
INFO:root:current train perplexity3.0969362258911133
INFO:root:current mean train loss 1434.6274513468293
INFO:root:current train perplexity3.098339796066284
INFO:root:current mean train loss 1435.0855654761904
INFO:root:current train perplexity3.0990405082702637
INFO:root:current mean train loss 1436.7308019689613
INFO:root:current train perplexity3.102299928665161
INFO:root:current mean train loss 1437.5577289739897
INFO:root:current train perplexity3.104526996612549
INFO:root:current mean train loss 1437.687656018861
INFO:root:current train perplexity3.1066319942474365
INFO:root:current mean train loss 1438.4368780331295
INFO:root:current train perplexity3.106072187423706
INFO:root:current mean train loss 1438.2839088000026
INFO:root:current train perplexity3.1070549488067627
INFO:root:current mean train loss 1439.0204226234007
INFO:root:current train perplexity3.1092066764831543
INFO:root:current mean train loss 1440.362642495939
INFO:root:current train perplexity3.1100573539733887
INFO:root:current mean train loss 1440.5816708442558
INFO:root:current train perplexity3.1120681762695312
INFO:root:current mean train loss 1440.9340106344873
INFO:root:current train perplexity3.1137378215789795
INFO:root:current mean train loss 1441.0797217423608
INFO:root:current train perplexity3.115269899368286
INFO:root:current mean train loss 1441.5787179225597
INFO:root:current train perplexity3.116311550140381
INFO:root:current mean train loss 1442.216178933904
INFO:root:current train perplexity3.117793321609497

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.37s/it]
INFO:root:final mean train loss: 1442.0796482934534
INFO:root:final train perplexity: 3.11837100982666
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.82s/it]
INFO:root:eval mean loss: 2132.1412288584606
INFO:root:eval perplexity: 5.608877182006836
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.53s/it]
INFO:root:eval mean loss: 2674.827448851673
INFO:root:eval perplexity: 8.913326263427734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [16:56:33<18:14:42, 631.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1420.3646752142138
INFO:root:current train perplexity3.0301923751831055
INFO:root:current mean train loss 1425.2186400435353
INFO:root:current train perplexity3.065218210220337
INFO:root:current mean train loss 1430.4090803402328
INFO:root:current train perplexity3.0788214206695557
INFO:root:current mean train loss 1430.1617151358337
INFO:root:current train perplexity3.0810599327087402
INFO:root:current mean train loss 1428.8611964250108
INFO:root:current train perplexity3.072983741760254
INFO:root:current mean train loss 1427.9177855295875
INFO:root:current train perplexity3.0775885581970215
INFO:root:current mean train loss 1430.7290528504482
INFO:root:current train perplexity3.0840189456939697
INFO:root:current mean train loss 1432.5874016757866
INFO:root:current train perplexity3.085405111312866
INFO:root:current mean train loss 1432.852093821685
INFO:root:current train perplexity3.0866692066192627
INFO:root:current mean train loss 1433.3498691185973
INFO:root:current train perplexity3.091417074203491
INFO:root:current mean train loss 1434.572805528613
INFO:root:current train perplexity3.0938754081726074
INFO:root:current mean train loss 1434.9107215942058
INFO:root:current train perplexity3.0963962078094482
INFO:root:current mean train loss 1435.2617036771426
INFO:root:current train perplexity3.0993545055389404
INFO:root:current mean train loss 1435.184816470816
INFO:root:current train perplexity3.100785732269287
INFO:root:current mean train loss 1435.5872087885166
INFO:root:current train perplexity3.1014442443847656
INFO:root:current mean train loss 1435.8870006040527
INFO:root:current train perplexity3.102588415145874
INFO:root:current mean train loss 1436.9906524527225
INFO:root:current train perplexity3.1042823791503906
INFO:root:current mean train loss 1437.7294271679575
INFO:root:current train perplexity3.1051340103149414
INFO:root:current mean train loss 1437.9097935058328
INFO:root:current train perplexity3.106537342071533
INFO:root:current mean train loss 1438.2521570601778
INFO:root:current train perplexity3.1084775924682617

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.82s/it]
INFO:root:final mean train loss: 1438.132309690967
INFO:root:final train perplexity: 3.1086785793304443
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.44s/it]
INFO:root:eval mean loss: 2135.211168221548
INFO:root:eval perplexity: 5.622822284698486
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.04s/it]
INFO:root:eval mean loss: 2678.4910196074356
INFO:root:eval perplexity: 8.940070152282715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [17:06:56<18:00:03, 629.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1436.7776438395183
INFO:root:current train perplexity3.077535629272461
INFO:root:current mean train loss 1431.2110373007285
INFO:root:current train perplexity3.06880521774292
INFO:root:current mean train loss 1432.2771709811302
INFO:root:current train perplexity3.0838725566864014
INFO:root:current mean train loss 1431.3003799613864
INFO:root:current train perplexity3.0928494930267334
INFO:root:current mean train loss 1429.770416532244
INFO:root:current train perplexity3.091338872909546
INFO:root:current mean train loss 1429.4276557421163
INFO:root:current train perplexity3.0865609645843506
INFO:root:current mean train loss 1428.1725275487076
INFO:root:current train perplexity3.0876448154449463
INFO:root:current mean train loss 1428.9530045616436
INFO:root:current train perplexity3.0896928310394287
INFO:root:current mean train loss 1430.918319126345
INFO:root:current train perplexity3.090628147125244
INFO:root:current mean train loss 1430.4595761842365
INFO:root:current train perplexity3.088334798812866
INFO:root:current mean train loss 1430.6664726897961
INFO:root:current train perplexity3.089586019515991
INFO:root:current mean train loss 1432.1001583724071
INFO:root:current train perplexity3.0930588245391846
INFO:root:current mean train loss 1432.8390500973433
INFO:root:current train perplexity3.0936532020568848
INFO:root:current mean train loss 1433.383152268407
INFO:root:current train perplexity3.09372878074646
INFO:root:current mean train loss 1432.7391823615817
INFO:root:current train perplexity3.0946662425994873
INFO:root:current mean train loss 1432.2525416332314
INFO:root:current train perplexity3.095132827758789
INFO:root:current mean train loss 1432.4718510896257
INFO:root:current train perplexity3.096292018890381
INFO:root:current mean train loss 1433.223796923046
INFO:root:current train perplexity3.0966076850891113
INFO:root:current mean train loss 1433.8869098481678
INFO:root:current train perplexity3.0975513458251953
INFO:root:current mean train loss 1434.6617426000826
INFO:root:current train perplexity3.098339080810547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.09s/it]
INFO:root:final mean train loss: 1434.027260276806
INFO:root:final train perplexity: 3.098630428314209
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.85s/it]
INFO:root:eval mean loss: 2136.6223815485096
INFO:root:eval perplexity: 5.629240989685059
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.44s/it]
INFO:root:eval mean loss: 2677.8577157960717
INFO:root:eval perplexity: 8.935441970825195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [17:17:29<17:51:21, 630.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1402.4202843299279
INFO:root:current train perplexity3.043241500854492
INFO:root:current mean train loss 1416.1812152284565
INFO:root:current train perplexity3.0486021041870117
INFO:root:current mean train loss 1418.417314637382
INFO:root:current train perplexity3.0550148487091064
INFO:root:current mean train loss 1418.3394006180436
INFO:root:current train perplexity3.0523359775543213
INFO:root:current mean train loss 1421.4544323336693
INFO:root:current train perplexity3.06221342086792
INFO:root:current mean train loss 1420.1374464186947
INFO:root:current train perplexity3.0668234825134277
INFO:root:current mean train loss 1420.8473697060033
INFO:root:current train perplexity3.0699570178985596
INFO:root:current mean train loss 1421.8556879978553
INFO:root:current train perplexity3.0723488330841064
INFO:root:current mean train loss 1423.8038180489073
INFO:root:current train perplexity3.076418876647949
INFO:root:current mean train loss 1425.0628473627753
INFO:root:current train perplexity3.0790927410125732
INFO:root:current mean train loss 1425.8406889579664
INFO:root:current train perplexity3.079033374786377
INFO:root:current mean train loss 1426.1757716101126
INFO:root:current train perplexity3.0801610946655273
INFO:root:current mean train loss 1426.8290995360362
INFO:root:current train perplexity3.0820629596710205
INFO:root:current mean train loss 1427.0080674615099
INFO:root:current train perplexity3.084141254425049
INFO:root:current mean train loss 1428.1576992620787
INFO:root:current train perplexity3.085127592086792
INFO:root:current mean train loss 1428.5922600401857
INFO:root:current train perplexity3.0872230529785156
INFO:root:current mean train loss 1429.907605530335
INFO:root:current train perplexity3.0887832641601562
INFO:root:current mean train loss 1430.6246301926567
INFO:root:current train perplexity3.0907750129699707
INFO:root:current mean train loss 1430.676937154407
INFO:root:current train perplexity3.0904390811920166
INFO:root:current mean train loss 1431.0224946077847
INFO:root:current train perplexity3.0904734134674072

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:05<00:00, 545.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:05<00:00, 545.53s/it]
INFO:root:final mean train loss: 1430.7589588405747
INFO:root:final train perplexity: 3.090653419494629
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.63s/it]
INFO:root:eval mean loss: 2141.1018490622228
INFO:root:eval perplexity: 5.649672508239746
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.57s/it]
INFO:root:eval mean loss: 2684.4809457765405
INFO:root:eval perplexity: 8.983972549438477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [17:27:50<17:36:12, 627.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1415.2332689238758
INFO:root:current train perplexity3.070077419281006
INFO:root:current mean train loss 1414.1908589457419
INFO:root:current train perplexity3.0662448406219482
INFO:root:current mean train loss 1419.3500664893618
INFO:root:current train perplexity3.064202070236206
INFO:root:current mean train loss 1421.6658002443962
INFO:root:current train perplexity3.0630762577056885
INFO:root:current mean train loss 1421.5105332497244
INFO:root:current train perplexity3.0664052963256836
INFO:root:current mean train loss 1420.1669691157915
INFO:root:current train perplexity3.064573287963867
INFO:root:current mean train loss 1419.7054862193
INFO:root:current train perplexity3.0666234493255615
INFO:root:current mean train loss 1419.4621861450507
INFO:root:current train perplexity3.0666425228118896
INFO:root:current mean train loss 1421.9161037868923
INFO:root:current train perplexity3.0702409744262695
INFO:root:current mean train loss 1422.804513096081
INFO:root:current train perplexity3.068953037261963
INFO:root:current mean train loss 1422.847083467212
INFO:root:current train perplexity3.0699377059936523
INFO:root:current mean train loss 1423.446281110373
INFO:root:current train perplexity3.069702625274658
INFO:root:current mean train loss 1424.6146657292072
INFO:root:current train perplexity3.0718207359313965
INFO:root:current mean train loss 1425.2408480830545
INFO:root:current train perplexity3.0734753608703613
INFO:root:current mean train loss 1425.7826887328936
INFO:root:current train perplexity3.0754783153533936
INFO:root:current mean train loss 1426.2280041179827
INFO:root:current train perplexity3.0775928497314453
INFO:root:current mean train loss 1427.1797054984766
INFO:root:current train perplexity3.079254627227783
INFO:root:current mean train loss 1427.1383571089584
INFO:root:current train perplexity3.079270124435425
INFO:root:current mean train loss 1427.2845029597834
INFO:root:current train perplexity3.081425189971924
INFO:root:current mean train loss 1427.9773169093128
INFO:root:current train perplexity3.082799196243286

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.28s/it]
INFO:root:final mean train loss: 1427.5245945825159
INFO:root:final train perplexity: 3.0827794075012207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it]
INFO:root:eval mean loss: 2142.7188924153647
INFO:root:eval perplexity: 5.657065391540527
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.57s/it]
INFO:root:eval mean loss: 2686.8514936731217
INFO:root:eval perplexity: 9.001407623291016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [17:38:19<17:26:32, 627.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1405.763001104798
INFO:root:current train perplexity3.043093681335449
INFO:root:current mean train loss 1418.344566460231
INFO:root:current train perplexity3.0546376705169678
INFO:root:current mean train loss 1417.8146993069345
INFO:root:current train perplexity3.054149627685547
INFO:root:current mean train loss 1418.4496568569862
INFO:root:current train perplexity3.0596206188201904
INFO:root:current mean train loss 1419.0490693300665
INFO:root:current train perplexity3.0550174713134766
INFO:root:current mean train loss 1418.1065628994288
INFO:root:current train perplexity3.0577478408813477
INFO:root:current mean train loss 1417.5557796712937
INFO:root:current train perplexity3.059816837310791
INFO:root:current mean train loss 1417.328198028297
INFO:root:current train perplexity3.058314323425293
INFO:root:current mean train loss 1417.8737539051638
INFO:root:current train perplexity3.0613882541656494
INFO:root:current mean train loss 1418.6491873954033
INFO:root:current train perplexity3.063044786453247
INFO:root:current mean train loss 1419.954227076106
INFO:root:current train perplexity3.0670619010925293
INFO:root:current mean train loss 1421.8834139940836
INFO:root:current train perplexity3.0694527626037598
INFO:root:current mean train loss 1421.1416683769667
INFO:root:current train perplexity3.068835973739624
INFO:root:current mean train loss 1421.2618370683301
INFO:root:current train perplexity3.0697946548461914
INFO:root:current mean train loss 1422.1858038822756
INFO:root:current train perplexity3.0704760551452637
INFO:root:current mean train loss 1423.0530880659055
INFO:root:current train perplexity3.0707128047943115
INFO:root:current mean train loss 1423.6654449337157
INFO:root:current train perplexity3.072326898574829
INFO:root:current mean train loss 1423.6122647211776
INFO:root:current train perplexity3.0717709064483643
INFO:root:current mean train loss 1424.195145111325
INFO:root:current train perplexity3.0726819038391113

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:05<00:00, 545.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:05<00:00, 545.28s/it]
INFO:root:final mean train loss: 1424.0087847226325
INFO:root:final train perplexity: 3.0742440223693848
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it]
INFO:root:eval mean loss: 2147.6945991245566
INFO:root:eval perplexity: 5.679875373840332
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.01s/it]
INFO:root:eval mean loss: 2691.0896861840647
INFO:root:eval perplexity: 9.032660484313965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [17:48:39<17:12:01, 625.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1397.1836242675781
INFO:root:current train perplexity3.0501229763031006
INFO:root:current mean train loss 1411.4168280239762
INFO:root:current train perplexity3.032930374145508
INFO:root:current mean train loss 1414.727932965314
INFO:root:current train perplexity3.0337884426116943
INFO:root:current mean train loss 1411.3247599541387
INFO:root:current train perplexity3.034245252609253
INFO:root:current mean train loss 1409.4293969961313
INFO:root:current train perplexity3.0389180183410645
INFO:root:current mean train loss 1409.8525199002997
INFO:root:current train perplexity3.0413851737976074
INFO:root:current mean train loss 1410.0143799224456
INFO:root:current train perplexity3.039339065551758
INFO:root:current mean train loss 1409.0702086720387
INFO:root:current train perplexity3.0413317680358887
INFO:root:current mean train loss 1410.727378097235
INFO:root:current train perplexity3.0447330474853516
INFO:root:current mean train loss 1411.714181292005
INFO:root:current train perplexity3.046748399734497
INFO:root:current mean train loss 1412.2606860784094
INFO:root:current train perplexity3.049008369445801
INFO:root:current mean train loss 1413.9234009882882
INFO:root:current train perplexity3.0512332916259766
INFO:root:current mean train loss 1414.1392682728015
INFO:root:current train perplexity3.052131175994873
INFO:root:current mean train loss 1415.1697417378064
INFO:root:current train perplexity3.0536906719207764
INFO:root:current mean train loss 1416.389833698165
INFO:root:current train perplexity3.056401252746582
INFO:root:current mean train loss 1416.9865441636864
INFO:root:current train perplexity3.0586869716644287
INFO:root:current mean train loss 1417.3928795993918
INFO:root:current train perplexity3.0595569610595703
INFO:root:current mean train loss 1418.2172981031013
INFO:root:current train perplexity3.061185359954834
INFO:root:current mean train loss 1419.0561772821234
INFO:root:current train perplexity3.0626771450042725
INFO:root:current mean train loss 1419.3896357590072
INFO:root:current train perplexity3.063053607940674

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.90s/it]
INFO:root:final mean train loss: 1419.645166902066
INFO:root:final train perplexity: 3.0636823177337646
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it]
INFO:root:eval mean loss: 2148.239643935616
INFO:root:eval perplexity: 5.682379245758057
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.50s/it]
INFO:root:eval mean loss: 2694.1526082356772
INFO:root:eval perplexity: 9.055317878723145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [17:59:10<17:04:35, 627.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1414.3728138316762
INFO:root:current train perplexity3.0398128032684326
INFO:root:current mean train loss 1411.110072544643
INFO:root:current train perplexity3.0547268390655518
INFO:root:current mean train loss 1407.8302814008853
INFO:root:current train perplexity3.041740894317627
INFO:root:current mean train loss 1410.8541816963448
INFO:root:current train perplexity3.0443050861358643
INFO:root:current mean train loss 1413.6300736707021
INFO:root:current train perplexity3.0459771156311035
INFO:root:current mean train loss 1412.0498956104157
INFO:root:current train perplexity3.044065237045288
INFO:root:current mean train loss 1410.8439403371224
INFO:root:current train perplexity3.044724225997925
INFO:root:current mean train loss 1412.987060546875
INFO:root:current train perplexity3.0467987060546875
INFO:root:current mean train loss 1413.22040241878
INFO:root:current train perplexity3.0484933853149414
INFO:root:current mean train loss 1414.41209432882
INFO:root:current train perplexity3.047497034072876
INFO:root:current mean train loss 1414.7022974507277
INFO:root:current train perplexity3.048110008239746
INFO:root:current mean train loss 1414.5105324161864
INFO:root:current train perplexity3.0491156578063965
INFO:root:current mean train loss 1414.6580912519642
INFO:root:current train perplexity3.0492570400238037
INFO:root:current mean train loss 1415.016283245616
INFO:root:current train perplexity3.0497095584869385
INFO:root:current mean train loss 1415.5161224812457
INFO:root:current train perplexity3.0512514114379883
INFO:root:current mean train loss 1416.0450920408564
INFO:root:current train perplexity3.0534372329711914
INFO:root:current mean train loss 1416.1438705154671
INFO:root:current train perplexity3.0538837909698486
INFO:root:current mean train loss 1416.0136251036859
INFO:root:current train perplexity3.0538227558135986
INFO:root:current mean train loss 1417.0850656262787
INFO:root:current train perplexity3.0558829307556152
INFO:root:current mean train loss 1416.9596235232839
INFO:root:current train perplexity3.056121349334717

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.13s/it]
INFO:root:final mean train loss: 1416.765258573608
INFO:root:final train perplexity: 3.056731700897217
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it]
INFO:root:eval mean loss: 2151.306996014101
INFO:root:eval perplexity: 5.696493148803711
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it]
INFO:root:eval mean loss: 2699.842521505153
INFO:root:eval perplexity: 9.097552299499512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [18:09:40<16:55:31, 628.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1411.0419555664062
INFO:root:current train perplexity3.00981068611145
INFO:root:current mean train loss 1402.446747233073
INFO:root:current train perplexity3.0231993198394775
INFO:root:current mean train loss 1407.8087802734376
INFO:root:current train perplexity3.027909278869629
INFO:root:current mean train loss 1406.3086129324777
INFO:root:current train perplexity3.025264263153076
INFO:root:current mean train loss 1405.786554090712
INFO:root:current train perplexity3.0286142826080322
INFO:root:current mean train loss 1408.2736496803977
INFO:root:current train perplexity3.0342047214508057
INFO:root:current mean train loss 1408.7899258188102
INFO:root:current train perplexity3.0377037525177
INFO:root:current mean train loss 1410.4577736002605
INFO:root:current train perplexity3.0380401611328125
INFO:root:current mean train loss 1410.4919515452666
INFO:root:current train perplexity3.0365569591522217
INFO:root:current mean train loss 1412.0773149671052
INFO:root:current train perplexity3.03995943069458
INFO:root:current mean train loss 1411.9769799804687
INFO:root:current train perplexity3.041738986968994
INFO:root:current mean train loss 1411.6076729152514
INFO:root:current train perplexity3.041128158569336
INFO:root:current mean train loss 1411.897491796875
INFO:root:current train perplexity3.0412023067474365
INFO:root:current mean train loss 1411.694212782118
INFO:root:current train perplexity3.0419974327087402
INFO:root:current mean train loss 1411.7425242456898
INFO:root:current train perplexity3.0424282550811768
INFO:root:current mean train loss 1411.960236343876
INFO:root:current train perplexity3.044124126434326
INFO:root:current mean train loss 1412.915624704072
INFO:root:current train perplexity3.045372247695923
INFO:root:current mean train loss 1413.2724739118303
INFO:root:current train perplexity3.045870780944824
INFO:root:current mean train loss 1413.3435691379857
INFO:root:current train perplexity3.0469794273376465
INFO:root:current mean train loss 1413.3284040715143
INFO:root:current train perplexity3.047206401824951

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.68s/it]
INFO:root:final mean train loss: 1413.0468599489705
INFO:root:final train perplexity: 3.047780752182007
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it]
INFO:root:eval mean loss: 2153.471580126607
INFO:root:eval perplexity: 5.706472873687744
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.66s/it]
INFO:root:eval mean loss: 2702.4897599457004
INFO:root:eval perplexity: 9.117270469665527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [18:20:17<16:49:10, 630.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1414.0963790665812
INFO:root:current train perplexity2.992691993713379
INFO:root:current mean train loss 1401.8384965908028
INFO:root:current train perplexity3.0041284561157227
INFO:root:current mean train loss 1402.2888631642088
INFO:root:current train perplexity3.0079760551452637
INFO:root:current mean train loss 1401.7124994678134
INFO:root:current train perplexity3.0116846561431885
INFO:root:current mean train loss 1401.3420146149792
INFO:root:current train perplexity3.0111677646636963
INFO:root:current mean train loss 1402.341495897404
INFO:root:current train perplexity3.0151689052581787
INFO:root:current mean train loss 1403.0504197974255
INFO:root:current train perplexity3.017552375793457
INFO:root:current mean train loss 1404.2030067493583
INFO:root:current train perplexity3.019690752029419
INFO:root:current mean train loss 1403.999805842029
INFO:root:current train perplexity3.0223686695098877
INFO:root:current mean train loss 1403.7755346603947
INFO:root:current train perplexity3.0232279300689697
INFO:root:current mean train loss 1403.8672501940312
INFO:root:current train perplexity3.0270705223083496
INFO:root:current mean train loss 1405.3463759238432
INFO:root:current train perplexity3.02978777885437
INFO:root:current mean train loss 1405.3864952274073
INFO:root:current train perplexity3.0305700302124023
INFO:root:current mean train loss 1406.0825590009488
INFO:root:current train perplexity3.031330108642578
INFO:root:current mean train loss 1405.4227538729656
INFO:root:current train perplexity3.032168388366699
INFO:root:current mean train loss 1405.7903726330667
INFO:root:current train perplexity3.033190965652466
INFO:root:current mean train loss 1406.72504105136
INFO:root:current train perplexity3.034653902053833
INFO:root:current mean train loss 1407.7672435542454
INFO:root:current train perplexity3.0364527702331543
INFO:root:current mean train loss 1408.6242242944897
INFO:root:current train perplexity3.037710666656494
INFO:root:current mean train loss 1409.5928767659548
INFO:root:current train perplexity3.038419246673584

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.75s/it]
INFO:root:final mean train loss: 1409.3249363978584
INFO:root:final train perplexity: 3.0388479232788086
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.30s/it]
INFO:root:eval mean loss: 2158.018247780225
INFO:root:eval perplexity: 5.7274956703186035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it]
INFO:root:eval mean loss: 2708.2434519233434
INFO:root:eval perplexity: 9.160272598266602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [18:30:50<16:39:36, 631.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1389.8867565336682
INFO:root:current train perplexity2.9862537384033203
INFO:root:current mean train loss 1393.3131660793138
INFO:root:current train perplexity2.998880624771118
INFO:root:current mean train loss 1394.2113819390954
INFO:root:current train perplexity3.0047168731689453
INFO:root:current mean train loss 1393.5817302068074
INFO:root:current train perplexity3.0027859210968018
INFO:root:current mean train loss 1396.4650283687372
INFO:root:current train perplexity3.008685827255249
INFO:root:current mean train loss 1400.3164731378424
INFO:root:current train perplexity3.0134146213531494
INFO:root:current mean train loss 1402.3028874982867
INFO:root:current train perplexity3.016103744506836
INFO:root:current mean train loss 1402.3106960374482
INFO:root:current train perplexity3.016751527786255
INFO:root:current mean train loss 1401.5451879717107
INFO:root:current train perplexity3.018781900405884
INFO:root:current mean train loss 1401.3926797262052
INFO:root:current train perplexity3.0199756622314453
INFO:root:current mean train loss 1402.0448000299095
INFO:root:current train perplexity3.0206727981567383
INFO:root:current mean train loss 1403.11767578125
INFO:root:current train perplexity3.0211751461029053
INFO:root:current mean train loss 1403.4936569071263
INFO:root:current train perplexity3.023695468902588
INFO:root:current mean train loss 1404.192904345562
INFO:root:current train perplexity3.025660514831543
INFO:root:current mean train loss 1405.0078296095855
INFO:root:current train perplexity3.027287721633911
INFO:root:current mean train loss 1404.8734728109957
INFO:root:current train perplexity3.0268001556396484
INFO:root:current mean train loss 1404.9378145992614
INFO:root:current train perplexity3.0278663635253906
INFO:root:current mean train loss 1405.803815217296
INFO:root:current train perplexity3.0308310985565186
INFO:root:current mean train loss 1406.7470539846238
INFO:root:current train perplexity3.032536268234253

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.74s/it]
INFO:root:final mean train loss: 1406.6749510426023
INFO:root:final train perplexity: 3.032503366470337
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it]
INFO:root:eval mean loss: 2160.3613826670544
INFO:root:eval perplexity: 5.738358974456787
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.62s/it]
INFO:root:eval mean loss: 2711.008267017121
INFO:root:eval perplexity: 9.181009292602539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [18:41:10<16:24:02, 628.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1380.68310546875
INFO:root:current train perplexity3.0697455406188965
INFO:root:current mean train loss 1389.3115343150525
INFO:root:current train perplexity2.9980199337005615
INFO:root:current mean train loss 1393.980518549829
INFO:root:current train perplexity3.004065752029419
INFO:root:current mean train loss 1395.7579840473163
INFO:root:current train perplexity3.0045135021209717
INFO:root:current mean train loss 1394.9330747228607
INFO:root:current train perplexity3.0064589977264404
INFO:root:current mean train loss 1394.3875788462137
INFO:root:current train perplexity3.0048329830169678
INFO:root:current mean train loss 1395.7113057420574
INFO:root:current train perplexity3.00482439994812
INFO:root:current mean train loss 1396.6497019116107
INFO:root:current train perplexity3.0090699195861816
INFO:root:current mean train loss 1397.7430686617315
INFO:root:current train perplexity3.010291337966919
INFO:root:current mean train loss 1397.3836140182782
INFO:root:current train perplexity3.0108282566070557
INFO:root:current mean train loss 1397.2201102120537
INFO:root:current train perplexity3.011296272277832
INFO:root:current mean train loss 1397.3588489113235
INFO:root:current train perplexity3.0138862133026123
INFO:root:current mean train loss 1397.820994101595
INFO:root:current train perplexity3.01557993888855
INFO:root:current mean train loss 1398.6741381329266
INFO:root:current train perplexity3.0163626670837402
INFO:root:current mean train loss 1398.61948026103
INFO:root:current train perplexity3.0172982215881348
INFO:root:current mean train loss 1399.1007554208652
INFO:root:current train perplexity3.01806640625
INFO:root:current mean train loss 1400.0246886253954
INFO:root:current train perplexity3.0187182426452637
INFO:root:current mean train loss 1400.6175507686196
INFO:root:current train perplexity3.0190229415893555
INFO:root:current mean train loss 1402.0042102396455
INFO:root:current train perplexity3.0211164951324463
INFO:root:current mean train loss 1402.2872840363625
INFO:root:current train perplexity3.021756649017334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.19s/it]
INFO:root:final mean train loss: 1402.6049372855305
INFO:root:final train perplexity: 3.022785186767578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 2161.0956420898438
INFO:root:eval perplexity: 5.7417683601379395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.03s/it]
INFO:root:eval mean loss: 2712.5179993108654
INFO:root:eval perplexity: 9.192350387573242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [18:51:39<16:13:40, 628.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1397.7562866210938
INFO:root:current train perplexity2.988729238510132
INFO:root:current mean train loss 1392.3684009616659
INFO:root:current train perplexity2.996497631072998
INFO:root:current mean train loss 1394.0347480423954
INFO:root:current train perplexity2.9990153312683105
INFO:root:current mean train loss 1392.0088735136596
INFO:root:current train perplexity2.993471622467041
INFO:root:current mean train loss 1393.4580072284316
INFO:root:current train perplexity2.994685173034668
INFO:root:current mean train loss 1392.700602292094
INFO:root:current train perplexity3.00030517578125
INFO:root:current mean train loss 1392.0790304535801
INFO:root:current train perplexity2.9991300106048584
INFO:root:current mean train loss 1391.4646099802512
INFO:root:current train perplexity2.9989173412323
INFO:root:current mean train loss 1392.6110645844476
INFO:root:current train perplexity3.0014069080352783
INFO:root:current mean train loss 1394.6626613508902
INFO:root:current train perplexity3.0030345916748047
INFO:root:current mean train loss 1395.700602173571
INFO:root:current train perplexity3.0053908824920654
INFO:root:current mean train loss 1395.2652534389326
INFO:root:current train perplexity3.005756139755249
INFO:root:current mean train loss 1395.1878574916295
INFO:root:current train perplexity3.0058670043945312
INFO:root:current mean train loss 1396.4109352586484
INFO:root:current train perplexity3.008629560470581
INFO:root:current mean train loss 1397.3976925095315
INFO:root:current train perplexity3.0105931758880615
INFO:root:current mean train loss 1397.8352787384717
INFO:root:current train perplexity3.0111536979675293
INFO:root:current mean train loss 1398.7146675100432
INFO:root:current train perplexity3.0114431381225586
INFO:root:current mean train loss 1399.0581221663772
INFO:root:current train perplexity3.012960433959961
INFO:root:current mean train loss 1399.5741837001083
INFO:root:current train perplexity3.013023614883423
INFO:root:current mean train loss 1399.6583915129693
INFO:root:current train perplexity3.013913869857788

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.80s/it]
INFO:root:final mean train loss: 1399.4698200081552
INFO:root:final train perplexity: 3.0153205394744873
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it]
INFO:root:eval mean loss: 2165.7993185706173
INFO:root:eval perplexity: 5.763652801513672
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it]
INFO:root:eval mean loss: 2718.035425497285
INFO:root:eval perplexity: 9.233924865722656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [19:02:21<16:09:34, 632.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1385.4447405133928
INFO:root:current train perplexity3.0030667781829834
INFO:root:current mean train loss 1376.19571307147
INFO:root:current train perplexity3.0011329650878906
INFO:root:current mean train loss 1381.9210927111037
INFO:root:current train perplexity2.98781156539917
INFO:root:current mean train loss 1383.691457993237
INFO:root:current train perplexity2.9850244522094727
INFO:root:current mean train loss 1384.0310159617457
INFO:root:current train perplexity2.987318277359009
INFO:root:current mean train loss 1386.0447402526286
INFO:root:current train perplexity2.987520933151245
INFO:root:current mean train loss 1386.8351247231792
INFO:root:current train perplexity2.986656665802002
INFO:root:current mean train loss 1388.496159850659
INFO:root:current train perplexity2.9901182651519775
INFO:root:current mean train loss 1388.1255808207802
INFO:root:current train perplexity2.9947757720947266
INFO:root:current mean train loss 1389.4981069309827
INFO:root:current train perplexity2.99436092376709
INFO:root:current mean train loss 1390.3577716919535
INFO:root:current train perplexity2.997039318084717
INFO:root:current mean train loss 1391.703274710903
INFO:root:current train perplexity2.9992544651031494
INFO:root:current mean train loss 1392.0200351483427
INFO:root:current train perplexity3.0007269382476807
INFO:root:current mean train loss 1393.1524385716584
INFO:root:current train perplexity3.0017013549804688
INFO:root:current mean train loss 1393.283040648138
INFO:root:current train perplexity3.0024638175964355
INFO:root:current mean train loss 1393.5553901001374
INFO:root:current train perplexity3.0023276805877686
INFO:root:current mean train loss 1393.7822336552704
INFO:root:current train perplexity3.0029137134552
INFO:root:current mean train loss 1394.1786111705242
INFO:root:current train perplexity3.003722667694092
INFO:root:current mean train loss 1394.8794257972156
INFO:root:current train perplexity3.004643440246582
INFO:root:current mean train loss 1396.1919352844395
INFO:root:current train perplexity3.006497383117676

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.87s/it]
INFO:root:final mean train loss: 1395.9513653530596
INFO:root:final train perplexity: 3.006964683532715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.44s/it]
INFO:root:eval mean loss: 2167.25051338791
INFO:root:eval perplexity: 5.770421504974365
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it]
INFO:root:eval mean loss: 2719.664010555186
INFO:root:eval perplexity: 9.246232986450195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [19:12:42<15:54:11, 629.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1383.7171795184795
INFO:root:current train perplexity2.9953160285949707
INFO:root:current mean train loss 1392.495122809159
INFO:root:current train perplexity2.994940996170044
INFO:root:current mean train loss 1390.5132204086062
INFO:root:current train perplexity2.9823265075683594
INFO:root:current mean train loss 1386.6445440812545
INFO:root:current train perplexity2.9841091632843018
INFO:root:current mean train loss 1387.5581203224385
INFO:root:current train perplexity2.989712715148926
INFO:root:current mean train loss 1389.4493041107621
INFO:root:current train perplexity2.986856698989868
INFO:root:current mean train loss 1389.792662825321
INFO:root:current train perplexity2.9865851402282715
INFO:root:current mean train loss 1391.4709216178733
INFO:root:current train perplexity2.986168622970581
INFO:root:current mean train loss 1391.9731343587239
INFO:root:current train perplexity2.9887490272521973
INFO:root:current mean train loss 1391.9128324364415
INFO:root:current train perplexity2.9909825325012207
INFO:root:current mean train loss 1391.2497805751323
INFO:root:current train perplexity2.991600751876831
INFO:root:current mean train loss 1391.3177972369724
INFO:root:current train perplexity2.9907164573669434
INFO:root:current mean train loss 1391.8009846355208
INFO:root:current train perplexity2.991649627685547
INFO:root:current mean train loss 1391.7837656235554
INFO:root:current train perplexity2.9934234619140625
INFO:root:current mean train loss 1392.4474102261966
INFO:root:current train perplexity2.9945058822631836
INFO:root:current mean train loss 1392.6707555239961
INFO:root:current train perplexity2.9959616661071777
INFO:root:current mean train loss 1392.6228189168196
INFO:root:current train perplexity2.997189998626709
INFO:root:current mean train loss 1392.7145068024936
INFO:root:current train perplexity2.9987990856170654
INFO:root:current mean train loss 1392.8855237528264
INFO:root:current train perplexity2.9995834827423096
INFO:root:current mean train loss 1393.3720389819537
INFO:root:current train perplexity3.0001237392425537

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.19s/it]
INFO:root:final mean train loss: 1392.8678429738716
INFO:root:final train perplexity: 2.999661445617676
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 2171.037829243545
INFO:root:eval perplexity: 5.788121223449707
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it]
INFO:root:eval mean loss: 2723.719407967642
INFO:root:eval perplexity: 9.276947975158691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/110
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [19:23:15<15:45:15, 630.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1375.4110461248868
INFO:root:current train perplexity2.953711986541748
INFO:root:current mean train loss 1373.0335151627219
INFO:root:current train perplexity2.9566690921783447
INFO:root:current mean train loss 1374.694280574756
INFO:root:current train perplexity2.9620888233184814
INFO:root:current mean train loss 1379.258807257262
INFO:root:current train perplexity2.962491512298584
INFO:root:current mean train loss 1379.4993719495435
INFO:root:current train perplexity2.961977958679199
INFO:root:current mean train loss 1380.8056423944831
INFO:root:current train perplexity2.964113235473633
INFO:root:current mean train loss 1383.1279236660944
INFO:root:current train perplexity2.968312978744507
INFO:root:current mean train loss 1384.268214192285
INFO:root:current train perplexity2.973167896270752
INFO:root:current mean train loss 1383.997529937428
INFO:root:current train perplexity2.9763498306274414
INFO:root:current mean train loss 1385.685430599563
INFO:root:current train perplexity2.9781410694122314
INFO:root:current mean train loss 1385.2075510480004
INFO:root:current train perplexity2.9799888134002686
INFO:root:current mean train loss 1384.8688387385384
INFO:root:current train perplexity2.981579303741455
INFO:root:current mean train loss 1385.8632186276411
INFO:root:current train perplexity2.981581449508667
INFO:root:current mean train loss 1385.5447551317682
INFO:root:current train perplexity2.9832215309143066
INFO:root:current mean train loss 1387.2627738396923
INFO:root:current train perplexity2.985123872756958
INFO:root:current mean train loss 1387.9058695514161
INFO:root:current train perplexity2.986347198486328
INFO:root:current mean train loss 1388.335957467163
INFO:root:current train perplexity2.987353801727295
INFO:root:current mean train loss 1389.3015620445653
INFO:root:current train perplexity2.989187717437744
INFO:root:current mean train loss 1389.24984252995
INFO:root:current train perplexity2.990126132965088
INFO:root:current mean train loss 1389.4538277877411
INFO:root:current train perplexity2.990711212158203

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.05s/it]
INFO:root:final mean train loss: 1389.3009019352485
INFO:root:final train perplexity: 2.9912350177764893
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 2173.0989691551695
INFO:root:eval perplexity: 5.797779083251953
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.67s/it]
INFO:root:eval mean loss: 2724.8845491882757
INFO:root:eval perplexity: 9.28579044342041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/111
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [19:33:37<15:31:06, 627.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1376.2664837504542
INFO:root:current train perplexity2.9659225940704346
INFO:root:current mean train loss 1375.9106839087701
INFO:root:current train perplexity2.9616940021514893
INFO:root:current mean train loss 1377.51584267783
INFO:root:current train perplexity2.966383218765259
INFO:root:current mean train loss 1376.9760568253116
INFO:root:current train perplexity2.9641337394714355
INFO:root:current mean train loss 1379.3813730247718
INFO:root:current train perplexity2.962167501449585
INFO:root:current mean train loss 1379.9660869507252
INFO:root:current train perplexity2.9646308422088623
INFO:root:current mean train loss 1381.520961216518
INFO:root:current train perplexity2.9666764736175537
INFO:root:current mean train loss 1380.5168969540196
INFO:root:current train perplexity2.9696531295776367
INFO:root:current mean train loss 1381.0647056700145
INFO:root:current train perplexity2.969494342803955
INFO:root:current mean train loss 1381.8683323115413
INFO:root:current train perplexity2.971356153488159
INFO:root:current mean train loss 1382.5991067060888
INFO:root:current train perplexity2.9727747440338135
INFO:root:current mean train loss 1383.1294099701597
INFO:root:current train perplexity2.9749879837036133
INFO:root:current mean train loss 1384.0272212999976
INFO:root:current train perplexity2.977185010910034
INFO:root:current mean train loss 1383.5556840552567
INFO:root:current train perplexity2.978057622909546
INFO:root:current mean train loss 1384.7148168879594
INFO:root:current train perplexity2.9790773391723633
INFO:root:current mean train loss 1384.6736889679225
INFO:root:current train perplexity2.9809274673461914
INFO:root:current mean train loss 1385.3693315499195
INFO:root:current train perplexity2.98301100730896
INFO:root:current mean train loss 1386.254805783809
INFO:root:current train perplexity2.984065532684326
INFO:root:current mean train loss 1386.4169927052956
INFO:root:current train perplexity2.9845449924468994

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.71s/it]
INFO:root:final mean train loss: 1386.6086906244582
INFO:root:final train perplexity: 2.9848902225494385
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.79s/it]
INFO:root:eval mean loss: 2175.6469691932625
INFO:root:eval perplexity: 5.809739112854004
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 2731.1738614562555
INFO:root:eval perplexity: 9.333678245544434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/112
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [19:44:01<15:19:05, 626.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1390.6868082682292
INFO:root:current train perplexity2.980712890625
INFO:root:current mean train loss 1377.5000094811894
INFO:root:current train perplexity2.9589803218841553
INFO:root:current mean train loss 1377.582620554957
INFO:root:current train perplexity2.972303867340088
INFO:root:current mean train loss 1373.0383260494018
INFO:root:current train perplexity2.9696078300476074
INFO:root:current mean train loss 1373.8191660083553
INFO:root:current train perplexity2.971125602722168
INFO:root:current mean train loss 1373.8130035703746
INFO:root:current train perplexity2.9679148197174072
INFO:root:current mean train loss 1376.24308288473
INFO:root:current train perplexity2.969705581665039
INFO:root:current mean train loss 1376.109925271437
INFO:root:current train perplexity2.971034526824951
INFO:root:current mean train loss 1376.7299094764262
INFO:root:current train perplexity2.971251964569092
INFO:root:current mean train loss 1377.3192175171305
INFO:root:current train perplexity2.9727630615234375
INFO:root:current mean train loss 1378.5101864815708
INFO:root:current train perplexity2.974640369415283
INFO:root:current mean train loss 1379.2059668145823
INFO:root:current train perplexity2.9733479022979736
INFO:root:current mean train loss 1380.4130060793655
INFO:root:current train perplexity2.9737937450408936
INFO:root:current mean train loss 1380.4609925862194
INFO:root:current train perplexity2.973358154296875
INFO:root:current mean train loss 1381.2796667402163
INFO:root:current train perplexity2.973416566848755
INFO:root:current mean train loss 1381.3776992726787
INFO:root:current train perplexity2.9736151695251465
INFO:root:current mean train loss 1382.6156453628207
INFO:root:current train perplexity2.9754018783569336
INFO:root:current mean train loss 1383.6175714874717
INFO:root:current train perplexity2.9746861457824707
INFO:root:current mean train loss 1383.9996076553184
INFO:root:current train perplexity2.9760982990264893
INFO:root:current mean train loss 1384.4828687177728
INFO:root:current train perplexity2.977231979370117

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.18s/it]
INFO:root:final mean train loss: 1384.110673051258
INFO:root:final train perplexity: 2.979015588760376
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.71s/it]
INFO:root:eval mean loss: 2177.547049880873
INFO:root:eval perplexity: 5.8186726570129395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.76s/it]
INFO:root:eval mean loss: 2733.0513318650264
INFO:root:eval perplexity: 9.348020553588867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/113
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [19:54:36<15:12:09, 629.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1346.3853698730468
INFO:root:current train perplexity2.9443047046661377
INFO:root:current mean train loss 1373.0566853841146
INFO:root:current train perplexity2.9567534923553467
INFO:root:current mean train loss 1370.6622430974787
INFO:root:current train perplexity2.9512953758239746
INFO:root:current mean train loss 1373.5204639434814
INFO:root:current train perplexity2.9528229236602783
INFO:root:current mean train loss 1371.8628066289994
INFO:root:current train perplexity2.9562742710113525
INFO:root:current mean train loss 1372.1569439227765
INFO:root:current train perplexity2.956571102142334
INFO:root:current mean train loss 1373.6955276981478
INFO:root:current train perplexity2.9561069011688232
INFO:root:current mean train loss 1372.4707646687825
INFO:root:current train perplexity2.9564332962036133
INFO:root:current mean train loss 1371.6365546994093
INFO:root:current train perplexity2.955885648727417
INFO:root:current mean train loss 1372.6857242750084
INFO:root:current train perplexity2.9570846557617188
INFO:root:current mean train loss 1375.010171807981
INFO:root:current train perplexity2.958435297012329
INFO:root:current mean train loss 1375.6112552097866
INFO:root:current train perplexity2.959428310394287
INFO:root:current mean train loss 1376.8177558273565
INFO:root:current train perplexity2.961012840270996
INFO:root:current mean train loss 1377.4398973869554
INFO:root:current train perplexity2.963066816329956
INFO:root:current mean train loss 1378.3345734072402
INFO:root:current train perplexity2.9637036323547363
INFO:root:current mean train loss 1378.5276794433594
INFO:root:current train perplexity2.9655117988586426
INFO:root:current mean train loss 1379.1203961407696
INFO:root:current train perplexity2.9673845767974854
INFO:root:current mean train loss 1379.4397208990054
INFO:root:current train perplexity2.9670510292053223
INFO:root:current mean train loss 1379.7412130167197
INFO:root:current train perplexity2.968548536300659
INFO:root:current mean train loss 1380.6658410390219
INFO:root:current train perplexity2.969266653060913

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.59s/it]
INFO:root:final mean train loss: 1380.1392944459055
INFO:root:final train perplexity: 2.9696998596191406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it]
INFO:root:eval mean loss: 2181.4402284013463
INFO:root:eval perplexity: 5.837021827697754
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.51s/it]
INFO:root:eval mean loss: 2739.6769478439437
INFO:root:eval perplexity: 9.398811340332031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/114
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [20:04:56<14:57:46, 626.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1361.5111842799831
INFO:root:current train perplexity2.911497116088867
INFO:root:current mean train loss 1358.1699281121691
INFO:root:current train perplexity2.9398794174194336
INFO:root:current mean train loss 1359.5805473488595
INFO:root:current train perplexity2.9311187267303467
INFO:root:current mean train loss 1368.0264015990124
INFO:root:current train perplexity2.94569993019104
INFO:root:current mean train loss 1368.5578518306636
INFO:root:current train perplexity2.952838182449341
INFO:root:current mean train loss 1370.4311730297807
INFO:root:current train perplexity2.9557995796203613
INFO:root:current mean train loss 1371.6038481085043
INFO:root:current train perplexity2.9583241939544678
INFO:root:current mean train loss 1371.8028463417995
INFO:root:current train perplexity2.956190347671509
INFO:root:current mean train loss 1371.9484966829543
INFO:root:current train perplexity2.954561233520508
INFO:root:current mean train loss 1371.6818964906283
INFO:root:current train perplexity2.954186201095581
INFO:root:current mean train loss 1372.8724107438825
INFO:root:current train perplexity2.9549543857574463
INFO:root:current mean train loss 1372.7783903123625
INFO:root:current train perplexity2.955073118209839
INFO:root:current mean train loss 1373.602077030808
INFO:root:current train perplexity2.956707715988159
INFO:root:current mean train loss 1374.0557480600226
INFO:root:current train perplexity2.9570839405059814
INFO:root:current mean train loss 1375.1905851423865
INFO:root:current train perplexity2.958571434020996
INFO:root:current mean train loss 1375.1860969459071
INFO:root:current train perplexity2.9594027996063232
INFO:root:current mean train loss 1375.7551821345735
INFO:root:current train perplexity2.9605846405029297
INFO:root:current mean train loss 1375.9268698332703
INFO:root:current train perplexity2.962014675140381
INFO:root:current mean train loss 1376.7735461472296
INFO:root:current train perplexity2.96217679977417
INFO:root:current mean train loss 1377.1409367614021
INFO:root:current train perplexity2.9620361328125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.23s/it]
INFO:root:final mean train loss: 1377.0601972232728
INFO:root:final train perplexity: 2.9624969959259033
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it]
INFO:root:eval mean loss: 2183.3260814044493
INFO:root:eval perplexity: 5.845932483673096
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it]
INFO:root:eval mean loss: 2739.9856337959886
INFO:root:eval perplexity: 9.401182174682617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/115
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [20:15:19<14:46:00, 625.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1375.19369619864
INFO:root:current train perplexity2.932891845703125
INFO:root:current mean train loss 1376.0821247843953
INFO:root:current train perplexity2.931364059448242
INFO:root:current mean train loss 1371.000605065053
INFO:root:current train perplexity2.934932231903076
INFO:root:current mean train loss 1366.1656838972017
INFO:root:current train perplexity2.9347124099731445
INFO:root:current mean train loss 1366.4469394767862
INFO:root:current train perplexity2.9389312267303467
INFO:root:current mean train loss 1367.532806065969
INFO:root:current train perplexity2.939919948577881
INFO:root:current mean train loss 1368.073759586439
INFO:root:current train perplexity2.9414782524108887
INFO:root:current mean train loss 1368.697111822882
INFO:root:current train perplexity2.942659378051758
INFO:root:current mean train loss 1368.6772415196867
INFO:root:current train perplexity2.9437012672424316
INFO:root:current mean train loss 1368.9779423807652
INFO:root:current train perplexity2.9469618797302246
INFO:root:current mean train loss 1370.04401607622
INFO:root:current train perplexity2.9478657245635986
INFO:root:current mean train loss 1370.764249540491
INFO:root:current train perplexity2.9476301670074463
INFO:root:current mean train loss 1370.8188461960788
INFO:root:current train perplexity2.949578285217285
INFO:root:current mean train loss 1370.990593553822
INFO:root:current train perplexity2.948979139328003
INFO:root:current mean train loss 1371.0428575938145
INFO:root:current train perplexity2.9493138790130615
INFO:root:current mean train loss 1371.594016135276
INFO:root:current train perplexity2.950355052947998
INFO:root:current mean train loss 1372.3743926005611
INFO:root:current train perplexity2.950641632080078
INFO:root:current mean train loss 1373.2502087861674
INFO:root:current train perplexity2.952028274536133
INFO:root:current mean train loss 1373.4212121726882
INFO:root:current train perplexity2.953432321548462
INFO:root:current mean train loss 1373.7264701663655
INFO:root:current train perplexity2.9547128677368164

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.22s/it]
INFO:root:final mean train loss: 1373.735944246801
INFO:root:final train perplexity: 2.954740524291992
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it]
INFO:root:eval mean loss: 2185.188960082142
INFO:root:eval perplexity: 5.854744911193848
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it]
INFO:root:eval mean loss: 2744.5758333679632
INFO:root:eval perplexity: 9.436541557312012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/116
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [20:26:01<14:42:22, 630.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1378.8435746313821
INFO:root:current train perplexity2.933624267578125
INFO:root:current mean train loss 1365.419100934302
INFO:root:current train perplexity2.9284262657165527
INFO:root:current mean train loss 1367.668976393133
INFO:root:current train perplexity2.9337708950042725
INFO:root:current mean train loss 1365.9855654323198
INFO:root:current train perplexity2.9332644939422607
INFO:root:current mean train loss 1366.0933363604697
INFO:root:current train perplexity2.93098521232605
INFO:root:current mean train loss 1365.7359800856502
INFO:root:current train perplexity2.931997299194336
INFO:root:current mean train loss 1365.8634326099107
INFO:root:current train perplexity2.935396909713745
INFO:root:current mean train loss 1367.4189350212284
INFO:root:current train perplexity2.9372076988220215
INFO:root:current mean train loss 1369.0526044563092
INFO:root:current train perplexity2.9396071434020996
INFO:root:current mean train loss 1368.1028674328977
INFO:root:current train perplexity2.939122200012207
INFO:root:current mean train loss 1368.377584334515
INFO:root:current train perplexity2.939229965209961
INFO:root:current mean train loss 1367.9061934994795
INFO:root:current train perplexity2.940762996673584
INFO:root:current mean train loss 1367.7248813680173
INFO:root:current train perplexity2.941225051879883
INFO:root:current mean train loss 1368.7950946076085
INFO:root:current train perplexity2.943030595779419
INFO:root:current mean train loss 1369.2045040376975
INFO:root:current train perplexity2.94467830657959
INFO:root:current mean train loss 1369.1951824263506
INFO:root:current train perplexity2.945967197418213
INFO:root:current mean train loss 1369.3335077821102
INFO:root:current train perplexity2.946255922317505
INFO:root:current mean train loss 1369.9724462973338
INFO:root:current train perplexity2.946993827819824
INFO:root:current mean train loss 1370.590639457927
INFO:root:current train perplexity2.947197198867798
INFO:root:current mean train loss 1371.3848608782423
INFO:root:current train perplexity2.9485018253326416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.02s/it]
INFO:root:final mean train loss: 1371.1561945051
INFO:root:final train perplexity: 2.948735237121582
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it]
INFO:root:eval mean loss: 2188.5150458153257
INFO:root:eval perplexity: 5.870515823364258
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it]
INFO:root:eval mean loss: 2748.815992422983
INFO:root:eval perplexity: 9.469320297241211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/117
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [20:36:25<14:29:14, 628.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1366.7684728449042
INFO:root:current train perplexity2.9216184616088867
INFO:root:current mean train loss 1370.0210928409658
INFO:root:current train perplexity2.9240469932556152
INFO:root:current mean train loss 1367.5408409966362
INFO:root:current train perplexity2.9247939586639404
INFO:root:current mean train loss 1368.0462539515545
INFO:root:current train perplexity2.9196367263793945
INFO:root:current mean train loss 1365.0757803995102
INFO:root:current train perplexity2.921751022338867
INFO:root:current mean train loss 1365.1403866722471
INFO:root:current train perplexity2.9212231636047363
INFO:root:current mean train loss 1366.344952073208
INFO:root:current train perplexity2.923851490020752
INFO:root:current mean train loss 1365.3978073197572
INFO:root:current train perplexity2.925675868988037
INFO:root:current mean train loss 1365.879481135188
INFO:root:current train perplexity2.928341865539551
INFO:root:current mean train loss 1365.186452147449
INFO:root:current train perplexity2.9293339252471924
INFO:root:current mean train loss 1366.8312346514533
INFO:root:current train perplexity2.931091785430908
INFO:root:current mean train loss 1366.490269310948
INFO:root:current train perplexity2.9316956996917725
INFO:root:current mean train loss 1367.0357826185523
INFO:root:current train perplexity2.9341118335723877
INFO:root:current mean train loss 1367.5145899528043
INFO:root:current train perplexity2.9343602657318115
INFO:root:current mean train loss 1367.796295904344
INFO:root:current train perplexity2.9344255924224854
INFO:root:current mean train loss 1367.6706237024264
INFO:root:current train perplexity2.9369957447052
INFO:root:current mean train loss 1368.765051312921
INFO:root:current train perplexity2.939025402069092
INFO:root:current mean train loss 1369.1577433131686
INFO:root:current train perplexity2.940312623977661
INFO:root:current mean train loss 1369.040294517905
INFO:root:current train perplexity2.941157817840576

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.43s/it]
INFO:root:final mean train loss: 1368.678776497199
INFO:root:final train perplexity: 2.942979097366333
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.48s/it]
INFO:root:eval mean loss: 2192.0512699641235
INFO:root:eval perplexity: 5.887329578399658
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it]
INFO:root:eval mean loss: 2752.4631066288507
INFO:root:eval perplexity: 9.497608184814453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/118
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [20:46:45<14:15:40, 626.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1312.9316650390624
INFO:root:current train perplexity2.835845470428467
INFO:root:current mean train loss 1355.896111188616
INFO:root:current train perplexity2.9099836349487305
INFO:root:current mean train loss 1350.0929336175686
INFO:root:current train perplexity2.9035897254943848
INFO:root:current mean train loss 1354.4149161917264
INFO:root:current train perplexity2.9035353660583496
INFO:root:current mean train loss 1355.7369508342979
INFO:root:current train perplexity2.906053304672241
INFO:root:current mean train loss 1357.8535538172957
INFO:root:current train perplexity2.907438039779663
INFO:root:current mean train loss 1358.3561533525956
INFO:root:current train perplexity2.913677215576172
INFO:root:current mean train loss 1359.1481050531916
INFO:root:current train perplexity2.920574426651001
INFO:root:current mean train loss 1359.9466705890916
INFO:root:current train perplexity2.923720359802246
INFO:root:current mean train loss 1361.1683496633286
INFO:root:current train perplexity2.925647735595703
INFO:root:current mean train loss 1360.290421428016
INFO:root:current train perplexity2.9253063201904297
INFO:root:current mean train loss 1362.060730256646
INFO:root:current train perplexity2.9284205436706543
INFO:root:current mean train loss 1362.4485059809388
INFO:root:current train perplexity2.9294214248657227
INFO:root:current mean train loss 1363.4337515527718
INFO:root:current train perplexity2.9308769702911377
INFO:root:current mean train loss 1363.8791363156138
INFO:root:current train perplexity2.931762456893921
INFO:root:current mean train loss 1364.8177985004413
INFO:root:current train perplexity2.9332752227783203
INFO:root:current mean train loss 1364.8370234314154
INFO:root:current train perplexity2.9339072704315186
INFO:root:current mean train loss 1364.5417718881736
INFO:root:current train perplexity2.93304181098938
INFO:root:current mean train loss 1365.1678631811592
INFO:root:current train perplexity2.933136463165283
INFO:root:current mean train loss 1365.140318062049
INFO:root:current train perplexity2.9336512088775635

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.86s/it]
INFO:root:final mean train loss: 1365.0167747262867
INFO:root:final train perplexity: 2.9344921112060547
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it]
INFO:root:eval mean loss: 2193.915378868157
INFO:root:eval perplexity: 5.896210670471191
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.80s/it]
INFO:root:eval mean loss: 2756.441875051945
INFO:root:eval perplexity: 9.528562545776367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/119
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [20:57:06<14:02:55, 624.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1354.8723699396307
INFO:root:current train perplexity2.8947834968566895
INFO:root:current mean train loss 1350.62536821209
INFO:root:current train perplexity2.910238265991211
INFO:root:current mean train loss 1352.066602002393
INFO:root:current train perplexity2.9023220539093018
INFO:root:current mean train loss 1352.3219521090111
INFO:root:current train perplexity2.9039645195007324
INFO:root:current mean train loss 1353.443652112337
INFO:root:current train perplexity2.9049439430236816
INFO:root:current mean train loss 1354.2418626807203
INFO:root:current train perplexity2.9084460735321045
INFO:root:current mean train loss 1354.1233002395875
INFO:root:current train perplexity2.909827709197998
INFO:root:current mean train loss 1355.5002011962215
INFO:root:current train perplexity2.913055896759033
INFO:root:current mean train loss 1357.0304501572955
INFO:root:current train perplexity2.912719488143921
INFO:root:current mean train loss 1358.116779848707
INFO:root:current train perplexity2.915531635284424
INFO:root:current mean train loss 1358.3356445073614
INFO:root:current train perplexity2.9159905910491943
INFO:root:current mean train loss 1358.8279895476478
INFO:root:current train perplexity2.9169976711273193
INFO:root:current mean train loss 1358.9826170676274
INFO:root:current train perplexity2.9193294048309326
INFO:root:current mean train loss 1358.531915292437
INFO:root:current train perplexity2.920225143432617
INFO:root:current mean train loss 1359.038985497841
INFO:root:current train perplexity2.9226467609405518
INFO:root:current mean train loss 1360.5822845338678
INFO:root:current train perplexity2.924807071685791
INFO:root:current mean train loss 1361.3440785061123
INFO:root:current train perplexity2.926151990890503
INFO:root:current mean train loss 1361.4863442167311
INFO:root:current train perplexity2.927316427230835
INFO:root:current mean train loss 1362.295598152571
INFO:root:current train perplexity2.927799940109253
INFO:root:current mean train loss 1362.4620372760307
INFO:root:current train perplexity2.928290367126465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.45s/it]
INFO:root:final mean train loss: 1362.5495218881981
INFO:root:final train perplexity: 2.9287874698638916
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.30s/it]
INFO:root:eval mean loss: 2195.66190852172
INFO:root:eval perplexity: 5.904544830322266
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.50s/it]
INFO:root:eval mean loss: 2757.9638355877382
INFO:root:eval perplexity: 9.540431022644043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/120
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [21:07:37<13:55:22, 626.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1353.329314403045
INFO:root:current train perplexity2.889281749725342
INFO:root:current mean train loss 1350.1618529395234
INFO:root:current train perplexity2.8884904384613037
INFO:root:current mean train loss 1348.556439898503
INFO:root:current train perplexity2.8953092098236084
INFO:root:current mean train loss 1345.5954197346284
INFO:root:current train perplexity2.902371406555176
INFO:root:current mean train loss 1346.966024411838
INFO:root:current train perplexity2.899533748626709
INFO:root:current mean train loss 1350.233592979983
INFO:root:current train perplexity2.9036848545074463
INFO:root:current mean train loss 1350.896381025956
INFO:root:current train perplexity2.9024477005004883
INFO:root:current mean train loss 1352.0147624138406
INFO:root:current train perplexity2.9082212448120117
INFO:root:current mean train loss 1353.6455558258529
INFO:root:current train perplexity2.9072651863098145
INFO:root:current mean train loss 1353.7960218078158
INFO:root:current train perplexity2.907341957092285
INFO:root:current mean train loss 1354.44233323245
INFO:root:current train perplexity2.909010887145996
INFO:root:current mean train loss 1355.5070762198886
INFO:root:current train perplexity2.9107470512390137
INFO:root:current mean train loss 1355.517515365687
INFO:root:current train perplexity2.91119122505188
INFO:root:current mean train loss 1356.1854053864824
INFO:root:current train perplexity2.9123528003692627
INFO:root:current mean train loss 1356.7319833041065
INFO:root:current train perplexity2.9147701263427734
INFO:root:current mean train loss 1358.4081225379712
INFO:root:current train perplexity2.9174225330352783
INFO:root:current mean train loss 1359.1380267419634
INFO:root:current train perplexity2.9193832874298096
INFO:root:current mean train loss 1359.5673517860032
INFO:root:current train perplexity2.920088052749634
INFO:root:current mean train loss 1359.7945850697984
INFO:root:current train perplexity2.92160701751709
INFO:root:current mean train loss 1360.2853209410457
INFO:root:current train perplexity2.922677755355835

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.08s/it]
INFO:root:final mean train loss: 1359.9908909569228
INFO:root:final train perplexity: 2.9228837490081787
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it]
INFO:root:eval mean loss: 2199.6742138152426
INFO:root:eval perplexity: 5.923734664916992
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 2763.3718737879544
INFO:root:eval perplexity: 9.582718849182129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/121
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [21:18:02<13:44:09, 625.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1352.458476475307
INFO:root:current train perplexity2.903108596801758
INFO:root:current mean train loss 1350.668417123648
INFO:root:current train perplexity2.900782346725464
INFO:root:current mean train loss 1351.5010824203491
INFO:root:current train perplexity2.90073299407959
INFO:root:current mean train loss 1351.1817753823955
INFO:root:current train perplexity2.9039807319641113
INFO:root:current mean train loss 1353.9900239643298
INFO:root:current train perplexity2.90189266204834
INFO:root:current mean train loss 1355.9087653949107
INFO:root:current train perplexity2.9025661945343018
INFO:root:current mean train loss 1356.7417602539062
INFO:root:current train perplexity2.903014659881592
INFO:root:current mean train loss 1354.699528446904
INFO:root:current train perplexity2.9040110111236572
INFO:root:current mean train loss 1355.1755305495217
INFO:root:current train perplexity2.9078497886657715
INFO:root:current mean train loss 1355.1694756033032
INFO:root:current train perplexity2.9107367992401123
INFO:root:current mean train loss 1354.8953132629395
INFO:root:current train perplexity2.910466194152832
INFO:root:current mean train loss 1354.2883602789116
INFO:root:current train perplexity2.911119222640991
INFO:root:current mean train loss 1354.0750162890004
INFO:root:current train perplexity2.9115641117095947
INFO:root:current mean train loss 1354.736110901059
INFO:root:current train perplexity2.911593198776245
INFO:root:current mean train loss 1354.8094380137684
INFO:root:current train perplexity2.9125118255615234
INFO:root:current mean train loss 1355.8240177576217
INFO:root:current train perplexity2.9134035110473633
INFO:root:current mean train loss 1356.23410188979
INFO:root:current train perplexity2.914177179336548
INFO:root:current mean train loss 1356.6288409743602
INFO:root:current train perplexity2.9154181480407715
INFO:root:current mean train loss 1357.422690753279
INFO:root:current train perplexity2.915989637374878
INFO:root:current mean train loss 1357.6485613801485
INFO:root:current train perplexity2.9167582988739014

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.28s/it]
INFO:root:final mean train loss: 1357.4389418824658
INFO:root:final train perplexity: 2.9170069694519043
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.97s/it]
INFO:root:eval mean loss: 2201.856774296321
INFO:root:eval perplexity: 5.934201717376709
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it]
INFO:root:eval mean loss: 2765.284360195728
INFO:root:eval perplexity: 9.597718238830566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/122
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [21:28:30<13:34:35, 626.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1343.0531223244864
INFO:root:current train perplexity2.9019148349761963
INFO:root:current mean train loss 1344.1420362174856
INFO:root:current train perplexity2.8942975997924805
INFO:root:current mean train loss 1347.9291545043498
INFO:root:current train perplexity2.894106388092041
INFO:root:current mean train loss 1349.1873344032758
INFO:root:current train perplexity2.8949410915374756
INFO:root:current mean train loss 1347.4874985031547
INFO:root:current train perplexity2.897615909576416
INFO:root:current mean train loss 1347.9271152889125
INFO:root:current train perplexity2.8994123935699463
INFO:root:current mean train loss 1348.4336595917882
INFO:root:current train perplexity2.9009687900543213
INFO:root:current mean train loss 1350.1662566072728
INFO:root:current train perplexity2.9022200107574463
INFO:root:current mean train loss 1351.5332365440202
INFO:root:current train perplexity2.902012348175049
INFO:root:current mean train loss 1352.970460113494
INFO:root:current train perplexity2.9027531147003174
INFO:root:current mean train loss 1353.646308948698
INFO:root:current train perplexity2.903769016265869
INFO:root:current mean train loss 1354.3118427143277
INFO:root:current train perplexity2.9057209491729736
INFO:root:current mean train loss 1354.7069683449529
INFO:root:current train perplexity2.9050281047821045
INFO:root:current mean train loss 1354.4579588243412
INFO:root:current train perplexity2.906341552734375
INFO:root:current mean train loss 1353.9277837666539
INFO:root:current train perplexity2.9051172733306885
INFO:root:current mean train loss 1354.040903022315
INFO:root:current train perplexity2.905606508255005
INFO:root:current mean train loss 1354.765097244728
INFO:root:current train perplexity2.906388759613037
INFO:root:current mean train loss 1355.0184222897499
INFO:root:current train perplexity2.9071176052093506
INFO:root:current mean train loss 1354.5947334709106
INFO:root:current train perplexity2.9082252979278564
INFO:root:current mean train loss 1354.6331162218266
INFO:root:current train perplexity2.909409523010254

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.65s/it]
INFO:root:final mean train loss: 1354.2103750100955
INFO:root:final train perplexity: 2.90958833694458
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 2203.5992392682015
INFO:root:eval perplexity: 5.942569732666016
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.91s/it]
INFO:root:eval mean loss: 2768.615436959774
INFO:root:eval perplexity: 9.623902320861816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/123
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [21:38:53<13:22:38, 625.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1343.6933634440104
INFO:root:current train perplexity2.901153564453125
INFO:root:current mean train loss 1340.4147036903782
INFO:root:current train perplexity2.886995315551758
INFO:root:current mean train loss 1345.3176172716865
INFO:root:current train perplexity2.8913846015930176
INFO:root:current mean train loss 1347.767407852564
INFO:root:current train perplexity2.8940553665161133
INFO:root:current mean train loss 1347.875373435507
INFO:root:current train perplexity2.895137310028076
INFO:root:current mean train loss 1347.8871662721795
INFO:root:current train perplexity2.894676446914673
INFO:root:current mean train loss 1347.2120679772418
INFO:root:current train perplexity2.8955531120300293
INFO:root:current mean train loss 1347.8016570658624
INFO:root:current train perplexity2.8959217071533203
INFO:root:current mean train loss 1347.911309060086
INFO:root:current train perplexity2.8958914279937744
INFO:root:current mean train loss 1347.9981831251973
INFO:root:current train perplexity2.8978888988494873
INFO:root:current mean train loss 1349.016160989464
INFO:root:current train perplexity2.899116277694702
INFO:root:current mean train loss 1349.3915997160584
INFO:root:current train perplexity2.9015705585479736
INFO:root:current mean train loss 1349.2783248546511
INFO:root:current train perplexity2.9021120071411133
INFO:root:current mean train loss 1349.785828866204
INFO:root:current train perplexity2.9021081924438477
INFO:root:current mean train loss 1350.8040596161914
INFO:root:current train perplexity2.9024055004119873
INFO:root:current mean train loss 1350.3413882849352
INFO:root:current train perplexity2.9011447429656982
INFO:root:current mean train loss 1350.2567625508507
INFO:root:current train perplexity2.9012386798858643
INFO:root:current mean train loss 1350.7728676566865
INFO:root:current train perplexity2.9011127948760986
INFO:root:current mean train loss 1351.2675825815352
INFO:root:current train perplexity2.9026525020599365

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.11s/it]
INFO:root:final mean train loss: 1351.548684139896
INFO:root:final train perplexity: 2.90348744392395
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 2207.250199987533
INFO:root:eval perplexity: 5.960142612457275
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 2771.73085790323
INFO:root:eval perplexity: 9.648457527160645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/124
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [21:49:22<13:13:36, 626.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1358.592564174107
INFO:root:current train perplexity2.8357949256896973
INFO:root:current mean train loss 1340.426920953198
INFO:root:current train perplexity2.8591434955596924
INFO:root:current mean train loss 1346.7211566132623
INFO:root:current train perplexity2.877323627471924
INFO:root:current mean train loss 1344.101320745114
INFO:root:current train perplexity2.8787076473236084
INFO:root:current mean train loss 1339.5629543894925
INFO:root:current train perplexity2.878978729248047
INFO:root:current mean train loss 1342.1244033723187
INFO:root:current train perplexity2.883147954940796
INFO:root:current mean train loss 1343.0185192931426
INFO:root:current train perplexity2.88334059715271
INFO:root:current mean train loss 1344.2522418117928
INFO:root:current train perplexity2.8832974433898926
INFO:root:current mean train loss 1344.2273738818542
INFO:root:current train perplexity2.883105993270874
INFO:root:current mean train loss 1344.9482988485822
INFO:root:current train perplexity2.8855180740356445
INFO:root:current mean train loss 1344.3652047968906
INFO:root:current train perplexity2.8866126537323
INFO:root:current mean train loss 1344.976505269203
INFO:root:current train perplexity2.888864517211914
INFO:root:current mean train loss 1345.0477879483935
INFO:root:current train perplexity2.888110399246216
INFO:root:current mean train loss 1345.3302299890613
INFO:root:current train perplexity2.888753890991211
INFO:root:current mean train loss 1345.491010523554
INFO:root:current train perplexity2.889565944671631
INFO:root:current mean train loss 1347.063135057233
INFO:root:current train perplexity2.8916749954223633
INFO:root:current mean train loss 1346.983622752144
INFO:root:current train perplexity2.892754077911377
INFO:root:current mean train loss 1347.2441304703518
INFO:root:current train perplexity2.893254041671753
INFO:root:current mean train loss 1347.675399163842
INFO:root:current train perplexity2.8945858478546143
INFO:root:current mean train loss 1348.4600338468267
INFO:root:current train perplexity2.8963844776153564

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.78s/it]
INFO:root:final mean train loss: 1348.640681387497
INFO:root:final train perplexity: 2.896836042404175
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it]
INFO:root:eval mean loss: 2207.3466493863584
INFO:root:eval perplexity: 5.960607051849365
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 2772.5041746315383
INFO:root:eval perplexity: 9.654557228088379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/125
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [21:59:46<13:02:05, 625.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1328.64599609375
INFO:root:current train perplexity2.8638010025024414
INFO:root:current mean train loss 1336.8933843797254
INFO:root:current train perplexity2.874920129776001
INFO:root:current mean train loss 1337.063949584961
INFO:root:current train perplexity2.862769603729248
INFO:root:current mean train loss 1339.5661398805219
INFO:root:current train perplexity2.8722095489501953
INFO:root:current mean train loss 1342.3360831782502
INFO:root:current train perplexity2.874568223953247
INFO:root:current mean train loss 1341.343091426005
INFO:root:current train perplexity2.8743276596069336
INFO:root:current mean train loss 1341.9985204843374
INFO:root:current train perplexity2.8783891201019287
INFO:root:current mean train loss 1342.0460994151415
INFO:root:current train perplexity2.8788490295410156
INFO:root:current mean train loss 1341.0783098831917
INFO:root:current train perplexity2.8811826705932617
INFO:root:current mean train loss 1340.479731440028
INFO:root:current train perplexity2.8819525241851807
INFO:root:current mean train loss 1341.3743306398392
INFO:root:current train perplexity2.883756399154663
INFO:root:current mean train loss 1342.027550639631
INFO:root:current train perplexity2.8849287033081055
INFO:root:current mean train loss 1343.6287301256766
INFO:root:current train perplexity2.8862228393554688
INFO:root:current mean train loss 1343.9318075957976
INFO:root:current train perplexity2.8861756324768066
INFO:root:current mean train loss 1344.4140631857883
INFO:root:current train perplexity2.8878417015075684
INFO:root:current mean train loss 1344.924092210184
INFO:root:current train perplexity2.888580083847046
INFO:root:current mean train loss 1345.3495658536262
INFO:root:current train perplexity2.888540744781494
INFO:root:current mean train loss 1345.6160921950905
INFO:root:current train perplexity2.889248847961426
INFO:root:current mean train loss 1345.9712170383386
INFO:root:current train perplexity2.8899948596954346
INFO:root:current mean train loss 1346.584154727801
INFO:root:current train perplexity2.890961170196533

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.50s/it]
INFO:root:final mean train loss: 1346.342299376241
INFO:root:final train perplexity: 2.891590118408203
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.47s/it]
INFO:root:eval mean loss: 2211.128888935062
INFO:root:eval perplexity: 5.978866100311279
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.84s/it]
INFO:root:eval mean loss: 2777.0737287372563
INFO:root:eval perplexity: 9.690703392028809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/126
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [22:10:19<12:54:23, 627.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1334.698456554878
INFO:root:current train perplexity2.870795488357544
INFO:root:current mean train loss 1339.252340113863
INFO:root:current train perplexity2.8693909645080566
INFO:root:current mean train loss 1338.9812199129603
INFO:root:current train perplexity2.8699123859405518
INFO:root:current mean train loss 1339.578961951292
INFO:root:current train perplexity2.8704395294189453
INFO:root:current mean train loss 1341.7798233551232
INFO:root:current train perplexity2.8709096908569336
INFO:root:current mean train loss 1341.459208885094
INFO:root:current train perplexity2.8681952953338623
INFO:root:current mean train loss 1341.1811565333708
INFO:root:current train perplexity2.8673486709594727
INFO:root:current mean train loss 1340.0863460484143
INFO:root:current train perplexity2.8670461177825928
INFO:root:current mean train loss 1339.7393350317702
INFO:root:current train perplexity2.8670334815979004
INFO:root:current mean train loss 1340.1042698405122
INFO:root:current train perplexity2.8691093921661377
INFO:root:current mean train loss 1340.3537558959608
INFO:root:current train perplexity2.87117600440979
INFO:root:current mean train loss 1340.9636850983923
INFO:root:current train perplexity2.873372793197632
INFO:root:current mean train loss 1341.3584858835177
INFO:root:current train perplexity2.8760247230529785
INFO:root:current mean train loss 1342.3221309926419
INFO:root:current train perplexity2.8783233165740967
INFO:root:current mean train loss 1342.6907381247017
INFO:root:current train perplexity2.8789567947387695
INFO:root:current mean train loss 1343.4703292302077
INFO:root:current train perplexity2.8811097145080566
INFO:root:current mean train loss 1343.699852980033
INFO:root:current train perplexity2.883484125137329
INFO:root:current mean train loss 1344.1080664427097
INFO:root:current train perplexity2.8841214179992676
INFO:root:current mean train loss 1344.3976282288625
INFO:root:current train perplexity2.8853139877319336
INFO:root:current mean train loss 1344.5182898559256
INFO:root:current train perplexity2.885920763015747

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.54s/it]
INFO:root:final mean train loss: 1343.8810727364237
INFO:root:final train perplexity: 2.8859822750091553
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 2214.14214005707
INFO:root:eval perplexity: 5.993455410003662
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 2781.6386982802806
INFO:root:eval perplexity: 9.72695255279541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/127
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [22:20:40<12:41:24, 625.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1317.7795283876617
INFO:root:current train perplexity2.845632314682007
INFO:root:current mean train loss 1324.1520208044897
INFO:root:current train perplexity2.8624722957611084
INFO:root:current mean train loss 1329.0495908278826
INFO:root:current train perplexity2.8685481548309326
INFO:root:current mean train loss 1330.687527960239
INFO:root:current train perplexity2.8683438301086426
INFO:root:current mean train loss 1332.2699089216874
INFO:root:current train perplexity2.8668508529663086
INFO:root:current mean train loss 1334.8945122175319
INFO:root:current train perplexity2.8679707050323486
INFO:root:current mean train loss 1335.374947869669
INFO:root:current train perplexity2.868412494659424
INFO:root:current mean train loss 1336.2043706647326
INFO:root:current train perplexity2.8699657917022705
INFO:root:current mean train loss 1336.9619738171984
INFO:root:current train perplexity2.868946075439453
INFO:root:current mean train loss 1337.2677078406348
INFO:root:current train perplexity2.869807243347168
INFO:root:current mean train loss 1338.4754654824847
INFO:root:current train perplexity2.8709182739257812
INFO:root:current mean train loss 1338.3162850230058
INFO:root:current train perplexity2.8716611862182617
INFO:root:current mean train loss 1338.4530301965856
INFO:root:current train perplexity2.872408151626587
INFO:root:current mean train loss 1338.9779115657216
INFO:root:current train perplexity2.8736510276794434
INFO:root:current mean train loss 1339.2616924605088
INFO:root:current train perplexity2.8741776943206787
INFO:root:current mean train loss 1340.0492746453535
INFO:root:current train perplexity2.8745203018188477
INFO:root:current mean train loss 1340.4229768723142
INFO:root:current train perplexity2.8757410049438477
INFO:root:current mean train loss 1341.1415239318917
INFO:root:current train perplexity2.8770506381988525
INFO:root:current mean train loss 1341.48735133439
INFO:root:current train perplexity2.877948760986328
INFO:root:current mean train loss 1341.54133570109
INFO:root:current train perplexity2.8792715072631836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.24s/it]
INFO:root:final mean train loss: 1341.2919092991108
INFO:root:final train perplexity: 2.8800954818725586
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it]
INFO:root:eval mean loss: 2216.4741271539783
INFO:root:eval perplexity: 6.004770755767822
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.22s/it]
INFO:root:eval mean loss: 2784.8339536409853
INFO:root:eval perplexity: 9.752403259277344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/128
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [22:31:05<12:30:44, 625.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1330.6284342447916
INFO:root:current train perplexity2.866208791732788
INFO:root:current mean train loss 1330.582046595982
INFO:root:current train perplexity2.848381757736206
INFO:root:current mean train loss 1332.3794473544035
INFO:root:current train perplexity2.859342575073242
INFO:root:current mean train loss 1332.615041015625
INFO:root:current train perplexity2.8597395420074463
INFO:root:current mean train loss 1331.3245677425987
INFO:root:current train perplexity2.860344409942627
INFO:root:current mean train loss 1332.1512809952446
INFO:root:current train perplexity2.861638069152832
INFO:root:current mean train loss 1332.463572048611
INFO:root:current train perplexity2.861335277557373
INFO:root:current mean train loss 1333.7669389490927
INFO:root:current train perplexity2.8628616333007812
INFO:root:current mean train loss 1335.1291068638393
INFO:root:current train perplexity2.8644776344299316
INFO:root:current mean train loss 1335.1617003455528
INFO:root:current train perplexity2.8662075996398926
INFO:root:current mean train loss 1336.0572462073037
INFO:root:current train perplexity2.867095947265625
INFO:root:current mean train loss 1336.1589186128656
INFO:root:current train perplexity2.866764545440674
INFO:root:current mean train loss 1335.8814074946386
INFO:root:current train perplexity2.8670904636383057
INFO:root:current mean train loss 1336.3500185546875
INFO:root:current train perplexity2.8692641258239746
INFO:root:current mean train loss 1337.4387677932998
INFO:root:current train perplexity2.8704254627227783
INFO:root:current mean train loss 1337.4317992776537
INFO:root:current train perplexity2.8720555305480957
INFO:root:current mean train loss 1337.6401926888993
INFO:root:current train perplexity2.8726279735565186
INFO:root:current mean train loss 1338.2322610172755
INFO:root:current train perplexity2.872908353805542
INFO:root:current mean train loss 1338.6972456380208
INFO:root:current train perplexity2.873234748840332
INFO:root:current mean train loss 1338.4774271904669
INFO:root:current train perplexity2.873316764831543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.43s/it]
INFO:root:final mean train loss: 1338.2439250166947
INFO:root:final train perplexity: 2.873180389404297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it]
INFO:root:eval mean loss: 2219.5461122769834
INFO:root:eval perplexity: 6.019705772399902
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it]
INFO:root:eval mean loss: 2789.674093476424
INFO:root:eval perplexity: 9.791082382202148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/129
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [22:41:38<12:22:52, 627.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1326.9952949855638
INFO:root:current train perplexity2.8293683528900146
INFO:root:current mean train loss 1325.6137650807698
INFO:root:current train perplexity2.847233533859253
INFO:root:current mean train loss 1324.0037649494327
INFO:root:current train perplexity2.8537888526916504
INFO:root:current mean train loss 1326.9990287313656
INFO:root:current train perplexity2.8577845096588135
INFO:root:current mean train loss 1326.6605616623792
INFO:root:current train perplexity2.8537983894348145
INFO:root:current mean train loss 1328.2637172389675
INFO:root:current train perplexity2.8557326793670654
INFO:root:current mean train loss 1329.386535291727
INFO:root:current train perplexity2.8589227199554443
INFO:root:current mean train loss 1329.0883357500788
INFO:root:current train perplexity2.8597371578216553
INFO:root:current mean train loss 1329.033031651792
INFO:root:current train perplexity2.8600730895996094
INFO:root:current mean train loss 1330.353496920678
INFO:root:current train perplexity2.8617258071899414
INFO:root:current mean train loss 1331.248071132562
INFO:root:current train perplexity2.8637664318084717
INFO:root:current mean train loss 1331.1705855811201
INFO:root:current train perplexity2.863309144973755
INFO:root:current mean train loss 1331.9207836422759
INFO:root:current train perplexity2.863344669342041
INFO:root:current mean train loss 1332.759539023213
INFO:root:current train perplexity2.8633623123168945
INFO:root:current mean train loss 1333.569818409774
INFO:root:current train perplexity2.8637430667877197
INFO:root:current mean train loss 1334.589821360219
INFO:root:current train perplexity2.8651463985443115
INFO:root:current mean train loss 1335.529977712789
INFO:root:current train perplexity2.8650612831115723
INFO:root:current mean train loss 1335.7381677627563
INFO:root:current train perplexity2.866032838821411
INFO:root:current mean train loss 1336.0301613676625
INFO:root:current train perplexity2.867368459701538

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.05s/it]
INFO:root:final mean train loss: 1335.9409621676832
INFO:root:final train perplexity: 2.867966651916504
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it]
INFO:root:eval mean loss: 2221.3968640050143
INFO:root:eval perplexity: 6.028723239898682
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.91s/it]
INFO:root:eval mean loss: 2789.995027149823
INFO:root:eval perplexity: 9.793654441833496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/130
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [22:51:57<12:09:26, 625.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1310.4175618489583
INFO:root:current train perplexity2.7843942642211914
INFO:root:current mean train loss 1332.7953037646932
INFO:root:current train perplexity2.8590800762176514
INFO:root:current mean train loss 1329.1750394830292
INFO:root:current train perplexity2.861914873123169
INFO:root:current mean train loss 1328.6766270510973
INFO:root:current train perplexity2.8607065677642822
INFO:root:current mean train loss 1329.0332783370263
INFO:root:current train perplexity2.8563601970672607
INFO:root:current mean train loss 1330.0840349778211
INFO:root:current train perplexity2.858144521713257
INFO:root:current mean train loss 1329.7382980872844
INFO:root:current train perplexity2.8568859100341797
INFO:root:current mean train loss 1330.54537933737
INFO:root:current train perplexity2.860222339630127
INFO:root:current mean train loss 1330.8291930020666
INFO:root:current train perplexity2.8617630004882812
INFO:root:current mean train loss 1330.3465683604493
INFO:root:current train perplexity2.861621618270874
INFO:root:current mean train loss 1330.8624724888116
INFO:root:current train perplexity2.862851142883301
INFO:root:current mean train loss 1331.7671446598147
INFO:root:current train perplexity2.862661600112915
INFO:root:current mean train loss 1331.4111851139241
INFO:root:current train perplexity2.8623101711273193
INFO:root:current mean train loss 1332.175825732459
INFO:root:current train perplexity2.8623204231262207
INFO:root:current mean train loss 1332.325071596101
INFO:root:current train perplexity2.863251209259033
INFO:root:current mean train loss 1333.3548688338717
INFO:root:current train perplexity2.863534688949585
INFO:root:current mean train loss 1333.0194858814189
INFO:root:current train perplexity2.8635778427124023
INFO:root:current mean train loss 1333.5205889546153
INFO:root:current train perplexity2.8638839721679688
INFO:root:current mean train loss 1333.6974485617702
INFO:root:current train perplexity2.8635923862457275
INFO:root:current mean train loss 1334.1814876694277
INFO:root:current train perplexity2.8633058071136475

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.86s/it]
INFO:root:final mean train loss: 1334.0798517439741
INFO:root:final train perplexity: 2.863760471343994
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it]
INFO:root:eval mean loss: 2223.074675864362
INFO:root:eval perplexity: 6.036910057067871
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it]
INFO:root:eval mean loss: 2793.2616217863474
INFO:root:eval perplexity: 9.819853782653809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/131
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [23:02:18<11:57:39, 624.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1295.6312631460337
INFO:root:current train perplexity2.8647189140319824
INFO:root:current mean train loss 1317.4072052486358
INFO:root:current train perplexity2.8308396339416504
INFO:root:current mean train loss 1320.898985736138
INFO:root:current train perplexity2.8363418579101562
INFO:root:current mean train loss 1322.7656654404716
INFO:root:current train perplexity2.8397774696350098
INFO:root:current mean train loss 1323.6042082164208
INFO:root:current train perplexity2.839263677597046
INFO:root:current mean train loss 1325.0267280607623
INFO:root:current train perplexity2.840054750442505
INFO:root:current mean train loss 1325.4199717951278
INFO:root:current train perplexity2.8422040939331055
INFO:root:current mean train loss 1325.9906384176459
INFO:root:current train perplexity2.844252109527588
INFO:root:current mean train loss 1326.8899697218335
INFO:root:current train perplexity2.844902515411377
INFO:root:current mean train loss 1327.9508278107282
INFO:root:current train perplexity2.8474438190460205
INFO:root:current mean train loss 1328.4430093449225
INFO:root:current train perplexity2.847634792327881
INFO:root:current mean train loss 1328.8298698682768
INFO:root:current train perplexity2.849134922027588
INFO:root:current mean train loss 1328.7938914462366
INFO:root:current train perplexity2.8487741947174072
INFO:root:current mean train loss 1328.9844020653634
INFO:root:current train perplexity2.8493077754974365
INFO:root:current mean train loss 1328.53769789772
INFO:root:current train perplexity2.8494763374328613
INFO:root:current mean train loss 1328.8947385935453
INFO:root:current train perplexity2.8504765033721924
INFO:root:current mean train loss 1329.71875112611
INFO:root:current train perplexity2.8524811267852783
INFO:root:current mean train loss 1330.2269857855274
INFO:root:current train perplexity2.8548364639282227
INFO:root:current mean train loss 1330.738227234221
INFO:root:current train perplexity2.8548405170440674
INFO:root:current mean train loss 1331.055383541626
INFO:root:current train perplexity2.856091260910034

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.21s/it]
INFO:root:final mean train loss: 1330.9488895972208
INFO:root:final train perplexity: 2.8566975593566895
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.70s/it]
INFO:root:eval mean loss: 2225.4451237671765
INFO:root:eval perplexity: 6.048494338989258
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it]
INFO:root:eval mean loss: 2794.1036433226673
INFO:root:eval perplexity: 9.826617240905762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/132
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [23:13:04<11:54:38, 630.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1315.176936659702
INFO:root:current train perplexity2.8307065963745117
INFO:root:current mean train loss 1321.980742767974
INFO:root:current train perplexity2.83664870262146
INFO:root:current mean train loss 1320.7914833100244
INFO:root:current train perplexity2.8282926082611084
INFO:root:current mean train loss 1325.0115134013986
INFO:root:current train perplexity2.8349099159240723
INFO:root:current mean train loss 1324.6778886851016
INFO:root:current train perplexity2.837716579437256
INFO:root:current mean train loss 1325.8708460124597
INFO:root:current train perplexity2.839594841003418
INFO:root:current mean train loss 1326.2201294135157
INFO:root:current train perplexity2.8403806686401367
INFO:root:current mean train loss 1325.6998614674462
INFO:root:current train perplexity2.8398990631103516
INFO:root:current mean train loss 1325.8317881230075
INFO:root:current train perplexity2.8393137454986572
INFO:root:current mean train loss 1325.1007593990257
INFO:root:current train perplexity2.8412559032440186
INFO:root:current mean train loss 1325.535975981993
INFO:root:current train perplexity2.84316086769104
INFO:root:current mean train loss 1325.840386177924
INFO:root:current train perplexity2.8439364433288574
INFO:root:current mean train loss 1326.7827510818395
INFO:root:current train perplexity2.8447532653808594
INFO:root:current mean train loss 1326.5574346728406
INFO:root:current train perplexity2.845578670501709
INFO:root:current mean train loss 1327.1018716940348
INFO:root:current train perplexity2.847226858139038
INFO:root:current mean train loss 1327.6152418906706
INFO:root:current train perplexity2.848820209503174
INFO:root:current mean train loss 1328.1316224073246
INFO:root:current train perplexity2.8489973545074463
INFO:root:current mean train loss 1327.87367529549
INFO:root:current train perplexity2.8495476245880127
INFO:root:current mean train loss 1328.3248463887853
INFO:root:current train perplexity2.8494956493377686
INFO:root:current mean train loss 1328.6102052414717
INFO:root:current train perplexity2.850825309753418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.04s/it]
INFO:root:final mean train loss: 1328.4317107400207
INFO:root:final train perplexity: 2.8510324954986572
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 2226.861605164007
INFO:root:eval perplexity: 6.055426597595215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.94s/it]
INFO:root:eval mean loss: 2798.9183107200242
INFO:root:eval perplexity: 9.865386009216309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/133
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [23:23:26<11:41:18, 628.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1310.2512084960938
INFO:root:current train perplexity2.8328206539154053
INFO:root:current mean train loss 1324.152439880371
INFO:root:current train perplexity2.824774742126465
INFO:root:current mean train loss 1323.2811551607572
INFO:root:current train perplexity2.8249776363372803
INFO:root:current mean train loss 1324.2499372694228
INFO:root:current train perplexity2.830156087875366
INFO:root:current mean train loss 1325.045078974185
INFO:root:current train perplexity2.832791566848755
INFO:root:current mean train loss 1325.7396591186523
INFO:root:current train perplexity2.830862522125244
INFO:root:current mean train loss 1326.0985384854403
INFO:root:current train perplexity2.833258628845215
INFO:root:current mean train loss 1325.330856483861
INFO:root:current train perplexity2.8366708755493164
INFO:root:current mean train loss 1325.6210507415062
INFO:root:current train perplexity2.8371098041534424
INFO:root:current mean train loss 1325.2414117177327
INFO:root:current train perplexity2.8394522666931152
INFO:root:current mean train loss 1325.106117910709
INFO:root:current train perplexity2.839512825012207
INFO:root:current mean train loss 1325.7237365722656
INFO:root:current train perplexity2.8414835929870605
INFO:root:current mean train loss 1326.317519124349
INFO:root:current train perplexity2.841453790664673
INFO:root:current mean train loss 1326.440776421042
INFO:root:current train perplexity2.842306137084961
INFO:root:current mean train loss 1326.843018832272
INFO:root:current train perplexity2.842209815979004
INFO:root:current mean train loss 1326.7963758419721
INFO:root:current train perplexity2.8438515663146973
INFO:root:current mean train loss 1327.0445858874953
INFO:root:current train perplexity2.8457999229431152
INFO:root:current mean train loss 1327.605359649658
INFO:root:current train perplexity2.8468263149261475
INFO:root:current mean train loss 1327.6012651340936
INFO:root:current train perplexity2.8479084968566895
INFO:root:current mean train loss 1327.8756345787826
INFO:root:current train perplexity2.8485264778137207

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.04s/it]
INFO:root:final mean train loss: 1327.5977948179643
INFO:root:final train perplexity: 2.8491580486297607
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.98s/it]
INFO:root:eval mean loss: 2228.7870903285684
INFO:root:eval perplexity: 6.064863681793213
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.70s/it]
INFO:root:eval mean loss: 2802.0062476624835
INFO:root:eval perplexity: 9.89033317565918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/134
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [23:34:08<11:35:26, 632.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1311.7199786297688
INFO:root:current train perplexity2.8153421878814697
INFO:root:current mean train loss 1317.7402929963366
INFO:root:current train perplexity2.8324403762817383
INFO:root:current mean train loss 1315.8583750810865
INFO:root:current train perplexity2.823164701461792
INFO:root:current mean train loss 1316.5445326746933
INFO:root:current train perplexity2.8255395889282227
INFO:root:current mean train loss 1316.6146529415619
INFO:root:current train perplexity2.8263142108917236
INFO:root:current mean train loss 1317.1362224294573
INFO:root:current train perplexity2.828397512435913
INFO:root:current mean train loss 1317.87466065535
INFO:root:current train perplexity2.8291852474212646
INFO:root:current mean train loss 1318.6268937394425
INFO:root:current train perplexity2.831577777862549
INFO:root:current mean train loss 1320.067872346467
INFO:root:current train perplexity2.8327245712280273
INFO:root:current mean train loss 1320.5886289192442
INFO:root:current train perplexity2.831901788711548
INFO:root:current mean train loss 1321.5087813551822
INFO:root:current train perplexity2.8369038105010986
INFO:root:current mean train loss 1320.9943247157432
INFO:root:current train perplexity2.8367621898651123
INFO:root:current mean train loss 1321.3110801798343
INFO:root:current train perplexity2.8369619846343994
INFO:root:current mean train loss 1321.7227105034722
INFO:root:current train perplexity2.837812662124634
INFO:root:current mean train loss 1322.2668738859122
INFO:root:current train perplexity2.838914394378662
INFO:root:current mean train loss 1322.579412505078
INFO:root:current train perplexity2.8386783599853516
INFO:root:current mean train loss 1322.9560329230258
INFO:root:current train perplexity2.839773178100586
INFO:root:current mean train loss 1323.985467793771
INFO:root:current train perplexity2.8409361839294434
INFO:root:current mean train loss 1324.346948411278
INFO:root:current train perplexity2.842658519744873
INFO:root:current mean train loss 1324.6277254342913
INFO:root:current train perplexity2.8418774604797363

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.97s/it]
INFO:root:final mean train loss: 1324.3654429040892
INFO:root:final train perplexity: 2.8419039249420166
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it]
INFO:root:eval mean loss: 2232.2664872839096
INFO:root:eval perplexity: 6.081953525543213
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it]
INFO:root:eval mean loss: 2804.936185363337
INFO:root:eval perplexity: 9.91405963897705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/135
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [23:44:29<11:21:14, 628.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1305.4740379820478
INFO:root:current train perplexity2.8036203384399414
INFO:root:current mean train loss 1312.0602926667204
INFO:root:current train perplexity2.817040205001831
INFO:root:current mean train loss 1311.948001368516
INFO:root:current train perplexity2.815358877182007
INFO:root:current mean train loss 1314.1043453313373
INFO:root:current train perplexity2.812171697616577
INFO:root:current mean train loss 1314.6621128344825
INFO:root:current train perplexity2.8167154788970947
INFO:root:current mean train loss 1316.8116070782696
INFO:root:current train perplexity2.820427417755127
INFO:root:current mean train loss 1318.1387065260828
INFO:root:current train perplexity2.823707342147827
INFO:root:current mean train loss 1318.2568599210879
INFO:root:current train perplexity2.825981616973877
INFO:root:current mean train loss 1319.5259780371748
INFO:root:current train perplexity2.828296422958374
INFO:root:current mean train loss 1319.9497848909866
INFO:root:current train perplexity2.829336643218994
INFO:root:current mean train loss 1320.3141326625343
INFO:root:current train perplexity2.8302743434906006
INFO:root:current mean train loss 1320.3270713512222
INFO:root:current train perplexity2.8313121795654297
INFO:root:current mean train loss 1320.5495622449164
INFO:root:current train perplexity2.8313746452331543
INFO:root:current mean train loss 1321.1318173730049
INFO:root:current train perplexity2.83247709274292
INFO:root:current mean train loss 1320.980896404629
INFO:root:current train perplexity2.832015037536621
INFO:root:current mean train loss 1320.9281856675668
INFO:root:current train perplexity2.833050489425659
INFO:root:current mean train loss 1321.8392804538767
INFO:root:current train perplexity2.834408760070801
INFO:root:current mean train loss 1321.9067849591956
INFO:root:current train perplexity2.835237503051758
INFO:root:current mean train loss 1322.1639003411267
INFO:root:current train perplexity2.836003065109253

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.27s/it]
INFO:root:final mean train loss: 1322.0060334313835
INFO:root:final train perplexity: 2.836620807647705
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.50s/it]
INFO:root:eval mean loss: 2235.5207437285294
INFO:root:eval perplexity: 6.097982883453369
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it]
INFO:root:eval mean loss: 2809.1781356486867
INFO:root:eval perplexity: 9.948511123657227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/136
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [23:54:50<11:08:24, 626.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1316.13330078125
INFO:root:current train perplexity2.8274519443511963
INFO:root:current mean train loss 1308.7116149352478
INFO:root:current train perplexity2.799367666244507
INFO:root:current mean train loss 1307.068742941906
INFO:root:current train perplexity2.810548782348633
INFO:root:current mean train loss 1310.3145198515374
INFO:root:current train perplexity2.8097879886627197
INFO:root:current mean train loss 1310.8659299678757
INFO:root:current train perplexity2.8089897632598877
INFO:root:current mean train loss 1311.9745986251683
INFO:root:current train perplexity2.8128905296325684
INFO:root:current mean train loss 1313.3418566115358
INFO:root:current train perplexity2.8174495697021484
INFO:root:current mean train loss 1313.520184351925
INFO:root:current train perplexity2.8185880184173584
INFO:root:current mean train loss 1314.6807537713855
INFO:root:current train perplexity2.8219802379608154
INFO:root:current mean train loss 1315.5883781022742
INFO:root:current train perplexity2.823146104812622
INFO:root:current mean train loss 1315.9454620995225
INFO:root:current train perplexity2.8238539695739746
INFO:root:current mean train loss 1316.8350627909472
INFO:root:current train perplexity2.8246543407440186
INFO:root:current mean train loss 1316.351292856659
INFO:root:current train perplexity2.8232691287994385
INFO:root:current mean train loss 1317.322372052435
INFO:root:current train perplexity2.825113296508789
INFO:root:current mean train loss 1317.8240401864812
INFO:root:current train perplexity2.8268110752105713
INFO:root:current mean train loss 1317.7811936101402
INFO:root:current train perplexity2.8276002407073975
INFO:root:current mean train loss 1317.9690621090112
INFO:root:current train perplexity2.8283212184906006
INFO:root:current mean train loss 1318.276628593476
INFO:root:current train perplexity2.8284285068511963
INFO:root:current mean train loss 1319.400791549472
INFO:root:current train perplexity2.829853057861328
INFO:root:current mean train loss 1319.7547397264193
INFO:root:current train perplexity2.830512046813965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:04<00:00, 544.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:04<00:00, 544.80s/it]
INFO:root:final mean train loss: 1319.3263754794168
INFO:root:final train perplexity: 2.830632448196411
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it]
INFO:root:eval mean loss: 2237.582537711935
INFO:root:eval perplexity: 6.108158111572266
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.59s/it]
INFO:root:eval mean loss: 2812.14608396706
INFO:root:eval perplexity: 9.972688674926758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/137
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [24:05:09<10:55:17, 624.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1306.2739562988281
INFO:root:current train perplexity2.793729543685913
INFO:root:current mean train loss 1304.9376707077026
INFO:root:current train perplexity2.7960622310638428
INFO:root:current mean train loss 1309.0183555201481
INFO:root:current train perplexity2.800630807876587
INFO:root:current mean train loss 1312.275594199576
INFO:root:current train perplexity2.8069920539855957
INFO:root:current mean train loss 1310.468234623704
INFO:root:current train perplexity2.8108012676239014
INFO:root:current mean train loss 1310.3847087513316
INFO:root:current train perplexity2.8103156089782715
INFO:root:current mean train loss 1310.0113278528688
INFO:root:current train perplexity2.810760736465454
INFO:root:current mean train loss 1310.1134454077417
INFO:root:current train perplexity2.812002658843994
INFO:root:current mean train loss 1311.5523388259078
INFO:root:current train perplexity2.8148341178894043
INFO:root:current mean train loss 1312.263348809604
INFO:root:current train perplexity2.814842462539673
INFO:root:current mean train loss 1312.886053538044
INFO:root:current train perplexity2.8164045810699463
INFO:root:current mean train loss 1313.6154264625927
INFO:root:current train perplexity2.820225238800049
INFO:root:current mean train loss 1314.5110221142102
INFO:root:current train perplexity2.8213424682617188
INFO:root:current mean train loss 1314.9090430018414
INFO:root:current train perplexity2.823253870010376
INFO:root:current mean train loss 1314.93009987198
INFO:root:current train perplexity2.8246912956237793
INFO:root:current mean train loss 1315.2326986103158
INFO:root:current train perplexity2.824944019317627
INFO:root:current mean train loss 1315.3148060641652
INFO:root:current train perplexity2.8249359130859375
INFO:root:current mean train loss 1315.8920346719246
INFO:root:current train perplexity2.824704885482788
INFO:root:current mean train loss 1317.2346174711734
INFO:root:current train perplexity2.825571298599243
INFO:root:current mean train loss 1317.4972617754797
INFO:root:current train perplexity2.826051712036133

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.44s/it]
INFO:root:final mean train loss: 1317.6358139030392
INFO:root:final train perplexity: 2.8268611431121826
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it]
INFO:root:eval mean loss: 2237.8484903971353
INFO:root:eval perplexity: 6.10947322845459
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it]
INFO:root:eval mean loss: 2812.016738783383
INFO:root:eval perplexity: 9.971635818481445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/138
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [24:15:40<10:47:16, 626.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1303.91943359375
INFO:root:current train perplexity2.8150107860565186
INFO:root:current mean train loss 1308.3739535627694
INFO:root:current train perplexity2.805927038192749
INFO:root:current mean train loss 1306.8088802415498
INFO:root:current train perplexity2.801659107208252
INFO:root:current mean train loss 1306.9331390823143
INFO:root:current train perplexity2.802551031112671
INFO:root:current mean train loss 1306.662747706724
INFO:root:current train perplexity2.805189609527588
INFO:root:current mean train loss 1308.2665023383745
INFO:root:current train perplexity2.8065881729125977
INFO:root:current mean train loss 1309.3837375847868
INFO:root:current train perplexity2.807537078857422
INFO:root:current mean train loss 1309.393201584784
INFO:root:current train perplexity2.8088974952697754
INFO:root:current mean train loss 1310.449472569573
INFO:root:current train perplexity2.811089277267456
INFO:root:current mean train loss 1310.9195458467675
INFO:root:current train perplexity2.8117589950561523
INFO:root:current mean train loss 1311.7207285903858
INFO:root:current train perplexity2.8134100437164307
INFO:root:current mean train loss 1312.6762887213429
INFO:root:current train perplexity2.8133881092071533
INFO:root:current mean train loss 1313.1294926777423
INFO:root:current train perplexity2.815795421600342
INFO:root:current mean train loss 1313.5869785918621
INFO:root:current train perplexity2.8164236545562744
INFO:root:current mean train loss 1314.363107394842
INFO:root:current train perplexity2.817552328109741
INFO:root:current mean train loss 1314.9345258299202
INFO:root:current train perplexity2.818272113800049
INFO:root:current mean train loss 1315.387452433392
INFO:root:current train perplexity2.8201687335968018
INFO:root:current mean train loss 1315.718665984845
INFO:root:current train perplexity2.820267915725708
INFO:root:current mean train loss 1316.0499941776761
INFO:root:current train perplexity2.8211028575897217
INFO:root:current mean train loss 1315.975325730037
INFO:root:current train perplexity2.8225200176239014

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.43s/it]
INFO:root:final mean train loss: 1315.6891979962002
INFO:root:final train perplexity: 2.822524309158325
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.44s/it]
INFO:root:eval mean loss: 2240.641627534907
INFO:root:eval perplexity: 6.123288631439209
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it]
INFO:root:eval mean loss: 2814.598534550227
INFO:root:eval perplexity: 9.99271011352539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/139
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [24:26:03<10:35:37, 625.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1302.4628788117438
INFO:root:current train perplexity2.805295705795288
INFO:root:current mean train loss 1306.7153124397184
INFO:root:current train perplexity2.8005216121673584
INFO:root:current mean train loss 1308.323930813156
INFO:root:current train perplexity2.799143075942993
INFO:root:current mean train loss 1310.2685543502892
INFO:root:current train perplexity2.7993016242980957
INFO:root:current mean train loss 1310.738002232143
INFO:root:current train perplexity2.8019561767578125
INFO:root:current mean train loss 1310.3953535955573
INFO:root:current train perplexity2.799692392349243
INFO:root:current mean train loss 1309.5542833034365
INFO:root:current train perplexity2.8020286560058594
INFO:root:current mean train loss 1309.8263218196357
INFO:root:current train perplexity2.804499387741089
INFO:root:current mean train loss 1311.3710304490376
INFO:root:current train perplexity2.8060193061828613
INFO:root:current mean train loss 1312.545376783597
INFO:root:current train perplexity2.805732011795044
INFO:root:current mean train loss 1313.943186614473
INFO:root:current train perplexity2.8081557750701904
INFO:root:current mean train loss 1313.5533096392267
INFO:root:current train perplexity2.8094866275787354
INFO:root:current mean train loss 1312.5143739243883
INFO:root:current train perplexity2.8079450130462646
INFO:root:current mean train loss 1312.2950855316744
INFO:root:current train perplexity2.808807134628296
INFO:root:current mean train loss 1312.322737040174
INFO:root:current train perplexity2.809669256210327
INFO:root:current mean train loss 1312.309950668589
INFO:root:current train perplexity2.8107924461364746
INFO:root:current mean train loss 1313.1362784301905
INFO:root:current train perplexity2.8120017051696777
INFO:root:current mean train loss 1313.4319252247979
INFO:root:current train perplexity2.8136205673217773
INFO:root:current mean train loss 1313.3376415019134
INFO:root:current train perplexity2.815545082092285
INFO:root:current mean train loss 1313.3923020046907
INFO:root:current train perplexity2.8162076473236084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.45s/it]
INFO:root:final mean train loss: 1313.0696475461343
INFO:root:final train perplexity: 2.8166990280151367
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it]
INFO:root:eval mean loss: 2241.7800028915944
INFO:root:eval perplexity: 6.1289286613464355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 2817.755478446365
INFO:root:eval perplexity: 10.018542289733887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/140
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [24:36:32<10:26:17, 626.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1302.965956289557
INFO:root:current train perplexity2.8191709518432617
INFO:root:current mean train loss 1307.1318673075245
INFO:root:current train perplexity2.806450366973877
INFO:root:current mean train loss 1304.8848697566643
INFO:root:current train perplexity2.8049845695495605
INFO:root:current mean train loss 1304.9294890954816
INFO:root:current train perplexity2.801614999771118
INFO:root:current mean train loss 1306.7231506475077
INFO:root:current train perplexity2.805532693862915
INFO:root:current mean train loss 1305.2780110255424
INFO:root:current train perplexity2.802347183227539
INFO:root:current mean train loss 1306.6685857534058
INFO:root:current train perplexity2.8032400608062744
INFO:root:current mean train loss 1307.5653171759668
INFO:root:current train perplexity2.8035271167755127
INFO:root:current mean train loss 1306.9874013438566
INFO:root:current train perplexity2.804469347000122
INFO:root:current mean train loss 1308.0591927548837
INFO:root:current train perplexity2.8067378997802734
INFO:root:current mean train loss 1309.276327025349
INFO:root:current train perplexity2.807629108428955
INFO:root:current mean train loss 1309.719289221533
INFO:root:current train perplexity2.8084332942962646
INFO:root:current mean train loss 1309.7505713157861
INFO:root:current train perplexity2.8084557056427
INFO:root:current mean train loss 1309.782793184741
INFO:root:current train perplexity2.8079464435577393
INFO:root:current mean train loss 1311.0683416298227
INFO:root:current train perplexity2.808844804763794
INFO:root:current mean train loss 1311.2836333474756
INFO:root:current train perplexity2.8105661869049072
INFO:root:current mean train loss 1311.529082397679
INFO:root:current train perplexity2.8115055561065674
INFO:root:current mean train loss 1311.3066884513114
INFO:root:current train perplexity2.8115899562835693
INFO:root:current mean train loss 1311.4480737967335
INFO:root:current train perplexity2.812242269515991
INFO:root:current mean train loss 1311.321850006119
INFO:root:current train perplexity2.811962842941284

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:43<00:00, 583.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:43<00:00, 583.74s/it]
INFO:root:final mean train loss: 1311.0090300636464
INFO:root:final train perplexity: 2.8121254444122314
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it]
INFO:root:eval mean loss: 2244.426709763547
INFO:root:eval perplexity: 6.142062187194824
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it]
INFO:root:eval mean loss: 2819.472796933871
INFO:root:eval perplexity: 10.032624244689941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/141
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [24:47:30<10:25:24, 636.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1303.1595268249512
INFO:root:current train perplexity2.7944741249084473
INFO:root:current mean train loss 1300.428051384128
INFO:root:current train perplexity2.796205759048462
INFO:root:current mean train loss 1301.1354056693413
INFO:root:current train perplexity2.79278826713562
INFO:root:current mean train loss 1302.9596739489623
INFO:root:current train perplexity2.796198606491089
INFO:root:current mean train loss 1303.8603146460748
INFO:root:current train perplexity2.7968862056732178
INFO:root:current mean train loss 1305.1758244661676
INFO:root:current train perplexity2.7968382835388184
INFO:root:current mean train loss 1304.910224125303
INFO:root:current train perplexity2.796452283859253
INFO:root:current mean train loss 1304.7350790512621
INFO:root:current train perplexity2.7978594303131104
INFO:root:current mean train loss 1305.2071967806135
INFO:root:current train perplexity2.798922538757324
INFO:root:current mean train loss 1306.1518381877117
INFO:root:current train perplexity2.800114154815674
INFO:root:current mean train loss 1307.0632212840728
INFO:root:current train perplexity2.80110239982605
INFO:root:current mean train loss 1306.7258423259825
INFO:root:current train perplexity2.801532506942749
INFO:root:current mean train loss 1306.7935207037278
INFO:root:current train perplexity2.801903247833252
INFO:root:current mean train loss 1307.3537325708778
INFO:root:current train perplexity2.8018763065338135
INFO:root:current mean train loss 1307.7840048234093
INFO:root:current train perplexity2.8022937774658203
INFO:root:current mean train loss 1308.9069359188989
INFO:root:current train perplexity2.8042824268341064
INFO:root:current mean train loss 1309.0750172453106
INFO:root:current train perplexity2.806030511856079
INFO:root:current mean train loss 1309.9062481648673
INFO:root:current train perplexity2.8066647052764893
INFO:root:current mean train loss 1309.8364597755142
INFO:root:current train perplexity2.8078665733337402

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.60s/it]
INFO:root:final mean train loss: 1309.1950119103196
INFO:root:final train perplexity: 2.808105230331421
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it]
INFO:root:eval mean loss: 2247.1973617229055
INFO:root:eval perplexity: 6.15584135055542
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.14s/it]
INFO:root:eval mean loss: 2823.487775653812
INFO:root:eval perplexity: 10.065622329711914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/142
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [24:58:02<10:13:37, 634.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1325.0801814152644
INFO:root:current train perplexity2.7759246826171875
INFO:root:current mean train loss 1316.3176874481471
INFO:root:current train perplexity2.7950026988983154
INFO:root:current mean train loss 1309.2786252017313
INFO:root:current train perplexity2.782188653945923
INFO:root:current mean train loss 1307.6708812774561
INFO:root:current train perplexity2.7860589027404785
INFO:root:current mean train loss 1306.9315108698736
INFO:root:current train perplexity2.786681890487671
INFO:root:current mean train loss 1305.0710196987695
INFO:root:current train perplexity2.7862389087677
INFO:root:current mean train loss 1305.3743097949377
INFO:root:current train perplexity2.7889509201049805
INFO:root:current mean train loss 1304.706040648558
INFO:root:current train perplexity2.792560577392578
INFO:root:current mean train loss 1305.2241922638952
INFO:root:current train perplexity2.7941598892211914
INFO:root:current mean train loss 1304.7286917110914
INFO:root:current train perplexity2.7938477993011475
INFO:root:current mean train loss 1304.6516690494277
INFO:root:current train perplexity2.7949352264404297
INFO:root:current mean train loss 1304.999895039273
INFO:root:current train perplexity2.795787811279297
INFO:root:current mean train loss 1305.2087971938117
INFO:root:current train perplexity2.7969682216644287
INFO:root:current mean train loss 1305.4678687322985
INFO:root:current train perplexity2.7969133853912354
INFO:root:current mean train loss 1306.1962591712559
INFO:root:current train perplexity2.7978293895721436
INFO:root:current mean train loss 1307.0553003526727
INFO:root:current train perplexity2.798593282699585
INFO:root:current mean train loss 1307.3960941738028
INFO:root:current train perplexity2.800835609436035
INFO:root:current mean train loss 1307.430742521002
INFO:root:current train perplexity2.8014321327209473
INFO:root:current mean train loss 1307.5947618437156
INFO:root:current train perplexity2.80190110206604
INFO:root:current mean train loss 1307.6130619318274
INFO:root:current train perplexity2.802780866622925

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.13s/it]
INFO:root:final mean train loss: 1307.39982025562
INFO:root:final train perplexity: 2.8041324615478516
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it]
INFO:root:eval mean loss: 2248.0637406153037
INFO:root:eval perplexity: 6.160155296325684
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it]
INFO:root:eval mean loss: 2825.078605489528
INFO:root:eval perplexity: 10.078726768493652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/143
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [25:08:23<9:59:09, 630.69s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1303.7372680664062
INFO:root:current train perplexity2.7715156078338623
INFO:root:current mean train loss 1301.8500028170072
INFO:root:current train perplexity2.7770566940307617
INFO:root:current mean train loss 1305.5754649286685
INFO:root:current train perplexity2.7757582664489746
INFO:root:current mean train loss 1303.5642063950047
INFO:root:current train perplexity2.7774658203125
INFO:root:current mean train loss 1305.0076029932777
INFO:root:current train perplexity2.780188798904419
INFO:root:current mean train loss 1303.7305339309405
INFO:root:current train perplexity2.7839736938476562
INFO:root:current mean train loss 1303.7956488715279
INFO:root:current train perplexity2.7870750427246094
INFO:root:current mean train loss 1303.544542286494
INFO:root:current train perplexity2.789458751678467
INFO:root:current mean train loss 1303.9911819641848
INFO:root:current train perplexity2.7904257774353027
INFO:root:current mean train loss 1303.5191818401377
INFO:root:current train perplexity2.7901055812835693
INFO:root:current mean train loss 1304.077959790276
INFO:root:current train perplexity2.792687177658081
INFO:root:current mean train loss 1305.2277916292173
INFO:root:current train perplexity2.7941579818725586
INFO:root:current mean train loss 1304.8562957515562
INFO:root:current train perplexity2.7941982746124268
INFO:root:current mean train loss 1305.4368317338758
INFO:root:current train perplexity2.7953476905822754
INFO:root:current mean train loss 1305.5596887975305
INFO:root:current train perplexity2.7968857288360596
INFO:root:current mean train loss 1305.3784235536662
INFO:root:current train perplexity2.7981159687042236
INFO:root:current mean train loss 1305.5572998795772
INFO:root:current train perplexity2.799058675765991
INFO:root:current mean train loss 1305.7394443754515
INFO:root:current train perplexity2.799842119216919
INFO:root:current mean train loss 1305.830238817559
INFO:root:current train perplexity2.7997167110443115
INFO:root:current mean train loss 1306.1186630960574
INFO:root:current train perplexity2.799748182296753

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.47s/it]
INFO:root:final mean train loss: 1305.5437049269376
INFO:root:final train perplexity: 2.800030469894409
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.97s/it]
INFO:root:eval mean loss: 2252.410887806128
INFO:root:eval perplexity: 6.181850910186768
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it]
INFO:root:eval mean loss: 2829.3351968535294
INFO:root:eval perplexity: 10.113873481750488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/144
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [25:19:00<9:50:18, 632.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1288.069554105718
INFO:root:current train perplexity2.7849552631378174
INFO:root:current mean train loss 1295.723558075574
INFO:root:current train perplexity2.7796642780303955
INFO:root:current mean train loss 1295.0482306229442
INFO:root:current train perplexity2.7755954265594482
INFO:root:current mean train loss 1295.3561522733926
INFO:root:current train perplexity2.7749557495117188
INFO:root:current mean train loss 1296.840255020449
INFO:root:current train perplexity2.7782809734344482
INFO:root:current mean train loss 1296.8122714808044
INFO:root:current train perplexity2.7765862941741943
INFO:root:current mean train loss 1297.8226984368962
INFO:root:current train perplexity2.7814526557922363
INFO:root:current mean train loss 1299.588480059561
INFO:root:current train perplexity2.7829532623291016
INFO:root:current mean train loss 1300.7115327188792
INFO:root:current train perplexity2.784335136413574
INFO:root:current mean train loss 1301.7085811691527
INFO:root:current train perplexity2.7868096828460693
INFO:root:current mean train loss 1301.7286255698946
INFO:root:current train perplexity2.787923574447632
INFO:root:current mean train loss 1301.7881517086012
INFO:root:current train perplexity2.7888574600219727
INFO:root:current mean train loss 1302.278863510707
INFO:root:current train perplexity2.7893924713134766
INFO:root:current mean train loss 1303.1742199824841
INFO:root:current train perplexity2.790119171142578
INFO:root:current mean train loss 1303.1515144817402
INFO:root:current train perplexity2.790645122528076
INFO:root:current mean train loss 1302.912586530255
INFO:root:current train perplexity2.7900848388671875
INFO:root:current mean train loss 1303.245882146635
INFO:root:current train perplexity2.7910525798797607
INFO:root:current mean train loss 1303.3555691592953
INFO:root:current train perplexity2.79289174079895
INFO:root:current mean train loss 1303.1947876703564
INFO:root:current train perplexity2.792879819869995
INFO:root:current mean train loss 1303.4435805686633
INFO:root:current train perplexity2.793802261352539

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.29s/it]
INFO:root:final mean train loss: 1302.9247336183241
INFO:root:final train perplexity: 2.79425311088562
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it]
INFO:root:eval mean loss: 2252.5126728030805
INFO:root:eval perplexity: 6.1823577880859375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.03s/it]
INFO:root:eval mean loss: 2829.8528018166835
INFO:root:eval perplexity: 10.118154525756836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/145
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [25:29:26<9:38:02, 630.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1297.0555629730225
INFO:root:current train perplexity2.771697521209717
INFO:root:current mean train loss 1295.6030839129191
INFO:root:current train perplexity2.7731897830963135
INFO:root:current mean train loss 1287.7120777476919
INFO:root:current train perplexity2.7687933444976807
INFO:root:current mean train loss 1290.4877560793698
INFO:root:current train perplexity2.7709736824035645
INFO:root:current mean train loss 1291.6348903261382
INFO:root:current train perplexity2.7763447761535645
INFO:root:current mean train loss 1292.7476694093527
INFO:root:current train perplexity2.777989149093628
INFO:root:current mean train loss 1293.4055256671215
INFO:root:current train perplexity2.779625415802002
INFO:root:current mean train loss 1294.818047488547
INFO:root:current train perplexity2.7785093784332275
INFO:root:current mean train loss 1294.3959563926414
INFO:root:current train perplexity2.7791879177093506
INFO:root:current mean train loss 1295.1953016099098
INFO:root:current train perplexity2.781442642211914
INFO:root:current mean train loss 1296.160283368333
INFO:root:current train perplexity2.7839534282684326
INFO:root:current mean train loss 1296.4312976955139
INFO:root:current train perplexity2.784675121307373
INFO:root:current mean train loss 1297.4594969930529
INFO:root:current train perplexity2.785743236541748
INFO:root:current mean train loss 1297.9352163723138
INFO:root:current train perplexity2.7865920066833496
INFO:root:current mean train loss 1298.574766648923
INFO:root:current train perplexity2.786781072616577
INFO:root:current mean train loss 1299.3723128921235
INFO:root:current train perplexity2.787950038909912
INFO:root:current mean train loss 1299.7722940444946
INFO:root:current train perplexity2.7885184288024902
INFO:root:current mean train loss 1300.1111337397915
INFO:root:current train perplexity2.789519786834717
INFO:root:current mean train loss 1300.7597504971877
INFO:root:current train perplexity2.7901647090911865
INFO:root:current mean train loss 1301.118717791835
INFO:root:current train perplexity2.7898271083831787

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.58s/it]
INFO:root:final mean train loss: 1300.9134677227134
INFO:root:final train perplexity: 2.7898244857788086
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 2254.3550674763133
INFO:root:eval perplexity: 6.191577911376953
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.84s/it]
INFO:root:eval mean loss: 2831.7782939072194
INFO:root:eval perplexity: 10.134100914001465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/146
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [25:39:53<9:26:35, 629.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1306.3144124348958
INFO:root:current train perplexity2.7825870513916016
INFO:root:current mean train loss 1299.9389479832096
INFO:root:current train perplexity2.7742063999176025
INFO:root:current mean train loss 1297.6777773819783
INFO:root:current train perplexity2.7726690769195557
INFO:root:current mean train loss 1296.307965776739
INFO:root:current train perplexity2.7767832279205322
INFO:root:current mean train loss 1297.049383151556
INFO:root:current train perplexity2.777402400970459
INFO:root:current mean train loss 1297.8758782339178
INFO:root:current train perplexity2.7805826663970947
INFO:root:current mean train loss 1297.9847550133077
INFO:root:current train perplexity2.7825825214385986
INFO:root:current mean train loss 1297.489070408781
INFO:root:current train perplexity2.7821450233459473
INFO:root:current mean train loss 1298.8878348412227
INFO:root:current train perplexity2.7833080291748047
INFO:root:current mean train loss 1298.0084462452614
INFO:root:current train perplexity2.7837326526641846
INFO:root:current mean train loss 1298.3289750881706
INFO:root:current train perplexity2.7843687534332275
INFO:root:current mean train loss 1298.535467989257
INFO:root:current train perplexity2.7845635414123535
INFO:root:current mean train loss 1298.0236290388978
INFO:root:current train perplexity2.785451889038086
INFO:root:current mean train loss 1298.109056521118
INFO:root:current train perplexity2.785465955734253
INFO:root:current mean train loss 1298.7208484389507
INFO:root:current train perplexity2.78564453125
INFO:root:current mean train loss 1298.6852605772651
INFO:root:current train perplexity2.785484790802002
INFO:root:current mean train loss 1299.2472167097337
INFO:root:current train perplexity2.786020517349243
INFO:root:current mean train loss 1300.0579840838407
INFO:root:current train perplexity2.786982774734497
INFO:root:current mean train loss 1300.071334165566
INFO:root:current train perplexity2.7872698307037354
INFO:root:current mean train loss 1300.2283533780878
INFO:root:current train perplexity2.787407398223877

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.42s/it]
INFO:root:final mean train loss: 1299.8573739825626
INFO:root:final train perplexity: 2.787501811981201
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.70s/it]
INFO:root:eval mean loss: 2257.4983451248063
INFO:root:eval perplexity: 6.207338333129883
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.81s/it]
INFO:root:eval mean loss: 2835.42073524421
INFO:root:eval perplexity: 10.16433334350586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/147
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [25:50:27<9:17:04, 630.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1288.6618702168366
INFO:root:current train perplexity2.777353048324585
INFO:root:current mean train loss 1291.6170469341855
INFO:root:current train perplexity2.769273281097412
INFO:root:current mean train loss 1290.0966825549235
INFO:root:current train perplexity2.7750697135925293
INFO:root:current mean train loss 1289.0771530381398
INFO:root:current train perplexity2.7713961601257324
INFO:root:current mean train loss 1292.1596691943555
INFO:root:current train perplexity2.771138906478882
INFO:root:current mean train loss 1293.2927041962794
INFO:root:current train perplexity2.7720298767089844
INFO:root:current mean train loss 1293.6497012250402
INFO:root:current train perplexity2.772307872772217
INFO:root:current mean train loss 1294.2265719841596
INFO:root:current train perplexity2.7739384174346924
INFO:root:current mean train loss 1294.280243395697
INFO:root:current train perplexity2.774864673614502
INFO:root:current mean train loss 1294.6081578440082
INFO:root:current train perplexity2.775632619857788
INFO:root:current mean train loss 1295.6175371458405
INFO:root:current train perplexity2.776914119720459
INFO:root:current mean train loss 1295.6700859260877
INFO:root:current train perplexity2.7774875164031982
INFO:root:current mean train loss 1295.888956078763
INFO:root:current train perplexity2.7786002159118652
INFO:root:current mean train loss 1295.900376566831
INFO:root:current train perplexity2.779123306274414
INFO:root:current mean train loss 1296.3445011643128
INFO:root:current train perplexity2.7786991596221924
INFO:root:current mean train loss 1296.962872062368
INFO:root:current train perplexity2.7796435356140137
INFO:root:current mean train loss 1297.3587963522111
INFO:root:current train perplexity2.780564308166504
INFO:root:current mean train loss 1297.533213444626
INFO:root:current train perplexity2.7815680503845215
INFO:root:current mean train loss 1297.9185900351522
INFO:root:current train perplexity2.7821826934814453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.09s/it]
INFO:root:final mean train loss: 1298.0725136745837
INFO:root:final train perplexity: 2.7835800647735596
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.60s/it]
INFO:root:eval mean loss: 2258.600971194869
INFO:root:eval perplexity: 6.2128753662109375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.09s/it]
INFO:root:eval mean loss: 2838.437796085439
INFO:root:eval perplexity: 10.189446449279785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/148
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [26:00:51<9:04:50, 628.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1303.171004231771
INFO:root:current train perplexity2.7748610973358154
INFO:root:current mean train loss 1302.212744140625
INFO:root:current train perplexity2.7804110050201416
INFO:root:current mean train loss 1288.5476057185683
INFO:root:current train perplexity2.77640438079834
INFO:root:current mean train loss 1289.5206477089534
INFO:root:current train perplexity2.776113748550415
INFO:root:current mean train loss 1290.5881100574172
INFO:root:current train perplexity2.773303747177124
INFO:root:current mean train loss 1291.0054834458435
INFO:root:current train perplexity2.7731430530548096
INFO:root:current mean train loss 1292.330384392467
INFO:root:current train perplexity2.7732462882995605
INFO:root:current mean train loss 1293.541239790483
INFO:root:current train perplexity2.7728922367095947
INFO:root:current mean train loss 1294.4643881206864
INFO:root:current train perplexity2.771979331970215
INFO:root:current mean train loss 1294.6568084550033
INFO:root:current train perplexity2.7728617191314697
INFO:root:current mean train loss 1294.7483380397553
INFO:root:current train perplexity2.7731237411499023
INFO:root:current mean train loss 1294.5443941809137
INFO:root:current train perplexity2.774700880050659
INFO:root:current mean train loss 1294.9942624943737
INFO:root:current train perplexity2.774433135986328
INFO:root:current mean train loss 1295.5316746932926
INFO:root:current train perplexity2.7746572494506836
INFO:root:current mean train loss 1294.9772366904538
INFO:root:current train perplexity2.775416851043701
INFO:root:current mean train loss 1294.8464754312345
INFO:root:current train perplexity2.775949001312256
INFO:root:current mean train loss 1295.1043168295278
INFO:root:current train perplexity2.777082920074463
INFO:root:current mean train loss 1295.6296549004646
INFO:root:current train perplexity2.7779271602630615
INFO:root:current mean train loss 1295.4211903974044
INFO:root:current train perplexity2.777632474899292
INFO:root:current mean train loss 1295.7932642685216
INFO:root:current train perplexity2.778674602508545

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.96s/it]
INFO:root:final mean train loss: 1296.0238358752028
INFO:root:final train perplexity: 2.7790870666503906
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 2258.8331519593585
INFO:root:eval perplexity: 6.214043140411377
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it]
INFO:root:eval mean loss: 2839.392584618102
INFO:root:eval perplexity: 10.197404861450195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/149
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [26:11:12<8:52:31, 626.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1295.165599822998
INFO:root:current train perplexity2.8007900714874268
INFO:root:current mean train loss 1288.841856060606
INFO:root:current train perplexity2.7589778900146484
INFO:root:current mean train loss 1289.277948313746
INFO:root:current train perplexity2.7691187858581543
INFO:root:current mean train loss 1287.2805642736964
INFO:root:current train perplexity2.7692885398864746
INFO:root:current mean train loss 1290.081851252803
INFO:root:current train perplexity2.7678911685943604
INFO:root:current mean train loss 1290.3057937048432
INFO:root:current train perplexity2.7666022777557373
INFO:root:current mean train loss 1291.259107565578
INFO:root:current train perplexity2.7680447101593018
INFO:root:current mean train loss 1290.4767199240096
INFO:root:current train perplexity2.7677063941955566
INFO:root:current mean train loss 1291.6783655606782
INFO:root:current train perplexity2.7690165042877197
INFO:root:current mean train loss 1292.1211043591152
INFO:root:current train perplexity2.770501136779785
INFO:root:current mean train loss 1292.3959239397861
INFO:root:current train perplexity2.7687458992004395
INFO:root:current mean train loss 1292.625021890701
INFO:root:current train perplexity2.7702722549438477
INFO:root:current mean train loss 1292.6862415462344
INFO:root:current train perplexity2.7706799507141113
INFO:root:current mean train loss 1293.0671619495472
INFO:root:current train perplexity2.7712812423706055
INFO:root:current mean train loss 1293.4480236202644
INFO:root:current train perplexity2.7714431285858154
INFO:root:current mean train loss 1293.7095140103572
INFO:root:current train perplexity2.7734525203704834
INFO:root:current mean train loss 1294.1024037529442
INFO:root:current train perplexity2.7739505767822266
INFO:root:current mean train loss 1294.620681797935
INFO:root:current train perplexity2.774782657623291
INFO:root:current mean train loss 1294.6770146798879
INFO:root:current train perplexity2.774101734161377
INFO:root:current mean train loss 1294.5426153021076
INFO:root:current train perplexity2.774794340133667

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.16s/it]
INFO:root:final mean train loss: 1294.2933665711773
INFO:root:final train perplexity: 2.775296449661255
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it]
INFO:root:eval mean loss: 2262.4160632410794
INFO:root:eval perplexity: 6.232074737548828
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.83s/it]
INFO:root:eval mean loss: 2843.030224089927
INFO:root:eval perplexity: 10.227787971496582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/150
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [26:21:44<8:43:34, 628.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1291.8791204958545
INFO:root:current train perplexity2.7553117275238037
INFO:root:current mean train loss 1285.1571987075295
INFO:root:current train perplexity2.75466251373291
INFO:root:current mean train loss 1284.920147876663
INFO:root:current train perplexity2.7563018798828125
INFO:root:current mean train loss 1284.219583855659
INFO:root:current train perplexity2.754265785217285
INFO:root:current mean train loss 1285.4103900595073
INFO:root:current train perplexity2.7518575191497803
INFO:root:current mean train loss 1284.8892940111282
INFO:root:current train perplexity2.7536122798919678
INFO:root:current mean train loss 1287.700159199249
INFO:root:current train perplexity2.759941577911377
INFO:root:current mean train loss 1288.2554121641356
INFO:root:current train perplexity2.760854482650757
INFO:root:current mean train loss 1289.7416447256423
INFO:root:current train perplexity2.7604868412017822
INFO:root:current mean train loss 1289.3717724043402
INFO:root:current train perplexity2.762526035308838
INFO:root:current mean train loss 1290.1189595559758
INFO:root:current train perplexity2.763434410095215
INFO:root:current mean train loss 1290.752044810535
INFO:root:current train perplexity2.764512538909912
INFO:root:current mean train loss 1290.8091512272317
INFO:root:current train perplexity2.765474557876587
INFO:root:current mean train loss 1291.1461192499362
INFO:root:current train perplexity2.766388177871704
INFO:root:current mean train loss 1291.0111800905258
INFO:root:current train perplexity2.766395092010498
INFO:root:current mean train loss 1291.7811876645467
INFO:root:current train perplexity2.7678894996643066
INFO:root:current mean train loss 1291.8600867683776
INFO:root:current train perplexity2.768319845199585
INFO:root:current mean train loss 1292.295129582976
INFO:root:current train perplexity2.769320011138916
INFO:root:current mean train loss 1292.2917177438608
INFO:root:current train perplexity2.769754409790039
INFO:root:current mean train loss 1292.6519227984504
INFO:root:current train perplexity2.770371198654175

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.35s/it]
INFO:root:final mean train loss: 1292.14733375784
INFO:root:final train perplexity: 2.7706034183502197
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it]
INFO:root:eval mean loss: 2262.594089372784
INFO:root:eval perplexity: 6.232971668243408
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.87s/it]
INFO:root:eval mean loss: 2842.3399671189327
INFO:root:eval perplexity: 10.222012519836426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/151
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [26:32:14<8:33:18, 628.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1287.053008108428
INFO:root:current train perplexity2.7649402618408203
INFO:root:current mean train loss 1282.803970520755
INFO:root:current train perplexity2.7522945404052734
INFO:root:current mean train loss 1282.4347263422228
INFO:root:current train perplexity2.747040271759033
INFO:root:current mean train loss 1284.4361709011057
INFO:root:current train perplexity2.751710891723633
INFO:root:current mean train loss 1283.3047435580404
INFO:root:current train perplexity2.75303053855896
INFO:root:current mean train loss 1283.5086057413594
INFO:root:current train perplexity2.7555012702941895
INFO:root:current mean train loss 1284.2228730806
INFO:root:current train perplexity2.7567832469940186
INFO:root:current mean train loss 1284.8269462087446
INFO:root:current train perplexity2.756274938583374
INFO:root:current mean train loss 1285.3120369503736
INFO:root:current train perplexity2.7584517002105713
INFO:root:current mean train loss 1285.7572235044238
INFO:root:current train perplexity2.7586634159088135
INFO:root:current mean train loss 1286.656997193986
INFO:root:current train perplexity2.760345697402954
INFO:root:current mean train loss 1286.9496576168524
INFO:root:current train perplexity2.7615411281585693
INFO:root:current mean train loss 1288.4137523102722
INFO:root:current train perplexity2.7648160457611084
INFO:root:current mean train loss 1288.4054339340455
INFO:root:current train perplexity2.76525616645813
INFO:root:current mean train loss 1289.694353756768
INFO:root:current train perplexity2.76615047454834
INFO:root:current mean train loss 1290.1412825115492
INFO:root:current train perplexity2.7665908336639404
INFO:root:current mean train loss 1290.2193741266037
INFO:root:current train perplexity2.7671852111816406
INFO:root:current mean train loss 1290.7523178843653
INFO:root:current train perplexity2.7680776119232178
INFO:root:current mean train loss 1291.0221943584413
INFO:root:current train perplexity2.768317461013794
INFO:root:current mean train loss 1291.3190968883123
INFO:root:current train perplexity2.7677814960479736

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.16s/it]
INFO:root:final mean train loss: 1290.980956569562
INFO:root:final train perplexity: 2.7680559158325195
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.01s/it]
INFO:root:eval mean loss: 2263.4508472199136
INFO:root:eval perplexity: 6.237292766571045
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.70s/it]
INFO:root:eval mean loss: 2845.4964175393397
INFO:root:eval perplexity: 10.248435974121094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/152
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [26:42:37<8:21:31, 626.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1280.1781388248305
INFO:root:current train perplexity2.749636650085449
INFO:root:current mean train loss 1285.3705841231215
INFO:root:current train perplexity2.7576563358306885
INFO:root:current mean train loss 1284.9393103501823
INFO:root:current train perplexity2.7554147243499756
INFO:root:current mean train loss 1286.6990848869941
INFO:root:current train perplexity2.7562355995178223
INFO:root:current mean train loss 1286.4563877903404
INFO:root:current train perplexity2.7515947818756104
INFO:root:current mean train loss 1286.9112226378243
INFO:root:current train perplexity2.7538797855377197
INFO:root:current mean train loss 1286.2373375732063
INFO:root:current train perplexity2.7536096572875977
INFO:root:current mean train loss 1286.9987811676845
INFO:root:current train perplexity2.7566213607788086
INFO:root:current mean train loss 1287.0879748161894
INFO:root:current train perplexity2.7559382915496826
INFO:root:current mean train loss 1288.0112365536384
INFO:root:current train perplexity2.7583625316619873
INFO:root:current mean train loss 1287.815083877972
INFO:root:current train perplexity2.7595436573028564
INFO:root:current mean train loss 1288.4835085381114
INFO:root:current train perplexity2.7604470252990723
INFO:root:current mean train loss 1288.6710220301236
INFO:root:current train perplexity2.7617149353027344
INFO:root:current mean train loss 1288.9825072271274
INFO:root:current train perplexity2.7622461318969727
INFO:root:current mean train loss 1288.727209892453
INFO:root:current train perplexity2.761673927307129
INFO:root:current mean train loss 1288.7786188950963
INFO:root:current train perplexity2.7620468139648438
INFO:root:current mean train loss 1288.6526699236158
INFO:root:current train perplexity2.7617249488830566
INFO:root:current mean train loss 1288.613731670968
INFO:root:current train perplexity2.762733221054077
INFO:root:current mean train loss 1289.0750806325304
INFO:root:current train perplexity2.763401508331299
INFO:root:current mean train loss 1289.184911992414
INFO:root:current train perplexity2.7641377449035645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.02s/it]
INFO:root:final mean train loss: 1289.184911992414
INFO:root:final train perplexity: 2.7641377449035645
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it]
INFO:root:eval mean loss: 2267.0982453907636
INFO:root:eval perplexity: 6.255719184875488
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.76s/it]
INFO:root:eval mean loss: 2848.8894700936394
INFO:root:eval perplexity: 10.276911735534668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/153
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [26:52:59<8:09:54, 625.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1283.5069592285156
INFO:root:current train perplexity2.7607131004333496
INFO:root:current mean train loss 1282.3084674072265
INFO:root:current train perplexity2.7572004795074463
INFO:root:current mean train loss 1286.5334029134115
INFO:root:current train perplexity2.7563424110412598
INFO:root:current mean train loss 1285.1663806152344
INFO:root:current train perplexity2.752182960510254
INFO:root:current mean train loss 1285.3111450195313
INFO:root:current train perplexity2.7526164054870605
INFO:root:current mean train loss 1284.9720277913411
INFO:root:current train perplexity2.7513577938079834
INFO:root:current mean train loss 1285.6013457380022
INFO:root:current train perplexity2.752701759338379
INFO:root:current mean train loss 1285.387356414795
INFO:root:current train perplexity2.751636266708374
INFO:root:current mean train loss 1285.6342583550347
INFO:root:current train perplexity2.7537546157836914
INFO:root:current mean train loss 1286.058025024414
INFO:root:current train perplexity2.7545554637908936
INFO:root:current mean train loss 1287.080605024858
INFO:root:current train perplexity2.7548701763153076
INFO:root:current mean train loss 1286.1544893391927
INFO:root:current train perplexity2.755136013031006
INFO:root:current mean train loss 1286.2479240534856
INFO:root:current train perplexity2.7550315856933594
INFO:root:current mean train loss 1286.6914720807756
INFO:root:current train perplexity2.756648063659668
INFO:root:current mean train loss 1287.1330793457032
INFO:root:current train perplexity2.756025552749634
INFO:root:current mean train loss 1287.7268873596192
INFO:root:current train perplexity2.7568440437316895
INFO:root:current mean train loss 1286.9364652745865
INFO:root:current train perplexity2.757692813873291
INFO:root:current mean train loss 1287.3348970540364
INFO:root:current train perplexity2.758547306060791
INFO:root:current mean train loss 1287.3726170590048
INFO:root:current train perplexity2.7591099739074707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:30<00:00, 570.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:30<00:00, 570.15s/it]
INFO:root:final mean train loss: 1287.0670941035914
INFO:root:final train perplexity: 2.7595252990722656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.58s/it]
INFO:root:eval mean loss: 2267.2809253449136
INFO:root:eval perplexity: 6.256643295288086
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.92s/it]
INFO:root:eval mean loss: 2849.209032856826
INFO:root:eval perplexity: 10.279600143432617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/154
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [27:03:44<8:03:59, 631.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1266.6822437959559
INFO:root:current train perplexity2.708064556121826
INFO:root:current mean train loss 1275.6740461822249
INFO:root:current train perplexity2.743803024291992
INFO:root:current mean train loss 1276.9826812040972
INFO:root:current train perplexity2.746183395385742
INFO:root:current mean train loss 1277.8971197567528
INFO:root:current train perplexity2.744457960128784
INFO:root:current mean train loss 1280.8393051184053
INFO:root:current train perplexity2.7464864253997803
INFO:root:current mean train loss 1281.282870205966
INFO:root:current train perplexity2.744053363800049
INFO:root:current mean train loss 1281.311618600904
INFO:root:current train perplexity2.744460344314575
INFO:root:current mean train loss 1282.555890156468
INFO:root:current train perplexity2.746196985244751
INFO:root:current mean train loss 1282.7967731004246
INFO:root:current train perplexity2.7483181953430176
INFO:root:current mean train loss 1283.118929364819
INFO:root:current train perplexity2.7488088607788086
INFO:root:current mean train loss 1283.389194124685
INFO:root:current train perplexity2.7487285137176514
INFO:root:current mean train loss 1284.0184471519697
INFO:root:current train perplexity2.7498743534088135
INFO:root:current mean train loss 1284.0294401095161
INFO:root:current train perplexity2.749116897583008
INFO:root:current mean train loss 1283.9610554920332
INFO:root:current train perplexity2.750473976135254
INFO:root:current mean train loss 1285.0943983423938
INFO:root:current train perplexity2.75117826461792
INFO:root:current mean train loss 1285.254414728777
INFO:root:current train perplexity2.7517476081848145
INFO:root:current mean train loss 1285.3298336069158
INFO:root:current train perplexity2.752714157104492
INFO:root:current mean train loss 1285.0695920931994
INFO:root:current train perplexity2.7532594203948975
INFO:root:current mean train loss 1285.3711446070317
INFO:root:current train perplexity2.7543768882751465
INFO:root:current mean train loss 1285.5604451179006
INFO:root:current train perplexity2.7545166015625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.25s/it]
INFO:root:final mean train loss: 1284.9622551883883
INFO:root:final train perplexity: 2.7549479007720947
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.44s/it]
INFO:root:eval mean loss: 2269.698831761137
INFO:root:eval perplexity: 6.268889904022217
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it]
INFO:root:eval mean loss: 2852.3188952723294
INFO:root:eval perplexity: 10.305778503417969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/155
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [27:14:07<7:51:40, 628.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1274.3515768612133
INFO:root:current train perplexity2.709662437438965
INFO:root:current mean train loss 1278.6846887389227
INFO:root:current train perplexity2.744788646697998
INFO:root:current mean train loss 1277.2261321238982
INFO:root:current train perplexity2.744166374206543
INFO:root:current mean train loss 1278.249169629491
INFO:root:current train perplexity2.7419681549072266
INFO:root:current mean train loss 1278.6478361490135
INFO:root:current train perplexity2.743220567703247
INFO:root:current mean train loss 1279.9023151754886
INFO:root:current train perplexity2.744748592376709
INFO:root:current mean train loss 1280.2692647747438
INFO:root:current train perplexity2.7438230514526367
INFO:root:current mean train loss 1281.38823232209
INFO:root:current train perplexity2.7437407970428467
INFO:root:current mean train loss 1282.1559622419252
INFO:root:current train perplexity2.743298053741455
INFO:root:current mean train loss 1281.924073703284
INFO:root:current train perplexity2.7428576946258545
INFO:root:current mean train loss 1280.7793675907806
INFO:root:current train perplexity2.7436273097991943
INFO:root:current mean train loss 1280.9437960939222
INFO:root:current train perplexity2.744872808456421
INFO:root:current mean train loss 1281.239889927003
INFO:root:current train perplexity2.74546480178833
INFO:root:current mean train loss 1281.8951421506044
INFO:root:current train perplexity2.747133493423462
INFO:root:current mean train loss 1281.9097512217247
INFO:root:current train perplexity2.748019218444824
INFO:root:current mean train loss 1282.110538726369
INFO:root:current train perplexity2.7479519844055176
INFO:root:current mean train loss 1282.6828124701174
INFO:root:current train perplexity2.748605966567993
INFO:root:current mean train loss 1283.1655980938447
INFO:root:current train perplexity2.7499115467071533
INFO:root:current mean train loss 1283.5133022029631
INFO:root:current train perplexity2.7502493858337402
INFO:root:current mean train loss 1283.6510887106547
INFO:root:current train perplexity2.7511398792266846

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.85s/it]
INFO:root:final mean train loss: 1283.2775575423325
INFO:root:final train perplexity: 2.7512898445129395
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it]
INFO:root:eval mean loss: 2270.3713179784463
INFO:root:eval perplexity: 6.272298812866211
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it]
INFO:root:eval mean loss: 2853.5447746980276
INFO:root:eval perplexity: 10.316116333007812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/156
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [27:24:28<7:39:30, 626.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1274.283265356924
INFO:root:current train perplexity2.754913330078125
INFO:root:current mean train loss 1277.3732538286424
INFO:root:current train perplexity2.7465107440948486
INFO:root:current mean train loss 1278.4202827362426
INFO:root:current train perplexity2.7444796562194824
INFO:root:current mean train loss 1278.1448254707532
INFO:root:current train perplexity2.738579273223877
INFO:root:current mean train loss 1280.906998391162
INFO:root:current train perplexity2.7416696548461914
INFO:root:current mean train loss 1280.785837495392
INFO:root:current train perplexity2.7434909343719482
INFO:root:current mean train loss 1281.3926589426724
INFO:root:current train perplexity2.743281841278076
INFO:root:current mean train loss 1280.829587243051
INFO:root:current train perplexity2.7441935539245605
INFO:root:current mean train loss 1280.379626048858
INFO:root:current train perplexity2.7443830966949463
INFO:root:current mean train loss 1280.8480354252924
INFO:root:current train perplexity2.7433738708496094
INFO:root:current mean train loss 1281.684152880813
INFO:root:current train perplexity2.7445578575134277
INFO:root:current mean train loss 1282.1701003670382
INFO:root:current train perplexity2.7458386421203613
INFO:root:current mean train loss 1282.4648275520208
INFO:root:current train perplexity2.7464494705200195
INFO:root:current mean train loss 1282.6656288130032
INFO:root:current train perplexity2.7477400302886963
INFO:root:current mean train loss 1283.450677368248
INFO:root:current train perplexity2.7486658096313477
INFO:root:current mean train loss 1283.6376638307947
INFO:root:current train perplexity2.7489070892333984
INFO:root:current mean train loss 1283.5274399422935
INFO:root:current train perplexity2.7489545345306396
INFO:root:current mean train loss 1283.6846684706952
INFO:root:current train perplexity2.7499451637268066
INFO:root:current mean train loss 1283.4692518666009
INFO:root:current train perplexity2.7506046295166016
INFO:root:current mean train loss 1283.581659533072
INFO:root:current train perplexity2.750340700149536

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.52s/it]
INFO:root:final mean train loss: 1283.0109485312657
INFO:root:final train perplexity: 2.75071120262146
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 2271.4035155384254
INFO:root:eval perplexity: 6.277537822723389
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it]
INFO:root:eval mean loss: 2854.8302175102503
INFO:root:eval perplexity: 10.3269681930542
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/157
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [27:35:00<7:30:11, 628.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1273.3052924661076
INFO:root:current train perplexity2.724606513977051
INFO:root:current mean train loss 1272.5420633951824
INFO:root:current train perplexity2.7321841716766357
INFO:root:current mean train loss 1272.537734302122
INFO:root:current train perplexity2.7346818447113037
INFO:root:current mean train loss 1275.8541893337083
INFO:root:current train perplexity2.741652250289917
INFO:root:current mean train loss 1276.177947476379
INFO:root:current train perplexity2.7405588626861572
INFO:root:current mean train loss 1275.9649999914036
INFO:root:current train perplexity2.7400200366973877
INFO:root:current mean train loss 1275.0013636057963
INFO:root:current train perplexity2.741356134414673
INFO:root:current mean train loss 1276.1818439165752
INFO:root:current train perplexity2.7430174350738525
INFO:root:current mean train loss 1277.0778634207588
INFO:root:current train perplexity2.744089365005493
INFO:root:current mean train loss 1277.253937650318
INFO:root:current train perplexity2.7448954582214355
INFO:root:current mean train loss 1278.3124691395278
INFO:root:current train perplexity2.7450649738311768
INFO:root:current mean train loss 1279.144262862532
INFO:root:current train perplexity2.7462520599365234
INFO:root:current mean train loss 1279.903297015169
INFO:root:current train perplexity2.7450194358825684
INFO:root:current mean train loss 1280.0684231763694
INFO:root:current train perplexity2.745488405227661
INFO:root:current mean train loss 1279.5119409379258
INFO:root:current train perplexity2.7444701194763184
INFO:root:current mean train loss 1279.8445334142568
INFO:root:current train perplexity2.7445297241210938
INFO:root:current mean train loss 1279.9901134756258
INFO:root:current train perplexity2.7454802989959717
INFO:root:current mean train loss 1280.1397112678078
INFO:root:current train perplexity2.7451608180999756
INFO:root:current mean train loss 1280.3785829074377
INFO:root:current train perplexity2.745544672012329
INFO:root:current mean train loss 1281.0288547422829
INFO:root:current train perplexity2.7457244396209717

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.17s/it]
INFO:root:final mean train loss: 1280.6902900422635
INFO:root:final train perplexity: 2.7456815242767334
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 2273.857594591506
INFO:root:eval perplexity: 6.29000997543335
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.33s/it]
INFO:root:eval mean loss: 2857.6875567064217
INFO:root:eval perplexity: 10.351125717163086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/158
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [27:45:24<7:18:52, 626.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1268.7040986902573
INFO:root:current train perplexity2.7302801609039307
INFO:root:current mean train loss 1267.6953309755067
INFO:root:current train perplexity2.730036973953247
INFO:root:current mean train loss 1272.204180372807
INFO:root:current train perplexity2.734821319580078
INFO:root:current mean train loss 1273.3087773310674
INFO:root:current train perplexity2.7357537746429443
INFO:root:current mean train loss 1274.3034927210856
INFO:root:current train perplexity2.736644744873047
INFO:root:current mean train loss 1272.6973891559828
INFO:root:current train perplexity2.737445592880249
INFO:root:current mean train loss 1274.4006980283416
INFO:root:current train perplexity2.738274335861206
INFO:root:current mean train loss 1275.364320791451
INFO:root:current train perplexity2.739746332168579
INFO:root:current mean train loss 1275.8598788676288
INFO:root:current train perplexity2.7388155460357666
INFO:root:current mean train loss 1276.973081823049
INFO:root:current train perplexity2.7385799884796143
INFO:root:current mean train loss 1276.3682582310269
INFO:root:current train perplexity2.73856782913208
INFO:root:current mean train loss 1276.3920838690005
INFO:root:current train perplexity2.738898515701294
INFO:root:current mean train loss 1276.4334105020366
INFO:root:current train perplexity2.7390336990356445
INFO:root:current mean train loss 1276.9377143501806
INFO:root:current train perplexity2.738294839859009
INFO:root:current mean train loss 1277.1447441537773
INFO:root:current train perplexity2.7379302978515625
INFO:root:current mean train loss 1277.5789464523364
INFO:root:current train perplexity2.7394752502441406
INFO:root:current mean train loss 1278.4276804757048
INFO:root:current train perplexity2.739995241165161
INFO:root:current mean train loss 1279.1675071395746
INFO:root:current train perplexity2.7407732009887695
INFO:root:current mean train loss 1279.476661321908
INFO:root:current train perplexity2.7414402961730957

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.58s/it]
INFO:root:final mean train loss: 1279.1027403584767
INFO:root:final train perplexity: 2.742246627807617
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.08s/it]
INFO:root:eval mean loss: 2273.834167047595
INFO:root:eval perplexity: 6.289889335632324
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 2859.100453045351
INFO:root:eval perplexity: 10.363097190856934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/159
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [27:55:45<7:07:14, 625.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1200.057373046875
INFO:root:current train perplexity2.722954034805298
INFO:root:current mean train loss 1268.4688732670802
INFO:root:current train perplexity2.7396628856658936
INFO:root:current mean train loss 1267.7295550355816
INFO:root:current train perplexity2.7283294200897217
INFO:root:current mean train loss 1273.1258827866309
INFO:root:current train perplexity2.729987144470215
INFO:root:current mean train loss 1272.2200639259756
INFO:root:current train perplexity2.7276499271392822
INFO:root:current mean train loss 1273.5134622642242
INFO:root:current train perplexity2.7291154861450195
INFO:root:current mean train loss 1274.6872256459587
INFO:root:current train perplexity2.730445146560669
INFO:root:current mean train loss 1274.924604366987
INFO:root:current train perplexity2.7304723262786865
INFO:root:current mean train loss 1275.6002504724518
INFO:root:current train perplexity2.7320034503936768
INFO:root:current mean train loss 1275.288417232539
INFO:root:current train perplexity2.7340428829193115
INFO:root:current mean train loss 1275.31689416577
INFO:root:current train perplexity2.7357003688812256
INFO:root:current mean train loss 1276.518536520956
INFO:root:current train perplexity2.737233877182007
INFO:root:current mean train loss 1276.591570202007
INFO:root:current train perplexity2.736886978149414
INFO:root:current mean train loss 1277.1719768190164
INFO:root:current train perplexity2.7371456623077393
INFO:root:current mean train loss 1278.1417192793776
INFO:root:current train perplexity2.737189531326294
INFO:root:current mean train loss 1278.2396177655053
INFO:root:current train perplexity2.7384538650512695
INFO:root:current mean train loss 1278.7639500764426
INFO:root:current train perplexity2.739720344543457
INFO:root:current mean train loss 1278.790734762871
INFO:root:current train perplexity2.740678310394287
INFO:root:current mean train loss 1278.894371921823
INFO:root:current train perplexity2.7412497997283936
INFO:root:current mean train loss 1279.1188483493938
INFO:root:current train perplexity2.7417526245117188

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.12s/it]
INFO:root:final mean train loss: 1278.7807308779902
INFO:root:final train perplexity: 2.7415497303009033
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it]
INFO:root:eval mean loss: 2276.948988894199
INFO:root:eval perplexity: 6.305755138397217
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 2860.8840145895665
INFO:root:eval perplexity: 10.37822151184082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/160
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [28:06:18<6:58:14, 627.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1279.0377582750823
INFO:root:current train perplexity2.746997594833374
INFO:root:current mean train loss 1273.3269648191308
INFO:root:current train perplexity2.7169179916381836
INFO:root:current mean train loss 1274.3924187089754
INFO:root:current train perplexity2.7186808586120605
INFO:root:current mean train loss 1270.807463738612
INFO:root:current train perplexity2.723517656326294
INFO:root:current mean train loss 1271.7300323267825
INFO:root:current train perplexity2.725358724594116
INFO:root:current mean train loss 1271.730446640926
INFO:root:current train perplexity2.728653907775879
INFO:root:current mean train loss 1272.316112413545
INFO:root:current train perplexity2.729557514190674
INFO:root:current mean train loss 1273.0559492893776
INFO:root:current train perplexity2.7292683124542236
INFO:root:current mean train loss 1272.8665665660294
INFO:root:current train perplexity2.7297980785369873
INFO:root:current mean train loss 1273.1580271259097
INFO:root:current train perplexity2.730847120285034
INFO:root:current mean train loss 1273.8636701020455
INFO:root:current train perplexity2.7316694259643555
INFO:root:current mean train loss 1274.4213939186075
INFO:root:current train perplexity2.73376202583313
INFO:root:current mean train loss 1275.351054891785
INFO:root:current train perplexity2.7342073917388916
INFO:root:current mean train loss 1276.4993974224376
INFO:root:current train perplexity2.735055923461914
INFO:root:current mean train loss 1276.6122424049727
INFO:root:current train perplexity2.7345235347747803
INFO:root:current mean train loss 1276.2652024551
INFO:root:current train perplexity2.7363369464874268
INFO:root:current mean train loss 1275.7240481079177
INFO:root:current train perplexity2.7362496852874756
INFO:root:current mean train loss 1276.168735257826
INFO:root:current train perplexity2.736752510070801
INFO:root:current mean train loss 1276.812371755708
INFO:root:current train perplexity2.7366912364959717
INFO:root:current mean train loss 1277.1018815748762
INFO:root:current train perplexity2.73695707321167

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.29s/it]
INFO:root:final mean train loss: 1276.732848844081
INFO:root:final train perplexity: 2.7371256351470947
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.48s/it]
INFO:root:eval mean loss: 2279.269431689107
INFO:root:eval perplexity: 6.317598819732666
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it]
INFO:root:eval mean loss: 2865.880808295933
INFO:root:eval perplexity: 10.420719146728516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/161
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [28:16:40<6:46:45, 625.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1282.5455729166667
INFO:root:current train perplexity2.734116792678833
INFO:root:current mean train loss 1274.2063553754022
INFO:root:current train perplexity2.7137296199798584
INFO:root:current mean train loss 1273.3638062557932
INFO:root:current train perplexity2.725929021835327
INFO:root:current mean train loss 1274.2744889032274
INFO:root:current train perplexity2.7279531955718994
INFO:root:current mean train loss 1275.1114947117796
INFO:root:current train perplexity2.728482723236084
INFO:root:current mean train loss 1273.919174422079
INFO:root:current train perplexity2.7293272018432617
INFO:root:current mean train loss 1274.7907352087632
INFO:root:current train perplexity2.7278058528900146
INFO:root:current mean train loss 1274.316176538882
INFO:root:current train perplexity2.730762481689453
INFO:root:current mean train loss 1274.513544402054
INFO:root:current train perplexity2.730081796646118
INFO:root:current mean train loss 1274.1144565680088
INFO:root:current train perplexity2.72995924949646
INFO:root:current mean train loss 1274.138414655413
INFO:root:current train perplexity2.730679512023926
INFO:root:current mean train loss 1274.7995540994993
INFO:root:current train perplexity2.7315597534179688
INFO:root:current mean train loss 1274.8594004806962
INFO:root:current train perplexity2.731842041015625
INFO:root:current mean train loss 1275.0582009503942
INFO:root:current train perplexity2.7329392433166504
INFO:root:current mean train loss 1275.0795989395185
INFO:root:current train perplexity2.732724189758301
INFO:root:current mean train loss 1275.8930220603943
INFO:root:current train perplexity2.7331314086914062
INFO:root:current mean train loss 1276.123576866094
INFO:root:current train perplexity2.7345588207244873
INFO:root:current mean train loss 1275.660901891471
INFO:root:current train perplexity2.734797477722168
INFO:root:current mean train loss 1275.859695534301
INFO:root:current train perplexity2.7350616455078125
INFO:root:current mean train loss 1275.9284038070805
INFO:root:current train perplexity2.7346794605255127

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.92s/it]
INFO:root:final mean train loss: 1275.477954735614
INFO:root:final train perplexity: 2.7344179153442383
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.04s/it]
INFO:root:eval mean loss: 2279.224592925809
INFO:root:eval perplexity: 6.317371368408203
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.37s/it]
INFO:root:eval mean loss: 2865.699599678635
INFO:root:eval perplexity: 10.41917896270752
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/162
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [28:27:10<6:37:14, 627.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1273.5578106574292
INFO:root:current train perplexity2.7217745780944824
INFO:root:current mean train loss 1274.7582313687194
INFO:root:current train perplexity2.7164998054504395
INFO:root:current mean train loss 1273.237288282794
INFO:root:current train perplexity2.7113051414489746
INFO:root:current mean train loss 1272.6655875143856
INFO:root:current train perplexity2.7148571014404297
INFO:root:current mean train loss 1272.1250924285148
INFO:root:current train perplexity2.719611406326294
INFO:root:current mean train loss 1271.8536946467423
INFO:root:current train perplexity2.7216742038726807
INFO:root:current mean train loss 1271.7409381954083
INFO:root:current train perplexity2.72204327583313
INFO:root:current mean train loss 1271.3446220002802
INFO:root:current train perplexity2.722278594970703
INFO:root:current mean train loss 1271.6929599632272
INFO:root:current train perplexity2.7225444316864014
INFO:root:current mean train loss 1271.9421021660628
INFO:root:current train perplexity2.723273515701294
INFO:root:current mean train loss 1273.0217323411903
INFO:root:current train perplexity2.725006580352783
INFO:root:current mean train loss 1273.9317897985215
INFO:root:current train perplexity2.7257096767425537
INFO:root:current mean train loss 1273.9541941138143
INFO:root:current train perplexity2.7261860370635986
INFO:root:current mean train loss 1274.7765922010694
INFO:root:current train perplexity2.7285373210906982
INFO:root:current mean train loss 1273.7866716693372
INFO:root:current train perplexity2.728426694869995
INFO:root:current mean train loss 1273.8914122867031
INFO:root:current train perplexity2.7289605140686035
INFO:root:current mean train loss 1273.8100770556848
INFO:root:current train perplexity2.729231834411621
INFO:root:current mean train loss 1274.0101754971388
INFO:root:current train perplexity2.729665994644165
INFO:root:current mean train loss 1274.1040482415551
INFO:root:current train perplexity2.7301697731018066
INFO:root:current mean train loss 1274.2084425903258
INFO:root:current train perplexity2.730933427810669

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.42s/it]
INFO:root:final mean train loss: 1273.9785528678335
INFO:root:final train perplexity: 2.7311863899230957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it]
INFO:root:eval mean loss: 2279.8578326719025
INFO:root:eval perplexity: 6.320606708526611
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it]
INFO:root:eval mean loss: 2865.990457304826
INFO:root:eval perplexity: 10.421655654907227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/163
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [28:37:42<6:27:34, 628.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1271.3428431919642
INFO:root:current train perplexity2.7422358989715576
INFO:root:current mean train loss 1269.8179543887868
INFO:root:current train perplexity2.728769302368164
INFO:root:current mean train loss 1268.3086932146991
INFO:root:current train perplexity2.7267861366271973
INFO:root:current mean train loss 1269.149962389147
INFO:root:current train perplexity2.72087025642395
INFO:root:current mean train loss 1268.503230447972
INFO:root:current train perplexity2.7163074016571045
INFO:root:current mean train loss 1269.735588421738
INFO:root:current train perplexity2.7153992652893066
INFO:root:current mean train loss 1269.859648838328
INFO:root:current train perplexity2.717594861984253
INFO:root:current mean train loss 1270.38490465833
INFO:root:current train perplexity2.7191195487976074
INFO:root:current mean train loss 1270.64601601787
INFO:root:current train perplexity2.7195394039154053
INFO:root:current mean train loss 1271.400786032136
INFO:root:current train perplexity2.7203381061553955
INFO:root:current mean train loss 1271.1774464259638
INFO:root:current train perplexity2.7216591835021973
INFO:root:current mean train loss 1270.8935081547143
INFO:root:current train perplexity2.723446846008301
INFO:root:current mean train loss 1270.7851083830585
INFO:root:current train perplexity2.7233879566192627
INFO:root:current mean train loss 1270.8501901445597
INFO:root:current train perplexity2.7233245372772217
INFO:root:current mean train loss 1270.9685875717475
INFO:root:current train perplexity2.7244365215301514
INFO:root:current mean train loss 1271.3591238617137
INFO:root:current train perplexity2.724120855331421
INFO:root:current mean train loss 1271.5961797839868
INFO:root:current train perplexity2.7246310710906982
INFO:root:current mean train loss 1272.2212758209746
INFO:root:current train perplexity2.7257587909698486
INFO:root:current mean train loss 1272.0727242046498
INFO:root:current train perplexity2.726579427719116
INFO:root:current mean train loss 1272.8607419396415
INFO:root:current train perplexity2.7279515266418457

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.31s/it]
INFO:root:final mean train loss: 1272.4898370155108
INFO:root:final train perplexity: 2.7279815673828125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 2282.1621621855606
INFO:root:eval perplexity: 6.332396984100342
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.78s/it]
INFO:root:eval mean loss: 2868.5219354291335
INFO:root:eval perplexity: 10.443252563476562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/164
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [28:48:05<6:16:11, 627.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1260.0674445492098
INFO:root:current train perplexity2.7125930786132812
INFO:root:current mean train loss 1266.7411293396976
INFO:root:current train perplexity2.715195655822754
INFO:root:current mean train loss 1265.5846023825402
INFO:root:current train perplexity2.7111611366271973
INFO:root:current mean train loss 1267.8285199148095
INFO:root:current train perplexity2.711798906326294
INFO:root:current mean train loss 1267.4582341564264
INFO:root:current train perplexity2.7137577533721924
INFO:root:current mean train loss 1266.191090988341
INFO:root:current train perplexity2.7146215438842773
INFO:root:current mean train loss 1266.436347528316
INFO:root:current train perplexity2.71589732170105
INFO:root:current mean train loss 1267.162850327837
INFO:root:current train perplexity2.717334270477295
INFO:root:current mean train loss 1267.6166913743218
INFO:root:current train perplexity2.717822551727295
INFO:root:current mean train loss 1266.7343731448282
INFO:root:current train perplexity2.7180228233337402
INFO:root:current mean train loss 1267.4788354559569
INFO:root:current train perplexity2.718554973602295
INFO:root:current mean train loss 1268.019601386439
INFO:root:current train perplexity2.7188496589660645
INFO:root:current mean train loss 1268.4427054878715
INFO:root:current train perplexity2.719292640686035
INFO:root:current mean train loss 1268.16624453984
INFO:root:current train perplexity2.7208516597747803
INFO:root:current mean train loss 1268.4851886105362
INFO:root:current train perplexity2.720460891723633
INFO:root:current mean train loss 1269.1634476102217
INFO:root:current train perplexity2.7216436862945557
INFO:root:current mean train loss 1269.9442072824818
INFO:root:current train perplexity2.7233951091766357
INFO:root:current mean train loss 1270.2991929697337
INFO:root:current train perplexity2.7237038612365723
INFO:root:current mean train loss 1270.5183921858438
INFO:root:current train perplexity2.7235169410705566

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.88s/it]
INFO:root:final mean train loss: 1270.5774990126033
INFO:root:final train perplexity: 2.7238705158233643
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.05s/it]
INFO:root:eval mean loss: 2282.986663601923
INFO:root:eval perplexity: 6.3366193771362305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.74s/it]
INFO:root:eval mean loss: 2870.9675548364085
INFO:root:eval perplexity: 10.464160919189453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/165
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [28:58:28<6:05:01, 625.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1245.519775390625
INFO:root:current train perplexity2.7221524715423584
INFO:root:current mean train loss 1258.0328744741587
INFO:root:current train perplexity2.7020652294158936
INFO:root:current mean train loss 1261.8522195255055
INFO:root:current train perplexity2.7098820209503174
INFO:root:current mean train loss 1263.1509748760022
INFO:root:current train perplexity2.7112717628479004
INFO:root:current mean train loss 1266.3282570414024
INFO:root:current train perplexity2.7125332355499268
INFO:root:current mean train loss 1266.58132668147
INFO:root:current train perplexity2.713533639907837
INFO:root:current mean train loss 1266.2057549685042
INFO:root:current train perplexity2.7166035175323486
INFO:root:current mean train loss 1267.1033325195312
INFO:root:current train perplexity2.7173337936401367
INFO:root:current mean train loss 1267.2276479237116
INFO:root:current train perplexity2.715287923812866
INFO:root:current mean train loss 1267.4453025075186
INFO:root:current train perplexity2.7166688442230225
INFO:root:current mean train loss 1268.0560097257455
INFO:root:current train perplexity2.717198133468628
INFO:root:current mean train loss 1268.1396643597147
INFO:root:current train perplexity2.7176318168640137
INFO:root:current mean train loss 1268.5661193239332
INFO:root:current train perplexity2.7177045345306396
INFO:root:current mean train loss 1269.1222970412553
INFO:root:current train perplexity2.719015598297119
INFO:root:current mean train loss 1268.5264676085903
INFO:root:current train perplexity2.719255208969116
INFO:root:current mean train loss 1268.7616611237222
INFO:root:current train perplexity2.721035957336426
INFO:root:current mean train loss 1268.6467607074842
INFO:root:current train perplexity2.7209672927856445
INFO:root:current mean train loss 1269.2404548752477
INFO:root:current train perplexity2.720672607421875
INFO:root:current mean train loss 1269.6583752008341
INFO:root:current train perplexity2.7218105792999268
INFO:root:current mean train loss 1269.7924752115202
INFO:root:current train perplexity2.7224886417388916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.15s/it]
INFO:root:final mean train loss: 1270.1198572879239
INFO:root:final train perplexity: 2.7228877544403076
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 2284.4046786693816
INFO:root:eval perplexity: 6.343892574310303
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it]
INFO:root:eval mean loss: 2871.4153754051695
INFO:root:eval perplexity: 10.46799373626709
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/166
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [29:09:00<5:55:38, 627.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1261.0916050502233
INFO:root:current train perplexity2.69297194480896
INFO:root:current mean train loss 1265.0876696878229
INFO:root:current train perplexity2.706630229949951
INFO:root:current mean train loss 1265.788879118354
INFO:root:current train perplexity2.7017433643341064
INFO:root:current mean train loss 1265.208604473934
INFO:root:current train perplexity2.703767776489258
INFO:root:current mean train loss 1266.8234080407512
INFO:root:current train perplexity2.7070705890655518
INFO:root:current mean train loss 1265.2080410831034
INFO:root:current train perplexity2.7098891735076904
INFO:root:current mean train loss 1266.357395141405
INFO:root:current train perplexity2.7111752033233643
INFO:root:current mean train loss 1266.842745163239
INFO:root:current train perplexity2.713540554046631
INFO:root:current mean train loss 1267.038375575708
INFO:root:current train perplexity2.7124667167663574
INFO:root:current mean train loss 1267.6996909937823
INFO:root:current train perplexity2.712714672088623
INFO:root:current mean train loss 1267.6028806441677
INFO:root:current train perplexity2.7134504318237305
INFO:root:current mean train loss 1267.0323557109305
INFO:root:current train perplexity2.7156662940979004
INFO:root:current mean train loss 1267.7161345360807
INFO:root:current train perplexity2.715076446533203
INFO:root:current mean train loss 1267.585133185087
INFO:root:current train perplexity2.7153286933898926
INFO:root:current mean train loss 1267.6903101084183
INFO:root:current train perplexity2.714876174926758
INFO:root:current mean train loss 1268.1052456366083
INFO:root:current train perplexity2.7161622047424316
INFO:root:current mean train loss 1268.480095610951
INFO:root:current train perplexity2.716545581817627
INFO:root:current mean train loss 1268.6260139425433
INFO:root:current train perplexity2.7174437046051025
INFO:root:current mean train loss 1268.7388351582879
INFO:root:current train perplexity2.718541383743286
INFO:root:current mean train loss 1268.7944524031266
INFO:root:current train perplexity2.719254732131958

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.46s/it]
INFO:root:final mean train loss: 1268.3937471806253
INFO:root:final train perplexity: 2.7191834449768066
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it]
INFO:root:eval mean loss: 2287.3190740490636
INFO:root:eval perplexity: 6.358862400054932
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it]
INFO:root:eval mean loss: 2875.412201144171
INFO:root:eval perplexity: 10.502264022827148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/167
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [29:19:32<5:45:55, 628.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1263.7890753495067
INFO:root:current train perplexity2.702680826187134
INFO:root:current mean train loss 1263.8956316519475
INFO:root:current train perplexity2.7044029235839844
INFO:root:current mean train loss 1265.0226245527508
INFO:root:current train perplexity2.7019922733306885
INFO:root:current mean train loss 1264.8503555207562
INFO:root:current train perplexity2.699962615966797
INFO:root:current mean train loss 1266.592961559557
INFO:root:current train perplexity2.7052581310272217
INFO:root:current mean train loss 1264.6399381843198
INFO:root:current train perplexity2.704237461090088
INFO:root:current mean train loss 1265.3797814061274
INFO:root:current train perplexity2.7039990425109863
INFO:root:current mean train loss 1266.7528446683393
INFO:root:current train perplexity2.706993818283081
INFO:root:current mean train loss 1267.0866713785613
INFO:root:current train perplexity2.7067248821258545
INFO:root:current mean train loss 1266.3152905689883
INFO:root:current train perplexity2.7081387042999268
INFO:root:current mean train loss 1266.063274876001
INFO:root:current train perplexity2.709833860397339
INFO:root:current mean train loss 1265.9111836572522
INFO:root:current train perplexity2.711453914642334
INFO:root:current mean train loss 1265.5648375774624
INFO:root:current train perplexity2.713318347930908
INFO:root:current mean train loss 1265.4775291180574
INFO:root:current train perplexity2.7128751277923584
INFO:root:current mean train loss 1265.938116548456
INFO:root:current train perplexity2.7132372856140137
INFO:root:current mean train loss 1265.8775262522604
INFO:root:current train perplexity2.7137162685394287
INFO:root:current mean train loss 1266.2710660717862
INFO:root:current train perplexity2.7144486904144287
INFO:root:current mean train loss 1266.645415732995
INFO:root:current train perplexity2.7150938510894775
INFO:root:current mean train loss 1266.6835475253333
INFO:root:current train perplexity2.7148470878601074
INFO:root:current mean train loss 1267.0568789077618
INFO:root:current train perplexity2.71547794342041

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.42s/it]
INFO:root:final mean train loss: 1266.5762732616893
INFO:root:final train perplexity: 2.7152884006500244
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it]
INFO:root:eval mean loss: 2287.365285454067
INFO:root:eval perplexity: 6.359099388122559
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it]
INFO:root:eval mean loss: 2875.9399959483044
INFO:root:eval perplexity: 10.506799697875977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/168
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [29:30:07<5:36:19, 630.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1260.4750577059658
INFO:root:current train perplexity2.7065224647521973
INFO:root:current mean train loss 1260.680689264113
INFO:root:current train perplexity2.69527006149292
INFO:root:current mean train loss 1262.0648241230085
INFO:root:current train perplexity2.6983797550201416
INFO:root:current mean train loss 1262.6206082196302
INFO:root:current train perplexity2.699403762817383
INFO:root:current mean train loss 1262.615630365728
INFO:root:current train perplexity2.7024619579315186
INFO:root:current mean train loss 1263.8665437165682
INFO:root:current train perplexity2.705151319503784
INFO:root:current mean train loss 1264.2379442986642
INFO:root:current train perplexity2.7073278427124023
INFO:root:current mean train loss 1264.9894841680464
INFO:root:current train perplexity2.7083609104156494
INFO:root:current mean train loss 1264.519814510234
INFO:root:current train perplexity2.7092645168304443
INFO:root:current mean train loss 1264.9807559667458
INFO:root:current train perplexity2.7096614837646484
INFO:root:current mean train loss 1265.0762893170543
INFO:root:current train perplexity2.709300994873047
INFO:root:current mean train loss 1265.275452135755
INFO:root:current train perplexity2.709465503692627
INFO:root:current mean train loss 1266.3617854752863
INFO:root:current train perplexity2.7094566822052
INFO:root:current mean train loss 1266.1436775686116
INFO:root:current train perplexity2.709916353225708
INFO:root:current mean train loss 1266.376374150961
INFO:root:current train perplexity2.7119433879852295
INFO:root:current mean train loss 1266.589870362113
INFO:root:current train perplexity2.7131364345550537
INFO:root:current mean train loss 1266.663098550203
INFO:root:current train perplexity2.715160369873047
INFO:root:current mean train loss 1266.4662295088808
INFO:root:current train perplexity2.7155675888061523
INFO:root:current mean train loss 1266.6275653191333
INFO:root:current train perplexity2.7155983448028564
INFO:root:current mean train loss 1266.5878011483976
INFO:root:current train perplexity2.7149531841278076

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.45s/it]
INFO:root:final mean train loss: 1266.3668488364476
INFO:root:final train perplexity: 2.7148401737213135
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 2288.222647592531
INFO:root:eval perplexity: 6.363509178161621
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it]
INFO:root:eval mean loss: 2876.281146976119
INFO:root:eval perplexity: 10.509733200073242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/169
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [29:40:31<5:24:45, 628.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1259.0255449083115
INFO:root:current train perplexity2.6781930923461914
INFO:root:current mean train loss 1259.9557608670966
INFO:root:current train perplexity2.681591272354126
INFO:root:current mean train loss 1263.223149467917
INFO:root:current train perplexity2.6909916400909424
INFO:root:current mean train loss 1263.4242107432376
INFO:root:current train perplexity2.696650981903076
INFO:root:current mean train loss 1263.0199460821636
INFO:root:current train perplexity2.695736885070801
INFO:root:current mean train loss 1262.2358347219188
INFO:root:current train perplexity2.701244831085205
INFO:root:current mean train loss 1261.6531955174037
INFO:root:current train perplexity2.7010726928710938
INFO:root:current mean train loss 1262.184991075585
INFO:root:current train perplexity2.701441764831543
INFO:root:current mean train loss 1262.2277734039026
INFO:root:current train perplexity2.7026991844177246
INFO:root:current mean train loss 1262.874466507523
INFO:root:current train perplexity2.7043304443359375
INFO:root:current mean train loss 1261.7022360047297
INFO:root:current train perplexity2.703348398208618
INFO:root:current mean train loss 1262.4621049796356
INFO:root:current train perplexity2.7053160667419434
INFO:root:current mean train loss 1263.3311652417453
INFO:root:current train perplexity2.7055752277374268
INFO:root:current mean train loss 1263.69132048048
INFO:root:current train perplexity2.707336664199829
INFO:root:current mean train loss 1264.1169030562692
INFO:root:current train perplexity2.7082319259643555
INFO:root:current mean train loss 1263.5442455184975
INFO:root:current train perplexity2.7080440521240234
INFO:root:current mean train loss 1263.516908928538
INFO:root:current train perplexity2.708534002304077
INFO:root:current mean train loss 1263.8878264760863
INFO:root:current train perplexity2.7091522216796875
INFO:root:current mean train loss 1264.4134069589468
INFO:root:current train perplexity2.7107973098754883
INFO:root:current mean train loss 1264.8417181359343
INFO:root:current train perplexity2.710904359817505

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.53s/it]
INFO:root:final mean train loss: 1264.4811096345302
INFO:root:final train perplexity: 2.710805654525757
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it]
INFO:root:eval mean loss: 2288.8141401574967
INFO:root:eval perplexity: 6.366555690765381
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.85s/it]
INFO:root:eval mean loss: 2878.0556584351452
INFO:root:eval perplexity: 10.524996757507324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/170
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [29:50:54<5:13:29, 627.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1254.7816381561622
INFO:root:current train perplexity2.7017500400543213
INFO:root:current mean train loss 1257.8156156994048
INFO:root:current train perplexity2.706864595413208
INFO:root:current mean train loss 1261.754838884083
INFO:root:current train perplexity2.7030186653137207
INFO:root:current mean train loss 1262.2197679848168
INFO:root:current train perplexity2.7007455825805664
INFO:root:current mean train loss 1261.7106971038631
INFO:root:current train perplexity2.7032153606414795
INFO:root:current mean train loss 1260.6964260548202
INFO:root:current train perplexity2.702979564666748
INFO:root:current mean train loss 1261.1992609165231
INFO:root:current train perplexity2.7039358615875244
INFO:root:current mean train loss 1261.8328498482554
INFO:root:current train perplexity2.703136444091797
INFO:root:current mean train loss 1262.0455986855402
INFO:root:current train perplexity2.7036333084106445
INFO:root:current mean train loss 1262.415956873262
INFO:root:current train perplexity2.7032103538513184
INFO:root:current mean train loss 1261.8680136324178
INFO:root:current train perplexity2.7023963928222656
INFO:root:current mean train loss 1261.4134147778793
INFO:root:current train perplexity2.7023234367370605
INFO:root:current mean train loss 1261.737522027583
INFO:root:current train perplexity2.703528642654419
INFO:root:current mean train loss 1261.9390719738515
INFO:root:current train perplexity2.7043542861938477
INFO:root:current mean train loss 1261.956687583949
INFO:root:current train perplexity2.7048068046569824
INFO:root:current mean train loss 1262.3827797737865
INFO:root:current train perplexity2.7063426971435547
INFO:root:current mean train loss 1262.4990562497687
INFO:root:current train perplexity2.7066380977630615
INFO:root:current mean train loss 1262.7929553761703
INFO:root:current train perplexity2.7075986862182617
INFO:root:current mean train loss 1263.287344985566
INFO:root:current train perplexity2.7074882984161377

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.86s/it]
INFO:root:final mean train loss: 1263.5692739481885
INFO:root:final train perplexity: 2.7088568210601807
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 2291.2775952494735
INFO:root:eval perplexity: 6.379251003265381
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it]
INFO:root:eval mean loss: 2880.527280117603
INFO:root:eval perplexity: 10.546292304992676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/171
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [30:01:25<5:03:38, 628.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1257.4932861328125
INFO:root:current train perplexity2.7189884185791016
INFO:root:current mean train loss 1270.0714940484966
INFO:root:current train perplexity2.6950523853302
INFO:root:current mean train loss 1259.1486549747801
INFO:root:current train perplexity2.683284044265747
INFO:root:current mean train loss 1257.8331765567555
INFO:root:current train perplexity2.6844470500946045
INFO:root:current mean train loss 1259.8260143261239
INFO:root:current train perplexity2.691455602645874
INFO:root:current mean train loss 1262.1921343294528
INFO:root:current train perplexity2.6961352825164795
INFO:root:current mean train loss 1260.8536552202584
INFO:root:current train perplexity2.6948745250701904
INFO:root:current mean train loss 1260.0018175681657
INFO:root:current train perplexity2.695248603820801
INFO:root:current mean train loss 1259.467022538481
INFO:root:current train perplexity2.6976001262664795
INFO:root:current mean train loss 1259.4120791942605
INFO:root:current train perplexity2.698072910308838
INFO:root:current mean train loss 1259.0248189816182
INFO:root:current train perplexity2.6983742713928223
INFO:root:current mean train loss 1259.1513164168457
INFO:root:current train perplexity2.6985340118408203
INFO:root:current mean train loss 1260.1302668380104
INFO:root:current train perplexity2.6997623443603516
INFO:root:current mean train loss 1260.865162871333
INFO:root:current train perplexity2.700517416000366
INFO:root:current mean train loss 1261.4620535838317
INFO:root:current train perplexity2.7009010314941406
INFO:root:current mean train loss 1261.4481879610464
INFO:root:current train perplexity2.7023024559020996
INFO:root:current mean train loss 1262.2469361567705
INFO:root:current train perplexity2.70296049118042
INFO:root:current mean train loss 1262.7868198694405
INFO:root:current train perplexity2.7046172618865967
INFO:root:current mean train loss 1262.8507066559819
INFO:root:current train perplexity2.7058863639831543
INFO:root:current mean train loss 1262.734656479026
INFO:root:current train perplexity2.705693483352661

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.26s/it]
INFO:root:final mean train loss: 1262.591942245168
INFO:root:final train perplexity: 2.7067697048187256
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it]
INFO:root:eval mean loss: 2291.385005869764
INFO:root:eval perplexity: 6.379805564880371
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.96s/it]
INFO:root:eval mean loss: 2881.34898300712
INFO:root:eval perplexity: 10.553380966186523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/172
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [30:11:46<4:52:11, 626.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1245.794438901155
INFO:root:current train perplexity2.6761467456817627
INFO:root:current mean train loss 1249.1931589018038
INFO:root:current train perplexity2.6868298053741455
INFO:root:current mean train loss 1251.8036890414799
INFO:root:current train perplexity2.6971116065979004
INFO:root:current mean train loss 1252.460786707261
INFO:root:current train perplexity2.6953983306884766
INFO:root:current mean train loss 1253.3690448156767
INFO:root:current train perplexity2.6933884620666504
INFO:root:current mean train loss 1254.1245693695478
INFO:root:current train perplexity2.697758913040161
INFO:root:current mean train loss 1255.4688991099645
INFO:root:current train perplexity2.697796583175659
INFO:root:current mean train loss 1255.7961034075684
INFO:root:current train perplexity2.697969913482666
INFO:root:current mean train loss 1257.1439471517124
INFO:root:current train perplexity2.6987130641937256
INFO:root:current mean train loss 1258.8217303936299
INFO:root:current train perplexity2.699936628341675
INFO:root:current mean train loss 1258.907543849852
INFO:root:current train perplexity2.6993801593780518
INFO:root:current mean train loss 1258.879689326163
INFO:root:current train perplexity2.6992669105529785
INFO:root:current mean train loss 1259.3296449400807
INFO:root:current train perplexity2.699856758117676
INFO:root:current mean train loss 1260.5605044318074
INFO:root:current train perplexity2.702134609222412
INFO:root:current mean train loss 1261.410038983579
INFO:root:current train perplexity2.7012887001037598
INFO:root:current mean train loss 1261.7218682833275
INFO:root:current train perplexity2.7024457454681396
INFO:root:current mean train loss 1261.5360375931434
INFO:root:current train perplexity2.702583074569702
INFO:root:current mean train loss 1261.435212970541
INFO:root:current train perplexity2.7032630443573
INFO:root:current mean train loss 1261.338033654176
INFO:root:current train perplexity2.704115629196167
INFO:root:current mean train loss 1261.432221966613
INFO:root:current train perplexity2.703911781311035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.71s/it]
INFO:root:final mean train loss: 1261.3132630164012
INFO:root:final train perplexity: 2.7040414810180664
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 2293.18583560159
INFO:root:eval perplexity: 6.38910436630249
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.00s/it]
INFO:root:eval mean loss: 2882.5708483973294
INFO:root:eval perplexity: 10.563933372497559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/173
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [30:22:07<4:41:02, 624.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1251.952130126953
INFO:root:current train perplexity2.69582462310791
INFO:root:current mean train loss 1254.272145298549
INFO:root:current train perplexity2.6930360794067383
INFO:root:current mean train loss 1258.845152282715
INFO:root:current train perplexity2.6903584003448486
INFO:root:current mean train loss 1258.7066079532399
INFO:root:current train perplexity2.691580295562744
INFO:root:current mean train loss 1257.709126697887
INFO:root:current train perplexity2.6939163208007812
INFO:root:current mean train loss 1258.037252468533
INFO:root:current train perplexity2.6944479942321777
INFO:root:current mean train loss 1258.262947654724
INFO:root:current train perplexity2.6943368911743164
INFO:root:current mean train loss 1258.8058479927681
INFO:root:current train perplexity2.693399429321289
INFO:root:current mean train loss 1258.2161382765996
INFO:root:current train perplexity2.6951143741607666
INFO:root:current mean train loss 1259.008064302485
INFO:root:current train perplexity2.6976265907287598
INFO:root:current mean train loss 1258.6814092782827
INFO:root:current train perplexity2.6973047256469727
INFO:root:current mean train loss 1258.0907846551193
INFO:root:current train perplexity2.697936534881592
INFO:root:current mean train loss 1258.151046162267
INFO:root:current train perplexity2.697190284729004
INFO:root:current mean train loss 1258.031968119607
INFO:root:current train perplexity2.6989986896514893
INFO:root:current mean train loss 1258.8145315382217
INFO:root:current train perplexity2.700524091720581
INFO:root:current mean train loss 1258.9846323781198
INFO:root:current train perplexity2.700666666030884
INFO:root:current mean train loss 1259.2353244688452
INFO:root:current train perplexity2.701093912124634
INFO:root:current mean train loss 1259.7472838653914
INFO:root:current train perplexity2.701561212539673
INFO:root:current mean train loss 1259.7668728372325
INFO:root:current train perplexity2.7014968395233154
INFO:root:current mean train loss 1260.1324868113725
INFO:root:current train perplexity2.7014265060424805

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.18s/it]
INFO:root:final mean train loss: 1260.0719512462376
INFO:root:final train perplexity: 2.7013955116271973
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it]
INFO:root:eval mean loss: 2294.101410994293
INFO:root:eval perplexity: 6.39383602142334
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.28s/it]
INFO:root:eval mean loss: 2883.7885620982934
INFO:root:eval perplexity: 10.574459075927734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/174
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [30:32:39<4:31:35, 626.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1257.2576711554277
INFO:root:current train perplexity2.699984312057495
INFO:root:current mean train loss 1253.062698267068
INFO:root:current train perplexity2.694471836090088
INFO:root:current mean train loss 1252.9962956172483
INFO:root:current train perplexity2.6888601779937744
INFO:root:current mean train loss 1256.0760624562324
INFO:root:current train perplexity2.6907737255096436
INFO:root:current mean train loss 1256.6879634398078
INFO:root:current train perplexity2.6896259784698486
INFO:root:current mean train loss 1256.4088660741836
INFO:root:current train perplexity2.6931838989257812
INFO:root:current mean train loss 1255.763670202804
INFO:root:current train perplexity2.693153142929077
INFO:root:current mean train loss 1255.8031829874299
INFO:root:current train perplexity2.692640781402588
INFO:root:current mean train loss 1256.0348616859321
INFO:root:current train perplexity2.6941938400268555
INFO:root:current mean train loss 1257.162693960415
INFO:root:current train perplexity2.6951041221618652
INFO:root:current mean train loss 1257.0917533362035
INFO:root:current train perplexity2.6956334114074707
INFO:root:current mean train loss 1257.1295014087145
INFO:root:current train perplexity2.6962318420410156
INFO:root:current mean train loss 1258.0426724600052
INFO:root:current train perplexity2.696290969848633
INFO:root:current mean train loss 1258.2846524063593
INFO:root:current train perplexity2.6962265968322754
INFO:root:current mean train loss 1258.2843349354678
INFO:root:current train perplexity2.6966092586517334
INFO:root:current mean train loss 1258.6899234524276
INFO:root:current train perplexity2.696836233139038
INFO:root:current mean train loss 1258.6712359910134
INFO:root:current train perplexity2.6969730854034424
INFO:root:current mean train loss 1259.0788638831948
INFO:root:current train perplexity2.6981000900268555
INFO:root:current mean train loss 1259.304985149098
INFO:root:current train perplexity2.697953701019287
INFO:root:current mean train loss 1259.5937996514915
INFO:root:current train perplexity2.699322462081909

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.95s/it]
INFO:root:final mean train loss: 1259.231971790739
INFO:root:final train perplexity: 2.699606418609619
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it]
INFO:root:eval mean loss: 2294.9825495726673
INFO:root:eval perplexity: 6.398395538330078
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.04s/it]
INFO:root:eval mean loss: 2885.653343687666
INFO:root:eval perplexity: 10.590597152709961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/175
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [30:43:03<4:20:47, 625.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1250.32486044394
INFO:root:current train perplexity2.671405553817749
INFO:root:current mean train loss 1252.137670758127
INFO:root:current train perplexity2.676689386367798
INFO:root:current mean train loss 1248.9003830512945
INFO:root:current train perplexity2.6857500076293945
INFO:root:current mean train loss 1249.5129443489932
INFO:root:current train perplexity2.6868834495544434
INFO:root:current mean train loss 1250.4909580407766
INFO:root:current train perplexity2.6871938705444336
INFO:root:current mean train loss 1252.3294990353468
INFO:root:current train perplexity2.6892592906951904
INFO:root:current mean train loss 1254.4900369615866
INFO:root:current train perplexity2.6928610801696777
INFO:root:current mean train loss 1255.354405760457
INFO:root:current train perplexity2.6927013397216797
INFO:root:current mean train loss 1255.750454760798
INFO:root:current train perplexity2.6933786869049072
INFO:root:current mean train loss 1256.1157004730412
INFO:root:current train perplexity2.6940739154815674
INFO:root:current mean train loss 1255.7454548699009
INFO:root:current train perplexity2.6938953399658203
INFO:root:current mean train loss 1256.0167164583222
INFO:root:current train perplexity2.693138599395752
INFO:root:current mean train loss 1256.5149048426463
INFO:root:current train perplexity2.693474531173706
INFO:root:current mean train loss 1256.3027329535116
INFO:root:current train perplexity2.692870616912842
INFO:root:current mean train loss 1256.8669025312447
INFO:root:current train perplexity2.694075345993042
INFO:root:current mean train loss 1257.1802257261554
INFO:root:current train perplexity2.6953704357147217
INFO:root:current mean train loss 1257.81200734347
INFO:root:current train perplexity2.6967921257019043
INFO:root:current mean train loss 1258.1436411138318
INFO:root:current train perplexity2.6973137855529785
INFO:root:current mean train loss 1258.3149333290255
INFO:root:current train perplexity2.697401523590088
INFO:root:current mean train loss 1258.5152760421613
INFO:root:current train perplexity2.697061538696289

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.17s/it]
INFO:root:final mean train loss: 1258.1748310652756
INFO:root:final train perplexity: 2.697356939315796
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 2296.0072233592364
INFO:root:eval perplexity: 6.403698921203613
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.85s/it]
INFO:root:eval mean loss: 2886.2478525148217
INFO:root:eval perplexity: 10.595748901367188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/176
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [30:53:24<4:09:47, 624.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1253.4838290371738
INFO:root:current train perplexity2.6993930339813232
INFO:root:current mean train loss 1255.7763703830578
INFO:root:current train perplexity2.6987557411193848
INFO:root:current mean train loss 1255.7544398356958
INFO:root:current train perplexity2.6971852779388428
INFO:root:current mean train loss 1256.2565740014586
INFO:root:current train perplexity2.692986488342285
INFO:root:current mean train loss 1255.9361291329876
INFO:root:current train perplexity2.6935667991638184
INFO:root:current mean train loss 1256.596199874749
INFO:root:current train perplexity2.6938767433166504
INFO:root:current mean train loss 1257.4542796332307
INFO:root:current train perplexity2.6947128772735596
INFO:root:current mean train loss 1257.1409904393174
INFO:root:current train perplexity2.696197748184204
INFO:root:current mean train loss 1256.9209428267045
INFO:root:current train perplexity2.695199489593506
INFO:root:current mean train loss 1256.9591802294872
INFO:root:current train perplexity2.6932287216186523
INFO:root:current mean train loss 1256.2891698010355
INFO:root:current train perplexity2.693990707397461
INFO:root:current mean train loss 1256.9037306983364
INFO:root:current train perplexity2.6939260959625244
INFO:root:current mean train loss 1256.8548546162435
INFO:root:current train perplexity2.6944353580474854
INFO:root:current mean train loss 1256.8450354679637
INFO:root:current train perplexity2.6943886280059814
INFO:root:current mean train loss 1257.0026696638163
INFO:root:current train perplexity2.694908380508423
INFO:root:current mean train loss 1257.304345994682
INFO:root:current train perplexity2.6953022480010986
INFO:root:current mean train loss 1257.8228757599977
INFO:root:current train perplexity2.6963086128234863
INFO:root:current mean train loss 1257.801186787889
INFO:root:current train perplexity2.6963951587677
INFO:root:current mean train loss 1257.59841313758
INFO:root:current train perplexity2.696275234222412

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.48s/it]
INFO:root:final mean train loss: 1257.617074509552
INFO:root:final train perplexity: 2.6961705684661865
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.51s/it]
INFO:root:eval mean loss: 2296.923019517398
INFO:root:eval perplexity: 6.408444404602051
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it]
INFO:root:eval mean loss: 2887.6396631551975
INFO:root:eval perplexity: 10.607815742492676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/177
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [31:03:56<4:00:12, 626.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1240.2212524414062
INFO:root:current train perplexity2.701660394668579
INFO:root:current mean train loss 1262.445246943721
INFO:root:current train perplexity2.7003793716430664
INFO:root:current mean train loss 1260.5532431969275
INFO:root:current train perplexity2.701967477798462
INFO:root:current mean train loss 1254.0164723582081
INFO:root:current train perplexity2.6950290203094482
INFO:root:current mean train loss 1255.31753839231
INFO:root:current train perplexity2.6938130855560303
INFO:root:current mean train loss 1254.086234265425
INFO:root:current train perplexity2.692763090133667
INFO:root:current mean train loss 1254.7696711891576
INFO:root:current train perplexity2.695250988006592
INFO:root:current mean train loss 1255.6783038640426
INFO:root:current train perplexity2.6935553550720215
INFO:root:current mean train loss 1255.1555548941735
INFO:root:current train perplexity2.6916863918304443
INFO:root:current mean train loss 1255.2897094188809
INFO:root:current train perplexity2.692608118057251
INFO:root:current mean train loss 1255.7411474803137
INFO:root:current train perplexity2.6921615600585938
INFO:root:current mean train loss 1255.3529848174499
INFO:root:current train perplexity2.6924984455108643
INFO:root:current mean train loss 1255.127332775798
INFO:root:current train perplexity2.6920716762542725
INFO:root:current mean train loss 1254.9309283615253
INFO:root:current train perplexity2.692107677459717
INFO:root:current mean train loss 1255.2159889394586
INFO:root:current train perplexity2.6915361881256104
INFO:root:current mean train loss 1254.780539677061
INFO:root:current train perplexity2.691378593444824
INFO:root:current mean train loss 1255.2219336969936
INFO:root:current train perplexity2.692905902862549
INFO:root:current mean train loss 1255.752314547465
INFO:root:current train perplexity2.693704605102539
INFO:root:current mean train loss 1256.1691634591702
INFO:root:current train perplexity2.6935672760009766
INFO:root:current mean train loss 1256.618937046523
INFO:root:current train perplexity2.6931819915771484

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.32s/it]
INFO:root:final mean train loss: 1256.1675846255673
INFO:root:final train perplexity: 2.6930902004241943
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 2298.053154695119
INFO:root:eval perplexity: 6.414304256439209
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 2889.473039343002
INFO:root:eval perplexity: 10.623733520507812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/178
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [31:14:21<3:49:36, 626.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1248.343798828125
INFO:root:current train perplexity2.733351707458496
INFO:root:current mean train loss 1248.7312529296876
INFO:root:current train perplexity2.6906111240386963
INFO:root:current mean train loss 1255.3137223307292
INFO:root:current train perplexity2.688368320465088
INFO:root:current mean train loss 1253.8446499399038
INFO:root:current train perplexity2.691148042678833
INFO:root:current mean train loss 1253.4740814568015
INFO:root:current train perplexity2.6907620429992676
INFO:root:current mean train loss 1253.6582528831846
INFO:root:current train perplexity2.689408302307129
INFO:root:current mean train loss 1253.1732435546876
INFO:root:current train perplexity2.6898305416107178
INFO:root:current mean train loss 1253.31037109375
INFO:root:current train perplexity2.690840721130371
INFO:root:current mean train loss 1253.110302438447
INFO:root:current train perplexity2.6917543411254883
INFO:root:current mean train loss 1253.3280571684966
INFO:root:current train perplexity2.6906087398529053
INFO:root:current mean train loss 1254.2266614662728
INFO:root:current train perplexity2.690356492996216
INFO:root:current mean train loss 1254.0943090277779
INFO:root:current train perplexity2.6902408599853516
INFO:root:current mean train loss 1253.965246631856
INFO:root:current train perplexity2.691173791885376
INFO:root:current mean train loss 1254.6789579341096
INFO:root:current train perplexity2.690680980682373
INFO:root:current mean train loss 1255.1036210766174
INFO:root:current train perplexity2.6903462409973145
INFO:root:current mean train loss 1255.096225265753
INFO:root:current train perplexity2.6914665699005127
INFO:root:current mean train loss 1255.424490685096
INFO:root:current train perplexity2.690751791000366
INFO:root:current mean train loss 1255.4091097712862
INFO:root:current train perplexity2.6911544799804688
INFO:root:current mean train loss 1255.4300447479666
INFO:root:current train perplexity2.6922101974487305
INFO:root:current mean train loss 1255.8473767248377
INFO:root:current train perplexity2.6921303272247314

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.28s/it]
INFO:root:final mean train loss: 1255.8483682344854
INFO:root:final train perplexity: 2.6924123764038086
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it]
INFO:root:eval mean loss: 2297.2248868468805
INFO:root:eval perplexity: 6.410007476806641
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.90s/it]
INFO:root:eval mean loss: 2888.819732449579
INFO:root:eval perplexity: 10.618061065673828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/179
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [31:24:43<3:38:44, 624.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1246.06449672154
INFO:root:current train perplexity2.6642489433288574
INFO:root:current mean train loss 1247.9390894930127
INFO:root:current train perplexity2.6725776195526123
INFO:root:current mean train loss 1250.6957452947443
INFO:root:current train perplexity2.6734578609466553
INFO:root:current mean train loss 1250.510653668677
INFO:root:current train perplexity2.678598642349243
INFO:root:current mean train loss 1250.9458441410668
INFO:root:current train perplexity2.683194875717163
INFO:root:current mean train loss 1252.516676561419
INFO:root:current train perplexity2.6844232082366943
INFO:root:current mean train loss 1251.2647275360202
INFO:root:current train perplexity2.6835036277770996
INFO:root:current mean train loss 1251.630336216518
INFO:root:current train perplexity2.68556547164917
INFO:root:current mean train loss 1251.3881389409516
INFO:root:current train perplexity2.6858162879943848
INFO:root:current mean train loss 1250.5824003118364
INFO:root:current train perplexity2.6845695972442627
INFO:root:current mean train loss 1250.9556858992623
INFO:root:current train perplexity2.6850383281707764
INFO:root:current mean train loss 1252.4012265180331
INFO:root:current train perplexity2.6861536502838135
INFO:root:current mean train loss 1252.7925686306423
INFO:root:current train perplexity2.687570333480835
INFO:root:current mean train loss 1253.4386890485282
INFO:root:current train perplexity2.687502145767212
INFO:root:current mean train loss 1254.0319293441455
INFO:root:current train perplexity2.6878421306610107
INFO:root:current mean train loss 1254.6131756457219
INFO:root:current train perplexity2.6880745887756348
INFO:root:current mean train loss 1254.243712338112
INFO:root:current train perplexity2.688563823699951
INFO:root:current mean train loss 1254.0498690161721
INFO:root:current train perplexity2.6883885860443115
INFO:root:current mean train loss 1254.2845346987183
INFO:root:current train perplexity2.6884944438934326
INFO:root:current mean train loss 1254.6008122264418
INFO:root:current train perplexity2.689260959625244

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.53s/it]
INFO:root:final mean train loss: 1254.0298577336068
INFO:root:final train perplexity: 2.68855357170105
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it]
INFO:root:eval mean loss: 2299.5010782877603
INFO:root:eval perplexity: 6.421819686889648
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it]
INFO:root:eval mean loss: 2891.277121685921
INFO:root:eval perplexity: 10.639421463012695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/180
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [31:35:13<3:28:50, 626.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1248.6082949880827
INFO:root:current train perplexity2.652495861053467
INFO:root:current mean train loss 1258.1743094966096
INFO:root:current train perplexity2.6765291690826416
INFO:root:current mean train loss 1255.0426784206081
INFO:root:current train perplexity2.6809840202331543
INFO:root:current mean train loss 1252.685046012687
INFO:root:current train perplexity2.6787736415863037
INFO:root:current mean train loss 1253.0845846205236
INFO:root:current train perplexity2.6800038814544678
INFO:root:current mean train loss 1252.245951371031
INFO:root:current train perplexity2.6831932067871094
INFO:root:current mean train loss 1254.5483620720315
INFO:root:current train perplexity2.6848204135894775
INFO:root:current mean train loss 1254.3261773432353
INFO:root:current train perplexity2.68298602104187
INFO:root:current mean train loss 1253.282181656541
INFO:root:current train perplexity2.6822195053100586
INFO:root:current mean train loss 1252.1841325650498
INFO:root:current train perplexity2.683371067047119
INFO:root:current mean train loss 1251.2388974803027
INFO:root:current train perplexity2.6833655834198
INFO:root:current mean train loss 1251.4341358517242
INFO:root:current train perplexity2.68505597114563
INFO:root:current mean train loss 1252.087235090939
INFO:root:current train perplexity2.6855950355529785
INFO:root:current mean train loss 1252.0139360462945
INFO:root:current train perplexity2.6851918697357178
INFO:root:current mean train loss 1252.2326199987149
INFO:root:current train perplexity2.684600830078125
INFO:root:current mean train loss 1252.5345636726267
INFO:root:current train perplexity2.6859829425811768
INFO:root:current mean train loss 1253.1819949158707
INFO:root:current train perplexity2.6861302852630615
INFO:root:current mean train loss 1253.5793264106026
INFO:root:current train perplexity2.686405658721924
INFO:root:current mean train loss 1253.9915463517852
INFO:root:current train perplexity2.687380313873291
INFO:root:current mean train loss 1253.8845416736456
INFO:root:current train perplexity2.6873786449432373

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.10s/it]
INFO:root:final mean train loss: 1253.5371670552233
INFO:root:final train perplexity: 2.687509298324585
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it]
INFO:root:eval mean loss: 2299.954691136137
INFO:root:eval perplexity: 6.424176216125488
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it]
INFO:root:eval mean loss: 2891.970179348127
INFO:root:eval perplexity: 10.6454496383667
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/181
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [31:45:35<3:17:59, 625.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1244.713189376028
INFO:root:current train perplexity2.67159366607666
INFO:root:current mean train loss 1249.1672696200285
INFO:root:current train perplexity2.675021171569824
INFO:root:current mean train loss 1249.5453610627549
INFO:root:current train perplexity2.67427396774292
INFO:root:current mean train loss 1247.9124671449053
INFO:root:current train perplexity2.6768407821655273
INFO:root:current mean train loss 1249.1943095231256
INFO:root:current train perplexity2.6812641620635986
INFO:root:current mean train loss 1249.9799900054932
INFO:root:current train perplexity2.678738832473755
INFO:root:current mean train loss 1249.8194706482295
INFO:root:current train perplexity2.6798503398895264
INFO:root:current mean train loss 1250.9127035239308
INFO:root:current train perplexity2.681781053543091
INFO:root:current mean train loss 1251.0130861883295
INFO:root:current train perplexity2.6840479373931885
INFO:root:current mean train loss 1250.429781429103
INFO:root:current train perplexity2.684314727783203
INFO:root:current mean train loss 1250.846256979336
INFO:root:current train perplexity2.684864044189453
INFO:root:current mean train loss 1251.3521154494513
INFO:root:current train perplexity2.684803009033203
INFO:root:current mean train loss 1251.8378043339171
INFO:root:current train perplexity2.684931993484497
INFO:root:current mean train loss 1251.8375983127328
INFO:root:current train perplexity2.6847288608551025
INFO:root:current mean train loss 1252.2385599606728
INFO:root:current train perplexity2.685239553451538
INFO:root:current mean train loss 1253.0618558777164
INFO:root:current train perplexity2.6860716342926025
INFO:root:current mean train loss 1253.205458757132
INFO:root:current train perplexity2.6865265369415283
INFO:root:current mean train loss 1253.2721793372352
INFO:root:current train perplexity2.6850199699401855
INFO:root:current mean train loss 1253.0964600780626
INFO:root:current train perplexity2.6847610473632812
INFO:root:current mean train loss 1253.2955610143993
INFO:root:current train perplexity2.68638277053833

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.13s/it]
INFO:root:final mean train loss: 1252.989124199987
INFO:root:final train perplexity: 2.6863479614257812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 2300.640764818124
INFO:root:eval perplexity: 6.427740573883057
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.79s/it]
INFO:root:eval mean loss: 2893.097790440769
INFO:root:eval perplexity: 10.655271530151367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/182
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [31:55:55<3:07:03, 623.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1255.1018840830814
INFO:root:current train perplexity2.677856683731079
INFO:root:current mean train loss 1253.1802061407059
INFO:root:current train perplexity2.675816059112549
INFO:root:current mean train loss 1250.9749322572259
INFO:root:current train perplexity2.6730148792266846
INFO:root:current mean train loss 1249.9915734210997
INFO:root:current train perplexity2.675865888595581
INFO:root:current mean train loss 1251.0867221669782
INFO:root:current train perplexity2.6758406162261963
INFO:root:current mean train loss 1250.6097053926671
INFO:root:current train perplexity2.678685188293457
INFO:root:current mean train loss 1250.7692649147727
INFO:root:current train perplexity2.682264804840088
INFO:root:current mean train loss 1251.5155974456673
INFO:root:current train perplexity2.6822876930236816
INFO:root:current mean train loss 1251.5563422157143
INFO:root:current train perplexity2.6823487281799316
INFO:root:current mean train loss 1251.393050671104
INFO:root:current train perplexity2.6838340759277344
INFO:root:current mean train loss 1251.3421378454154
INFO:root:current train perplexity2.6845314502716064
INFO:root:current mean train loss 1251.5704292495611
INFO:root:current train perplexity2.684302568435669
INFO:root:current mean train loss 1251.3932701399967
INFO:root:current train perplexity2.6843678951263428
INFO:root:current mean train loss 1251.6032215345701
INFO:root:current train perplexity2.6835827827453613
INFO:root:current mean train loss 1251.6405360432016
INFO:root:current train perplexity2.683636426925659
INFO:root:current mean train loss 1252.0029905310832
INFO:root:current train perplexity2.684170722961426
INFO:root:current mean train loss 1252.0032664804296
INFO:root:current train perplexity2.6839077472686768
INFO:root:current mean train loss 1251.9364748953178
INFO:root:current train perplexity2.6837408542633057
INFO:root:current mean train loss 1252.2082035248077
INFO:root:current train perplexity2.6833016872406006

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.36s/it]
INFO:root:final mean train loss: 1251.768939766088
INFO:root:final train perplexity: 2.6837639808654785
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it]
INFO:root:eval mean loss: 2301.2665279740136
INFO:root:eval perplexity: 6.430994987487793
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it]
INFO:root:eval mean loss: 2893.297641186004
INFO:root:eval perplexity: 10.657014846801758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/183
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [32:06:27<2:57:22, 626.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1268.1904541015624
INFO:root:current train perplexity2.6581668853759766
INFO:root:current mean train loss 1252.9276910955255
INFO:root:current train perplexity2.6702260971069336
INFO:root:current mean train loss 1250.3465750558037
INFO:root:current train perplexity2.6731278896331787
INFO:root:current mean train loss 1249.2324246314265
INFO:root:current train perplexity2.6781370639801025
INFO:root:current mean train loss 1249.317437297542
INFO:root:current train perplexity2.6820645332336426
INFO:root:current mean train loss 1249.8518224379595
INFO:root:current train perplexity2.685131311416626
INFO:root:current mean train loss 1250.7103959880892
INFO:root:current train perplexity2.6849634647369385
INFO:root:current mean train loss 1250.471632578675
INFO:root:current train perplexity2.683472156524658
INFO:root:current mean train loss 1250.8378294391396
INFO:root:current train perplexity2.68420672416687
INFO:root:current mean train loss 1251.0412047669129
INFO:root:current train perplexity2.6839499473571777
INFO:root:current mean train loss 1250.9862001324643
INFO:root:current train perplexity2.6843690872192383
INFO:root:current mean train loss 1251.2202836870074
INFO:root:current train perplexity2.6849801540374756
INFO:root:current mean train loss 1252.0495998918518
INFO:root:current train perplexity2.68308162689209
INFO:root:current mean train loss 1252.0040346567866
INFO:root:current train perplexity2.6826560497283936
INFO:root:current mean train loss 1252.1690972510805
INFO:root:current train perplexity2.682311773300171
INFO:root:current mean train loss 1252.0931790989755
INFO:root:current train perplexity2.6818203926086426
INFO:root:current mean train loss 1251.6373700444003
INFO:root:current train perplexity2.681476354598999
INFO:root:current mean train loss 1251.6274040712947
INFO:root:current train perplexity2.681553840637207
INFO:root:current mean train loss 1251.002055434759
INFO:root:current train perplexity2.6811299324035645
INFO:root:current mean train loss 1251.068950553215
INFO:root:current train perplexity2.6820545196533203

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.66s/it]
INFO:root:final mean train loss: 1251.013397909329
INFO:root:final train perplexity: 2.6821653842926025
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it]
INFO:root:eval mean loss: 2302.5162379488033
INFO:root:eval perplexity: 6.437498092651367
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it]
INFO:root:eval mean loss: 2895.7230579565603
INFO:root:eval perplexity: 10.678173065185547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/184
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [32:17:00<2:47:29, 628.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1247.0157787181713
INFO:root:current train perplexity2.6782100200653076
INFO:root:current mean train loss 1244.15592896469
INFO:root:current train perplexity2.6739237308502197
INFO:root:current mean train loss 1245.9713925265005
INFO:root:current train perplexity2.672149896621704
INFO:root:current mean train loss 1245.5286895098673
INFO:root:current train perplexity2.665889263153076
INFO:root:current mean train loss 1245.8475173128293
INFO:root:current train perplexity2.667938709259033
INFO:root:current mean train loss 1244.4551816647147
INFO:root:current train perplexity2.668876886367798
INFO:root:current mean train loss 1245.9999375046725
INFO:root:current train perplexity2.668253183364868
INFO:root:current mean train loss 1247.1088494428086
INFO:root:current train perplexity2.6697676181793213
INFO:root:current mean train loss 1247.9725148432776
INFO:root:current train perplexity2.6727566719055176
INFO:root:current mean train loss 1248.77324813958
INFO:root:current train perplexity2.675072193145752
INFO:root:current mean train loss 1248.5883950713546
INFO:root:current train perplexity2.6779491901397705
INFO:root:current mean train loss 1248.880514935254
INFO:root:current train perplexity2.6772823333740234
INFO:root:current mean train loss 1249.694069710804
INFO:root:current train perplexity2.678400993347168
INFO:root:current mean train loss 1249.8327979840276
INFO:root:current train perplexity2.679440498352051
INFO:root:current mean train loss 1249.7210177533177
INFO:root:current train perplexity2.679488182067871
INFO:root:current mean train loss 1250.4954039368195
INFO:root:current train perplexity2.679941415786743
INFO:root:current mean train loss 1250.7179767629743
INFO:root:current train perplexity2.680217742919922
INFO:root:current mean train loss 1250.4467707701895
INFO:root:current train perplexity2.6806118488311768
INFO:root:current mean train loss 1250.4904612106382
INFO:root:current train perplexity2.6805689334869385
INFO:root:current mean train loss 1250.8247150130142
INFO:root:current train perplexity2.680291175842285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.50s/it]
INFO:root:final mean train loss: 1250.2757433392578
INFO:root:final train perplexity: 2.680605173110962
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.85s/it]
INFO:root:eval mean loss: 2302.3578556141956
INFO:root:eval perplexity: 6.436673164367676
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it]
INFO:root:eval mean loss: 2895.3865914852063
INFO:root:eval perplexity: 10.675237655639648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/185
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [32:27:32<2:37:19, 629.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1241.3636890758169
INFO:root:current train perplexity2.681997537612915
INFO:root:current mean train loss 1246.3983357747395
INFO:root:current train perplexity2.6736464500427246
INFO:root:current mean train loss 1247.0436281298028
INFO:root:current train perplexity2.6742355823516846
INFO:root:current mean train loss 1247.4726952841115
INFO:root:current train perplexity2.6743531227111816
INFO:root:current mean train loss 1247.2785045177013
INFO:root:current train perplexity2.67449688911438
INFO:root:current mean train loss 1247.169699276195
INFO:root:current train perplexity2.6785213947296143
INFO:root:current mean train loss 1246.6091856393755
INFO:root:current train perplexity2.6770870685577393
INFO:root:current mean train loss 1247.644810994466
INFO:root:current train perplexity2.6773571968078613
INFO:root:current mean train loss 1249.7017930740428
INFO:root:current train perplexity2.6770474910736084
INFO:root:current mean train loss 1249.222571809413
INFO:root:current train perplexity2.6778724193573
INFO:root:current mean train loss 1249.4584724747815
INFO:root:current train perplexity2.6769444942474365
INFO:root:current mean train loss 1250.0573354867788
INFO:root:current train perplexity2.676175355911255
INFO:root:current mean train loss 1250.1318812722945
INFO:root:current train perplexity2.6767396926879883
INFO:root:current mean train loss 1249.553213936942
INFO:root:current train perplexity2.6756134033203125
INFO:root:current mean train loss 1250.0747542870013
INFO:root:current train perplexity2.6770753860473633
INFO:root:current mean train loss 1249.98443484924
INFO:root:current train perplexity2.6776158809661865
INFO:root:current mean train loss 1249.6801354624058
INFO:root:current train perplexity2.677955389022827
INFO:root:current mean train loss 1249.7207634602119
INFO:root:current train perplexity2.6786305904388428
INFO:root:current mean train loss 1249.9330416532505
INFO:root:current train perplexity2.679260730743408
INFO:root:current mean train loss 1249.7211668540422
INFO:root:current train perplexity2.6792092323303223

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.32s/it]
INFO:root:final mean train loss: 1249.5712697023823
INFO:root:final train perplexity: 2.679116725921631
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.25s/it]
INFO:root:eval mean loss: 2303.1022512016566
INFO:root:eval perplexity: 6.440550804138184
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.86s/it]
INFO:root:eval mean loss: 2896.2834360109155
INFO:root:eval perplexity: 10.683072090148926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/186
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [32:38:04<2:27:03, 630.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1255.691674404457
INFO:root:current train perplexity2.6707730293273926
INFO:root:current mean train loss 1257.3237319851514
INFO:root:current train perplexity2.6761422157287598
INFO:root:current mean train loss 1256.0106084246288
INFO:root:current train perplexity2.6779775619506836
INFO:root:current mean train loss 1254.215050018395
INFO:root:current train perplexity2.680677890777588
INFO:root:current mean train loss 1251.6311628296164
INFO:root:current train perplexity2.6772301197052
INFO:root:current mean train loss 1251.2798880782782
INFO:root:current train perplexity2.675670862197876
INFO:root:current mean train loss 1250.436783644868
INFO:root:current train perplexity2.676664113998413
INFO:root:current mean train loss 1248.9340804271724
INFO:root:current train perplexity2.6776273250579834
INFO:root:current mean train loss 1249.2624751322498
INFO:root:current train perplexity2.6780412197113037
INFO:root:current mean train loss 1248.3489784455076
INFO:root:current train perplexity2.6771674156188965
INFO:root:current mean train loss 1248.3791819149094
INFO:root:current train perplexity2.6770410537719727
INFO:root:current mean train loss 1248.0716808230377
INFO:root:current train perplexity2.676920175552368
INFO:root:current mean train loss 1248.0729719096946
INFO:root:current train perplexity2.677638530731201
INFO:root:current mean train loss 1249.1892671942448
INFO:root:current train perplexity2.6780078411102295
INFO:root:current mean train loss 1249.9324527560318
INFO:root:current train perplexity2.6768856048583984
INFO:root:current mean train loss 1249.840208475136
INFO:root:current train perplexity2.6774661540985107
INFO:root:current mean train loss 1249.708206829
INFO:root:current train perplexity2.6784379482269287
INFO:root:current mean train loss 1249.410298977299
INFO:root:current train perplexity2.6779775619506836
INFO:root:current mean train loss 1249.2605827942386
INFO:root:current train perplexity2.6775217056274414
INFO:root:current mean train loss 1249.0328273277146
INFO:root:current train perplexity2.6775057315826416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:45<00:00, 585.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:45<00:00, 585.07s/it]
INFO:root:final mean train loss: 1248.6470432329586
INFO:root:final train perplexity: 2.677164316177368
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it]
INFO:root:eval mean loss: 2303.9000815533577
INFO:root:eval perplexity: 6.444707870483398
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 2896.97548680948
INFO:root:eval perplexity: 10.689118385314941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/187
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [32:49:04<2:18:29, 639.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1237.1026110526843
INFO:root:current train perplexity2.6817641258239746
INFO:root:current mean train loss 1245.8643551944347
INFO:root:current train perplexity2.680145740509033
INFO:root:current mean train loss 1244.6423598913839
INFO:root:current train perplexity2.6672935485839844
INFO:root:current mean train loss 1245.6987827845983
INFO:root:current train perplexity2.6685404777526855
INFO:root:current mean train loss 1244.844577677579
INFO:root:current train perplexity2.6692309379577637
INFO:root:current mean train loss 1244.9884440808148
INFO:root:current train perplexity2.6714651584625244
INFO:root:current mean train loss 1244.653136126763
INFO:root:current train perplexity2.6713356971740723
INFO:root:current mean train loss 1245.280423907204
INFO:root:current train perplexity2.670478105545044
INFO:root:current mean train loss 1245.1739158543476
INFO:root:current train perplexity2.671894073486328
INFO:root:current mean train loss 1245.9156834889043
INFO:root:current train perplexity2.6721529960632324
INFO:root:current mean train loss 1246.333898993724
INFO:root:current train perplexity2.67360258102417
INFO:root:current mean train loss 1246.879546756453
INFO:root:current train perplexity2.674685001373291
INFO:root:current mean train loss 1247.7202561069541
INFO:root:current train perplexity2.6744513511657715
INFO:root:current mean train loss 1248.269446296858
INFO:root:current train perplexity2.6737308502197266
INFO:root:current mean train loss 1248.589460690386
INFO:root:current train perplexity2.674553155899048
INFO:root:current mean train loss 1248.432225680623
INFO:root:current train perplexity2.67345929145813
INFO:root:current mean train loss 1248.1142689428682
INFO:root:current train perplexity2.6732192039489746
INFO:root:current mean train loss 1248.33108551403
INFO:root:current train perplexity2.673973560333252
INFO:root:current mean train loss 1248.695393750208
INFO:root:current train perplexity2.675416946411133
INFO:root:current mean train loss 1248.4228946388791
INFO:root:current train perplexity2.6758627891540527

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.47s/it]
INFO:root:final mean train loss: 1248.0998066696807
INFO:root:final train perplexity: 2.676009178161621
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.59s/it]
INFO:root:eval mean loss: 2304.751092572584
INFO:root:eval perplexity: 6.4491424560546875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.14s/it]
INFO:root:eval mean loss: 2897.878756042913
INFO:root:eval perplexity: 10.697015762329102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/188
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [32:59:39<2:07:33, 637.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1247.8110454358552
INFO:root:current train perplexity2.677467107772827
INFO:root:current mean train loss 1247.786862104367
INFO:root:current train perplexity2.6666476726531982
INFO:root:current mean train loss 1248.592839645127
INFO:root:current train perplexity2.664233446121216
INFO:root:current mean train loss 1247.6030910057357
INFO:root:current train perplexity2.6634414196014404
INFO:root:current mean train loss 1248.546870314473
INFO:root:current train perplexity2.667819023132324
INFO:root:current mean train loss 1247.2733131729253
INFO:root:current train perplexity2.6677796840667725
INFO:root:current mean train loss 1246.6526850199527
INFO:root:current train perplexity2.667567729949951
INFO:root:current mean train loss 1246.189097969487
INFO:root:current train perplexity2.6679296493530273
INFO:root:current mean train loss 1246.0896487102827
INFO:root:current train perplexity2.667673349380493
INFO:root:current mean train loss 1247.199138392156
INFO:root:current train perplexity2.669166088104248
INFO:root:current mean train loss 1247.2585179437785
INFO:root:current train perplexity2.6712679862976074
INFO:root:current mean train loss 1247.7415870570737
INFO:root:current train perplexity2.672316789627075
INFO:root:current mean train loss 1247.5488960884713
INFO:root:current train perplexity2.6734507083892822
INFO:root:current mean train loss 1247.168950387825
INFO:root:current train perplexity2.6738903522491455
INFO:root:current mean train loss 1247.5615982310828
INFO:root:current train perplexity2.6741104125976562
INFO:root:current mean train loss 1247.5026700871865
INFO:root:current train perplexity2.674886465072632
INFO:root:current mean train loss 1248.0219626457642
INFO:root:current train perplexity2.675029993057251
INFO:root:current mean train loss 1248.158157493145
INFO:root:current train perplexity2.675960063934326
INFO:root:current mean train loss 1248.0225026797493
INFO:root:current train perplexity2.6762399673461914

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.81s/it]
INFO:root:final mean train loss: 1247.8605453791308
INFO:root:final train perplexity: 2.675504207611084
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.77s/it]
INFO:root:eval mean loss: 2305.2547165890956
INFO:root:eval perplexity: 6.451770782470703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.66s/it]
INFO:root:eval mean loss: 2898.6354872250386
INFO:root:eval perplexity: 10.703639030456543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/189
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [33:10:04<1:56:14, 634.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1232.9350280761719
INFO:root:current train perplexity2.645155668258667
INFO:root:current mean train loss 1246.3021022251673
INFO:root:current train perplexity2.6627442836761475
INFO:root:current mean train loss 1245.1465436827461
INFO:root:current train perplexity2.6729233264923096
INFO:root:current mean train loss 1244.3237042549329
INFO:root:current train perplexity2.6682276725769043
INFO:root:current mean train loss 1243.6441822237182
INFO:root:current train perplexity2.667203187942505
INFO:root:current mean train loss 1244.0003263950348
INFO:root:current train perplexity2.6710240840911865
INFO:root:current mean train loss 1245.7342325846355
INFO:root:current train perplexity2.6693782806396484
INFO:root:current mean train loss 1245.9442973619098
INFO:root:current train perplexity2.6695265769958496
INFO:root:current mean train loss 1246.1455907962593
INFO:root:current train perplexity2.671565055847168
INFO:root:current mean train loss 1245.4552695291084
INFO:root:current train perplexity2.673177480697632
INFO:root:current mean train loss 1245.9052218109252
INFO:root:current train perplexity2.6726629734039307
INFO:root:current mean train loss 1246.3879117897088
INFO:root:current train perplexity2.672367572784424
INFO:root:current mean train loss 1247.0782829259488
INFO:root:current train perplexity2.672635793685913
INFO:root:current mean train loss 1246.558503685928
INFO:root:current train perplexity2.672600269317627
INFO:root:current mean train loss 1246.8146550770184
INFO:root:current train perplexity2.673151969909668
INFO:root:current mean train loss 1247.1628244389933
INFO:root:current train perplexity2.6730270385742188
INFO:root:current mean train loss 1246.9926139888337
INFO:root:current train perplexity2.6737401485443115
INFO:root:current mean train loss 1246.9011087863246
INFO:root:current train perplexity2.6732687950134277
INFO:root:current mean train loss 1247.0897041640796
INFO:root:current train perplexity2.6733901500701904
INFO:root:current mean train loss 1247.0719321661913
INFO:root:current train perplexity2.6735146045684814

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.30s/it]
INFO:root:final mean train loss: 1246.7821831638262
INFO:root:final train perplexity: 2.673229694366455
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it]
INFO:root:eval mean loss: 2305.003675528452
INFO:root:eval perplexity: 6.4504618644714355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.13s/it]
INFO:root:eval mean loss: 2898.4134231459166
INFO:root:eval perplexity: 10.70169448852539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/190
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [33:20:27<1:45:08, 630.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1253.723043507543
INFO:root:current train perplexity2.6690406799316406
INFO:root:current mean train loss 1240.8429134871608
INFO:root:current train perplexity2.667811155319214
INFO:root:current mean train loss 1241.2959128300695
INFO:root:current train perplexity2.664032459259033
INFO:root:current mean train loss 1243.1340306058844
INFO:root:current train perplexity2.66738224029541
INFO:root:current mean train loss 1245.631971381483
INFO:root:current train perplexity2.6688475608825684
INFO:root:current mean train loss 1245.1740978796224
INFO:root:current train perplexity2.668443202972412
INFO:root:current mean train loss 1244.142004646823
INFO:root:current train perplexity2.6687636375427246
INFO:root:current mean train loss 1245.4588298195838
INFO:root:current train perplexity2.668628692626953
INFO:root:current mean train loss 1245.0851634063536
INFO:root:current train perplexity2.6687169075012207
INFO:root:current mean train loss 1245.2697573888674
INFO:root:current train perplexity2.669776439666748
INFO:root:current mean train loss 1244.867121423067
INFO:root:current train perplexity2.6702675819396973
INFO:root:current mean train loss 1244.0946659057724
INFO:root:current train perplexity2.670025110244751
INFO:root:current mean train loss 1244.7961508220924
INFO:root:current train perplexity2.6693928241729736
INFO:root:current mean train loss 1245.4560665363115
INFO:root:current train perplexity2.670126438140869
INFO:root:current mean train loss 1245.6038027336915
INFO:root:current train perplexity2.670886754989624
INFO:root:current mean train loss 1246.080630515119
INFO:root:current train perplexity2.6709392070770264
INFO:root:current mean train loss 1246.2994200423716
INFO:root:current train perplexity2.6724021434783936
INFO:root:current mean train loss 1246.2518050732676
INFO:root:current train perplexity2.6728930473327637
INFO:root:current mean train loss 1246.5660735433255
INFO:root:current train perplexity2.6732099056243896
INFO:root:current mean train loss 1246.7156076228575
INFO:root:current train perplexity2.6729490756988525

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.04s/it]
INFO:root:final mean train loss: 1246.775092959344
INFO:root:final train perplexity: 2.6732146739959717
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.57s/it]
INFO:root:eval mean loss: 2305.2536443615636
INFO:root:eval perplexity: 6.451766014099121
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 2898.7084116834276
INFO:root:eval perplexity: 10.704277038574219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/191
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [33:31:01<1:34:43, 631.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1239.9743519658628
INFO:root:current train perplexity2.64853572845459
INFO:root:current mean train loss 1239.1912206362372
INFO:root:current train perplexity2.6589460372924805
INFO:root:current mean train loss 1241.77478821297
INFO:root:current train perplexity2.666660785675049
INFO:root:current mean train loss 1243.5736789593118
INFO:root:current train perplexity2.6713502407073975
INFO:root:current mean train loss 1243.4670035186905
INFO:root:current train perplexity2.6691677570343018
INFO:root:current mean train loss 1243.3543658693195
INFO:root:current train perplexity2.6685781478881836
INFO:root:current mean train loss 1243.5690575945118
INFO:root:current train perplexity2.6692614555358887
INFO:root:current mean train loss 1244.0010069982616
INFO:root:current train perplexity2.6689624786376953
INFO:root:current mean train loss 1244.477460856697
INFO:root:current train perplexity2.6669957637786865
INFO:root:current mean train loss 1244.2048492109045
INFO:root:current train perplexity2.6662702560424805
INFO:root:current mean train loss 1244.670111632484
INFO:root:current train perplexity2.666019916534424
INFO:root:current mean train loss 1245.4529068499128
INFO:root:current train perplexity2.6666667461395264
INFO:root:current mean train loss 1245.4916064413937
INFO:root:current train perplexity2.6684367656707764
INFO:root:current mean train loss 1245.4579330829774
INFO:root:current train perplexity2.668703079223633
INFO:root:current mean train loss 1245.5084903025859
INFO:root:current train perplexity2.669646978378296
INFO:root:current mean train loss 1245.2892553174017
INFO:root:current train perplexity2.670095920562744
INFO:root:current mean train loss 1245.643087245714
INFO:root:current train perplexity2.6711437702178955
INFO:root:current mean train loss 1246.2242692420846
INFO:root:current train perplexity2.6715192794799805
INFO:root:current mean train loss 1246.559398713117
INFO:root:current train perplexity2.6717634201049805
INFO:root:current mean train loss 1246.3056293734544
INFO:root:current train perplexity2.671332359313965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.14s/it]
INFO:root:final mean train loss: 1246.0907967048527
INFO:root:final train perplexity: 2.6717729568481445
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it]
INFO:root:eval mean loss: 2305.872954240082
INFO:root:eval perplexity: 6.454998016357422
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it]
INFO:root:eval mean loss: 2899.506422110483
INFO:root:eval perplexity: 10.71126651763916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/192
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [33:41:21<1:23:46, 628.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1258.728279234871
INFO:root:current train perplexity2.645282506942749
INFO:root:current mean train loss 1244.4443531621453
INFO:root:current train perplexity2.667705774307251
INFO:root:current mean train loss 1242.4749194243109
INFO:root:current train perplexity2.6666650772094727
INFO:root:current mean train loss 1244.4283063904313
INFO:root:current train perplexity2.662896156311035
INFO:root:current mean train loss 1245.824611062365
INFO:root:current train perplexity2.6635634899139404
INFO:root:current mean train loss 1245.4851692159052
INFO:root:current train perplexity2.666141986846924
INFO:root:current mean train loss 1245.9220432839602
INFO:root:current train perplexity2.667750120162964
INFO:root:current mean train loss 1246.6791033863553
INFO:root:current train perplexity2.6681134700775146
INFO:root:current mean train loss 1245.705632179941
INFO:root:current train perplexity2.6679136753082275
INFO:root:current mean train loss 1245.530597437208
INFO:root:current train perplexity2.668121814727783
INFO:root:current mean train loss 1245.7940454492004
INFO:root:current train perplexity2.669984817504883
INFO:root:current mean train loss 1245.797712068566
INFO:root:current train perplexity2.6701500415802
INFO:root:current mean train loss 1246.085344835585
INFO:root:current train perplexity2.670478582382202
INFO:root:current mean train loss 1245.7051890003095
INFO:root:current train perplexity2.670093059539795
INFO:root:current mean train loss 1245.5102191124563
INFO:root:current train perplexity2.671135187149048
INFO:root:current mean train loss 1245.6948231253498
INFO:root:current train perplexity2.6709864139556885
INFO:root:current mean train loss 1245.7346346288004
INFO:root:current train perplexity2.6706371307373047
INFO:root:current mean train loss 1246.1996180577096
INFO:root:current train perplexity2.6698782444000244
INFO:root:current mean train loss 1246.03662705639
INFO:root:current train perplexity2.670339584350586
INFO:root:current mean train loss 1245.569617949149
INFO:root:current train perplexity2.670487403869629

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:08<00:00, 548.68s/it]
INFO:root:final mean train loss: 1245.4513890838239
INFO:root:final train perplexity: 2.6704256534576416
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 2306.876668294271
INFO:root:eval perplexity: 6.460240364074707
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.89s/it]
INFO:root:eval mean loss: 2900.0590551930964
INFO:root:eval perplexity: 10.716107368469238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/193
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [33:51:44<1:13:07, 626.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1240.560122680664
INFO:root:current train perplexity2.6601152420043945
INFO:root:current mean train loss 1245.3062628851997
INFO:root:current train perplexity2.6733455657958984
INFO:root:current mean train loss 1245.2495670863561
INFO:root:current train perplexity2.6764607429504395
INFO:root:current mean train loss 1244.7327270507812
INFO:root:current train perplexity2.674530506134033
INFO:root:current mean train loss 1245.6914405822754
INFO:root:current train perplexity2.671419143676758
INFO:root:current mean train loss 1244.9435420595366
INFO:root:current train perplexity2.669318914413452
INFO:root:current mean train loss 1244.3855644674861
INFO:root:current train perplexity2.6674861907958984
INFO:root:current mean train loss 1244.4622467823517
INFO:root:current train perplexity2.6678857803344727
INFO:root:current mean train loss 1244.4277340975675
INFO:root:current train perplexity2.6669631004333496
INFO:root:current mean train loss 1244.4124799455915
INFO:root:current train perplexity2.6665055751800537
INFO:root:current mean train loss 1243.8639604356554
INFO:root:current train perplexity2.666078567504883
INFO:root:current mean train loss 1244.3955043986691
INFO:root:current train perplexity2.6666018962860107
INFO:root:current mean train loss 1244.2822138786316
INFO:root:current train perplexity2.6662397384643555
INFO:root:current mean train loss 1244.5884264075237
INFO:root:current train perplexity2.666290283203125
INFO:root:current mean train loss 1244.4219434583508
INFO:root:current train perplexity2.6671197414398193
INFO:root:current mean train loss 1244.2253920156745
INFO:root:current train perplexity2.6681137084960938
INFO:root:current mean train loss 1244.1952778407506
INFO:root:current train perplexity2.6682651042938232
INFO:root:current mean train loss 1244.6561072874606
INFO:root:current train perplexity2.6684534549713135
INFO:root:current mean train loss 1244.907718934404
INFO:root:current train perplexity2.6692872047424316
INFO:root:current mean train loss 1245.0255017213146
INFO:root:current train perplexity2.668887138366699

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.97s/it]
INFO:root:final mean train loss: 1244.6482628280323
INFO:root:final train perplexity: 2.6687347888946533
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it]
INFO:root:eval mean loss: 2306.5311296611812
INFO:root:eval perplexity: 6.458433628082275
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 2900.416358027898
INFO:root:eval perplexity: 10.719237327575684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/194
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [34:02:20<1:02:56, 629.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1234.7411706668815
INFO:root:current train perplexity2.6671347618103027
INFO:root:current mean train loss 1236.3382140803458
INFO:root:current train perplexity2.6606321334838867
INFO:root:current mean train loss 1239.4848098498
INFO:root:current train perplexity2.6662917137145996
INFO:root:current mean train loss 1242.095185018006
INFO:root:current train perplexity2.6629955768585205
INFO:root:current mean train loss 1242.566546987
INFO:root:current train perplexity2.6616008281707764
INFO:root:current mean train loss 1241.8361481070717
INFO:root:current train perplexity2.6633293628692627
INFO:root:current mean train loss 1241.578442522922
INFO:root:current train perplexity2.666092872619629
INFO:root:current mean train loss 1242.471922602827
INFO:root:current train perplexity2.6664464473724365
INFO:root:current mean train loss 1243.7824994175464
INFO:root:current train perplexity2.6666927337646484
INFO:root:current mean train loss 1243.466981878252
INFO:root:current train perplexity2.66782808303833
INFO:root:current mean train loss 1243.7329782574636
INFO:root:current train perplexity2.668362855911255
INFO:root:current mean train loss 1243.8005673974976
INFO:root:current train perplexity2.668405532836914
INFO:root:current mean train loss 1243.6963932505
INFO:root:current train perplexity2.6663811206817627
INFO:root:current mean train loss 1243.5879886657235
INFO:root:current train perplexity2.6660003662109375
INFO:root:current mean train loss 1243.3218454324012
INFO:root:current train perplexity2.666383981704712
INFO:root:current mean train loss 1244.0311667598182
INFO:root:current train perplexity2.666280508041382
INFO:root:current mean train loss 1244.2240295949655
INFO:root:current train perplexity2.6669905185699463
INFO:root:current mean train loss 1244.4175503687786
INFO:root:current train perplexity2.6670572757720947
INFO:root:current mean train loss 1244.548673365326
INFO:root:current train perplexity2.667239189147949

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.91s/it]
INFO:root:final mean train loss: 1243.9234211316207
INFO:root:final train perplexity: 2.6672093868255615
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it]
INFO:root:eval mean loss: 2306.9079273846132
INFO:root:eval perplexity: 6.460402011871338
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.44s/it]
INFO:root:eval mean loss: 2900.678130021332
INFO:root:eval perplexity: 10.721532821655273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/195
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [34:12:44<52:18, 627.78s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1224.8943045479912
INFO:root:current train perplexity2.6820130348205566
INFO:root:current mean train loss 1243.4729389391448
INFO:root:current train perplexity2.6702678203582764
INFO:root:current mean train loss 1245.2109494788624
INFO:root:current train perplexity2.6685025691986084
INFO:root:current mean train loss 1244.925329123333
INFO:root:current train perplexity2.66664719581604
INFO:root:current mean train loss 1244.9625836800838
INFO:root:current train perplexity2.667520761489868
INFO:root:current mean train loss 1245.4286449150352
INFO:root:current train perplexity2.6706042289733887
INFO:root:current mean train loss 1243.9935769941596
INFO:root:current train perplexity2.6690213680267334
INFO:root:current mean train loss 1243.7443124466583
INFO:root:current train perplexity2.6673762798309326
INFO:root:current mean train loss 1244.9382249236985
INFO:root:current train perplexity2.667813301086426
INFO:root:current mean train loss 1245.1070161314449
INFO:root:current train perplexity2.668437957763672
INFO:root:current mean train loss 1244.6437284029448
INFO:root:current train perplexity2.66882061958313
INFO:root:current mean train loss 1244.164264233793
INFO:root:current train perplexity2.6683971881866455
INFO:root:current mean train loss 1244.277353704663
INFO:root:current train perplexity2.667956829071045
INFO:root:current mean train loss 1244.0446247814998
INFO:root:current train perplexity2.6674675941467285
INFO:root:current mean train loss 1243.9472027769184
INFO:root:current train perplexity2.6670801639556885
INFO:root:current mean train loss 1244.9254085888479
INFO:root:current train perplexity2.6669578552246094
INFO:root:current mean train loss 1245.0237911559982
INFO:root:current train perplexity2.6670286655426025
INFO:root:current mean train loss 1244.9918427261478
INFO:root:current train perplexity2.6675872802734375
INFO:root:current mean train loss 1244.9224600492264
INFO:root:current train perplexity2.6676723957061768
INFO:root:current mean train loss 1244.6306026064117
INFO:root:current train perplexity2.667168140411377

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:06<00:00, 546.27s/it]
INFO:root:final mean train loss: 1244.2993897530869
INFO:root:final train perplexity: 2.6680006980895996
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.06s/it]
INFO:root:eval mean loss: 2307.404777364528
INFO:root:eval perplexity: 6.462998867034912
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.53s/it]
INFO:root:eval mean loss: 2901.199513969692
INFO:root:eval perplexity: 10.726106643676758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/196
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [34:23:03<41:40, 625.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1234.2508269279233
INFO:root:current train perplexity2.6821305751800537
INFO:root:current mean train loss 1243.3375262777313
INFO:root:current train perplexity2.6675922870635986
INFO:root:current mean train loss 1245.1866291260822
INFO:root:current train perplexity2.661652088165283
INFO:root:current mean train loss 1244.3209571492637
INFO:root:current train perplexity2.6625308990478516
INFO:root:current mean train loss 1245.0648068740031
INFO:root:current train perplexity2.6660242080688477
INFO:root:current mean train loss 1245.6012629564648
INFO:root:current train perplexity2.6659140586853027
INFO:root:current mean train loss 1245.4893994218007
INFO:root:current train perplexity2.66442608833313
INFO:root:current mean train loss 1245.329688869325
INFO:root:current train perplexity2.665523052215576
INFO:root:current mean train loss 1245.5183832602381
INFO:root:current train perplexity2.666252374649048
INFO:root:current mean train loss 1244.886813416773
INFO:root:current train perplexity2.666130304336548
INFO:root:current mean train loss 1244.4317584329156
INFO:root:current train perplexity2.6664788722991943
INFO:root:current mean train loss 1243.5465140776967
INFO:root:current train perplexity2.6665444374084473
INFO:root:current mean train loss 1243.843279469023
INFO:root:current train perplexity2.665807008743286
INFO:root:current mean train loss 1244.0479574912836
INFO:root:current train perplexity2.6665220260620117
INFO:root:current mean train loss 1243.8228463760045
INFO:root:current train perplexity2.66690993309021
INFO:root:current mean train loss 1243.5800593081524
INFO:root:current train perplexity2.666794776916504
INFO:root:current mean train loss 1243.1972150305603
INFO:root:current train perplexity2.6660876274108887
INFO:root:current mean train loss 1242.9937153887295
INFO:root:current train perplexity2.6652138233184814
INFO:root:current mean train loss 1243.2125936161294
INFO:root:current train perplexity2.6659772396087646
INFO:root:current mean train loss 1243.4619743074547
INFO:root:current train perplexity2.665821075439453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:04<00:00, 544.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:04<00:00, 544.83s/it]
INFO:root:final mean train loss: 1243.083630906652
INFO:root:final train perplexity: 2.6654436588287354
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it]
INFO:root:eval mean loss: 2307.627497679798
INFO:root:eval perplexity: 6.464163780212402
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.69s/it]
INFO:root:eval mean loss: 2901.530364773798
INFO:root:eval perplexity: 10.729009628295898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/197
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [34:33:21<31:09, 623.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1245.3037948608398
INFO:root:current train perplexity2.6805481910705566
INFO:root:current mean train loss 1241.2186675200592
INFO:root:current train perplexity2.6693782806396484
INFO:root:current mean train loss 1238.0940364714593
INFO:root:current train perplexity2.6590192317962646
INFO:root:current mean train loss 1240.6227132863012
INFO:root:current train perplexity2.6600849628448486
INFO:root:current mean train loss 1240.113349369594
INFO:root:current train perplexity2.6610448360443115
INFO:root:current mean train loss 1241.4528772952783
INFO:root:current train perplexity2.657992362976074
INFO:root:current mean train loss 1241.035226704162
INFO:root:current train perplexity2.6590030193328857
INFO:root:current mean train loss 1240.5762826848159
INFO:root:current train perplexity2.6593716144561768
INFO:root:current mean train loss 1241.4501020323555
INFO:root:current train perplexity2.6597611904144287
INFO:root:current mean train loss 1242.2389700201493
INFO:root:current train perplexity2.6641173362731934
INFO:root:current mean train loss 1243.0950332525122
INFO:root:current train perplexity2.665475368499756
INFO:root:current mean train loss 1243.0215151052441
INFO:root:current train perplexity2.6662113666534424
INFO:root:current mean train loss 1243.3935085198818
INFO:root:current train perplexity2.666801929473877
INFO:root:current mean train loss 1243.7772209552345
INFO:root:current train perplexity2.6666295528411865
INFO:root:current mean train loss 1243.9061299529524
INFO:root:current train perplexity2.665398120880127
INFO:root:current mean train loss 1243.9795157656806
INFO:root:current train perplexity2.665604829788208
INFO:root:current mean train loss 1243.8039445599306
INFO:root:current train perplexity2.6655373573303223
INFO:root:current mean train loss 1243.772027266653
INFO:root:current train perplexity2.665961980819702
INFO:root:current mean train loss 1243.881945589404
INFO:root:current train perplexity2.665804386138916
INFO:root:current mean train loss 1243.6965164090573
INFO:root:current train perplexity2.6658413410186768

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.15s/it]
INFO:root:final mean train loss: 1243.2649458877017
INFO:root:final train perplexity: 2.6658248901367188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.44s/it]
INFO:root:eval mean loss: 2307.480466152759
INFO:root:eval perplexity: 6.463396072387695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.57s/it]
INFO:root:eval mean loss: 2901.318939425421
INFO:root:eval perplexity: 10.727155685424805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/198
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [34:43:48<20:48, 624.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1229.7891564002405
INFO:root:current train perplexity2.6740689277648926
INFO:root:current mean train loss 1238.546983753551
INFO:root:current train perplexity2.6666362285614014
INFO:root:current mean train loss 1240.431045935289
INFO:root:current train perplexity2.666917085647583
INFO:root:current mean train loss 1239.8975030768408
INFO:root:current train perplexity2.6703200340270996
INFO:root:current mean train loss 1240.9829035933299
INFO:root:current train perplexity2.6684908866882324
INFO:root:current mean train loss 1240.9567441146985
INFO:root:current train perplexity2.668177604675293
INFO:root:current mean train loss 1241.1511485623237
INFO:root:current train perplexity2.668962240219116
INFO:root:current mean train loss 1241.4903484668607
INFO:root:current train perplexity2.669546127319336
INFO:root:current mean train loss 1241.6992482444455
INFO:root:current train perplexity2.669171094894409
INFO:root:current mean train loss 1241.5485390776798
INFO:root:current train perplexity2.6698060035705566
INFO:root:current mean train loss 1242.239169555091
INFO:root:current train perplexity2.66875958442688
INFO:root:current mean train loss 1242.382182135193
INFO:root:current train perplexity2.6675405502319336
INFO:root:current mean train loss 1242.607684929286
INFO:root:current train perplexity2.668001651763916
INFO:root:current mean train loss 1242.9243185525413
INFO:root:current train perplexity2.667227029800415
INFO:root:current mean train loss 1242.747194549248
INFO:root:current train perplexity2.6676361560821533
INFO:root:current mean train loss 1243.1013563454721
INFO:root:current train perplexity2.6666619777679443
INFO:root:current mean train loss 1242.863586022546
INFO:root:current train perplexity2.6663625240325928
INFO:root:current mean train loss 1243.051182940864
INFO:root:current train perplexity2.6653473377227783
INFO:root:current mean train loss 1243.106676427928
INFO:root:current train perplexity2.6652348041534424
INFO:root:current mean train loss 1243.2627944596852
INFO:root:current train perplexity2.665144443511963

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.58s/it]
INFO:root:final mean train loss: 1242.888098273804
INFO:root:final train perplexity: 2.6650326251983643
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it]
INFO:root:eval mean loss: 2307.736406475094
INFO:root:eval perplexity: 6.464733123779297
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it]
INFO:root:eval mean loss: 2901.805935474152
INFO:root:eval perplexity: 10.731430053710938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/199
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [34:54:19<10:26, 626.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1227.424966951696
INFO:root:current train perplexity2.672473430633545
INFO:root:current mean train loss 1235.2292051210509
INFO:root:current train perplexity2.661078691482544
INFO:root:current mean train loss 1237.529001655308
INFO:root:current train perplexity2.661011219024658
INFO:root:current mean train loss 1236.8308482544585
INFO:root:current train perplexity2.6593456268310547
INFO:root:current mean train loss 1239.980600697371
INFO:root:current train perplexity2.6614558696746826
INFO:root:current mean train loss 1241.2168809818647
INFO:root:current train perplexity2.662626266479492
INFO:root:current mean train loss 1241.6755066812912
INFO:root:current train perplexity2.6630032062530518
INFO:root:current mean train loss 1242.5133729432246
INFO:root:current train perplexity2.6621522903442383
INFO:root:current mean train loss 1241.736350961283
INFO:root:current train perplexity2.6624393463134766
INFO:root:current mean train loss 1241.3920985452999
INFO:root:current train perplexity2.6637837886810303
INFO:root:current mean train loss 1242.3708238866104
INFO:root:current train perplexity2.6640448570251465
INFO:root:current mean train loss 1242.19859311383
INFO:root:current train perplexity2.6640148162841797
INFO:root:current mean train loss 1242.6378957477634
INFO:root:current train perplexity2.664515733718872
INFO:root:current mean train loss 1242.9603711361478
INFO:root:current train perplexity2.6651220321655273
INFO:root:current mean train loss 1242.6444589303412
INFO:root:current train perplexity2.66473650932312
INFO:root:current mean train loss 1242.575349482212
INFO:root:current train perplexity2.664609432220459
INFO:root:current mean train loss 1242.9974024134215
INFO:root:current train perplexity2.6643099784851074
INFO:root:current mean train loss 1243.1704720134285
INFO:root:current train perplexity2.6648497581481934
INFO:root:current mean train loss 1243.0918889790614
INFO:root:current train perplexity2.6651856899261475
INFO:root:current mean train loss 1243.2215108707862
INFO:root:current train perplexity2.6650588512420654

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.40s/it]
INFO:root:final mean train loss: 1242.9071837794102
INFO:root:final train perplexity: 2.6650729179382324
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it]
INFO:root:eval mean loss: 2307.7383782136526
INFO:root:eval perplexity: 6.4647440910339355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.53s/it]
INFO:root:eval mean loss: 2901.690925760472
INFO:root:eval perplexity: 10.730417251586914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_allminilml12/200
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [35:04:39<00:00, 624.43s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [35:04:39<00:00, 631.40s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.98s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.00s/it]
INFO:root:eval mean loss: 2307.7383782136526
INFO:root:eval perplexity: 6.4647440910339355
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.35s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.37s/it]
INFO:root:eval mean loss: 2901.690925760472
INFO:root:eval perplexity: 10.730417251586914
INFO:root:evalaution complete
INFO:root:save model final: allminil16_allminilml12/final
