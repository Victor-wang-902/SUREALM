INFO:root:Output: small_val_110
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['cls.predictions.transform.dense.bias', 'encoder.layer.3.crossattention.self.value.bias', 'cls.predictions.decoder.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.value.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.value.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.query.weight', 'cls.predictions.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.2.crossattention.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/200 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24418.29478377525
INFO:root:current train perplexity15278.341796875
INFO:root:current mean train loss 20488.721758205087
INFO:root:current train perplexity3212.63037109375
INFO:root:current mean train loss 17707.557741299122
INFO:root:current train perplexity1076.33349609375
INFO:root:current mean train loss 15821.049070429981
INFO:root:current train perplexity507.3225402832031
INFO:root:current mean train loss 14453.377065654748
INFO:root:current train perplexity295.90167236328125
INFO:root:current mean train loss 13414.081513622965
INFO:root:current train perplexity197.06442260742188
INFO:root:current mean train loss 12606.428482514082
INFO:root:current train perplexity143.31663513183594
INFO:root:current mean train loss 11957.796007827166
INFO:root:current train perplexity111.24667358398438
INFO:root:current mean train loss 11426.540544724172
INFO:root:current train perplexity90.27091217041016


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.97s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.88s/it]
INFO:root:eval mean loss: 6411.270383144947
INFO:root:eval perplexity: 13.363532066345215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/1

  0%|          | 1/200 [02:57<9:48:13, 177.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6820.9111328125
INFO:root:current train perplexity14.495214462280273
INFO:root:current mean train loss 6726.40277270736
INFO:root:current train perplexity14.37173843383789
INFO:root:current mean train loss 6700.720401192633
INFO:root:current train perplexity14.150368690490723
INFO:root:current mean train loss 6629.527133804967
INFO:root:current train perplexity13.733580589294434
INFO:root:current mean train loss 6575.262894464066
INFO:root:current train perplexity13.429962158203125
INFO:root:current mean train loss 6525.204627403846
INFO:root:current train perplexity13.159753799438477
INFO:root:current mean train loss 6482.613323079695
INFO:root:current train perplexity12.889975547790527
INFO:root:current mean train loss 6435.442691527803
INFO:root:current train perplexity12.651046752929688
INFO:root:current mean train loss 6391.319171361912
INFO:root:current train perplexity12.425582885742188
INFO:root:current mean train loss 6346.91641077212
INFO:root:current train perplexity12.22208023071289


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.23s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.76s/it]
INFO:root:eval mean loss: 5548.257116439495
INFO:root:eval perplexity: 9.4267578125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/2

  1%|          | 2/200 [05:03<8:05:34, 147.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5997.232063802084
INFO:root:current train perplexity10.680164337158203
INFO:root:current mean train loss 5885.721832540761
INFO:root:current train perplexity10.256714820861816
INFO:root:current mean train loss 5861.819329124273
INFO:root:current train perplexity10.109285354614258
INFO:root:current mean train loss 5843.170672123016
INFO:root:current train perplexity10.002415657043457
INFO:root:current mean train loss 5818.703908603163
INFO:root:current train perplexity9.912090301513672
INFO:root:current mean train loss 5792.73146332676
INFO:root:current train perplexity9.82336139678955
INFO:root:current mean train loss 5767.9779185721545
INFO:root:current train perplexity9.743250846862793
INFO:root:current mean train loss 5749.495699027535
INFO:root:current train perplexity9.666547775268555
INFO:root:current mean train loss 5736.545345451495
INFO:root:current train perplexity9.596400260925293
INFO:root:current mean train loss 5718.046594838627
INFO:root:current train perplexity9.51390266418457


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.54s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.19s/it]
INFO:root:eval mean loss: 5191.593708444149
INFO:root:eval perplexity: 8.160684585571289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/3

  2%|â–         | 3/200 [07:18<7:45:08, 141.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5569.388417119565
INFO:root:current train perplexity8.836996078491211
INFO:root:current mean train loss 5486.763397961128
INFO:root:current train perplexity8.72212028503418
INFO:root:current mean train loss 5487.111424467489
INFO:root:current train perplexity8.666459083557129
INFO:root:current mean train loss 5461.951761440596
INFO:root:current train perplexity8.591611862182617
INFO:root:current mean train loss 5450.164871684767
INFO:root:current train perplexity8.569276809692383
INFO:root:current mean train loss 5434.732637540332
INFO:root:current train perplexity8.518500328063965
INFO:root:current mean train loss 5425.190464172853
INFO:root:current train perplexity8.486727714538574
INFO:root:current mean train loss 5415.5610750021615
INFO:root:current train perplexity8.452407836914062
INFO:root:current mean train loss 5405.9383525639805
INFO:root:current train perplexity8.419962882995605
INFO:root:current mean train loss 5395.198125275088
INFO:root:current train perplexity8.384723663330078


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.11s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.77s/it]
INFO:root:eval mean loss: 4982.655709773936
INFO:root:eval perplexity: 7.499523162841797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/4

  2%|â–         | 4/200 [09:42<7:45:37, 142.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5332.237225932459
INFO:root:current train perplexity8.005485534667969
INFO:root:current mean train loss 5250.240103918178
INFO:root:current train perplexity7.914692401885986
INFO:root:current mean train loss 5255.101437787473
INFO:root:current train perplexity7.944589614868164
INFO:root:current mean train loss 5245.268910203456
INFO:root:current train perplexity7.900725841522217
INFO:root:current mean train loss 5238.65508877429
INFO:root:current train perplexity7.868220329284668
INFO:root:current mean train loss 5228.510348619939
INFO:root:current train perplexity7.839228630065918
INFO:root:current mean train loss 5221.409664873465
INFO:root:current train perplexity7.816295623779297
INFO:root:current mean train loss 5213.587086397059
INFO:root:current train perplexity7.800540447235107
INFO:root:current mean train loss 5201.012608937838
INFO:root:current train perplexity7.777957916259766
INFO:root:current mean train loss 5193.343469933204
INFO:root:current train perplexity7.74938440322876


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.59s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.17s/it]
INFO:root:eval mean loss: 4848.685553800975
INFO:root:eval perplexity: 7.104058265686035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/5

  2%|â–Ž         | 5/200 [12:13<7:53:32, 145.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5090.006723257212
INFO:root:current train perplexity7.366809368133545
INFO:root:current mean train loss 5086.522169373876
INFO:root:current train perplexity7.441652774810791
INFO:root:current mean train loss 5094.5484603817995
INFO:root:current train perplexity7.453046798706055
INFO:root:current mean train loss 5077.892941095132
INFO:root:current train perplexity7.39176607131958
INFO:root:current mean train loss 5075.922952777975
INFO:root:current train perplexity7.382564544677734
INFO:root:current mean train loss 5064.166970445849
INFO:root:current train perplexity7.360204219818115
INFO:root:current mean train loss 5056.738816907521
INFO:root:current train perplexity7.341037750244141
INFO:root:current mean train loss 5057.392651466297
INFO:root:current train perplexity7.338144302368164
INFO:root:current mean train loss 5053.968549216887
INFO:root:current train perplexity7.3229660987854
INFO:root:current mean train loss 5046.0107089074145
INFO:root:current train perplexity7.307527542114258


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.17s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.17s/it]
INFO:root:eval mean loss: 4740.7778805130765
INFO:root:eval perplexity: 6.800741672515869
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/6

  3%|â–Ž         | 6/200 [15:03<8:17:19, 153.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4907.706979305186
INFO:root:current train perplexity6.976860046386719
INFO:root:current mean train loss 4964.224184204932
INFO:root:current train perplexity7.061329364776611
INFO:root:current mean train loss 4945.47114989246
INFO:root:current train perplexity7.042705535888672
INFO:root:current mean train loss 4948.390363269993
INFO:root:current train perplexity7.042360305786133
INFO:root:current mean train loss 4945.324852314038
INFO:root:current train perplexity7.031126499176025
INFO:root:current mean train loss 4936.541669047075
INFO:root:current train perplexity7.009482383728027
INFO:root:current mean train loss 4936.368365563418
INFO:root:current train perplexity7.006945610046387
INFO:root:current mean train loss 4933.454608799782
INFO:root:current train perplexity6.995218276977539
INFO:root:current mean train loss 4930.607234517968
INFO:root:current train perplexity6.988492488861084
INFO:root:current mean train loss 4928.372480221258
INFO:root:current train perplexity6.977444648742676


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.61s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.04s/it]
INFO:root:eval mean loss: 4654.273373434729
INFO:root:eval perplexity: 6.566962242126465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/7

  4%|â–Ž         | 7/200 [17:11<7:48:20, 145.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4818.207199928977
INFO:root:current train perplexity6.781583786010742
INFO:root:current mean train loss 4870.168132560484
INFO:root:current train perplexity6.842835426330566
INFO:root:current mean train loss 4862.323293887867
INFO:root:current train perplexity6.796133995056152
INFO:root:current mean train loss 4860.658117847711
INFO:root:current train perplexity6.786317825317383
INFO:root:current mean train loss 4854.86641590831
INFO:root:current train perplexity6.769218921661377
INFO:root:current mean train loss 4848.918518616272
INFO:root:current train perplexity6.75140380859375
INFO:root:current mean train loss 4848.440944805582
INFO:root:current train perplexity6.751833438873291
INFO:root:current mean train loss 4849.569572640728
INFO:root:current train perplexity6.745303630828857
INFO:root:current mean train loss 4840.691689510234
INFO:root:current train perplexity6.728924751281738
INFO:root:current mean train loss 4833.3147174615515
INFO:root:current train perplexity6.72048807144165


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.26s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.48s/it]
INFO:root:eval mean loss: 4582.216791680518
INFO:root:eval perplexity: 6.378378868103027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/8

  4%|â–         | 8/200 [19:16<7:24:34, 138.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4771.3154219370035
INFO:root:current train perplexity6.511163234710693
INFO:root:current mean train loss 4759.690275414589
INFO:root:current train perplexity6.532268524169922
INFO:root:current mean train loss 4753.973565047231
INFO:root:current train perplexity6.531747817993164
INFO:root:current mean train loss 4764.3852505434315
INFO:root:current train perplexity6.530883312225342
INFO:root:current mean train loss 4769.159190760833
INFO:root:current train perplexity6.541687488555908
INFO:root:current mean train loss 4761.7346425573105
INFO:root:current train perplexity6.529966354370117
INFO:root:current mean train loss 4759.613307394773
INFO:root:current train perplexity6.528982639312744
INFO:root:current mean train loss 4758.131852256205
INFO:root:current train perplexity6.522717475891113
INFO:root:current mean train loss 4753.472838153154
INFO:root:current train perplexity6.514784336090088
INFO:root:current mean train loss 4749.780065803884
INFO:root:current train perplexity6.504981994628906


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.38s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.82s/it]
INFO:root:eval mean loss: 4521.950141636193
INFO:root:eval perplexity: 6.224815368652344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/9

  4%|â–         | 9/200 [21:22<7:09:29, 134.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4667.4998968419895
INFO:root:current train perplexity6.276638507843018
INFO:root:current mean train loss 4678.854540730081
INFO:root:current train perplexity6.32831335067749
INFO:root:current mean train loss 4700.882780068035
INFO:root:current train perplexity6.363919734954834
INFO:root:current mean train loss 4694.919223014235
INFO:root:current train perplexity6.351429462432861
INFO:root:current mean train loss 4688.509639148752
INFO:root:current train perplexity6.347888469696045
INFO:root:current mean train loss 4689.814336826839
INFO:root:current train perplexity6.345570087432861
INFO:root:current mean train loss 4691.496047177719
INFO:root:current train perplexity6.35125207901001
INFO:root:current mean train loss 4681.372972144536
INFO:root:current train perplexity6.336346626281738
INFO:root:current mean train loss 4683.618723539753
INFO:root:current train perplexity6.333121299743652
INFO:root:current mean train loss 4679.322179635202
INFO:root:current train perplexity6.325937747955322


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.53s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.72s/it]
INFO:root:eval mean loss: 4472.636178523936
INFO:root:eval perplexity: 6.10191535949707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/10

  5%|â–Œ         | 10/200 [23:28<6:58:42, 132.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4665.523131551622
INFO:root:current train perplexity6.211307048797607
INFO:root:current mean train loss 4625.068467124214
INFO:root:current train perplexity6.171465873718262
INFO:root:current mean train loss 4634.715077389953
INFO:root:current train perplexity6.184430122375488
INFO:root:current mean train loss 4628.456511404394
INFO:root:current train perplexity6.186063289642334
INFO:root:current mean train loss 4631.910780617986
INFO:root:current train perplexity6.184017181396484
INFO:root:current mean train loss 4625.316394021886
INFO:root:current train perplexity6.18346643447876
INFO:root:current mean train loss 4624.759529394675
INFO:root:current train perplexity6.180609226226807
INFO:root:current mean train loss 4622.69616495507
INFO:root:current train perplexity6.1770148277282715
INFO:root:current mean train loss 4617.2741235379335
INFO:root:current train perplexity6.173133373260498
INFO:root:current mean train loss 4616.616637373117
INFO:root:current train perplexity6.1733880043029785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.60s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.42s/it]
INFO:root:eval mean loss: 4427.60688338043
INFO:root:eval perplexity: 5.991814136505127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/11

  6%|â–Œ         | 11/200 [25:33<6:49:29, 130.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4564.825675175108
INFO:root:current train perplexity6.0371994972229
INFO:root:current mean train loss 4584.448364910595
INFO:root:current train perplexity6.066690921783447
INFO:root:current mean train loss 4570.724793118467
INFO:root:current train perplexity6.038309574127197
INFO:root:current mean train loss 4570.264587875485
INFO:root:current train perplexity6.049934387207031
INFO:root:current mean train loss 4567.2353515625
INFO:root:current train perplexity6.04787540435791
INFO:root:current mean train loss 4563.950628693303
INFO:root:current train perplexity6.042004585266113
INFO:root:current mean train loss 4563.62681701749
INFO:root:current train perplexity6.04390287399292
INFO:root:current mean train loss 4560.67858281796
INFO:root:current train perplexity6.037413120269775
INFO:root:current mean train loss 4561.845715510939
INFO:root:current train perplexity6.0394062995910645
INFO:root:current mean train loss 4561.737743497499
INFO:root:current train perplexity6.039911270141602


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.51s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.20s/it]
INFO:root:eval mean loss: 4387.4055729859265
INFO:root:eval perplexity: 5.895196437835693
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/12

  6%|â–Œ         | 12/200 [27:40<6:44:09, 128.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4524.5806640625
INFO:root:current train perplexity5.945611953735352
INFO:root:current mean train loss 4508.5515186798875
INFO:root:current train perplexity5.937952995300293
INFO:root:current mean train loss 4512.414938923464
INFO:root:current train perplexity5.946162700653076
INFO:root:current mean train loss 4506.415618819225
INFO:root:current train perplexity5.9322967529296875
INFO:root:current mean train loss 4511.430841619318
INFO:root:current train perplexity5.931212425231934
INFO:root:current mean train loss 4506.727838596376
INFO:root:current train perplexity5.929187774658203
INFO:root:current mean train loss 4504.984724525068
INFO:root:current train perplexity5.926952362060547
INFO:root:current mean train loss 4509.111526815546
INFO:root:current train perplexity5.921586990356445
INFO:root:current mean train loss 4511.045410701816
INFO:root:current train perplexity5.9246134757995605


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.21s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.54s/it]
INFO:root:eval mean loss: 4354.991610912566
INFO:root:eval perplexity: 5.818432807922363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/13

  6%|â–‹         | 13/200 [29:46<6:38:54, 127.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4723.699544270833
INFO:root:current train perplexity6.078607082366943
INFO:root:current mean train loss 4481.3145906022455
INFO:root:current train perplexity5.814065933227539
INFO:root:current mean train loss 4479.821332358374
INFO:root:current train perplexity5.815143585205078
INFO:root:current mean train loss 4480.327531971947
INFO:root:current train perplexity5.826519966125488
INFO:root:current mean train loss 4482.303589170091
INFO:root:current train perplexity5.83167839050293
INFO:root:current mean train loss 4478.535568813681
INFO:root:current train perplexity5.834136486053467
INFO:root:current mean train loss 4474.331117848259
INFO:root:current train perplexity5.8343586921691895
INFO:root:current mean train loss 4470.276950277272
INFO:root:current train perplexity5.826359748840332
INFO:root:current mean train loss 4468.676428237858
INFO:root:current train perplexity5.823415756225586
INFO:root:current mean train loss 4468.549656526855
INFO:root:current train perplexity5.821897983551025


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.80s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.09s/it]
INFO:root:eval mean loss: 4330.347029449246
INFO:root:eval perplexity: 5.760735988616943
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/14

  7%|â–‹         | 14/200 [31:51<6:33:48, 127.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4411.702015269886
INFO:root:current train perplexity5.641101360321045
INFO:root:current mean train loss 4420.029635592624
INFO:root:current train perplexity5.740028381347656
INFO:root:current mean train loss 4410.416972517402
INFO:root:current train perplexity5.734419822692871
INFO:root:current mean train loss 4414.881897953929
INFO:root:current train perplexity5.732203006744385
INFO:root:current mean train loss 4412.562997191491
INFO:root:current train perplexity5.727414131164551
INFO:root:current mean train loss 4416.077071516481
INFO:root:current train perplexity5.731929302215576
INFO:root:current mean train loss 4423.989780057666
INFO:root:current train perplexity5.738056659698486
INFO:root:current mean train loss 4425.157546932687
INFO:root:current train perplexity5.7347092628479
INFO:root:current mean train loss 4426.766305944629
INFO:root:current train perplexity5.737212181091309
INFO:root:current mean train loss 4428.653843700689
INFO:root:current train perplexity5.732588768005371


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.77s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.17s/it]
INFO:root:eval mean loss: 4305.494029809397
INFO:root:eval perplexity: 5.7031331062316895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/15

  8%|â–Š         | 15/200 [33:55<6:29:37, 126.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4449.7071340460525
INFO:root:current train perplexity5.727044105529785
INFO:root:current mean train loss 4384.42185243238
INFO:root:current train perplexity5.619462966918945
INFO:root:current mean train loss 4383.441524418522
INFO:root:current train perplexity5.636754512786865
INFO:root:current mean train loss 4383.124618865106
INFO:root:current train perplexity5.640156269073486
INFO:root:current mean train loss 4388.926872599381
INFO:root:current train perplexity5.647740364074707
INFO:root:current mean train loss 4385.814582016197
INFO:root:current train perplexity5.641621112823486
INFO:root:current mean train loss 4384.890666413192
INFO:root:current train perplexity5.641731262207031
INFO:root:current mean train loss 4387.426150347162
INFO:root:current train perplexity5.643930435180664
INFO:root:current mean train loss 4387.454285487733
INFO:root:current train perplexity5.6454057693481445
INFO:root:current mean train loss 4387.650231495257
INFO:root:current train perplexity5.643136501312256


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.73s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.05s/it]
INFO:root:eval mean loss: 4277.635333554965
INFO:root:eval perplexity: 5.639245510101318
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/16

  8%|â–Š         | 16/200 [35:59<6:25:01, 125.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4388.013292100694
INFO:root:current train perplexity5.654146194458008
INFO:root:current mean train loss 4334.7754790538875
INFO:root:current train perplexity5.577896595001221
INFO:root:current mean train loss 4347.654024771132
INFO:root:current train perplexity5.574573993682861
INFO:root:current mean train loss 4344.5140817624715
INFO:root:current train perplexity5.5641398429870605
INFO:root:current mean train loss 4349.477054211798
INFO:root:current train perplexity5.563884735107422
INFO:root:current mean train loss 4348.70942957261
INFO:root:current train perplexity5.557082653045654
INFO:root:current mean train loss 4349.287203215336
INFO:root:current train perplexity5.555641174316406
INFO:root:current mean train loss 4349.047413989963
INFO:root:current train perplexity5.562478542327881
INFO:root:current mean train loss 4349.083414319925
INFO:root:current train perplexity5.558937072753906
INFO:root:current mean train loss 4351.16353576726
INFO:root:current train perplexity5.563815116882324


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.71s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.14s/it]
INFO:root:eval mean loss: 4257.501698595413
INFO:root:eval perplexity: 5.593519687652588
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/17

  8%|â–Š         | 17/200 [38:04<6:22:13, 125.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4281.737555803571
INFO:root:current train perplexity5.464087963104248
INFO:root:current mean train loss 4315.3021864149305
INFO:root:current train perplexity5.481828212738037
INFO:root:current mean train loss 4311.94893409242
INFO:root:current train perplexity5.4893798828125
INFO:root:current mean train loss 4314.885691901819
INFO:root:current train perplexity5.4881744384765625
INFO:root:current mean train loss 4316.124852393139
INFO:root:current train perplexity5.494991302490234
INFO:root:current mean train loss 4327.546451975029
INFO:root:current train perplexity5.498531341552734
INFO:root:current mean train loss 4323.3005574864665
INFO:root:current train perplexity5.492732048034668
INFO:root:current mean train loss 4321.472995721726
INFO:root:current train perplexity5.488230228424072
INFO:root:current mean train loss 4322.2468206165795
INFO:root:current train perplexity5.495358943939209
INFO:root:current mean train loss 4321.080231137199
INFO:root:current train perplexity5.497401237487793


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.65s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.53s/it]
INFO:root:eval mean loss: 4237.919281222296
INFO:root:eval perplexity: 5.549401760101318
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/18

  9%|â–‰         | 18/200 [40:10<6:20:51, 125.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4282.011786882267
INFO:root:current train perplexity5.434202671051025
INFO:root:current mean train loss 4301.183023519449
INFO:root:current train perplexity5.446840286254883
INFO:root:current mean train loss 4294.927135577418
INFO:root:current train perplexity5.43815803527832
INFO:root:current mean train loss 4301.862828557762
INFO:root:current train perplexity5.4532880783081055
INFO:root:current mean train loss 4302.854112474429
INFO:root:current train perplexity5.449699401855469
INFO:root:current mean train loss 4303.0961311579185
INFO:root:current train perplexity5.4471821784973145
INFO:root:current mean train loss 4299.606960551735
INFO:root:current train perplexity5.4423723220825195
INFO:root:current mean train loss 4296.031127108218
INFO:root:current train perplexity5.437344074249268
INFO:root:current mean train loss 4292.318667229667
INFO:root:current train perplexity5.4345221519470215
INFO:root:current mean train loss 4291.64679971252
INFO:root:current train perplexity5.432283878326416


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.65s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.28s/it]
INFO:root:eval mean loss: 4219.734960244902
INFO:root:eval perplexity: 5.5087456703186035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/19

 10%|â–‰         | 19/200 [42:14<6:17:18, 125.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4234.636685240503
INFO:root:current train perplexity5.295708656311035
INFO:root:current mean train loss 4230.682761084954
INFO:root:current train perplexity5.302857875823975
INFO:root:current mean train loss 4260.8626208058395
INFO:root:current train perplexity5.333079814910889
INFO:root:current mean train loss 4253.624071430956
INFO:root:current train perplexity5.345912456512451
INFO:root:current mean train loss 4259.3029243824485
INFO:root:current train perplexity5.349643707275391
INFO:root:current mean train loss 4257.78126240642
INFO:root:current train perplexity5.355197429656982
INFO:root:current mean train loss 4265.058123844926
INFO:root:current train perplexity5.367531776428223
INFO:root:current mean train loss 4266.212148125416
INFO:root:current train perplexity5.3686747550964355
INFO:root:current mean train loss 4266.715913263807
INFO:root:current train perplexity5.373049736022949
INFO:root:current mean train loss 4268.790452124819
INFO:root:current train perplexity5.375721454620361


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.95s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 4202.323751246676
INFO:root:eval perplexity: 5.470096588134766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/20

 10%|â–ˆ         | 20/200 [44:17<6:13:35, 124.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4272.2694609043965
INFO:root:current train perplexity5.331491947174072
INFO:root:current mean train loss 4259.691231205778
INFO:root:current train perplexity5.319121360778809
INFO:root:current mean train loss 4251.276756492821
INFO:root:current train perplexity5.318726539611816
INFO:root:current mean train loss 4249.059201041304
INFO:root:current train perplexity5.327713489532471
INFO:root:current mean train loss 4244.079279216026
INFO:root:current train perplexity5.32084846496582
INFO:root:current mean train loss 4239.844857586091
INFO:root:current train perplexity5.315566539764404
INFO:root:current mean train loss 4241.213176258417
INFO:root:current train perplexity5.315368175506592
INFO:root:current mean train loss 4245.223883708004
INFO:root:current train perplexity5.3254008293151855
INFO:root:current mean train loss 4243.0612045483485
INFO:root:current train perplexity5.323922634124756
INFO:root:current mean train loss 4240.473367287294
INFO:root:current train perplexity5.320288181304932


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.48s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.40s/it]
INFO:root:eval mean loss: 4190.625777440714
INFO:root:eval perplexity: 5.444283485412598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/21

 10%|â–ˆ         | 21/200 [46:35<6:23:55, 128.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4187.756952541978
INFO:root:current train perplexity5.254456520080566
INFO:root:current mean train loss 4204.424680424308
INFO:root:current train perplexity5.281149387359619
INFO:root:current mean train loss 4207.1169845066715
INFO:root:current train perplexity5.265225410461426
INFO:root:current mean train loss 4203.816726227223
INFO:root:current train perplexity5.254310131072998
INFO:root:current mean train loss 4209.282964212226
INFO:root:current train perplexity5.261462688446045
INFO:root:current mean train loss 4209.148712642609
INFO:root:current train perplexity5.257018566131592
INFO:root:current mean train loss 4211.486407187032
INFO:root:current train perplexity5.259237289428711
INFO:root:current mean train loss 4212.816153515116
INFO:root:current train perplexity5.260159492492676
INFO:root:current mean train loss 4214.171729979906
INFO:root:current train perplexity5.260826110839844
INFO:root:current mean train loss 4213.264261145133
INFO:root:current train perplexity5.264397621154785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.77s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.93s/it]
INFO:root:eval mean loss: 4173.3270116494905
INFO:root:eval perplexity: 5.406332492828369
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/22

 11%|â–ˆ         | 22/200 [48:43<6:20:52, 128.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4200.591526692709
INFO:root:current train perplexity5.212970733642578
INFO:root:current mean train loss 4189.964807477679
INFO:root:current train perplexity5.217816352844238
INFO:root:current mean train loss 4181.127735262784
INFO:root:current train perplexity5.195291519165039
INFO:root:current mean train loss 4181.023734375
INFO:root:current train perplexity5.2018280029296875
INFO:root:current mean train loss 4181.683434930099
INFO:root:current train perplexity5.204404830932617
INFO:root:current mean train loss 4187.538519021739
INFO:root:current train perplexity5.2115044593811035
INFO:root:current mean train loss 4185.114245515047
INFO:root:current train perplexity5.212929725646973
INFO:root:current mean train loss 4189.723507434476
INFO:root:current train perplexity5.216163158416748
INFO:root:current mean train loss 4190.038884765625
INFO:root:current train perplexity5.216185569763184
INFO:root:current mean train loss 4191.377065554888
INFO:root:current train perplexity5.2163004875183105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.43s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.68s/it]
INFO:root:eval mean loss: 4168.035933690714
INFO:root:eval perplexity: 5.394777297973633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/23

 12%|â–ˆâ–        | 23/200 [50:47<6:14:55, 127.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4169.971997364458
INFO:root:current train perplexity5.130116939544678
INFO:root:current mean train loss 4163.233745303962
INFO:root:current train perplexity5.144093990325928
INFO:root:current mean train loss 4163.8574529317575
INFO:root:current train perplexity5.147397518157959
INFO:root:current mean train loss 4169.8695530505465
INFO:root:current train perplexity5.157593727111816
INFO:root:current mean train loss 4172.652544925919
INFO:root:current train perplexity5.1650567054748535
INFO:root:current mean train loss 4166.777326161825
INFO:root:current train perplexity5.160109519958496
INFO:root:current mean train loss 4161.12984420754
INFO:root:current train perplexity5.153065204620361
INFO:root:current mean train loss 4167.0782391193725
INFO:root:current train perplexity5.165512561798096
INFO:root:current mean train loss 4166.613922430191
INFO:root:current train perplexity5.169086933135986
INFO:root:current mean train loss 4167.428890752161
INFO:root:current train perplexity5.17036247253418


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.32s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.52s/it]
INFO:root:eval mean loss: 4151.973648395944
INFO:root:eval perplexity: 5.359850883483887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/24

 12%|â–ˆâ–        | 24/200 [53:22<6:37:04, 135.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4112.089146205357
INFO:root:current train perplexity5.0852742195129395
INFO:root:current mean train loss 4127.636601153468
INFO:root:current train perplexity5.109175205230713
INFO:root:current mean train loss 4125.156453870007
INFO:root:current train perplexity5.0984392166137695
INFO:root:current mean train loss 4136.32205894841
INFO:root:current train perplexity5.118828773498535
INFO:root:current mean train loss 4136.286686231066
INFO:root:current train perplexity5.121329307556152
INFO:root:current mean train loss 4142.041844711691
INFO:root:current train perplexity5.124858856201172
INFO:root:current mean train loss 4145.096183633321
INFO:root:current train perplexity5.129208087921143
INFO:root:current mean train loss 4148.951921581167
INFO:root:current train perplexity5.129850387573242
INFO:root:current mean train loss 4147.508450115302
INFO:root:current train perplexity5.13200044631958
INFO:root:current mean train loss 4146.493431360763
INFO:root:current train perplexity5.1274800300598145


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.16s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.21s/it]
INFO:root:eval mean loss: 4137.868129432624
INFO:root:eval perplexity: 5.329366207122803
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/25

 12%|â–ˆâ–Ž        | 25/200 [55:28<6:26:52, 132.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4095.2622538865216
INFO:root:current train perplexity5.0925188064575195
INFO:root:current mean train loss 4109.089384912845
INFO:root:current train perplexity5.070501804351807
INFO:root:current mean train loss 4120.642778989862
INFO:root:current train perplexity5.0771379470825195
INFO:root:current mean train loss 4127.058118318257
INFO:root:current train perplexity5.087203025817871
INFO:root:current mean train loss 4126.1863805736475
INFO:root:current train perplexity5.083437442779541
INFO:root:current mean train loss 4124.638730566569
INFO:root:current train perplexity5.078226089477539
INFO:root:current mean train loss 4125.336661539364
INFO:root:current train perplexity5.080399036407471
INFO:root:current mean train loss 4128.903297090113
INFO:root:current train perplexity5.084243297576904
INFO:root:current mean train loss 4128.5111112499135
INFO:root:current train perplexity5.088113307952881


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.22s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.23s/it]
INFO:root:eval mean loss: 4135.426499819925
INFO:root:eval perplexity: 5.324108600616455
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/26

 13%|â–ˆâ–Ž        | 26/200 [58:24<7:02:14, 145.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4149.68620954241
INFO:root:current train perplexity5.120150089263916
INFO:root:current mean train loss 4093.5676155446845
INFO:root:current train perplexity5.047454833984375
INFO:root:current mean train loss 4103.954698350694
INFO:root:current train perplexity5.057609558105469
INFO:root:current mean train loss 4106.380398927372
INFO:root:current train perplexity5.0547051429748535
INFO:root:current mean train loss 4113.847682043727
INFO:root:current train perplexity5.066792011260986
INFO:root:current mean train loss 4104.477292514177
INFO:root:current train perplexity5.053780555725098
INFO:root:current mean train loss 4107.350951142916
INFO:root:current train perplexity5.047585964202881
INFO:root:current mean train loss 4109.0150127491825
INFO:root:current train perplexity5.052038192749023
INFO:root:current mean train loss 4107.075128453667
INFO:root:current train perplexity5.049343585968018
INFO:root:current mean train loss 4104.711922137713
INFO:root:current train perplexity5.045810222625732


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.20s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.62s/it]
INFO:root:eval mean loss: 4118.680567098848
INFO:root:eval perplexity: 5.288176536560059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/27

 14%|â–ˆâ–Ž        | 27/200 [1:01:18<7:24:29, 154.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4110.907307942708
INFO:root:current train perplexity4.969907760620117
INFO:root:current mean train loss 4061.0062648607336
INFO:root:current train perplexity4.981143951416016
INFO:root:current mean train loss 4060.5958564226016
INFO:root:current train perplexity4.98150110244751
INFO:root:current mean train loss 4074.7595245845732
INFO:root:current train perplexity4.99712610244751
INFO:root:current mean train loss 4085.645551346009
INFO:root:current train perplexity5.011618614196777
INFO:root:current mean train loss 4080.0020123824333
INFO:root:current train perplexity5.0005645751953125
INFO:root:current mean train loss 4082.4741123602644
INFO:root:current train perplexity5.000991344451904
INFO:root:current mean train loss 4083.9755350606424
INFO:root:current train perplexity5.000996112823486
INFO:root:current mean train loss 4087.4616741157015
INFO:root:current train perplexity5.004855155944824
INFO:root:current mean train loss 4084.280160038849
INFO:root:current train perplexity5.003350257873535


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.42s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.51s/it]
INFO:root:eval mean loss: 4111.225419714096
INFO:root:eval perplexity: 5.2722601890563965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/28

 14%|â–ˆâ–        | 28/200 [1:03:27<7:00:33, 146.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4098.459716796875
INFO:root:current train perplexity4.986149311065674
INFO:root:current mean train loss 4068.894221608232
INFO:root:current train perplexity4.957857131958008
INFO:root:current mean train loss 4077.384183190863
INFO:root:current train perplexity4.982264518737793
INFO:root:current mean train loss 4067.509538113148
INFO:root:current train perplexity4.972434997558594
INFO:root:current mean train loss 4079.537166514295
INFO:root:current train perplexity4.982179164886475
INFO:root:current mean train loss 4079.610129361855
INFO:root:current train perplexity4.980019569396973
INFO:root:current mean train loss 4071.954682719076
INFO:root:current train perplexity4.974728107452393
INFO:root:current mean train loss 4069.0756805546553
INFO:root:current train perplexity4.973759651184082
INFO:root:current mean train loss 4072.3990355407045
INFO:root:current train perplexity4.976041793823242
INFO:root:current mean train loss 4070.390060540527
INFO:root:current train perplexity4.975336074829102


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.52s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.76s/it]
INFO:root:eval mean loss: 4107.0925327598625
INFO:root:eval perplexity: 5.263455390930176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/29

 14%|â–ˆâ–        | 29/200 [1:05:45<6:50:32, 144.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4065.2003449470767
INFO:root:current train perplexity4.916538715362549
INFO:root:current mean train loss 4051.710678450024
INFO:root:current train perplexity4.922472953796387
INFO:root:current mean train loss 4066.456556708266
INFO:root:current train perplexity4.935522556304932
INFO:root:current mean train loss 4070.141864880334
INFO:root:current train perplexity4.938572883605957
INFO:root:current mean train loss 4066.9110654047636
INFO:root:current train perplexity4.933667182922363
INFO:root:current mean train loss 4062.433506392714
INFO:root:current train perplexity4.93434476852417
INFO:root:current mean train loss 4057.2158810574733
INFO:root:current train perplexity4.931056022644043
INFO:root:current mean train loss 4058.176316956652
INFO:root:current train perplexity4.936375617980957
INFO:root:current mean train loss 4055.183357835533
INFO:root:current train perplexity4.933373928070068
INFO:root:current mean train loss 4050.097782647187
INFO:root:current train perplexity4.935510158538818


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.04s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.28s/it]
INFO:root:eval mean loss: 4094.172820395612
INFO:root:eval perplexity: 5.236028671264648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/30

 15%|â–ˆâ–Œ        | 30/200 [1:08:22<6:59:05, 147.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4030.521208934295
INFO:root:current train perplexity4.924020767211914
INFO:root:current mean train loss 4022.3664761550135
INFO:root:current train perplexity4.902858734130859
INFO:root:current mean train loss 4027.4179360617154
INFO:root:current train perplexity4.889284133911133
INFO:root:current mean train loss 4025.0663558374818
INFO:root:current train perplexity4.889076232910156
INFO:root:current mean train loss 4032.930458850904
INFO:root:current train perplexity4.894948482513428
INFO:root:current mean train loss 4030.88818359375
INFO:root:current train perplexity4.89691686630249
INFO:root:current mean train loss 4030.587286577538
INFO:root:current train perplexity4.899103164672852
INFO:root:current mean train loss 4035.592946549391
INFO:root:current train perplexity4.903696537017822
INFO:root:current mean train loss 4035.3086839569055
INFO:root:current train perplexity4.9067277908325195
INFO:root:current mean train loss 4034.5118214502627
INFO:root:current train perplexity4.906599521636963


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.74s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.28s/it]
INFO:root:eval mean loss: 4091.7435969359485
INFO:root:eval perplexity: 5.2308878898620605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/31

 16%|â–ˆâ–Œ        | 31/200 [1:10:43<6:50:37, 145.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4000.7996800199467
INFO:root:current train perplexity4.838526725769043
INFO:root:current mean train loss 4001.3508184523807
INFO:root:current train perplexity4.838505744934082
INFO:root:current mean train loss 3994.526753661121
INFO:root:current train perplexity4.827152729034424
INFO:root:current mean train loss 4006.569965637383
INFO:root:current train perplexity4.842906951904297
INFO:root:current mean train loss 4011.6848805404084
INFO:root:current train perplexity4.852614402770996
INFO:root:current mean train loss 4013.3841443384367
INFO:root:current train perplexity4.8623433113098145
INFO:root:current mean train loss 4018.1689513499805
INFO:root:current train perplexity4.869577884674072
INFO:root:current mean train loss 4013.381173456848
INFO:root:current train perplexity4.869277000427246
INFO:root:current mean train loss 4015.734835321816
INFO:root:current train perplexity4.872910976409912
INFO:root:current mean train loss 4015.933614116536
INFO:root:current train perplexity4.872335433959961


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.24s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.75s/it]
INFO:root:eval mean loss: 4080.2669513242463
INFO:root:eval perplexity: 5.206669330596924
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/32

 16%|â–ˆâ–Œ        | 32/200 [1:12:59<6:39:40, 142.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3991.962451171875
INFO:root:current train perplexity4.76898717880249
INFO:root:current mean train loss 4011.1755040322582
INFO:root:current train perplexity4.826691150665283
INFO:root:current mean train loss 3990.7507601868874
INFO:root:current train perplexity4.816114902496338
INFO:root:current mean train loss 3985.5794406084947
INFO:root:current train perplexity4.825141906738281
INFO:root:current mean train loss 3994.340849824004
INFO:root:current train perplexity4.835056304931641
INFO:root:current mean train loss 3996.3652409733954
INFO:root:current train perplexity4.837327003479004
INFO:root:current mean train loss 4001.3443586742605
INFO:root:current train perplexity4.840784549713135
INFO:root:current mean train loss 4002.4127130975785
INFO:root:current train perplexity4.840032577514648
INFO:root:current mean train loss 4003.051093064693
INFO:root:current train perplexity4.840559959411621
INFO:root:current mean train loss 4002.2875380910505
INFO:root:current train perplexity4.844022750854492


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.08s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.94s/it]
INFO:root:eval mean loss: 4074.9153870927526
INFO:root:eval perplexity: 5.195413112640381
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/33

 16%|â–ˆâ–‹        | 33/200 [1:15:04<6:22:26, 137.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3932.6598462301586
INFO:root:current train perplexity4.762000560760498
INFO:root:current mean train loss 3961.034026912385
INFO:root:current train perplexity4.801848411560059
INFO:root:current mean train loss 3960.7262143907437
INFO:root:current train perplexity4.80229377746582
INFO:root:current mean train loss 3969.5370152160813
INFO:root:current train perplexity4.801576614379883
INFO:root:current mean train loss 3979.6501907777065
INFO:root:current train perplexity4.8053083419799805
INFO:root:current mean train loss 3975.773425358015
INFO:root:current train perplexity4.798271656036377
INFO:root:current mean train loss 3978.9332336149605
INFO:root:current train perplexity4.805528163909912
INFO:root:current mean train loss 3977.5815151309594
INFO:root:current train perplexity4.80259895324707
INFO:root:current mean train loss 3979.2013939496123
INFO:root:current train perplexity4.80346155166626
INFO:root:current mean train loss 3986.4185373973746
INFO:root:current train perplexity4.813981056213379


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.31s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.03s/it]
INFO:root:eval mean loss: 4067.6175199468084
INFO:root:eval perplexity: 5.180103778839111
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/34

 17%|â–ˆâ–‹        | 34/200 [1:18:16<7:05:37, 153.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3999.7318992077467
INFO:root:current train perplexity4.7883124351501465
INFO:root:current mean train loss 3966.6299884639984
INFO:root:current train perplexity4.770286560058594
INFO:root:current mean train loss 3962.2589620329795
INFO:root:current train perplexity4.772557735443115
INFO:root:current mean train loss 3963.7043575482226
INFO:root:current train perplexity4.766436576843262
INFO:root:current mean train loss 3963.6060145675756
INFO:root:current train perplexity4.767176151275635
INFO:root:current mean train loss 3967.1544550747044
INFO:root:current train perplexity4.775948524475098
INFO:root:current mean train loss 3969.350295224595
INFO:root:current train perplexity4.779522895812988
INFO:root:current mean train loss 3968.6001119057028
INFO:root:current train perplexity4.779712677001953
INFO:root:current mean train loss 3971.7407310652266
INFO:root:current train perplexity4.782780647277832
INFO:root:current mean train loss 3970.4072715688562
INFO:root:current train perplexity4.784183979034424


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.83s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.87s/it]
INFO:root:eval mean loss: 4063.891828388187
INFO:root:eval perplexity: 5.172305583953857
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/35

 18%|â–ˆâ–Š        | 35/200 [1:20:24<6:41:34, 146.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3977.1875154519385
INFO:root:current train perplexity4.773499488830566
INFO:root:current mean train loss 3958.7257755215605
INFO:root:current train perplexity4.745972156524658
INFO:root:current mean train loss 3963.144824393761
INFO:root:current train perplexity4.759451866149902
INFO:root:current mean train loss 3960.3426007998023
INFO:root:current train perplexity4.755091190338135
INFO:root:current mean train loss 3958.3214144457856
INFO:root:current train perplexity4.757347583770752
INFO:root:current mean train loss 3961.136208542476
INFO:root:current train perplexity4.755661964416504
INFO:root:current mean train loss 3960.974055294436
INFO:root:current train perplexity4.758021831512451
INFO:root:current mean train loss 3959.0156090164674
INFO:root:current train perplexity4.758452892303467
INFO:root:current mean train loss 3957.3025568939315
INFO:root:current train perplexity4.757246017456055
INFO:root:current mean train loss 3957.3294546811157
INFO:root:current train perplexity4.759649276733398


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.77s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.65s/it]
INFO:root:eval mean loss: 4061.990488904588
INFO:root:eval perplexity: 5.168330669403076
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/36

 18%|â–ˆâ–Š        | 36/200 [1:23:39<7:19:15, 160.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3907.7923120959053
INFO:root:current train perplexity4.705506324768066
INFO:root:current mean train loss 3914.572533265792
INFO:root:current train perplexity4.696575164794922
INFO:root:current mean train loss 3927.7579562622495
INFO:root:current train perplexity4.708547592163086
INFO:root:current mean train loss 3934.2873408985383
INFO:root:current train perplexity4.7199530601501465
INFO:root:current mean train loss 3930.5462919701295
INFO:root:current train perplexity4.723052501678467
INFO:root:current mean train loss 3931.5216794379526
INFO:root:current train perplexity4.725295543670654
INFO:root:current mean train loss 3936.7333312721753
INFO:root:current train perplexity4.72809362411499
INFO:root:current mean train loss 3939.9394081435635
INFO:root:current train perplexity4.730929851531982
INFO:root:current mean train loss 3941.457801655422
INFO:root:current train perplexity4.729714393615723
INFO:root:current mean train loss 3943.512787081671
INFO:root:current train perplexity4.733944416046143


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.65s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.08s/it]
INFO:root:eval mean loss: 4054.7040219137853
INFO:root:eval perplexity: 5.153124809265137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/37

 18%|â–ˆâ–Š        | 37/200 [1:26:58<7:47:57, 172.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3901.1433773643093
INFO:root:current train perplexity4.659670352935791
INFO:root:current mean train loss 3904.9672162960737
INFO:root:current train perplexity4.6727447509765625
INFO:root:current mean train loss 3914.8024703720866
INFO:root:current train perplexity4.690217018127441
INFO:root:current mean train loss 3908.005134988133
INFO:root:current train perplexity4.691403865814209
INFO:root:current mean train loss 3914.0266261245265
INFO:root:current train perplexity4.695659637451172
INFO:root:current mean train loss 3918.187248063288
INFO:root:current train perplexity4.698800086975098
INFO:root:current mean train loss 3919.6639890821716
INFO:root:current train perplexity4.7002644538879395
INFO:root:current mean train loss 3926.448007566824
INFO:root:current train perplexity4.70746374130249
INFO:root:current mean train loss 3932.388321076292
INFO:root:current train perplexity4.712290287017822


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.47s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.45s/it]
INFO:root:eval mean loss: 4054.438409034242
INFO:root:eval perplexity: 5.152571201324463
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/38

 19%|â–ˆâ–‰        | 38/200 [1:29:13<7:14:58, 161.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3865.5218098958335
INFO:root:current train perplexity4.551672458648682
INFO:root:current mean train loss 3916.2705030719053
INFO:root:current train perplexity4.667619228363037
INFO:root:current mean train loss 3909.133654364224
INFO:root:current train perplexity4.664923191070557
INFO:root:current mean train loss 3911.9850534369843
INFO:root:current train perplexity4.665624618530273
INFO:root:current mean train loss 3907.534215430172
INFO:root:current train perplexity4.66227388381958
INFO:root:current mean train loss 3909.4635211193777
INFO:root:current train perplexity4.661314010620117
INFO:root:current mean train loss 3914.2887171402103
INFO:root:current train perplexity4.6694841384887695
INFO:root:current mean train loss 3912.4267619799075
INFO:root:current train perplexity4.674332618713379
INFO:root:current mean train loss 3914.525847894614
INFO:root:current train perplexity4.675613880157471
INFO:root:current mean train loss 3916.6055420192242
INFO:root:current train perplexity4.678822040557861


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.60s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.54s/it]
INFO:root:eval mean loss: 4047.9634498974956
INFO:root:eval perplexity: 5.139097690582275
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/39

 20%|â–ˆâ–‰        | 39/200 [1:31:22<6:46:19, 151.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3841.8284801136365
INFO:root:current train perplexity4.569404602050781
INFO:root:current mean train loss 3880.719662778012
INFO:root:current train perplexity4.621326923370361
INFO:root:current mean train loss 3893.270673272734
INFO:root:current train perplexity4.633621692657471
INFO:root:current mean train loss 3893.238841752914
INFO:root:current train perplexity4.64767599105835
INFO:root:current mean train loss 3896.130976990192
INFO:root:current train perplexity4.65488338470459
INFO:root:current mean train loss 3900.519742902244
INFO:root:current train perplexity4.656731605529785
INFO:root:current mean train loss 3898.555511025087
INFO:root:current train perplexity4.652064800262451
INFO:root:current mean train loss 3901.230429261713
INFO:root:current train perplexity4.657851696014404
INFO:root:current mean train loss 3902.22416444301
INFO:root:current train perplexity4.657647132873535
INFO:root:current mean train loss 3903.270179254425
INFO:root:current train perplexity4.659163951873779


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.89s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.60s/it]
INFO:root:eval mean loss: 4041.147429770612
INFO:root:eval perplexity: 5.124953269958496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/40

 20%|â–ˆâ–ˆ        | 40/200 [1:33:40<6:32:59, 147.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3901.2768297697367
INFO:root:current train perplexity4.655304908752441
INFO:root:current mean train loss 3888.5819307215074
INFO:root:current train perplexity4.640713691711426
INFO:root:current mean train loss 3884.3999569688212
INFO:root:current train perplexity4.633861064910889
INFO:root:current mean train loss 3893.016260224824
INFO:root:current train perplexity4.635129451751709
INFO:root:current mean train loss 3892.953413423889
INFO:root:current train perplexity4.636462688446045
INFO:root:current mean train loss 3896.001025955112
INFO:root:current train perplexity4.639135360717773
INFO:root:current mean train loss 3894.558963313434
INFO:root:current train perplexity4.63751220703125
INFO:root:current mean train loss 3899.2265193764124
INFO:root:current train perplexity4.644744873046875
INFO:root:current mean train loss 3895.2845061026214
INFO:root:current train perplexity4.640060901641846
INFO:root:current mean train loss 3891.911738780689
INFO:root:current train perplexity4.638854026794434


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.57s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.26s/it]
INFO:root:eval mean loss: 4037.6801221049423
INFO:root:eval perplexity: 5.117772579193115
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/41

 20%|â–ˆâ–ˆ        | 41/200 [1:35:51<6:18:02, 142.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3831.9573838975693
INFO:root:current train perplexity4.588903427124023
INFO:root:current mean train loss 3856.2581585260828
INFO:root:current train perplexity4.582204341888428
INFO:root:current mean train loss 3861.223921049009
INFO:root:current train perplexity4.593506336212158
INFO:root:current mean train loss 3864.9136249880544
INFO:root:current train perplexity4.592278003692627
INFO:root:current mean train loss 3866.4176863015955
INFO:root:current train perplexity4.599127769470215
INFO:root:current mean train loss 3867.484505640714
INFO:root:current train perplexity4.596004486083984
INFO:root:current mean train loss 3869.896082925264
INFO:root:current train perplexity4.595602989196777
INFO:root:current mean train loss 3874.817965458971
INFO:root:current train perplexity4.603740692138672
INFO:root:current mean train loss 3879.8706326282877
INFO:root:current train perplexity4.611462593078613
INFO:root:current mean train loss 3879.8126682911106
INFO:root:current train perplexity4.612761497497559


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.22s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.26s/it]
INFO:root:eval mean loss: 4032.8308140098625
INFO:root:eval perplexity: 5.107746601104736
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/42

 21%|â–ˆâ–ˆ        | 42/200 [1:37:57<6:02:02, 137.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3811.3840680803573
INFO:root:current train perplexity4.567569255828857
INFO:root:current mean train loss 3832.7179976851853
INFO:root:current train perplexity4.574796199798584
INFO:root:current mean train loss 3848.999646775266
INFO:root:current train perplexity4.575422763824463
INFO:root:current mean train loss 3859.358744607043
INFO:root:current train perplexity4.585665702819824
INFO:root:current mean train loss 3862.2286716505027
INFO:root:current train perplexity4.585555076599121
INFO:root:current mean train loss 3864.5883830132884
INFO:root:current train perplexity4.587728500366211
INFO:root:current mean train loss 3865.087911386565
INFO:root:current train perplexity4.59160852432251
INFO:root:current mean train loss 3868.660802641369
INFO:root:current train perplexity4.59216833114624
INFO:root:current mean train loss 3865.7344305529564
INFO:root:current train perplexity4.589641571044922
INFO:root:current mean train loss 3865.9648722113134
INFO:root:current train perplexity4.5905961990356445


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.17s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.72s/it]
INFO:root:eval mean loss: 4030.809236134198
INFO:root:eval perplexity: 5.103573322296143
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/43

 22%|â–ˆâ–ˆâ–       | 43/200 [1:41:08<6:41:47, 153.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3891.3027570857557
INFO:root:current train perplexity4.573229789733887
INFO:root:current mean train loss 3869.1162058156688
INFO:root:current train perplexity4.5776047706604
INFO:root:current mean train loss 3859.3070445119597
INFO:root:current train perplexity4.557987213134766
INFO:root:current mean train loss 3856.6212510534347
INFO:root:current train perplexity4.559283256530762
INFO:root:current mean train loss 3856.63085496614
INFO:root:current train perplexity4.5574469566345215
INFO:root:current mean train loss 3856.844434313133
INFO:root:current train perplexity4.561705589294434
INFO:root:current mean train loss 3856.299925049208
INFO:root:current train perplexity4.563173294067383
INFO:root:current mean train loss 3853.7209590947805
INFO:root:current train perplexity4.564711570739746
INFO:root:current mean train loss 3855.034454526709
INFO:root:current train perplexity4.569504261016846
INFO:root:current mean train loss 3854.8176287654096
INFO:root:current train perplexity4.570553779602051


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.69s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.13s/it]
INFO:root:eval mean loss: 4030.8187489611037
INFO:root:eval perplexity: 5.103593826293945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/44

 22%|â–ˆâ–ˆâ–       | 44/200 [1:43:20<6:22:33, 147.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3795.8262101715686
INFO:root:current train perplexity4.507863998413086
INFO:root:current mean train loss 3832.17185074762
INFO:root:current train perplexity4.525200843811035
INFO:root:current mean train loss 3835.9158950136953
INFO:root:current train perplexity4.537316799163818
INFO:root:current mean train loss 3834.0151297631764
INFO:root:current train perplexity4.534947395324707
INFO:root:current mean train loss 3841.5733731897867
INFO:root:current train perplexity4.537308692932129
INFO:root:current mean train loss 3844.6931307424
INFO:root:current train perplexity4.5460710525512695
INFO:root:current mean train loss 3840.5803511424733
INFO:root:current train perplexity4.544843673706055
INFO:root:current mean train loss 3843.6417387493757
INFO:root:current train perplexity4.54936408996582
INFO:root:current mean train loss 3841.7014119992104
INFO:root:current train perplexity4.549465656280518
INFO:root:current mean train loss 3844.8099826046596
INFO:root:current train perplexity4.552083492279053


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.75s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 4027.8612623282356
INFO:root:eval perplexity: 5.0974931716918945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/45

 22%|â–ˆâ–ˆâ–Ž       | 45/200 [1:45:25<6:02:57, 140.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3820.7373667571505
INFO:root:current train perplexity4.489727973937988
INFO:root:current mean train loss 3833.3632505404876
INFO:root:current train perplexity4.527806758880615
INFO:root:current mean train loss 3831.0306740543556
INFO:root:current train perplexity4.531350135803223
INFO:root:current mean train loss 3828.422320437631
INFO:root:current train perplexity4.527985095977783
INFO:root:current mean train loss 3828.9217670249523
INFO:root:current train perplexity4.530367851257324
INFO:root:current mean train loss 3830.4375781774093
INFO:root:current train perplexity4.5311455726623535
INFO:root:current mean train loss 3835.1638683730084
INFO:root:current train perplexity4.533271312713623
INFO:root:current mean train loss 3837.6795643038745
INFO:root:current train perplexity4.5310750007629395
INFO:root:current mean train loss 3834.594782552841
INFO:root:current train perplexity4.531710147857666
INFO:root:current mean train loss 3833.643067169985
INFO:root:current train perplexity4.531562805175781


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:51<00:00, 111.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:51<00:00, 111.79s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.76s/it]
INFO:root:eval mean loss: 4027.7776588818706
INFO:root:eval perplexity: 5.097319602966309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/46

 23%|â–ˆâ–ˆâ–Ž       | 46/200 [1:47:54<6:07:11, 143.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3840.751082235308
INFO:root:current train perplexity4.5194621086120605
INFO:root:current mean train loss 3827.4999795331214
INFO:root:current train perplexity4.49481725692749
INFO:root:current mean train loss 3819.081890434808
INFO:root:current train perplexity4.496675491333008
INFO:root:current mean train loss 3825.7581304815226
INFO:root:current train perplexity4.507198333740234
INFO:root:current mean train loss 3829.58484017415
INFO:root:current train perplexity4.509118556976318
INFO:root:current mean train loss 3827.632400431961
INFO:root:current train perplexity4.509450435638428
INFO:root:current mean train loss 3829.096195432557
INFO:root:current train perplexity4.516441822052002
INFO:root:current mean train loss 3825.4283592094807
INFO:root:current train perplexity4.513790130615234
INFO:root:current mean train loss 3824.837214521608
INFO:root:current train perplexity4.514111042022705
INFO:root:current mean train loss 3823.365332334217
INFO:root:current train perplexity4.513113021850586


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:50<00:00, 110.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:50<00:00, 110.92s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.59s/it]
INFO:root:eval mean loss: 4025.379233502327
INFO:root:eval perplexity: 5.092380046844482
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/47

 24%|â–ˆâ–ˆâ–Ž       | 47/200 [1:51:03<6:40:21, 157.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3809.950390625
INFO:root:current train perplexity4.442516803741455
INFO:root:current mean train loss 3800.1343568638395
INFO:root:current train perplexity4.475164413452148
INFO:root:current mean train loss 3801.3562189275567
INFO:root:current train perplexity4.47561502456665
INFO:root:current mean train loss 3808.8954361979168
INFO:root:current train perplexity4.48643159866333
INFO:root:current mean train loss 3808.439929584704
INFO:root:current train perplexity4.487987041473389
INFO:root:current mean train loss 3810.5856929347824
INFO:root:current train perplexity4.4899516105651855
INFO:root:current mean train loss 3809.375621383102
INFO:root:current train perplexity4.49064302444458
INFO:root:current mean train loss 3808.773482232863
INFO:root:current train perplexity4.493147850036621
INFO:root:current mean train loss 3810.33017578125
INFO:root:current train perplexity4.495364665985107
INFO:root:current mean train loss 3811.5423587740383
INFO:root:current train perplexity4.494412899017334


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:52<00:00, 112.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:52<00:00, 112.35s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.59s/it]
INFO:root:eval mean loss: 4022.8574461159133
INFO:root:eval perplexity: 5.087189197540283
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/48

 24%|â–ˆâ–ˆâ–       | 48/200 [1:53:05<6:11:05, 146.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3801.1273884600905
INFO:root:current train perplexity4.448389530181885
INFO:root:current mean train loss 3807.4465065210893
INFO:root:current train perplexity4.45435094833374
INFO:root:current mean train loss 3795.384750959309
INFO:root:current train perplexity4.450841426849365
INFO:root:current mean train loss 3792.1613310572375
INFO:root:current train perplexity4.45960807800293
INFO:root:current mean train loss 3792.3907291262294
INFO:root:current train perplexity4.4634270668029785
INFO:root:current mean train loss 3796.337666585147
INFO:root:current train perplexity4.457976341247559
INFO:root:current mean train loss 3797.894199890762
INFO:root:current train perplexity4.462287902832031
INFO:root:current mean train loss 3797.3650915698836
INFO:root:current train perplexity4.466485977172852
INFO:root:current mean train loss 3797.930844610437
INFO:root:current train perplexity4.4682416915893555
INFO:root:current mean train loss 3801.0079108516657
INFO:root:current train perplexity4.475788116455078


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.42s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.91s/it]
INFO:root:eval mean loss: 4016.589651554189
INFO:root:eval perplexity: 5.07431173324585
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/49

 24%|â–ˆâ–ˆâ–       | 49/200 [1:55:14<5:54:53, 141.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3784.8459982400414
INFO:root:current train perplexity4.398426532745361
INFO:root:current mean train loss 3784.968358863711
INFO:root:current train perplexity4.423832416534424
INFO:root:current mean train loss 3777.0755107656787
INFO:root:current train perplexity4.433008193969727
INFO:root:current mean train loss 3781.9890923463477
INFO:root:current train perplexity4.4404616355896
INFO:root:current mean train loss 3782.5064296994337
INFO:root:current train perplexity4.443178653717041
INFO:root:current mean train loss 3785.2987483971815
INFO:root:current train perplexity4.4465556144714355
INFO:root:current mean train loss 3783.519324207444
INFO:root:current train perplexity4.44503927230835
INFO:root:current mean train loss 3786.912394874467
INFO:root:current train perplexity4.449174880981445
INFO:root:current mean train loss 3786.488516074372
INFO:root:current train perplexity4.450901985168457
INFO:root:current mean train loss 3791.1231831108885
INFO:root:current train perplexity4.457320213317871


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.02s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.21s/it]
INFO:root:eval mean loss: 4017.726967669548
INFO:root:eval perplexity: 5.076646327972412
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/50

 25%|â–ˆâ–ˆâ–Œ       | 50/200 [1:57:22<5:42:55, 137.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3765.034002130682
INFO:root:current train perplexity4.3903985023498535
INFO:root:current mean train loss 3770.820706314777
INFO:root:current train perplexity4.407718658447266
INFO:root:current mean train loss 3775.044327445652
INFO:root:current train perplexity4.418808460235596
INFO:root:current mean train loss 3777.6075069264957
INFO:root:current train perplexity4.422353744506836
INFO:root:current mean train loss 3781.252381716558
INFO:root:current train perplexity4.433309078216553
INFO:root:current mean train loss 3779.7304455179205
INFO:root:current train perplexity4.437467098236084
INFO:root:current mean train loss 3775.6958825107295
INFO:root:current train perplexity4.437934398651123
INFO:root:current mean train loss 3775.879654255319
INFO:root:current train perplexity4.438257217407227
INFO:root:current mean train loss 3777.5925181625416
INFO:root:current train perplexity4.439594268798828


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.83s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.53s/it]
INFO:root:eval mean loss: 4022.1390787760415
INFO:root:eval perplexity: 5.08571195602417
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/51

 26%|â–ˆâ–ˆâ–Œ       | 51/200 [1:59:29<5:33:15, 134.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3717.6125139508927
INFO:root:current train perplexity4.391578674316406
INFO:root:current mean train loss 3768.045873338931
INFO:root:current train perplexity4.403921604156494
INFO:root:current mean train loss 3767.5704257246375
INFO:root:current train perplexity4.413149356842041
INFO:root:current mean train loss 3777.6931701063722
INFO:root:current train perplexity4.415122032165527
INFO:root:current mean train loss 3778.0042793592597
INFO:root:current train perplexity4.420076370239258
INFO:root:current mean train loss 3774.8043586083886
INFO:root:current train perplexity4.418492317199707
INFO:root:current mean train loss 3771.172251467257
INFO:root:current train perplexity4.418334484100342
INFO:root:current mean train loss 3768.1446835357365
INFO:root:current train perplexity4.420279502868652
INFO:root:current mean train loss 3771.480459069083
INFO:root:current train perplexity4.424188137054443
INFO:root:current mean train loss 3771.770791252498
INFO:root:current train perplexity4.422999382019043


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.04s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.39s/it]
INFO:root:eval mean loss: 4015.7729474872563
INFO:root:eval perplexity: 5.072636127471924
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/52

 26%|â–ˆâ–ˆâ–Œ       | 52/200 [2:01:35<5:24:30, 131.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3779.643343098958
INFO:root:current train perplexity4.483901500701904
INFO:root:current mean train loss 3744.2163850203806
INFO:root:current train perplexity4.386380672454834
INFO:root:current mean train loss 3746.244313226744
INFO:root:current train perplexity4.388768196105957
INFO:root:current mean train loss 3744.6884657118057
INFO:root:current train perplexity4.391285419464111
INFO:root:current mean train loss 3749.0918774708207
INFO:root:current train perplexity4.388631820678711
INFO:root:current mean train loss 3751.8364997345266
INFO:root:current train perplexity4.391923427581787
INFO:root:current mean train loss 3750.3975836032773
INFO:root:current train perplexity4.3978424072265625
INFO:root:current mean train loss 3754.2475623497594
INFO:root:current train perplexity4.401137828826904
INFO:root:current mean train loss 3759.78883872939
INFO:root:current train perplexity4.402994155883789
INFO:root:current mean train loss 3761.0647223467386
INFO:root:current train perplexity4.404533863067627


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.33s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 4015.019839455895
INFO:root:eval perplexity: 5.07109260559082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/53

 26%|â–ˆâ–ˆâ–‹       | 53/200 [2:03:39<5:17:10, 129.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3752.515582540761
INFO:root:current train perplexity4.444613456726074
INFO:root:current mean train loss 3755.0667397103657
INFO:root:current train perplexity4.4021453857421875
INFO:root:current mean train loss 3744.9645426797224
INFO:root:current train perplexity4.389873027801514
INFO:root:current mean train loss 3753.6333612495164
INFO:root:current train perplexity4.39357328414917
INFO:root:current mean train loss 3747.428150510675
INFO:root:current train perplexity4.389588832855225
INFO:root:current mean train loss 3753.273878166826
INFO:root:current train perplexity4.395378589630127
INFO:root:current mean train loss 3755.416778221559
INFO:root:current train perplexity4.3946757316589355
INFO:root:current mean train loss 3750.7351749573177
INFO:root:current train perplexity4.3882880210876465
INFO:root:current mean train loss 3752.3608623889354
INFO:root:current train perplexity4.390012741088867
INFO:root:current mean train loss 3754.1621778824992
INFO:root:current train perplexity4.390892028808594


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.81s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.59s/it]
INFO:root:eval mean loss: 4013.4500896913787
INFO:root:eval perplexity: 5.067873954772949
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/54

 27%|â–ˆâ–ˆâ–‹       | 54/200 [2:05:43<5:11:16, 127.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3722.4791456653224
INFO:root:current train perplexity4.37988805770874
INFO:root:current mean train loss 3729.4416746183206
INFO:root:current train perplexity4.354969024658203
INFO:root:current mean train loss 3742.2934908515963
INFO:root:current train perplexity4.37192964553833
INFO:root:current mean train loss 3732.5581349721488
INFO:root:current train perplexity4.361809730529785
INFO:root:current mean train loss 3736.5530289298144
INFO:root:current train perplexity4.369633197784424
INFO:root:current mean train loss 3739.177927020804
INFO:root:current train perplexity4.375394821166992
INFO:root:current mean train loss 3738.181102432275
INFO:root:current train perplexity4.377955436706543
INFO:root:current mean train loss 3739.4613232488673
INFO:root:current train perplexity4.377363204956055
INFO:root:current mean train loss 3740.613954032228
INFO:root:current train perplexity4.376917839050293
INFO:root:current mean train loss 3742.923350333143
INFO:root:current train perplexity4.376451015472412


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.40s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.39s/it]
INFO:root:eval mean loss: 4014.510397620235
INFO:root:eval perplexity: 5.070047855377197
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/55

 28%|â–ˆâ–ˆâ–Š       | 55/200 [2:07:47<5:06:04, 126.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3686.7751903044873
INFO:root:current train perplexity4.30272912979126
INFO:root:current mean train loss 3728.9591319132196
INFO:root:current train perplexity4.337401390075684
INFO:root:current mean train loss 3729.1515050912003
INFO:root:current train perplexity4.338554859161377
INFO:root:current mean train loss 3724.456442863892
INFO:root:current train perplexity4.332660675048828
INFO:root:current mean train loss 3721.3431304723094
INFO:root:current train perplexity4.333492279052734
INFO:root:current mean train loss 3720.759841720779
INFO:root:current train perplexity4.341862201690674
INFO:root:current mean train loss 3722.695948641065
INFO:root:current train perplexity4.345335960388184
INFO:root:current mean train loss 3726.2836468068126
INFO:root:current train perplexity4.352033615112305
INFO:root:current mean train loss 3728.9927863574567
INFO:root:current train perplexity4.354160308837891
INFO:root:current mean train loss 3733.1001400363584
INFO:root:current train perplexity4.357344627380371


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.50s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.22s/it]
INFO:root:eval mean loss: 4013.1454679881426
INFO:root:eval perplexity: 5.0672502517700195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/56

 28%|â–ˆâ–ˆâ–Š       | 56/200 [2:09:52<5:02:29, 126.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3727.143835189495
INFO:root:current train perplexity4.3431925773620605
INFO:root:current mean train loss 3710.121980628189
INFO:root:current train perplexity4.321413516998291
INFO:root:current mean train loss 3715.170530743927
INFO:root:current train perplexity4.322442054748535
INFO:root:current mean train loss 3716.3067616399494
INFO:root:current train perplexity4.323195457458496
INFO:root:current mean train loss 3715.484999825224
INFO:root:current train perplexity4.330037593841553
INFO:root:current mean train loss 3718.900563799703
INFO:root:current train perplexity4.333075046539307
INFO:root:current mean train loss 3724.6231683792985
INFO:root:current train perplexity4.338386535644531
INFO:root:current mean train loss 3724.6719455948796
INFO:root:current train perplexity4.33996057510376
INFO:root:current mean train loss 3725.9206295080985
INFO:root:current train perplexity4.341439723968506
INFO:root:current mean train loss 3726.1263880180836
INFO:root:current train perplexity4.342123508453369


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.82s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.87s/it]
INFO:root:eval mean loss: 4010.449151221742
INFO:root:eval perplexity: 5.061727523803711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/57

 28%|â–ˆâ–ˆâ–Š       | 57/200 [2:11:55<4:58:40, 125.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3674.4789195667613
INFO:root:current train perplexity4.25637674331665
INFO:root:current mean train loss 3690.0317398563507
INFO:root:current train perplexity4.29263973236084
INFO:root:current mean train loss 3697.343198529412
INFO:root:current train perplexity4.293771266937256
INFO:root:current mean train loss 3697.0481404049297
INFO:root:current train perplexity4.29652738571167
INFO:root:current mean train loss 3709.230865277301
INFO:root:current train perplexity4.310931205749512
INFO:root:current mean train loss 3709.0797671206365
INFO:root:current train perplexity4.314703464508057
INFO:root:current mean train loss 3709.620344555105
INFO:root:current train perplexity4.318759441375732
INFO:root:current mean train loss 3711.090385709851
INFO:root:current train perplexity4.325023651123047
INFO:root:current mean train loss 3712.388258691977
INFO:root:current train perplexity4.324128150939941
INFO:root:current mean train loss 3714.9930878803993
INFO:root:current train perplexity4.3259782791137695


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.30s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.87s/it]
INFO:root:eval mean loss: 4011.761727407469
INFO:root:eval perplexity: 5.064414978027344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/58

 29%|â–ˆâ–ˆâ–‰       | 58/200 [2:14:00<4:56:24, 125.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3706.337615482391
INFO:root:current train perplexity4.32024621963501
INFO:root:current mean train loss 3684.3731801787767
INFO:root:current train perplexity4.273643493652344
INFO:root:current mean train loss 3691.6314609077945
INFO:root:current train perplexity4.27890157699585
INFO:root:current mean train loss 3684.5010027924845
INFO:root:current train perplexity4.2809600830078125
INFO:root:current mean train loss 3690.664068300317
INFO:root:current train perplexity4.289247989654541
INFO:root:current mean train loss 3693.7816719339753
INFO:root:current train perplexity4.292113780975342
INFO:root:current mean train loss 3695.7397114795435
INFO:root:current train perplexity4.294789791107178
INFO:root:current mean train loss 3697.748776097129
INFO:root:current train perplexity4.301395893096924
INFO:root:current mean train loss 3700.233039157554
INFO:root:current train perplexity4.306447505950928
INFO:root:current mean train loss 3705.659981574101
INFO:root:current train perplexity4.311458110809326


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.50s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 4011.1408933815383
INFO:root:eval perplexity: 5.063144207000732
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/59

 30%|â–ˆâ–ˆâ–‰       | 59/200 [2:16:03<4:52:31, 124.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3695.135594327685
INFO:root:current train perplexity4.281666278839111
INFO:root:current mean train loss 3679.6140864857457
INFO:root:current train perplexity4.261672496795654
INFO:root:current mean train loss 3692.858295736278
INFO:root:current train perplexity4.275837421417236
INFO:root:current mean train loss 3696.689440621841
INFO:root:current train perplexity4.286795139312744
INFO:root:current mean train loss 3694.425551623043
INFO:root:current train perplexity4.292908191680908
INFO:root:current mean train loss 3695.4911061836415
INFO:root:current train perplexity4.2957987785339355
INFO:root:current mean train loss 3695.9719976888505
INFO:root:current train perplexity4.296841621398926
INFO:root:current mean train loss 3698.1023338703794
INFO:root:current train perplexity4.2962646484375
INFO:root:current mean train loss 3697.8571637194136
INFO:root:current train perplexity4.296566486358643
INFO:root:current mean train loss 3697.7163143766898
INFO:root:current train perplexity4.297287464141846


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.33s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.25s/it]
INFO:root:eval mean loss: 4008.5277662344856
INFO:root:eval perplexity: 5.057796001434326
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/60

 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [2:18:07<4:49:46, 124.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3684.6895860116692
INFO:root:current train perplexity4.284178256988525
INFO:root:current mean train loss 3695.0305489481493
INFO:root:current train perplexity4.288143634796143
INFO:root:current mean train loss 3691.2063417058694
INFO:root:current train perplexity4.289557933807373
INFO:root:current mean train loss 3681.0557413629617
INFO:root:current train perplexity4.281991481781006
INFO:root:current mean train loss 3680.582452762102
INFO:root:current train perplexity4.276384353637695
INFO:root:current mean train loss 3683.3712080196187
INFO:root:current train perplexity4.279908657073975
INFO:root:current mean train loss 3682.141361377025
INFO:root:current train perplexity4.277006149291992
INFO:root:current mean train loss 3684.6743333299905
INFO:root:current train perplexity4.27938985824585
INFO:root:current mean train loss 3686.12866433136
INFO:root:current train perplexity4.278848648071289
INFO:root:current mean train loss 3690.603495674796
INFO:root:current train perplexity4.283300399780273


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.02s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.98s/it]
INFO:root:eval mean loss: 4013.071548786569
INFO:root:eval perplexity: 5.067098617553711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/61

 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [2:20:12<4:48:12, 124.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3665.2194038478806
INFO:root:current train perplexity4.225597858428955
INFO:root:current mean train loss 3674.018985523897
INFO:root:current train perplexity4.253859519958496
INFO:root:current mean train loss 3678.076218661531
INFO:root:current train perplexity4.258836269378662
INFO:root:current mean train loss 3680.798203579215
INFO:root:current train perplexity4.262726783752441
INFO:root:current mean train loss 3682.0530592274126
INFO:root:current train perplexity4.266430854797363
INFO:root:current mean train loss 3682.546297297567
INFO:root:current train perplexity4.2653985023498535
INFO:root:current mean train loss 3681.5132973128184
INFO:root:current train perplexity4.265233993530273
INFO:root:current mean train loss 3680.190644977962
INFO:root:current train perplexity4.267409801483154
INFO:root:current mean train loss 3679.41684630866
INFO:root:current train perplexity4.266685485839844
INFO:root:current mean train loss 3681.584331415828
INFO:root:current train perplexity4.268896579742432


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.60s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.54s/it]
INFO:root:eval mean loss: 4013.547624736813
INFO:root:eval perplexity: 5.068073749542236
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/62

 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [2:22:16<4:45:54, 124.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3643.3782663445722
INFO:root:current train perplexity4.216043472290039
INFO:root:current mean train loss 3659.020634264824
INFO:root:current train perplexity4.237473964691162
INFO:root:current mean train loss 3663.5641460871293
INFO:root:current train perplexity4.240220546722412
INFO:root:current mean train loss 3666.392484177215
INFO:root:current train perplexity4.243423938751221
INFO:root:current mean train loss 3670.402687026515
INFO:root:current train perplexity4.243677139282227
INFO:root:current mean train loss 3671.8472705488443
INFO:root:current train perplexity4.2500762939453125
INFO:root:current mean train loss 3671.8404268772483
INFO:root:current train perplexity4.250068187713623
INFO:root:current mean train loss 3674.1644955041274
INFO:root:current train perplexity4.256958961486816
INFO:root:current mean train loss 3674.114025947102
INFO:root:current train perplexity4.25640869140625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:52<00:00, 112.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:52<00:00, 112.69s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.38s/it]
INFO:root:eval mean loss: 4009.0512158549423
INFO:root:eval perplexity: 5.05886697769165
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/63

 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [2:24:18<4:42:12, 123.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3679.4195149739585
INFO:root:current train perplexity4.2939019203186035
INFO:root:current mean train loss 3667.0573611953882
INFO:root:current train perplexity4.2329607009887695
INFO:root:current mean train loss 3656.5332283809266
INFO:root:current train perplexity4.2269392013549805
INFO:root:current mean train loss 3656.1726138678323
INFO:root:current train perplexity4.2351298332214355
INFO:root:current mean train loss 3663.458748715687
INFO:root:current train perplexity4.2389631271362305
INFO:root:current mean train loss 3668.0718802419856
INFO:root:current train perplexity4.237107276916504
INFO:root:current mean train loss 3668.313567659748
INFO:root:current train perplexity4.236758232116699
INFO:root:current mean train loss 3664.6518700546762
INFO:root:current train perplexity4.233860015869141
INFO:root:current mean train loss 3665.7906124737315
INFO:root:current train perplexity4.236624240875244
INFO:root:current mean train loss 3666.465016243598
INFO:root:current train perplexity4.238766193389893


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.47s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.94s/it]
INFO:root:eval mean loss: 4006.3665416528147
INFO:root:eval perplexity: 5.053378105163574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/64
#################best###########
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [2:26:23<4:41:19, 124.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3639.5861594460225
INFO:root:current train perplexity4.211841583251953
INFO:root:current mean train loss 3667.2776142842063
INFO:root:current train perplexity4.22189998626709
INFO:root:current mean train loss 3646.6214443405656
INFO:root:current train perplexity4.216689109802246
INFO:root:current mean train loss 3635.4460967330688
INFO:root:current train perplexity4.20988655090332
INFO:root:current mean train loss 3640.9301781573145
INFO:root:current train perplexity4.209147930145264
INFO:root:current mean train loss 3646.8050486943494
INFO:root:current train perplexity4.213830471038818
INFO:root:current mean train loss 3651.1641092503323
INFO:root:current train perplexity4.21964168548584
INFO:root:current mean train loss 3653.5643878834826
INFO:root:current train perplexity4.223748683929443
INFO:root:current mean train loss 3657.4802101596215
INFO:root:current train perplexity4.226910591125488
INFO:root:current mean train loss 3656.6880603710724
INFO:root:current train perplexity4.2275800704956055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.28s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.23s/it]
INFO:root:eval mean loss: 4008.080206255541
INFO:root:eval perplexity: 5.056881427764893
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/65

 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [2:28:25<4:38:07, 123.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3599.7051680715463
INFO:root:current train perplexity4.207959175109863
INFO:root:current mean train loss 3641.7757619649424
INFO:root:current train perplexity4.198606014251709
INFO:root:current mean train loss 3644.3561287100456
INFO:root:current train perplexity4.201509952545166
INFO:root:current mean train loss 3646.5179952304566
INFO:root:current train perplexity4.202507495880127
INFO:root:current mean train loss 3648.7103705576897
INFO:root:current train perplexity4.208323955535889
INFO:root:current mean train loss 3645.5561589294316
INFO:root:current train perplexity4.203636646270752
INFO:root:current mean train loss 3649.6278480443507
INFO:root:current train perplexity4.20906925201416
INFO:root:current mean train loss 3647.6867543354483
INFO:root:current train perplexity4.211142063140869
INFO:root:current mean train loss 3646.2088672232717
INFO:root:current train perplexity4.207743167877197
INFO:root:current mean train loss 3646.837333803727
INFO:root:current train perplexity4.212630748748779


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.89s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 4006.727094068595
INFO:root:eval perplexity: 5.0541157722473145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/66

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [2:31:25<5:13:28, 140.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3609.4480794270835
INFO:root:current train perplexity4.11605167388916
INFO:root:current mean train loss 3621.1434239665355
INFO:root:current train perplexity4.164893627166748
INFO:root:current mean train loss 3635.931770761633
INFO:root:current train perplexity4.19374942779541
INFO:root:current mean train loss 3637.8179479943137
INFO:root:current train perplexity4.191761493682861
INFO:root:current mean train loss 3641.2174189475995
INFO:root:current train perplexity4.191842555999756
INFO:root:current mean train loss 3635.7159398348554
INFO:root:current train perplexity4.187877655029297
INFO:root:current mean train loss 3635.4926002417264
INFO:root:current train perplexity4.190953254699707
INFO:root:current mean train loss 3636.1735373054935
INFO:root:current train perplexity4.195811748504639
INFO:root:current mean train loss 3637.081725409991
INFO:root:current train perplexity4.198073863983154
INFO:root:current mean train loss 3640.8351405533645
INFO:root:current train perplexity4.201581001281738


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.05s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.05s/it]
INFO:root:eval mean loss: 4007.467640112478
INFO:root:eval perplexity: 5.055628776550293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/67

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [2:34:45<5:50:58, 158.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3607.9755929129465
INFO:root:current train perplexity4.151980400085449
INFO:root:current mean train loss 3604.602072482639
INFO:root:current train perplexity4.1572442054748535
INFO:root:current mean train loss 3614.4750509059177
INFO:root:current train perplexity4.166940212249756
INFO:root:current mean train loss 3624.082142753032
INFO:root:current train perplexity4.173844337463379
INFO:root:current mean train loss 3623.1911216998924
INFO:root:current train perplexity4.1731109619140625
INFO:root:current mean train loss 3631.7405341888143
INFO:root:current train perplexity4.180908679962158
INFO:root:current mean train loss 3632.9603092704233
INFO:root:current train perplexity4.179998874664307
INFO:root:current mean train loss 3634.060010762117
INFO:root:current train perplexity4.184961795806885
INFO:root:current mean train loss 3635.777212469592
INFO:root:current train perplexity4.189099311828613
INFO:root:current mean train loss 3637.2806525735296
INFO:root:current train perplexity4.190910816192627


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.08s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.23s/it]
INFO:root:eval mean loss: 4010.123784491356
INFO:root:eval perplexity: 5.061062335968018
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/68

 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [2:36:51<5:27:08, 148.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3625.9311750545057
INFO:root:current train perplexity4.171016216278076
INFO:root:current mean train loss 3632.4563124863416
INFO:root:current train perplexity4.178380012512207
INFO:root:current mean train loss 3631.224065835584
INFO:root:current train perplexity4.178274631500244
INFO:root:current mean train loss 3628.257235246219
INFO:root:current train perplexity4.1717939376831055
INFO:root:current mean train loss 3622.2447655809115
INFO:root:current train perplexity4.167202949523926
INFO:root:current mean train loss 3624.7847857677257
INFO:root:current train perplexity4.1703200340271
INFO:root:current mean train loss 3627.9786420617465
INFO:root:current train perplexity4.172705173492432
INFO:root:current mean train loss 3628.9509960806063
INFO:root:current train perplexity4.176007270812988
INFO:root:current mean train loss 3631.1078273279954
INFO:root:current train perplexity4.180078983306885
INFO:root:current mean train loss 3628.374653853642
INFO:root:current train perplexity4.178276062011719


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.98s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.37s/it]
INFO:root:eval mean loss: 4010.350781596299
INFO:root:eval perplexity: 5.061526775360107
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/69

 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [2:38:56<5:08:38, 141.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3604.6311848958335
INFO:root:current train perplexity4.14864444732666
INFO:root:current mean train loss 3599.963839701469
INFO:root:current train perplexity4.15191650390625
INFO:root:current mean train loss 3603.6278402016933
INFO:root:current train perplexity4.147724628448486
INFO:root:current mean train loss 3613.6721163583957
INFO:root:current train perplexity4.160584926605225
INFO:root:current mean train loss 3606.410714363047
INFO:root:current train perplexity4.157812595367432
INFO:root:current mean train loss 3606.9214053283804
INFO:root:current train perplexity4.160031318664551
INFO:root:current mean train loss 3611.1332250264018
INFO:root:current train perplexity4.16177225112915
INFO:root:current mean train loss 3612.753460880285
INFO:root:current train perplexity4.163313865661621
INFO:root:current mean train loss 3616.471681982594
INFO:root:current train perplexity4.164158821105957
INFO:root:current mean train loss 3619.8262868855154
INFO:root:current train perplexity4.166568279266357


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.96s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 4011.8994157939937
INFO:root:eval perplexity: 5.064696788787842
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/70

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [2:41:00<4:55:08, 136.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3572.916938393803
INFO:root:current train perplexity4.14029598236084
INFO:root:current mean train loss 3581.940184011399
INFO:root:current train perplexity4.134097099304199
INFO:root:current mean train loss 3596.580085666023
INFO:root:current train perplexity4.140687465667725
INFO:root:current mean train loss 3597.135475604979
INFO:root:current train perplexity4.143551349639893
INFO:root:current mean train loss 3599.214594290407
INFO:root:current train perplexity4.139586448669434
INFO:root:current mean train loss 3600.380157088551
INFO:root:current train perplexity4.14157247543335
INFO:root:current mean train loss 3602.503775844082
INFO:root:current train perplexity4.143669605255127
INFO:root:current mean train loss 3603.2968534487195
INFO:root:current train perplexity4.146723747253418
INFO:root:current mean train loss 3606.3294340939683
INFO:root:current train perplexity4.149596691131592
INFO:root:current mean train loss 3611.905680762839
INFO:root:current train perplexity4.152673721313477


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.21s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.47s/it]
INFO:root:eval mean loss: 4013.633193428635
INFO:root:eval perplexity: 5.068248748779297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/71

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [2:43:25<4:58:55, 139.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3578.2309023729013
INFO:root:current train perplexity4.088140964508057
INFO:root:current mean train loss 3581.2573022899514
INFO:root:current train perplexity4.101466655731201
INFO:root:current mean train loss 3581.295080063495
INFO:root:current train perplexity4.111509799957275
INFO:root:current mean train loss 3594.863975088343
INFO:root:current train perplexity4.1248979568481445
INFO:root:current mean train loss 3594.895815732903
INFO:root:current train perplexity4.124377250671387
INFO:root:current mean train loss 3591.2875692377647
INFO:root:current train perplexity4.1270432472229
INFO:root:current mean train loss 3597.4213545082926
INFO:root:current train perplexity4.13079309463501
INFO:root:current mean train loss 3600.350949761143
INFO:root:current train perplexity4.136110305786133
INFO:root:current mean train loss 3599.7311203548516
INFO:root:current train perplexity4.136911392211914
INFO:root:current mean train loss 3605.5925848407605
INFO:root:current train perplexity4.143513202667236


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.27s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.57s/it]
INFO:root:eval mean loss: 4015.550467849623
INFO:root:eval perplexity: 5.072179317474365
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/72

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [2:46:04<5:09:00, 144.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3610.3770540364585
INFO:root:current train perplexity4.112800121307373
INFO:root:current mean train loss 3590.8446554129464
INFO:root:current train perplexity4.107517719268799
INFO:root:current mean train loss 3592.4987659801136
INFO:root:current train perplexity4.110089302062988
INFO:root:current mean train loss 3590.010656901042
INFO:root:current train perplexity4.1178412437438965
INFO:root:current mean train loss 3593.192711245888
INFO:root:current train perplexity4.12327241897583
INFO:root:current mean train loss 3593.8450883152173
INFO:root:current train perplexity4.122218132019043
INFO:root:current mean train loss 3594.1054300491896
INFO:root:current train perplexity4.123440265655518
INFO:root:current mean train loss 3596.1695983492946
INFO:root:current train perplexity4.1281890869140625
INFO:root:current mean train loss 3598.0776612723216
INFO:root:current train perplexity4.129423141479492
INFO:root:current mean train loss 3598.853479066506
INFO:root:current train perplexity4.131682395935059


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.80s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.64s/it]
INFO:root:eval mean loss: 4013.0534113890735
INFO:root:eval perplexity: 5.067060470581055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/73

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [2:48:13<4:56:46, 140.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3556.4431946536147
INFO:root:current train perplexity4.084844589233398
INFO:root:current mean train loss 3575.876468846055
INFO:root:current train perplexity4.1036152839660645
INFO:root:current mean train loss 3585.694005528103
INFO:root:current train perplexity4.114374160766602
INFO:root:current mean train loss 3584.076150201942
INFO:root:current train perplexity4.108912467956543
INFO:root:current mean train loss 3585.4303532002136
INFO:root:current train perplexity4.114315509796143
INFO:root:current mean train loss 3585.4334036301993
INFO:root:current train perplexity4.116885662078857
INFO:root:current mean train loss 3588.113552199625
INFO:root:current train perplexity4.118489742279053
INFO:root:current mean train loss 3587.7936085668102
INFO:root:current train perplexity4.116625785827637
INFO:root:current mean train loss 3589.439446765731
INFO:root:current train perplexity4.117027282714844
INFO:root:current mean train loss 3590.384435054123
INFO:root:current train perplexity4.119048118591309


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.15s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.08s/it]
INFO:root:eval mean loss: 4012.527837225731
INFO:root:eval perplexity: 5.065983772277832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/74

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [2:50:28<4:50:45, 138.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3592.109664749313
INFO:root:current train perplexity4.108813762664795
INFO:root:current mean train loss 3574.7611141504417
INFO:root:current train perplexity4.089547157287598
INFO:root:current mean train loss 3581.2317842568727
INFO:root:current train perplexity4.0970048904418945
INFO:root:current mean train loss 3576.987375244765
INFO:root:current train perplexity4.096737861633301
INFO:root:current mean train loss 3575.836181143394
INFO:root:current train perplexity4.095100402832031
INFO:root:current mean train loss 3577.6487369956903
INFO:root:current train perplexity4.093622207641602
INFO:root:current mean train loss 3578.5976781555264
INFO:root:current train perplexity4.098937511444092
INFO:root:current mean train loss 3579.842986096022
INFO:root:current train perplexity4.102801322937012
INFO:root:current mean train loss 3581.6679186066394
INFO:root:current train perplexity4.1059088706970215
INFO:root:current mean train loss 3584.9990712309223
INFO:root:current train perplexity4.1094441413879395


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.67s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.96s/it]
INFO:root:eval mean loss: 4011.2301380346853
INFO:root:eval perplexity: 5.063327312469482
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/75

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [2:52:33<4:40:20, 134.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3561.1953026357323
INFO:root:current train perplexity4.077631950378418
INFO:root:current mean train loss 3571.942296933888
INFO:root:current train perplexity4.0790534019470215
INFO:root:current mean train loss 3570.400525351432
INFO:root:current train perplexity4.084146976470947
INFO:root:current mean train loss 3569.9371469445095
INFO:root:current train perplexity4.0862250328063965
INFO:root:current mean train loss 3574.06022836689
INFO:root:current train perplexity4.0888543128967285
INFO:root:current mean train loss 3573.947919383869
INFO:root:current train perplexity4.08589506149292
INFO:root:current mean train loss 3577.5455956193
INFO:root:current train perplexity4.09399938583374
INFO:root:current mean train loss 3575.7391468950445
INFO:root:current train perplexity4.094186782836914
INFO:root:current mean train loss 3576.221822532849
INFO:root:current train perplexity4.096376895904541


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.84s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.53s/it]
INFO:root:eval mean loss: 4015.099003352172
INFO:root:eval perplexity: 5.071253776550293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/76

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [2:54:36<4:31:07, 131.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3584.663016183036
INFO:root:current train perplexity4.115933418273926
INFO:root:current mean train loss 3569.3852926949476
INFO:root:current train perplexity4.090787410736084
INFO:root:current mean train loss 3562.291729176102
INFO:root:current train perplexity4.078298568725586
INFO:root:current mean train loss 3560.1529465467224
INFO:root:current train perplexity4.06998872756958
INFO:root:current mean train loss 3563.561886949094
INFO:root:current train perplexity4.073783874511719
INFO:root:current mean train loss 3564.6404843904093
INFO:root:current train perplexity4.076096534729004
INFO:root:current mean train loss 3569.613030271829
INFO:root:current train perplexity4.08168888092041
INFO:root:current mean train loss 3570.3845919294777
INFO:root:current train perplexity4.084249496459961
INFO:root:current mean train loss 3570.3809111074
INFO:root:current train perplexity4.084285259246826
INFO:root:current mean train loss 3569.2976682551507
INFO:root:current train perplexity4.083827495574951


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.79s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.92s/it]
INFO:root:eval mean loss: 4016.566963791002
INFO:root:eval perplexity: 5.074265480041504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/77

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [2:57:49<5:06:38, 149.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3519.235546875
INFO:root:current train perplexity4.004356384277344
INFO:root:current mean train loss 3552.492527173913
INFO:root:current train perplexity4.045459747314453
INFO:root:current mean train loss 3559.150054505814
INFO:root:current train perplexity4.054729461669922
INFO:root:current mean train loss 3555.2710185701885
INFO:root:current train perplexity4.055633544921875
INFO:root:current mean train loss 3560.527463761295
INFO:root:current train perplexity4.066334247589111
INFO:root:current mean train loss 3560.93728667324
INFO:root:current train perplexity4.068197727203369
INFO:root:current mean train loss 3556.5136111375764
INFO:root:current train perplexity4.063566207885742
INFO:root:current mean train loss 3560.8204234730115
INFO:root:current train perplexity4.070056915283203
INFO:root:current mean train loss 3561.3491318778756
INFO:root:current train perplexity4.071755886077881
INFO:root:current mean train loss 3562.8651529947915
INFO:root:current train perplexity4.073450088500977


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.02s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.92s/it]
INFO:root:eval mean loss: 4014.65790184508
INFO:root:eval perplexity: 5.07034969329834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/78

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [3:00:05<4:56:10, 145.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3548.9729853091035
INFO:root:current train perplexity4.056130886077881
INFO:root:current mean train loss 3549.018872268801
INFO:root:current train perplexity4.063096046447754
INFO:root:current mean train loss 3546.4967856642374
INFO:root:current train perplexity4.063272476196289
INFO:root:current mean train loss 3549.6548070759964
INFO:root:current train perplexity4.058718681335449
INFO:root:current mean train loss 3548.741694601433
INFO:root:current train perplexity4.057382583618164
INFO:root:current mean train loss 3547.78970622834
INFO:root:current train perplexity4.0590291023254395
INFO:root:current mean train loss 3552.803862202799
INFO:root:current train perplexity4.0615458488464355
INFO:root:current mean train loss 3553.1824220100707
INFO:root:current train perplexity4.060604095458984
INFO:root:current mean train loss 3555.514353273561
INFO:root:current train perplexity4.06156063079834
INFO:root:current mean train loss 3556.551899059622
INFO:root:current train perplexity4.0659871101379395


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.51s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.59s/it]
INFO:root:eval mean loss: 4014.3202155363474
INFO:root:eval perplexity: 5.069656848907471
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/79

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [3:02:09<4:40:38, 139.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3540.881379158266
INFO:root:current train perplexity4.02799654006958
INFO:root:current mean train loss 3546.4846992783873
INFO:root:current train perplexity4.044450283050537
INFO:root:current mean train loss 3551.0445794439934
INFO:root:current train perplexity4.045079708099365
INFO:root:current mean train loss 3554.6233994406157
INFO:root:current train perplexity4.046955108642578
INFO:root:current mean train loss 3553.9053011936267
INFO:root:current train perplexity4.0540337562561035
INFO:root:current mean train loss 3552.866817840749
INFO:root:current train perplexity4.056281566619873
INFO:root:current mean train loss 3552.0587082755546
INFO:root:current train perplexity4.054922580718994
INFO:root:current mean train loss 3551.3025640443316
INFO:root:current train perplexity4.054297924041748
INFO:root:current mean train loss 3554.447002975519
INFO:root:current train perplexity4.05856466293335
INFO:root:current mean train loss 3551.347218580072
INFO:root:current train perplexity4.057280540466309


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.07s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.48s/it]
INFO:root:eval mean loss: 4020.010035738032
INFO:root:eval perplexity: 5.081335544586182
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/80

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [3:04:13<4:28:55, 134.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3499.2730994591348
INFO:root:current train perplexity4.037227630615234
INFO:root:current mean train loss 3521.6373686207285
INFO:root:current train perplexity4.017319679260254
INFO:root:current mean train loss 3524.7886518534256
INFO:root:current train perplexity4.018286228179932
INFO:root:current mean train loss 3530.07960208679
INFO:root:current train perplexity4.018373966217041
INFO:root:current mean train loss 3531.9887495106063
INFO:root:current train perplexity4.028996467590332
INFO:root:current mean train loss 3532.132385367144
INFO:root:current train perplexity4.030847072601318
INFO:root:current mean train loss 3538.870517211341
INFO:root:current train perplexity4.037038326263428
INFO:root:current mean train loss 3541.47634577977
INFO:root:current train perplexity4.042325973510742
INFO:root:current mean train loss 3543.3145476967557
INFO:root:current train perplexity4.044368743896484
INFO:root:current mean train loss 3543.0325565033445
INFO:root:current train perplexity4.043547630310059


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.38s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.09s/it]
INFO:root:eval mean loss: 4020.5666902149824
INFO:root:eval perplexity: 5.082479953765869
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/81

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [3:06:16<4:20:05, 131.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3541.296391913231
INFO:root:current train perplexity4.067391872406006
INFO:root:current mean train loss 3548.705046569409
INFO:root:current train perplexity4.042133331298828
INFO:root:current mean train loss 3533.2026307882084
INFO:root:current train perplexity4.026933193206787
INFO:root:current mean train loss 3531.2034556803856
INFO:root:current train perplexity4.023734092712402
INFO:root:current mean train loss 3538.581745053831
INFO:root:current train perplexity4.0267157554626465
INFO:root:current mean train loss 3532.8246177659394
INFO:root:current train perplexity4.026529788970947
INFO:root:current mean train loss 3535.636048966987
INFO:root:current train perplexity4.02985954284668
INFO:root:current mean train loss 3538.8102455394496
INFO:root:current train perplexity4.030195713043213
INFO:root:current mean train loss 3541.177274341426
INFO:root:current train perplexity4.033211708068848
INFO:root:current mean train loss 3538.7051397402156
INFO:root:current train perplexity4.035623073577881


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.09s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.72s/it]
INFO:root:eval mean loss: 4022.53756129488
INFO:root:eval perplexity: 5.086531162261963
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/82

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [3:08:33<4:21:08, 132.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3530.9338156960225
INFO:root:current train perplexity4.015896797180176
INFO:root:current mean train loss 3526.1302734375
INFO:root:current train perplexity4.016220569610596
INFO:root:current mean train loss 3521.7094669117646
INFO:root:current train perplexity4.013149261474609
INFO:root:current mean train loss 3526.139874009683
INFO:root:current train perplexity4.021443843841553
INFO:root:current mean train loss 3523.3465004721843
INFO:root:current train perplexity4.024871349334717
INFO:root:current mean train loss 3526.8937807925113
INFO:root:current train perplexity4.0263752937316895
INFO:root:current mean train loss 3527.3719182371183
INFO:root:current train perplexity4.024770736694336
INFO:root:current mean train loss 3529.922733210886
INFO:root:current train perplexity4.024986743927002
INFO:root:current mean train loss 3531.2106393914473
INFO:root:current train perplexity4.0245842933654785
INFO:root:current mean train loss 3533.7341111747382
INFO:root:current train perplexity4.026078701019287


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.58s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.12s/it]
INFO:root:eval mean loss: 4020.5722361896055
INFO:root:eval perplexity: 5.082490921020508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/83

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [3:10:35<4:12:58, 129.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3522.2636369977677
INFO:root:current train perplexity3.9809165000915527
INFO:root:current mean train loss 3521.3315040260736
INFO:root:current train perplexity3.9982047080993652
INFO:root:current mean train loss 3513.490212096008
INFO:root:current train perplexity4.006398677825928
INFO:root:current mean train loss 3515.1882431828944
INFO:root:current train perplexity4.01049280166626
INFO:root:current mean train loss 3518.2649801101848
INFO:root:current train perplexity4.008397102355957
INFO:root:current mean train loss 3519.8294593174123
INFO:root:current train perplexity4.010750770568848
INFO:root:current mean train loss 3523.987515686864
INFO:root:current train perplexity4.014301776885986
INFO:root:current mean train loss 3526.784954346023
INFO:root:current train perplexity4.017275810241699
INFO:root:current mean train loss 3526.5575657001377
INFO:root:current train perplexity4.0163493156433105
INFO:root:current mean train loss 3527.0002279152877
INFO:root:current train perplexity4.0173211097717285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.29s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.92s/it]
INFO:root:eval mean loss: 4019.7909619486923
INFO:root:eval perplexity: 5.080885410308838
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/84

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [3:12:40<4:07:34, 128.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3492.621279434419
INFO:root:current train perplexity3.9851863384246826
INFO:root:current mean train loss 3504.4970945837904
INFO:root:current train perplexity3.98628306388855
INFO:root:current mean train loss 3502.584173561462
INFO:root:current train perplexity3.988107681274414
INFO:root:current mean train loss 3505.884853805172
INFO:root:current train perplexity3.994988203048706
INFO:root:current mean train loss 3508.3177088516786
INFO:root:current train perplexity3.994386911392212
INFO:root:current mean train loss 3513.7630194081107
INFO:root:current train perplexity3.9981422424316406
INFO:root:current mean train loss 3518.4286247060127
INFO:root:current train perplexity4.003169536590576
INFO:root:current mean train loss 3522.0765167117584
INFO:root:current train perplexity4.004706859588623
INFO:root:current mean train loss 3522.99748627655
INFO:root:current train perplexity4.007653713226318
INFO:root:current mean train loss 3521.750299958564
INFO:root:current train perplexity4.008303165435791


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.23s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.37s/it]
INFO:root:eval mean loss: 4021.972041569703
INFO:root:eval perplexity: 5.0853681564331055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/85

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [3:14:43<4:02:52, 126.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3469.7140124357197
INFO:root:current train perplexity3.9929113388061523
INFO:root:current mean train loss 3497.7809267523567
INFO:root:current train perplexity3.9921445846557617
INFO:root:current mean train loss 3511.9212677111336
INFO:root:current train perplexity3.996082305908203
INFO:root:current mean train loss 3514.4504929192776
INFO:root:current train perplexity3.9925143718719482
INFO:root:current mean train loss 3513.6697801816936
INFO:root:current train perplexity3.9930200576782227
INFO:root:current mean train loss 3511.4368489583335
INFO:root:current train perplexity3.9934098720550537
INFO:root:current mean train loss 3511.0236557523704
INFO:root:current train perplexity3.995793104171753
INFO:root:current mean train loss 3513.7309410477174
INFO:root:current train perplexity3.9971461296081543
INFO:root:current mean train loss 3515.1052079444858
INFO:root:current train perplexity3.996990919113159
INFO:root:current mean train loss 3515.8009692806754
INFO:root:current train perplexity3.9974329471588135


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.14s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.63s/it]
INFO:root:eval mean loss: 4022.208115165115
INFO:root:eval perplexity: 5.085853099822998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/86

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [3:17:59<4:40:23, 147.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3474.9571210488507
INFO:root:current train perplexity3.9575023651123047
INFO:root:current mean train loss 3483.050441803142
INFO:root:current train perplexity3.9622092247009277
INFO:root:current mean train loss 3487.147943264101
INFO:root:current train perplexity3.977586269378662
INFO:root:current mean train loss 3492.636340237403
INFO:root:current train perplexity3.978656768798828
INFO:root:current mean train loss 3495.3416299369546
INFO:root:current train perplexity3.9773271083831787
INFO:root:current mean train loss 3502.4496845719764
INFO:root:current train perplexity3.9826860427856445
INFO:root:current mean train loss 3503.24013735842
INFO:root:current train perplexity3.9828197956085205
INFO:root:current mean train loss 3506.3071506214264
INFO:root:current train perplexity3.9870126247406006
INFO:root:current mean train loss 3507.2580874678515
INFO:root:current train perplexity3.986985921859741
INFO:root:current mean train loss 3509.087414958919
INFO:root:current train perplexity3.98813533782959


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.97s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 4023.2558974678636
INFO:root:eval perplexity: 5.088008403778076
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/87

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [3:20:18<4:32:36, 144.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3494.0427965666117
INFO:root:current train perplexity3.952096700668335
INFO:root:current mean train loss 3508.892700821314
INFO:root:current train perplexity3.9686055183410645
INFO:root:current mean train loss 3505.993478548729
INFO:root:current train perplexity3.9729461669921875
INFO:root:current mean train loss 3497.911834948576
INFO:root:current train perplexity3.9694859981536865
INFO:root:current mean train loss 3497.581687973485
INFO:root:current train perplexity3.9692203998565674
INFO:root:current mean train loss 3499.1333303243173
INFO:root:current train perplexity3.967129707336426
INFO:root:current mean train loss 3498.1239956862637
INFO:root:current train perplexity3.968845844268799
INFO:root:current mean train loss 3499.8199645612226
INFO:root:current train perplexity3.9732666015625
INFO:root:current mean train loss 3501.982757125087
INFO:root:current train perplexity3.977196216583252


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.52s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.20s/it]
INFO:root:eval mean loss: 4025.394664575022
INFO:root:eval perplexity: 5.092410564422607
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/88

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [3:23:21<4:52:05, 156.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3691.4586588541665
INFO:root:current train perplexity4.072709083557129
INFO:root:current mean train loss 3503.8327304877125
INFO:root:current train perplexity3.9638006687164307
INFO:root:current mean train loss 3492.1608537946427
INFO:root:current train perplexity3.954822540283203
INFO:root:current mean train loss 3485.383724602929
INFO:root:current train perplexity3.946354627609253
INFO:root:current mean train loss 3491.986286324248
INFO:root:current train perplexity3.958787202835083
INFO:root:current mean train loss 3492.826536387146
INFO:root:current train perplexity3.962796211242676
INFO:root:current mean train loss 3494.723941328514
INFO:root:current train perplexity3.9634628295898438
INFO:root:current mean train loss 3492.12042314467
INFO:root:current train perplexity3.9637837409973145
INFO:root:current mean train loss 3494.870760830966
INFO:root:current train perplexity3.9649322032928467
INFO:root:current mean train loss 3495.9273231481
INFO:root:current train perplexity3.9698100090026855


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.62s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.94s/it]
INFO:root:eval mean loss: 4026.290478861924
INFO:root:eval perplexity: 5.0942559242248535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/89

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [3:25:28<4:32:50, 147.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3476.436678799716
INFO:root:current train perplexity3.890782356262207
INFO:root:current mean train loss 3479.19408959741
INFO:root:current train perplexity3.9455182552337646
INFO:root:current mean train loss 3479.645453430465
INFO:root:current train perplexity3.949204921722412
INFO:root:current mean train loss 3478.932220753366
INFO:root:current train perplexity3.951570987701416
INFO:root:current mean train loss 3476.7244424564706
INFO:root:current train perplexity3.9442527294158936
INFO:root:current mean train loss 3478.3585833346074
INFO:root:current train perplexity3.9449515342712402
INFO:root:current mean train loss 3480.7185965630115
INFO:root:current train perplexity3.9516830444335938
INFO:root:current mean train loss 3487.0544859380493
INFO:root:current train perplexity3.953765869140625
INFO:root:current mean train loss 3486.697161466361
INFO:root:current train perplexity3.9548871517181396
INFO:root:current mean train loss 3489.3974826448443
INFO:root:current train perplexity3.9585936069488525


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.16s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.78s/it]
INFO:root:eval mean loss: 4028.373486674424
INFO:root:eval perplexity: 5.098548412322998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/90

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [3:27:33<4:17:55, 140.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3437.5326891447367
INFO:root:current train perplexity3.974015712738037
INFO:root:current mean train loss 3481.647288602941
INFO:root:current train perplexity3.933184862136841
INFO:root:current mean train loss 3494.433533550942
INFO:root:current train perplexity3.939615488052368
INFO:root:current mean train loss 3490.128239646601
INFO:root:current train perplexity3.9445583820343018
INFO:root:current mean train loss 3490.332069123844
INFO:root:current train perplexity3.9430012702941895
INFO:root:current mean train loss 3488.2055076055212
INFO:root:current train perplexity3.943528175354004
INFO:root:current mean train loss 3485.2107115022973
INFO:root:current train perplexity3.944878578186035
INFO:root:current mean train loss 3482.911072371566
INFO:root:current train perplexity3.9495198726654053
INFO:root:current mean train loss 3484.6237053690666
INFO:root:current train perplexity3.951552152633667
INFO:root:current mean train loss 3488.4043423026897
INFO:root:current train perplexity3.9548234939575195


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.06s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.99s/it]
INFO:root:eval mean loss: 4029.098591256649
INFO:root:eval perplexity: 5.100043773651123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/91

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [3:29:38<4:07:01, 135.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3476.368426287616
INFO:root:current train perplexity3.976104497909546
INFO:root:current mean train loss 3474.432790200541
INFO:root:current train perplexity3.9381227493286133
INFO:root:current mean train loss 3472.2089951300936
INFO:root:current train perplexity3.938974618911743
INFO:root:current mean train loss 3474.608877759461
INFO:root:current train perplexity3.9392812252044678
INFO:root:current mean train loss 3469.350221155957
INFO:root:current train perplexity3.937326669692993
INFO:root:current mean train loss 3475.3527063011443
INFO:root:current train perplexity3.9422383308410645
INFO:root:current mean train loss 3477.2975634220493
INFO:root:current train perplexity3.9409594535827637
INFO:root:current mean train loss 3479.6109419328145
INFO:root:current train perplexity3.9429771900177
INFO:root:current mean train loss 3480.065374187576
INFO:root:current train perplexity3.944540023803711
INFO:root:current mean train loss 3480.393102487443
INFO:root:current train perplexity3.9447214603424072


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.70s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.61s/it]
INFO:root:eval mean loss: 4032.006666251108
INFO:root:eval perplexity: 5.106046199798584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/92

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [3:32:48<4:34:09, 152.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3455.762890625
INFO:root:current train perplexity3.914053201675415
INFO:root:current mean train loss 3468.2196234809026
INFO:root:current train perplexity3.924767255783081
INFO:root:current mean train loss 3473.4333828540557
INFO:root:current train perplexity3.9325201511383057
INFO:root:current mean train loss 3476.062150186567
INFO:root:current train perplexity3.93363881111145
INFO:root:current mean train loss 3479.107263604526
INFO:root:current train perplexity3.937269926071167
INFO:root:current mean train loss 3480.1920419283
INFO:root:current train perplexity3.939438581466675
INFO:root:current mean train loss 3476.1299835445375
INFO:root:current train perplexity3.9343366622924805
INFO:root:current mean train loss 3472.9561001939837
INFO:root:current train perplexity3.932784080505371
INFO:root:current mean train loss 3474.450293553518
INFO:root:current train perplexity3.934384346008301
INFO:root:current mean train loss 3473.456517901905
INFO:root:current train perplexity3.932859420776367


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.18s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.22s/it]
INFO:root:eval mean loss: 4029.114044838763
INFO:root:eval perplexity: 5.100075721740723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/93

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [3:35:04<4:22:40, 147.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3425.431271575218
INFO:root:current train perplexity3.901637315750122
INFO:root:current mean train loss 3466.4076158216785
INFO:root:current train perplexity3.9014151096343994
INFO:root:current mean train loss 3458.5870235741386
INFO:root:current train perplexity3.914027214050293
INFO:root:current mean train loss 3461.4716754168185
INFO:root:current train perplexity3.9172708988189697
INFO:root:current mean train loss 3460.2554631287035
INFO:root:current train perplexity3.916640520095825
INFO:root:current mean train loss 3460.820796285106
INFO:root:current train perplexity3.917296886444092
INFO:root:current mean train loss 3462.43457107188
INFO:root:current train perplexity3.9212028980255127
INFO:root:current mean train loss 3468.0921671932833
INFO:root:current train perplexity3.923909902572632
INFO:root:current mean train loss 3468.74115040916
INFO:root:current train perplexity3.925342321395874
INFO:root:current mean train loss 3469.0777084334404
INFO:root:current train perplexity3.9258029460906982


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.45s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.83s/it]
INFO:root:eval mean loss: 4031.0842562195257
INFO:root:eval perplexity: 5.104140758514404
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/94

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [3:37:08<4:07:59, 140.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3453.947337431066
INFO:root:current train perplexity3.9275119304656982
INFO:root:current mean train loss 3465.1077064362585
INFO:root:current train perplexity3.9162893295288086
INFO:root:current mean train loss 3468.0796073518427
INFO:root:current train perplexity3.922140598297119
INFO:root:current mean train loss 3466.4389537148327
INFO:root:current train perplexity3.9107656478881836
INFO:root:current mean train loss 3463.363078250589
INFO:root:current train perplexity3.9110188484191895
INFO:root:current mean train loss 3465.9264011279206
INFO:root:current train perplexity3.917191982269287
INFO:root:current mean train loss 3464.9969975578438
INFO:root:current train perplexity3.919404983520508
INFO:root:current mean train loss 3465.1028745526796
INFO:root:current train perplexity3.91831374168396
INFO:root:current mean train loss 3465.408261649897
INFO:root:current train perplexity3.9204063415527344
INFO:root:current mean train loss 3466.2904698384923
INFO:root:current train perplexity3.9227635860443115


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.63s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.94s/it]
INFO:root:eval mean loss: 4034.202205576795
INFO:root:eval perplexity: 5.1105804443359375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/95

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [3:39:11<3:56:47, 135.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3428.461628542108
INFO:root:current train perplexity3.865525960922241
INFO:root:current mean train loss 3437.2355680645637
INFO:root:current train perplexity3.868889808654785
INFO:root:current mean train loss 3442.076290646115
INFO:root:current train perplexity3.8797175884246826
INFO:root:current mean train loss 3450.889500865033
INFO:root:current train perplexity3.8906028270721436
INFO:root:current mean train loss 3452.8923541964527
INFO:root:current train perplexity3.8955984115600586
INFO:root:current mean train loss 3456.5664503612757
INFO:root:current train perplexity3.8986549377441406
INFO:root:current mean train loss 3456.6618200368694
INFO:root:current train perplexity3.90236496925354
INFO:root:current mean train loss 3459.5334990530305
INFO:root:current train perplexity3.906336545944214
INFO:root:current mean train loss 3461.718115063846
INFO:root:current train perplexity3.9100122451782227
INFO:root:current mean train loss 3461.8384025820355
INFO:root:current train perplexity3.9114551544189453


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.88s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.37s/it]
INFO:root:eval mean loss: 4034.1336003296765
INFO:root:eval perplexity: 5.110438346862793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/96

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [3:41:16<3:48:44, 131.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3454.4975367304105
INFO:root:current train perplexity3.925506591796875
INFO:root:current mean train loss 3451.918033074476
INFO:root:current train perplexity3.901392698287964
INFO:root:current mean train loss 3458.3656156732795
INFO:root:current train perplexity3.9043588638305664
INFO:root:current mean train loss 3456.263993182689
INFO:root:current train perplexity3.899167060852051
INFO:root:current mean train loss 3454.271433142064
INFO:root:current train perplexity3.8992919921875
INFO:root:current mean train loss 3452.090328586585
INFO:root:current train perplexity3.8995141983032227
INFO:root:current mean train loss 3453.349676724138
INFO:root:current train perplexity3.8998830318450928
INFO:root:current mean train loss 3451.497023203227
INFO:root:current train perplexity3.902182102203369
INFO:root:current mean train loss 3455.148119018977
INFO:root:current train perplexity3.904289960861206
INFO:root:current mean train loss 3454.325352097741
INFO:root:current train perplexity3.9038686752319336


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.69s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.59s/it]
INFO:root:eval mean loss: 4035.248273700687
INFO:root:eval perplexity: 5.1127424240112305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/97

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [3:43:19<3:42:02, 129.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3439.9505143229167
INFO:root:current train perplexity3.906003952026367
INFO:root:current mean train loss 3440.1927566964287
INFO:root:current train perplexity3.892139434814453
INFO:root:current mean train loss 3449.2615864701706
INFO:root:current train perplexity3.886770248413086
INFO:root:current mean train loss 3452.51141796875
INFO:root:current train perplexity3.887275218963623
INFO:root:current mean train loss 3448.981279296875
INFO:root:current train perplexity3.8888845443725586
INFO:root:current mean train loss 3444.274564792799
INFO:root:current train perplexity3.8894834518432617
INFO:root:current mean train loss 3448.573816189236
INFO:root:current train perplexity3.891024112701416
INFO:root:current mean train loss 3447.4187884324597
INFO:root:current train perplexity3.8913180828094482
INFO:root:current mean train loss 3448.899794363839
INFO:root:current train perplexity3.89259672164917
INFO:root:current mean train loss 3447.883478565705
INFO:root:current train perplexity3.8944520950317383


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.89s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.51s/it]
INFO:root:eval mean loss: 4036.881893076795
INFO:root:eval perplexity: 5.116121292114258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/98

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [3:45:23<3:37:20, 127.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3427.665242022779
INFO:root:current train perplexity3.867936134338379
INFO:root:current mean train loss 3428.4229596247437
INFO:root:current train perplexity3.8759658336639404
INFO:root:current mean train loss 3443.788952075972
INFO:root:current train perplexity3.87945294380188
INFO:root:current mean train loss 3445.538729754814
INFO:root:current train perplexity3.878633737564087
INFO:root:current mean train loss 3444.9279315071817
INFO:root:current train perplexity3.880794048309326
INFO:root:current mean train loss 3443.640614112082
INFO:root:current train perplexity3.881291389465332
INFO:root:current mean train loss 3445.590232659224
INFO:root:current train perplexity3.885601758956909
INFO:root:current mean train loss 3442.837992895913
INFO:root:current train perplexity3.8844356536865234
INFO:root:current mean train loss 3444.325158539337
INFO:root:current train perplexity3.8855679035186768
INFO:root:current mean train loss 3445.3888566569176
INFO:root:current train perplexity3.888911485671997


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.62s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.49s/it]
INFO:root:eval mean loss: 4041.3136150820037
INFO:root:eval perplexity: 5.1252970695495605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/99

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [3:47:27<3:33:16, 126.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3408.074495084993
INFO:root:current train perplexity3.8344407081604004
INFO:root:current mean train loss 3419.6664310475294
INFO:root:current train perplexity3.8413047790527344
INFO:root:current mean train loss 3426.4673925445663
INFO:root:current train perplexity3.857024669647217
INFO:root:current mean train loss 3431.698521918958
INFO:root:current train perplexity3.8646128177642822
INFO:root:current mean train loss 3433.3234788696536
INFO:root:current train perplexity3.868060827255249
INFO:root:current mean train loss 3433.9711695120823
INFO:root:current train perplexity3.868387222290039
INFO:root:current mean train loss 3435.272234109307
INFO:root:current train perplexity3.870736598968506
INFO:root:current mean train loss 3436.6779136995297
INFO:root:current train perplexity3.873884439468384
INFO:root:current mean train loss 3435.5596749833403
INFO:root:current train perplexity3.8754234313964844
INFO:root:current mean train loss 3439.184335287115
INFO:root:current train perplexity3.879875659942627


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 115.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 115.00s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.33s/it]
INFO:root:eval mean loss: 4041.10982691988
INFO:root:eval perplexity: 5.124875545501709
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/100

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [3:49:31<3:29:55, 125.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3408.436027758049
INFO:root:current train perplexity3.8338136672973633
INFO:root:current mean train loss 3416.5317137445036
INFO:root:current train perplexity3.8576951026916504
INFO:root:current mean train loss 3420.260655635974
INFO:root:current train perplexity3.860084056854248
INFO:root:current mean train loss 3419.0822148143798
INFO:root:current train perplexity3.8581714630126953
INFO:root:current mean train loss 3423.6957719149236
INFO:root:current train perplexity3.859337568283081
INFO:root:current mean train loss 3426.0628362537823
INFO:root:current train perplexity3.8631317615509033
INFO:root:current mean train loss 3431.7087992612214
INFO:root:current train perplexity3.868252992630005
INFO:root:current mean train loss 3435.640863640586
INFO:root:current train perplexity3.8715579509735107
INFO:root:current mean train loss 3435.294307042547
INFO:root:current train perplexity3.8729922771453857


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.58s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.64s/it]
INFO:root:eval mean loss: 4041.548407372008
INFO:root:eval perplexity: 5.125784397125244
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/101

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [3:51:40<3:29:18, 126.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3368.328927176339
INFO:root:current train perplexity3.816645622253418
INFO:root:current mean train loss 3448.3561076226633
INFO:root:current train perplexity3.863346576690674
INFO:root:current mean train loss 3431.714449822615
INFO:root:current train perplexity3.850673198699951
INFO:root:current mean train loss 3425.293667771529
INFO:root:current train perplexity3.859118700027466
INFO:root:current mean train loss 3430.0023082386365
INFO:root:current train perplexity3.8606629371643066
INFO:root:current mean train loss 3429.02630458734
INFO:root:current train perplexity3.8623738288879395
INFO:root:current mean train loss 3426.915782746216
INFO:root:current train perplexity3.858419418334961
INFO:root:current mean train loss 3426.0517882005834
INFO:root:current train perplexity3.859269618988037
INFO:root:current mean train loss 3427.2864952418295
INFO:root:current train perplexity3.8614132404327393
INFO:root:current mean train loss 3427.3361722195423
INFO:root:current train perplexity3.863557815551758


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 115.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.00s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 4045.273645279255
INFO:root:eval perplexity: 5.133511066436768
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/102

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [3:53:45<3:25:53, 126.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3395.121240234375
INFO:root:current train perplexity3.7931535243988037
INFO:root:current mean train loss 3399.593444293478
INFO:root:current train perplexity3.8061208724975586
INFO:root:current mean train loss 3401.242063726381
INFO:root:current train perplexity3.8206915855407715
INFO:root:current mean train loss 3418.638079737103
INFO:root:current train perplexity3.8391122817993164
INFO:root:current mean train loss 3425.269086502259
INFO:root:current train perplexity3.846003532409668
INFO:root:current mean train loss 3420.33065552943
INFO:root:current train perplexity3.8426992893218994
INFO:root:current mean train loss 3422.507418699187
INFO:root:current train perplexity3.8467519283294678
INFO:root:current mean train loss 3421.0486089106207
INFO:root:current train perplexity3.849661111831665
INFO:root:current mean train loss 3420.9062113568825
INFO:root:current train perplexity3.851879835128784
INFO:root:current mean train loss 3422.0500837815916
INFO:root:current train perplexity3.8544209003448486


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.12s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.93s/it]
INFO:root:eval mean loss: 4042.934123587101
INFO:root:eval perplexity: 5.128657817840576
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/103

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [3:55:48<3:22:18, 125.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3352.695556640625
INFO:root:current train perplexity3.7928807735443115
INFO:root:current mean train loss 3402.5569165237553
INFO:root:current train perplexity3.812278985977173
INFO:root:current mean train loss 3409.226124579596
INFO:root:current train perplexity3.8276209831237793
INFO:root:current mean train loss 3405.636466294988
INFO:root:current train perplexity3.827575206756592
INFO:root:current mean train loss 3405.582967410978
INFO:root:current train perplexity3.8312017917633057
INFO:root:current mean train loss 3410.445332105939
INFO:root:current train perplexity3.840104818344116
INFO:root:current mean train loss 3413.569885743755
INFO:root:current train perplexity3.843987226486206
INFO:root:current mean train loss 3415.5701183356027
INFO:root:current train perplexity3.8476617336273193
INFO:root:current mean train loss 3416.3846784107304
INFO:root:current train perplexity3.8477630615234375
INFO:root:current mean train loss 3417.0224331641894
INFO:root:current train perplexity3.8463735580444336


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.13s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.62s/it]
INFO:root:eval mean loss: 4044.478122575909
INFO:root:eval perplexity: 5.131860256195068
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/104

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [3:57:51<3:19:31, 124.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3358.4435090095767
INFO:root:current train perplexity3.788482189178467
INFO:root:current mean train loss 3384.064745721016
INFO:root:current train perplexity3.808640956878662
INFO:root:current mean train loss 3382.028700791396
INFO:root:current train perplexity3.81752872467041
INFO:root:current mean train loss 3392.5436797819107
INFO:root:current train perplexity3.8279850482940674
INFO:root:current mean train loss 3393.714425142293
INFO:root:current train perplexity3.8273749351501465
INFO:root:current mean train loss 3400.3776386498057
INFO:root:current train perplexity3.832620620727539
INFO:root:current mean train loss 3406.691033268126
INFO:root:current train perplexity3.8370790481567383
INFO:root:current mean train loss 3409.0494499989313
INFO:root:current train perplexity3.839221715927124
INFO:root:current mean train loss 3414.5718381585625
INFO:root:current train perplexity3.8442800045013428
INFO:root:current mean train loss 3414.6108272564784
INFO:root:current train perplexity3.842825412750244


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.84s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.64s/it]
INFO:root:eval mean loss: 4045.8211263020835
INFO:root:eval perplexity: 5.134648323059082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/105

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [3:59:56<3:17:18, 124.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3396.337070562901
INFO:root:current train perplexity3.8362557888031006
INFO:root:current mean train loss 3414.8827211668167
INFO:root:current train perplexity3.8373751640319824
INFO:root:current mean train loss 3408.6964882567336
INFO:root:current train perplexity3.8370699882507324
INFO:root:current mean train loss 3417.777072962758
INFO:root:current train perplexity3.838439702987671
INFO:root:current mean train loss 3413.4459537167213
INFO:root:current train perplexity3.834439754486084
INFO:root:current mean train loss 3412.086053455473
INFO:root:current train perplexity3.833935260772705
INFO:root:current mean train loss 3415.0805045114435
INFO:root:current train perplexity3.835800886154175
INFO:root:current mean train loss 3416.2560751041315
INFO:root:current train perplexity3.8378920555114746
INFO:root:current mean train loss 3413.2050659034194
INFO:root:current train perplexity3.8363380432128906
INFO:root:current mean train loss 3412.122748914237
INFO:root:current train perplexity3.837076425552368


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.81s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.27s/it]
INFO:root:eval mean loss: 4046.5331234762853
INFO:root:eval perplexity: 5.13612699508667
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/106

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [4:02:49<3:38:13, 139.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3342.8741688829787
INFO:root:current train perplexity3.792952299118042
INFO:root:current mean train loss 3385.4961269664113
INFO:root:current train perplexity3.8170738220214844
INFO:root:current mean train loss 3386.850341796875
INFO:root:current train perplexity3.8128716945648193
INFO:root:current mean train loss 3390.301613579566
INFO:root:current train perplexity3.818171501159668
INFO:root:current mean train loss 3396.2433994643106
INFO:root:current train perplexity3.8171966075897217
INFO:root:current mean train loss 3402.2422428444925
INFO:root:current train perplexity3.8216350078582764
INFO:root:current mean train loss 3404.400038187065
INFO:root:current train perplexity3.8238370418548584
INFO:root:current mean train loss 3402.9824483480797
INFO:root:current train perplexity3.8241095542907715
INFO:root:current mean train loss 3406.0247867588732
INFO:root:current train perplexity3.829345941543579
INFO:root:current mean train loss 3405.6298090804844
INFO:root:current train perplexity3.829803466796875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.68s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.96s/it]
INFO:root:eval mean loss: 4051.3650283272386
INFO:root:eval perplexity: 5.146172523498535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/107

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [4:06:10<4:04:34, 157.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3385.4363503196023
INFO:root:current train perplexity3.8053855895996094
INFO:root:current mean train loss 3391.1719616305445
INFO:root:current train perplexity3.8040153980255127
INFO:root:current mean train loss 3384.286555989583
INFO:root:current train perplexity3.8055529594421387
INFO:root:current mean train loss 3394.4696536641727
INFO:root:current train perplexity3.8123888969421387
INFO:root:current mean train loss 3398.0829144488325
INFO:root:current train perplexity3.8114192485809326
INFO:root:current mean train loss 3397.346319415118
INFO:root:current train perplexity3.816082000732422
INFO:root:current mean train loss 3398.503406786737
INFO:root:current train perplexity3.820136785507202
INFO:root:current mean train loss 3401.2377674229097
INFO:root:current train perplexity3.8193533420562744
INFO:root:current mean train loss 3400.5247532894737
INFO:root:current train perplexity3.819314479827881
INFO:root:current mean train loss 3403.5984190935865
INFO:root:current train perplexity3.8245978355407715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.48s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.01s/it]
INFO:root:eval mean loss: 4052.5578578651375
INFO:root:eval perplexity: 5.148653984069824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/108

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [4:08:25<3:51:17, 150.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3347.3658156622023
INFO:root:current train perplexity3.8023927211761475
INFO:root:current mean train loss 3364.854632980253
INFO:root:current train perplexity3.804471254348755
INFO:root:current mean train loss 3373.6179189935838
INFO:root:current train perplexity3.801419258117676
INFO:root:current mean train loss 3383.403937053418
INFO:root:current train perplexity3.8104910850524902
INFO:root:current mean train loss 3387.932789615112
INFO:root:current train perplexity3.8056528568267822
INFO:root:current mean train loss 3391.863604313527
INFO:root:current train perplexity3.8095602989196777
INFO:root:current mean train loss 3394.6363309972426
INFO:root:current train perplexity3.810650587081909
INFO:root:current mean train loss 3394.5986209734397
INFO:root:current train perplexity3.810188055038452
INFO:root:current mean train loss 3395.141812321209
INFO:root:current train perplexity3.813322067260742
INFO:root:current mean train loss 3397.111784462617
INFO:root:current train perplexity3.8165764808654785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 115.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 115.00s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.56s/it]
INFO:root:eval mean loss: 4050.51566136137
INFO:root:eval perplexity: 5.14440393447876
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/109

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [4:10:37<3:40:11, 145.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3369.759394256162
INFO:root:current train perplexity3.7752790451049805
INFO:root:current mean train loss 3369.527032506396
INFO:root:current train perplexity3.7903802394866943
INFO:root:current mean train loss 3373.506177388434
INFO:root:current train perplexity3.794797897338867
INFO:root:current mean train loss 3378.873369324882
INFO:root:current train perplexity3.7917511463165283
INFO:root:current mean train loss 3381.38166695694
INFO:root:current train perplexity3.7980618476867676
INFO:root:current mean train loss 3385.659520030648
INFO:root:current train perplexity3.804987668991089
INFO:root:current mean train loss 3387.21069918091
INFO:root:current train perplexity3.8064894676208496
INFO:root:current mean train loss 3389.364874972134
INFO:root:current train perplexity3.807739734649658
INFO:root:current mean train loss 3390.359136745659
INFO:root:current train perplexity3.8082263469696045
INFO:root:current mean train loss 3392.523794533664
INFO:root:current train perplexity3.8108177185058594


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.13s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.02s/it]
INFO:root:eval mean loss: 4051.1081923897386
INFO:root:eval perplexity: 5.145637512207031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/110

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [4:13:57<4:02:40, 161.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3379.4415329558938
INFO:root:current train perplexity3.781137228012085
INFO:root:current mean train loss 3380.562048544431
INFO:root:current train perplexity3.779296875
INFO:root:current mean train loss 3388.4144510248657
INFO:root:current train perplexity3.7939155101776123
INFO:root:current mean train loss 3390.4595216132093
INFO:root:current train perplexity3.7988414764404297
INFO:root:current mean train loss 3391.7496743092706
INFO:root:current train perplexity3.7958905696868896
INFO:root:current mean train loss 3387.40154723594
INFO:root:current train perplexity3.7915241718292236
INFO:root:current mean train loss 3388.9560464176407
INFO:root:current train perplexity3.794276714324951
INFO:root:current mean train loss 3386.0923058408216
INFO:root:current train perplexity3.7960922718048096
INFO:root:current mean train loss 3386.325276137212
INFO:root:current train perplexity3.800341844558716
INFO:root:current mean train loss 3388.1062974316105
INFO:root:current train perplexity3.8030710220336914


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.41s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 4052.4612543633643
INFO:root:eval perplexity: 5.148453712463379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/111

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [4:17:14<4:15:39, 172.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3388.6792188622485
INFO:root:current train perplexity3.781780481338501
INFO:root:current mean train loss 3383.564297762784
INFO:root:current train perplexity3.7834362983703613
INFO:root:current mean train loss 3383.1080062813044
INFO:root:current train perplexity3.7902817726135254
INFO:root:current mean train loss 3379.017841191255
INFO:root:current train perplexity3.7844173908233643
INFO:root:current mean train loss 3378.4636556323794
INFO:root:current train perplexity3.788262128829956
INFO:root:current mean train loss 3378.652713080281
INFO:root:current train perplexity3.7912724018096924
INFO:root:current mean train loss 3382.8485038124318
INFO:root:current train perplexity3.795269727706909
INFO:root:current mean train loss 3381.1202418946555
INFO:root:current train perplexity3.7959585189819336
INFO:root:current mean train loss 3383.046869219895
INFO:root:current train perplexity3.796682119369507
INFO:root:current mean train loss 3383.921409970238
INFO:root:current train perplexity3.795971632003784


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.18s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 4056.725982449579
INFO:root:eval perplexity: 5.157340049743652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/112

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [4:19:19<3:51:43, 157.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3362.5726690995066
INFO:root:current train perplexity3.768777370452881
INFO:root:current mean train loss 3352.063824619391
INFO:root:current train perplexity3.775150775909424
INFO:root:current mean train loss 3358.533530852754
INFO:root:current train perplexity3.7735209465026855
INFO:root:current mean train loss 3368.222950454905
INFO:root:current train perplexity3.7818522453308105
INFO:root:current mean train loss 3370.3281989820075
INFO:root:current train perplexity3.7840218544006348
INFO:root:current mean train loss 3368.6486722032564
INFO:root:current train perplexity3.7819411754608154
INFO:root:current mean train loss 3373.209552748426
INFO:root:current train perplexity3.7863998413085938
INFO:root:current mean train loss 3376.347731795401
INFO:root:current train perplexity3.788719654083252
INFO:root:current mean train loss 3378.1885349380236
INFO:root:current train perplexity3.791288137435913


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.41s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.26s/it]
INFO:root:eval mean loss: 4057.106859139517
INFO:root:eval perplexity: 5.158134460449219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/113

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [4:21:22<3:34:08, 147.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3302.7156575520835
INFO:root:current train perplexity3.806731700897217
INFO:root:current mean train loss 3349.5610967839807
INFO:root:current train perplexity3.7538042068481445
INFO:root:current mean train loss 3370.7829529710593
INFO:root:current train perplexity3.7790896892547607
INFO:root:current mean train loss 3367.226987127424
INFO:root:current train perplexity3.7760441303253174
INFO:root:current mean train loss 3366.7424498148653
INFO:root:current train perplexity3.7770333290100098
INFO:root:current mean train loss 3371.8499238941354
INFO:root:current train perplexity3.7816684246063232
INFO:root:current mean train loss 3372.9338395101317
INFO:root:current train perplexity3.7819948196411133
INFO:root:current mean train loss 3373.866761035295
INFO:root:current train perplexity3.7831215858459473
INFO:root:current mean train loss 3377.4181134709684
INFO:root:current train perplexity3.786558151245117
INFO:root:current mean train loss 3376.1277244795992
INFO:root:current train perplexity3.783829689025879


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.07s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.15s/it]
INFO:root:eval mean loss: 4057.986572265625
INFO:root:eval perplexity: 5.159969329833984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/114

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [4:23:27<3:21:32, 140.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3341.0463423295455
INFO:root:current train perplexity3.770472764968872
INFO:root:current mean train loss 3360.341733090512
INFO:root:current train perplexity3.783135175704956
INFO:root:current mean train loss 3359.555625879369
INFO:root:current train perplexity3.781148672103882
INFO:root:current mean train loss 3367.955552275924
INFO:root:current train perplexity3.7798335552215576
INFO:root:current mean train loss 3368.8414244268934
INFO:root:current train perplexity3.7786247730255127
INFO:root:current mean train loss 3367.206202796294
INFO:root:current train perplexity3.7774946689605713
INFO:root:current mean train loss 3371.9769888470487
INFO:root:current train perplexity3.775606155395508
INFO:root:current mean train loss 3370.4631048918777
INFO:root:current train perplexity3.7755606174468994
INFO:root:current mean train loss 3368.7466283908757
INFO:root:current train perplexity3.7746002674102783
INFO:root:current mean train loss 3370.58662704317
INFO:root:current train perplexity3.776376247406006


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.78s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.39s/it]
INFO:root:eval mean loss: 4058.9883020279253
INFO:root:eval perplexity: 5.162059783935547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/115

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [4:25:32<3:12:37, 135.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3299.459292763158
INFO:root:current train perplexity3.7005796432495117
INFO:root:current mean train loss 3326.4981330422793
INFO:root:current train perplexity3.7419698238372803
INFO:root:current mean train loss 3345.782771698416
INFO:root:current train perplexity3.7505128383636475
INFO:root:current mean train loss 3353.5439759257447
INFO:root:current train perplexity3.7559285163879395
INFO:root:current mean train loss 3356.1383280970317
INFO:root:current train perplexity3.756608724594116
INFO:root:current mean train loss 3359.3766807600255
INFO:root:current train perplexity3.757648229598999
INFO:root:current mean train loss 3361.6335153410237
INFO:root:current train perplexity3.7621941566467285
INFO:root:current mean train loss 3366.115914165725
INFO:root:current train perplexity3.7657294273376465
INFO:root:current mean train loss 3366.8140471182464
INFO:root:current train perplexity3.7670786380767822
INFO:root:current mean train loss 3365.267980332733
INFO:root:current train perplexity3.769408702850342


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.37s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.61s/it]
INFO:root:eval mean loss: 4061.2458738502883
INFO:root:eval perplexity: 5.166774749755859
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/116

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [4:27:36<3:05:18, 132.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3372.085467303241
INFO:root:current train perplexity3.7749485969543457
INFO:root:current mean train loss 3367.1618575449065
INFO:root:current train perplexity3.7594892978668213
INFO:root:current mean train loss 3364.9463353094025
INFO:root:current train perplexity3.7553622722625732
INFO:root:current mean train loss 3359.0343469275613
INFO:root:current train perplexity3.754617691040039
INFO:root:current mean train loss 3363.0012058374195
INFO:root:current train perplexity3.7602717876434326
INFO:root:current mean train loss 3362.598249692392
INFO:root:current train perplexity3.759298801422119
INFO:root:current mean train loss 3363.80841697194
INFO:root:current train perplexity3.760800361633301
INFO:root:current mean train loss 3365.045421574106
INFO:root:current train perplexity3.764413356781006
INFO:root:current mean train loss 3365.0494563369107
INFO:root:current train perplexity3.765428066253662
INFO:root:current mean train loss 3366.0269294747
INFO:root:current train perplexity3.76941180229187


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.98s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.33s/it]
INFO:root:eval mean loss: 4062.154381718196
INFO:root:eval perplexity: 5.168672561645508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/117

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [4:29:40<2:59:43, 129.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3354.8452915736607
INFO:root:current train perplexity3.736396074295044
INFO:root:current mean train loss 3354.0746473524305
INFO:root:current train perplexity3.738795518875122
INFO:root:current mean train loss 3351.356528424202
INFO:root:current train perplexity3.7463314533233643
INFO:root:current mean train loss 3358.631538596082
INFO:root:current train perplexity3.7533204555511475
INFO:root:current mean train loss 3360.4873512706536
INFO:root:current train perplexity3.7538962364196777
INFO:root:current mean train loss 3360.861650755695
INFO:root:current train perplexity3.755855083465576
INFO:root:current mean train loss 3360.156886687992
INFO:root:current train perplexity3.7588162422180176
INFO:root:current mean train loss 3361.6207482993195
INFO:root:current train perplexity3.759002208709717
INFO:root:current mean train loss 3361.2904355351798
INFO:root:current train perplexity3.7603251934051514
INFO:root:current mean train loss 3361.6743858622995
INFO:root:current train perplexity3.7629826068878174


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.99s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.59s/it]
INFO:root:eval mean loss: 4062.5391767785904
INFO:root:eval perplexity: 5.1694769859313965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/118

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [4:31:44<2:55:19, 128.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3346.6491301780525
INFO:root:current train perplexity3.7350881099700928
INFO:root:current mean train loss 3336.9013825529937
INFO:root:current train perplexity3.724483013153076
INFO:root:current mean train loss 3337.661706492734
INFO:root:current train perplexity3.7314887046813965
INFO:root:current mean train loss 3343.4509441053206
INFO:root:current train perplexity3.7363383769989014
INFO:root:current mean train loss 3350.5604763332394
INFO:root:current train perplexity3.739631175994873
INFO:root:current mean train loss 3350.7981892229222
INFO:root:current train perplexity3.740468978881836
INFO:root:current mean train loss 3353.6673741555696
INFO:root:current train perplexity3.7461986541748047
INFO:root:current mean train loss 3355.1290557573816
INFO:root:current train perplexity3.749493360519409
INFO:root:current mean train loss 3354.235536333222
INFO:root:current train perplexity3.753941535949707
INFO:root:current mean train loss 3354.937530032145
INFO:root:current train perplexity3.7535061836242676


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.79s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.76s/it]
INFO:root:eval mean loss: 4064.0905571254434
INFO:root:eval perplexity: 5.172720909118652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/119

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [4:33:49<2:51:38, 127.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3354.2493489583335
INFO:root:current train perplexity3.745596408843994
INFO:root:current mean train loss 3339.3987042761796
INFO:root:current train perplexity3.731375217437744
INFO:root:current mean train loss 3338.105428870456
INFO:root:current train perplexity3.7369489669799805
INFO:root:current mean train loss 3335.274748625579
INFO:root:current train perplexity3.739025354385376
INFO:root:current mean train loss 3337.489750424404
INFO:root:current train perplexity3.739513635635376
INFO:root:current mean train loss 3342.544497841283
INFO:root:current train perplexity3.7416553497314453
INFO:root:current mean train loss 3346.8494964927754
INFO:root:current train perplexity3.744736909866333
INFO:root:current mean train loss 3351.432640918879
INFO:root:current train perplexity3.7490530014038086
INFO:root:current mean train loss 3351.135498333762
INFO:root:current train perplexity3.749880790710449
INFO:root:current mean train loss 3352.7152557854397
INFO:root:current train perplexity3.7504422664642334


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.44s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.81s/it]
INFO:root:eval mean loss: 4066.6194297844636
INFO:root:eval perplexity: 5.178013324737549
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/120

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [4:35:54<2:48:45, 126.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3332.648205773305
INFO:root:current train perplexity3.7169644832611084
INFO:root:current mean train loss 3329.724758316136
INFO:root:current train perplexity3.7194137573242188
INFO:root:current mean train loss 3330.1707014282697
INFO:root:current train perplexity3.7157297134399414
INFO:root:current mean train loss 3337.6856332422963
INFO:root:current train perplexity3.7281734943389893
INFO:root:current mean train loss 3339.898388033599
INFO:root:current train perplexity3.732788324356079
INFO:root:current mean train loss 3337.6689348306127
INFO:root:current train perplexity3.7351250648498535
INFO:root:current mean train loss 3343.826001458175
INFO:root:current train perplexity3.740000009536743
INFO:root:current mean train loss 3346.270059738863
INFO:root:current train perplexity3.7425694465637207
INFO:root:current mean train loss 3348.164888144372
INFO:root:current train perplexity3.743311882019043
INFO:root:current mean train loss 3347.610712045425
INFO:root:current train perplexity3.7426598072052


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.80s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.55s/it]
INFO:root:eval mean loss: 4066.008539727394
INFO:root:eval perplexity: 5.176734924316406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/121

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [4:37:58<2:45:46, 125.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3330.658461841185
INFO:root:current train perplexity3.7324469089508057
INFO:root:current mean train loss 3334.845356649981
INFO:root:current train perplexity3.7260310649871826
INFO:root:current mean train loss 3329.298307840297
INFO:root:current train perplexity3.7171032428741455
INFO:root:current mean train loss 3330.319653253789
INFO:root:current train perplexity3.722057342529297
INFO:root:current mean train loss 3334.1545112168765
INFO:root:current train perplexity3.7211217880249023
INFO:root:current mean train loss 3335.294647593557
INFO:root:current train perplexity3.724213123321533
INFO:root:current mean train loss 3339.445466963784
INFO:root:current train perplexity3.7279696464538574
INFO:root:current mean train loss 3339.214814784163
INFO:root:current train perplexity3.7289159297943115
INFO:root:current mean train loss 3341.62419126658
INFO:root:current train perplexity3.7313997745513916
INFO:root:current mean train loss 3344.528348336915
INFO:root:current train perplexity3.7367098331451416


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.43s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.28s/it]
INFO:root:eval mean loss: 4065.166020819481
INFO:root:eval perplexity: 5.174971580505371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/122

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [4:40:03<2:43:09, 125.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3337.1704296875
INFO:root:current train perplexity3.7228455543518066
INFO:root:current mean train loss 3323.633330078125
INFO:root:current train perplexity3.7277181148529053
INFO:root:current mean train loss 3331.936552734375
INFO:root:current train perplexity3.729346990585327
INFO:root:current mean train loss 3333.730919921875
INFO:root:current train perplexity3.727301597595215
INFO:root:current mean train loss 3337.74873098273
INFO:root:current train perplexity3.7303590774536133
INFO:root:current mean train loss 3338.8013493546196
INFO:root:current train perplexity3.728241443634033
INFO:root:current mean train loss 3339.825651041667
INFO:root:current train perplexity3.7291259765625
INFO:root:current mean train loss 3340.9957377772175
INFO:root:current train perplexity3.730818033218384
INFO:root:current mean train loss 3339.59294140625
INFO:root:current train perplexity3.7300527095794678
INFO:root:current mean train loss 3339.4658415965546
INFO:root:current train perplexity3.7305102348327637


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.66s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.41s/it]
INFO:root:eval mean loss: 4066.1885042664007
INFO:root:eval perplexity: 5.177112102508545
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/123

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [4:42:07<2:40:29, 125.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3319.478421498494
INFO:root:current train perplexity3.7193470001220703
INFO:root:current mean train loss 3309.5047467341187
INFO:root:current train perplexity3.7108349800109863
INFO:root:current mean train loss 3316.2477552865503
INFO:root:current train perplexity3.7104616165161133
INFO:root:current mean train loss 3325.0394863995184
INFO:root:current train perplexity3.718188524246216
INFO:root:current mean train loss 3328.4275144967974
INFO:root:current train perplexity3.724281072616577
INFO:root:current mean train loss 3337.7016421493086
INFO:root:current train perplexity3.726637840270996
INFO:root:current mean train loss 3339.2152970008237
INFO:root:current train perplexity3.7270021438598633
INFO:root:current mean train loss 3337.0742125139686
INFO:root:current train perplexity3.723534345626831
INFO:root:current mean train loss 3337.038161695746
INFO:root:current train perplexity3.725398302078247
INFO:root:current mean train loss 3337.0317186605894
INFO:root:current train perplexity3.726555347442627


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.72s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.41s/it]
INFO:root:eval mean loss: 4072.442827806405
INFO:root:eval perplexity: 5.190221309661865
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/124

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [4:45:22<3:04:59, 146.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3299.964827652816
INFO:root:current train perplexity3.6645867824554443
INFO:root:current mean train loss 3326.690314647415
INFO:root:current train perplexity3.7060184478759766
INFO:root:current mean train loss 3329.811003275344
INFO:root:current train perplexity3.7097980976104736
INFO:root:current mean train loss 3332.069942854859
INFO:root:current train perplexity3.7106614112854004
INFO:root:current mean train loss 3330.4673299070773
INFO:root:current train perplexity3.7110538482666016
INFO:root:current mean train loss 3332.9103590808745
INFO:root:current train perplexity3.716747283935547
INFO:root:current mean train loss 3334.677728368646
INFO:root:current train perplexity3.7186837196350098
INFO:root:current mean train loss 3337.2484916368717
INFO:root:current train perplexity3.719708204269409
INFO:root:current mean train loss 3335.5078253783495
INFO:root:current train perplexity3.722447395324707
INFO:root:current mean train loss 3335.050335835015
INFO:root:current train perplexity3.72373104095459


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.23s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.86s/it]
INFO:root:eval mean loss: 4070.5176577737147
INFO:root:eval perplexity: 5.186182498931885
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/125

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [4:47:37<2:58:19, 142.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3327.7205403645835
INFO:root:current train perplexity3.7057533264160156
INFO:root:current mean train loss 3319.338021896592
INFO:root:current train perplexity3.7085087299346924
INFO:root:current mean train loss 3323.3297498824204
INFO:root:current train perplexity3.710712432861328
INFO:root:current mean train loss 3323.2762221716403
INFO:root:current train perplexity3.7099294662475586
INFO:root:current mean train loss 3323.9610510082666
INFO:root:current train perplexity3.709026575088501
INFO:root:current mean train loss 3325.750403504539
INFO:root:current train perplexity3.708604335784912
INFO:root:current mean train loss 3325.063095507533
INFO:root:current train perplexity3.7098755836486816
INFO:root:current mean train loss 3328.412053152378
INFO:root:current train perplexity3.7126362323760986
INFO:root:current mean train loss 3330.1046135788897
INFO:root:current train perplexity3.7164859771728516


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.07s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.95s/it]
INFO:root:eval mean loss: 4072.4672037760415
INFO:root:eval perplexity: 5.190272331237793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/126

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [4:50:01<2:56:29, 143.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3313.942557198661
INFO:root:current train perplexity3.7372310161590576
INFO:root:current mean train loss 3312.792418863172
INFO:root:current train perplexity3.6949284076690674
INFO:root:current mean train loss 3318.4140955238527
INFO:root:current train perplexity3.6973588466644287
INFO:root:current mean train loss 3319.286016706535
INFO:root:current train perplexity3.7004644870758057
INFO:root:current mean train loss 3312.699120373925
INFO:root:current train perplexity3.7008512020111084
INFO:root:current mean train loss 3317.4894552437745
INFO:root:current train perplexity3.704436779022217
INFO:root:current mean train loss 3319.835815228583
INFO:root:current train perplexity3.7042243480682373
INFO:root:current mean train loss 3324.7590563395065
INFO:root:current train perplexity3.709787130355835
INFO:root:current mean train loss 3325.555183646995
INFO:root:current train perplexity3.710216999053955
INFO:root:current mean train loss 3325.994688393657
INFO:root:current train perplexity3.7093522548675537


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.95s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.66s/it]
INFO:root:eval mean loss: 4074.353117381427
INFO:root:eval perplexity: 5.19423246383667
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/127

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [4:52:08<2:48:25, 138.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3298.930029296875
INFO:root:current train perplexity3.737874746322632
INFO:root:current mean train loss 3307.872265625
INFO:root:current train perplexity3.7210910320281982
INFO:root:current mean train loss 3311.5010980650436
INFO:root:current train perplexity3.714996337890625
INFO:root:current mean train loss 3316.4532645089284
INFO:root:current train perplexity3.7068915367126465
INFO:root:current mean train loss 3318.1311682275978
INFO:root:current train perplexity3.704155445098877
INFO:root:current mean train loss 3317.0078689130764
INFO:root:current train perplexity3.704378366470337
INFO:root:current mean train loss 3318.3754211922
INFO:root:current train perplexity3.7022933959960938
INFO:root:current mean train loss 3319.2948897781907
INFO:root:current train perplexity3.70312237739563
INFO:root:current mean train loss 3319.2518599621358
INFO:root:current train perplexity3.702378511428833
INFO:root:current mean train loss 3321.340663422131
INFO:root:current train perplexity3.705181360244751


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.57s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.14s/it]
INFO:root:eval mean loss: 4078.3217911957004
INFO:root:eval perplexity: 5.202574253082275
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/128

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [4:54:11<2:40:25, 133.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3278.538223930027
INFO:root:current train perplexity3.6904120445251465
INFO:root:current mean train loss 3320.55839724657
INFO:root:current train perplexity3.6957712173461914
INFO:root:current mean train loss 3317.966276844521
INFO:root:current train perplexity3.6946327686309814
INFO:root:current mean train loss 3319.9185658741294
INFO:root:current train perplexity3.704059600830078
INFO:root:current mean train loss 3317.2041281120714
INFO:root:current train perplexity3.697112560272217
INFO:root:current mean train loss 3316.3479195297564
INFO:root:current train perplexity3.6997361183166504
INFO:root:current mean train loss 3317.751458573686
INFO:root:current train perplexity3.701045513153076
INFO:root:current mean train loss 3318.95139001448
INFO:root:current train perplexity3.701979160308838
INFO:root:current mean train loss 3317.1778996074763
INFO:root:current train perplexity3.699873685836792
INFO:root:current mean train loss 3318.3612117416033
INFO:root:current train perplexity3.700148582458496


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.30s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.37s/it]
INFO:root:eval mean loss: 4076.732967295545
INFO:root:eval perplexity: 5.199233531951904
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/129

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [4:56:16<2:34:57, 130.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3317.0085370463707
INFO:root:current train perplexity3.667964458465576
INFO:root:current mean train loss 3304.937190630964
INFO:root:current train perplexity3.6827220916748047
INFO:root:current mean train loss 3319.5385530810336
INFO:root:current train perplexity3.697892189025879
INFO:root:current mean train loss 3318.092074206949
INFO:root:current train perplexity3.6963911056518555
INFO:root:current mean train loss 3314.9388164334396
INFO:root:current train perplexity3.6971561908721924
INFO:root:current mean train loss 3318.1510310918375
INFO:root:current train perplexity3.7021191120147705
INFO:root:current mean train loss 3316.519750241432
INFO:root:current train perplexity3.697190523147583
INFO:root:current mean train loss 3318.3146752228326
INFO:root:current train perplexity3.6979331970214844
INFO:root:current mean train loss 3315.3465468938025
INFO:root:current train perplexity3.695831537246704
INFO:root:current mean train loss 3314.935256056576
INFO:root:current train perplexity3.6948935985565186


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.70s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.51s/it]
INFO:root:eval mean loss: 4078.322847406915
INFO:root:eval perplexity: 5.202576160430908
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/130

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [4:58:19<2:30:02, 128.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3313.7518842648237
INFO:root:current train perplexity3.6906890869140625
INFO:root:current mean train loss 3314.8833359093974
INFO:root:current train perplexity3.694910764694214
INFO:root:current mean train loss 3310.3240910613886
INFO:root:current train perplexity3.684727668762207
INFO:root:current mean train loss 3311.946080210638
INFO:root:current train perplexity3.6870384216308594
INFO:root:current mean train loss 3312.017372913404
INFO:root:current train perplexity3.689744710922241
INFO:root:current mean train loss 3305.880044516031
INFO:root:current train perplexity3.687072515487671
INFO:root:current mean train loss 3305.303155030443
INFO:root:current train perplexity3.686671733856201
INFO:root:current mean train loss 3305.9488378377664
INFO:root:current train perplexity3.6851062774658203
INFO:root:current mean train loss 3309.9946903051436
INFO:root:current train perplexity3.6878695487976074
INFO:root:current mean train loss 3310.5036595093684
INFO:root:current train perplexity3.689222574234009


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.85s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.58s/it]
INFO:root:eval mean loss: 4075.861681349734
INFO:root:eval perplexity: 5.197401523590088
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/131

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [5:00:22<2:26:06, 127.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3271.894463721742
INFO:root:current train perplexity3.678746223449707
INFO:root:current mean train loss 3302.0834030877977
INFO:root:current train perplexity3.6724607944488525
INFO:root:current mean train loss 3303.0137203077556
INFO:root:current train perplexity3.6831552982330322
INFO:root:current mean train loss 3300.5259774067904
INFO:root:current train perplexity3.674349546432495
INFO:root:current mean train loss 3302.67180181243
INFO:root:current train perplexity3.675231695175171
INFO:root:current mean train loss 3303.741291722606
INFO:root:current train perplexity3.6766676902770996
INFO:root:current mean train loss 3304.5472119668902
INFO:root:current train perplexity3.6800029277801514
INFO:root:current mean train loss 3305.468464679029
INFO:root:current train perplexity3.681553602218628
INFO:root:current mean train loss 3305.1969413532133
INFO:root:current train perplexity3.6815574169158936
INFO:root:current mean train loss 3306.893646723617
INFO:root:current train perplexity3.6828384399414062


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.09s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.06s/it]
INFO:root:eval mean loss: 4076.74993593473
INFO:root:eval perplexity: 5.199267864227295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/132

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [5:02:25<2:22:37, 125.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3283.9617542613637
INFO:root:current train perplexity3.673175811767578
INFO:root:current mean train loss 3281.407543157762
INFO:root:current train perplexity3.67051362991333
INFO:root:current mean train loss 3283.466046262255
INFO:root:current train perplexity3.673468828201294
INFO:root:current mean train loss 3285.4754236355634
INFO:root:current train perplexity3.668321132659912
INFO:root:current mean train loss 3290.446677541209
INFO:root:current train perplexity3.6687514781951904
INFO:root:current mean train loss 3293.8260592623874
INFO:root:current train perplexity3.6706793308258057
INFO:root:current mean train loss 3296.336290851622
INFO:root:current train perplexity3.674791097640991
INFO:root:current mean train loss 3298.642065268005
INFO:root:current train perplexity3.6762895584106445
INFO:root:current mean train loss 3301.784317605537
INFO:root:current train perplexity3.677663803100586
INFO:root:current mean train loss 3304.0090689933736
INFO:root:current train perplexity3.6804332733154297


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.74s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.22s/it]
INFO:root:eval mean loss: 4081.2840134640956
INFO:root:eval perplexity: 5.208810329437256
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/133

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [5:04:30<2:20:12, 125.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3290.2249581473216
INFO:root:current train perplexity3.6756935119628906
INFO:root:current mean train loss 3285.5431424942485
INFO:root:current train perplexity3.664897918701172
INFO:root:current mean train loss 3294.2890615717088
INFO:root:current train perplexity3.6750197410583496
INFO:root:current mean train loss 3298.2707189975035
INFO:root:current train perplexity3.67828369140625
INFO:root:current mean train loss 3299.7186324117506
INFO:root:current train perplexity3.676166296005249
INFO:root:current mean train loss 3306.7493287216917
INFO:root:current train perplexity3.67889404296875
INFO:root:current mean train loss 3303.3151100584464
INFO:root:current train perplexity3.674936056137085
INFO:root:current mean train loss 3301.3215050453596
INFO:root:current train perplexity3.67358136177063
INFO:root:current mean train loss 3301.6783369468785
INFO:root:current train perplexity3.675045967102051
INFO:root:current mean train loss 3304.032266872323
INFO:root:current train perplexity3.678074836730957


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.91s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.22s/it]
INFO:root:eval mean loss: 4083.300183884641
INFO:root:eval perplexity: 5.213059425354004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/134

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [5:06:33<2:17:16, 124.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3296.321464431118
INFO:root:current train perplexity3.6688430309295654
INFO:root:current mean train loss 3280.1149474026865
INFO:root:current train perplexity3.6479878425598145
INFO:root:current mean train loss 3282.6715389688075
INFO:root:current train perplexity3.652827262878418
INFO:root:current mean train loss 3287.5875879169475
INFO:root:current train perplexity3.6588406562805176
INFO:root:current mean train loss 3292.346523665572
INFO:root:current train perplexity3.663994073867798
INFO:root:current mean train loss 3298.4650216177756
INFO:root:current train perplexity3.6669654846191406
INFO:root:current mean train loss 3302.4933216077916
INFO:root:current train perplexity3.6735501289367676
INFO:root:current mean train loss 3300.248953773508
INFO:root:current train perplexity3.6719648838043213
INFO:root:current mean train loss 3301.017254659694
INFO:root:current train perplexity3.673466920852661
INFO:root:current mean train loss 3299.801512163282
INFO:root:current train perplexity3.672421455383301


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.51s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.72s/it]
INFO:root:eval mean loss: 4082.20748316988
INFO:root:eval perplexity: 5.210755825042725
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/135

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [5:08:37<2:14:59, 124.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3295.9821097458466
INFO:root:current train perplexity3.6568307876586914
INFO:root:current mean train loss 3286.689672715171
INFO:root:current train perplexity3.6663362979888916
INFO:root:current mean train loss 3290.0186903211807
INFO:root:current train perplexity3.6661763191223145
INFO:root:current mean train loss 3294.811881596306
INFO:root:current train perplexity3.6681466102600098
INFO:root:current mean train loss 3297.6670834216793
INFO:root:current train perplexity3.669687032699585
INFO:root:current mean train loss 3299.3105675362963
INFO:root:current train perplexity3.6698813438415527
INFO:root:current mean train loss 3302.2029898057804
INFO:root:current train perplexity3.670430898666382
INFO:root:current mean train loss 3301.54254314927
INFO:root:current train perplexity3.668428659439087
INFO:root:current mean train loss 3300.1999061766746
INFO:root:current train perplexity3.6685564517974854
INFO:root:current mean train loss 3297.1475941051135
INFO:root:current train perplexity3.668034791946411


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.99s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.19s/it]
INFO:root:eval mean loss: 4085.5009315436614
INFO:root:eval perplexity: 5.2176995277404785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/136

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [5:11:48<2:34:11, 144.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3272.079637549389
INFO:root:current train perplexity3.6512997150421143
INFO:root:current mean train loss 3288.432144573028
INFO:root:current train perplexity3.6602723598480225
INFO:root:current mean train loss 3286.5389289457207
INFO:root:current train perplexity3.656550645828247
INFO:root:current mean train loss 3293.651718573361
INFO:root:current train perplexity3.6612372398376465
INFO:root:current mean train loss 3297.7512798583484
INFO:root:current train perplexity3.664275884628296
INFO:root:current mean train loss 3296.654924071018
INFO:root:current train perplexity3.6619815826416016
INFO:root:current mean train loss 3295.4770077812273
INFO:root:current train perplexity3.6613144874572754
INFO:root:current mean train loss 3292.4534823697586
INFO:root:current train perplexity3.6594905853271484
INFO:root:current mean train loss 3292.722626248503
INFO:root:current train perplexity3.660780429840088
INFO:root:current mean train loss 3294.0994641768775
INFO:root:current train perplexity3.664401054382324


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.33s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.43s/it]
INFO:root:eval mean loss: 4085.3943009613254
INFO:root:eval perplexity: 5.217475414276123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/137

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [5:14:48<2:42:51, 155.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3273.1835654810857
INFO:root:current train perplexity3.6440956592559814
INFO:root:current mean train loss 3284.6326622596152
INFO:root:current train perplexity3.6480088233947754
INFO:root:current mean train loss 3286.99780190678
INFO:root:current train perplexity3.6536600589752197
INFO:root:current mean train loss 3287.265371588212
INFO:root:current train perplexity3.657282829284668
INFO:root:current mean train loss 3286.146032098327
INFO:root:current train perplexity3.6580686569213867
INFO:root:current mean train loss 3289.061504973083
INFO:root:current train perplexity3.6609811782836914
INFO:root:current mean train loss 3287.5424853866907
INFO:root:current train perplexity3.6597068309783936
INFO:root:current mean train loss 3291.1864537269066
INFO:root:current train perplexity3.662874698638916
INFO:root:current mean train loss 3290.5875889271997
INFO:root:current train perplexity3.6606602668762207


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.11s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.89s/it]
INFO:root:eval mean loss: 4086.3750986951463
INFO:root:eval perplexity: 5.219544410705566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/138

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [5:17:00<2:33:05, 148.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3355.4115397135415
INFO:root:current train perplexity3.5338292121887207
INFO:root:current mean train loss 3262.4862617566746
INFO:root:current train perplexity3.621981620788574
INFO:root:current mean train loss 3266.9624336129928
INFO:root:current train perplexity3.6299760341644287
INFO:root:current mean train loss 3273.6132562719163
INFO:root:current train perplexity3.6404218673706055
INFO:root:current mean train loss 3280.230942491858
INFO:root:current train perplexity3.6412458419799805
INFO:root:current mean train loss 3281.223780850056
INFO:root:current train perplexity3.641596555709839
INFO:root:current mean train loss 3282.58415280369
INFO:root:current train perplexity3.6432738304138184
INFO:root:current mean train loss 3283.273066948013
INFO:root:current train perplexity3.6463804244995117
INFO:root:current mean train loss 3285.9289155534907
INFO:root:current train perplexity3.6496520042419434
INFO:root:current mean train loss 3286.463448119982
INFO:root:current train perplexity3.6522300243377686


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.62s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.63s/it]
INFO:root:eval mean loss: 4085.7417182651816
INFO:root:eval perplexity: 5.218207359313965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/139

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [5:19:05<2:23:38, 141.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3333.4223854758525
INFO:root:current train perplexity3.5909619331359863
INFO:root:current mean train loss 3279.987612612613
INFO:root:current train perplexity3.64691162109375
INFO:root:current mean train loss 3276.621416571016
INFO:root:current train perplexity3.637695789337158
INFO:root:current mean train loss 3266.8497483232013
INFO:root:current train perplexity3.6274609565734863
INFO:root:current mean train loss 3270.8927937528515
INFO:root:current train perplexity3.6315672397613525
INFO:root:current mean train loss 3273.465799290607
INFO:root:current train perplexity3.640238046646118
INFO:root:current mean train loss 3275.442633346333
INFO:root:current train perplexity3.640115261077881
INFO:root:current mean train loss 3278.5880554456753
INFO:root:current train perplexity3.6414215564727783
INFO:root:current mean train loss 3281.2257141790615
INFO:root:current train perplexity3.6467299461364746
INFO:root:current mean train loss 3283.4601699711857
INFO:root:current train perplexity3.6478490829467773


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.67s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.55s/it]
INFO:root:eval mean loss: 4086.82603508699
INFO:root:eval perplexity: 5.220496654510498
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/140

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [5:21:10<2:16:26, 136.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3265.891049033717
INFO:root:current train perplexity3.632617950439453
INFO:root:current mean train loss 3262.1250882188815
INFO:root:current train perplexity3.632563829421997
INFO:root:current mean train loss 3261.495712489298
INFO:root:current train perplexity3.641529083251953
INFO:root:current mean train loss 3269.337638065733
INFO:root:current train perplexity3.642296314239502
INFO:root:current mean train loss 3272.5380026150433
INFO:root:current train perplexity3.6427178382873535
INFO:root:current mean train loss 3275.8283291561297
INFO:root:current train perplexity3.6446170806884766
INFO:root:current mean train loss 3273.505128925182
INFO:root:current train perplexity3.6420891284942627
INFO:root:current mean train loss 3277.1828565743435
INFO:root:current train perplexity3.6443910598754883
INFO:root:current mean train loss 3279.0005920186586
INFO:root:current train perplexity3.645390033721924
INFO:root:current mean train loss 3280.316769405859
INFO:root:current train perplexity3.645017147064209


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.66s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.26s/it]
INFO:root:eval mean loss: 4091.1482989804963
INFO:root:eval perplexity: 5.229628086090088
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/141

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [5:23:14<2:10:27, 132.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3231.010986328125
INFO:root:current train perplexity3.646420478820801
INFO:root:current mean train loss 3267.5111708753693
INFO:root:current train perplexity3.636903762817383
INFO:root:current mean train loss 3270.419019522646
INFO:root:current train perplexity3.6396539211273193
INFO:root:current mean train loss 3271.440906769639
INFO:root:current train perplexity3.642808675765991
INFO:root:current mean train loss 3275.602026767418
INFO:root:current train perplexity3.642073154449463
INFO:root:current mean train loss 3275.6779979727526
INFO:root:current train perplexity3.6399102210998535
INFO:root:current mean train loss 3277.288027530652
INFO:root:current train perplexity3.6427721977233887
INFO:root:current mean train loss 3278.1201756200567
INFO:root:current train perplexity3.6440348625183105
INFO:root:current mean train loss 3278.6977739806907
INFO:root:current train perplexity3.645043134689331
INFO:root:current mean train loss 3278.3981090821367
INFO:root:current train perplexity3.642789602279663


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.72s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.69s/it]
INFO:root:eval mean loss: 4091.326114735705
INFO:root:eval perplexity: 5.230005264282227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/142

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [5:26:27<2:25:37, 150.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3336.0453752790177
INFO:root:current train perplexity3.643120050430298
INFO:root:current mean train loss 3300.0527235243057
INFO:root:current train perplexity3.627711772918701
INFO:root:current mean train loss 3287.130176820146
INFO:root:current train perplexity3.627017021179199
INFO:root:current mean train loss 3285.6444175606343
INFO:root:current train perplexity3.6298491954803467
INFO:root:current mean train loss 3279.477027209052
INFO:root:current train perplexity3.6327998638153076
INFO:root:current mean train loss 3284.291329128943
INFO:root:current train perplexity3.637866735458374
INFO:root:current mean train loss 3279.9951837014028
INFO:root:current train perplexity3.633739709854126
INFO:root:current mean train loss 3277.6062533216414
INFO:root:current train perplexity3.6350975036621094
INFO:root:current mean train loss 3276.3940689909246
INFO:root:current train perplexity3.63789963722229
INFO:root:current mean train loss 3276.868292791193
INFO:root:current train perplexity3.640162467956543


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.46s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.00s/it]
INFO:root:eval mean loss: 4090.5135073830897
INFO:root:eval perplexity: 5.228287220001221
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/143

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [5:29:39<2:34:51, 163.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3265.9847610828488
INFO:root:current train perplexity3.612025260925293
INFO:root:current mean train loss 3257.9778651524257
INFO:root:current train perplexity3.6096668243408203
INFO:root:current mean train loss 3257.065673828125
INFO:root:current train perplexity3.6135265827178955
INFO:root:current mean train loss 3263.912801937181
INFO:root:current train perplexity3.6174986362457275
INFO:root:current mean train loss 3264.7369999250495
INFO:root:current train perplexity3.620426654815674
INFO:root:current mean train loss 3267.6077307601
INFO:root:current train perplexity3.624849796295166
INFO:root:current mean train loss 3270.7051673521337
INFO:root:current train perplexity3.6282742023468018
INFO:root:current mean train loss 3268.2745106672696
INFO:root:current train perplexity3.6292405128479004
INFO:root:current mean train loss 3270.3841956739325
INFO:root:current train perplexity3.6316792964935303
INFO:root:current mean train loss 3272.1288785479355
INFO:root:current train perplexity3.635413885116577


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.15s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 4094.7686949384974
INFO:root:eval perplexity: 5.237290382385254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/144

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [5:31:42<2:21:02, 151.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3271.004514208027
INFO:root:current train perplexity3.607600688934326
INFO:root:current mean train loss 3267.138689660079
INFO:root:current train perplexity3.6234853267669678
INFO:root:current mean train loss 3265.043914187002
INFO:root:current train perplexity3.6185872554779053
INFO:root:current mean train loss 3260.7763303229613
INFO:root:current train perplexity3.6190855503082275
INFO:root:current mean train loss 3264.9390969287
INFO:root:current train perplexity3.6215744018554688
INFO:root:current mean train loss 3266.5552639554503
INFO:root:current train perplexity3.626103401184082
INFO:root:current mean train loss 3271.0782675091205
INFO:root:current train perplexity3.6295723915100098
INFO:root:current mean train loss 3272.9441915987018
INFO:root:current train perplexity3.6321170330047607
INFO:root:current mean train loss 3272.2792019154854
INFO:root:current train perplexity3.632077932357788
INFO:root:current mean train loss 3271.0848438732255
INFO:root:current train perplexity3.6325087547302246


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.98s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.03s/it]
INFO:root:eval mean loss: 4094.784295697584
INFO:root:eval perplexity: 5.237322807312012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/145

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [5:33:47<2:11:19, 143.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3274.387993246822
INFO:root:current train perplexity3.618366003036499
INFO:root:current mean train loss 3266.5110293214425
INFO:root:current train perplexity3.618431568145752
INFO:root:current mean train loss 3259.5531444181347
INFO:root:current train perplexity3.6179652214050293
INFO:root:current mean train loss 3260.785659492514
INFO:root:current train perplexity3.6210806369781494
INFO:root:current mean train loss 3262.8827640973923
INFO:root:current train perplexity3.6213576793670654
INFO:root:current mean train loss 3264.722665858397
INFO:root:current train perplexity3.6237757205963135
INFO:root:current mean train loss 3269.179744552589
INFO:root:current train perplexity3.625697612762451
INFO:root:current mean train loss 3268.653973605793
INFO:root:current train perplexity3.627049446105957
INFO:root:current mean train loss 3269.04435117142
INFO:root:current train perplexity3.627532482147217
INFO:root:current mean train loss 3268.105281125766
INFO:root:current train perplexity3.627351999282837


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.83s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.87s/it]
INFO:root:eval mean loss: 4096.525272883422
INFO:root:eval perplexity: 5.241011619567871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/146

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [5:36:03<2:07:05, 141.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3261.58494636194
INFO:root:current train perplexity3.6177384853363037
INFO:root:current mean train loss 3273.266047494854
INFO:root:current train perplexity3.6110827922821045
INFO:root:current mean train loss 3269.5721595564137
INFO:root:current train perplexity3.6167726516723633
INFO:root:current mean train loss 3271.2549180698657
INFO:root:current train perplexity3.6155266761779785
INFO:root:current mean train loss 3267.5214409838395
INFO:root:current train perplexity3.6163198947906494
INFO:root:current mean train loss 3264.7578973248733
INFO:root:current train perplexity3.6180498600006104
INFO:root:current mean train loss 3266.4454325571587
INFO:root:current train perplexity3.620020627975464
INFO:root:current mean train loss 3266.3158447583933
INFO:root:current train perplexity3.619986057281494
INFO:root:current mean train loss 3267.391239997837
INFO:root:current train perplexity3.6235673427581787
INFO:root:current mean train loss 3268.2658648485976
INFO:root:current train perplexity3.625687599182129


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.40s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.22s/it]
INFO:root:eval mean loss: 4095.4046223958335
INFO:root:eval perplexity: 5.238636493682861
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/147

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [5:39:22<2:20:00, 158.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3239.3285709635416
INFO:root:current train perplexity3.5945169925689697
INFO:root:current mean train loss 3257.9078794642855
INFO:root:current train perplexity3.6157145500183105
INFO:root:current mean train loss 3262.379933416193
INFO:root:current train perplexity3.619811773300171
INFO:root:current mean train loss 3256.958007161458
INFO:root:current train perplexity3.6144192218780518
INFO:root:current mean train loss 3255.932455283717
INFO:root:current train perplexity3.61088228225708
INFO:root:current mean train loss 3257.241652513587
INFO:root:current train perplexity3.6108760833740234
INFO:root:current mean train loss 3260.434957320602
INFO:root:current train perplexity3.613274097442627
INFO:root:current mean train loss 3261.080200982863
INFO:root:current train perplexity3.612870454788208
INFO:root:current mean train loss 3265.290402622768
INFO:root:current train perplexity3.618459939956665
INFO:root:current mean train loss 3263.5142838541665
INFO:root:current train perplexity3.6192166805267334


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.69s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.17s/it]
INFO:root:eval mean loss: 4096.345239084663
INFO:root:eval perplexity: 5.240630626678467
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/148

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [5:41:38<2:11:30, 151.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3265.6577677899095
INFO:root:current train perplexity3.6227853298187256
INFO:root:current mean train loss 3253.20851877348
INFO:root:current train perplexity3.6126177310943604
INFO:root:current mean train loss 3254.9719747267004
INFO:root:current train perplexity3.6102547645568848
INFO:root:current mean train loss 3259.675857743146
INFO:root:current train perplexity3.6131246089935303
INFO:root:current mean train loss 3259.3726515997023
INFO:root:current train perplexity3.6115028858184814
INFO:root:current mean train loss 3258.209955074775
INFO:root:current train perplexity3.614025354385376
INFO:root:current mean train loss 3258.9946800220764
INFO:root:current train perplexity3.614434242248535
INFO:root:current mean train loss 3258.7567954032966
INFO:root:current train perplexity3.6142942905426025
INFO:root:current mean train loss 3259.7558405736836
INFO:root:current train perplexity3.6158947944641113
INFO:root:current mean train loss 3261.7273947637177
INFO:root:current train perplexity3.617617607116699


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.34s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.84s/it]
INFO:root:eval mean loss: 4096.866139946254
INFO:root:eval perplexity: 5.241734981536865
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/149

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [5:43:44<2:02:27, 144.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3251.9313025841348
INFO:root:current train perplexity3.5979745388031006
INFO:root:current mean train loss 3248.7783931712206
INFO:root:current train perplexity3.598736524581909
INFO:root:current mean train loss 3251.3930529827103
INFO:root:current train perplexity3.6040074825286865
INFO:root:current mean train loss 3251.6353506883393
INFO:root:current train perplexity3.6026687622070312
INFO:root:current mean train loss 3252.793799126464
INFO:root:current train perplexity3.6054277420043945
INFO:root:current mean train loss 3252.086596803617
INFO:root:current train perplexity3.6061465740203857
INFO:root:current mean train loss 3255.2803864982816
INFO:root:current train perplexity3.608151912689209
INFO:root:current mean train loss 3255.25932055448
INFO:root:current train perplexity3.6112098693847656
INFO:root:current mean train loss 3257.1010128410844
INFO:root:current train perplexity3.6121957302093506
INFO:root:current mean train loss 3258.857675623581
INFO:root:current train perplexity3.613661766052246


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.64s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.22s/it]
INFO:root:eval mean loss: 4100.72969304078
INFO:root:eval perplexity: 5.249929904937744
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/150

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [5:46:03<1:58:46, 142.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3250.931729403409
INFO:root:current train perplexity3.6198678016662598
INFO:root:current mean train loss 3252.866683269865
INFO:root:current train perplexity3.605563163757324
INFO:root:current mean train loss 3252.125511960441
INFO:root:current train perplexity3.60416316986084
INFO:root:current mean train loss 3249.7377091410167
INFO:root:current train perplexity3.6018991470336914
INFO:root:current mean train loss 3251.379103910947
INFO:root:current train perplexity3.6025900840759277
INFO:root:current mean train loss 3253.2289712998227
INFO:root:current train perplexity3.607517957687378
INFO:root:current mean train loss 3252.3644481653478
INFO:root:current train perplexity3.6091315746307373
INFO:root:current mean train loss 3249.7694655550886
INFO:root:current train perplexity3.6075022220611572
INFO:root:current mean train loss 3254.0474482823797
INFO:root:current train perplexity3.609072208404541


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:54<00:00, 114.79s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.15s/it]
INFO:root:eval mean loss: 4099.959077875665
INFO:root:eval perplexity: 5.248294830322266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/151

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [5:48:17<1:54:19, 139.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3248.0383649553573
INFO:root:current train perplexity3.6101062297821045
INFO:root:current mean train loss 3250.143666490216
INFO:root:current train perplexity3.601166248321533
INFO:root:current mean train loss 3249.0751552121073
INFO:root:current train perplexity3.604356527328491
INFO:root:current mean train loss 3245.7494019747555
INFO:root:current train perplexity3.6052868366241455
INFO:root:current mean train loss 3246.463285329008
INFO:root:current train perplexity3.604694128036499
INFO:root:current mean train loss 3248.67897867357
INFO:root:current train perplexity3.602409601211548
INFO:root:current mean train loss 3248.177513160266
INFO:root:current train perplexity3.6025328636169434
INFO:root:current mean train loss 3253.300688359154
INFO:root:current train perplexity3.6036295890808105
INFO:root:current mean train loss 3254.163261706649
INFO:root:current train perplexity3.6048364639282227
INFO:root:current mean train loss 3257.221916560433
INFO:root:current train perplexity3.6075894832611084


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:53<00:00, 113.96s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.10s/it]
INFO:root:eval mean loss: 4105.201932000776
INFO:root:eval perplexity: 5.259432792663574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/152

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [5:50:22<1:48:13, 135.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3270.263704427083
INFO:root:current train perplexity3.6051220893859863
INFO:root:current mean train loss 3252.079084578804
INFO:root:current train perplexity3.6017377376556396
INFO:root:current mean train loss 3250.565261627907
INFO:root:current train perplexity3.6032862663269043
INFO:root:current mean train loss 3242.4814794146823
INFO:root:current train perplexity3.596579074859619
INFO:root:current mean train loss 3248.0745823136294
INFO:root:current train perplexity3.5987908840179443
INFO:root:current mean train loss 3250.7927193947207
INFO:root:current train perplexity3.6024742126464844
INFO:root:current mean train loss 3251.6460123697916
INFO:root:current train perplexity3.5996198654174805
INFO:root:current mean train loss 3253.9125256091565
INFO:root:current train perplexity3.6031367778778076
INFO:root:current mean train loss 3252.246735105924
INFO:root:current train perplexity3.6040005683898926
INFO:root:current mean train loss 3252.1563631318304
INFO:root:current train perplexity3.6044750213623047


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:55<00:00, 115.57s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.59s/it]
INFO:root:eval mean loss: 4101.304893547762
INFO:root:eval perplexity: 5.2511515617370605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/153

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [5:52:27<1:43:33, 132.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3192.9299528702445
INFO:root:current train perplexity3.5419561862945557
INFO:root:current mean train loss 3235.7712501587907
INFO:root:current train perplexity3.5850417613983154
INFO:root:current mean train loss 3235.4204397158774
INFO:root:current train perplexity3.5798499584198
INFO:root:current mean train loss 3237.8053171258225
INFO:root:current train perplexity3.5824332237243652
INFO:root:current mean train loss 3240.841421718011
INFO:root:current train perplexity3.5887138843536377
INFO:root:current mean train loss 3243.0936150924654
INFO:root:current train perplexity3.5896244049072266
INFO:root:current mean train loss 3242.8141498106443
INFO:root:current train perplexity3.5923397541046143
INFO:root:current mean train loss 3246.5183875372795
INFO:root:current train perplexity3.596318006515503
INFO:root:current mean train loss 3248.6691633481737
INFO:root:current train perplexity3.596405506134033
INFO:root:current mean train loss 3249.4863342086774
INFO:root:current train perplexity3.598783493041992


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:50<00:00, 110.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:50<00:00, 110.94s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.28s/it]
INFO:root:eval mean loss: 4101.449715688719
INFO:root:eval perplexity: 5.251458168029785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/154

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [5:55:19<1:50:29, 144.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3264.9020208543348
INFO:root:current train perplexity3.6182801723480225
INFO:root:current mean train loss 3246.749880725191
INFO:root:current train perplexity3.6044557094573975
INFO:root:current mean train loss 3241.1550176711307
INFO:root:current train perplexity3.5897014141082764
INFO:root:current mean train loss 3243.508353149783
INFO:root:current train perplexity3.5942158699035645
INFO:root:current mean train loss 3239.3314325106944
INFO:root:current train perplexity3.595346689224243
INFO:root:current mean train loss 3238.602641132592
INFO:root:current train perplexity3.5944724082946777
INFO:root:current mean train loss 3243.1371872988066
INFO:root:current train perplexity3.598400831222534
INFO:root:current mean train loss 3246.011506003655
INFO:root:current train perplexity3.600992441177368
INFO:root:current mean train loss 3248.2653585312314
INFO:root:current train perplexity3.598008394241333
INFO:root:current mean train loss 3246.075395135439
INFO:root:current train perplexity3.596524238586426


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:50<00:00, 110.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:50<00:00, 110.59s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.44s/it]
INFO:root:eval mean loss: 4104.534363225842
INFO:root:eval perplexity: 5.258013725280762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/155

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [5:57:30<1:45:13, 140.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3284.6852338741987
INFO:root:current train perplexity3.5996906757354736
INFO:root:current mean train loss 3241.0067832452787
INFO:root:current train perplexity3.578756809234619
INFO:root:current mean train loss 3243.6288163572176
INFO:root:current train perplexity3.5854673385620117
INFO:root:current mean train loss 3240.80121407748
INFO:root:current train perplexity3.5886008739471436
INFO:root:current mean train loss 3237.220376677285
INFO:root:current train perplexity3.5914435386657715
INFO:root:current mean train loss 3239.474920552383
INFO:root:current train perplexity3.5902175903320312
INFO:root:current mean train loss 3240.105914239779
INFO:root:current train perplexity3.5894479751586914
INFO:root:current mean train loss 3242.3511568103013
INFO:root:current train perplexity3.5901010036468506
INFO:root:current mean train loss 3242.664581335202
INFO:root:current train perplexity3.5885884761810303
INFO:root:current mean train loss 3244.164980822351
INFO:root:current train perplexity3.5926783084869385


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:51<00:00, 111.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:51<00:00, 111.78s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.51s/it]
INFO:root:eval mean loss: 4104.532746010638
INFO:root:eval perplexity: 5.2580084800720215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/156

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [5:59:30<1:38:26, 134.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3238.7062780501997
INFO:root:current train perplexity3.5508761405944824
INFO:root:current mean train loss 3244.420724051339
INFO:root:current train perplexity3.572477340698242
INFO:root:current mean train loss 3235.234583557376
INFO:root:current train perplexity3.5741398334503174
INFO:root:current mean train loss 3236.3534494889227
INFO:root:current train perplexity3.5763556957244873
INFO:root:current mean train loss 3238.6392644758457
INFO:root:current train perplexity3.581310987472534
INFO:root:current mean train loss 3234.7641244501256
INFO:root:current train perplexity3.5813612937927246
INFO:root:current mean train loss 3235.314640286901
INFO:root:current train perplexity3.5834689140319824
INFO:root:current mean train loss 3238.7210747286017
INFO:root:current train perplexity3.586085081100464
INFO:root:current mean train loss 3241.0652864314306
INFO:root:current train perplexity3.5869483947753906
INFO:root:current mean train loss 3242.3611154364935
INFO:root:current train perplexity3.588947057723999


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:50<00:00, 110.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:50<00:00, 110.74s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.05s/it]
INFO:root:eval mean loss: 4106.251632798648
INFO:root:eval perplexity: 5.261666297912598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/157

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [6:01:30<1:33:04, 129.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3210.427618963068
INFO:root:current train perplexity3.5926427841186523
INFO:root:current mean train loss 3211.721296938004
INFO:root:current train perplexity3.5779483318328857
INFO:root:current mean train loss 3223.9868958716297
INFO:root:current train perplexity3.5794403553009033
INFO:root:current mean train loss 3229.4964541153167
INFO:root:current train perplexity3.583169460296631
INFO:root:current mean train loss 3231.3140356713598
INFO:root:current train perplexity3.5833921432495117
INFO:root:current mean train loss 3234.635010645411
INFO:root:current train perplexity3.5828704833984375
INFO:root:current mean train loss 3238.4553364295084
INFO:root:current train perplexity3.585927724838257
INFO:root:current mean train loss 3239.628164127173
INFO:root:current train perplexity3.5870440006256104
INFO:root:current mean train loss 3241.7894188596492
INFO:root:current train perplexity3.5894510746002197
INFO:root:current mean train loss 3241.0082171854547
INFO:root:current train perplexity3.58794903755188


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:51<00:00, 112.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:51<00:00, 112.00s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 4104.68487159242
INFO:root:eval perplexity: 5.2583327293396
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/158

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [6:03:31<1:29:07, 127.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3251.2655901227677
INFO:root:current train perplexity3.5807132720947266
INFO:root:current mean train loss 3245.6805532256517
INFO:root:current train perplexity3.576646089553833
INFO:root:current mean train loss 3239.444469611454
INFO:root:current train perplexity3.573554039001465
INFO:root:current mean train loss 3231.7483919001806
INFO:root:current train perplexity3.5758867263793945
INFO:root:current mean train loss 3234.6288551017483
INFO:root:current train perplexity3.582179069519043
INFO:root:current mean train loss 3236.658668423207
INFO:root:current train perplexity3.5826497077941895
INFO:root:current mean train loss 3235.196579600891
INFO:root:current train perplexity3.5851263999938965
INFO:root:current mean train loss 3240.2549016910016
INFO:root:current train perplexity3.5863821506500244
INFO:root:current mean train loss 3238.5811047603743
INFO:root:current train perplexity3.5854973793029785
INFO:root:current mean train loss 3238.6076264663648
INFO:root:current train perplexity3.584731101989746


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:49<00:00, 109.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:49<00:00, 109.93s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 4105.934651692708
INFO:root:eval perplexity: 5.260990619659424
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/159

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [6:05:30<1:25:19, 124.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3241.4162838358275
INFO:root:current train perplexity3.5906944274902344
INFO:root:current mean train loss 3227.1772874977155
INFO:root:current train perplexity3.5692081451416016
INFO:root:current mean train loss 3228.5074809732473
INFO:root:current train perplexity3.570289373397827
INFO:root:current mean train loss 3224.961268504675
INFO:root:current train perplexity3.575119972229004
INFO:root:current mean train loss 3229.7163770153265
INFO:root:current train perplexity3.5771803855895996
INFO:root:current mean train loss 3229.7325039678194
INFO:root:current train perplexity3.5788540840148926
INFO:root:current mean train loss 3232.3459388971683
INFO:root:current train perplexity3.5775415897369385
INFO:root:current mean train loss 3234.6804221384564
INFO:root:current train perplexity3.579058885574341
INFO:root:current mean train loss 3236.1237523881496
INFO:root:current train perplexity3.582767963409424
INFO:root:current mean train loss 3236.161071211621
INFO:root:current train perplexity3.5824294090270996


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:52<00:00, 112.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:52<00:00, 112.48s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.85s/it]
INFO:root:eval mean loss: 4108.068187957115
INFO:root:eval perplexity: 5.26553201675415
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/160

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [6:07:33<1:22:44, 124.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3230.752883331685
INFO:root:current train perplexity3.5664010047912598
INFO:root:current mean train loss 3226.156438220147
INFO:root:current train perplexity3.5794577598571777
INFO:root:current mean train loss 3233.1483316182234
INFO:root:current train perplexity3.5831964015960693
INFO:root:current mean train loss 3237.7446901024487
INFO:root:current train perplexity3.5801455974578857
INFO:root:current mean train loss 3235.344023702538
INFO:root:current train perplexity3.5783915519714355
INFO:root:current mean train loss 3236.9301403618847
INFO:root:current train perplexity3.578645944595337
INFO:root:current mean train loss 3232.5574546667895
INFO:root:current train perplexity3.578683853149414
INFO:root:current mean train loss 3233.886589941532
INFO:root:current train perplexity3.5792815685272217
INFO:root:current mean train loss 3232.828356086462
INFO:root:current train perplexity3.580223798751831
INFO:root:current mean train loss 3234.919984468766
INFO:root:current train perplexity3.5808374881744385


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.86s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.75s/it]
INFO:root:eval mean loss: 4109.163231382979
INFO:root:eval perplexity: 5.267863750457764
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/161

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [6:09:48<1:22:49, 127.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3221.9489914466594
INFO:root:current train perplexity3.549978494644165
INFO:root:current mean train loss 3219.2739218645556
INFO:root:current train perplexity3.5548179149627686
INFO:root:current mean train loss 3225.508450498149
INFO:root:current train perplexity3.558776617050171
INFO:root:current mean train loss 3231.151298424378
INFO:root:current train perplexity3.567850351333618
INFO:root:current mean train loss 3229.4743547067505
INFO:root:current train perplexity3.569328546524048
INFO:root:current mean train loss 3231.3885367034445
INFO:root:current train perplexity3.5699782371520996
INFO:root:current mean train loss 3230.052845961836
INFO:root:current train perplexity3.5700907707214355
INFO:root:current mean train loss 3231.4934277467837
INFO:root:current train perplexity3.572749137878418
INFO:root:current mean train loss 3231.712051133561
INFO:root:current train perplexity3.5746941566467285
INFO:root:current mean train loss 3234.3773610154667
INFO:root:current train perplexity3.5790212154388428


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.81s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.68s/it]
INFO:root:eval mean loss: 4106.991223057957
INFO:root:eval perplexity: 5.26323938369751
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/162

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [6:12:00<1:21:32, 128.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3227.54800832648
INFO:root:current train perplexity3.5761983394622803
INFO:root:current mean train loss 3235.134004407051
INFO:root:current train perplexity3.5824062824249268
INFO:root:current mean train loss 3230.018730965307
INFO:root:current train perplexity3.570845365524292
INFO:root:current mean train loss 3233.8037708910206
INFO:root:current train perplexity3.569066047668457
INFO:root:current mean train loss 3235.6737990254105
INFO:root:current train perplexity3.5725791454315186
INFO:root:current mean train loss 3235.1972446986606
INFO:root:current train perplexity3.5728137493133545
INFO:root:current mean train loss 3233.381494140625
INFO:root:current train perplexity3.570443868637085
INFO:root:current mean train loss 3230.884524555326
INFO:root:current train perplexity3.5710816383361816
INFO:root:current mean train loss 3231.487625480098
INFO:root:current train perplexity3.572813034057617


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.77s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.02s/it]
INFO:root:eval mean loss: 4109.921949454233
INFO:root:eval perplexity: 5.269480228424072
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/163

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [6:14:08<1:19:23, 128.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3215.8373209635415
INFO:root:current train perplexity3.5351765155792236
INFO:root:current mean train loss 3196.3858749241504
INFO:root:current train perplexity3.561575412750244
INFO:root:current mean train loss 3220.625270599215
INFO:root:current train perplexity3.574446678161621
INFO:root:current mean train loss 3219.879263194874
INFO:root:current train perplexity3.5725836753845215
INFO:root:current mean train loss 3220.0701634712314
INFO:root:current train perplexity3.574899196624756
INFO:root:current mean train loss 3223.0928724527835
INFO:root:current train perplexity3.575087547302246
INFO:root:current mean train loss 3225.2523175139927
INFO:root:current train perplexity3.572310447692871
INFO:root:current mean train loss 3224.9927789245867
INFO:root:current train perplexity3.5697762966156006
INFO:root:current mean train loss 3225.2312939027474
INFO:root:current train perplexity3.570279121398926
INFO:root:current mean train loss 3229.050493039694
INFO:root:current train perplexity3.5714094638824463


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.82s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.56s/it]
INFO:root:eval mean loss: 4110.189271318151
INFO:root:eval perplexity: 5.270050048828125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/164

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [6:16:15<1:16:48, 128.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3237.3048206676135
INFO:root:current train perplexity3.5495529174804688
INFO:root:current mean train loss 3221.242864935248
INFO:root:current train perplexity3.546482563018799
INFO:root:current mean train loss 3225.268020123667
INFO:root:current train perplexity3.555584669113159
INFO:root:current mean train loss 3224.337175473523
INFO:root:current train perplexity3.561779737472534
INFO:root:current mean train loss 3230.793590684877
INFO:root:current train perplexity3.5705230236053467
INFO:root:current mean train loss 3228.2412071153376
INFO:root:current train perplexity3.5719237327575684
INFO:root:current mean train loss 3225.7049590515035
INFO:root:current train perplexity3.5687201023101807
INFO:root:current mean train loss 3224.6441834097004
INFO:root:current train perplexity3.5677008628845215
INFO:root:current mean train loss 3225.6690913152165
INFO:root:current train perplexity3.567082643508911
INFO:root:current mean train loss 3226.296299085397
INFO:root:current train perplexity3.5677382946014404


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.56s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.58s/it]
INFO:root:eval mean loss: 4111.708593057402
INFO:root:eval perplexity: 5.273289203643799
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/165

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [6:18:21<1:14:19, 127.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3249.6279168379933
INFO:root:current train perplexity3.592034339904785
INFO:root:current mean train loss 3225.0066943769693
INFO:root:current train perplexity3.566816806793213
INFO:root:current mean train loss 3227.9425188177797
INFO:root:current train perplexity3.5723507404327393
INFO:root:current mean train loss 3228.196153598893
INFO:root:current train perplexity3.568401575088501
INFO:root:current mean train loss 3225.576376976432
INFO:root:current train perplexity3.5685622692108154
INFO:root:current mean train loss 3223.587192072345
INFO:root:current train perplexity3.5680761337280273
INFO:root:current mean train loss 3226.3137013769688
INFO:root:current train perplexity3.568967342376709
INFO:root:current mean train loss 3228.3828644520386
INFO:root:current train perplexity3.5687835216522217
INFO:root:current mean train loss 3228.585936605712
INFO:root:current train perplexity3.570469856262207
INFO:root:current mean train loss 3226.7483537111502
INFO:root:current train perplexity3.5674657821655273


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.04s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.40s/it]
INFO:root:eval mean loss: 4112.710158327793
INFO:root:eval perplexity: 5.275424957275391
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/166

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [6:20:28<1:12:12, 127.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3216.5918782552085
INFO:root:current train perplexity3.569026470184326
INFO:root:current mean train loss 3221.2980284202754
INFO:root:current train perplexity3.5562667846679688
INFO:root:current mean train loss 3225.4842018429927
INFO:root:current train perplexity3.5641629695892334
INFO:root:current mean train loss 3220.018530796063
INFO:root:current train perplexity3.5602216720581055
INFO:root:current mean train loss 3222.233203468055
INFO:root:current train perplexity3.5590157508850098
INFO:root:current mean train loss 3225.3451550825725
INFO:root:current train perplexity3.558844804763794
INFO:root:current mean train loss 3225.5610495632727
INFO:root:current train perplexity3.5611164569854736
INFO:root:current mean train loss 3226.430827606495
INFO:root:current train perplexity3.5627224445343018
INFO:root:current mean train loss 3223.5780783564464
INFO:root:current train perplexity3.5631816387176514
INFO:root:current mean train loss 3223.7336383642632
INFO:root:current train perplexity3.5637571811676025


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.53s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.73s/it]
INFO:root:eval mean loss: 4114.393946005098
INFO:root:eval perplexity: 5.279018402099609
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/167

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [6:22:36<1:10:13, 127.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3251.9071219308034
INFO:root:current train perplexity3.558809518814087
INFO:root:current mean train loss 3222.8977665653933
INFO:root:current train perplexity3.562761068344116
INFO:root:current mean train loss 3211.209006191822
INFO:root:current train perplexity3.5541722774505615
INFO:root:current mean train loss 3216.7751617887125
INFO:root:current train perplexity3.554548501968384
INFO:root:current mean train loss 3219.1245897315016
INFO:root:current train perplexity3.5567471981048584
INFO:root:current mean train loss 3221.9911707797896
INFO:root:current train perplexity3.5570414066314697
INFO:root:current mean train loss 3221.0436519592768
INFO:root:current train perplexity3.5585741996765137
INFO:root:current mean train loss 3222.4357265757867
INFO:root:current train perplexity3.5582504272460938
INFO:root:current mean train loss 3222.213475392964
INFO:root:current train perplexity3.558197498321533
INFO:root:current mean train loss 3221.3063466117983
INFO:root:current train perplexity3.5592987537384033


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.65s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 4113.667419866467
INFO:root:eval perplexity: 5.277467727661133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/168

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [6:24:42<1:07:48, 127.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3222.2379576217295
INFO:root:current train perplexity3.5323572158813477
INFO:root:current mean train loss 3234.8899045290646
INFO:root:current train perplexity3.565098524093628
INFO:root:current mean train loss 3217.995606473444
INFO:root:current train perplexity3.558457851409912
INFO:root:current mean train loss 3213.536196160942
INFO:root:current train perplexity3.5528924465179443
INFO:root:current mean train loss 3215.2621381428116
INFO:root:current train perplexity3.554453134536743
INFO:root:current mean train loss 3212.6359170875057
INFO:root:current train perplexity3.5492160320281982
INFO:root:current mean train loss 3217.64398905278
INFO:root:current train perplexity3.550926923751831
INFO:root:current mean train loss 3219.270249542606
INFO:root:current train perplexity3.5557351112365723
INFO:root:current mean train loss 3221.1996656171227
INFO:root:current train perplexity3.557616949081421
INFO:root:current mean train loss 3219.675937883169
INFO:root:current train perplexity3.5574514865875244


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.33s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.94s/it]
INFO:root:eval mean loss: 4115.993461879432
INFO:root:eval perplexity: 5.282434463500977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/169

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [6:26:49<1:05:42, 127.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3224.639308555453
INFO:root:current train perplexity3.5431344509124756
INFO:root:current mean train loss 3211.228305437707
INFO:root:current train perplexity3.5432045459747314
INFO:root:current mean train loss 3214.2021153666583
INFO:root:current train perplexity3.5548489093780518
INFO:root:current mean train loss 3212.548171518875
INFO:root:current train perplexity3.551560640335083
INFO:root:current mean train loss 3208.000303687119
INFO:root:current train perplexity3.5479681491851807
INFO:root:current mean train loss 3207.999193139604
INFO:root:current train perplexity3.5486156940460205
INFO:root:current mean train loss 3212.0843016453055
INFO:root:current train perplexity3.5510120391845703
INFO:root:current mean train loss 3214.3722494356484
INFO:root:current train perplexity3.553194999694824
INFO:root:current mean train loss 3215.6546244996694
INFO:root:current train perplexity3.552382230758667
INFO:root:current mean train loss 3216.875337073229
INFO:root:current train perplexity3.5541930198669434


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.73s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.38s/it]
INFO:root:eval mean loss: 4115.445158397052
INFO:root:eval perplexity: 5.281262397766113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/170

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [6:28:56<1:03:33, 127.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3207.177651615466
INFO:root:current train perplexity3.551743268966675
INFO:root:current mean train loss 3199.7913810682
INFO:root:current train perplexity3.535604476928711
INFO:root:current mean train loss 3198.402432357022
INFO:root:current train perplexity3.542386531829834
INFO:root:current mean train loss 3207.067441977498
INFO:root:current train perplexity3.550786018371582
INFO:root:current mean train loss 3206.3532927602464
INFO:root:current train perplexity3.548492908477783
INFO:root:current mean train loss 3208.8394484954997
INFO:root:current train perplexity3.5514256954193115
INFO:root:current mean train loss 3212.5002563661797
INFO:root:current train perplexity3.553203821182251
INFO:root:current mean train loss 3214.4241340245185
INFO:root:current train perplexity3.553528308868408
INFO:root:current mean train loss 3215.5734959914325
INFO:root:current train perplexity3.55460786819458
INFO:root:current mean train loss 3215.956635889843
INFO:root:current train perplexity3.554309606552124


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.32s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.39s/it]
INFO:root:eval mean loss: 4113.888020833333
INFO:root:eval perplexity: 5.277937889099121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/171

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [6:31:02<1:01:13, 126.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3239.8561683768658
INFO:root:current train perplexity3.5425479412078857
INFO:root:current mean train loss 3229.44010367936
INFO:root:current train perplexity3.5592844486236572
INFO:root:current mean train loss 3220.5172827788506
INFO:root:current train perplexity3.5620107650756836
INFO:root:current mean train loss 3219.005929224498
INFO:root:current train perplexity3.561030387878418
INFO:root:current mean train loss 3211.2782915593216
INFO:root:current train perplexity3.5557000637054443
INFO:root:current mean train loss 3208.962340770365
INFO:root:current train perplexity3.5505993366241455
INFO:root:current mean train loss 3208.917814286216
INFO:root:current train perplexity3.55035138130188
INFO:root:current mean train loss 3211.0420886341876
INFO:root:current train perplexity3.5505189895629883
INFO:root:current mean train loss 3213.783877257245
INFO:root:current train perplexity3.550825834274292
INFO:root:current mean train loss 3213.8227231046408
INFO:root:current train perplexity3.5506324768066406


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.35s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.70s/it]
INFO:root:eval mean loss: 4116.603174520723
INFO:root:eval perplexity: 5.283736705780029
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/172

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [6:33:10<59:17, 127.06s/it]  

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3207.0188606770835
INFO:root:current train perplexity3.5608015060424805
INFO:root:current mean train loss 3203.5259026227677
INFO:root:current train perplexity3.5440688133239746
INFO:root:current mean train loss 3214.4274263139205
INFO:root:current train perplexity3.5492608547210693
INFO:root:current mean train loss 3210.4055462239585
INFO:root:current train perplexity3.5459837913513184
INFO:root:current mean train loss 3211.7442783717106
INFO:root:current train perplexity3.547947406768799
INFO:root:current mean train loss 3213.0197155230976
INFO:root:current train perplexity3.5478897094726562
INFO:root:current mean train loss 3210.8390610532406
INFO:root:current train perplexity3.548309803009033
INFO:root:current mean train loss 3212.8216633064517
INFO:root:current train perplexity3.5496649742126465
INFO:root:current mean train loss 3215.051772042411
INFO:root:current train perplexity3.550659418106079
INFO:root:current mean train loss 3214.3239372996795
INFO:root:current train perplexity3.5500543117523193


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.28s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.62s/it]
INFO:root:eval mean loss: 4117.21065007203
INFO:root:eval perplexity: 5.2850341796875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/173

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [6:35:27<58:26, 129.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3212.9111592855797
INFO:root:current train perplexity3.566607713699341
INFO:root:current mean train loss 3212.1548451908297
INFO:root:current train perplexity3.542487859725952
INFO:root:current mean train loss 3209.8904610893333
INFO:root:current train perplexity3.5449538230895996
INFO:root:current mean train loss 3210.729183027701
INFO:root:current train perplexity3.5407116413116455
INFO:root:current mean train loss 3218.7453699210664
INFO:root:current train perplexity3.5465197563171387
INFO:root:current mean train loss 3213.555960130119
INFO:root:current train perplexity3.5461833477020264
INFO:root:current mean train loss 3211.5412683445047
INFO:root:current train perplexity3.544914722442627
INFO:root:current mean train loss 3213.6908297289074
INFO:root:current train perplexity3.547755002975464
INFO:root:current mean train loss 3215.0313393062534
INFO:root:current train perplexity3.5494868755340576
INFO:root:current mean train loss 3212.9442035601314
INFO:root:current train perplexity3.5487194061279297


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.23s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.93s/it]
INFO:root:eval mean loss: 4119.931159269725
INFO:root:eval perplexity: 5.290853023529053
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/174

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [6:37:35<56:03, 129.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3191.330029833448
INFO:root:current train perplexity3.535809278488159
INFO:root:current mean train loss 3190.259780963678
INFO:root:current train perplexity3.527240514755249
INFO:root:current mean train loss 3201.753711608677
INFO:root:current train perplexity3.5369656085968018
INFO:root:current mean train loss 3206.460630294917
INFO:root:current train perplexity3.5400922298431396
INFO:root:current mean train loss 3202.899464780104
INFO:root:current train perplexity3.5355167388916016
INFO:root:current mean train loss 3204.977134226946
INFO:root:current train perplexity3.536520481109619
INFO:root:current mean train loss 3207.127385935804
INFO:root:current train perplexity3.5388567447662354
INFO:root:current mean train loss 3207.0667843438882
INFO:root:current train perplexity3.5392794609069824
INFO:root:current mean train loss 3210.211620874544
INFO:root:current train perplexity3.54328989982605
INFO:root:current mean train loss 3210.3882720362167
INFO:root:current train perplexity3.5452356338500977


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.10s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.67s/it]
INFO:root:eval mean loss: 4117.518291500443
INFO:root:eval perplexity: 5.285691261291504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/175

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [6:39:40<53:26, 128.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3203.2179682567867
INFO:root:current train perplexity3.5461463928222656
INFO:root:current mean train loss 3203.8515477779524
INFO:root:current train perplexity3.538220167160034
INFO:root:current mean train loss 3204.184613588263
INFO:root:current train perplexity3.5382468700408936
INFO:root:current mean train loss 3204.7578388108946
INFO:root:current train perplexity3.5383644104003906
INFO:root:current mean train loss 3206.181823118894
INFO:root:current train perplexity3.540041923522949
INFO:root:current mean train loss 3207.9170667747026
INFO:root:current train perplexity3.5439038276672363
INFO:root:current mean train loss 3208.3690089497272
INFO:root:current train perplexity3.54164981842041
INFO:root:current mean train loss 3207.673748985548
INFO:root:current train perplexity3.5420310497283936
INFO:root:current mean train loss 3207.851199955245
INFO:root:current train perplexity3.5425047874450684


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.91s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.54s/it]
INFO:root:eval mean loss: 4119.337381565824
INFO:root:eval perplexity: 5.289582252502441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/176

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [6:41:47<51:04, 127.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3187.9302804129466
INFO:root:current train perplexity3.4492907524108887
INFO:root:current mean train loss 3223.0153124087324
INFO:root:current train perplexity3.5438930988311768
INFO:root:current mean train loss 3210.7696999075333
INFO:root:current train perplexity3.5341110229492188
INFO:root:current mean train loss 3205.634760058276
INFO:root:current train perplexity3.5332210063934326
INFO:root:current mean train loss 3207.2129188181434
INFO:root:current train perplexity3.532176971435547
INFO:root:current mean train loss 3204.1389266094984
INFO:root:current train perplexity3.53216814994812
INFO:root:current mean train loss 3203.8945738841126
INFO:root:current train perplexity3.535219669342041
INFO:root:current mean train loss 3206.2185041327793
INFO:root:current train perplexity3.5403242111206055
INFO:root:current mean train loss 3207.2740746253485
INFO:root:current train perplexity3.5414559841156006
INFO:root:current mean train loss 3209.838841885164
INFO:root:current train perplexity3.545048713684082


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.44s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.42s/it]
INFO:root:eval mean loss: 4118.627463915669
INFO:root:eval perplexity: 5.2880635261535645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/177

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [6:43:54<48:50, 127.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3192.867333984375
INFO:root:current train perplexity3.480180025100708
INFO:root:current mean train loss 3195.7044136379077
INFO:root:current train perplexity3.5107500553131104
INFO:root:current mean train loss 3200.940824854651
INFO:root:current train perplexity3.5372345447540283
INFO:root:current mean train loss 3199.596253410218
INFO:root:current train perplexity3.5394489765167236
INFO:root:current mean train loss 3201.711646978539
INFO:root:current train perplexity3.535496473312378
INFO:root:current mean train loss 3201.6127507774577
INFO:root:current train perplexity3.534257650375366
INFO:root:current mean train loss 3204.586333682673
INFO:root:current train perplexity3.53549861907959
INFO:root:current mean train loss 3207.2941498442965
INFO:root:current train perplexity3.5382986068725586
INFO:root:current mean train loss 3207.4101847081097
INFO:root:current train perplexity3.538435220718384
INFO:root:current mean train loss 3206.2053993767076
INFO:root:current train perplexity3.5397958755493164


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.46s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.67s/it]
INFO:root:eval mean loss: 4118.7240362505545
INFO:root:eval perplexity: 5.28826904296875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/178

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [6:46:01<46:40, 127.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3226.447127632473
INFO:root:current train perplexity3.5417704582214355
INFO:root:current mean train loss 3214.3457448075455
INFO:root:current train perplexity3.5275802612304688
INFO:root:current mean train loss 3210.4293568700955
INFO:root:current train perplexity3.526383638381958
INFO:root:current mean train loss 3211.843377364309
INFO:root:current train perplexity3.5311062335968018
INFO:root:current mean train loss 3215.4546966192006
INFO:root:current train perplexity3.536585807800293
INFO:root:current mean train loss 3209.372439090882
INFO:root:current train perplexity3.5360641479492188
INFO:root:current mean train loss 3208.6207970975875
INFO:root:current train perplexity3.5363619327545166
INFO:root:current mean train loss 3205.7699823867565
INFO:root:current train perplexity3.5374433994293213
INFO:root:current mean train loss 3204.007859666901
INFO:root:current train perplexity3.535726308822632
INFO:root:current mean train loss 3204.8223547641014
INFO:root:current train perplexity3.5391199588775635


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.70s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.21s/it]
INFO:root:eval mean loss: 4119.314250540226
INFO:root:eval perplexity: 5.289531707763672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/179

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [6:48:08<44:31, 127.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3186.8121613533267
INFO:root:current train perplexity3.535069227218628
INFO:root:current mean train loss 3196.9277921487355
INFO:root:current train perplexity3.533315658569336
INFO:root:current mean train loss 3195.56753711783
INFO:root:current train perplexity3.5396363735198975
INFO:root:current mean train loss 3194.8548963840635
INFO:root:current train perplexity3.5371596813201904
INFO:root:current mean train loss 3197.201217757577
INFO:root:current train perplexity3.5355682373046875
INFO:root:current mean train loss 3199.2890298559614
INFO:root:current train perplexity3.5331151485443115
INFO:root:current mean train loss 3200.4212868958
INFO:root:current train perplexity3.5348567962646484
INFO:root:current mean train loss 3203.3411479485508
INFO:root:current train perplexity3.5374066829681396
INFO:root:current mean train loss 3203.87249836652
INFO:root:current train perplexity3.536151885986328
INFO:root:current mean train loss 3203.0836998502114
INFO:root:current train perplexity3.535588264465332


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.71s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.94s/it]
INFO:root:eval mean loss: 4119.371862533245
INFO:root:eval perplexity: 5.289655685424805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/180

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [6:50:15<42:25, 127.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3211.221905048077
INFO:root:current train perplexity3.5552384853363037
INFO:root:current mean train loss 3194.9612817558454
INFO:root:current train perplexity3.533562183380127
INFO:root:current mean train loss 3191.6557586542235
INFO:root:current train perplexity3.5279650688171387
INFO:root:current mean train loss 3197.2225705487185
INFO:root:current train perplexity3.5270965099334717
INFO:root:current mean train loss 3196.2046487934226
INFO:root:current train perplexity3.5283098220825195
INFO:root:current mean train loss 3196.729797023568
INFO:root:current train perplexity3.5281622409820557
INFO:root:current mean train loss 3195.7866054290153
INFO:root:current train perplexity3.526749849319458
INFO:root:current mean train loss 3198.5703878234945
INFO:root:current train perplexity3.5286998748779297
INFO:root:current mean train loss 3201.2055617504097
INFO:root:current train perplexity3.5328528881073
INFO:root:current mean train loss 3201.3297208840854
INFO:root:current train perplexity3.5320489406585693


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.76s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.43s/it]
INFO:root:eval mean loss: 4121.246256510417
INFO:root:eval perplexity: 5.293666362762451
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/181

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [6:52:28<40:49, 128.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3215.6334566156916
INFO:root:current train perplexity3.5253188610076904
INFO:root:current mean train loss 3197.9948199006167
INFO:root:current train perplexity3.5349481105804443
INFO:root:current mean train loss 3201.8386764217485
INFO:root:current train perplexity3.533243179321289
INFO:root:current mean train loss 3209.1860168632925
INFO:root:current train perplexity3.5394234657287598
INFO:root:current mean train loss 3206.174854935682
INFO:root:current train perplexity3.5363993644714355
INFO:root:current mean train loss 3204.346044564814
INFO:root:current train perplexity3.537210702896118
INFO:root:current mean train loss 3205.9920237333367
INFO:root:current train perplexity3.536555051803589
INFO:root:current mean train loss 3203.937733355296
INFO:root:current train perplexity3.5356545448303223
INFO:root:current mean train loss 3203.540061545344
INFO:root:current train perplexity3.535175323486328
INFO:root:current mean train loss 3203.3295679303887
INFO:root:current train perplexity3.535123586654663


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.14s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.67s/it]
INFO:root:eval mean loss: 4121.542433718418
INFO:root:eval perplexity: 5.294300556182861
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/182

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [6:55:33<43:44, 145.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3196.2995383522725
INFO:root:current train perplexity3.550483465194702
INFO:root:current mean train loss 3192.734543535786
INFO:root:current train perplexity3.5433976650238037
INFO:root:current mean train loss 3190.8125804227943
INFO:root:current train perplexity3.5278913974761963
INFO:root:current mean train loss 3196.5759022887323
INFO:root:current train perplexity3.5288171768188477
INFO:root:current mean train loss 3199.030590015453
INFO:root:current train perplexity3.527693748474121
INFO:root:current mean train loss 3196.8511309649493
INFO:root:current train perplexity3.530430316925049
INFO:root:current mean train loss 3198.6150986999046
INFO:root:current train perplexity3.5293703079223633
INFO:root:current mean train loss 3200.3529911268624
INFO:root:current train perplexity3.532865524291992
INFO:root:current mean train loss 3201.9782306514985
INFO:root:current train perplexity3.5332491397857666
INFO:root:current mean train loss 3202.4566730918687
INFO:root:current train perplexity3.533083200454712


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.84s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 4121.120279947917
INFO:root:eval perplexity: 5.29339599609375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/183

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [6:58:08<42:07, 148.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3190.3191886780755
INFO:root:current train perplexity3.538318395614624
INFO:root:current mean train loss 3207.3638848614837
INFO:root:current train perplexity3.53295636177063
INFO:root:current mean train loss 3200.7516829922174
INFO:root:current train perplexity3.5325305461883545
INFO:root:current mean train loss 3199.525233917657
INFO:root:current train perplexity3.5327706336975098
INFO:root:current mean train loss 3200.0800438503984
INFO:root:current train perplexity3.5330827236175537
INFO:root:current mean train loss 3198.451728238094
INFO:root:current train perplexity3.531881332397461
INFO:root:current mean train loss 3200.2189911947353
INFO:root:current train perplexity3.5318539142608643
INFO:root:current mean train loss 3201.7737059586952
INFO:root:current train perplexity3.5310473442077637
INFO:root:current mean train loss 3198.8788179859503
INFO:root:current train perplexity3.5300440788269043
INFO:root:current mean train loss 3199.2841708142687
INFO:root:current train perplexity3.5312838554382324


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.95s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.12s/it]
INFO:root:eval mean loss: 4121.641179078014
INFO:root:eval perplexity: 5.294511795043945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/184

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [7:00:18<38:09, 143.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3202.349365234375
INFO:root:current train perplexity3.529757022857666
INFO:root:current mean train loss 3206.5231605217473
INFO:root:current train perplexity3.526810646057129
INFO:root:current mean train loss 3204.902522125807
INFO:root:current train perplexity3.527190685272217
INFO:root:current mean train loss 3201.1613058825387
INFO:root:current train perplexity3.5254786014556885
INFO:root:current mean train loss 3200.310819524615
INFO:root:current train perplexity3.5254907608032227
INFO:root:current mean train loss 3200.102590798079
INFO:root:current train perplexity3.526323080062866
INFO:root:current mean train loss 3199.891302481138
INFO:root:current train perplexity3.528273582458496
INFO:root:current mean train loss 3198.731656837711
INFO:root:current train perplexity3.529116630554199
INFO:root:current mean train loss 3201.814998587292
INFO:root:current train perplexity3.5298707485198975
INFO:root:current mean train loss 3200.478016280735
INFO:root:current train perplexity3.530578374862671


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.76s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.44s/it]
INFO:root:eval mean loss: 4122.625621606272
INFO:root:eval perplexity: 5.296619892120361
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/185

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [7:03:25<39:02, 156.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3190.163762732397
INFO:root:current train perplexity3.5163733959198
INFO:root:current mean train loss 3184.2960089145427
INFO:root:current train perplexity3.5231175422668457
INFO:root:current mean train loss 3187.5173086077507
INFO:root:current train perplexity3.5306766033172607
INFO:root:current mean train loss 3191.6288740414743
INFO:root:current train perplexity3.526803970336914
INFO:root:current mean train loss 3195.108629326233
INFO:root:current train perplexity3.5281684398651123
INFO:root:current mean train loss 3196.6222668056457
INFO:root:current train perplexity3.526238203048706
INFO:root:current mean train loss 3198.5705886413843
INFO:root:current train perplexity3.528435230255127
INFO:root:current mean train loss 3198.811211288511
INFO:root:current train perplexity3.529571533203125
INFO:root:current mean train loss 3199.9392409254124
INFO:root:current train perplexity3.529557943344116
INFO:root:current mean train loss 3198.52183300482
INFO:root:current train perplexity3.5280869007110596


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.85s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.38s/it]
INFO:root:eval mean loss: 4121.279128920102
INFO:root:eval perplexity: 5.293736457824707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/186

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [7:05:45<35:16, 151.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3203.764606344289
INFO:root:current train perplexity3.5450665950775146
INFO:root:current mean train loss 3199.299055293282
INFO:root:current train perplexity3.536407470703125
INFO:root:current mean train loss 3202.3582665845493
INFO:root:current train perplexity3.5301437377929688
INFO:root:current mean train loss 3202.249039208858
INFO:root:current train perplexity3.5277085304260254
INFO:root:current mean train loss 3202.720463496214
INFO:root:current train perplexity3.5270440578460693
INFO:root:current mean train loss 3200.394120328471
INFO:root:current train perplexity3.527601718902588
INFO:root:current mean train loss 3202.0556796988717
INFO:root:current train perplexity3.52909517288208
INFO:root:current mean train loss 3200.311784640049
INFO:root:current train perplexity3.5290653705596924
INFO:root:current mean train loss 3199.0593660821237
INFO:root:current train perplexity3.5287318229675293
INFO:root:current mean train loss 3198.930585897923
INFO:root:current train perplexity3.529254198074341


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.13s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.61s/it]
INFO:root:eval mean loss: 4123.0812953651375
INFO:root:eval perplexity: 5.297595500946045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/187

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [7:07:51<31:09, 143.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3202.4996453536182
INFO:root:current train perplexity3.5173566341400146
INFO:root:current mean train loss 3196.88001176883
INFO:root:current train perplexity3.5232620239257812
INFO:root:current mean train loss 3195.8586823027013
INFO:root:current train perplexity3.524155855178833
INFO:root:current mean train loss 3192.9424724337423
INFO:root:current train perplexity3.5221197605133057
INFO:root:current mean train loss 3190.709741457544
INFO:root:current train perplexity3.5196433067321777
INFO:root:current mean train loss 3194.295221408876
INFO:root:current train perplexity3.524350881576538
INFO:root:current mean train loss 3197.505473667941
INFO:root:current train perplexity3.526498317718506
INFO:root:current mean train loss 3197.5122497174725
INFO:root:current train perplexity3.5265071392059326
INFO:root:current mean train loss 3196.2804695683485
INFO:root:current train perplexity3.5261549949645996


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.81s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.44s/it]
INFO:root:eval mean loss: 4122.512813054078
INFO:root:eval perplexity: 5.296378135681152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/188

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [7:10:01<27:56, 139.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3134.7831217447915
INFO:root:current train perplexity3.4294075965881348
INFO:root:current mean train loss 3190.0212354937803
INFO:root:current train perplexity3.5026609897613525
INFO:root:current mean train loss 3188.227985250539
INFO:root:current train perplexity3.5116114616394043
INFO:root:current mean train loss 3193.357304236283
INFO:root:current train perplexity3.5202274322509766
INFO:root:current mean train loss 3191.054838346193
INFO:root:current train perplexity3.5208330154418945
INFO:root:current mean train loss 3192.5627659822317
INFO:root:current train perplexity3.524315118789673
INFO:root:current mean train loss 3189.476991264381
INFO:root:current train perplexity3.5236752033233643
INFO:root:current mean train loss 3191.96348760613
INFO:root:current train perplexity3.521829128265381
INFO:root:current mean train loss 3192.0388724777204
INFO:root:current train perplexity3.521880865097046
INFO:root:current mean train loss 3196.5727917575095
INFO:root:current train perplexity3.524170160293579


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.73s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.83s/it]
INFO:root:eval mean loss: 4122.468514516844
INFO:root:eval perplexity: 5.29628324508667
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/189

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [7:12:08<24:53, 135.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3156.468106356534
INFO:root:current train perplexity3.5037477016448975
INFO:root:current mean train loss 3177.364090653153
INFO:root:current train perplexity3.5110979080200195
INFO:root:current mean train loss 3190.6815480598343
INFO:root:current train perplexity3.516146659851074
INFO:root:current mean train loss 3191.871854432526
INFO:root:current train perplexity3.517713785171509
INFO:root:current mean train loss 3189.8634927197386
INFO:root:current train perplexity3.5215978622436523
INFO:root:current mean train loss 3189.8560506742297
INFO:root:current train perplexity3.5222179889678955
INFO:root:current mean train loss 3188.179242372903
INFO:root:current train perplexity3.5199358463287354
INFO:root:current mean train loss 3190.3192054544656
INFO:root:current train perplexity3.5219552516937256
INFO:root:current mean train loss 3190.9043968191277
INFO:root:current train perplexity3.5213379859924316
INFO:root:current mean train loss 3193.8789681561298
INFO:root:current train perplexity3.522968053817749


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.03s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.56s/it]
INFO:root:eval mean loss: 4123.1932745318045
INFO:root:eval perplexity: 5.297835350036621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/190

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [7:14:13<22:06, 132.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3181.7561163651317
INFO:root:current train perplexity3.5375914573669434
INFO:root:current mean train loss 3211.09182970063
INFO:root:current train perplexity3.5305545330047607
INFO:root:current mean train loss 3204.4933535780538
INFO:root:current train perplexity3.5234086513519287
INFO:root:current mean train loss 3203.395620316174
INFO:root:current train perplexity3.5235085487365723
INFO:root:current mean train loss 3197.3533390746197
INFO:root:current train perplexity3.523892402648926
INFO:root:current mean train loss 3198.628624006503
INFO:root:current train perplexity3.524883508682251
INFO:root:current mean train loss 3195.1080201970162
INFO:root:current train perplexity3.523250102996826
INFO:root:current mean train loss 3194.8312770965535
INFO:root:current train perplexity3.523284673690796
INFO:root:current mean train loss 3192.98733896854
INFO:root:current train perplexity3.5231921672821045
INFO:root:current mean train loss 3193.463570446392
INFO:root:current train perplexity3.522559881210327


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.79s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.27s/it]
INFO:root:eval mean loss: 4123.84683032746
INFO:root:eval perplexity: 5.299236297607422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/191

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [7:16:19<19:36, 130.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3243.763970269097
INFO:root:current train perplexity3.5347342491149902
INFO:root:current mean train loss 3208.430298812746
INFO:root:current train perplexity3.5176472663879395
INFO:root:current mean train loss 3201.9892599635186
INFO:root:current train perplexity3.5222554206848145
INFO:root:current mean train loss 3201.408529392441
INFO:root:current train perplexity3.5226962566375732
INFO:root:current mean train loss 3197.5093699685303
INFO:root:current train perplexity3.521787166595459
INFO:root:current mean train loss 3200.1727987502964
INFO:root:current train perplexity3.5223217010498047
INFO:root:current mean train loss 3195.8993424167666
INFO:root:current train perplexity3.5212419033050537
INFO:root:current mean train loss 3193.5341387175463
INFO:root:current train perplexity3.519867420196533
INFO:root:current mean train loss 3191.903293743387
INFO:root:current train perplexity3.5198421478271484
INFO:root:current mean train loss 3192.1682315896373
INFO:root:current train perplexity3.5202748775482178


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.30s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.97s/it]
INFO:root:eval mean loss: 4123.674787372562
INFO:root:eval perplexity: 5.298867225646973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/192

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [7:18:26<17:14, 129.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3170.2867396763395
INFO:root:current train perplexity3.5127954483032227
INFO:root:current mean train loss 3192.761747685185
INFO:root:current train perplexity3.520542621612549
INFO:root:current mean train loss 3187.598276471077
INFO:root:current train perplexity3.5195868015289307
INFO:root:current mean train loss 3192.109616225513
INFO:root:current train perplexity3.5238828659057617
INFO:root:current mean train loss 3196.307580706717
INFO:root:current train perplexity3.523881196975708
INFO:root:current mean train loss 3191.053178847839
INFO:root:current train perplexity3.519367218017578
INFO:root:current mean train loss 3192.3983375369094
INFO:root:current train perplexity3.521334171295166
INFO:root:current mean train loss 3190.252223838754
INFO:root:current train perplexity3.520379066467285
INFO:root:current mean train loss 3190.3052427371817
INFO:root:current train perplexity3.519300699234009
INFO:root:current mean train loss 3191.4708587483287
INFO:root:current train perplexity3.5201027393341064


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.25s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.59s/it]
INFO:root:eval mean loss: 4123.54680227726
INFO:root:eval perplexity: 5.2985920906066895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/193

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [7:20:33<15:02, 128.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3193.0452625363373
INFO:root:current train perplexity3.5410830974578857
INFO:root:current mean train loss 3194.7964806189902
INFO:root:current train perplexity3.536295175552368
INFO:root:current mean train loss 3194.0448897247943
INFO:root:current train perplexity3.5258781909942627
INFO:root:current mean train loss 3189.20246375615
INFO:root:current train perplexity3.5252416133880615
INFO:root:current mean train loss 3192.948543092198
INFO:root:current train perplexity3.5219128131866455
INFO:root:current mean train loss 3192.291019221915
INFO:root:current train perplexity3.51912784576416
INFO:root:current mean train loss 3191.3763911839037
INFO:root:current train perplexity3.5194180011749268
INFO:root:current mean train loss 3190.476306858807
INFO:root:current train perplexity3.5178236961364746
INFO:root:current mean train loss 3193.4133040132897
INFO:root:current train perplexity3.519598960876465
INFO:root:current mean train loss 3193.589077671411
INFO:root:current train perplexity3.5198917388916016


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:56<00:00, 116.71s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.60s/it]
INFO:root:eval mean loss: 4123.824386704898
INFO:root:eval perplexity: 5.299187660217285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/194

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [7:22:40<12:48, 128.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3162.2067583869484
INFO:root:current train perplexity3.4886207580566406
INFO:root:current mean train loss 3178.759369502794
INFO:root:current train perplexity3.5059897899627686
INFO:root:current mean train loss 3183.417677921128
INFO:root:current train perplexity3.515650510787964
INFO:root:current mean train loss 3184.8553358985487
INFO:root:current train perplexity3.5168309211730957
INFO:root:current mean train loss 3186.477501169277
INFO:root:current train perplexity3.515993356704712
INFO:root:current mean train loss 3189.3814788098343
INFO:root:current train perplexity3.5195560455322266
INFO:root:current mean train loss 3192.684030277938
INFO:root:current train perplexity3.5218725204467773
INFO:root:current mean train loss 3190.8576790191205
INFO:root:current train perplexity3.5207314491271973
INFO:root:current mean train loss 3191.4665082669285
INFO:root:current train perplexity3.5207927227020264
INFO:root:current mean train loss 3192.3939053668837
INFO:root:current train perplexity3.5213687419891357


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.64s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.82s/it]
INFO:root:eval mean loss: 4123.443684895833
INFO:root:eval perplexity: 5.298372745513916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/195

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [7:24:53<10:47, 129.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3207.0084994041313
INFO:root:current train perplexity3.54156231880188
INFO:root:current mean train loss 3203.6494616622444
INFO:root:current train perplexity3.530000686645508
INFO:root:current mean train loss 3202.1772112165177
INFO:root:current train perplexity3.52372407913208
INFO:root:current mean train loss 3198.620305563414
INFO:root:current train perplexity3.5209786891937256
INFO:root:current mean train loss 3195.1749009608184
INFO:root:current train perplexity3.5197911262512207
INFO:root:current mean train loss 3189.0970828034156
INFO:root:current train perplexity3.5168726444244385
INFO:root:current mean train loss 3187.891308519656
INFO:root:current train perplexity3.5170388221740723
INFO:root:current mean train loss 3189.191620797822
INFO:root:current train perplexity3.518256902694702
INFO:root:current mean train loss 3191.1119437345387
INFO:root:current train perplexity3.518122673034668
INFO:root:current mean train loss 3191.249148435463
INFO:root:current train perplexity3.518662929534912


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.89s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.96s/it]
INFO:root:eval mean loss: 4124.123874529034
INFO:root:eval perplexity: 5.299829006195068
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/196

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [7:27:04<08:40, 130.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3203.05812004431
INFO:root:current train perplexity3.5267868041992188
INFO:root:current mean train loss 3191.3875301155504
INFO:root:current train perplexity3.52146315574646
INFO:root:current mean train loss 3196.121621349778
INFO:root:current train perplexity3.5218284130096436
INFO:root:current mean train loss 3195.007579003108
INFO:root:current train perplexity3.519174814224243
INFO:root:current mean train loss 3195.8040878655315
INFO:root:current train perplexity3.520209789276123
INFO:root:current mean train loss 3194.6926407317846
INFO:root:current train perplexity3.5199379920959473
INFO:root:current mean train loss 3191.481056956873
INFO:root:current train perplexity3.517777919769287
INFO:root:current mean train loss 3191.802461268538
INFO:root:current train perplexity3.519073963165283
INFO:root:current mean train loss 3190.480050866854
INFO:root:current train perplexity3.5179977416992188
INFO:root:current mean train loss 3189.886495564568
INFO:root:current train perplexity3.5175302028656006


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:58<00:00, 118.33s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.93s/it]
INFO:root:eval mean loss: 4124.089447237921
INFO:root:eval perplexity: 5.299755573272705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/197

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [7:29:26<06:40, 133.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3186.8873046875
INFO:root:current train perplexity3.5123867988586426
INFO:root:current mean train loss 3190.098397042411
INFO:root:current train perplexity3.51391339302063
INFO:root:current mean train loss 3187.4358780184657
INFO:root:current train perplexity3.5149741172790527
INFO:root:current mean train loss 3183.5394453125
INFO:root:current train perplexity3.512394428253174
INFO:root:current mean train loss 3187.6966550164475
INFO:root:current train perplexity3.512460947036743
INFO:root:current mean train loss 3189.541231742527
INFO:root:current train perplexity3.51301646232605
INFO:root:current mean train loss 3191.992907624421
INFO:root:current train perplexity3.516693353652954
INFO:root:current mean train loss 3189.7943097908264
INFO:root:current train perplexity3.5158395767211914
INFO:root:current mean train loss 3191.455518973214
INFO:root:current train perplexity3.516295909881592
INFO:root:current mean train loss 3190.446235977564
INFO:root:current train perplexity3.517739772796631


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.52s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.71s/it]
INFO:root:eval mean loss: 4124.140943594858
INFO:root:eval perplexity: 5.299866199493408
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/198

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [7:31:35<04:24, 132.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3184.0429540427335
INFO:root:current train perplexity3.5207810401916504
INFO:root:current mean train loss 3194.622587943989
INFO:root:current train perplexity3.5194973945617676
INFO:root:current mean train loss 3198.0399898892997
INFO:root:current train perplexity3.5271782875061035
INFO:root:current mean train loss 3195.361555054667
INFO:root:current train perplexity3.525433301925659
INFO:root:current mean train loss 3187.43136565088
INFO:root:current train perplexity3.521989583969116
INFO:root:current mean train loss 3191.3582765765705
INFO:root:current train perplexity3.525203227996826
INFO:root:current mean train loss 3191.954252765259
INFO:root:current train perplexity3.521348476409912
INFO:root:current mean train loss 3191.0405554058907
INFO:root:current train perplexity3.518104314804077
INFO:root:current mean train loss 3191.2067179868877
INFO:root:current train perplexity3.5164859294891357
INFO:root:current mean train loss 3190.579780089649
INFO:root:current train perplexity3.5170559883117676


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:57<00:00, 117.58s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.97s/it]
INFO:root:eval mean loss: 4124.236996481604
INFO:root:eval perplexity: 5.300070762634277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [7:33:53<02:14, 134.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3185.539379077953
INFO:root:current train perplexity3.5232746601104736
INFO:root:current mean train loss 3182.6454963084916
INFO:root:current train perplexity3.5070455074310303
INFO:root:current mean train loss 3182.9716360609964
INFO:root:current train perplexity3.5132627487182617
INFO:root:current mean train loss 3187.0235642533166
INFO:root:current train perplexity3.514479637145996
INFO:root:current mean train loss 3189.5643601427255
INFO:root:current train perplexity3.5170576572418213
INFO:root:current mean train loss 3189.3653438458387
INFO:root:current train perplexity3.5196027755737305
INFO:root:current mean train loss 3187.914033528175
INFO:root:current train perplexity3.5173590183258057
INFO:root:current mean train loss 3189.388546255235
INFO:root:current train perplexity3.516909122467041
INFO:root:current mean train loss 3190.147893047226
INFO:root:current train perplexity3.5173606872558594
INFO:root:current mean train loss 3189.5660566682172
INFO:root:current train perplexity3.5161919593811035


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.42s/it]
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.89s/it]
INFO:root:eval mean loss: 4124.310191918772
INFO:root:eval perplexity: 5.300229072570801
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_110/200

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [7:36:18<00:00, 137.18s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [7:36:18<00:00, 136.89s/it]
INFO:root:evaluating final model
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.43s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.43s/it]
INFO:root:eval mean loss: 4124.310191918772
INFO:root:eval perplexity: 5.300229072570801
INFO:root:evalaution complete
INFO:root:save model final: small_val_110/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x14b3b5e3ff06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x14b3b5e378e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x14b3b5d5ce09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x14b3b5e40a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x14b3b5d5a948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x14b3b5e40a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x14b3b5d15b46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x14b3b577a46a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x14b4b1fd2a27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x14b4b1fd2be0]
python(+0x24a989) [0x55750e14a989]
python(+0x24a9bd) [0x55750e14a9bd]
python(+0x24aa14) [0x55750e14aa14]
python(+0x108f75) [0x55750e008f75]
python(Py_RunMain+0x313) [0x55750e14d983]
python(Py_BytesMain+0x39) [0x55750e14dbc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x14b4b1fb00b3]
python(+0x1d6e13) [0x55750e0d6e13]
/opt/slurm/data/slurmd/job26146189/slurm_script: line 127: 731836 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path sentence-transformers/multi-qa-MiniLM-L6-cos-v1 --data_config data_config.json --data_folder fast_processed_data_110_final  --output small_val_110 --batch_size 128 --epochs 200 --save_head  --save_epochs 1 --external_embedding
"
