INFO:root:Output: v11
INFO:root:Steps per epochs:1983
INFO:root:Total steps:198300
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.value.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.query.bias', 'cls.predictions.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.key.bias', 'cls.predictions.decoder.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.value.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
INFO:root:current mean train loss 12240.634627525253
INFO:root:current train perplexity16733.34375
INFO:root:current mean train loss 10565.999892038317
INFO:root:current train perplexity4183.7109375
INFO:root:current mean train loss 9191.531356148098
INFO:root:current train perplexity1403.788818359375
INFO:root:current mean train loss 8241.23034270246
INFO:root:current train perplexity662.7943115234375
INFO:root:current mean train loss 7547.81859226265
INFO:root:current train perplexity384.3849182128906
INFO:root:current mean train loss 7021.5366084587595
INFO:root:current train perplexity253.7653045654297
INFO:root:current mean train loss 6611.394393287845
INFO:root:current train perplexity183.05442810058594
INFO:root:current mean train loss 6285.460170550102
INFO:root:current train perplexity141.1048126220703
INFO:root:current mean train loss 6008.501669335285
INFO:root:current train perplexity113.98999786376953
INFO:root:current mean train loss 5784.508976017033
INFO:root:current train perplexity95.03651428222656
INFO:root:current mean train loss 5584.993012557581
INFO:root:current train perplexity81.3905029296875
INFO:root:current mean train loss 5415.497774227546
INFO:root:current train perplexity71.2503433227539
INFO:root:current mean train loss 5268.781732454953
INFO:root:current train perplexity63.292030334472656
INFO:root:current mean train loss 5132.95249466695
INFO:root:current train perplexity57.00983810424805
INFO:root:current mean train loss 5014.255564744986
INFO:root:current train perplexity51.990089416503906
INFO:root:current mean train loss 4907.669857289957
INFO:root:current train perplexity47.825443267822266
INFO:root:current mean train loss 4812.174727378697
INFO:root:current train perplexity44.324951171875
INFO:root:current mean train loss 4723.699276426357
INFO:root:current train perplexity41.38542556762695
INFO:root:current mean train loss 4641.19569908813
INFO:root:current train perplexity38.83860778808594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.21s/it]
INFO:root:final mean train loss: 4577.097179295496
INFO:root:final train perplexity: 36.95771408081055
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.18s/it]
INFO:root:eval mean loss: 3481.271163986252
INFO:root:eval perplexity: 17.40290641784668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/1
  1%|          | 1/100 [05:57<9:50:18, 357.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3109.039276123047
INFO:root:current train perplexity11.527016639709473
INFO:root:current mean train loss 3102.034327013739
INFO:root:current train perplexity11.569591522216797
INFO:root:current mean train loss 3084.8485582139756
INFO:root:current train perplexity11.512731552124023
INFO:root:current mean train loss 3084.1753061028976
INFO:root:current train perplexity11.4981107711792
INFO:root:current mean train loss 3077.3125739464394
INFO:root:current train perplexity11.403772354125977
INFO:root:current mean train loss 3067.650849098383
INFO:root:current train perplexity11.266457557678223
INFO:root:current mean train loss 3049.6342698134386
INFO:root:current train perplexity11.134567260742188
INFO:root:current mean train loss 3039.1122763862822
INFO:root:current train perplexity11.036654472351074
INFO:root:current mean train loss 3030.5358994427847
INFO:root:current train perplexity10.961213111877441
INFO:root:current mean train loss 3024.6699965031385
INFO:root:current train perplexity10.885297775268555
INFO:root:current mean train loss 3012.3088873915785
INFO:root:current train perplexity10.800000190734863
INFO:root:current mean train loss 3004.0254805370046
INFO:root:current train perplexity10.708205223083496
INFO:root:current mean train loss 2997.2378746835807
INFO:root:current train perplexity10.635348320007324
INFO:root:current mean train loss 2988.698353126781
INFO:root:current train perplexity10.556116104125977
INFO:root:current mean train loss 2979.9634964937545
INFO:root:current train perplexity10.4862060546875
INFO:root:current mean train loss 2972.2873047197086
INFO:root:current train perplexity10.416031837463379
INFO:root:current mean train loss 2963.5245426291285
INFO:root:current train perplexity10.346790313720703
INFO:root:current mean train loss 2956.3044844762985
INFO:root:current train perplexity10.28591251373291
INFO:root:current mean train loss 2946.5576103311278
INFO:root:current train perplexity10.218279838562012
INFO:root:current mean train loss 2938.872932577432
INFO:root:current train perplexity10.149585723876953

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.44s/it]
INFO:root:final mean train loss: 2933.33960675015
INFO:root:final train perplexity: 10.108820915222168
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.31s/it]
INFO:root:eval mean loss: 3238.4676869252066
INFO:root:eval perplexity: 14.2591552734375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/2
  2%|â–         | 2/100 [11:59<9:48:00, 360.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2823.7322887073865
INFO:root:current train perplexity9.246149063110352
INFO:root:current mean train loss 2768.1931097274437
INFO:root:current train perplexity8.94943618774414
INFO:root:current mean train loss 2765.248668228608
INFO:root:current train perplexity8.908040046691895
INFO:root:current mean train loss 2753.6024283560905
INFO:root:current train perplexity8.840903282165527
INFO:root:current mean train loss 2756.787712678623
INFO:root:current train perplexity8.810516357421875
INFO:root:current mean train loss 2752.4685479999707
INFO:root:current train perplexity8.765096664428711
INFO:root:current mean train loss 2748.041723362831
INFO:root:current train perplexity8.72447395324707
INFO:root:current mean train loss 2742.6357651693597
INFO:root:current train perplexity8.691397666931152
INFO:root:current mean train loss 2738.608529153849
INFO:root:current train perplexity8.663169860839844
INFO:root:current mean train loss 2732.452046123476
INFO:root:current train perplexity8.630687713623047
INFO:root:current mean train loss 2727.8904276549642
INFO:root:current train perplexity8.600478172302246
INFO:root:current mean train loss 2723.051011168841
INFO:root:current train perplexity8.577232360839844
INFO:root:current mean train loss 2717.7911908597553
INFO:root:current train perplexity8.545933723449707
INFO:root:current mean train loss 2711.5609009063787
INFO:root:current train perplexity8.508047103881836
INFO:root:current mean train loss 2710.772435722697
INFO:root:current train perplexity8.49168872833252
INFO:root:current mean train loss 2709.779368062775
INFO:root:current train perplexity8.469001770019531
INFO:root:current mean train loss 2705.852396883851
INFO:root:current train perplexity8.442879676818848
INFO:root:current mean train loss 2702.465022241732
INFO:root:current train perplexity8.414859771728516
INFO:root:current mean train loss 2698.4346406377863
INFO:root:current train perplexity8.383742332458496
INFO:root:current mean train loss 2693.908428699318
INFO:root:current train perplexity8.35888385772705

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.99s/it]
INFO:root:final mean train loss: 2690.0776820257342
INFO:root:final train perplexity: 8.34411907196045
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.34s/it]
INFO:root:eval mean loss: 3126.0399598817567
INFO:root:eval perplexity: 13.002528190612793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/3
  3%|â–Ž         | 3/100 [18:03<9:45:00, 361.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2620.01408203125
INFO:root:current train perplexity7.849421501159668
INFO:root:current mean train loss 2609.9661865234375
INFO:root:current train perplexity7.826040744781494
INFO:root:current mean train loss 2602.03666015625
INFO:root:current train perplexity7.7962846755981445
INFO:root:current mean train loss 2595.6684953962053
INFO:root:current train perplexity7.745038032531738
INFO:root:current mean train loss 2599.653938259549
INFO:root:current train perplexity7.735960006713867
INFO:root:current mean train loss 2591.953976384943
INFO:root:current train perplexity7.6977338790893555
INFO:root:current mean train loss 2588.201006234976
INFO:root:current train perplexity7.681865692138672
INFO:root:current mean train loss 2585.179455403646
INFO:root:current train perplexity7.666675567626953
INFO:root:current mean train loss 2582.9220973115807
INFO:root:current train perplexity7.662743091583252
INFO:root:current mean train loss 2579.995341539885
INFO:root:current train perplexity7.642740726470947
INFO:root:current mean train loss 2576.6449400111605
INFO:root:current train perplexity7.62419319152832
INFO:root:current mean train loss 2576.2042858355976
INFO:root:current train perplexity7.617127418518066
INFO:root:current mean train loss 2573.0393791015626
INFO:root:current train perplexity7.603056907653809
INFO:root:current mean train loss 2570.8278804976853
INFO:root:current train perplexity7.588540077209473
INFO:root:current mean train loss 2570.470481883082
INFO:root:current train perplexity7.584385395050049
INFO:root:current mean train loss 2567.585086473034
INFO:root:current train perplexity7.5701584815979
INFO:root:current mean train loss 2566.0957263553505
INFO:root:current train perplexity7.559162616729736
INFO:root:current mean train loss 2563.2714888392857
INFO:root:current train perplexity7.541460037231445
INFO:root:current mean train loss 2562.1181866290117
INFO:root:current train perplexity7.534519195556641
INFO:root:current mean train loss 2560.0494805438702
INFO:root:current train perplexity7.524941444396973

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.67s/it]
INFO:root:final mean train loss: 2558.490025445781
INFO:root:final train perplexity: 7.521601676940918
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.32s/it]
INFO:root:eval mean loss: 3059.2646543027404
INFO:root:eval perplexity: 12.309237480163574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/4
  4%|â–         | 4/100 [24:10<9:42:16, 363.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2536.339891120569
INFO:root:current train perplexity7.238341808319092
INFO:root:current mean train loss 2500.6487196505427
INFO:root:current train perplexity7.1533894538879395
INFO:root:current mean train loss 2497.717043758778
INFO:root:current train perplexity7.158846378326416
INFO:root:current mean train loss 2497.452418522224
INFO:root:current train perplexity7.164864540100098
INFO:root:current mean train loss 2498.115128772417
INFO:root:current train perplexity7.174131870269775
INFO:root:current mean train loss 2493.1207342131006
INFO:root:current train perplexity7.139925956726074
INFO:root:current mean train loss 2494.269141796289
INFO:root:current train perplexity7.138594150543213
INFO:root:current mean train loss 2491.3074860454694
INFO:root:current train perplexity7.124174118041992
INFO:root:current mean train loss 2491.365894990809
INFO:root:current train perplexity7.112052917480469
INFO:root:current mean train loss 2487.665491997641
INFO:root:current train perplexity7.095463275909424
INFO:root:current mean train loss 2487.027772998184
INFO:root:current train perplexity7.090329170227051
INFO:root:current mean train loss 2486.4489298398003
INFO:root:current train perplexity7.083254814147949
INFO:root:current mean train loss 2483.372371297233
INFO:root:current train perplexity7.07139778137207
INFO:root:current mean train loss 2483.1138390050637
INFO:root:current train perplexity7.067327976226807
INFO:root:current mean train loss 2480.637792169926
INFO:root:current train perplexity7.062657356262207
INFO:root:current mean train loss 2478.5147793105857
INFO:root:current train perplexity7.058586120605469
INFO:root:current mean train loss 2474.818715334082
INFO:root:current train perplexity7.041959285736084
INFO:root:current mean train loss 2473.4689153855848
INFO:root:current train perplexity7.030708312988281
INFO:root:current mean train loss 2471.589028356927
INFO:root:current train perplexity7.021067142486572
INFO:root:current mean train loss 2469.6822697184202
INFO:root:current train perplexity7.0085649490356445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.95s/it]
INFO:root:final mean train loss: 2468.7257043450877
INFO:root:final train perplexity: 7.007533073425293
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.83s/it]
INFO:root:eval mean loss: 3022.5332610442474
INFO:root:eval perplexity: 11.943761825561523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/5
  5%|â–Œ         | 5/100 [30:25<9:42:25, 367.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2427.9885457356772
INFO:root:current train perplexity6.725142002105713
INFO:root:current mean train loss 2421.916290283203
INFO:root:current train perplexity6.73646354675293
INFO:root:current mean train loss 2419.991564253686
INFO:root:current train perplexity6.759950160980225
INFO:root:current mean train loss 2421.3760719299316
INFO:root:current train perplexity6.763882160186768
INFO:root:current mean train loss 2427.225592999419
INFO:root:current train perplexity6.7761664390563965
INFO:root:current mean train loss 2420.5793985863256
INFO:root:current train perplexity6.7412824630737305
INFO:root:current mean train loss 2418.7309857641744
INFO:root:current train perplexity6.720524311065674
INFO:root:current mean train loss 2418.926544500857
INFO:root:current train perplexity6.727940559387207
INFO:root:current mean train loss 2416.909862811749
INFO:root:current train perplexity6.714067459106445
INFO:root:current mean train loss 2412.3509857673957
INFO:root:current train perplexity6.6940789222717285
INFO:root:current mean train loss 2411.804463741964
INFO:root:current train perplexity6.694462776184082
INFO:root:current mean train loss 2410.2527547269256
INFO:root:current train perplexity6.687443256378174
INFO:root:current mean train loss 2409.0900501477013
INFO:root:current train perplexity6.682219505310059
INFO:root:current mean train loss 2408.9223467876454
INFO:root:current train perplexity6.67811918258667
INFO:root:current mean train loss 2409.32205660838
INFO:root:current train perplexity6.680185317993164
INFO:root:current mean train loss 2408.572568411779
INFO:root:current train perplexity6.671929836273193
INFO:root:current mean train loss 2407.665579462844
INFO:root:current train perplexity6.665836334228516
INFO:root:current mean train loss 2404.7549128511027
INFO:root:current train perplexity6.660302639007568
INFO:root:current mean train loss 2404.1031790893294
INFO:root:current train perplexity6.653234481811523

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.66s/it]
INFO:root:final mean train loss: 2401.6241409524905
INFO:root:final train perplexity: 6.646332740783691
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.99s/it]
INFO:root:eval mean loss: 2985.51708691113
INFO:root:eval perplexity: 11.586429595947266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/6
  6%|â–Œ         | 6/100 [36:35<9:37:21, 368.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2466.33984375
INFO:root:current train perplexity6.099257946014404
INFO:root:current mean train loss 2342.7676119662747
INFO:root:current train perplexity6.363081932067871
INFO:root:current mean train loss 2354.28564210199
INFO:root:current train perplexity6.419594764709473
INFO:root:current mean train loss 2364.173184518402
INFO:root:current train perplexity6.437361240386963
INFO:root:current mean train loss 2360.46037159299
INFO:root:current train perplexity6.43012809753418
INFO:root:current mean train loss 2357.6872531791887
INFO:root:current train perplexity6.4305644035339355
INFO:root:current mean train loss 2355.4396891411448
INFO:root:current train perplexity6.4235100746154785
INFO:root:current mean train loss 2357.5157808529666
INFO:root:current train perplexity6.4257893562316895
INFO:root:current mean train loss 2357.8329239939335
INFO:root:current train perplexity6.425272464752197
INFO:root:current mean train loss 2356.6427664465696
INFO:root:current train perplexity6.416147232055664
INFO:root:current mean train loss 2353.7492972115774
INFO:root:current train perplexity6.405904769897461
INFO:root:current mean train loss 2352.614853307185
INFO:root:current train perplexity6.397425651550293
INFO:root:current mean train loss 2352.209253214281
INFO:root:current train perplexity6.39393949508667
INFO:root:current mean train loss 2351.9700513014327
INFO:root:current train perplexity6.393919944763184
INFO:root:current mean train loss 2351.6216357909807
INFO:root:current train perplexity6.3928632736206055
INFO:root:current mean train loss 2351.960326009874
INFO:root:current train perplexity6.388731956481934
INFO:root:current mean train loss 2350.743460279342
INFO:root:current train perplexity6.382734298706055
INFO:root:current mean train loss 2350.5561311734136
INFO:root:current train perplexity6.382688522338867
INFO:root:current mean train loss 2350.445325581383
INFO:root:current train perplexity6.379024505615234
INFO:root:current mean train loss 2349.9734221272315
INFO:root:current train perplexity6.376486778259277

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.50s/it]
INFO:root:final mean train loss: 2348.595717468108
INFO:root:final train perplexity: 6.374105453491211
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.98s/it]
INFO:root:eval mean loss: 2953.0973307291665
INFO:root:eval perplexity: 11.282262802124023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/7
  7%|â–‹         | 7/100 [42:58<9:38:53, 373.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2310.053561740451
INFO:root:current train perplexity6.166299819946289
INFO:root:current mean train loss 2298.694319385593
INFO:root:current train perplexity6.2011895179748535
INFO:root:current mean train loss 2315.3416468069095
INFO:root:current train perplexity6.247843265533447
INFO:root:current mean train loss 2319.2890924417748
INFO:root:current train perplexity6.2495527267456055
INFO:root:current mean train loss 2317.7644866505307
INFO:root:current train perplexity6.220961570739746
INFO:root:current mean train loss 2317.6367877974935
INFO:root:current train perplexity6.2171783447265625
INFO:root:current mean train loss 2317.3582653058
INFO:root:current train perplexity6.210354804992676
INFO:root:current mean train loss 2318.2327629238116
INFO:root:current train perplexity6.213225841522217
INFO:root:current mean train loss 2317.0369422371637
INFO:root:current train perplexity6.202798843383789
INFO:root:current mean train loss 2315.448392182394
INFO:root:current train perplexity6.198639392852783
INFO:root:current mean train loss 2312.4583502808814
INFO:root:current train perplexity6.1885881423950195
INFO:root:current mean train loss 2312.7405301607573
INFO:root:current train perplexity6.182865619659424
INFO:root:current mean train loss 2312.471411092724
INFO:root:current train perplexity6.17877721786499
INFO:root:current mean train loss 2312.9745473210473
INFO:root:current train perplexity6.18491268157959
INFO:root:current mean train loss 2313.0075688758925
INFO:root:current train perplexity6.181687831878662
INFO:root:current mean train loss 2313.1155382641377
INFO:root:current train perplexity6.178041934967041
INFO:root:current mean train loss 2310.992907397974
INFO:root:current train perplexity6.170865058898926
INFO:root:current mean train loss 2309.0327835527096
INFO:root:current train perplexity6.163426399230957
INFO:root:current mean train loss 2307.9971106668772
INFO:root:current train perplexity6.162780284881592
INFO:root:current mean train loss 2305.831943547763
INFO:root:current train perplexity6.159538745880127

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.26s/it]
INFO:root:final mean train loss: 2305.2000086058647
INFO:root:final train perplexity: 6.159647464752197
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.34s/it]
INFO:root:eval mean loss: 2933.227320582301
INFO:root:eval perplexity: 11.099797248840332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/8
  8%|â–Š         | 8/100 [49:20<9:36:43, 376.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2273.915352957589
INFO:root:current train perplexity5.979830265045166
INFO:root:current mean train loss 2280.37715838397
INFO:root:current train perplexity5.991930961608887
INFO:root:current mean train loss 2272.875484125665
INFO:root:current train perplexity5.998783588409424
INFO:root:current mean train loss 2274.3851314715484
INFO:root:current train perplexity6.011477470397949
INFO:root:current mean train loss 2271.405396630298
INFO:root:current train perplexity6.015375137329102
INFO:root:current mean train loss 2270.5639488719335
INFO:root:current train perplexity6.00398063659668
INFO:root:current mean train loss 2273.4908372293307
INFO:root:current train perplexity6.000985145568848
INFO:root:current mean train loss 2275.5493212226297
INFO:root:current train perplexity6.003735065460205
INFO:root:current mean train loss 2275.9030709089634
INFO:root:current train perplexity6.007446765899658
INFO:root:current mean train loss 2277.705207114806
INFO:root:current train perplexity6.010727882385254
INFO:root:current mean train loss 2276.548627151268
INFO:root:current train perplexity6.01056432723999
INFO:root:current mean train loss 2273.7307222475565
INFO:root:current train perplexity6.003072738647461
INFO:root:current mean train loss 2271.683137197147
INFO:root:current train perplexity5.998589038848877
INFO:root:current mean train loss 2272.4304587832103
INFO:root:current train perplexity6.000433444976807
INFO:root:current mean train loss 2271.837418931702
INFO:root:current train perplexity5.998075008392334
INFO:root:current mean train loss 2272.608004313416
INFO:root:current train perplexity5.996968746185303
INFO:root:current mean train loss 2271.7318166750288
INFO:root:current train perplexity5.995677947998047
INFO:root:current mean train loss 2270.43655390231
INFO:root:current train perplexity5.990784645080566
INFO:root:current mean train loss 2269.0357039365845
INFO:root:current train perplexity5.985388278961182
INFO:root:current mean train loss 2268.9523768698523
INFO:root:current train perplexity5.984530448913574

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.17s/it]
INFO:root:final mean train loss: 2269.2768562690094
INFO:root:final train perplexity: 5.987585544586182
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.74s/it]
INFO:root:eval mean loss: 2915.098313890062
INFO:root:eval perplexity: 10.935900688171387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/9
  9%|â–‰         | 9/100 [55:32<9:28:33, 374.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2222.271479679988
INFO:root:current train perplexity5.810727596282959
INFO:root:current mean train loss 2231.5900051719264
INFO:root:current train perplexity5.775493621826172
INFO:root:current mean train loss 2241.272721063523
INFO:root:current train perplexity5.825395107269287
INFO:root:current mean train loss 2236.7024262168193
INFO:root:current train perplexity5.833085060119629
INFO:root:current mean train loss 2242.9832037191477
INFO:root:current train perplexity5.849302291870117
INFO:root:current mean train loss 2245.217037477355
INFO:root:current train perplexity5.857356071472168
INFO:root:current mean train loss 2247.7932684962734
INFO:root:current train perplexity5.864043235778809
INFO:root:current mean train loss 2244.401811315658
INFO:root:current train perplexity5.855072498321533
INFO:root:current mean train loss 2244.136602124138
INFO:root:current train perplexity5.8581414222717285
INFO:root:current mean train loss 2240.9844807857226
INFO:root:current train perplexity5.851271152496338
INFO:root:current mean train loss 2242.0484838449456
INFO:root:current train perplexity5.854372501373291
INFO:root:current mean train loss 2241.453169716729
INFO:root:current train perplexity5.8469953536987305
INFO:root:current mean train loss 2240.9117455040687
INFO:root:current train perplexity5.846001625061035
INFO:root:current mean train loss 2241.569385505992
INFO:root:current train perplexity5.852341651916504
INFO:root:current mean train loss 2240.291796555532
INFO:root:current train perplexity5.848006725311279
INFO:root:current mean train loss 2237.506137257999
INFO:root:current train perplexity5.839205265045166
INFO:root:current mean train loss 2237.4122277506904
INFO:root:current train perplexity5.83554744720459
INFO:root:current mean train loss 2238.943571116826
INFO:root:current train perplexity5.8394293785095215
INFO:root:current mean train loss 2237.2433775537215
INFO:root:current train perplexity5.834773540496826
INFO:root:current mean train loss 2237.358841380135
INFO:root:current train perplexity5.834975242614746

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.57s/it]
INFO:root:final mean train loss: 2236.4995985776563
INFO:root:final train perplexity: 5.834790229797363
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.47s/it]
INFO:root:eval mean loss: 2901.956374343093
INFO:root:eval perplexity: 10.818599700927734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/10
 10%|â–ˆ         | 10/100 [1:01:55<9:26:12, 377.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2231.1909038156705
INFO:root:current train perplexity5.753077030181885
INFO:root:current mean train loss 2231.8080368493434
INFO:root:current train perplexity5.733886241912842
INFO:root:current mean train loss 2213.2705845035143
INFO:root:current train perplexity5.694550037384033
INFO:root:current mean train loss 2211.8874157747923
INFO:root:current train perplexity5.697949409484863
INFO:root:current mean train loss 2212.6658284852247
INFO:root:current train perplexity5.6982502937316895
INFO:root:current mean train loss 2216.2590482205624
INFO:root:current train perplexity5.710331439971924
INFO:root:current mean train loss 2211.711916069635
INFO:root:current train perplexity5.700610637664795
INFO:root:current mean train loss 2213.3735151551323
INFO:root:current train perplexity5.7132439613342285
INFO:root:current mean train loss 2214.9391019445843
INFO:root:current train perplexity5.710087299346924
INFO:root:current mean train loss 2213.859883059412
INFO:root:current train perplexity5.710682392120361
INFO:root:current mean train loss 2212.299946398686
INFO:root:current train perplexity5.712051868438721
INFO:root:current mean train loss 2212.237586524774
INFO:root:current train perplexity5.712285041809082
INFO:root:current mean train loss 2211.6450509867204
INFO:root:current train perplexity5.70922327041626
INFO:root:current mean train loss 2212.1272920506813
INFO:root:current train perplexity5.7113823890686035
INFO:root:current mean train loss 2212.864499875686
INFO:root:current train perplexity5.7126665115356445
INFO:root:current mean train loss 2211.185697965215
INFO:root:current train perplexity5.710099220275879
INFO:root:current mean train loss 2210.3050972291135
INFO:root:current train perplexity5.708976745605469
INFO:root:current mean train loss 2209.2203653442316
INFO:root:current train perplexity5.707911968231201
INFO:root:current mean train loss 2208.2371601494574
INFO:root:current train perplexity5.706576824188232
INFO:root:current mean train loss 2209.72095067541
INFO:root:current train perplexity5.710683822631836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.41s/it]
INFO:root:final mean train loss: 2209.2840134182543
INFO:root:final train perplexity: 5.710887432098389
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.50s/it]
INFO:root:eval mean loss: 2880.977414426145
INFO:root:eval perplexity: 10.633954048156738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/11
 11%|â–ˆ         | 11/100 [1:08:23<9:24:18, 380.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2212.773633380269
INFO:root:current train perplexity5.64537239074707
INFO:root:current mean train loss 2182.475419239331
INFO:root:current train perplexity5.58880090713501
INFO:root:current mean train loss 2183.541015625
INFO:root:current train perplexity5.5874714851379395
INFO:root:current mean train loss 2192.6262260792787
INFO:root:current train perplexity5.615914344787598
INFO:root:current mean train loss 2187.783300077964
INFO:root:current train perplexity5.596083164215088
INFO:root:current mean train loss 2187.582002294755
INFO:root:current train perplexity5.5921831130981445
INFO:root:current mean train loss 2188.509880755455
INFO:root:current train perplexity5.595393657684326
INFO:root:current mean train loss 2188.496204793605
INFO:root:current train perplexity5.60313081741333
INFO:root:current mean train loss 2186.0275464197853
INFO:root:current train perplexity5.599184989929199
INFO:root:current mean train loss 2186.074739839194
INFO:root:current train perplexity5.602842807769775
INFO:root:current mean train loss 2182.4800719652826
INFO:root:current train perplexity5.593059062957764
INFO:root:current mean train loss 2185.5827687152523
INFO:root:current train perplexity5.598355770111084
INFO:root:current mean train loss 2184.595932837408
INFO:root:current train perplexity5.597607612609863
INFO:root:current mean train loss 2184.5794503348216
INFO:root:current train perplexity5.598434925079346
INFO:root:current mean train loss 2183.9824997502733
INFO:root:current train perplexity5.595871448516846
INFO:root:current mean train loss 2183.46867688096
INFO:root:current train perplexity5.592618942260742
INFO:root:current mean train loss 2183.6352443491437
INFO:root:current train perplexity5.593142509460449
INFO:root:current mean train loss 2183.939186292693
INFO:root:current train perplexity5.5954437255859375
INFO:root:current mean train loss 2184.058678085958
INFO:root:current train perplexity5.595774173736572

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.58s/it]
INFO:root:final mean train loss: 2183.7856759568144
INFO:root:final train perplexity: 5.5971903800964355
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.70s/it]
INFO:root:eval mean loss: 2874.4940614442567
INFO:root:eval perplexity: 10.577530860900879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/12
 12%|â–ˆâ–        | 12/100 [1:14:34<9:13:59, 377.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2058.6815185546875
INFO:root:current train perplexity5.15490198135376
INFO:root:current mean train loss 2164.446495278368
INFO:root:current train perplexity5.501917839050293
INFO:root:current mean train loss 2169.822266827663
INFO:root:current train perplexity5.526066780090332
INFO:root:current mean train loss 2165.1885813093027
INFO:root:current train perplexity5.51890754699707
INFO:root:current mean train loss 2160.6130861798233
INFO:root:current train perplexity5.514318466186523
INFO:root:current mean train loss 2163.5449221176846
INFO:root:current train perplexity5.5230584144592285
INFO:root:current mean train loss 2161.820084554441
INFO:root:current train perplexity5.521890163421631
INFO:root:current mean train loss 2159.9293542810387
INFO:root:current train perplexity5.515844821929932
INFO:root:current mean train loss 2159.471028443143
INFO:root:current train perplexity5.509728908538818
INFO:root:current mean train loss 2162.6151548873545
INFO:root:current train perplexity5.513621807098389
INFO:root:current mean train loss 2161.862882543775
INFO:root:current train perplexity5.509161472320557
INFO:root:current mean train loss 2160.4267160894647
INFO:root:current train perplexity5.504441738128662
INFO:root:current mean train loss 2158.984387278061
INFO:root:current train perplexity5.504939556121826
INFO:root:current mean train loss 2158.0872763387074
INFO:root:current train perplexity5.502629280090332
INFO:root:current mean train loss 2158.0825052621612
INFO:root:current train perplexity5.500523567199707
INFO:root:current mean train loss 2158.525179377573
INFO:root:current train perplexity5.495962142944336
INFO:root:current mean train loss 2160.5850355656385
INFO:root:current train perplexity5.497514724731445
INFO:root:current mean train loss 2159.533192229705
INFO:root:current train perplexity5.496068477630615
INFO:root:current mean train loss 2160.654255778672
INFO:root:current train perplexity5.498990535736084
INFO:root:current mean train loss 2161.6351001476905
INFO:root:current train perplexity5.50081729888916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.26s/it]
INFO:root:final mean train loss: 2161.9583173281485
INFO:root:final train perplexity: 5.501661777496338
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.38s/it]
INFO:root:eval mean loss: 2870.3163974521394
INFO:root:eval perplexity: 10.541333198547363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/13
 13%|â–ˆâ–Ž        | 13/100 [1:21:01<9:11:44, 380.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2213.889758300781
INFO:root:current train perplexity5.505138397216797
INFO:root:current mean train loss 2147.14069925944
INFO:root:current train perplexity5.394537448883057
INFO:root:current mean train loss 2151.893248401989
INFO:root:current train perplexity5.4167070388793945
INFO:root:current mean train loss 2142.335277938843
INFO:root:current train perplexity5.399384021759033
INFO:root:current mean train loss 2145.286701311384
INFO:root:current train perplexity5.399277210235596
INFO:root:current mean train loss 2146.420314143254
INFO:root:current train perplexity5.416390419006348
INFO:root:current mean train loss 2146.170739155431
INFO:root:current train perplexity5.414966106414795
INFO:root:current mean train loss 2147.321947903103
INFO:root:current train perplexity5.417793273925781
INFO:root:current mean train loss 2148.015862739377
INFO:root:current train perplexity5.420926570892334
INFO:root:current mean train loss 2148.339645916483
INFO:root:current train perplexity5.420815467834473
INFO:root:current mean train loss 2146.2785937739354
INFO:root:current train perplexity5.420917510986328
INFO:root:current mean train loss 2146.914187513079
INFO:root:current train perplexity5.423926830291748
INFO:root:current mean train loss 2144.178762767354
INFO:root:current train perplexity5.422723293304443
INFO:root:current mean train loss 2142.8872615929804
INFO:root:current train perplexity5.421245098114014
INFO:root:current mean train loss 2142.2861531862072
INFO:root:current train perplexity5.414974212646484
INFO:root:current mean train loss 2141.1918430529145
INFO:root:current train perplexity5.412919998168945
INFO:root:current mean train loss 2141.193246572989
INFO:root:current train perplexity5.411046981811523
INFO:root:current mean train loss 2140.9320844783338
INFO:root:current train perplexity5.409541606903076
INFO:root:current mean train loss 2141.6285459413634
INFO:root:current train perplexity5.413068771362305
INFO:root:current mean train loss 2142.7121151606243
INFO:root:current train perplexity5.414680480957031

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.12s/it]
INFO:root:final mean train loss: 2141.5932018839826
INFO:root:final train perplexity: 5.414005756378174
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.92s/it]
INFO:root:eval mean loss: 2859.588164824981
INFO:root:eval perplexity: 10.448943138122559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/14
 14%|â–ˆâ–        | 14/100 [1:27:28<9:08:19, 382.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2102.809154613598
INFO:root:current train perplexity5.281738758087158
INFO:root:current mean train loss 2100.5919332016992
INFO:root:current train perplexity5.301279067993164
INFO:root:current mean train loss 2115.8350737366495
INFO:root:current train perplexity5.324079990386963
INFO:root:current mean train loss 2112.478756505587
INFO:root:current train perplexity5.319057464599609
INFO:root:current mean train loss 2111.5762827718286
INFO:root:current train perplexity5.32819938659668
INFO:root:current mean train loss 2115.3918106959964
INFO:root:current train perplexity5.332569599151611
INFO:root:current mean train loss 2115.0469355560735
INFO:root:current train perplexity5.324475288391113
INFO:root:current mean train loss 2112.6570400615883
INFO:root:current train perplexity5.323424339294434
INFO:root:current mean train loss 2114.2764088985027
INFO:root:current train perplexity5.326225280761719
INFO:root:current mean train loss 2115.819357172784
INFO:root:current train perplexity5.331655025482178
INFO:root:current mean train loss 2116.3428261737586
INFO:root:current train perplexity5.333248138427734
INFO:root:current mean train loss 2118.675916203723
INFO:root:current train perplexity5.334469318389893
INFO:root:current mean train loss 2120.682645608074
INFO:root:current train perplexity5.339223384857178
INFO:root:current mean train loss 2120.8301628529357
INFO:root:current train perplexity5.339226245880127
INFO:root:current mean train loss 2121.1719806753435
INFO:root:current train perplexity5.33489990234375
INFO:root:current mean train loss 2122.446602537792
INFO:root:current train perplexity5.341374397277832
INFO:root:current mean train loss 2122.5255174677623
INFO:root:current train perplexity5.340359687805176
INFO:root:current mean train loss 2123.3467735769286
INFO:root:current train perplexity5.337464332580566
INFO:root:current mean train loss 2123.2538513615523
INFO:root:current train perplexity5.3350324630737305
INFO:root:current mean train loss 2124.2219250255107
INFO:root:current train perplexity5.33632230758667

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.95s/it]
INFO:root:final mean train loss: 2122.9695423182006
INFO:root:final train perplexity: 5.335067272186279
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.84s/it]
INFO:root:eval mean loss: 2855.2410782364395
INFO:root:eval perplexity: 10.411736488342285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/15
 15%|â–ˆâ–Œ        | 15/100 [1:33:54<9:03:26, 383.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2114.865320276331
INFO:root:current train perplexity5.242091178894043
INFO:root:current mean train loss 2106.230785815747
INFO:root:current train perplexity5.208796977996826
INFO:root:current mean train loss 2103.691804179995
INFO:root:current train perplexity5.2431793212890625
INFO:root:current mean train loss 2100.2261169778426
INFO:root:current train perplexity5.252255439758301
INFO:root:current mean train loss 2100.1142161365124
INFO:root:current train perplexity5.247992515563965
INFO:root:current mean train loss 2099.4423817107822
INFO:root:current train perplexity5.250223159790039
INFO:root:current mean train loss 2100.895142534822
INFO:root:current train perplexity5.248966217041016
INFO:root:current mean train loss 2102.572533078788
INFO:root:current train perplexity5.257144451141357
INFO:root:current mean train loss 2103.4780659374087
INFO:root:current train perplexity5.2555766105651855
INFO:root:current mean train loss 2102.1502372053933
INFO:root:current train perplexity5.254367351531982
INFO:root:current mean train loss 2102.62708758765
INFO:root:current train perplexity5.254088878631592
INFO:root:current mean train loss 2102.029058446504
INFO:root:current train perplexity5.256015777587891
INFO:root:current mean train loss 2104.0530024624327
INFO:root:current train perplexity5.260993003845215
INFO:root:current mean train loss 2106.1434518202723
INFO:root:current train perplexity5.266541957855225
INFO:root:current mean train loss 2105.6840987382598
INFO:root:current train perplexity5.262950897216797
INFO:root:current mean train loss 2106.029308265087
INFO:root:current train perplexity5.265189170837402
INFO:root:current mean train loss 2105.420554662702
INFO:root:current train perplexity5.263866901397705
INFO:root:current mean train loss 2105.608496288617
INFO:root:current train perplexity5.263735771179199
INFO:root:current mean train loss 2105.452824762338
INFO:root:current train perplexity5.263884544372559
INFO:root:current mean train loss 2107.049133175837
INFO:root:current train perplexity5.2662248611450195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.66s/it]
INFO:root:final mean train loss: 2106.845179262993
INFO:root:final train perplexity: 5.26765251159668
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.40s/it]
INFO:root:eval mean loss: 2844.947067673142
INFO:root:eval perplexity: 10.324159622192383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/16
 16%|â–ˆâ–Œ        | 16/100 [1:40:19<8:57:20, 383.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2105.058382276078
INFO:root:current train perplexity5.2707438468933105
INFO:root:current mean train loss 2084.16141336006
INFO:root:current train perplexity5.2067766189575195
INFO:root:current mean train loss 2082.3745027098707
INFO:root:current train perplexity5.211386203765869
INFO:root:current mean train loss 2083.478514308878
INFO:root:current train perplexity5.202874660491943
INFO:root:current mean train loss 2084.76648467564
INFO:root:current train perplexity5.197370529174805
INFO:root:current mean train loss 2085.8210923817865
INFO:root:current train perplexity5.191705226898193
INFO:root:current mean train loss 2085.0785214101506
INFO:root:current train perplexity5.191477298736572
INFO:root:current mean train loss 2087.3711054662167
INFO:root:current train perplexity5.190150260925293
INFO:root:current mean train loss 2086.188991332027
INFO:root:current train perplexity5.191055774688721
INFO:root:current mean train loss 2087.425449988132
INFO:root:current train perplexity5.191401481628418
INFO:root:current mean train loss 2087.0961404581362
INFO:root:current train perplexity5.187868118286133
INFO:root:current mean train loss 2088.225756377262
INFO:root:current train perplexity5.187975883483887
INFO:root:current mean train loss 2087.2176558811957
INFO:root:current train perplexity5.188230037689209
INFO:root:current mean train loss 2087.523110999755
INFO:root:current train perplexity5.191944599151611
INFO:root:current mean train loss 2087.4832832549073
INFO:root:current train perplexity5.193308353424072
INFO:root:current mean train loss 2088.4009879225764
INFO:root:current train perplexity5.196451663970947
INFO:root:current mean train loss 2088.331175150663
INFO:root:current train perplexity5.19252872467041
INFO:root:current mean train loss 2089.3878643223284
INFO:root:current train perplexity5.19665002822876
INFO:root:current mean train loss 2089.4628694209105
INFO:root:current train perplexity5.19827938079834
INFO:root:current mean train loss 2091.0455877186987
INFO:root:current train perplexity5.200968265533447

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.20s/it]
INFO:root:final mean train loss: 2090.937008948622
INFO:root:final train perplexity: 5.201976776123047
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.18s/it]
INFO:root:eval mean loss: 2842.6863064236113
INFO:root:eval perplexity: 10.305024147033691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/17
 17%|â–ˆâ–‹        | 17/100 [1:46:34<8:47:32, 381.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2059.2885756059127
INFO:root:current train perplexity5.092254161834717
INFO:root:current mean train loss 2066.0556997745593
INFO:root:current train perplexity5.106479644775391
INFO:root:current mean train loss 2074.0451655917695
INFO:root:current train perplexity5.119936943054199
INFO:root:current mean train loss 2066.155469127537
INFO:root:current train perplexity5.110770225524902
INFO:root:current mean train loss 2069.5466738841574
INFO:root:current train perplexity5.126453399658203
INFO:root:current mean train loss 2071.70945085798
INFO:root:current train perplexity5.12833309173584
INFO:root:current mean train loss 2072.900597683219
INFO:root:current train perplexity5.134631156921387
INFO:root:current mean train loss 2071.181453801654
INFO:root:current train perplexity5.1335859298706055
INFO:root:current mean train loss 2072.2926978033943
INFO:root:current train perplexity5.134941577911377
INFO:root:current mean train loss 2076.2339245259523
INFO:root:current train perplexity5.139583587646484
INFO:root:current mean train loss 2077.4934043884277
INFO:root:current train perplexity5.138321876525879
INFO:root:current mean train loss 2077.302720297868
INFO:root:current train perplexity5.134033679962158
INFO:root:current mean train loss 2075.199610076336
INFO:root:current train perplexity5.1321210861206055
INFO:root:current mean train loss 2074.528304306162
INFO:root:current train perplexity5.130199909210205
INFO:root:current mean train loss 2074.9336398545133
INFO:root:current train perplexity5.130821704864502
INFO:root:current mean train loss 2075.191374809976
INFO:root:current train perplexity5.134952068328857
INFO:root:current mean train loss 2076.2719171171507
INFO:root:current train perplexity5.13907527923584
INFO:root:current mean train loss 2076.168858880165
INFO:root:current train perplexity5.141124725341797
INFO:root:current mean train loss 2076.394330105539
INFO:root:current train perplexity5.142569065093994

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.08s/it]
INFO:root:final mean train loss: 2076.3576767883455
INFO:root:final train perplexity: 5.142505645751953
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.06s/it]
INFO:root:eval mean loss: 2838.984572218703
INFO:root:eval perplexity: 10.273771286010742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/18
 18%|â–ˆâ–Š        | 18/100 [1:52:58<8:41:59, 381.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2080.342822265625
INFO:root:current train perplexity5.149190425872803
INFO:root:current mean train loss 2059.8773135230654
INFO:root:current train perplexity5.086416721343994
INFO:root:current mean train loss 2062.7523884098705
INFO:root:current train perplexity5.082455158233643
INFO:root:current mean train loss 2066.5346419537655
INFO:root:current train perplexity5.095474720001221
INFO:root:current mean train loss 2063.578836926119
INFO:root:current train perplexity5.094494819641113
INFO:root:current mean train loss 2061.6481034382737
INFO:root:current train perplexity5.088149070739746
INFO:root:current mean train loss 2065.279521040483
INFO:root:current train perplexity5.094731330871582
INFO:root:current mean train loss 2064.725972406915
INFO:root:current train perplexity5.097684860229492
INFO:root:current mean train loss 2064.6777901785713
INFO:root:current train perplexity5.09149169921875
INFO:root:current mean train loss 2066.235020961024
INFO:root:current train perplexity5.096968173980713
INFO:root:current mean train loss 2068.692436499145
INFO:root:current train perplexity5.102389335632324
INFO:root:current mean train loss 2066.759509332579
INFO:root:current train perplexity5.095520496368408
INFO:root:current mean train loss 2066.118823748703
INFO:root:current train perplexity5.092735767364502
INFO:root:current mean train loss 2065.152166210189
INFO:root:current train perplexity5.091843605041504
INFO:root:current mean train loss 2064.782972277441
INFO:root:current train perplexity5.089768409729004
INFO:root:current mean train loss 2063.2211911629206
INFO:root:current train perplexity5.088231563568115
INFO:root:current mean train loss 2062.250706714856
INFO:root:current train perplexity5.086650371551514
INFO:root:current mean train loss 2063.0496776770988
INFO:root:current train perplexity5.088425636291504
INFO:root:current mean train loss 2062.294467881644
INFO:root:current train perplexity5.086630821228027
INFO:root:current mean train loss 2062.701269018619
INFO:root:current train perplexity5.088335990905762

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.35s/it]
INFO:root:final mean train loss: 2063.54213438741
INFO:root:final train perplexity: 5.090792655944824
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.56s/it]
INFO:root:eval mean loss: 2835.2529355527404
INFO:root:eval perplexity: 10.242358207702637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/19
 19%|â–ˆâ–‰        | 19/100 [1:59:25<8:37:45, 383.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2013.8665993430398
INFO:root:current train perplexity4.958954811096191
INFO:root:current mean train loss 2037.343994140625
INFO:root:current train perplexity4.966207027435303
INFO:root:current mean train loss 2034.6974949192356
INFO:root:current train perplexity4.977343559265137
INFO:root:current mean train loss 2036.1715281231802
INFO:root:current train perplexity4.981714725494385
INFO:root:current mean train loss 2044.7539392263404
INFO:root:current train perplexity4.987925052642822
INFO:root:current mean train loss 2046.432936862054
INFO:root:current train perplexity5.000152587890625
INFO:root:current mean train loss 2046.011319960812
INFO:root:current train perplexity5.006417274475098
INFO:root:current mean train loss 2044.5453320447757
INFO:root:current train perplexity5.00999641418457
INFO:root:current mean train loss 2046.8830101588637
INFO:root:current train perplexity5.011107921600342
INFO:root:current mean train loss 2047.6917631931265
INFO:root:current train perplexity5.012077331542969
INFO:root:current mean train loss 2046.642915191949
INFO:root:current train perplexity5.014947891235352
INFO:root:current mean train loss 2046.939368916068
INFO:root:current train perplexity5.0189313888549805
INFO:root:current mean train loss 2047.9306618648347
INFO:root:current train perplexity5.021821022033691
INFO:root:current mean train loss 2049.839663229984
INFO:root:current train perplexity5.0282087326049805
INFO:root:current mean train loss 2049.9051270733066
INFO:root:current train perplexity5.027032852172852
INFO:root:current mean train loss 2050.7435193657093
INFO:root:current train perplexity5.0305495262146
INFO:root:current mean train loss 2050.4053161846873
INFO:root:current train perplexity5.029693126678467
INFO:root:current mean train loss 2050.5473814996417
INFO:root:current train perplexity5.033637046813965
INFO:root:current mean train loss 2051.368752840714
INFO:root:current train perplexity5.037193298339844
INFO:root:current mean train loss 2051.842147017369
INFO:root:current train perplexity5.038783550262451

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.45s/it]
INFO:root:final mean train loss: 2049.952199253961
INFO:root:final train perplexity: 5.036520957946777
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.86s/it]
INFO:root:eval mean loss: 2830.2829934426613
INFO:root:eval perplexity: 10.200671195983887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/20
 20%|â–ˆâ–ˆ        | 20/100 [2:05:39<8:27:46, 380.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2015.156246869992
INFO:root:current train perplexity4.937347412109375
INFO:root:current mean train loss 2047.4597396301708
INFO:root:current train perplexity4.968685150146484
INFO:root:current mean train loss 2044.4360019572111
INFO:root:current train perplexity4.9697980880737305
INFO:root:current mean train loss 2043.2454571119101
INFO:root:current train perplexity4.970245361328125
INFO:root:current mean train loss 2040.994552716579
INFO:root:current train perplexity4.971433639526367
INFO:root:current mean train loss 2040.7557223573024
INFO:root:current train perplexity4.978033542633057
INFO:root:current mean train loss 2039.137022493031
INFO:root:current train perplexity4.984378337860107
INFO:root:current mean train loss 2040.278976584965
INFO:root:current train perplexity4.984956741333008
INFO:root:current mean train loss 2038.752163365288
INFO:root:current train perplexity4.985160827636719
INFO:root:current mean train loss 2039.2456646189014
INFO:root:current train perplexity4.984250545501709
INFO:root:current mean train loss 2038.74618950294
INFO:root:current train perplexity4.983433723449707
INFO:root:current mean train loss 2039.6283598808577
INFO:root:current train perplexity4.986050605773926
INFO:root:current mean train loss 2038.1338333979645
INFO:root:current train perplexity4.982388973236084
INFO:root:current mean train loss 2039.4942474707104
INFO:root:current train perplexity4.985553741455078
INFO:root:current mean train loss 2040.0673347139127
INFO:root:current train perplexity4.990162372589111
INFO:root:current mean train loss 2041.171348487502
INFO:root:current train perplexity4.994192600250244
INFO:root:current mean train loss 2040.0735229715624
INFO:root:current train perplexity4.992650985717773
INFO:root:current mean train loss 2040.4196603960386
INFO:root:current train perplexity4.994959354400635
INFO:root:current mean train loss 2040.369429703962
INFO:root:current train perplexity4.993924617767334
INFO:root:current mean train loss 2039.5330433444672
INFO:root:current train perplexity4.993427753448486

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.30s/it]
INFO:root:final mean train loss: 2038.4970157717553
INFO:root:final train perplexity: 4.991225242614746
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.96s/it]
INFO:root:eval mean loss: 2838.5168068459084
INFO:root:eval perplexity: 10.269827842712402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/21
 21%|â–ˆâ–ˆ        | 21/100 [2:11:55<8:19:19, 379.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2004.3473488943916
INFO:root:current train perplexity4.94346809387207
INFO:root:current mean train loss 2011.3584665151743
INFO:root:current train perplexity4.930856704711914
INFO:root:current mean train loss 2017.439877986908
INFO:root:current train perplexity4.94368314743042
INFO:root:current mean train loss 2022.0827300682497
INFO:root:current train perplexity4.950680255889893
INFO:root:current mean train loss 2023.7170300400048
INFO:root:current train perplexity4.951773643493652
INFO:root:current mean train loss 2023.6101256446016
INFO:root:current train perplexity4.939252853393555
INFO:root:current mean train loss 2021.9686083909942
INFO:root:current train perplexity4.937516689300537
INFO:root:current mean train loss 2023.1051655118429
INFO:root:current train perplexity4.9357171058654785
INFO:root:current mean train loss 2023.4261960894148
INFO:root:current train perplexity4.9383158683776855
INFO:root:current mean train loss 2025.2097399085137
INFO:root:current train perplexity4.939184665679932
INFO:root:current mean train loss 2025.2089376738577
INFO:root:current train perplexity4.94021463394165
INFO:root:current mean train loss 2025.5150678694042
INFO:root:current train perplexity4.939619064331055
INFO:root:current mean train loss 2024.9248941992498
INFO:root:current train perplexity4.935904502868652
INFO:root:current mean train loss 2026.0425433943758
INFO:root:current train perplexity4.93988561630249
INFO:root:current mean train loss 2026.496082347828
INFO:root:current train perplexity4.939099311828613
INFO:root:current mean train loss 2026.7637912779664
INFO:root:current train perplexity4.9398512840271
INFO:root:current mean train loss 2027.4356998314604
INFO:root:current train perplexity4.939610004425049
INFO:root:current mean train loss 2027.660709876406
INFO:root:current train perplexity4.941459655761719
INFO:root:current mean train loss 2028.1262545092352
INFO:root:current train perplexity4.943629741668701
INFO:root:current mean train loss 2027.6971378755472
INFO:root:current train perplexity4.945945739746094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.51s/it]
INFO:root:final mean train loss: 2027.2622389492817
INFO:root:final train perplexity: 4.947195053100586
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.70s/it]
INFO:root:eval mean loss: 2825.3588529936187
INFO:root:eval perplexity: 10.159538269042969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/22
 22%|â–ˆâ–ˆâ–       | 22/100 [2:18:07<8:10:20, 377.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2009.8295246281036
INFO:root:current train perplexity4.904271602630615
INFO:root:current mean train loss 2015.6038140974981
INFO:root:current train perplexity4.892678737640381
INFO:root:current mean train loss 2014.0069486177886
INFO:root:current train perplexity4.890445709228516
INFO:root:current mean train loss 2012.6254035192903
INFO:root:current train perplexity4.896498680114746
INFO:root:current mean train loss 2009.5565616535082
INFO:root:current train perplexity4.8759965896606445
INFO:root:current mean train loss 2012.2324225141115
INFO:root:current train perplexity4.885963439941406
INFO:root:current mean train loss 2012.7588004895872
INFO:root:current train perplexity4.890303134918213
INFO:root:current mean train loss 2011.1455894559044
INFO:root:current train perplexity4.889756202697754
INFO:root:current mean train loss 2011.8388764161834
INFO:root:current train perplexity4.892550945281982
INFO:root:current mean train loss 2014.1343497328253
INFO:root:current train perplexity4.895912170410156
INFO:root:current mean train loss 2016.007393388135
INFO:root:current train perplexity4.900650501251221
INFO:root:current mean train loss 2016.1046892899483
INFO:root:current train perplexity4.901153564453125
INFO:root:current mean train loss 2016.0401739823192
INFO:root:current train perplexity4.903352737426758
INFO:root:current mean train loss 2015.1840039702636
INFO:root:current train perplexity4.902215480804443
INFO:root:current mean train loss 2016.0229854337715
INFO:root:current train perplexity4.901121616363525
INFO:root:current mean train loss 2017.6335314188652
INFO:root:current train perplexity4.908254623413086
INFO:root:current mean train loss 2017.8399619531717
INFO:root:current train perplexity4.906713008880615
INFO:root:current mean train loss 2016.9709580061601
INFO:root:current train perplexity4.904147624969482
INFO:root:current mean train loss 2017.1008906244786
INFO:root:current train perplexity4.904495716094971
INFO:root:current mean train loss 2017.7238142165327
INFO:root:current train perplexity4.907342433929443

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.87s/it]
INFO:root:final mean train loss: 2016.799621089564
INFO:root:final train perplexity: 4.906542778015137
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.53s/it]
INFO:root:eval mean loss: 2826.5116366366365
INFO:root:eval perplexity: 10.169157028198242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/23
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [2:24:36<8:08:28, 380.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2021.1326185438368
INFO:root:current train perplexity4.855675220489502
INFO:root:current mean train loss 2004.5975110505756
INFO:root:current train perplexity4.8257598876953125
INFO:root:current mean train loss 2005.915895659348
INFO:root:current train perplexity4.841030120849609
INFO:root:current mean train loss 2010.2892427884615
INFO:root:current train perplexity4.853049278259277
INFO:root:current mean train loss 2002.3356684470664
INFO:root:current train perplexity4.841232776641846
INFO:root:current mean train loss 2004.6509161480403
INFO:root:current train perplexity4.847775936126709
INFO:root:current mean train loss 2006.7752264492754
INFO:root:current train perplexity4.855442047119141
INFO:root:current mean train loss 2008.0709999567346
INFO:root:current train perplexity4.854639530181885
INFO:root:current mean train loss 2007.2975980951544
INFO:root:current train perplexity4.8554911613464355
INFO:root:current mean train loss 2009.174019491793
INFO:root:current train perplexity4.863422393798828
INFO:root:current mean train loss 2007.0406373190224
INFO:root:current train perplexity4.862542629241943
INFO:root:current mean train loss 2005.5526688263196
INFO:root:current train perplexity4.854692459106445
INFO:root:current mean train loss 2004.5049847270168
INFO:root:current train perplexity4.850159168243408
INFO:root:current mean train loss 2004.1741614032992
INFO:root:current train perplexity4.852293968200684
INFO:root:current mean train loss 2004.7034517224204
INFO:root:current train perplexity4.855955600738525
INFO:root:current mean train loss 2006.4058040978773
INFO:root:current train perplexity4.861475467681885
INFO:root:current mean train loss 2005.8681963497365
INFO:root:current train perplexity4.863325595855713
INFO:root:current mean train loss 2006.2601809368452
INFO:root:current train perplexity4.86505651473999
INFO:root:current mean train loss 2006.8535286070808
INFO:root:current train perplexity4.866853713989258

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.75s/it]
INFO:root:final mean train loss: 2006.4497845948374
INFO:root:final train perplexity: 4.866655349731445
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.72s/it]
INFO:root:eval mean loss: 2825.761335309919
INFO:root:eval perplexity: 10.162894248962402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/24
 24%|â–ˆâ–ˆâ–       | 24/100 [2:30:50<7:59:28, 378.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1919.9733712332588
INFO:root:current train perplexity4.688728332519531
INFO:root:current mean train loss 1969.2243161780812
INFO:root:current train perplexity4.762373924255371
INFO:root:current mean train loss 1978.5926124462183
INFO:root:current train perplexity4.781137943267822
INFO:root:current mean train loss 1984.7925925984832
INFO:root:current train perplexity4.801601409912109
INFO:root:current mean train loss 1984.9197017285396
INFO:root:current train perplexity4.797150611877441
INFO:root:current mean train loss 1984.8855430708363
INFO:root:current train perplexity4.794146537780762
INFO:root:current mean train loss 1986.8165918692725
INFO:root:current train perplexity4.803589820861816
INFO:root:current mean train loss 1990.3934752641
INFO:root:current train perplexity4.8141374588012695
INFO:root:current mean train loss 1989.5972708284928
INFO:root:current train perplexity4.8118743896484375
INFO:root:current mean train loss 1990.9104376711946
INFO:root:current train perplexity4.814733505249023
INFO:root:current mean train loss 1991.1802822139555
INFO:root:current train perplexity4.818442344665527
INFO:root:current mean train loss 1992.1186659071182
INFO:root:current train perplexity4.817690372467041
INFO:root:current mean train loss 1995.4162146592791
INFO:root:current train perplexity4.828124523162842
INFO:root:current mean train loss 1994.9890231050056
INFO:root:current train perplexity4.82605504989624
INFO:root:current mean train loss 1995.3001040937888
INFO:root:current train perplexity4.8272905349731445
INFO:root:current mean train loss 1996.402383846088
INFO:root:current train perplexity4.828104019165039
INFO:root:current mean train loss 1998.1394963623502
INFO:root:current train perplexity4.830366611480713
INFO:root:current mean train loss 1997.4418205167372
INFO:root:current train perplexity4.830616474151611
INFO:root:current mean train loss 1997.5987962934942
INFO:root:current train perplexity4.831559181213379
INFO:root:current mean train loss 1997.0713681809616
INFO:root:current train perplexity4.830207347869873

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.95s/it]
INFO:root:final mean train loss: 1996.6159813862164
INFO:root:final train perplexity: 4.8290581703186035
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.98s/it]
INFO:root:eval mean loss: 2826.7903235266517
INFO:root:eval perplexity: 10.171480178833008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/25
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [2:37:04<7:51:31, 377.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1964.9058380126953
INFO:root:current train perplexity4.733513832092285
INFO:root:current mean train loss 1961.433333858367
INFO:root:current train perplexity4.778234004974365
INFO:root:current mean train loss 1973.908284323556
INFO:root:current train perplexity4.79240608215332
INFO:root:current mean train loss 1979.6320830922068
INFO:root:current train perplexity4.777782917022705
INFO:root:current mean train loss 1978.4563984421063
INFO:root:current train perplexity4.773192405700684
INFO:root:current mean train loss 1980.2866609296725
INFO:root:current train perplexity4.773024082183838
INFO:root:current mean train loss 1983.799437107184
INFO:root:current train perplexity4.78229284286499
INFO:root:current mean train loss 1986.1416460743267
INFO:root:current train perplexity4.789802074432373
INFO:root:current mean train loss 1986.7072900568398
INFO:root:current train perplexity4.787949562072754
INFO:root:current mean train loss 1985.626245539942
INFO:root:current train perplexity4.782299995422363
INFO:root:current mean train loss 1986.5425782203674
INFO:root:current train perplexity4.789607048034668
INFO:root:current mean train loss 1987.0100870913034
INFO:root:current train perplexity4.785835266113281
INFO:root:current mean train loss 1985.653287201925
INFO:root:current train perplexity4.780543804168701
INFO:root:current mean train loss 1985.9877677986628
INFO:root:current train perplexity4.78430700302124
INFO:root:current mean train loss 1986.9176660602013
INFO:root:current train perplexity4.786099910736084
INFO:root:current mean train loss 1987.351468063715
INFO:root:current train perplexity4.787384986877441
INFO:root:current mean train loss 1988.1804450274687
INFO:root:current train perplexity4.78853178024292
INFO:root:current mean train loss 1989.2956268947805
INFO:root:current train perplexity4.791921138763428
INFO:root:current mean train loss 1988.498216595566
INFO:root:current train perplexity4.793911457061768
INFO:root:current mean train loss 1988.6917874342191
INFO:root:current train perplexity4.793705940246582

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.13s/it]
INFO:root:final mean train loss: 1987.1567218451564
INFO:root:final train perplexity: 4.7931671142578125
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.02s/it]
INFO:root:eval mean loss: 2826.692521378801
INFO:root:eval perplexity: 10.17066478729248
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/26
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [2:43:17<7:43:48, 376.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1991.0506145198171
INFO:root:current train perplexity4.763492584228516
INFO:root:current mean train loss 1973.2274317098847
INFO:root:current train perplexity4.755676746368408
INFO:root:current mean train loss 1975.541018664095
INFO:root:current train perplexity4.76820182800293
INFO:root:current mean train loss 1984.0107615182826
INFO:root:current train perplexity4.774722576141357
INFO:root:current mean train loss 1976.802606215012
INFO:root:current train perplexity4.767098903656006
INFO:root:current mean train loss 1978.1936646636004
INFO:root:current train perplexity4.765719413757324
INFO:root:current mean train loss 1978.0453423605695
INFO:root:current train perplexity4.766376972198486
INFO:root:current mean train loss 1978.058382721565
INFO:root:current train perplexity4.769005298614502
INFO:root:current mean train loss 1982.167409781185
INFO:root:current train perplexity4.77644157409668
INFO:root:current mean train loss 1980.4538306987247
INFO:root:current train perplexity4.770030498504639
INFO:root:current mean train loss 1978.2016544103851
INFO:root:current train perplexity4.7646164894104
INFO:root:current mean train loss 1979.153558461944
INFO:root:current train perplexity4.761480808258057
INFO:root:current mean train loss 1979.0561664098698
INFO:root:current train perplexity4.759096622467041
INFO:root:current mean train loss 1979.3604405891708
INFO:root:current train perplexity4.761020183563232
INFO:root:current mean train loss 1979.6098587915021
INFO:root:current train perplexity4.762967586517334
INFO:root:current mean train loss 1979.3398732179794
INFO:root:current train perplexity4.76301908493042
INFO:root:current mean train loss 1978.761315642734
INFO:root:current train perplexity4.761682033538818
INFO:root:current mean train loss 1978.7473802911627
INFO:root:current train perplexity4.761326313018799
INFO:root:current mean train loss 1978.8391731921129
INFO:root:current train perplexity4.7604522705078125
INFO:root:current mean train loss 1978.9296546083083
INFO:root:current train perplexity4.76064920425415

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.30s/it]
INFO:root:final mean train loss: 1978.679884240655
INFO:root:final train perplexity: 4.761229515075684
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.62s/it]
INFO:root:eval mean loss: 2823.6154843808654
INFO:root:eval perplexity: 10.145017623901367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/27
 27%|â–ˆâ–ˆâ–‹       | 27/100 [2:49:33<7:37:33, 376.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1981.5002904431574
INFO:root:current train perplexity4.687719821929932
INFO:root:current mean train loss 1961.3023333972014
INFO:root:current train perplexity4.6787943840026855
INFO:root:current mean train loss 1952.246471789456
INFO:root:current train perplexity4.692625522613525
INFO:root:current mean train loss 1952.986769692192
INFO:root:current train perplexity4.690978527069092
INFO:root:current mean train loss 1957.1316781522926
INFO:root:current train perplexity4.703503131866455
INFO:root:current mean train loss 1962.595197998922
INFO:root:current train perplexity4.711969375610352
INFO:root:current mean train loss 1964.6522404169239
INFO:root:current train perplexity4.7158403396606445
INFO:root:current mean train loss 1965.9107996153014
INFO:root:current train perplexity4.717866897583008
INFO:root:current mean train loss 1967.1399544669198
INFO:root:current train perplexity4.722762107849121
INFO:root:current mean train loss 1966.4882764079625
INFO:root:current train perplexity4.718997478485107
INFO:root:current mean train loss 1965.7828755658154
INFO:root:current train perplexity4.71750545501709
INFO:root:current mean train loss 1967.266284369434
INFO:root:current train perplexity4.719117641448975
INFO:root:current mean train loss 1968.7746636370975
INFO:root:current train perplexity4.721723556518555
INFO:root:current mean train loss 1968.562234465609
INFO:root:current train perplexity4.719719886779785
INFO:root:current mean train loss 1968.7608887890892
INFO:root:current train perplexity4.72071647644043
INFO:root:current mean train loss 1969.7074390651326
INFO:root:current train perplexity4.723276138305664
INFO:root:current mean train loss 1969.4738741553736
INFO:root:current train perplexity4.722682476043701
INFO:root:current mean train loss 1968.8241332035693
INFO:root:current train perplexity4.720794200897217
INFO:root:current mean train loss 1969.5080055918452
INFO:root:current train perplexity4.725161075592041
INFO:root:current mean train loss 1969.8762620997989
INFO:root:current train perplexity4.726147174835205

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.58s/it]
INFO:root:final mean train loss: 1969.6927701379695
INFO:root:final train perplexity: 4.727602481842041
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.78s/it]
INFO:root:eval mean loss: 2826.1557785813156
INFO:root:eval perplexity: 10.166184425354004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/28
 28%|â–ˆâ–ˆâ–Š       | 28/100 [2:55:45<7:29:39, 374.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1980.2741438802084
INFO:root:current train perplexity4.730206489562988
INFO:root:current mean train loss 1969.2134988839287
INFO:root:current train perplexity4.688850402832031
INFO:root:current mean train loss 1964.4352325994319
INFO:root:current train perplexity4.689189434051514
INFO:root:current mean train loss 1964.7871158854166
INFO:root:current train perplexity4.696297645568848
INFO:root:current mean train loss 1965.0920690275493
INFO:root:current train perplexity4.700894832611084
INFO:root:current mean train loss 1961.0353248131794
INFO:root:current train perplexity4.691081523895264
INFO:root:current mean train loss 1960.3045793547453
INFO:root:current train perplexity4.6903300285339355
INFO:root:current mean train loss 1963.9174234501008
INFO:root:current train perplexity4.698124885559082
INFO:root:current mean train loss 1964.0227469308036
INFO:root:current train perplexity4.696432113647461
INFO:root:current mean train loss 1965.1051143078926
INFO:root:current train perplexity4.696052551269531
INFO:root:current mean train loss 1965.6376500045421
INFO:root:current train perplexity4.696540832519531
INFO:root:current mean train loss 1963.8531173121676
INFO:root:current train perplexity4.696604251861572
INFO:root:current mean train loss 1962.2030331839767
INFO:root:current train perplexity4.694336414337158
INFO:root:current mean train loss 1961.3510375532671
INFO:root:current train perplexity4.696374416351318
INFO:root:current mean train loss 1961.2301285255562
INFO:root:current train perplexity4.694316387176514
INFO:root:current mean train loss 1962.744867466518
INFO:root:current train perplexity4.696209907531738
INFO:root:current mean train loss 1963.0952255567863
INFO:root:current train perplexity4.697720050811768
INFO:root:current mean train loss 1962.4664800423636
INFO:root:current train perplexity4.697459697723389
INFO:root:current mean train loss 1962.6878343098958
INFO:root:current train perplexity4.699026584625244
INFO:root:current mean train loss 1962.1998571622823
INFO:root:current train perplexity4.6983747482299805

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.32s/it]
INFO:root:final mean train loss: 1961.861085954244
INFO:root:final train perplexity: 4.698492527008057
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.08s/it]
INFO:root:eval mean loss: 2826.730807467624
INFO:root:eval perplexity: 10.170982360839844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/29
 29%|â–ˆâ–ˆâ–‰       | 29/100 [3:02:10<7:27:16, 377.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1948.6715273649795
INFO:root:current train perplexity4.643115997314453
INFO:root:current mean train loss 1946.465445836385
INFO:root:current train perplexity4.648410797119141
INFO:root:current mean train loss 1953.5008783209814
INFO:root:current train perplexity4.648846626281738
INFO:root:current mean train loss 1954.0822196493343
INFO:root:current train perplexity4.649549961090088
INFO:root:current mean train loss 1961.8670168000508
INFO:root:current train perplexity4.661787986755371
INFO:root:current mean train loss 1961.6879055951092
INFO:root:current train perplexity4.668045520782471
INFO:root:current mean train loss 1961.0631318726291
INFO:root:current train perplexity4.661933898925781
INFO:root:current mean train loss 1959.0122212111348
INFO:root:current train perplexity4.661363124847412
INFO:root:current mean train loss 1960.3558816268305
INFO:root:current train perplexity4.662786960601807
INFO:root:current mean train loss 1959.6483594832882
INFO:root:current train perplexity4.663759231567383
INFO:root:current mean train loss 1958.1151171114855
INFO:root:current train perplexity4.659323215484619
INFO:root:current mean train loss 1957.4876031043545
INFO:root:current train perplexity4.660522937774658
INFO:root:current mean train loss 1957.04833417485
INFO:root:current train perplexity4.6606621742248535
INFO:root:current mean train loss 1956.6100836567496
INFO:root:current train perplexity4.663150310516357
INFO:root:current mean train loss 1957.647095790178
INFO:root:current train perplexity4.665660858154297
INFO:root:current mean train loss 1956.7043644890714
INFO:root:current train perplexity4.664306163787842
INFO:root:current mean train loss 1955.787699453656
INFO:root:current train perplexity4.664126873016357
INFO:root:current mean train loss 1953.907291139875
INFO:root:current train perplexity4.6648640632629395
INFO:root:current mean train loss 1953.8716559702448
INFO:root:current train perplexity4.6669487953186035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.14s/it]
INFO:root:final mean train loss: 1953.5015876527634
INFO:root:final train perplexity: 4.6676177978515625
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.36s/it]
INFO:root:eval mean loss: 2820.317188526417
INFO:root:eval perplexity: 10.117597579956055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/30
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [3:08:23<7:19:07, 376.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1894.9984130859375
INFO:root:current train perplexity4.662429332733154
INFO:root:current mean train loss 1929.6173644459575
INFO:root:current train perplexity4.624739646911621
INFO:root:current mean train loss 1940.2359654184734
INFO:root:current train perplexity4.629720211029053
INFO:root:current mean train loss 1942.0743668935831
INFO:root:current train perplexity4.641949653625488
INFO:root:current mean train loss 1946.340109081315
INFO:root:current train perplexity4.6369524002075195
INFO:root:current mean train loss 1941.412280369367
INFO:root:current train perplexity4.620415687561035
INFO:root:current mean train loss 1942.006790837631
INFO:root:current train perplexity4.620608329772949
INFO:root:current mean train loss 1941.3702607793768
INFO:root:current train perplexity4.622126579284668
INFO:root:current mean train loss 1942.9662897324533
INFO:root:current train perplexity4.623165130615234
INFO:root:current mean train loss 1943.5878187794365
INFO:root:current train perplexity4.626428604125977
INFO:root:current mean train loss 1945.06474674705
INFO:root:current train perplexity4.6300530433654785
INFO:root:current mean train loss 1944.9959320536168
INFO:root:current train perplexity4.631317138671875
INFO:root:current mean train loss 1945.4166472808106
INFO:root:current train perplexity4.635138034820557
INFO:root:current mean train loss 1945.9396267651236
INFO:root:current train perplexity4.6357622146606445
INFO:root:current mean train loss 1946.5076513567913
INFO:root:current train perplexity4.635290145874023
INFO:root:current mean train loss 1946.3841009121054
INFO:root:current train perplexity4.636598110198975
INFO:root:current mean train loss 1946.4455103616376
INFO:root:current train perplexity4.636721134185791
INFO:root:current mean train loss 1946.467712223774
INFO:root:current train perplexity4.638916015625
INFO:root:current mean train loss 1946.3028936264857
INFO:root:current train perplexity4.639553070068359
INFO:root:current mean train loss 1946.0440938558922
INFO:root:current train perplexity4.6391167640686035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.89s/it]
INFO:root:final mean train loss: 1945.7076313213092
INFO:root:final train perplexity: 4.639015197753906
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.64s/it]
INFO:root:eval mean loss: 2825.8371523378846
INFO:root:eval perplexity: 10.16352653503418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/31
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [3:14:37<7:11:56, 375.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1929.5270010141226
INFO:root:current train perplexity4.5983099937438965
INFO:root:current mean train loss 1935.1969507610986
INFO:root:current train perplexity4.596796035766602
INFO:root:current mean train loss 1936.3406890599074
INFO:root:current train perplexity4.592492580413818
INFO:root:current mean train loss 1927.9754814662817
INFO:root:current train perplexity4.571015357971191
INFO:root:current mean train loss 1927.2312593415309
INFO:root:current train perplexity4.570088863372803
INFO:root:current mean train loss 1930.0384189620218
INFO:root:current train perplexity4.577872276306152
INFO:root:current mean train loss 1931.4623329235724
INFO:root:current train perplexity4.5831990242004395
INFO:root:current mean train loss 1934.7179153484417
INFO:root:current train perplexity4.587766170501709
INFO:root:current mean train loss 1938.3642776156742
INFO:root:current train perplexity4.594944953918457
INFO:root:current mean train loss 1936.6893267044495
INFO:root:current train perplexity4.594453811645508
INFO:root:current mean train loss 1936.7305897495203
INFO:root:current train perplexity4.599369525909424
INFO:root:current mean train loss 1938.820800022376
INFO:root:current train perplexity4.607536792755127
INFO:root:current mean train loss 1938.9659176899597
INFO:root:current train perplexity4.6101861000061035
INFO:root:current mean train loss 1939.6829117764894
INFO:root:current train perplexity4.60980224609375
INFO:root:current mean train loss 1938.713066796601
INFO:root:current train perplexity4.61112117767334
INFO:root:current mean train loss 1937.2827838782714
INFO:root:current train perplexity4.610599517822266
INFO:root:current mean train loss 1938.4391095864084
INFO:root:current train perplexity4.613044261932373
INFO:root:current mean train loss 1939.2698052363214
INFO:root:current train perplexity4.615330696105957
INFO:root:current mean train loss 1938.859796630592
INFO:root:current train perplexity4.613505840301514
INFO:root:current mean train loss 1939.0181909483913
INFO:root:current train perplexity4.615314960479736

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.18s/it]
INFO:root:final mean train loss: 1939.2927525568898
INFO:root:final train perplexity: 4.615605354309082
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.10s/it]
INFO:root:eval mean loss: 2823.7334101679803
INFO:root:eval perplexity: 10.145998001098633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/32
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [3:21:02<7:09:01, 378.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1908.7339065906613
INFO:root:current train perplexity4.47605037689209
INFO:root:current mean train loss 1927.624892441543
INFO:root:current train perplexity4.53321647644043
INFO:root:current mean train loss 1934.499383117927
INFO:root:current train perplexity4.562839031219482
INFO:root:current mean train loss 1934.2851850771
INFO:root:current train perplexity4.571998596191406
INFO:root:current mean train loss 1929.4106472867875
INFO:root:current train perplexity4.567382335662842
INFO:root:current mean train loss 1925.9505010502992
INFO:root:current train perplexity4.564286231994629
INFO:root:current mean train loss 1923.6109712164657
INFO:root:current train perplexity4.567277431488037
INFO:root:current mean train loss 1925.0505364521996
INFO:root:current train perplexity4.571206569671631
INFO:root:current mean train loss 1925.490561199075
INFO:root:current train perplexity4.573906421661377
INFO:root:current mean train loss 1928.655353566369
INFO:root:current train perplexity4.578622341156006
INFO:root:current mean train loss 1929.429439146018
INFO:root:current train perplexity4.581806659698486
INFO:root:current mean train loss 1929.7591154377187
INFO:root:current train perplexity4.582977771759033
INFO:root:current mean train loss 1931.3778852000892
INFO:root:current train perplexity4.584813594818115
INFO:root:current mean train loss 1931.703357688012
INFO:root:current train perplexity4.584022045135498
INFO:root:current mean train loss 1931.7304799165152
INFO:root:current train perplexity4.584447383880615
INFO:root:current mean train loss 1932.7370550090125
INFO:root:current train perplexity4.584763050079346
INFO:root:current mean train loss 1933.4717941052002
INFO:root:current train perplexity4.585733413696289
INFO:root:current mean train loss 1932.8558566716642
INFO:root:current train perplexity4.586585521697998
INFO:root:current mean train loss 1932.5330303852415
INFO:root:current train perplexity4.589127063751221
INFO:root:current mean train loss 1932.8898605998497
INFO:root:current train perplexity4.5901641845703125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.61s/it]
INFO:root:final mean train loss: 1932.0159986595042
INFO:root:final train perplexity: 4.589191913604736
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.73s/it]
INFO:root:eval mean loss: 2829.047353750235
INFO:root:eval perplexity: 10.190335273742676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/33
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [3:27:15<7:00:41, 376.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1895.192049153646
INFO:root:current train perplexity4.490994930267334
INFO:root:current mean train loss 1903.4512199401856
INFO:root:current train perplexity4.528500556945801
INFO:root:current mean train loss 1907.9875037560096
INFO:root:current train perplexity4.542034149169922
INFO:root:current mean train loss 1909.9621015760633
INFO:root:current train perplexity4.544118881225586
INFO:root:current mean train loss 1909.3958578358527
INFO:root:current train perplexity4.547016143798828
INFO:root:current mean train loss 1911.7534724644252
INFO:root:current train perplexity4.544683456420898
INFO:root:current mean train loss 1914.3163078539299
INFO:root:current train perplexity4.550451278686523
INFO:root:current mean train loss 1917.2480769107217
INFO:root:current train perplexity4.550416469573975
INFO:root:current mean train loss 1920.4783986646075
INFO:root:current train perplexity4.553316593170166
INFO:root:current mean train loss 1921.4490247090657
INFO:root:current train perplexity4.55018424987793
INFO:root:current mean train loss 1921.1198622217719
INFO:root:current train perplexity4.549370288848877
INFO:root:current mean train loss 1920.2333048853382
INFO:root:current train perplexity4.548471927642822
INFO:root:current mean train loss 1920.9232795836433
INFO:root:current train perplexity4.550985336303711
INFO:root:current mean train loss 1920.337636790556
INFO:root:current train perplexity4.550498962402344
INFO:root:current mean train loss 1920.155228371816
INFO:root:current train perplexity4.549285411834717
INFO:root:current mean train loss 1919.6885167048529
INFO:root:current train perplexity4.549811363220215
INFO:root:current mean train loss 1920.272520796075
INFO:root:current train perplexity4.551193714141846
INFO:root:current mean train loss 1922.384448588978
INFO:root:current train perplexity4.554625511169434
INFO:root:current mean train loss 1923.580523812899
INFO:root:current train perplexity4.5578694343566895
INFO:root:current mean train loss 1925.1921235999282
INFO:root:current train perplexity4.562856674194336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.42s/it]
INFO:root:final mean train loss: 1924.3252727529705
INFO:root:final train perplexity: 4.561441898345947
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.66s/it]
INFO:root:eval mean loss: 2826.387407915728
INFO:root:eval perplexity: 10.168116569519043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/34
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [3:33:27<6:52:55, 375.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1937.558766550832
INFO:root:current train perplexity4.518630504608154
INFO:root:current mean train loss 1930.09603278381
INFO:root:current train perplexity4.531692981719971
INFO:root:current mean train loss 1920.3584596929998
INFO:root:current train perplexity4.524261951446533
INFO:root:current mean train loss 1917.7128886822363
INFO:root:current train perplexity4.524593830108643
INFO:root:current mean train loss 1915.4269569125065
INFO:root:current train perplexity4.530948638916016
INFO:root:current mean train loss 1916.7471327227984
INFO:root:current train perplexity4.533432960510254
INFO:root:current mean train loss 1915.6987223547706
INFO:root:current train perplexity4.529659271240234
INFO:root:current mean train loss 1916.2951443351833
INFO:root:current train perplexity4.525289535522461
INFO:root:current mean train loss 1915.3747951111745
INFO:root:current train perplexity4.523995876312256
INFO:root:current mean train loss 1916.0906568857151
INFO:root:current train perplexity4.527225017547607
INFO:root:current mean train loss 1916.38694554916
INFO:root:current train perplexity4.529536247253418
INFO:root:current mean train loss 1917.457834715345
INFO:root:current train perplexity4.5319976806640625
INFO:root:current mean train loss 1918.5905733997222
INFO:root:current train perplexity4.536503791809082
INFO:root:current mean train loss 1918.995657594635
INFO:root:current train perplexity4.5379438400268555
INFO:root:current mean train loss 1918.3063407799805
INFO:root:current train perplexity4.537657737731934
INFO:root:current mean train loss 1918.3061055901237
INFO:root:current train perplexity4.537192344665527
INFO:root:current mean train loss 1919.3680872681173
INFO:root:current train perplexity4.54003381729126
INFO:root:current mean train loss 1919.7367237372282
INFO:root:current train perplexity4.541627407073975
INFO:root:current mean train loss 1920.065276205381
INFO:root:current train perplexity4.543421268463135
INFO:root:current mean train loss 1919.7037682617681
INFO:root:current train perplexity4.543255805969238

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.98s/it]
INFO:root:final mean train loss: 1919.156109677621
INFO:root:final train perplexity: 4.542883396148682
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.58s/it]
INFO:root:eval mean loss: 2826.8818711289414
INFO:root:eval perplexity: 10.17224407196045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/35
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [3:39:40<6:45:48, 374.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1934.0358860746344
INFO:root:current train perplexity4.557742595672607
INFO:root:current mean train loss 1918.7427210856958
INFO:root:current train perplexity4.520694732666016
INFO:root:current mean train loss 1916.6186382267751
INFO:root:current train perplexity4.507510185241699
INFO:root:current mean train loss 1913.12373127429
INFO:root:current train perplexity4.500331878662109
INFO:root:current mean train loss 1910.8086869089227
INFO:root:current train perplexity4.505595684051514
INFO:root:current mean train loss 1912.3915078519572
INFO:root:current train perplexity4.507524490356445
INFO:root:current mean train loss 1911.7455122450244
INFO:root:current train perplexity4.5110273361206055
INFO:root:current mean train loss 1912.3205855439232
INFO:root:current train perplexity4.508075714111328
INFO:root:current mean train loss 1912.4641817848155
INFO:root:current train perplexity4.51183557510376
INFO:root:current mean train loss 1911.1678490130234
INFO:root:current train perplexity4.510677814483643
INFO:root:current mean train loss 1912.9062707541848
INFO:root:current train perplexity4.513258457183838
INFO:root:current mean train loss 1913.770234534489
INFO:root:current train perplexity4.5123724937438965
INFO:root:current mean train loss 1913.121455715834
INFO:root:current train perplexity4.515113353729248
INFO:root:current mean train loss 1913.38755695447
INFO:root:current train perplexity4.515209674835205
INFO:root:current mean train loss 1913.470044402872
INFO:root:current train perplexity4.514837265014648
INFO:root:current mean train loss 1912.0929707104767
INFO:root:current train perplexity4.512787818908691
INFO:root:current mean train loss 1911.6295169618645
INFO:root:current train perplexity4.512503623962402
INFO:root:current mean train loss 1912.404674925533
INFO:root:current train perplexity4.514744758605957
INFO:root:current mean train loss 1912.294647829082
INFO:root:current train perplexity4.515815258026123

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.78s/it]
INFO:root:final mean train loss: 1911.733676527584
INFO:root:final train perplexity: 4.516368865966797
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.50s/it]
INFO:root:eval mean loss: 2830.951608835398
INFO:root:eval perplexity: 10.206271171569824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/36
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [3:45:54<6:39:30, 374.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1937.073153409091
INFO:root:current train perplexity4.6053667068481445
INFO:root:current mean train loss 1892.0822522962414
INFO:root:current train perplexity4.489439010620117
INFO:root:current mean train loss 1887.2131810482078
INFO:root:current train perplexity4.461686134338379
INFO:root:current mean train loss 1892.804461414791
INFO:root:current train perplexity4.472485542297363
INFO:root:current mean train loss 1895.366320533474
INFO:root:current train perplexity4.463245391845703
INFO:root:current mean train loss 1897.8517029644693
INFO:root:current train perplexity4.472776412963867
INFO:root:current mean train loss 1901.5802119827895
INFO:root:current train perplexity4.482287883758545
INFO:root:current mean train loss 1901.6769600612033
INFO:root:current train perplexity4.480741024017334
INFO:root:current mean train loss 1899.6437006902165
INFO:root:current train perplexity4.480478763580322
INFO:root:current mean train loss 1899.1907045131982
INFO:root:current train perplexity4.483560085296631
INFO:root:current mean train loss 1899.552285817917
INFO:root:current train perplexity4.484344005584717
INFO:root:current mean train loss 1899.5914792284893
INFO:root:current train perplexity4.485650062561035
INFO:root:current mean train loss 1901.2997668870316
INFO:root:current train perplexity4.487156867980957
INFO:root:current mean train loss 1900.786701077273
INFO:root:current train perplexity4.487307548522949
INFO:root:current mean train loss 1903.8103306781816
INFO:root:current train perplexity4.489011287689209
INFO:root:current mean train loss 1904.0095159100192
INFO:root:current train perplexity4.491511821746826
INFO:root:current mean train loss 1904.8742240086467
INFO:root:current train perplexity4.493068218231201
INFO:root:current mean train loss 1905.6708833124817
INFO:root:current train perplexity4.492441654205322
INFO:root:current mean train loss 1905.7374324198258
INFO:root:current train perplexity4.493412494659424
INFO:root:current mean train loss 1905.6978761043179
INFO:root:current train perplexity4.493827819824219

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.97s/it]
INFO:root:final mean train loss: 1906.2359297190178
INFO:root:final train perplexity: 4.496828079223633
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.80s/it]
INFO:root:eval mean loss: 2825.9316765495964
INFO:root:eval perplexity: 10.164316177368164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/37
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [3:52:07<6:32:45, 374.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1884.973619733538
INFO:root:current train perplexity4.412309169769287
INFO:root:current mean train loss 1893.0668725967407
INFO:root:current train perplexity4.450308322906494
INFO:root:current mean train loss 1892.6406426680715
INFO:root:current train perplexity4.44150972366333
INFO:root:current mean train loss 1885.7354099924971
INFO:root:current train perplexity4.4341816902160645
INFO:root:current mean train loss 1885.4203710823415
INFO:root:current train perplexity4.439268112182617
INFO:root:current mean train loss 1888.7685498324308
INFO:root:current train perplexity4.450334072113037
INFO:root:current mean train loss 1890.4412647417396
INFO:root:current train perplexity4.453827857971191
INFO:root:current mean train loss 1889.4100336766505
INFO:root:current train perplexity4.454159259796143
INFO:root:current mean train loss 1889.9955718551857
INFO:root:current train perplexity4.458844184875488
INFO:root:current mean train loss 1890.3351241802347
INFO:root:current train perplexity4.460477352142334
INFO:root:current mean train loss 1892.6185003495866
INFO:root:current train perplexity4.462149620056152
INFO:root:current mean train loss 1893.9841821548787
INFO:root:current train perplexity4.462397575378418
INFO:root:current mean train loss 1893.6193944079869
INFO:root:current train perplexity4.464283466339111
INFO:root:current mean train loss 1894.5704627898801
INFO:root:current train perplexity4.464744567871094
INFO:root:current mean train loss 1893.9411534755504
INFO:root:current train perplexity4.464023590087891
INFO:root:current mean train loss 1896.0698816589036
INFO:root:current train perplexity4.468024730682373
INFO:root:current mean train loss 1898.8182789195669
INFO:root:current train perplexity4.472589015960693
INFO:root:current mean train loss 1900.2898010677761
INFO:root:current train perplexity4.473809719085693
INFO:root:current mean train loss 1901.0398324511505
INFO:root:current train perplexity4.475908279418945
INFO:root:current mean train loss 1900.8965014699088
INFO:root:current train perplexity4.475611686706543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.97s/it]
INFO:root:final mean train loss: 1900.2286296927202
INFO:root:final train perplexity: 4.475574016571045
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.72s/it]
INFO:root:eval mean loss: 2830.3595304288665
INFO:root:eval perplexity: 10.201313018798828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/38
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [3:58:20<6:26:08, 373.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1874.9872097439236
INFO:root:current train perplexity4.4346604347229
INFO:root:current mean train loss 1894.2590231007543
INFO:root:current train perplexity4.43360710144043
INFO:root:current mean train loss 1898.460842833227
INFO:root:current train perplexity4.44641637802124
INFO:root:current mean train loss 1890.9315174932065
INFO:root:current train perplexity4.437701225280762
INFO:root:current mean train loss 1892.0922393455935
INFO:root:current train perplexity4.4384765625
INFO:root:current mean train loss 1890.4062168506307
INFO:root:current train perplexity4.436295032501221
INFO:root:current mean train loss 1890.7679766987646
INFO:root:current train perplexity4.434026718139648
INFO:root:current mean train loss 1889.0754337182782
INFO:root:current train perplexity4.4301910400390625
INFO:root:current mean train loss 1890.911622682831
INFO:root:current train perplexity4.432837963104248
INFO:root:current mean train loss 1890.7211123511904
INFO:root:current train perplexity4.432044982910156
INFO:root:current mean train loss 1891.3633153595993
INFO:root:current train perplexity4.436209201812744
INFO:root:current mean train loss 1893.0622916808816
INFO:root:current train perplexity4.441421031951904
INFO:root:current mean train loss 1893.5239483323921
INFO:root:current train perplexity4.443812370300293
INFO:root:current mean train loss 1892.0216206944121
INFO:root:current train perplexity4.445641994476318
INFO:root:current mean train loss 1893.5746960491458
INFO:root:current train perplexity4.44694709777832
INFO:root:current mean train loss 1893.8452680964301
INFO:root:current train perplexity4.447754859924316
INFO:root:current mean train loss 1894.2442169096694
INFO:root:current train perplexity4.448907375335693
INFO:root:current mean train loss 1894.8554269872627
INFO:root:current train perplexity4.450582027435303
INFO:root:current mean train loss 1895.1886635384908
INFO:root:current train perplexity4.452793121337891
INFO:root:current mean train loss 1894.9812262763094
INFO:root:current train perplexity4.453563690185547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.50s/it]
INFO:root:final mean train loss: 1894.5643215746934
INFO:root:final train perplexity: 4.455626010894775
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.35s/it]
INFO:root:eval mean loss: 2826.0510818435623
INFO:root:eval perplexity: 10.165312767028809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/39
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [4:04:48<6:24:17, 377.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1874.314411778604
INFO:root:current train perplexity4.398797988891602
INFO:root:current mean train loss 1877.2290860399787
INFO:root:current train perplexity4.398664474487305
INFO:root:current mean train loss 1884.0018096224953
INFO:root:current train perplexity4.402174472808838
INFO:root:current mean train loss 1884.798766752633
INFO:root:current train perplexity4.407294750213623
INFO:root:current mean train loss 1880.7903690750982
INFO:root:current train perplexity4.408945083618164
INFO:root:current mean train loss 1883.2536684083768
INFO:root:current train perplexity4.421273708343506
INFO:root:current mean train loss 1883.6253662109375
INFO:root:current train perplexity4.424426555633545
INFO:root:current mean train loss 1883.549366227598
INFO:root:current train perplexity4.423676013946533
INFO:root:current mean train loss 1885.763003603765
INFO:root:current train perplexity4.429361343383789
INFO:root:current mean train loss 1884.9332064749544
INFO:root:current train perplexity4.428773403167725
INFO:root:current mean train loss 1886.4081715154557
INFO:root:current train perplexity4.427593231201172
INFO:root:current mean train loss 1886.5906330049552
INFO:root:current train perplexity4.425343990325928
INFO:root:current mean train loss 1885.7001787720694
INFO:root:current train perplexity4.424426555633545
INFO:root:current mean train loss 1886.889599949953
INFO:root:current train perplexity4.42827844619751
INFO:root:current mean train loss 1886.560045067491
INFO:root:current train perplexity4.43071985244751
INFO:root:current mean train loss 1887.4908874746168
INFO:root:current train perplexity4.431919097900391
INFO:root:current mean train loss 1888.3714705374266
INFO:root:current train perplexity4.432568550109863
INFO:root:current mean train loss 1888.6183804220834
INFO:root:current train perplexity4.433813095092773
INFO:root:current mean train loss 1889.1381309501082
INFO:root:current train perplexity4.434142589569092
INFO:root:current mean train loss 1889.191660034304
INFO:root:current train perplexity4.43368673324585

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.69s/it]
INFO:root:final mean train loss: 1888.5984824868806
INFO:root:final train perplexity: 4.4347100257873535
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.72s/it]
INFO:root:eval mean loss: 2828.047828101539
INFO:root:eval perplexity: 10.181981086730957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/40
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [4:11:03<6:16:57, 376.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1878.814001928402
INFO:root:current train perplexity4.412827014923096
INFO:root:current mean train loss 1883.7978836144814
INFO:root:current train perplexity4.404444217681885
INFO:root:current mean train loss 1880.7322665525594
INFO:root:current train perplexity4.404173851013184
INFO:root:current mean train loss 1880.6340628349687
INFO:root:current train perplexity4.409295558929443
INFO:root:current mean train loss 1879.3682229314816
INFO:root:current train perplexity4.4095659255981445
INFO:root:current mean train loss 1882.0430699481865
INFO:root:current train perplexity4.404946327209473
INFO:root:current mean train loss 1882.585290832969
INFO:root:current train perplexity4.405609607696533
INFO:root:current mean train loss 1884.6224827503208
INFO:root:current train perplexity4.41158390045166
INFO:root:current mean train loss 1883.6284403274763
INFO:root:current train perplexity4.411187648773193
INFO:root:current mean train loss 1884.2301461801344
INFO:root:current train perplexity4.41216516494751
INFO:root:current mean train loss 1884.3524496875725
INFO:root:current train perplexity4.411187171936035
INFO:root:current mean train loss 1884.114827266884
INFO:root:current train perplexity4.414066791534424
INFO:root:current mean train loss 1885.0537867184446
INFO:root:current train perplexity4.413133144378662
INFO:root:current mean train loss 1886.2351536297815
INFO:root:current train perplexity4.418332576751709
INFO:root:current mean train loss 1886.6350643217281
INFO:root:current train perplexity4.419187068939209
INFO:root:current mean train loss 1885.5732988547193
INFO:root:current train perplexity4.419313907623291
INFO:root:current mean train loss 1884.809742839511
INFO:root:current train perplexity4.416196346282959
INFO:root:current mean train loss 1883.7414839660405
INFO:root:current train perplexity4.415526390075684
INFO:root:current mean train loss 1883.484425543216
INFO:root:current train perplexity4.416275978088379
INFO:root:current mean train loss 1883.570283817486
INFO:root:current train perplexity4.415345668792725

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.44s/it]
INFO:root:final mean train loss: 1883.009733368397
INFO:root:final train perplexity: 4.4152069091796875
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.99s/it]
INFO:root:eval mean loss: 2832.0481866143487
INFO:root:eval perplexity: 10.215458869934082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/41
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [4:17:17<6:09:59, 376.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1863.7003237406414
INFO:root:current train perplexity4.360408306121826
INFO:root:current mean train loss 1862.4707946777344
INFO:root:current train perplexity4.356210708618164
INFO:root:current mean train loss 1868.5641941379856
INFO:root:current train perplexity4.373472690582275
INFO:root:current mean train loss 1870.4692580097853
INFO:root:current train perplexity4.37593936920166
INFO:root:current mean train loss 1869.6808725172473
INFO:root:current train perplexity4.381584644317627
INFO:root:current mean train loss 1872.2885717609586
INFO:root:current train perplexity4.375741004943848
INFO:root:current mean train loss 1868.9628911511652
INFO:root:current train perplexity4.371408939361572
INFO:root:current mean train loss 1870.4843246996702
INFO:root:current train perplexity4.376226425170898
INFO:root:current mean train loss 1871.722196987697
INFO:root:current train perplexity4.378182411193848
INFO:root:current mean train loss 1871.8488997493882
INFO:root:current train perplexity4.380521297454834
INFO:root:current mean train loss 1872.2382074063712
INFO:root:current train perplexity4.376950263977051
INFO:root:current mean train loss 1873.5416063799905
INFO:root:current train perplexity4.379707336425781
INFO:root:current mean train loss 1875.3731032006535
INFO:root:current train perplexity4.383205890655518
INFO:root:current mean train loss 1875.4962113607237
INFO:root:current train perplexity4.386338710784912
INFO:root:current mean train loss 1876.3395473051837
INFO:root:current train perplexity4.389668941497803
INFO:root:current mean train loss 1878.6461616841175
INFO:root:current train perplexity4.393238544464111
INFO:root:current mean train loss 1878.784854529039
INFO:root:current train perplexity4.3947248458862305
INFO:root:current mean train loss 1878.5078927020984
INFO:root:current train perplexity4.395227909088135
INFO:root:current mean train loss 1878.9152403883793
INFO:root:current train perplexity4.396868705749512

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.11s/it]
INFO:root:final mean train loss: 1878.1351282963294
INFO:root:final train perplexity: 4.398265838623047
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.80s/it]
INFO:root:eval mean loss: 2830.683882613082
INFO:root:eval perplexity: 10.204028129577637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/42
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [4:23:39<6:05:24, 378.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1879.6272348257212
INFO:root:current train perplexity4.451840400695801
INFO:root:current mean train loss 1857.851943834693
INFO:root:current train perplexity4.387659072875977
INFO:root:current mean train loss 1857.006415855157
INFO:root:current train perplexity4.373208522796631
INFO:root:current mean train loss 1862.3581137367712
INFO:root:current train perplexity4.36229133605957
INFO:root:current mean train loss 1861.2128941718372
INFO:root:current train perplexity4.360372066497803
INFO:root:current mean train loss 1863.995645207039
INFO:root:current train perplexity4.356714725494385
INFO:root:current mean train loss 1865.52126871081
INFO:root:current train perplexity4.365082740783691
INFO:root:current mean train loss 1868.7971076697822
INFO:root:current train perplexity4.365715980529785
INFO:root:current mean train loss 1868.6930044251615
INFO:root:current train perplexity4.3702802658081055
INFO:root:current mean train loss 1870.646859945107
INFO:root:current train perplexity4.369932174682617
INFO:root:current mean train loss 1871.8325294125586
INFO:root:current train perplexity4.371389389038086
INFO:root:current mean train loss 1871.8479909836872
INFO:root:current train perplexity4.373585224151611
INFO:root:current mean train loss 1871.8929254165487
INFO:root:current train perplexity4.375517845153809
INFO:root:current mean train loss 1871.5673714700947
INFO:root:current train perplexity4.373863697052002
INFO:root:current mean train loss 1873.283143688075
INFO:root:current train perplexity4.377227783203125
INFO:root:current mean train loss 1873.169605282861
INFO:root:current train perplexity4.378167629241943
INFO:root:current mean train loss 1871.6127378743995
INFO:root:current train perplexity4.373281002044678
INFO:root:current mean train loss 1872.0437680860744
INFO:root:current train perplexity4.375201225280762
INFO:root:current mean train loss 1871.4018962037412
INFO:root:current train perplexity4.373899936676025
INFO:root:current mean train loss 1872.4689856537711
INFO:root:current train perplexity4.376677989959717

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.12s/it]
INFO:root:final mean train loss: 1872.381016041135
INFO:root:final train perplexity: 4.37835168838501
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.69s/it]
INFO:root:eval mean loss: 2834.348294828031
INFO:root:eval perplexity: 10.234756469726562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/43
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [4:29:53<5:57:57, 376.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1881.5296630859375
INFO:root:current train perplexity4.401165962219238
INFO:root:current mean train loss 1868.4709585336539
INFO:root:current train perplexity4.350045204162598
INFO:root:current mean train loss 1877.4404105808424
INFO:root:current train perplexity4.369922637939453
INFO:root:current mean train loss 1874.094989568537
INFO:root:current train perplexity4.354183673858643
INFO:root:current mean train loss 1869.7798234806505
INFO:root:current train perplexity4.353218078613281
INFO:root:current mean train loss 1869.9393796524912
INFO:root:current train perplexity4.348304748535156
INFO:root:current mean train loss 1867.5320957728795
INFO:root:current train perplexity4.347957134246826
INFO:root:current mean train loss 1868.8615828004602
INFO:root:current train perplexity4.352841377258301
INFO:root:current mean train loss 1870.0843875011765
INFO:root:current train perplexity4.351833343505859
INFO:root:current mean train loss 1869.964105421497
INFO:root:current train perplexity4.353030681610107
INFO:root:current mean train loss 1868.9434164991656
INFO:root:current train perplexity4.35408878326416
INFO:root:current mean train loss 1868.8317024163441
INFO:root:current train perplexity4.35423469543457
INFO:root:current mean train loss 1869.0520674542684
INFO:root:current train perplexity4.3565497398376465
INFO:root:current mean train loss 1868.7245845938087
INFO:root:current train perplexity4.355947494506836
INFO:root:current mean train loss 1868.9546809269832
INFO:root:current train perplexity4.358523845672607
INFO:root:current mean train loss 1867.467412412556
INFO:root:current train perplexity4.3570756912231445
INFO:root:current mean train loss 1867.4739886886503
INFO:root:current train perplexity4.360252380371094
INFO:root:current mean train loss 1868.332845028563
INFO:root:current train perplexity4.360613822937012
INFO:root:current mean train loss 1868.3791963504311
INFO:root:current train perplexity4.362571716308594
INFO:root:current mean train loss 1867.591269252955
INFO:root:current train perplexity4.360219955444336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.08s/it]
INFO:root:final mean train loss: 1867.4703213397866
INFO:root:final train perplexity: 4.361427307128906
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.87s/it]
INFO:root:eval mean loss: 2832.3390438778624
INFO:root:eval perplexity: 10.217899322509766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/44
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [4:36:20<5:54:32, 379.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1855.3562375332447
INFO:root:current train perplexity4.338158130645752
INFO:root:current mean train loss 1837.3876994645514
INFO:root:current train perplexity4.2960381507873535
INFO:root:current mean train loss 1849.2588379894673
INFO:root:current train perplexity4.297780513763428
INFO:root:current mean train loss 1856.8864679254098
INFO:root:current train perplexity4.324896812438965
INFO:root:current mean train loss 1857.7100040853957
INFO:root:current train perplexity4.326229572296143
INFO:root:current mean train loss 1858.4459851141169
INFO:root:current train perplexity4.329566478729248
INFO:root:current mean train loss 1858.544922629685
INFO:root:current train perplexity4.332048416137695
INFO:root:current mean train loss 1858.957734747584
INFO:root:current train perplexity4.324709892272949
INFO:root:current mean train loss 1861.5912616103712
INFO:root:current train perplexity4.331648349761963
INFO:root:current mean train loss 1862.064536653577
INFO:root:current train perplexity4.330595970153809
INFO:root:current mean train loss 1861.794523951431
INFO:root:current train perplexity4.335716724395752
INFO:root:current mean train loss 1863.365315684258
INFO:root:current train perplexity4.338173866271973
INFO:root:current mean train loss 1861.6817506546963
INFO:root:current train perplexity4.337010383605957
INFO:root:current mean train loss 1860.6136070427049
INFO:root:current train perplexity4.336352825164795
INFO:root:current mean train loss 1861.5464388538246
INFO:root:current train perplexity4.337820053100586
INFO:root:current mean train loss 1863.0134185021666
INFO:root:current train perplexity4.344698429107666
INFO:root:current mean train loss 1862.3319783306295
INFO:root:current train perplexity4.343947887420654
INFO:root:current mean train loss 1861.9108790991029
INFO:root:current train perplexity4.341639518737793
INFO:root:current mean train loss 1862.3355158386066
INFO:root:current train perplexity4.343094825744629
INFO:root:current mean train loss 1863.652025376581
INFO:root:current train perplexity4.3463134765625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.74s/it]
INFO:root:final mean train loss: 1863.0812759591784
INFO:root:final train perplexity: 4.346357345581055
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.58s/it]
INFO:root:eval mean loss: 2836.093063033737
INFO:root:eval perplexity: 10.249423027038574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/45
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [4:42:57<5:52:48, 384.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1848.5023174285889
INFO:root:current train perplexity4.294763088226318
INFO:root:current mean train loss 1856.7228721060403
INFO:root:current train perplexity4.307117462158203
INFO:root:current mean train loss 1857.470258770567
INFO:root:current train perplexity4.319247722625732
INFO:root:current mean train loss 1859.1086003230168
INFO:root:current train perplexity4.338499546051025
INFO:root:current mean train loss 1858.6283085264008
INFO:root:current train perplexity4.3314714431762695
INFO:root:current mean train loss 1857.849583402593
INFO:root:current train perplexity4.3297200202941895
INFO:root:current mean train loss 1854.9986090602645
INFO:root:current train perplexity4.32330846786499
INFO:root:current mean train loss 1854.4357010606695
INFO:root:current train perplexity4.324296951293945
INFO:root:current mean train loss 1856.6594971550835
INFO:root:current train perplexity4.327615737915039
INFO:root:current mean train loss 1857.8928325225704
INFO:root:current train perplexity4.330005168914795
INFO:root:current mean train loss 1856.181503066443
INFO:root:current train perplexity4.328207969665527
INFO:root:current mean train loss 1857.3093378126007
INFO:root:current train perplexity4.327139854431152
INFO:root:current mean train loss 1858.3456559965882
INFO:root:current train perplexity4.327753067016602
INFO:root:current mean train loss 1859.6044705298639
INFO:root:current train perplexity4.328285217285156
INFO:root:current mean train loss 1860.2318899852983
INFO:root:current train perplexity4.3274006843566895
INFO:root:current mean train loss 1859.9051704114052
INFO:root:current train perplexity4.327024936676025
INFO:root:current mean train loss 1858.8945126166711
INFO:root:current train perplexity4.328812599182129
INFO:root:current mean train loss 1858.9445128148916
INFO:root:current train perplexity4.328644752502441
INFO:root:current mean train loss 1858.6326211429973
INFO:root:current train perplexity4.32951545715332
INFO:root:current mean train loss 1858.8127814951351
INFO:root:current train perplexity4.329514026641846

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.83s/it]
INFO:root:final mean train loss: 1858.1362851018323
INFO:root:final train perplexity: 4.329439163208008
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.97s/it]
INFO:root:eval mean loss: 2835.0193435623123
INFO:root:eval perplexity: 10.240397453308105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/46
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [4:49:23<5:46:40, 385.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1858.798627688561
INFO:root:current train perplexity4.310484409332275
INFO:root:current mean train loss 1860.194066843275
INFO:root:current train perplexity4.305280685424805
INFO:root:current mean train loss 1859.564616899049
INFO:root:current train perplexity4.303931713104248
INFO:root:current mean train loss 1858.2766859800483
INFO:root:current train perplexity4.299099445343018
INFO:root:current mean train loss 1853.253608814644
INFO:root:current train perplexity4.296359062194824
INFO:root:current mean train loss 1854.3479745572693
INFO:root:current train perplexity4.300811290740967
INFO:root:current mean train loss 1855.0376299215309
INFO:root:current train perplexity4.3083062171936035
INFO:root:current mean train loss 1856.217305006352
INFO:root:current train perplexity4.30851411819458
INFO:root:current mean train loss 1858.5436044578248
INFO:root:current train perplexity4.309774875640869
INFO:root:current mean train loss 1855.8330116699717
INFO:root:current train perplexity4.308200836181641
INFO:root:current mean train loss 1855.7411268094863
INFO:root:current train perplexity4.308639049530029
INFO:root:current mean train loss 1855.8805679980221
INFO:root:current train perplexity4.309158802032471
INFO:root:current mean train loss 1856.123911182365
INFO:root:current train perplexity4.312483787536621
INFO:root:current mean train loss 1855.7870414894098
INFO:root:current train perplexity4.3131513595581055
INFO:root:current mean train loss 1855.1234527320012
INFO:root:current train perplexity4.313477993011475
INFO:root:current mean train loss 1853.7262015393985
INFO:root:current train perplexity4.31077241897583
INFO:root:current mean train loss 1854.1411480651166
INFO:root:current train perplexity4.310182094573975
INFO:root:current mean train loss 1854.111187822962
INFO:root:current train perplexity4.311423301696777
INFO:root:current mean train loss 1853.1603561312133
INFO:root:current train perplexity4.311160564422607
INFO:root:current mean train loss 1853.6635867277218
INFO:root:current train perplexity4.312262058258057

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.57s/it]
INFO:root:final mean train loss: 1853.0617960796653
INFO:root:final train perplexity: 4.312147617340088
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.52s/it]
INFO:root:eval mean loss: 2837.399435323996
INFO:root:eval perplexity: 10.260415077209473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/47
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [4:55:35<5:36:49, 381.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1846.8687906070631
INFO:root:current train perplexity4.255496501922607
INFO:root:current mean train loss 1844.9685280539773
INFO:root:current train perplexity4.259428977966309
INFO:root:current mean train loss 1844.2083596863204
INFO:root:current train perplexity4.280200004577637
INFO:root:current mean train loss 1842.165905209642
INFO:root:current train perplexity4.280123710632324
INFO:root:current mean train loss 1843.3007560025258
INFO:root:current train perplexity4.278682231903076
INFO:root:current mean train loss 1843.346497806817
INFO:root:current train perplexity4.278740882873535
INFO:root:current mean train loss 1846.9235049359777
INFO:root:current train perplexity4.287691116333008
INFO:root:current mean train loss 1847.0013343600701
INFO:root:current train perplexity4.290724754333496
INFO:root:current mean train loss 1847.7543946671858
INFO:root:current train perplexity4.293415546417236
INFO:root:current mean train loss 1846.1901465284084
INFO:root:current train perplexity4.290240287780762
INFO:root:current mean train loss 1848.0889223303734
INFO:root:current train perplexity4.289717674255371
INFO:root:current mean train loss 1848.4899779050697
INFO:root:current train perplexity4.291670322418213
INFO:root:current mean train loss 1846.5976492906755
INFO:root:current train perplexity4.289018154144287
INFO:root:current mean train loss 1847.4299497154138
INFO:root:current train perplexity4.292629718780518
INFO:root:current mean train loss 1847.3597104896373
INFO:root:current train perplexity4.293961524963379
INFO:root:current mean train loss 1847.8652005344816
INFO:root:current train perplexity4.296705722808838
INFO:root:current mean train loss 1848.2332221616423
INFO:root:current train perplexity4.297377109527588
INFO:root:current mean train loss 1848.4305603909943
INFO:root:current train perplexity4.2970991134643555
INFO:root:current mean train loss 1848.407608337724
INFO:root:current train perplexity4.296080589294434

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.06s/it]
INFO:root:final mean train loss: 1848.4710216897338
INFO:root:final train perplexity: 4.296563625335693
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.56s/it]
INFO:root:eval mean loss: 2839.686861421969
INFO:root:eval perplexity: 10.279692649841309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/48
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [5:01:59<5:31:06, 382.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1778.8002115885417
INFO:root:current train perplexity4.046753883361816
INFO:root:current mean train loss 1838.9581755264946
INFO:root:current train perplexity4.2592363357543945
INFO:root:current mean train loss 1845.110177825218
INFO:root:current train perplexity4.257166385650635
INFO:root:current mean train loss 1843.3489695715525
INFO:root:current train perplexity4.253609657287598
INFO:root:current mean train loss 1845.3600821253765
INFO:root:current train perplexity4.259428977966309
INFO:root:current mean train loss 1841.8505757452215
INFO:root:current train perplexity4.253149509429932
INFO:root:current mean train loss 1838.290921740028
INFO:root:current train perplexity4.251552581787109
INFO:root:current mean train loss 1840.0207359047204
INFO:root:current train perplexity4.259932994842529
INFO:root:current mean train loss 1839.42174274468
INFO:root:current train perplexity4.263311386108398
INFO:root:current mean train loss 1838.4957703637294
INFO:root:current train perplexity4.264907360076904
INFO:root:current mean train loss 1840.6672882831742
INFO:root:current train perplexity4.269309997558594
INFO:root:current mean train loss 1841.7302611757286
INFO:root:current train perplexity4.266911506652832
INFO:root:current mean train loss 1842.8707080480003
INFO:root:current train perplexity4.267365455627441
INFO:root:current mean train loss 1843.143540948788
INFO:root:current train perplexity4.269199371337891
INFO:root:current mean train loss 1842.570178524597
INFO:root:current train perplexity4.2712297439575195
INFO:root:current mean train loss 1841.850424305126
INFO:root:current train perplexity4.27287483215332
INFO:root:current mean train loss 1842.7628628095974
INFO:root:current train perplexity4.274336814880371
INFO:root:current mean train loss 1842.5257373331588
INFO:root:current train perplexity4.2755937576293945
INFO:root:current mean train loss 1843.5736217824553
INFO:root:current train perplexity4.277562141418457
INFO:root:current mean train loss 1843.7138896892338
INFO:root:current train perplexity4.280229091644287

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:35<00:00, 335.92s/it]
INFO:root:final mean train loss: 1844.1814657991365
INFO:root:final train perplexity: 4.282052516937256
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.79s/it]
INFO:root:eval mean loss: 2841.191361527543
INFO:root:eval perplexity: 10.292388916015625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/49
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [5:08:27<5:26:12, 383.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1860.4671325683594
INFO:root:current train perplexity4.30694055557251
INFO:root:current mean train loss 1837.1065544359612
INFO:root:current train perplexity4.218654632568359
INFO:root:current mean train loss 1833.0558755808863
INFO:root:current train perplexity4.216660022735596
INFO:root:current mean train loss 1835.7009766360363
INFO:root:current train perplexity4.231874942779541
INFO:root:current mean train loss 1838.0056036489982
INFO:root:current train perplexity4.2423176765441895
INFO:root:current mean train loss 1835.3457024366335
INFO:root:current train perplexity4.246866703033447
INFO:root:current mean train loss 1835.6329988890056
INFO:root:current train perplexity4.2508697509765625
INFO:root:current mean train loss 1836.3554472376088
INFO:root:current train perplexity4.252642631530762
INFO:root:current mean train loss 1836.0474416292632
INFO:root:current train perplexity4.253415107727051
INFO:root:current mean train loss 1836.7382993247888
INFO:root:current train perplexity4.256625652313232
INFO:root:current mean train loss 1835.7212545705397
INFO:root:current train perplexity4.254459381103516
INFO:root:current mean train loss 1837.9431259101354
INFO:root:current train perplexity4.2579827308654785
INFO:root:current mean train loss 1838.7645149726372
INFO:root:current train perplexity4.259654521942139
INFO:root:current mean train loss 1837.876929205817
INFO:root:current train perplexity4.258404731750488
INFO:root:current mean train loss 1837.4493613642687
INFO:root:current train perplexity4.258602142333984
INFO:root:current mean train loss 1837.6380358663614
INFO:root:current train perplexity4.258641719818115
INFO:root:current mean train loss 1838.7238376841826
INFO:root:current train perplexity4.260676383972168
INFO:root:current mean train loss 1838.1490839370128
INFO:root:current train perplexity4.261303901672363
INFO:root:current mean train loss 1839.4623417083874
INFO:root:current train perplexity4.263786315917969
INFO:root:current mean train loss 1839.5908179747146
INFO:root:current train perplexity4.266153812408447

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.13s/it]
INFO:root:final mean train loss: 1839.9822661322412
INFO:root:final train perplexity: 4.267894268035889
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.20s/it]
INFO:root:eval mean loss: 2841.355083843609
INFO:root:eval perplexity: 10.29377269744873
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/50
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [5:14:51<5:20:01, 384.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1811.9474474848532
INFO:root:current train perplexity4.203972339630127
INFO:root:current mean train loss 1823.525183351248
INFO:root:current train perplexity4.186821460723877
INFO:root:current mean train loss 1823.8925016472137
INFO:root:current train perplexity4.206079959869385
INFO:root:current mean train loss 1827.0765240950707
INFO:root:current train perplexity4.2205491065979
INFO:root:current mean train loss 1832.1740328442545
INFO:root:current train perplexity4.223827362060547
INFO:root:current mean train loss 1832.6370142535434
INFO:root:current train perplexity4.227292060852051
INFO:root:current mean train loss 1831.2068401507127
INFO:root:current train perplexity4.230663776397705
INFO:root:current mean train loss 1833.238518382583
INFO:root:current train perplexity4.235645771026611
INFO:root:current mean train loss 1832.7932018194658
INFO:root:current train perplexity4.234764099121094
INFO:root:current mean train loss 1835.3103548297138
INFO:root:current train perplexity4.242550373077393
INFO:root:current mean train loss 1836.2941183521136
INFO:root:current train perplexity4.248682022094727
INFO:root:current mean train loss 1835.781400436521
INFO:root:current train perplexity4.250949382781982
INFO:root:current mean train loss 1835.7531780307058
INFO:root:current train perplexity4.253413677215576
INFO:root:current mean train loss 1834.0074894525458
INFO:root:current train perplexity4.250401020050049
INFO:root:current mean train loss 1833.7401810482174
INFO:root:current train perplexity4.250383377075195
INFO:root:current mean train loss 1833.5525110391281
INFO:root:current train perplexity4.250049114227295
INFO:root:current mean train loss 1833.8824898908904
INFO:root:current train perplexity4.250826835632324
INFO:root:current mean train loss 1834.191495028409
INFO:root:current train perplexity4.251857757568359
INFO:root:current mean train loss 1834.7699744398365
INFO:root:current train perplexity4.251846790313721
INFO:root:current mean train loss 1836.232925626423
INFO:root:current train perplexity4.2537126541137695

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.44s/it]
INFO:root:final mean train loss: 1835.415365291255
INFO:root:final train perplexity: 4.2525506019592285
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.47s/it]
INFO:root:eval mean loss: 2842.6130517724755
INFO:root:eval perplexity: 10.304405212402344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/51
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [5:21:05<5:11:10, 381.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1833.656797466856
INFO:root:current train perplexity4.213810443878174
INFO:root:current mean train loss 1825.6468961784637
INFO:root:current train perplexity4.223138332366943
INFO:root:current mean train loss 1829.63359081297
INFO:root:current train perplexity4.214341163635254
INFO:root:current mean train loss 1829.2414440717853
INFO:root:current train perplexity4.22947883605957
INFO:root:current mean train loss 1829.3620631664096
INFO:root:current train perplexity4.227514743804932
INFO:root:current mean train loss 1834.7390803145015
INFO:root:current train perplexity4.229663372039795
INFO:root:current mean train loss 1835.1151137709976
INFO:root:current train perplexity4.230171203613281
INFO:root:current mean train loss 1832.3752683634546
INFO:root:current train perplexity4.228643417358398
INFO:root:current mean train loss 1834.5918838465736
INFO:root:current train perplexity4.234805107116699
INFO:root:current mean train loss 1832.9033277681401
INFO:root:current train perplexity4.232095241546631
INFO:root:current mean train loss 1832.89433657877
INFO:root:current train perplexity4.23822021484375
INFO:root:current mean train loss 1831.7467985333137
INFO:root:current train perplexity4.235881805419922
INFO:root:current mean train loss 1832.3634136374717
INFO:root:current train perplexity4.2367262840271
INFO:root:current mean train loss 1831.3974839932398
INFO:root:current train perplexity4.238002777099609
INFO:root:current mean train loss 1830.6608137310284
INFO:root:current train perplexity4.237679958343506
INFO:root:current mean train loss 1831.7526724512093
INFO:root:current train perplexity4.239837169647217
INFO:root:current mean train loss 1831.227513490748
INFO:root:current train perplexity4.238370895385742
INFO:root:current mean train loss 1832.1676293585876
INFO:root:current train perplexity4.239239692687988
INFO:root:current mean train loss 1831.9160906596455
INFO:root:current train perplexity4.239456653594971
INFO:root:current mean train loss 1832.001919968567
INFO:root:current train perplexity4.239492416381836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.43s/it]
INFO:root:final mean train loss: 1831.7841377046693
INFO:root:final train perplexity: 4.240389823913574
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.50s/it]
INFO:root:eval mean loss: 2846.848363744604
INFO:root:eval perplexity: 10.340277671813965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/52
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [5:27:18<5:02:54, 378.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1821.8376391307418
INFO:root:current train perplexity4.217729091644287
INFO:root:current mean train loss 1820.3687277205004
INFO:root:current train perplexity4.212740898132324
INFO:root:current mean train loss 1815.9446900708094
INFO:root:current train perplexity4.197998046875
INFO:root:current mean train loss 1818.5509613276151
INFO:root:current train perplexity4.208412170410156
INFO:root:current mean train loss 1817.4501814121538
INFO:root:current train perplexity4.203117847442627
INFO:root:current mean train loss 1818.195758904642
INFO:root:current train perplexity4.211101055145264
INFO:root:current mean train loss 1820.8665860847707
INFO:root:current train perplexity4.213245868682861
INFO:root:current mean train loss 1820.9262631393178
INFO:root:current train perplexity4.2095818519592285
INFO:root:current mean train loss 1822.7309837125301
INFO:root:current train perplexity4.210991382598877
INFO:root:current mean train loss 1823.0906891769455
INFO:root:current train perplexity4.213344097137451
INFO:root:current mean train loss 1822.9320706326105
INFO:root:current train perplexity4.212839603424072
INFO:root:current mean train loss 1823.6815467247595
INFO:root:current train perplexity4.2179436683654785
INFO:root:current mean train loss 1822.6870474930583
INFO:root:current train perplexity4.219096660614014
INFO:root:current mean train loss 1823.8546952849613
INFO:root:current train perplexity4.221259593963623
INFO:root:current mean train loss 1825.5037422000116
INFO:root:current train perplexity4.2225823402404785
INFO:root:current mean train loss 1826.7539444981837
INFO:root:current train perplexity4.223596572875977
INFO:root:current mean train loss 1826.8902325327028
INFO:root:current train perplexity4.222618103027344
INFO:root:current mean train loss 1827.8530871807961
INFO:root:current train perplexity4.224971771240234
INFO:root:current mean train loss 1827.9680791643157
INFO:root:current train perplexity4.2258830070495605
INFO:root:current mean train loss 1827.6284562272972
INFO:root:current train perplexity4.226515293121338

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.69s/it]
INFO:root:final mean train loss: 1827.6284562272972
INFO:root:final train perplexity: 4.226515293121338
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.62s/it]
INFO:root:eval mean loss: 2845.7359175581832
INFO:root:eval perplexity: 10.330842018127441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/53
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [5:33:31<4:55:08, 376.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1817.6084887695313
INFO:root:current train perplexity4.266584873199463
INFO:root:current mean train loss 1831.189722290039
INFO:root:current train perplexity4.239624977111816
INFO:root:current mean train loss 1819.4871549479167
INFO:root:current train perplexity4.2185773849487305
INFO:root:current mean train loss 1819.3900079345703
INFO:root:current train perplexity4.212263584136963
INFO:root:current mean train loss 1817.5138552246094
INFO:root:current train perplexity4.204620361328125
INFO:root:current mean train loss 1822.9581013997397
INFO:root:current train perplexity4.213228702545166
INFO:root:current mean train loss 1820.86642124721
INFO:root:current train perplexity4.205350399017334
INFO:root:current mean train loss 1820.6354089355468
INFO:root:current train perplexity4.207698822021484
INFO:root:current mean train loss 1821.8046945529513
INFO:root:current train perplexity4.209431171417236
INFO:root:current mean train loss 1821.8146746826171
INFO:root:current train perplexity4.210755348205566
INFO:root:current mean train loss 1824.3330426580255
INFO:root:current train perplexity4.2140302658081055
INFO:root:current mean train loss 1824.7694334920247
INFO:root:current train perplexity4.214576721191406
INFO:root:current mean train loss 1825.3986946927585
INFO:root:current train perplexity4.214108467102051
INFO:root:current mean train loss 1822.883946271624
INFO:root:current train perplexity4.2105278968811035
INFO:root:current mean train loss 1822.9959607747396
INFO:root:current train perplexity4.21110200881958
INFO:root:current mean train loss 1823.460093307495
INFO:root:current train perplexity4.211963176727295
INFO:root:current mean train loss 1824.2323099293428
INFO:root:current train perplexity4.2121100425720215
INFO:root:current mean train loss 1825.615685696072
INFO:root:current train perplexity4.214634895324707
INFO:root:current mean train loss 1824.3709405838815
INFO:root:current train perplexity4.2135329246521

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.48s/it]
INFO:root:final mean train loss: 1823.366151933771
INFO:root:final train perplexity: 4.212331295013428
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.40s/it]
INFO:root:eval mean loss: 2845.4234835421357
INFO:root:eval perplexity: 10.328197479248047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/54
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [5:39:45<4:48:13, 375.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1820.8367201861213
INFO:root:current train perplexity4.261592388153076
INFO:root:current mean train loss 1810.0346210186299
INFO:root:current train perplexity4.1903076171875
INFO:root:current mean train loss 1814.6674697805659
INFO:root:current train perplexity4.181731700897217
INFO:root:current mean train loss 1812.7806577471904
INFO:root:current train perplexity4.184720039367676
INFO:root:current mean train loss 1819.028496245972
INFO:root:current train perplexity4.199026584625244
INFO:root:current mean train loss 1817.6217791854297
INFO:root:current train perplexity4.193054676055908
INFO:root:current mean train loss 1815.958649423559
INFO:root:current train perplexity4.189355373382568
INFO:root:current mean train loss 1816.2225966619812
INFO:root:current train perplexity4.195601463317871
INFO:root:current mean train loss 1816.430786879877
INFO:root:current train perplexity4.195948600769043
INFO:root:current mean train loss 1817.4858273305447
INFO:root:current train perplexity4.198834419250488
INFO:root:current mean train loss 1817.8153346238937
INFO:root:current train perplexity4.200114727020264
INFO:root:current mean train loss 1818.5287041181737
INFO:root:current train perplexity4.203619480133057
INFO:root:current mean train loss 1818.8554580174416
INFO:root:current train perplexity4.205399990081787
INFO:root:current mean train loss 1818.079597722244
INFO:root:current train perplexity4.2055344581604
INFO:root:current mean train loss 1818.7497350117987
INFO:root:current train perplexity4.205029010772705
INFO:root:current mean train loss 1818.3697928200447
INFO:root:current train perplexity4.201454162597656
INFO:root:current mean train loss 1818.7472162382353
INFO:root:current train perplexity4.2023606300354
INFO:root:current mean train loss 1818.8359342296246
INFO:root:current train perplexity4.202027320861816
INFO:root:current mean train loss 1819.3105878562276
INFO:root:current train perplexity4.201524257659912
INFO:root:current mean train loss 1819.7101042761924
INFO:root:current train perplexity4.199939727783203

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.81s/it]
INFO:root:final mean train loss: 1819.9121906320916
INFO:root:final train perplexity: 4.200872421264648
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.02s/it]
INFO:root:eval mean loss: 2848.945217189846
INFO:root:eval perplexity: 10.358084678649902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/55
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [5:45:58<4:41:17, 375.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1796.4433306525734
INFO:root:current train perplexity4.15751314163208
INFO:root:current mean train loss 1807.1264812412546
INFO:root:current train perplexity4.15912389755249
INFO:root:current mean train loss 1816.7867911575188
INFO:root:current train perplexity4.170205593109131
INFO:root:current mean train loss 1819.0949575458458
INFO:root:current train perplexity4.177736759185791
INFO:root:current mean train loss 1819.1222044773365
INFO:root:current train perplexity4.181995391845703
INFO:root:current mean train loss 1818.0462621338804
INFO:root:current train perplexity4.179190158843994
INFO:root:current mean train loss 1815.6233129651764
INFO:root:current train perplexity4.173544883728027
INFO:root:current mean train loss 1814.8960677726393
INFO:root:current train perplexity4.172354698181152
INFO:root:current mean train loss 1814.3100035596524
INFO:root:current train perplexity4.17375373840332
INFO:root:current mean train loss 1811.981382970381
INFO:root:current train perplexity4.17320442199707
INFO:root:current mean train loss 1811.2964745527079
INFO:root:current train perplexity4.176540374755859
INFO:root:current mean train loss 1811.3914004801863
INFO:root:current train perplexity4.175698757171631
INFO:root:current mean train loss 1812.560376233761
INFO:root:current train perplexity4.180222511291504
INFO:root:current mean train loss 1812.6698658727278
INFO:root:current train perplexity4.181291580200195
INFO:root:current mean train loss 1812.7822713386397
INFO:root:current train perplexity4.183207988739014
INFO:root:current mean train loss 1814.0669395715347
INFO:root:current train perplexity4.184530735015869
INFO:root:current mean train loss 1814.8413202479537
INFO:root:current train perplexity4.186357498168945
INFO:root:current mean train loss 1815.912937749491
INFO:root:current train perplexity4.189323902130127
INFO:root:current mean train loss 1815.6063420119956
INFO:root:current train perplexity4.187652111053467
INFO:root:current mean train loss 1816.703517215575
INFO:root:current train perplexity4.188642978668213

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.62s/it]
INFO:root:final mean train loss: 1816.1852387751946
INFO:root:final train perplexity: 4.188543319702148
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.48s/it]
INFO:root:eval mean loss: 2850.07934643628
INFO:root:eval perplexity: 10.367730140686035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/56
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [5:52:09<4:34:11, 373.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1814.3320384306066
INFO:root:current train perplexity4.176478862762451
INFO:root:current mean train loss 1812.9640272532079
INFO:root:current train perplexity4.168920993804932
INFO:root:current mean train loss 1809.7158110721177
INFO:root:current train perplexity4.1706743240356445
INFO:root:current mean train loss 1808.6780911959136
INFO:root:current train perplexity4.16127872467041
INFO:root:current mean train loss 1808.6480509891214
INFO:root:current train perplexity4.16141414642334
INFO:root:current mean train loss 1810.2947340063522
INFO:root:current train perplexity4.16280460357666
INFO:root:current mean train loss 1811.9914187007969
INFO:root:current train perplexity4.168123722076416
INFO:root:current mean train loss 1809.551755699432
INFO:root:current train perplexity4.166399955749512
INFO:root:current mean train loss 1809.0130603758905
INFO:root:current train perplexity4.166648864746094
INFO:root:current mean train loss 1809.0105723672862
INFO:root:current train perplexity4.1687703132629395
INFO:root:current mean train loss 1810.0866300835141
INFO:root:current train perplexity4.171694755554199
INFO:root:current mean train loss 1811.1060944796645
INFO:root:current train perplexity4.171207904815674
INFO:root:current mean train loss 1812.7378561994155
INFO:root:current train perplexity4.172743320465088
INFO:root:current mean train loss 1813.6888829816455
INFO:root:current train perplexity4.174915790557861
INFO:root:current mean train loss 1813.6169940046734
INFO:root:current train perplexity4.17572546005249
INFO:root:current mean train loss 1813.8399245792784
INFO:root:current train perplexity4.177505016326904
INFO:root:current mean train loss 1813.467187263401
INFO:root:current train perplexity4.176843166351318
INFO:root:current mean train loss 1813.6377900546786
INFO:root:current train perplexity4.177977561950684
INFO:root:current mean train loss 1814.323319149172
INFO:root:current train perplexity4.178962230682373
INFO:root:current mean train loss 1813.595508037745
INFO:root:current train perplexity4.1782546043396

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.96s/it]
INFO:root:final mean train loss: 1813.0297364943326
INFO:root:final train perplexity: 4.178132057189941
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.59s/it]
INFO:root:eval mean loss: 2853.0434973547767
INFO:root:eval perplexity: 10.39297866821289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/57
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [5:58:47<4:33:05, 381.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1792.6763718548943
INFO:root:current train perplexity4.098450183868408
INFO:root:current mean train loss 1786.4400075276692
INFO:root:current train perplexity4.108713150024414
INFO:root:current mean train loss 1798.030036584655
INFO:root:current train perplexity4.1235761642456055
INFO:root:current mean train loss 1797.6877321989639
INFO:root:current train perplexity4.1310224533081055
INFO:root:current mean train loss 1800.8018300635183
INFO:root:current train perplexity4.135960102081299
INFO:root:current mean train loss 1802.4178591446139
INFO:root:current train perplexity4.141469955444336
INFO:root:current mean train loss 1801.3810620336476
INFO:root:current train perplexity4.1388630867004395
INFO:root:current mean train loss 1802.252113501231
INFO:root:current train perplexity4.141647815704346
INFO:root:current mean train loss 1804.3693358249927
INFO:root:current train perplexity4.145008087158203
INFO:root:current mean train loss 1807.08276909442
INFO:root:current train perplexity4.151657581329346
INFO:root:current mean train loss 1805.749189283964
INFO:root:current train perplexity4.151973247528076
INFO:root:current mean train loss 1805.571068750669
INFO:root:current train perplexity4.15383768081665
INFO:root:current mean train loss 1807.2362771981898
INFO:root:current train perplexity4.156294345855713
INFO:root:current mean train loss 1805.706182290239
INFO:root:current train perplexity4.1566548347473145
INFO:root:current mean train loss 1806.4378266295555
INFO:root:current train perplexity4.160581588745117
INFO:root:current mean train loss 1807.2575217266472
INFO:root:current train perplexity4.161551475524902
INFO:root:current mean train loss 1807.4452626619407
INFO:root:current train perplexity4.160983562469482
INFO:root:current mean train loss 1808.0156160242418
INFO:root:current train perplexity4.16141939163208
INFO:root:current mean train loss 1808.4503796595832
INFO:root:current train perplexity4.162365436553955
INFO:root:current mean train loss 1809.320606448786
INFO:root:current train perplexity4.165036201477051

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.87s/it]
INFO:root:final mean train loss: 1808.9754349962966
INFO:root:final train perplexity: 4.164793968200684
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.39s/it]
INFO:root:eval mean loss: 2849.8467420056777
INFO:root:eval perplexity: 10.365753173828125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/58
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [6:05:08<4:26:48, 381.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1800.4456571691176
INFO:root:current train perplexity4.14548921585083
INFO:root:current mean train loss 1799.4092080605997
INFO:root:current train perplexity4.131568431854248
INFO:root:current mean train loss 1794.940054053591
INFO:root:current train perplexity4.116970062255859
INFO:root:current mean train loss 1794.4962785993303
INFO:root:current train perplexity4.116142272949219
INFO:root:current mean train loss 1797.0767552955863
INFO:root:current train perplexity4.121829986572266
INFO:root:current mean train loss 1796.8763154380342
INFO:root:current train perplexity4.122740745544434
INFO:root:current mean train loss 1794.126792562443
INFO:root:current train perplexity4.1228485107421875
INFO:root:current mean train loss 1796.2451739463077
INFO:root:current train perplexity4.124316692352295
INFO:root:current mean train loss 1798.0065497274452
INFO:root:current train perplexity4.1305670738220215
INFO:root:current mean train loss 1798.5561936121908
INFO:root:current train perplexity4.134655475616455
INFO:root:current mean train loss 1799.300961374028
INFO:root:current train perplexity4.133948802947998
INFO:root:current mean train loss 1800.684946412678
INFO:root:current train perplexity4.137382984161377
INFO:root:current mean train loss 1800.0722069172543
INFO:root:current train perplexity4.139009475708008
INFO:root:current mean train loss 1801.3922366806746
INFO:root:current train perplexity4.139927864074707
INFO:root:current mean train loss 1801.4318545152041
INFO:root:current train perplexity4.141584396362305
INFO:root:current mean train loss 1801.9258573417783
INFO:root:current train perplexity4.145971298217773
INFO:root:current mean train loss 1802.1805039584106
INFO:root:current train perplexity4.14772367477417
INFO:root:current mean train loss 1804.2003584148504
INFO:root:current train perplexity4.150969505310059
INFO:root:current mean train loss 1804.7983197685262
INFO:root:current train perplexity4.152020454406738

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.76s/it]
INFO:root:final mean train loss: 1805.767587451098
INFO:root:final train perplexity: 4.154271125793457
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.31s/it]
INFO:root:eval mean loss: 2854.1741111228416
INFO:root:eval perplexity: 10.402627944946289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/59
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [6:11:33<4:21:17, 382.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1857.89306640625
INFO:root:current train perplexity4.2913432121276855
INFO:root:current mean train loss 1801.9519342160693
INFO:root:current train perplexity4.111532211303711
INFO:root:current mean train loss 1794.3181907729347
INFO:root:current train perplexity4.111400604248047
INFO:root:current mean train loss 1792.1257740551273
INFO:root:current train perplexity4.104438304901123
INFO:root:current mean train loss 1794.7602575501398
INFO:root:current train perplexity4.111587047576904
INFO:root:current mean train loss 1798.871031012668
INFO:root:current train perplexity4.11962890625
INFO:root:current mean train loss 1797.3067835810969
INFO:root:current train perplexity4.119568347930908
INFO:root:current mean train loss 1800.630496120181
INFO:root:current train perplexity4.125746726989746
INFO:root:current mean train loss 1800.7216092154868
INFO:root:current train perplexity4.134645938873291
INFO:root:current mean train loss 1799.8518174672602
INFO:root:current train perplexity4.136181354522705
INFO:root:current mean train loss 1799.3684654616548
INFO:root:current train perplexity4.136880874633789
INFO:root:current mean train loss 1800.2528339808302
INFO:root:current train perplexity4.137080669403076
INFO:root:current mean train loss 1799.7338743289179
INFO:root:current train perplexity4.137269020080566
INFO:root:current mean train loss 1800.1045708487843
INFO:root:current train perplexity4.138820648193359
INFO:root:current mean train loss 1800.2397527980397
INFO:root:current train perplexity4.139544486999512
INFO:root:current mean train loss 1801.8787446815704
INFO:root:current train perplexity4.139353275299072
INFO:root:current mean train loss 1802.507254344545
INFO:root:current train perplexity4.139707565307617
INFO:root:current mean train loss 1802.087690593213
INFO:root:current train perplexity4.139851093292236
INFO:root:current mean train loss 1802.0682251789462
INFO:root:current train perplexity4.139773368835449
INFO:root:current mean train loss 1801.7580391836718
INFO:root:current train perplexity4.140336036682129

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.72s/it]
INFO:root:final mean train loss: 1801.8001002909496
INFO:root:final train perplexity: 4.141292095184326
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.13s/it]
INFO:root:eval mean loss: 2854.7069410719314
INFO:root:eval perplexity: 10.407175064086914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/60
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [6:17:49<4:13:37, 380.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1758.2580630653783
INFO:root:current train perplexity4.096159934997559
INFO:root:current mean train loss 1784.3045479910713
INFO:root:current train perplexity4.113931655883789
INFO:root:current mean train loss 1796.3216742249929
INFO:root:current train perplexity4.118463039398193
INFO:root:current mean train loss 1798.3219889578027
INFO:root:current train perplexity4.127856254577637
INFO:root:current mean train loss 1799.6176233405429
INFO:root:current train perplexity4.132148742675781
INFO:root:current mean train loss 1797.2601649995484
INFO:root:current train perplexity4.132992744445801
INFO:root:current mean train loss 1796.4981433085748
INFO:root:current train perplexity4.130085468292236
INFO:root:current mean train loss 1793.6083052294312
INFO:root:current train perplexity4.126551628112793
INFO:root:current mean train loss 1793.5079953818968
INFO:root:current train perplexity4.1263909339904785
INFO:root:current mean train loss 1793.1908062591388
INFO:root:current train perplexity4.122898101806641
INFO:root:current mean train loss 1796.1239836658183
INFO:root:current train perplexity4.1262640953063965
INFO:root:current mean train loss 1796.127544822386
INFO:root:current train perplexity4.128302574157715
INFO:root:current mean train loss 1796.5798718371873
INFO:root:current train perplexity4.127920150756836
INFO:root:current mean train loss 1795.5779780343773
INFO:root:current train perplexity4.125988960266113
INFO:root:current mean train loss 1796.643555117628
INFO:root:current train perplexity4.128684043884277
INFO:root:current mean train loss 1797.1052123139452
INFO:root:current train perplexity4.130092620849609
INFO:root:current mean train loss 1797.6385879563725
INFO:root:current train perplexity4.130552768707275
INFO:root:current mean train loss 1798.751550271665
INFO:root:current train perplexity4.131186008453369
INFO:root:current mean train loss 1799.2278572237708
INFO:root:current train perplexity4.1324639320373535
INFO:root:current mean train loss 1800.2287815207303
INFO:root:current train perplexity4.133986949920654

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.54s/it]
INFO:root:final mean train loss: 1799.6426414685964
INFO:root:final train perplexity: 4.134252548217773
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.78s/it]
INFO:root:eval mean loss: 2854.836692649681
INFO:root:eval perplexity: 10.408284187316895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/61
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [6:24:02<4:05:44, 378.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1796.8035040961372
INFO:root:current train perplexity4.066483497619629
INFO:root:current mean train loss 1789.122470631319
INFO:root:current train perplexity4.08500862121582
INFO:root:current mean train loss 1792.960497322729
INFO:root:current train perplexity4.101282596588135
INFO:root:current mean train loss 1794.7376476469494
INFO:root:current train perplexity4.119617938995361
INFO:root:current mean train loss 1795.6086991336367
INFO:root:current train perplexity4.119393348693848
INFO:root:current mean train loss 1796.5985658560226
INFO:root:current train perplexity4.119544982910156
INFO:root:current mean train loss 1794.8841464444527
INFO:root:current train perplexity4.116880416870117
INFO:root:current mean train loss 1796.2130967845087
INFO:root:current train perplexity4.119548797607422
INFO:root:current mean train loss 1798.5115772594106
INFO:root:current train perplexity4.127223491668701
INFO:root:current mean train loss 1798.6445782001201
INFO:root:current train perplexity4.126885890960693
INFO:root:current mean train loss 1797.2193974675358
INFO:root:current train perplexity4.122668743133545
INFO:root:current mean train loss 1797.1524751690072
INFO:root:current train perplexity4.120909690856934
INFO:root:current mean train loss 1796.6531362194073
INFO:root:current train perplexity4.11918830871582
INFO:root:current mean train loss 1796.8360913670706
INFO:root:current train perplexity4.119200706481934
INFO:root:current mean train loss 1796.5349413518454
INFO:root:current train perplexity4.121280193328857
INFO:root:current mean train loss 1796.2601958910625
INFO:root:current train perplexity4.121970176696777
INFO:root:current mean train loss 1795.5372684544047
INFO:root:current train perplexity4.120880603790283
INFO:root:current mean train loss 1795.7718346239785
INFO:root:current train perplexity4.121031284332275
INFO:root:current mean train loss 1795.9221944040203
INFO:root:current train perplexity4.12091064453125
INFO:root:current mean train loss 1796.503738466373
INFO:root:current train perplexity4.122427463531494

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.13s/it]
INFO:root:final mean train loss: 1796.0339530294614
INFO:root:final train perplexity: 4.122503280639648
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.44s/it]
INFO:root:eval mean loss: 2855.505466403904
INFO:root:eval perplexity: 10.413997650146484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/62
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [6:30:14<3:58:25, 376.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1795.0030609706662
INFO:root:current train perplexity4.08152961730957
INFO:root:current mean train loss 1782.8548081341912
INFO:root:current train perplexity4.092637062072754
INFO:root:current mean train loss 1784.6629214079483
INFO:root:current train perplexity4.091304302215576
INFO:root:current mean train loss 1788.7256467997522
INFO:root:current train perplexity4.1022443771362305
INFO:root:current mean train loss 1789.1947730192812
INFO:root:current train perplexity4.104763507843018
INFO:root:current mean train loss 1791.1458369387856
INFO:root:current train perplexity4.10862922668457
INFO:root:current mean train loss 1791.147471779886
INFO:root:current train perplexity4.106167316436768
INFO:root:current mean train loss 1792.2208107673473
INFO:root:current train perplexity4.1088643074035645
INFO:root:current mean train loss 1794.1021817241995
INFO:root:current train perplexity4.110378742218018
INFO:root:current mean train loss 1794.0144890928318
INFO:root:current train perplexity4.108745098114014
INFO:root:current mean train loss 1794.4605032403697
INFO:root:current train perplexity4.1091132164001465
INFO:root:current mean train loss 1794.157041498401
INFO:root:current train perplexity4.110538959503174
INFO:root:current mean train loss 1793.3053175308946
INFO:root:current train perplexity4.110934734344482
INFO:root:current mean train loss 1793.253520460897
INFO:root:current train perplexity4.110199451446533
INFO:root:current mean train loss 1794.1049398906625
INFO:root:current train perplexity4.112680435180664
INFO:root:current mean train loss 1794.8336296400867
INFO:root:current train perplexity4.115392208099365
INFO:root:current mean train loss 1794.3986481875993
INFO:root:current train perplexity4.115407943725586
INFO:root:current mean train loss 1794.1981176103243
INFO:root:current train perplexity4.114851951599121
INFO:root:current mean train loss 1794.1931685289692
INFO:root:current train perplexity4.115601539611816
INFO:root:current mean train loss 1794.2784420702924
INFO:root:current train perplexity4.114905834197998

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.32s/it]
INFO:root:final mean train loss: 1793.5258313523839
INFO:root:final train perplexity: 4.114355564117432
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.46s/it]
INFO:root:eval mean loss: 2858.6056058499908
INFO:root:eval perplexity: 10.440524101257324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/63
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [6:36:27<3:51:29, 375.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1792.8259800502233
INFO:root:current train perplexity4.111766815185547
INFO:root:current mean train loss 1791.4572200999542
INFO:root:current train perplexity4.1093854904174805
INFO:root:current mean train loss 1790.8883870442708
INFO:root:current train perplexity4.099867820739746
INFO:root:current mean train loss 1786.6924395586993
INFO:root:current train perplexity4.088007926940918
INFO:root:current mean train loss 1788.776772616772
INFO:root:current train perplexity4.099902153015137
INFO:root:current mean train loss 1788.0632724695038
INFO:root:current train perplexity4.105120658874512
INFO:root:current mean train loss 1788.917598348589
INFO:root:current train perplexity4.098361968994141
INFO:root:current mean train loss 1790.3132276658887
INFO:root:current train perplexity4.101154327392578
INFO:root:current mean train loss 1792.2417448197289
INFO:root:current train perplexity4.103819847106934
INFO:root:current mean train loss 1793.0173029004914
INFO:root:current train perplexity4.103096961975098
INFO:root:current mean train loss 1792.570933461412
INFO:root:current train perplexity4.1013078689575195
INFO:root:current mean train loss 1792.2206700512486
INFO:root:current train perplexity4.09833288192749
INFO:root:current mean train loss 1792.1477565014457
INFO:root:current train perplexity4.096759796142578
INFO:root:current mean train loss 1791.5983320918397
INFO:root:current train perplexity4.0974249839782715
INFO:root:current mean train loss 1791.3183455901892
INFO:root:current train perplexity4.098628520965576
INFO:root:current mean train loss 1790.6988601587382
INFO:root:current train perplexity4.098198413848877
INFO:root:current mean train loss 1790.9514885268525
INFO:root:current train perplexity4.100260257720947
INFO:root:current mean train loss 1791.0469227246645
INFO:root:current train perplexity4.099978446960449
INFO:root:current mean train loss 1790.6221626159343
INFO:root:current train perplexity4.100687026977539
INFO:root:current mean train loss 1790.5385115725135
INFO:root:current train perplexity4.102689266204834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:34<00:00, 334.82s/it]
INFO:root:final mean train loss: 1790.0380523266122
INFO:root:final train perplexity: 4.103054523468018
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.58s/it]
INFO:root:eval mean loss: 2860.8505925358954
INFO:root:eval perplexity: 10.459771156311035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/64
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [6:42:53<3:47:04, 378.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1788.5851966594828
INFO:root:current train perplexity4.076936721801758
INFO:root:current mean train loss 1789.5772352575618
INFO:root:current train perplexity4.088964939117432
INFO:root:current mean train loss 1789.129660363812
INFO:root:current train perplexity4.081968784332275
INFO:root:current mean train loss 1781.6981059229652
INFO:root:current train perplexity4.080651760101318
INFO:root:current mean train loss 1781.0194547993935
INFO:root:current train perplexity4.083434581756592
INFO:root:current mean train loss 1779.3273965292935
INFO:root:current train perplexity4.080684185028076
INFO:root:current mean train loss 1780.0571187781454
INFO:root:current train perplexity4.081147193908691
INFO:root:current mean train loss 1779.2886576670703
INFO:root:current train perplexity4.077757358551025
INFO:root:current mean train loss 1782.3877045331437
INFO:root:current train perplexity4.0801801681518555
INFO:root:current mean train loss 1784.3178368349086
INFO:root:current train perplexity4.0839643478393555
INFO:root:current mean train loss 1783.6925765303372
INFO:root:current train perplexity4.082309246063232
INFO:root:current mean train loss 1785.0700964345185
INFO:root:current train perplexity4.087378978729248
INFO:root:current mean train loss 1785.03740682061
INFO:root:current train perplexity4.087464332580566
INFO:root:current mean train loss 1785.9385994249053
INFO:root:current train perplexity4.089747428894043
INFO:root:current mean train loss 1787.0774366613516
INFO:root:current train perplexity4.091088771820068
INFO:root:current mean train loss 1787.9602378455813
INFO:root:current train perplexity4.093906402587891
INFO:root:current mean train loss 1787.4078326448578
INFO:root:current train perplexity4.094780921936035
INFO:root:current mean train loss 1787.058228768646
INFO:root:current train perplexity4.093041896820068
INFO:root:current mean train loss 1787.0641969520073
INFO:root:current train perplexity4.09298849105835

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.49s/it]
INFO:root:final mean train loss: 1787.3596459800885
INFO:root:final train perplexity: 4.094396591186523
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.57s/it]
INFO:root:eval mean loss: 2859.7644174936654
INFO:root:eval perplexity: 10.450453758239746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/65
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [6:49:05<3:39:40, 376.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1765.8338928222656
INFO:root:current train perplexity4.083845138549805
INFO:root:current mean train loss 1771.9253833477314
INFO:root:current train perplexity4.05700159072876
INFO:root:current mean train loss 1787.119333304611
INFO:root:current train perplexity4.088021755218506
INFO:root:current mean train loss 1783.9132369192023
INFO:root:current train perplexity4.0761871337890625
INFO:root:current mean train loss 1783.036803292756
INFO:root:current train perplexity4.076235294342041
INFO:root:current mean train loss 1784.1942356654577
INFO:root:current train perplexity4.077605247497559
INFO:root:current mean train loss 1784.028080011835
INFO:root:current train perplexity4.07546329498291
INFO:root:current mean train loss 1783.9987123662775
INFO:root:current train perplexity4.078404903411865
INFO:root:current mean train loss 1786.1685101713115
INFO:root:current train perplexity4.083920478820801
INFO:root:current mean train loss 1786.2874894943911
INFO:root:current train perplexity4.082063674926758
INFO:root:current mean train loss 1785.7300750610839
INFO:root:current train perplexity4.0793962478637695
INFO:root:current mean train loss 1784.5519678972769
INFO:root:current train perplexity4.0793890953063965
INFO:root:current mean train loss 1785.3457518922926
INFO:root:current train perplexity4.082356929779053
INFO:root:current mean train loss 1785.59612213322
INFO:root:current train perplexity4.083661079406738
INFO:root:current mean train loss 1785.2878088448463
INFO:root:current train perplexity4.084609508514404
INFO:root:current mean train loss 1784.687472647809
INFO:root:current train perplexity4.083467960357666
INFO:root:current mean train loss 1784.787828250419
INFO:root:current train perplexity4.082380294799805
INFO:root:current mean train loss 1783.8730197243847
INFO:root:current train perplexity4.083141326904297
INFO:root:current mean train loss 1784.0508811933767
INFO:root:current train perplexity4.084333896636963
INFO:root:current mean train loss 1784.7505078355805
INFO:root:current train perplexity4.085413455963135

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.42s/it]
INFO:root:final mean train loss: 1785.1991839079442
INFO:root:final train perplexity: 4.087425708770752
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.35s/it]
INFO:root:eval mean loss: 2859.619995483765
INFO:root:eval perplexity: 10.449214935302734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/66
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [6:55:18<3:32:45, 375.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1745.693870907738
INFO:root:current train perplexity3.975708246231079
INFO:root:current mean train loss 1777.3647723237345
INFO:root:current train perplexity4.022885799407959
INFO:root:current mean train loss 1770.7182031691884
INFO:root:current train perplexity4.039825439453125
INFO:root:current mean train loss 1777.8284121124173
INFO:root:current train perplexity4.061097145080566
INFO:root:current mean train loss 1780.914015817529
INFO:root:current train perplexity4.069234371185303
INFO:root:current mean train loss 1780.6905719076146
INFO:root:current train perplexity4.071369171142578
INFO:root:current mean train loss 1780.9887986236915
INFO:root:current train perplexity4.071134567260742
INFO:root:current mean train loss 1779.7560594958175
INFO:root:current train perplexity4.062259674072266
INFO:root:current mean train loss 1780.9467950372546
INFO:root:current train perplexity4.064877510070801
INFO:root:current mean train loss 1781.5781764259298
INFO:root:current train perplexity4.06587553024292
INFO:root:current mean train loss 1780.218210188579
INFO:root:current train perplexity4.065788269042969
INFO:root:current mean train loss 1780.0495107822605
INFO:root:current train perplexity4.066109657287598
INFO:root:current mean train loss 1780.3873967851018
INFO:root:current train perplexity4.066805362701416
INFO:root:current mean train loss 1778.4829666172348
INFO:root:current train perplexity4.067580223083496
INFO:root:current mean train loss 1779.3906596195186
INFO:root:current train perplexity4.069815635681152
INFO:root:current mean train loss 1778.9931187977688
INFO:root:current train perplexity4.070348739624023
INFO:root:current mean train loss 1779.8816291484327
INFO:root:current train perplexity4.070797443389893
INFO:root:current mean train loss 1780.079204907326
INFO:root:current train perplexity4.072716236114502
INFO:root:current mean train loss 1780.9285443561016
INFO:root:current train perplexity4.072299003601074
INFO:root:current mean train loss 1780.4482867326792
INFO:root:current train perplexity4.071725845336914

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.47s/it]
INFO:root:final mean train loss: 1781.0138911460303
INFO:root:final train perplexity: 4.0739569664001465
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.40s/it]
INFO:root:eval mean loss: 2862.594870994041
INFO:root:eval perplexity: 10.474754333496094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/67
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [7:01:30<3:25:55, 374.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1768.0617804276317
INFO:root:current train perplexity4.049088954925537
INFO:root:current mean train loss 1762.4300245202105
INFO:root:current train perplexity4.028302192687988
INFO:root:current mean train loss 1766.2771508994222
INFO:root:current train perplexity4.034775257110596
INFO:root:current mean train loss 1766.5832003079927
INFO:root:current train perplexity4.04154109954834
INFO:root:current mean train loss 1770.0513144018444
INFO:root:current train perplexity4.048449516296387
INFO:root:current mean train loss 1774.442584069688
INFO:root:current train perplexity4.052537441253662
INFO:root:current mean train loss 1777.6223502323546
INFO:root:current train perplexity4.054751396179199
INFO:root:current mean train loss 1774.6421538562308
INFO:root:current train perplexity4.05305290222168
INFO:root:current mean train loss 1775.9283732776141
INFO:root:current train perplexity4.054409503936768
INFO:root:current mean train loss 1777.9621032844982
INFO:root:current train perplexity4.056594371795654
INFO:root:current mean train loss 1777.91542079683
INFO:root:current train perplexity4.058766841888428
INFO:root:current mean train loss 1779.1416723589905
INFO:root:current train perplexity4.0583906173706055
INFO:root:current mean train loss 1779.0326967994308
INFO:root:current train perplexity4.058737754821777
INFO:root:current mean train loss 1778.0340673791632
INFO:root:current train perplexity4.058877944946289
INFO:root:current mean train loss 1778.2934229058915
INFO:root:current train perplexity4.060319423675537
INFO:root:current mean train loss 1779.4386172052787
INFO:root:current train perplexity4.062629222869873
INFO:root:current mean train loss 1779.3191134833592
INFO:root:current train perplexity4.063462734222412
INFO:root:current mean train loss 1779.811091626061
INFO:root:current train perplexity4.065732479095459
INFO:root:current mean train loss 1780.340131392287
INFO:root:current train perplexity4.066978454589844
INFO:root:current mean train loss 1779.0605209870234
INFO:root:current train perplexity4.066244125366211

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.90s/it]
INFO:root:final mean train loss: 1778.6843408227749
INFO:root:final train perplexity: 4.066479206085205
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.76s/it]
INFO:root:eval mean loss: 2864.0094188426706
INFO:root:eval perplexity: 10.486918449401855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/68
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [7:07:42<3:19:15, 373.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1760.2389137961648
INFO:root:current train perplexity4.0325517654418945
INFO:root:current mean train loss 1779.473921843498
INFO:root:current train perplexity4.039202690124512
INFO:root:current mean train loss 1777.2902281518077
INFO:root:current train perplexity4.048194885253906
INFO:root:current mean train loss 1781.1290836817782
INFO:root:current train perplexity4.0607075691223145
INFO:root:current mean train loss 1779.596622810783
INFO:root:current train perplexity4.062695503234863
INFO:root:current mean train loss 1777.1169090477197
INFO:root:current train perplexity4.056126594543457
INFO:root:current mean train loss 1776.3657666388358
INFO:root:current train perplexity4.054520130157471
INFO:root:current mean train loss 1775.8445362621585
INFO:root:current train perplexity4.047904014587402
INFO:root:current mean train loss 1774.5050845497533
INFO:root:current train perplexity4.046753883361816
INFO:root:current mean train loss 1775.6005846592768
INFO:root:current train perplexity4.049833297729492
INFO:root:current mean train loss 1775.0827983838121
INFO:root:current train perplexity4.049884796142578
INFO:root:current mean train loss 1776.6857938692167
INFO:root:current train perplexity4.052892684936523
INFO:root:current mean train loss 1777.1315418015438
INFO:root:current train perplexity4.054040431976318
INFO:root:current mean train loss 1776.8317755780097
INFO:root:current train perplexity4.054709434509277
INFO:root:current mean train loss 1777.3849958387027
INFO:root:current train perplexity4.05592155456543
INFO:root:current mean train loss 1777.9796206949609
INFO:root:current train perplexity4.0569233894348145
INFO:root:current mean train loss 1779.1206821038284
INFO:root:current train perplexity4.060157775878906
INFO:root:current mean train loss 1777.9470819978633
INFO:root:current train perplexity4.05871057510376
INFO:root:current mean train loss 1777.3963790194364
INFO:root:current train perplexity4.058390140533447
INFO:root:current mean train loss 1776.875754088575
INFO:root:current train perplexity4.058396816253662

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.88s/it]
INFO:root:final mean train loss: 1776.3898393301067
INFO:root:final train perplexity: 4.059126853942871
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.27s/it]
INFO:root:eval mean loss: 2863.7900302646394
INFO:root:eval perplexity: 10.485031127929688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/69
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [7:13:52<3:12:30, 372.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1760.7837287055122
INFO:root:current train perplexity4.042433738708496
INFO:root:current mean train loss 1763.01581520258
INFO:root:current train perplexity4.038148403167725
INFO:root:current mean train loss 1763.275255988626
INFO:root:current train perplexity4.039517402648926
INFO:root:current mean train loss 1762.536867859543
INFO:root:current train perplexity4.033787727355957
INFO:root:current mean train loss 1767.3037577483612
INFO:root:current train perplexity4.035703182220459
INFO:root:current mean train loss 1769.307308810574
INFO:root:current train perplexity4.042435646057129
INFO:root:current mean train loss 1770.4372017270043
INFO:root:current train perplexity4.046270847320557
INFO:root:current mean train loss 1769.2530416379939
INFO:root:current train perplexity4.043200969696045
INFO:root:current mean train loss 1767.485856362439
INFO:root:current train perplexity4.0426859855651855
INFO:root:current mean train loss 1767.6742357795622
INFO:root:current train perplexity4.042315483093262
INFO:root:current mean train loss 1767.5548258539457
INFO:root:current train perplexity4.042117595672607
INFO:root:current mean train loss 1769.1993262385345
INFO:root:current train perplexity4.04440450668335
INFO:root:current mean train loss 1769.5788653871548
INFO:root:current train perplexity4.044235706329346
INFO:root:current mean train loss 1769.0997779779461
INFO:root:current train perplexity4.045192718505859
INFO:root:current mean train loss 1770.203436644181
INFO:root:current train perplexity4.047241687774658
INFO:root:current mean train loss 1770.0403349199369
INFO:root:current train perplexity4.046622276306152
INFO:root:current mean train loss 1771.6403147136195
INFO:root:current train perplexity4.047537326812744
INFO:root:current mean train loss 1772.0943573893596
INFO:root:current train perplexity4.047094821929932
INFO:root:current mean train loss 1773.1913833618164
INFO:root:current train perplexity4.047889709472656
INFO:root:current mean train loss 1773.564815498027
INFO:root:current train perplexity4.048913955688477

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.32s/it]
INFO:root:final mean train loss: 1773.348386702006
INFO:root:final train perplexity: 4.049402236938477
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.07s/it]
INFO:root:eval mean loss: 2867.582914701811
INFO:root:eval perplexity: 10.517714500427246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/70
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [7:20:02<3:05:57, 371.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1760.448637201545
INFO:root:current train perplexity4.058309078216553
INFO:root:current mean train loss 1753.8643236917162
INFO:root:current train perplexity4.030511856079102
INFO:root:current mean train loss 1760.8225579179282
INFO:root:current train perplexity4.03307580947876
INFO:root:current mean train loss 1759.7134758721281
INFO:root:current train perplexity4.029357433319092
INFO:root:current mean train loss 1764.5214406893053
INFO:root:current train perplexity4.035494804382324
INFO:root:current mean train loss 1764.4561290902882
INFO:root:current train perplexity4.036573886871338
INFO:root:current mean train loss 1765.1818137203488
INFO:root:current train perplexity4.034402370452881
INFO:root:current mean train loss 1763.9846230085057
INFO:root:current train perplexity4.0282487869262695
INFO:root:current mean train loss 1765.757885000703
INFO:root:current train perplexity4.030728340148926
INFO:root:current mean train loss 1768.3282543525656
INFO:root:current train perplexity4.031767845153809
INFO:root:current mean train loss 1766.2129900523344
INFO:root:current train perplexity4.029885768890381
INFO:root:current mean train loss 1765.8533693254244
INFO:root:current train perplexity4.031889915466309
INFO:root:current mean train loss 1766.2403968828792
INFO:root:current train perplexity4.0327019691467285
INFO:root:current mean train loss 1766.253809402279
INFO:root:current train perplexity4.033576965332031
INFO:root:current mean train loss 1767.2951976604475
INFO:root:current train perplexity4.036699295043945
INFO:root:current mean train loss 1767.1255611854203
INFO:root:current train perplexity4.037026405334473
INFO:root:current mean train loss 1768.273972975989
INFO:root:current train perplexity4.036996841430664
INFO:root:current mean train loss 1769.2717437317679
INFO:root:current train perplexity4.036932468414307
INFO:root:current mean train loss 1770.56003326206
INFO:root:current train perplexity4.0384931564331055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.04s/it]
INFO:root:final mean train loss: 1770.696119653776
INFO:root:final train perplexity: 4.040940284729004
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.05s/it]
INFO:root:eval mean loss: 2865.322329409488
INFO:root:eval perplexity: 10.498221397399902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/71
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [7:26:11<2:59:21, 371.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1817.9095865885417
INFO:root:current train perplexity4.06766414642334
INFO:root:current mean train loss 1761.1175283755897
INFO:root:current train perplexity3.9891257286071777
INFO:root:current mean train loss 1755.1031695615898
INFO:root:current train perplexity3.990504503250122
INFO:root:current mean train loss 1756.2390559576695
INFO:root:current train perplexity3.9915640354156494
INFO:root:current mean train loss 1759.0457297639894
INFO:root:current train perplexity4.00432825088501
INFO:root:current mean train loss 1758.7308108363698
INFO:root:current train perplexity4.0058064460754395
INFO:root:current mean train loss 1761.388917425678
INFO:root:current train perplexity4.0131425857543945
INFO:root:current mean train loss 1763.8471358085826
INFO:root:current train perplexity4.018703937530518
INFO:root:current mean train loss 1764.6465092131282
INFO:root:current train perplexity4.017923355102539
INFO:root:current mean train loss 1764.6506960702523
INFO:root:current train perplexity4.017956733703613
INFO:root:current mean train loss 1766.045720307064
INFO:root:current train perplexity4.024065017700195
INFO:root:current mean train loss 1762.0010547051593
INFO:root:current train perplexity4.0200653076171875
INFO:root:current mean train loss 1763.8424908335924
INFO:root:current train perplexity4.021337032318115
INFO:root:current mean train loss 1765.7263495779694
INFO:root:current train perplexity4.023621082305908
INFO:root:current mean train loss 1766.1680178906806
INFO:root:current train perplexity4.026558876037598
INFO:root:current mean train loss 1766.5488826756775
INFO:root:current train perplexity4.0258002281188965
INFO:root:current mean train loss 1766.3628636570381
INFO:root:current train perplexity4.027983665466309
INFO:root:current mean train loss 1765.3007462603266
INFO:root:current train perplexity4.026658058166504
INFO:root:current mean train loss 1766.4523374234323
INFO:root:current train perplexity4.029860496520996
INFO:root:current mean train loss 1768.7280701260001
INFO:root:current train perplexity4.0325727462768555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.67s/it]
INFO:root:final mean train loss: 1768.596329143176
INFO:root:final train perplexity: 4.03425407409668
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.03s/it]
INFO:root:eval mean loss: 2869.842069608671
INFO:root:eval perplexity: 10.537229537963867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/72
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [7:32:22<2:53:07, 370.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1786.7879161005435
INFO:root:current train perplexity4.018734931945801
INFO:root:current mean train loss 1775.911865234375
INFO:root:current train perplexity4.028580665588379
INFO:root:current mean train loss 1766.8405592024594
INFO:root:current train perplexity4.015404224395752
INFO:root:current mean train loss 1765.8074822676808
INFO:root:current train perplexity4.013652801513672
INFO:root:current mean train loss 1766.228145085328
INFO:root:current train perplexity4.0180344581604
INFO:root:current mean train loss 1766.7884066346498
INFO:root:current train perplexity4.01768159866333
INFO:root:current mean train loss 1764.8828209253988
INFO:root:current train perplexity4.012601375579834
INFO:root:current mean train loss 1764.096141598861
INFO:root:current train perplexity4.018850326538086
INFO:root:current mean train loss 1764.0764455320189
INFO:root:current train perplexity4.019293785095215
INFO:root:current mean train loss 1764.8228841763018
INFO:root:current train perplexity4.021178245544434
INFO:root:current mean train loss 1766.1246403519826
INFO:root:current train perplexity4.02199649810791
INFO:root:current mean train loss 1766.3035342996925
INFO:root:current train perplexity4.023322105407715
INFO:root:current mean train loss 1765.8315556448986
INFO:root:current train perplexity4.023524761199951
INFO:root:current mean train loss 1765.43845128112
INFO:root:current train perplexity4.023440837860107
INFO:root:current mean train loss 1765.2084073075423
INFO:root:current train perplexity4.023660182952881
INFO:root:current mean train loss 1766.0950978229646
INFO:root:current train perplexity4.025787830352783
INFO:root:current mean train loss 1766.8345498997564
INFO:root:current train perplexity4.026383876800537
INFO:root:current mean train loss 1766.9626384077553
INFO:root:current train perplexity4.026661396026611
INFO:root:current mean train loss 1767.0667871254457
INFO:root:current train perplexity4.025191783905029
INFO:root:current mean train loss 1766.7748659067456
INFO:root:current train perplexity4.0261549949646

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.54s/it]
INFO:root:final mean train loss: 1766.3475252844983
INFO:root:final train perplexity: 4.027105331420898
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.06s/it]
INFO:root:eval mean loss: 2868.425399276229
INFO:root:eval perplexity: 10.524989128112793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/73
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [7:38:36<2:47:17, 371.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1751.5686737060546
INFO:root:current train perplexity4.043648719787598
INFO:root:current mean train loss 1755.1810433523995
INFO:root:current train perplexity4.002798080444336
INFO:root:current mean train loss 1752.7514333089193
INFO:root:current train perplexity4.001029014587402
INFO:root:current mean train loss 1756.8176804486443
INFO:root:current train perplexity4.008450031280518
INFO:root:current mean train loss 1761.8975541548295
INFO:root:current train perplexity4.0139994621276855
INFO:root:current mean train loss 1762.4563842773437
INFO:root:current train perplexity4.019946098327637
INFO:root:current mean train loss 1762.9360431671143
INFO:root:current train perplexity4.014730453491211
INFO:root:current mean train loss 1762.5903554555532
INFO:root:current train perplexity4.0148468017578125
INFO:root:current mean train loss 1762.6605149042039
INFO:root:current train perplexity4.014357089996338
INFO:root:current mean train loss 1762.494035696476
INFO:root:current train perplexity4.016730785369873
INFO:root:current mean train loss 1763.3272529015173
INFO:root:current train perplexity4.019365310668945
INFO:root:current mean train loss 1763.2363865902548
INFO:root:current train perplexity4.021905899047852
INFO:root:current mean train loss 1764.0216502528037
INFO:root:current train perplexity4.022675514221191
INFO:root:current mean train loss 1764.1231990074043
INFO:root:current train perplexity4.021562576293945
INFO:root:current mean train loss 1762.9661667717828
INFO:root:current train perplexity4.017701148986816
INFO:root:current mean train loss 1762.6775874150264
INFO:root:current train perplexity4.0177202224731445
INFO:root:current mean train loss 1763.3189279695837
INFO:root:current train perplexity4.017928600311279
INFO:root:current mean train loss 1763.7014313094917
INFO:root:current train perplexity4.018359661102295
INFO:root:current mean train loss 1764.046907972253
INFO:root:current train perplexity4.019294261932373
INFO:root:current mean train loss 1764.4111769214119
INFO:root:current train perplexity4.019287109375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.88s/it]
INFO:root:final mean train loss: 1763.8868422361559
INFO:root:final train perplexity: 4.019298076629639
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.02s/it]
INFO:root:eval mean loss: 2872.046894795186
INFO:root:eval perplexity: 10.556312561035156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/74
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [7:44:46<2:40:51, 371.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1749.5551051089637
INFO:root:current train perplexity3.9740843772888184
INFO:root:current mean train loss 1767.7481782755274
INFO:root:current train perplexity4.016709804534912
INFO:root:current mean train loss 1764.647903620501
INFO:root:current train perplexity4.0008063316345215
INFO:root:current mean train loss 1760.4313424588586
INFO:root:current train perplexity3.998791456222534
INFO:root:current mean train loss 1756.1460487148695
INFO:root:current train perplexity3.99334454536438
INFO:root:current mean train loss 1759.6747253527546
INFO:root:current train perplexity4.00517463684082
INFO:root:current mean train loss 1760.3714475123668
INFO:root:current train perplexity4.001806259155273
INFO:root:current mean train loss 1758.5958559950875
INFO:root:current train perplexity4.000155448913574
INFO:root:current mean train loss 1758.9227250765753
INFO:root:current train perplexity4.003567695617676
INFO:root:current mean train loss 1758.5504720562303
INFO:root:current train perplexity4.002849578857422
INFO:root:current mean train loss 1757.570707929281
INFO:root:current train perplexity3.999180316925049
INFO:root:current mean train loss 1759.8420743554857
INFO:root:current train perplexity4.001029014587402
INFO:root:current mean train loss 1758.2648148881885
INFO:root:current train perplexity3.9995970726013184
INFO:root:current mean train loss 1759.1586396815412
INFO:root:current train perplexity4.003500938415527
INFO:root:current mean train loss 1759.7803361901863
INFO:root:current train perplexity4.005880832672119
INFO:root:current mean train loss 1760.0506748598818
INFO:root:current train perplexity4.007638931274414
INFO:root:current mean train loss 1760.8298354577644
INFO:root:current train perplexity4.009718894958496
INFO:root:current mean train loss 1760.6812812227652
INFO:root:current train perplexity4.009047508239746
INFO:root:current mean train loss 1762.4238757173027
INFO:root:current train perplexity4.014552593231201
INFO:root:current mean train loss 1762.044599514563
INFO:root:current train perplexity4.013071060180664

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.68s/it]
INFO:root:final mean train loss: 1761.9911973946514
INFO:root:final train perplexity: 4.013293266296387
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.54s/it]
INFO:root:eval mean loss: 2871.3061112870682
INFO:root:eval perplexity: 10.549896240234375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/75
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [7:51:08<2:36:03, 374.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1767.9253803974873
INFO:root:current train perplexity4.035419940948486
INFO:root:current mean train loss 1752.5137553598688
INFO:root:current train perplexity3.9969232082366943
INFO:root:current mean train loss 1758.091477888344
INFO:root:current train perplexity3.9956717491149902
INFO:root:current mean train loss 1758.7195924157127
INFO:root:current train perplexity3.9940311908721924
INFO:root:current mean train loss 1760.6344246522283
INFO:root:current train perplexity4.000837326049805
INFO:root:current mean train loss 1758.6038958718968
INFO:root:current train perplexity4.002774715423584
INFO:root:current mean train loss 1757.3427837609538
INFO:root:current train perplexity3.998990297317505
INFO:root:current mean train loss 1759.0564912702378
INFO:root:current train perplexity4.003044128417969
INFO:root:current mean train loss 1758.747679267377
INFO:root:current train perplexity4.000580787658691
INFO:root:current mean train loss 1760.1970081995155
INFO:root:current train perplexity4.002967357635498
INFO:root:current mean train loss 1760.1200028460341
INFO:root:current train perplexity4.001121997833252
INFO:root:current mean train loss 1760.5561411141132
INFO:root:current train perplexity4.000866889953613
INFO:root:current mean train loss 1759.0557612205039
INFO:root:current train perplexity3.999764919281006
INFO:root:current mean train loss 1761.2747536205309
INFO:root:current train perplexity4.005924701690674
INFO:root:current mean train loss 1760.5849658236252
INFO:root:current train perplexity4.006011009216309
INFO:root:current mean train loss 1760.1950728575187
INFO:root:current train perplexity4.006425380706787
INFO:root:current mean train loss 1760.5803470588785
INFO:root:current train perplexity4.007759094238281
INFO:root:current mean train loss 1760.2965374143444
INFO:root:current train perplexity4.007321357727051
INFO:root:current mean train loss 1760.9171323664289
INFO:root:current train perplexity4.008545875549316
INFO:root:current mean train loss 1760.9806674389129
INFO:root:current train perplexity4.008960247039795

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.91s/it]
INFO:root:final mean train loss: 1760.718213857092
INFO:root:final train perplexity: 4.0092668533325195
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.04s/it]
INFO:root:eval mean loss: 2873.5144226257507
INFO:root:eval perplexity: 10.569032669067383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/76
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [7:57:18<2:29:15, 373.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1754.2050284920158
INFO:root:current train perplexity4.007559776306152
INFO:root:current mean train loss 1760.3206154388906
INFO:root:current train perplexity4.018285751342773
INFO:root:current mean train loss 1755.827137530874
INFO:root:current train perplexity4.002535820007324
INFO:root:current mean train loss 1755.754178488651
INFO:root:current train perplexity3.9979958534240723
INFO:root:current mean train loss 1756.5134374303875
INFO:root:current train perplexity3.999624252319336
INFO:root:current mean train loss 1754.437519209034
INFO:root:current train perplexity3.989192247390747
INFO:root:current mean train loss 1755.0706774743353
INFO:root:current train perplexity3.9914650917053223
INFO:root:current mean train loss 1757.1665657901885
INFO:root:current train perplexity3.992971420288086
INFO:root:current mean train loss 1756.9473626236322
INFO:root:current train perplexity3.994466781616211
INFO:root:current mean train loss 1756.8840017924997
INFO:root:current train perplexity3.99589467048645
INFO:root:current mean train loss 1757.8115775915157
INFO:root:current train perplexity3.996229410171509
INFO:root:current mean train loss 1758.9020066473486
INFO:root:current train perplexity3.998750925064087
INFO:root:current mean train loss 1757.882877742847
INFO:root:current train perplexity3.9977362155914307
INFO:root:current mean train loss 1758.4719948237273
INFO:root:current train perplexity4.000131607055664
INFO:root:current mean train loss 1758.4426545437993
INFO:root:current train perplexity3.9987494945526123
INFO:root:current mean train loss 1758.8433685206828
INFO:root:current train perplexity3.999788284301758
INFO:root:current mean train loss 1758.1093483625398
INFO:root:current train perplexity3.9975359439849854
INFO:root:current mean train loss 1758.5987509296701
INFO:root:current train perplexity3.999593734741211
INFO:root:current mean train loss 1758.2140598791354
INFO:root:current train perplexity3.9997315406799316

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.53s/it]
INFO:root:final mean train loss: 1758.2702916193898
INFO:root:final train perplexity: 4.0015339851379395
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.05s/it]
INFO:root:eval mean loss: 2877.284130566113
INFO:root:eval perplexity: 10.601776123046875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/77
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [8:03:27<2:22:37, 372.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1702.9104309082031
INFO:root:current train perplexity3.858623743057251
INFO:root:current mean train loss 1744.655320909288
INFO:root:current train perplexity3.9728238582611084
INFO:root:current mean train loss 1751.3048753004807
INFO:root:current train perplexity3.970705032348633
INFO:root:current mean train loss 1752.1035960804331
INFO:root:current train perplexity3.975409984588623
INFO:root:current mean train loss 1754.007932775161
INFO:root:current train perplexity3.97603702545166
INFO:root:current mean train loss 1752.6895929772083
INFO:root:current train perplexity3.9764068126678467
INFO:root:current mean train loss 1752.6734554893092
INFO:root:current train perplexity3.978559970855713
INFO:root:current mean train loss 1752.1285188319318
INFO:root:current train perplexity3.9818923473358154
INFO:root:current mean train loss 1755.6762992934425
INFO:root:current train perplexity3.987501621246338
INFO:root:current mean train loss 1756.245084250026
INFO:root:current train perplexity3.990021228790283
INFO:root:current mean train loss 1756.622314937531
INFO:root:current train perplexity3.988722562789917
INFO:root:current mean train loss 1754.768365302241
INFO:root:current train perplexity3.987267255783081
INFO:root:current mean train loss 1753.7762801820868
INFO:root:current train perplexity3.984942674636841
INFO:root:current mean train loss 1754.124011865085
INFO:root:current train perplexity3.98604679107666
INFO:root:current mean train loss 1755.1352083899758
INFO:root:current train perplexity3.990090847015381
INFO:root:current mean train loss 1755.1849359567982
INFO:root:current train perplexity3.9900197982788086
INFO:root:current mean train loss 1754.6882721250922
INFO:root:current train perplexity3.9902782440185547
INFO:root:current mean train loss 1756.1790152556443
INFO:root:current train perplexity3.9919281005859375
INFO:root:current mean train loss 1755.913427234751
INFO:root:current train perplexity3.9919610023498535
INFO:root:current mean train loss 1755.435416103659
INFO:root:current train perplexity3.99188494682312

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.99s/it]
INFO:root:final mean train loss: 1755.9241436118136
INFO:root:final train perplexity: 3.9941368103027344
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.62s/it]
INFO:root:eval mean loss: 2874.6927369263794
INFO:root:eval perplexity: 10.579255104064941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/78
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [8:09:38<2:16:15, 371.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1757.6669677734376
INFO:root:current train perplexity4.017803192138672
INFO:root:current mean train loss 1739.638755859375
INFO:root:current train perplexity3.9568655490875244
INFO:root:current mean train loss 1750.376689453125
INFO:root:current train perplexity3.9902453422546387
INFO:root:current mean train loss 1747.0560081129809
INFO:root:current train perplexity3.988239049911499
INFO:root:current mean train loss 1751.3521357996324
INFO:root:current train perplexity3.989640712738037
INFO:root:current mean train loss 1751.2519501023066
INFO:root:current train perplexity3.9883873462677
INFO:root:current mean train loss 1752.3003595703126
INFO:root:current train perplexity3.9859864711761475
INFO:root:current mean train loss 1752.4003350619612
INFO:root:current train perplexity3.9833431243896484
INFO:root:current mean train loss 1751.8155283794981
INFO:root:current train perplexity3.9849209785461426
INFO:root:current mean train loss 1750.2030221970017
INFO:root:current train perplexity3.9831252098083496
INFO:root:current mean train loss 1749.6001426733994
INFO:root:current train perplexity3.9828643798828125
INFO:root:current mean train loss 1751.3840182291667
INFO:root:current train perplexity3.9844372272491455
INFO:root:current mean train loss 1751.8743065409758
INFO:root:current train perplexity3.9854254722595215
INFO:root:current mean train loss 1753.0939676076061
INFO:root:current train perplexity3.986450433731079
INFO:root:current mean train loss 1752.248605314556
INFO:root:current train perplexity3.9839742183685303
INFO:root:current mean train loss 1752.6413757524333
INFO:root:current train perplexity3.9848976135253906
INFO:root:current mean train loss 1752.7945868389422
INFO:root:current train perplexity3.983578681945801
INFO:root:current mean train loss 1753.8546773097826
INFO:root:current train perplexity3.9845945835113525
INFO:root:current mean train loss 1753.903269277076
INFO:root:current train perplexity3.988546133041382
INFO:root:current mean train loss 1754.485649223823
INFO:root:current train perplexity3.988985061645508

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.57s/it]
INFO:root:final mean train loss: 1754.3314779015184
INFO:root:final train perplexity: 3.9891223907470703
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.18s/it]
INFO:root:eval mean loss: 2874.82849231067
INFO:root:eval perplexity: 10.580435752868652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/79
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [8:15:48<2:09:52, 371.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1754.7173723493304
INFO:root:current train perplexity3.96797776222229
INFO:root:current mean train loss 1750.5010221239547
INFO:root:current train perplexity3.977797746658325
INFO:root:current mean train loss 1747.8770186999614
INFO:root:current train perplexity3.970447540283203
INFO:root:current mean train loss 1754.2265996207968
INFO:root:current train perplexity3.980008602142334
INFO:root:current mean train loss 1752.608112317944
INFO:root:current train perplexity3.9715492725372314
INFO:root:current mean train loss 1754.0351094038283
INFO:root:current train perplexity3.9742543697357178
INFO:root:current mean train loss 1754.0936199437792
INFO:root:current train perplexity3.9729995727539062
INFO:root:current mean train loss 1753.5780891356765
INFO:root:current train perplexity3.97702693939209
INFO:root:current mean train loss 1754.6409698993746
INFO:root:current train perplexity3.9836266040802
INFO:root:current mean train loss 1755.7126068309615
INFO:root:current train perplexity3.9870429039001465
INFO:root:current mean train loss 1754.4664194176614
INFO:root:current train perplexity3.986454963684082
INFO:root:current mean train loss 1753.1922079376916
INFO:root:current train perplexity3.9839742183685303
INFO:root:current mean train loss 1754.09651574766
INFO:root:current train perplexity3.9849038124084473
INFO:root:current mean train loss 1753.716111025405
INFO:root:current train perplexity3.985448122024536
INFO:root:current mean train loss 1753.6490046782897
INFO:root:current train perplexity3.98410964012146
INFO:root:current mean train loss 1753.7756543190408
INFO:root:current train perplexity3.984485387802124
INFO:root:current mean train loss 1754.8987486975202
INFO:root:current train perplexity3.98716139793396
INFO:root:current mean train loss 1754.3480623335022
INFO:root:current train perplexity3.9870235919952393
INFO:root:current mean train loss 1753.0966904233255
INFO:root:current train perplexity3.986311197280884
INFO:root:current mean train loss 1753.07801631845
INFO:root:current train perplexity3.985443353652954

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.05s/it]
INFO:root:final mean train loss: 1752.7190406479983
INFO:root:final train perplexity: 3.984053611755371
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.64s/it]
INFO:root:eval mean loss: 2875.8683803432336
INFO:root:eval perplexity: 10.589468002319336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/80
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [8:21:57<2:03:32, 370.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1735.8741206799523
INFO:root:current train perplexity3.992582082748413
INFO:root:current mean train loss 1753.8871087608097
INFO:root:current train perplexity3.993227005004883
INFO:root:current mean train loss 1745.6578986561897
INFO:root:current train perplexity3.9704220294952393
INFO:root:current mean train loss 1742.8633397349408
INFO:root:current train perplexity3.966564416885376
INFO:root:current mean train loss 1744.3148746532033
INFO:root:current train perplexity3.9656178951263428
INFO:root:current mean train loss 1744.5859285467213
INFO:root:current train perplexity3.96075701713562
INFO:root:current mean train loss 1745.640244155444
INFO:root:current train perplexity3.959540843963623
INFO:root:current mean train loss 1747.0815210958087
INFO:root:current train perplexity3.964555501937866
INFO:root:current mean train loss 1747.8766400622544
INFO:root:current train perplexity3.9688518047332764
INFO:root:current mean train loss 1747.4360996918583
INFO:root:current train perplexity3.9704196453094482
INFO:root:current mean train loss 1747.1267904798528
INFO:root:current train perplexity3.970447540283203
INFO:root:current mean train loss 1748.6512630222376
INFO:root:current train perplexity3.9713149070739746
INFO:root:current mean train loss 1750.2192711500634
INFO:root:current train perplexity3.9753341674804688
INFO:root:current mean train loss 1750.4568235777685
INFO:root:current train perplexity3.9778618812561035
INFO:root:current mean train loss 1750.6855119858153
INFO:root:current train perplexity3.9788830280303955
INFO:root:current mean train loss 1750.9880351518652
INFO:root:current train perplexity3.978544235229492
INFO:root:current mean train loss 1751.2834602894015
INFO:root:current train perplexity3.980095148086548
INFO:root:current mean train loss 1751.1130595247878
INFO:root:current train perplexity3.979421377182007
INFO:root:current mean train loss 1751.1035650703714
INFO:root:current train perplexity3.9785916805267334
INFO:root:current mean train loss 1751.4035012681852
INFO:root:current train perplexity3.9794914722442627

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.57s/it]
INFO:root:final mean train loss: 1751.4052019681944
INFO:root:final train perplexity: 3.9799270629882812
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.58s/it]
INFO:root:eval mean loss: 2877.0468669352945
INFO:root:eval perplexity: 10.599710464477539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/81
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [8:28:16<1:58:05, 372.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1758.1016412032277
INFO:root:current train perplexity4.0292768478393555
INFO:root:current mean train loss 1759.4978665438566
INFO:root:current train perplexity4.0044708251953125
INFO:root:current mean train loss 1758.7880713421366
INFO:root:current train perplexity3.9925031661987305
INFO:root:current mean train loss 1751.6376131747631
INFO:root:current train perplexity3.976025342941284
INFO:root:current mean train loss 1750.3638641613873
INFO:root:current train perplexity3.9754347801208496
INFO:root:current mean train loss 1750.225238588121
INFO:root:current train perplexity3.9732789993286133
INFO:root:current mean train loss 1749.551512227256
INFO:root:current train perplexity3.9710259437561035
INFO:root:current mean train loss 1748.5162351942554
INFO:root:current train perplexity3.972050666809082
INFO:root:current mean train loss 1750.4319039958798
INFO:root:current train perplexity3.9690909385681152
INFO:root:current mean train loss 1750.8058289074506
INFO:root:current train perplexity3.970447063446045
INFO:root:current mean train loss 1748.5153318497328
INFO:root:current train perplexity3.9684407711029053
INFO:root:current mean train loss 1748.0866285051618
INFO:root:current train perplexity3.969944953918457
INFO:root:current mean train loss 1749.6872160621572
INFO:root:current train perplexity3.9721500873565674
INFO:root:current mean train loss 1750.2982339193654
INFO:root:current train perplexity3.972034454345703
INFO:root:current mean train loss 1750.3117383010988
INFO:root:current train perplexity3.9697864055633545
INFO:root:current mean train loss 1750.5307582332398
INFO:root:current train perplexity3.9705991744995117
INFO:root:current mean train loss 1751.4431427657462
INFO:root:current train perplexity3.9722015857696533
INFO:root:current mean train loss 1750.510164621714
INFO:root:current train perplexity3.9722630977630615
INFO:root:current mean train loss 1749.9209261570911
INFO:root:current train perplexity3.9732401371002197
INFO:root:current mean train loss 1749.8068363328694
INFO:root:current train perplexity3.973191499710083

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.07s/it]
INFO:root:final mean train loss: 1749.094061270063
INFO:root:final train perplexity: 3.972679853439331
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.05s/it]
INFO:root:eval mean loss: 2876.3367593667886
INFO:root:eval perplexity: 10.593539237976074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/82
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [8:34:27<1:51:42, 372.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1750.1044423093078
INFO:root:current train perplexity3.970759630203247
INFO:root:current mean train loss 1759.797238680983
INFO:root:current train perplexity3.978529214859009
INFO:root:current mean train loss 1745.6972110474883
INFO:root:current train perplexity3.964845657348633
INFO:root:current mean train loss 1745.7083709173228
INFO:root:current train perplexity3.9649949073791504
INFO:root:current mean train loss 1744.8568796153968
INFO:root:current train perplexity3.960723876953125
INFO:root:current mean train loss 1743.177997659873
INFO:root:current train perplexity3.961223602294922
INFO:root:current mean train loss 1744.6254037303843
INFO:root:current train perplexity3.9668657779693604
INFO:root:current mean train loss 1744.3299437399019
INFO:root:current train perplexity3.967921495437622
INFO:root:current mean train loss 1745.278814335019
INFO:root:current train perplexity3.9725890159606934
INFO:root:current mean train loss 1746.8775583134677
INFO:root:current train perplexity3.9738991260528564
INFO:root:current mean train loss 1746.6469603710402
INFO:root:current train perplexity3.972635269165039
INFO:root:current mean train loss 1745.7404683857333
INFO:root:current train perplexity3.9700021743774414
INFO:root:current mean train loss 1745.7889113518404
INFO:root:current train perplexity3.9694623947143555
INFO:root:current mean train loss 1746.4061226718134
INFO:root:current train perplexity3.9679269790649414
INFO:root:current mean train loss 1746.3170398219033
INFO:root:current train perplexity3.9668028354644775
INFO:root:current mean train loss 1747.3066720429713
INFO:root:current train perplexity3.9680590629577637
INFO:root:current mean train loss 1747.7718564262773
INFO:root:current train perplexity3.9680802822113037
INFO:root:current mean train loss 1747.571224929631
INFO:root:current train perplexity3.9688618183135986
INFO:root:current mean train loss 1748.0905632748531
INFO:root:current train perplexity3.967789888381958

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.63s/it]
INFO:root:final mean train loss: 1747.0855426028468
INFO:root:final train perplexity: 3.9663915634155273
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.29s/it]
INFO:root:eval mean loss: 2877.035052141986
INFO:root:eval perplexity: 10.599609375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/83
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [8:40:38<1:45:22, 371.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1766.6321533203125
INFO:root:current train perplexity3.9606881141662598
INFO:root:current mean train loss 1746.4110695578836
INFO:root:current train perplexity3.9442102909088135
INFO:root:current mean train loss 1750.271696544829
INFO:root:current train perplexity3.951200246810913
INFO:root:current mean train loss 1749.2185164913055
INFO:root:current train perplexity3.958048105239868
INFO:root:current mean train loss 1743.6941346703506
INFO:root:current train perplexity3.954206943511963
INFO:root:current mean train loss 1742.7610004499847
INFO:root:current train perplexity3.960891008377075
INFO:root:current mean train loss 1743.8982015641009
INFO:root:current train perplexity3.965660572052002
INFO:root:current mean train loss 1742.799345634353
INFO:root:current train perplexity3.96392560005188
INFO:root:current mean train loss 1743.285677836854
INFO:root:current train perplexity3.9622511863708496
INFO:root:current mean train loss 1743.7442652440334
INFO:root:current train perplexity3.9603004455566406
INFO:root:current mean train loss 1743.3471141852956
INFO:root:current train perplexity3.9575998783111572
INFO:root:current mean train loss 1743.9893206072284
INFO:root:current train perplexity3.960761308670044
INFO:root:current mean train loss 1744.9563225359957
INFO:root:current train perplexity3.9628708362579346
INFO:root:current mean train loss 1745.9641300579974
INFO:root:current train perplexity3.9634175300598145
INFO:root:current mean train loss 1745.471105783882
INFO:root:current train perplexity3.9638569355010986
INFO:root:current mean train loss 1746.4730998260295
INFO:root:current train perplexity3.9646546840667725
INFO:root:current mean train loss 1746.4273040961034
INFO:root:current train perplexity3.963407516479492
INFO:root:current mean train loss 1746.2348808422423
INFO:root:current train perplexity3.9627177715301514
INFO:root:current mean train loss 1745.1486728057018
INFO:root:current train perplexity3.9627609252929688
INFO:root:current mean train loss 1745.986508929667
INFO:root:current train perplexity3.9625136852264404

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.94s/it]
INFO:root:final mean train loss: 1745.5977350139763
INFO:root:final train perplexity: 3.961740016937256
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.98s/it]
INFO:root:eval mean loss: 2879.2567802177177
INFO:root:eval perplexity: 10.618949890136719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/84
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [8:46:49<1:39:06, 371.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1725.4288556134259
INFO:root:current train perplexity3.9394469261169434
INFO:root:current mean train loss 1730.3440498892717
INFO:root:current train perplexity3.945099115371704
INFO:root:current mean train loss 1738.2865226846434
INFO:root:current train perplexity3.957738161087036
INFO:root:current mean train loss 1741.1752537718608
INFO:root:current train perplexity3.953608274459839
INFO:root:current mean train loss 1741.1643495224678
INFO:root:current train perplexity3.948218822479248
INFO:root:current mean train loss 1740.0476449463354
INFO:root:current train perplexity3.9518659114837646
INFO:root:current mean train loss 1740.1646366393168
INFO:root:current train perplexity3.9550907611846924
INFO:root:current mean train loss 1740.377065960282
INFO:root:current train perplexity3.9550881385803223
INFO:root:current mean train loss 1740.3152730773409
INFO:root:current train perplexity3.9542064666748047
INFO:root:current mean train loss 1742.0084098149273
INFO:root:current train perplexity3.955435037612915
INFO:root:current mean train loss 1742.1122847188412
INFO:root:current train perplexity3.954376697540283
INFO:root:current mean train loss 1743.5950901738922
INFO:root:current train perplexity3.956481456756592
INFO:root:current mean train loss 1744.267077507386
INFO:root:current train perplexity3.956735849380493
INFO:root:current mean train loss 1744.6873766418319
INFO:root:current train perplexity3.9580929279327393
INFO:root:current mean train loss 1745.6868792976961
INFO:root:current train perplexity3.958852767944336
INFO:root:current mean train loss 1746.141808050789
INFO:root:current train perplexity3.9587182998657227
INFO:root:current mean train loss 1746.2815962535294
INFO:root:current train perplexity3.958995819091797
INFO:root:current mean train loss 1746.1415767526103
INFO:root:current train perplexity3.95992374420166
INFO:root:current mean train loss 1745.346621892853
INFO:root:current train perplexity3.9591336250305176
INFO:root:current mean train loss 1744.9998638665793
INFO:root:current train perplexity3.9587862491607666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.89s/it]
INFO:root:final mean train loss: 1744.9395580512974
INFO:root:final train perplexity: 3.959683895111084
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.90s/it]
INFO:root:eval mean loss: 2877.840312969219
INFO:root:eval perplexity: 10.60661506652832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/85
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [8:53:02<1:33:04, 372.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1716.9544955166903
INFO:root:current train perplexity3.9456565380096436
INFO:root:current mean train loss 1718.868805779351
INFO:root:current train perplexity3.9509568214416504
INFO:root:current mean train loss 1734.8979827380572
INFO:root:current train perplexity3.9637293815612793
INFO:root:current mean train loss 1735.967103825059
INFO:root:current train perplexity3.9508800506591797
INFO:root:current mean train loss 1739.0929697397594
INFO:root:current train perplexity3.954678773880005
INFO:root:current mean train loss 1742.6045626472023
INFO:root:current train perplexity3.9558637142181396
INFO:root:current mean train loss 1745.4933750318444
INFO:root:current train perplexity3.953796863555908
INFO:root:current mean train loss 1743.6312270625945
INFO:root:current train perplexity3.9509434700012207
INFO:root:current mean train loss 1745.6145592278215
INFO:root:current train perplexity3.954315423965454
INFO:root:current mean train loss 1744.0230913323871
INFO:root:current train perplexity3.952200412750244
INFO:root:current mean train loss 1743.1694637605513
INFO:root:current train perplexity3.9561495780944824
INFO:root:current mean train loss 1743.096594963874
INFO:root:current train perplexity3.9542200565338135
INFO:root:current mean train loss 1742.88646332474
INFO:root:current train perplexity3.9538490772247314
INFO:root:current mean train loss 1741.8780226934523
INFO:root:current train perplexity3.953450918197632
INFO:root:current mean train loss 1742.7695738562586
INFO:root:current train perplexity3.9544496536254883
INFO:root:current mean train loss 1742.938610333853
INFO:root:current train perplexity3.9539778232574463
INFO:root:current mean train loss 1743.5185736217638
INFO:root:current train perplexity3.954336643218994
INFO:root:current mean train loss 1743.6567309318332
INFO:root:current train perplexity3.953436851501465
INFO:root:current mean train loss 1743.964085709247
INFO:root:current train perplexity3.9549193382263184
INFO:root:current mean train loss 1744.1402402022247
INFO:root:current train perplexity3.9540722370147705

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.15s/it]
INFO:root:final mean train loss: 1743.1936456523517
INFO:root:final train perplexity: 3.954235792160034
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.34s/it]
INFO:root:eval mean loss: 2880.254096870308
INFO:root:eval perplexity: 10.627645492553711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/86
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [8:59:14<1:26:48, 372.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1735.0754414542776
INFO:root:current train perplexity3.9279136657714844
INFO:root:current mean train loss 1723.5484490246506
INFO:root:current train perplexity3.9275548458099365
INFO:root:current mean train loss 1728.0064996595127
INFO:root:current train perplexity3.9263546466827393
INFO:root:current mean train loss 1732.5680651889284
INFO:root:current train perplexity3.934678077697754
INFO:root:current mean train loss 1733.3987796146284
INFO:root:current train perplexity3.94238543510437
INFO:root:current mean train loss 1734.2882700221423
INFO:root:current train perplexity3.947551965713501
INFO:root:current mean train loss 1734.8096427051814
INFO:root:current train perplexity3.945638656616211
INFO:root:current mean train loss 1735.523531498953
INFO:root:current train perplexity3.9454593658447266
INFO:root:current mean train loss 1737.2947046720747
INFO:root:current train perplexity3.946880578994751
INFO:root:current mean train loss 1737.6921119967808
INFO:root:current train perplexity3.9448540210723877
INFO:root:current mean train loss 1739.0506228232136
INFO:root:current train perplexity3.9491493701934814
INFO:root:current mean train loss 1739.9971094254684
INFO:root:current train perplexity3.9483699798583984
INFO:root:current mean train loss 1739.6144079560802
INFO:root:current train perplexity3.945728302001953
INFO:root:current mean train loss 1740.078251375511
INFO:root:current train perplexity3.9470112323760986
INFO:root:current mean train loss 1741.1725338120561
INFO:root:current train perplexity3.951465368270874
INFO:root:current mean train loss 1741.3557709150784
INFO:root:current train perplexity3.9502804279327393
INFO:root:current mean train loss 1741.0855856935063
INFO:root:current train perplexity3.9484329223632812
INFO:root:current mean train loss 1741.2668186688138
INFO:root:current train perplexity3.9487063884735107
INFO:root:current mean train loss 1741.6897823409583
INFO:root:current train perplexity3.9484994411468506
INFO:root:current mean train loss 1742.1998279810803
INFO:root:current train perplexity3.9497251510620117

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.68s/it]
INFO:root:final mean train loss: 1741.655462237121
INFO:root:final train perplexity: 3.949441909790039
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.22s/it]
INFO:root:eval mean loss: 2880.08899402332
INFO:root:eval perplexity: 10.626206398010254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/87
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [9:05:25<1:20:31, 371.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1743.920901567508
INFO:root:current train perplexity3.951172351837158
INFO:root:current mean train loss 1743.8932337385884
INFO:root:current train perplexity3.934656858444214
INFO:root:current mean train loss 1745.9973570460038
INFO:root:current train perplexity3.9378068447113037
INFO:root:current mean train loss 1747.1757560608878
INFO:root:current train perplexity3.9468274116516113
INFO:root:current mean train loss 1747.4603457909748
INFO:root:current train perplexity3.9482767581939697
INFO:root:current mean train loss 1746.1052398153654
INFO:root:current train perplexity3.94978928565979
INFO:root:current mean train loss 1744.463592079185
INFO:root:current train perplexity3.9475901126861572
INFO:root:current mean train loss 1741.3795639861826
INFO:root:current train perplexity3.9445865154266357
INFO:root:current mean train loss 1740.1561815961347
INFO:root:current train perplexity3.9418041706085205
INFO:root:current mean train loss 1738.8220432024061
INFO:root:current train perplexity3.9398629665374756
INFO:root:current mean train loss 1739.4887914993767
INFO:root:current train perplexity3.939833402633667
INFO:root:current mean train loss 1739.7795221558654
INFO:root:current train perplexity3.937242269515991
INFO:root:current mean train loss 1740.0680680491369
INFO:root:current train perplexity3.9374303817749023
INFO:root:current mean train loss 1739.039339328539
INFO:root:current train perplexity3.9380016326904297
INFO:root:current mean train loss 1739.7321476710504
INFO:root:current train perplexity3.9417576789855957
INFO:root:current mean train loss 1740.2112239552391
INFO:root:current train perplexity3.9425740242004395
INFO:root:current mean train loss 1741.3990924457828
INFO:root:current train perplexity3.945496082305908
INFO:root:current mean train loss 1740.8613918377391
INFO:root:current train perplexity3.9459829330444336
INFO:root:current mean train loss 1740.9927762715072
INFO:root:current train perplexity3.9464259147644043
INFO:root:current mean train loss 1741.1544540605844
INFO:root:current train perplexity3.946622133255005

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.48s/it]
INFO:root:final mean train loss: 1740.69847226203
INFO:root:final train perplexity: 3.9464621543884277
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.17s/it]
INFO:root:eval mean loss: 2881.650581245308
INFO:root:eval perplexity: 10.639829635620117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/88
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [9:11:35<1:14:16, 371.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1756.5072522615133
INFO:root:current train perplexity3.9677038192749023
INFO:root:current mean train loss 1748.55782815004
INFO:root:current train perplexity3.946290969848633
INFO:root:current mean train loss 1743.9006852489406
INFO:root:current train perplexity3.9430429935455322
INFO:root:current mean train loss 1739.2744585640824
INFO:root:current train perplexity3.9351747035980225
INFO:root:current mean train loss 1738.8194049873737
INFO:root:current train perplexity3.931960344314575
INFO:root:current mean train loss 1737.079738379727
INFO:root:current train perplexity3.92863392829895
INFO:root:current mean train loss 1738.5239470337792
INFO:root:current train perplexity3.9373319149017334
INFO:root:current mean train loss 1740.9336812721108
INFO:root:current train perplexity3.941391706466675
INFO:root:current mean train loss 1740.9594033694134
INFO:root:current train perplexity3.945283889770508
INFO:root:current mean train loss 1740.1777760874686
INFO:root:current train perplexity3.9424803256988525
INFO:root:current mean train loss 1740.8559582575272
INFO:root:current train perplexity3.943345308303833
INFO:root:current mean train loss 1739.8566391948875
INFO:root:current train perplexity3.9404680728912354
INFO:root:current mean train loss 1739.7791869645873
INFO:root:current train perplexity3.940034866333008
INFO:root:current mean train loss 1738.1914267263105
INFO:root:current train perplexity3.940070629119873
INFO:root:current mean train loss 1738.8465703549593
INFO:root:current train perplexity3.937922954559326
INFO:root:current mean train loss 1738.4467234644396
INFO:root:current train perplexity3.9374191761016846
INFO:root:current mean train loss 1738.941913615989
INFO:root:current train perplexity3.9394595623016357
INFO:root:current mean train loss 1739.6410685334697
INFO:root:current train perplexity3.9428560733795166
INFO:root:current mean train loss 1739.8557777585959
INFO:root:current train perplexity3.942969799041748

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.95s/it]
INFO:root:final mean train loss: 1739.4524528745803
INFO:root:final train perplexity: 3.9425861835479736
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.68s/it]
INFO:root:eval mean loss: 2881.3487244568787
INFO:root:eval perplexity: 10.63719654083252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/89
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [9:17:54<1:08:29, 373.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1718.09521484375
INFO:root:current train perplexity3.891538619995117
INFO:root:current mean train loss 1744.5581316266741
INFO:root:current train perplexity3.946229934692383
INFO:root:current mean train loss 1736.4829706156029
INFO:root:current train perplexity3.9372026920318604
INFO:root:current mean train loss 1734.8979241786858
INFO:root:current train perplexity3.9361815452575684
INFO:root:current mean train loss 1736.881556242415
INFO:root:current train perplexity3.9408650398254395
INFO:root:current mean train loss 1735.0316627025604
INFO:root:current train perplexity3.9349143505096436
INFO:root:current mean train loss 1733.0545979418787
INFO:root:current train perplexity3.9321088790893555
INFO:root:current mean train loss 1732.5437126588286
INFO:root:current train perplexity3.930232524871826
INFO:root:current mean train loss 1732.4429010099966
INFO:root:current train perplexity3.9270660877227783
INFO:root:current mean train loss 1732.4721287509851
INFO:root:current train perplexity3.9266438484191895
INFO:root:current mean train loss 1733.9351940531976
INFO:root:current train perplexity3.9277076721191406
INFO:root:current mean train loss 1734.0950557791073
INFO:root:current train perplexity3.930880069732666
INFO:root:current mean train loss 1734.3510761323935
INFO:root:current train perplexity3.9326236248016357
INFO:root:current mean train loss 1735.8848489900915
INFO:root:current train perplexity3.932657480239868
INFO:root:current mean train loss 1737.003113311681
INFO:root:current train perplexity3.933058261871338
INFO:root:current mean train loss 1736.803242274693
INFO:root:current train perplexity3.9327094554901123
INFO:root:current mean train loss 1736.0245627883646
INFO:root:current train perplexity3.9325079917907715
INFO:root:current mean train loss 1736.6025792059497
INFO:root:current train perplexity3.934457540512085
INFO:root:current mean train loss 1736.8761943623456
INFO:root:current train perplexity3.9348104000091553
INFO:root:current mean train loss 1738.0761880276093
INFO:root:current train perplexity3.9372267723083496

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.36s/it]
INFO:root:final mean train loss: 1737.947950031321
INFO:root:final train perplexity: 3.937910556793213
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.83s/it]
INFO:root:eval mean loss: 2881.474832254129
INFO:root:eval perplexity: 10.638298034667969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/90
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [9:24:13<1:02:32, 375.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1716.397183122306
INFO:root:current train perplexity3.957538604736328
INFO:root:current mean train loss 1726.8161990143533
INFO:root:current train perplexity3.909270763397217
INFO:root:current mean train loss 1736.350433482874
INFO:root:current train perplexity3.9197797775268555
INFO:root:current mean train loss 1739.1617082868304
INFO:root:current train perplexity3.9257326126098633
INFO:root:current mean train loss 1743.25866158581
INFO:root:current train perplexity3.9282033443450928
INFO:root:current mean train loss 1740.9222075204543
INFO:root:current train perplexity3.929368734359741
INFO:root:current mean train loss 1741.8277120180842
INFO:root:current train perplexity3.9344210624694824
INFO:root:current mean train loss 1741.4333291805983
INFO:root:current train perplexity3.929391622543335
INFO:root:current mean train loss 1741.6803903246098
INFO:root:current train perplexity3.93204665184021
INFO:root:current mean train loss 1740.000035740716
INFO:root:current train perplexity3.9312245845794678
INFO:root:current mean train loss 1740.3376133865934
INFO:root:current train perplexity3.9326012134552
INFO:root:current mean train loss 1737.9414014926097
INFO:root:current train perplexity3.9301300048828125
INFO:root:current mean train loss 1738.2452995480319
INFO:root:current train perplexity3.931450366973877
INFO:root:current mean train loss 1737.4850828057397
INFO:root:current train perplexity3.932788610458374
INFO:root:current mean train loss 1736.7178960203541
INFO:root:current train perplexity3.9338178634643555
INFO:root:current mean train loss 1736.9032777595396
INFO:root:current train perplexity3.934854030609131
INFO:root:current mean train loss 1736.510342705096
INFO:root:current train perplexity3.9334030151367188
INFO:root:current mean train loss 1737.0612935584152
INFO:root:current train perplexity3.9349875450134277
INFO:root:current mean train loss 1738.0032111366568
INFO:root:current train perplexity3.9359817504882812
INFO:root:current mean train loss 1737.563886311216
INFO:root:current train perplexity3.9347286224365234

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.12s/it]
INFO:root:final mean train loss: 1736.9239244023418
INFO:root:final train perplexity: 3.9347314834594727
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.27s/it]
INFO:root:eval mean loss: 2881.592902472785
INFO:root:eval perplexity: 10.639327049255371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/91
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [9:30:34<56:33, 377.08s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1737.554950216542
INFO:root:current train perplexity3.9520962238311768
INFO:root:current mean train loss 1734.3092567757385
INFO:root:current train perplexity3.934540033340454
INFO:root:current mean train loss 1736.1145783711256
INFO:root:current train perplexity3.9354426860809326
INFO:root:current mean train loss 1733.7929190045836
INFO:root:current train perplexity3.9284043312072754
INFO:root:current mean train loss 1735.1916268524033
INFO:root:current train perplexity3.9358105659484863
INFO:root:current mean train loss 1735.7089018769316
INFO:root:current train perplexity3.936213493347168
INFO:root:current mean train loss 1735.8339993031032
INFO:root:current train perplexity3.9356584548950195
INFO:root:current mean train loss 1733.932451918042
INFO:root:current train perplexity3.9319026470184326
INFO:root:current mean train loss 1733.1245257149915
INFO:root:current train perplexity3.9335529804229736
INFO:root:current mean train loss 1734.0276107304192
INFO:root:current train perplexity3.93369460105896
INFO:root:current mean train loss 1735.9751773637295
INFO:root:current train perplexity3.9373183250427246
INFO:root:current mean train loss 1736.3820193625245
INFO:root:current train perplexity3.937535047531128
INFO:root:current mean train loss 1736.4791472359989
INFO:root:current train perplexity3.934343099594116
INFO:root:current mean train loss 1736.7999440798255
INFO:root:current train perplexity3.936976671218872
INFO:root:current mean train loss 1737.5194569610132
INFO:root:current train perplexity3.9364280700683594
INFO:root:current mean train loss 1737.6958154675876
INFO:root:current train perplexity3.9368574619293213
INFO:root:current mean train loss 1737.1712814831646
INFO:root:current train perplexity3.936328887939453
INFO:root:current mean train loss 1737.2456503537103
INFO:root:current train perplexity3.936464548110962
INFO:root:current mean train loss 1737.1768158058176
INFO:root:current train perplexity3.935455799102783
INFO:root:current mean train loss 1736.9811186834572
INFO:root:current train perplexity3.934325695037842

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.83s/it]
INFO:root:final mean train loss: 1736.754023487978
INFO:root:final train perplexity: 3.934204339981079
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.80s/it]
INFO:root:eval mean loss: 2882.75097949512
INFO:root:eval perplexity: 10.649442672729492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/92
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [9:36:52<50:17, 377.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1727.1558469742063
INFO:root:current train perplexity3.903027057647705
INFO:root:current mean train loss 1730.339196702454
INFO:root:current train perplexity3.895510196685791
INFO:root:current mean train loss 1731.020196834898
INFO:root:current train perplexity3.9167263507843018
INFO:root:current mean train loss 1729.1548867133695
INFO:root:current train perplexity3.9198572635650635
INFO:root:current mean train loss 1735.107680516418
INFO:root:current train perplexity3.9275765419006348
INFO:root:current mean train loss 1736.0358316479103
INFO:root:current train perplexity3.9300994873046875
INFO:root:current mean train loss 1736.729047542244
INFO:root:current train perplexity3.9311766624450684
INFO:root:current mean train loss 1738.4458492574029
INFO:root:current train perplexity3.9297592639923096
INFO:root:current mean train loss 1738.931804422708
INFO:root:current train perplexity3.935119867324829
INFO:root:current mean train loss 1739.037205079139
INFO:root:current train perplexity3.9357547760009766
INFO:root:current mean train loss 1739.2778935831668
INFO:root:current train perplexity3.9368672370910645
INFO:root:current mean train loss 1737.605468015269
INFO:root:current train perplexity3.933309555053711
INFO:root:current mean train loss 1736.5224800744136
INFO:root:current train perplexity3.93026065826416
INFO:root:current mean train loss 1736.12300925979
INFO:root:current train perplexity3.9277656078338623
INFO:root:current mean train loss 1735.278845556941
INFO:root:current train perplexity3.9282591342926025
INFO:root:current mean train loss 1735.7723353526872
INFO:root:current train perplexity3.930009126663208
INFO:root:current mean train loss 1735.3946117004284
INFO:root:current train perplexity3.928351402282715
INFO:root:current mean train loss 1734.9873521169748
INFO:root:current train perplexity3.927579164505005
INFO:root:current mean train loss 1734.6289441225929
INFO:root:current train perplexity3.926093578338623
INFO:root:current mean train loss 1735.5310584061983
INFO:root:current train perplexity3.9284043312072754

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.79s/it]
INFO:root:final mean train loss: 1734.951221090943
INFO:root:final train perplexity: 3.928614616394043
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.01s/it]
INFO:root:eval mean loss: 2882.8969250011733
INFO:root:eval perplexity: 10.650717735290527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/93
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [9:43:04<43:49, 375.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1720.9415267944337
INFO:root:current train perplexity3.912020444869995
INFO:root:current mean train loss 1731.3094631618924
INFO:root:current train perplexity3.9104061126708984
INFO:root:current mean train loss 1735.45339617048
INFO:root:current train perplexity3.913928747177124
INFO:root:current mean train loss 1734.5616920872737
INFO:root:current train perplexity3.9270389080047607
INFO:root:current mean train loss 1733.891753133138
INFO:root:current train perplexity3.9257054328918457
INFO:root:current mean train loss 1734.0291821709995
INFO:root:current train perplexity3.9271938800811768
INFO:root:current mean train loss 1733.597902365292
INFO:root:current train perplexity3.925673723220825
INFO:root:current mean train loss 1733.031834372496
INFO:root:current train perplexity3.9262282848358154
INFO:root:current mean train loss 1732.5194396972656
INFO:root:current train perplexity3.9237091541290283
INFO:root:current mean train loss 1732.318102653659
INFO:root:current train perplexity3.9237043857574463
INFO:root:current mean train loss 1732.307886533384
INFO:root:current train perplexity3.9234917163848877
INFO:root:current mean train loss 1731.4690520722988
INFO:root:current train perplexity3.922816276550293
INFO:root:current mean train loss 1732.7531345367431
INFO:root:current train perplexity3.925661087036133
INFO:root:current mean train loss 1733.1024561785268
INFO:root:current train perplexity3.9238078594207764
INFO:root:current mean train loss 1734.6632013269373
INFO:root:current train perplexity3.9252431392669678
INFO:root:current mean train loss 1734.9313039272647
INFO:root:current train perplexity3.925229072570801
INFO:root:current mean train loss 1734.3526318504696
INFO:root:current train perplexity3.9253242015838623
INFO:root:current mean train loss 1734.734878368592
INFO:root:current train perplexity3.9253616333007812
INFO:root:current mean train loss 1734.1543184970287
INFO:root:current train perplexity3.9246513843536377
INFO:root:current mean train loss 1734.2302685053662
INFO:root:current train perplexity3.9250409603118896

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.76s/it]
INFO:root:final mean train loss: 1733.7871104214928
INFO:root:final train perplexity: 3.9250097274780273
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.73s/it]
INFO:root:eval mean loss: 2883.828418995167
INFO:root:eval perplexity: 10.658862113952637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/94
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [9:49:13<37:22, 373.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1736.1598869402385
INFO:root:current train perplexity3.9459640979766846
INFO:root:current mean train loss 1737.4368617643559
INFO:root:current train perplexity3.9430477619171143
INFO:root:current mean train loss 1737.7002692945075
INFO:root:current train perplexity3.9293813705444336
INFO:root:current mean train loss 1737.137907475008
INFO:root:current train perplexity3.9351110458374023
INFO:root:current mean train loss 1737.2575128505407
INFO:root:current train perplexity3.933412790298462
INFO:root:current mean train loss 1738.2934347437056
INFO:root:current train perplexity3.926534414291382
INFO:root:current mean train loss 1737.05411900612
INFO:root:current train perplexity3.922621250152588
INFO:root:current mean train loss 1735.2226488982121
INFO:root:current train perplexity3.923330307006836
INFO:root:current mean train loss 1735.2703025928442
INFO:root:current train perplexity3.921867609024048
INFO:root:current mean train loss 1735.8633048804618
INFO:root:current train perplexity3.925158977508545
INFO:root:current mean train loss 1736.3636671568768
INFO:root:current train perplexity3.9284141063690186
INFO:root:current mean train loss 1735.870135136017
INFO:root:current train perplexity3.9281046390533447
INFO:root:current mean train loss 1736.1898349594317
INFO:root:current train perplexity3.9301295280456543
INFO:root:current mean train loss 1735.5726919536003
INFO:root:current train perplexity3.9267141819000244
INFO:root:current mean train loss 1735.4780623258234
INFO:root:current train perplexity3.927354097366333
INFO:root:current mean train loss 1735.6050309937823
INFO:root:current train perplexity3.927558183670044
INFO:root:current mean train loss 1734.9680756280616
INFO:root:current train perplexity3.9268600940704346
INFO:root:current mean train loss 1734.7686764181622
INFO:root:current train perplexity3.9272782802581787
INFO:root:current mean train loss 1734.9627667529116
INFO:root:current train perplexity3.9282824993133545

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.74s/it]
INFO:root:final mean train loss: 1733.7696706797822
INFO:root:final train perplexity: 3.9249558448791504
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.06s/it]
INFO:root:eval mean loss: 2883.493290165165
INFO:root:eval perplexity: 10.655932426452637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/95
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [9:55:24<31:04, 372.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1708.0113874162946
INFO:root:current train perplexity3.870032548904419
INFO:root:current mean train loss 1725.5361403080456
INFO:root:current train perplexity3.8957364559173584
INFO:root:current mean train loss 1729.7183489933193
INFO:root:current train perplexity3.8940587043762207
INFO:root:current mean train loss 1729.792932206658
INFO:root:current train perplexity3.9009859561920166
INFO:root:current mean train loss 1728.3880818684895
INFO:root:current train perplexity3.8996682167053223
INFO:root:current mean train loss 1729.3384470661326
INFO:root:current train perplexity3.90374493598938
INFO:root:current mean train loss 1730.7349189484935
INFO:root:current train perplexity3.9135119915008545
INFO:root:current mean train loss 1732.7597051027442
INFO:root:current train perplexity3.9133753776550293
INFO:root:current mean train loss 1732.2843771894675
INFO:root:current train perplexity3.9144318103790283
INFO:root:current mean train loss 1732.807190609187
INFO:root:current train perplexity3.9150354862213135
INFO:root:current mean train loss 1732.8554535814997
INFO:root:current train perplexity3.9131925106048584
INFO:root:current mean train loss 1733.6604466327003
INFO:root:current train perplexity3.9148097038269043
INFO:root:current mean train loss 1733.7583150596556
INFO:root:current train perplexity3.916670322418213
INFO:root:current mean train loss 1733.1822663050264
INFO:root:current train perplexity3.9171526432037354
INFO:root:current mean train loss 1733.1993700861087
INFO:root:current train perplexity3.91953444480896
INFO:root:current mean train loss 1734.3929582845267
INFO:root:current train perplexity3.9204256534576416
INFO:root:current mean train loss 1734.359845356427
INFO:root:current train perplexity3.9223978519439697
INFO:root:current mean train loss 1735.0073311270467
INFO:root:current train perplexity3.9234158992767334
INFO:root:current mean train loss 1735.1304672560855
INFO:root:current train perplexity3.9229533672332764
INFO:root:current mean train loss 1735.1089260695246
INFO:root:current train perplexity3.9239673614501953

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.82s/it]
INFO:root:final mean train loss: 1733.4353907628908
INFO:root:final train perplexity: 3.9239211082458496
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.87s/it]
INFO:root:eval mean loss: 2883.925260709929
INFO:root:eval perplexity: 10.659708023071289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/96
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [10:01:35<24:48, 372.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1753.3980673513104
INFO:root:current train perplexity3.9827091693878174
INFO:root:current mean train loss 1741.3189119528267
INFO:root:current train perplexity3.969571590423584
INFO:root:current mean train loss 1738.6935290051745
INFO:root:current train perplexity3.951143741607666
INFO:root:current mean train loss 1736.8753949767513
INFO:root:current train perplexity3.9355082511901855
INFO:root:current mean train loss 1740.114000643489
INFO:root:current train perplexity3.9374332427978516
INFO:root:current mean train loss 1738.6771941391537
INFO:root:current train perplexity3.9330408573150635
INFO:root:current mean train loss 1737.341667453385
INFO:root:current train perplexity3.9276387691497803
INFO:root:current mean train loss 1737.0763268425103
INFO:root:current train perplexity3.9265592098236084
INFO:root:current mean train loss 1736.5044682728828
INFO:root:current train perplexity3.926802158355713
INFO:root:current mean train loss 1734.791138482017
INFO:root:current train perplexity3.9238593578338623
INFO:root:current mean train loss 1733.7175233768792
INFO:root:current train perplexity3.9228925704956055
INFO:root:current mean train loss 1733.4952097925648
INFO:root:current train perplexity3.922123908996582
INFO:root:current mean train loss 1733.7112322140283
INFO:root:current train perplexity3.921755790710449
INFO:root:current mean train loss 1733.6605157658714
INFO:root:current train perplexity3.920983076095581
INFO:root:current mean train loss 1732.2253634641422
INFO:root:current train perplexity3.9209275245666504
INFO:root:current mean train loss 1731.8324421110844
INFO:root:current train perplexity3.921367883682251
INFO:root:current mean train loss 1733.5126649258987
INFO:root:current train perplexity3.924454689025879
INFO:root:current mean train loss 1733.4721648658651
INFO:root:current train perplexity3.922661066055298
INFO:root:current mean train loss 1732.925457573666
INFO:root:current train perplexity3.922287940979004
INFO:root:current mean train loss 1732.949357509366
INFO:root:current train perplexity3.9216039180755615

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.85s/it]
INFO:root:final mean train loss: 1732.4116629226846
INFO:root:final train perplexity: 3.9207546710968018
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.06s/it]
INFO:root:eval mean loss: 2884.3553059895835
INFO:root:eval perplexity: 10.663470268249512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/97
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [10:07:45<18:34, 371.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1730.1337483723958
INFO:root:current train perplexity3.9229319095611572
INFO:root:current mean train loss 1729.0888737858952
INFO:root:current train perplexity3.937692880630493
INFO:root:current mean train loss 1732.8933784730973
INFO:root:current train perplexity3.9413888454437256
INFO:root:current mean train loss 1732.2161507442079
INFO:root:current train perplexity3.929677963256836
INFO:root:current mean train loss 1734.7231181008476
INFO:root:current train perplexity3.9282400608062744
INFO:root:current mean train loss 1736.1275336272524
INFO:root:current train perplexity3.9213602542877197
INFO:root:current mean train loss 1737.5614705026885
INFO:root:current train perplexity3.9226672649383545
INFO:root:current mean train loss 1736.5680878175133
INFO:root:current train perplexity3.9186060428619385
INFO:root:current mean train loss 1734.4847931771908
INFO:root:current train perplexity3.9197394847869873
INFO:root:current mean train loss 1734.4343479333547
INFO:root:current train perplexity3.9199092388153076
INFO:root:current mean train loss 1734.0774205331584
INFO:root:current train perplexity3.92051100730896
INFO:root:current mean train loss 1732.2641977981407
INFO:root:current train perplexity3.92071533203125
INFO:root:current mean train loss 1732.8847673856294
INFO:root:current train perplexity3.919792413711548
INFO:root:current mean train loss 1733.991077547611
INFO:root:current train perplexity3.92098069190979
INFO:root:current mean train loss 1733.6825875129489
INFO:root:current train perplexity3.9210171699523926
INFO:root:current mean train loss 1732.822322244176
INFO:root:current train perplexity3.919044256210327
INFO:root:current mean train loss 1732.9227067521474
INFO:root:current train perplexity3.918302059173584
INFO:root:current mean train loss 1732.713304462913
INFO:root:current train perplexity3.918062925338745
INFO:root:current mean train loss 1732.027650709276
INFO:root:current train perplexity3.918673276901245
INFO:root:current mean train loss 1731.5897821508638
INFO:root:current train perplexity3.918166160583496

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.51s/it]
INFO:root:final mean train loss: 1731.5162915236049
INFO:root:final train perplexity: 3.9179866313934326
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.39s/it]
INFO:root:eval mean loss: 2883.8452229084555
INFO:root:eval perplexity: 10.659008979797363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/98
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [10:13:54<12:22, 371.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1733.2632662259616
INFO:root:current train perplexity3.89017915725708
INFO:root:current mean train loss 1729.2346805456914
INFO:root:current train perplexity3.914915084838867
INFO:root:current mean train loss 1729.2007351857312
INFO:root:current train perplexity3.920165777206421
INFO:root:current mean train loss 1728.5763748796019
INFO:root:current train perplexity3.9206924438476562
INFO:root:current mean train loss 1731.9308588499664
INFO:root:current train perplexity3.922208070755005
INFO:root:current mean train loss 1735.0378601614352
INFO:root:current train perplexity3.919895648956299
INFO:root:current mean train loss 1734.3477594131814
INFO:root:current train perplexity3.9157025814056396
INFO:root:current mean train loss 1735.1487204159007
INFO:root:current train perplexity3.916696071624756
INFO:root:current mean train loss 1735.0421227251175
INFO:root:current train perplexity3.917963743209839
INFO:root:current mean train loss 1734.849974447458
INFO:root:current train perplexity3.9183402061462402
INFO:root:current mean train loss 1733.7713232192634
INFO:root:current train perplexity3.914229154586792
INFO:root:current mean train loss 1733.5644691565517
INFO:root:current train perplexity3.9175355434417725
INFO:root:current mean train loss 1733.6096263779953
INFO:root:current train perplexity3.9182446002960205
INFO:root:current mean train loss 1733.8386793870193
INFO:root:current train perplexity3.9195830821990967
INFO:root:current mean train loss 1732.6108858388438
INFO:root:current train perplexity3.9177799224853516
INFO:root:current mean train loss 1731.9304693740016
INFO:root:current train perplexity3.9165992736816406
INFO:root:current mean train loss 1731.529345849756
INFO:root:current train perplexity3.915156364440918
INFO:root:current mean train loss 1731.8555706251107
INFO:root:current train perplexity3.915452003479004
INFO:root:current mean train loss 1731.3668078056928
INFO:root:current train perplexity3.914774179458618
INFO:root:current mean train loss 1731.6441163973043
INFO:root:current train perplexity3.91634202003479

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.67s/it]
INFO:root:final mean train loss: 1731.134528655929
INFO:root:final train perplexity: 3.9168076515197754
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.37s/it]
INFO:root:eval mean loss: 2884.144427875141
INFO:root:eval perplexity: 10.661624908447266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/99
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [10:20:16<06:14, 374.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1727.3461601443407
INFO:root:current train perplexity3.8762643337249756
INFO:root:current mean train loss 1722.7389680631868
INFO:root:current train perplexity3.8914201259613037
INFO:root:current mean train loss 1726.3173377936614
INFO:root:current train perplexity3.897881031036377
INFO:root:current mean train loss 1727.850836149685
INFO:root:current train perplexity3.8961691856384277
INFO:root:current mean train loss 1728.4838834263971
INFO:root:current train perplexity3.897127866744995
INFO:root:current mean train loss 1728.454548943903
INFO:root:current train perplexity3.903559684753418
INFO:root:current mean train loss 1729.747084094632
INFO:root:current train perplexity3.9071860313415527
INFO:root:current mean train loss 1730.6305952535565
INFO:root:current train perplexity3.909881830215454
INFO:root:current mean train loss 1730.253954829002
INFO:root:current train perplexity3.910107374191284
INFO:root:current mean train loss 1730.671256568427
INFO:root:current train perplexity3.910998821258545
INFO:root:current mean train loss 1730.387552370646
INFO:root:current train perplexity3.910231351852417
INFO:root:current mean train loss 1730.3174639861595
INFO:root:current train perplexity3.909236431121826
INFO:root:current mean train loss 1730.6252091001609
INFO:root:current train perplexity3.9103195667266846
INFO:root:current mean train loss 1730.7403636882689
INFO:root:current train perplexity3.910912036895752
INFO:root:current mean train loss 1732.442261977717
INFO:root:current train perplexity3.9139113426208496
INFO:root:current mean train loss 1730.7247306736924
INFO:root:current train perplexity3.911884307861328
INFO:root:current mean train loss 1729.7198039269192
INFO:root:current train perplexity3.911686420440674
INFO:root:current mean train loss 1729.302195128367
INFO:root:current train perplexity3.9107978343963623
INFO:root:current mean train loss 1730.2405583607656
INFO:root:current train perplexity3.9133477210998535
INFO:root:current mean train loss 1730.914260448529
INFO:root:current train perplexity3.9146664142608643

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.52s/it]
INFO:root:final mean train loss: 1730.4097933016578
INFO:root:final train perplexity: 3.91456937789917
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.01s/it]
INFO:root:eval mean loss: 2884.0945828641143
INFO:root:eval perplexity: 10.661187171936035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: v11/100
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [10:26:27<00:00, 373.17s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [10:26:27<00:00, 375.87s/it]
INFO:root:evaluating final model
INFO:root:start evaluating
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.11s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.11s/it]
INFO:root:eval mean loss: 2884.0945828641143
INFO:root:eval perplexity: 10.661187171936035
INFO:root:evalaution complete
INFO:root:save model final: v11/final
