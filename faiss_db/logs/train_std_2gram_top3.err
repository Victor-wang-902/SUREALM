INFO:root:Output: std_23
INFO:root:Steps per epochs:1983
INFO:root:Total steps:198300
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'cls.predictions.decoder.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.key.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.0.crossattention.self.query.weight', 'cls.predictions.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.value.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.value.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
INFO:root:current mean train loss 12231.203332149622
INFO:root:current train perplexity16608.4453125
INFO:root:current mean train loss 10547.226356391331
INFO:root:current train perplexity4122.18115234375
INFO:root:current mean train loss 9175.120247831313
INFO:root:current train perplexity1385.7415771484375
INFO:root:current mean train loss 8226.713824355811
INFO:root:current train perplexity655.25341796875
INFO:root:current mean train loss 7535.337404790049
INFO:root:current train perplexity380.6205749511719
INFO:root:current mean train loss 7010.469112746505
INFO:root:current train perplexity251.5606689453125
INFO:root:current mean train loss 6600.793044541868
INFO:root:current train perplexity181.5316162109375
INFO:root:current mean train loss 6275.657836761284
INFO:root:current train perplexity140.01988220214844
INFO:root:current mean train loss 5999.233332174638
INFO:root:current train perplexity113.16020965576172
INFO:root:current mean train loss 5775.723600798064
INFO:root:current train perplexity94.38141632080078
INFO:root:current mean train loss 5576.591896619441
INFO:root:current train perplexity80.85367584228516
INFO:root:current mean train loss 5407.4693649330175
INFO:root:current train perplexity70.80115509033203
INFO:root:current mean train loss 5261.160188388604
INFO:root:current train perplexity62.913414001464844
INFO:root:current mean train loss 5125.5069411675195
INFO:root:current train perplexity56.676475524902344
INFO:root:current mean train loss 5007.05802761737
INFO:root:current train perplexity51.696075439453125
INFO:root:current mean train loss 4900.453217678773
INFO:root:current train perplexity47.554229736328125
INFO:root:current mean train loss 4805.01716039881
INFO:root:current train perplexity44.0756721496582
INFO:root:current mean train loss 4716.543334893083
INFO:root:current train perplexity41.15266799926758
INFO:root:current mean train loss 4634.04964411265
INFO:root:current train perplexity38.620384216308594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.43s/it]
INFO:root:final mean train loss: 4570.052088134888
INFO:root:final train perplexity: 36.75292205810547
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.76s/it]
INFO:root:eval mean loss: 3474.4752061631943
INFO:root:eval perplexity: 17.306123733520508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/1
  1%|          | 1/100 [05:17<8:43:54, 317.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3105.1024017333984
INFO:root:current train perplexity11.4913911819458
INFO:root:current mean train loss 3095.433259108971
INFO:root:current train perplexity11.509471893310547
INFO:root:current mean train loss 3077.329429343895
INFO:root:current train perplexity11.444366455078125
INFO:root:current mean train loss 3076.0138959281053
INFO:root:current train perplexity11.424040794372559
INFO:root:current mean train loss 3069.4387506338267
INFO:root:current train perplexity11.33297061920166
INFO:root:current mean train loss 3059.5192979916123
INFO:root:current train perplexity11.194356918334961
INFO:root:current mean train loss 3041.82972420036
INFO:root:current train perplexity11.066102027893066
INFO:root:current mean train loss 3031.123818168427
INFO:root:current train perplexity10.967214584350586
INFO:root:current mean train loss 3022.5207809747435
INFO:root:current train perplexity10.892021179199219
INFO:root:current mean train loss 3016.872167862138
INFO:root:current train perplexity10.818504333496094
INFO:root:current mean train loss 3004.81660857914
INFO:root:current train perplexity10.736268997192383
INFO:root:current mean train loss 2996.6402476320986
INFO:root:current train perplexity10.645967483520508
INFO:root:current mean train loss 2989.625266426488
INFO:root:current train perplexity10.571676254272461
INFO:root:current mean train loss 2980.999938408292
INFO:root:current train perplexity10.492233276367188
INFO:root:current mean train loss 2972.257459737487
INFO:root:current train perplexity10.4226713180542
INFO:root:current mean train loss 2964.386216135956
INFO:root:current train perplexity10.35135269165039
INFO:root:current mean train loss 2955.4277932950768
INFO:root:current train perplexity10.280945777893066
INFO:root:current mean train loss 2947.9176534728294
INFO:root:current train perplexity10.218123435974121
INFO:root:current mean train loss 2938.0519862238007
INFO:root:current train perplexity10.149953842163086
INFO:root:current mean train loss 2930.25092839697
INFO:root:current train perplexity10.080817222595215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.76s/it]
INFO:root:final mean train loss: 2924.6708874801043
INFO:root:final train perplexity: 10.03994083404541
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.98s/it]
INFO:root:eval mean loss: 3225.207551056916
INFO:root:eval perplexity: 14.104843139648438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/2
  2%|â–         | 2/100 [10:38<8:42:13, 319.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2807.4927201704545
INFO:root:current train perplexity9.128631591796875
INFO:root:current mean train loss 2755.03895603266
INFO:root:current train perplexity8.856719017028809
INFO:root:current mean train loss 2753.052893642704
INFO:root:current train perplexity8.822530746459961
INFO:root:current mean train loss 2741.7087805579017
INFO:root:current train perplexity8.75806999206543
INFO:root:current mean train loss 2744.1216045846563
INFO:root:current train perplexity8.722870826721191
INFO:root:current mean train loss 2739.798965081936
INFO:root:current train perplexity8.677950859069824
INFO:root:current mean train loss 2734.983695031719
INFO:root:current train perplexity8.635135650634766
INFO:root:current mean train loss 2728.7275633766412
INFO:root:current train perplexity8.596613883972168
INFO:root:current mean train loss 2724.5470880735106
INFO:root:current train perplexity8.56766128540039
INFO:root:current mean train loss 2718.3894906488645
INFO:root:current train perplexity8.535479545593262
INFO:root:current mean train loss 2713.9111037425128
INFO:root:current train perplexity8.506160736083984
INFO:root:current mean train loss 2709.1757642269554
INFO:root:current train perplexity8.483817100524902
INFO:root:current mean train loss 2703.91494619798
INFO:root:current train perplexity8.45283317565918
INFO:root:current mean train loss 2697.578107966933
INFO:root:current train perplexity8.414628982543945
INFO:root:current mean train loss 2696.6299954272613
INFO:root:current train perplexity8.397451400756836
INFO:root:current mean train loss 2695.6716256039017
INFO:root:current train perplexity8.375325202941895
INFO:root:current mean train loss 2691.5879900454015
INFO:root:current train perplexity8.348461151123047
INFO:root:current mean train loss 2688.140305489938
INFO:root:current train perplexity8.320387840270996
INFO:root:current mean train loss 2684.022562962442
INFO:root:current train perplexity8.289072036743164
INFO:root:current mean train loss 2679.361406431874
INFO:root:current train perplexity8.263589859008789

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.58s/it]
INFO:root:final mean train loss: 2675.467972332699
INFO:root:final train perplexity: 8.248529434204102
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.96s/it]
INFO:root:eval mean loss: 3106.9860267982826
INFO:root:eval perplexity: 12.800811767578125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/3
  3%|â–Ž         | 3/100 [16:00<8:38:35, 320.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2607.700947265625
INFO:root:current train perplexity7.7737812995910645
INFO:root:current mean train loss 2591.883709309896
INFO:root:current train perplexity7.715275287628174
INFO:root:current mean train loss 2584.5079814453125
INFO:root:current train perplexity7.689169883728027
INFO:root:current mean train loss 2577.4219126674107
INFO:root:current train perplexity7.634387016296387
INFO:root:current mean train loss 2581.6712689887154
INFO:root:current train perplexity7.627251625061035
INFO:root:current mean train loss 2574.383386896307
INFO:root:current train perplexity7.591967582702637
INFO:root:current mean train loss 2570.9154067758413
INFO:root:current train perplexity7.577972412109375
INFO:root:current mean train loss 2568.1653515625
INFO:root:current train perplexity7.5645856857299805
INFO:root:current mean train loss 2566.124901194853
INFO:root:current train perplexity7.5619330406188965
INFO:root:current mean train loss 2563.2459914679275
INFO:root:current train perplexity7.54249382019043
INFO:root:current mean train loss 2559.6927155412945
INFO:root:current train perplexity7.522979259490967
INFO:root:current mean train loss 2559.0769592815896
INFO:root:current train perplexity7.514997959136963
INFO:root:current mean train loss 2555.8308392578124
INFO:root:current train perplexity7.500604629516602
INFO:root:current mean train loss 2553.4906545681424
INFO:root:current train perplexity7.485530376434326
INFO:root:current mean train loss 2553.03256894868
INFO:root:current train perplexity7.4808526039123535
INFO:root:current mean train loss 2550.2497619235132
INFO:root:current train perplexity7.467405796051025
INFO:root:current mean train loss 2548.8440562115293
INFO:root:current train perplexity7.457061767578125
INFO:root:current mean train loss 2546.0578221958704
INFO:root:current train perplexity7.439826965332031
INFO:root:current mean train loss 2544.787223989126
INFO:root:current train perplexity7.4322943687438965
INFO:root:current mean train loss 2542.5517061673677
INFO:root:current train perplexity7.421852111816406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.86s/it]
INFO:root:final mean train loss: 2541.0087827835428
INFO:root:final train perplexity: 7.418614387512207
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.21s/it]
INFO:root:eval mean loss: 3039.553127346096
INFO:root:eval perplexity: 12.111739158630371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/4
  4%|â–         | 4/100 [21:22<8:33:47, 321.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2518.5289725687967
INFO:root:current train perplexity7.138425827026367
INFO:root:current mean train loss 2481.583039974738
INFO:root:current train perplexity7.046876907348633
INFO:root:current mean train loss 2479.65608449643
INFO:root:current train perplexity7.057676315307617
INFO:root:current mean train loss 2480.2593262383984
INFO:root:current train perplexity7.068392276763916
INFO:root:current mean train loss 2481.15952341868
INFO:root:current train perplexity7.078820705413818
INFO:root:current mean train loss 2476.262122421668
INFO:root:current train perplexity7.045648574829102
INFO:root:current mean train loss 2477.2673608874275
INFO:root:current train perplexity7.0435919761657715
INFO:root:current mean train loss 2474.1352133222476
INFO:root:current train perplexity7.0284037590026855
INFO:root:current mean train loss 2474.536790753181
INFO:root:current train perplexity7.018426418304443
INFO:root:current mean train loss 2470.604538768622
INFO:root:current train perplexity7.000748157501221
INFO:root:current mean train loss 2469.8415933482092
INFO:root:current train perplexity6.9950056076049805
INFO:root:current mean train loss 2469.0827411824857
INFO:root:current train perplexity6.987059116363525
INFO:root:current mean train loss 2465.9968603746856
INFO:root:current train perplexity6.975276470184326
INFO:root:current mean train loss 2465.7141535660603
INFO:root:current train perplexity6.971148490905762
INFO:root:current mean train loss 2463.193451822251
INFO:root:current train perplexity6.9662346839904785
INFO:root:current mean train loss 2460.7419933715896
INFO:root:current train perplexity6.960360050201416
INFO:root:current mean train loss 2457.390899822965
INFO:root:current train perplexity6.945827484130859
INFO:root:current mean train loss 2456.0469562420417
INFO:root:current train perplexity6.934788703918457
INFO:root:current mean train loss 2454.1693916177774
INFO:root:current train perplexity6.925286769866943
INFO:root:current mean train loss 2452.1998295359763
INFO:root:current train perplexity6.912625312805176

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.05s/it]
INFO:root:final mean train loss: 2451.201355657611
INFO:root:final train perplexity: 6.911348342895508
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.79s/it]
INFO:root:eval mean loss: 3003.167115357545
INFO:root:eval perplexity: 11.755459785461426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/5
  5%|â–Œ         | 5/100 [26:47<8:30:48, 322.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2410.0384114583335
INFO:root:current train perplexity6.631048679351807
INFO:root:current mean train loss 2404.186470363451
INFO:root:current train perplexity6.643045902252197
INFO:root:current mean train loss 2402.630315646319
INFO:root:current train perplexity6.667903423309326
INFO:root:current mean train loss 2404.0192556381226
INFO:root:current train perplexity6.671831130981445
INFO:root:current mean train loss 2410.5824415979305
INFO:root:current train perplexity6.68784236907959
INFO:root:current mean train loss 2404.3142254973113
INFO:root:current train perplexity6.655393600463867
INFO:root:current mean train loss 2402.814704582705
INFO:root:current train perplexity6.6367950439453125
INFO:root:current mean train loss 2402.6832454447845
INFO:root:current train perplexity6.642366409301758
INFO:root:current mean train loss 2400.99281083189
INFO:root:current train perplexity6.6303935050964355
INFO:root:current mean train loss 2396.967338499984
INFO:root:current train perplexity6.613408088684082
INFO:root:current mean train loss 2396.300111327224
INFO:root:current train perplexity6.613137722015381
INFO:root:current mean train loss 2394.739826820992
INFO:root:current train perplexity6.606152534484863
INFO:root:current mean train loss 2393.6965282594674
INFO:root:current train perplexity6.601606369018555
INFO:root:current mean train loss 2393.555323253477
INFO:root:current train perplexity6.597714424133301
INFO:root:current mean train loss 2393.8115087133856
INFO:root:current train perplexity6.599008083343506
INFO:root:current mean train loss 2392.979497813215
INFO:root:current train perplexity6.590452671051025
INFO:root:current mean train loss 2392.1585749175374
INFO:root:current train perplexity6.584888458251953
INFO:root:current mean train loss 2389.1059922017325
INFO:root:current train perplexity6.578624248504639
INFO:root:current mean train loss 2388.665397239086
INFO:root:current train perplexity6.57275915145874

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.92s/it]
INFO:root:final mean train loss: 2386.1737971611233
INFO:root:final train perplexity: 6.56583833694458
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.17s/it]
INFO:root:eval mean loss: 2967.8008157082863
INFO:root:eval perplexity: 11.419209480285645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/6
  6%|â–Œ         | 6/100 [32:11<8:26:00, 322.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2459.8173828125
INFO:root:current train perplexity6.070160865783691
INFO:root:current mean train loss 2326.9530863242576
INFO:root:current train perplexity6.284091472625732
INFO:root:current mean train loss 2338.949264905939
INFO:root:current train perplexity6.342307090759277
INFO:root:current mean train loss 2348.8610641124637
INFO:root:current train perplexity6.360190391540527
INFO:root:current mean train loss 2345.6940826644327
INFO:root:current train perplexity6.355704307556152
INFO:root:current mean train loss 2343.037009720793
INFO:root:current train perplexity6.356627941131592
INFO:root:current mean train loss 2340.711181437513
INFO:root:current train perplexity6.349236965179443
INFO:root:current mean train loss 2342.9257943103044
INFO:root:current train perplexity6.352235317230225
INFO:root:current mean train loss 2343.503908535961
INFO:root:current train perplexity6.353041648864746
INFO:root:current mean train loss 2342.536773512287
INFO:root:current train perplexity6.345155239105225
INFO:root:current mean train loss 2339.8781522432646
INFO:root:current train perplexity6.336174488067627
INFO:root:current mean train loss 2338.854160236078
INFO:root:current train perplexity6.328354835510254
INFO:root:current mean train loss 2338.503259714398
INFO:root:current train perplexity6.325188636779785
INFO:root:current mean train loss 2338.368655064764
INFO:root:current train perplexity6.325682163238525
INFO:root:current mean train loss 2338.055377314892
INFO:root:current train perplexity6.32481050491333
INFO:root:current mean train loss 2338.5539861446537
INFO:root:current train perplexity6.321552276611328
INFO:root:current mean train loss 2337.146488263561
INFO:root:current train perplexity6.314666748046875
INFO:root:current mean train loss 2337.0592175931665
INFO:root:current train perplexity6.315114974975586
INFO:root:current mean train loss 2336.9465851219807
INFO:root:current train perplexity6.311498641967773
INFO:root:current mean train loss 2336.60481306354
INFO:root:current train perplexity6.309636116027832

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.96s/it]
INFO:root:final mean train loss: 2335.3014475581504
INFO:root:final train perplexity: 6.307625770568848
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.80s/it]
INFO:root:eval mean loss: 2945.3810448632225
INFO:root:eval perplexity: 11.211050033569336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/7
  7%|â–‹         | 7/100 [37:36<8:21:49, 323.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2297.747748480903
INFO:root:current train perplexity6.106834411621094
INFO:root:current mean train loss 2284.1301652294096
INFO:root:current train perplexity6.129908561706543
INFO:root:current mean train loss 2301.574013246309
INFO:root:current train perplexity6.1801438331604
INFO:root:current mean train loss 2304.3466535844145
INFO:root:current train perplexity6.176202774047852
INFO:root:current mean train loss 2303.755809729179
INFO:root:current train perplexity6.152610778808594
INFO:root:current mean train loss 2304.35446414432
INFO:root:current train perplexity6.152410507202148
INFO:root:current mean train loss 2303.379972291224
INFO:root:current train perplexity6.142317295074463
INFO:root:current mean train loss 2304.470962226889
INFO:root:current train perplexity6.146214962005615
INFO:root:current mean train loss 2303.2952315276875
INFO:root:current train perplexity6.1360249519348145
INFO:root:current mean train loss 2302.080780361732
INFO:root:current train perplexity6.133696556091309
INFO:root:current mean train loss 2299.6430058507412
INFO:root:current train perplexity6.12639045715332
INFO:root:current mean train loss 2299.85799783287
INFO:root:current train perplexity6.120439052581787
INFO:root:current mean train loss 2299.812244133409
INFO:root:current train perplexity6.117484092712402
INFO:root:current mean train loss 2300.4451232817537
INFO:root:current train perplexity6.12416410446167
INFO:root:current mean train loss 2300.590467358846
INFO:root:current train perplexity6.121532917022705
INFO:root:current mean train loss 2300.7054985357995
INFO:root:current train perplexity6.117976188659668
INFO:root:current mean train loss 2298.9607452656637
INFO:root:current train perplexity6.112671375274658
INFO:root:current mean train loss 2296.977871167646
INFO:root:current train perplexity6.105182647705078
INFO:root:current mean train loss 2295.9889179896995
INFO:root:current train perplexity6.104745388031006
INFO:root:current mean train loss 2293.7836409997394
INFO:root:current train perplexity6.101303577423096

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 291.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 291.00s/it]
INFO:root:final mean train loss: 2293.2747789191526
INFO:root:final train perplexity: 6.101987361907959
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.39s/it]
INFO:root:eval mean loss: 2926.552441112988
INFO:root:eval perplexity: 11.039168357849121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/8
  8%|â–Š         | 8/100 [43:05<8:18:50, 325.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2261.0999128069197
INFO:root:current train perplexity5.919862747192383
INFO:root:current mean train loss 2267.6454210069446
INFO:root:current train perplexity5.932332992553711
INFO:root:current mean train loss 2261.3391954787235
INFO:root:current train perplexity5.944481372833252
INFO:root:current mean train loss 2262.8546521542676
INFO:root:current train perplexity5.957062721252441
INFO:root:current mean train loss 2259.3404456829203
INFO:root:current train perplexity5.958316802978516
INFO:root:current mean train loss 2258.4838698342583
INFO:root:current train perplexity5.946997165679932
INFO:root:current mean train loss 2261.7626207246553
INFO:root:current train perplexity5.945766448974609
INFO:root:current mean train loss 2264.3196764057184
INFO:root:current train perplexity5.950864315032959
INFO:root:current mean train loss 2264.7125105258233
INFO:root:current train perplexity5.954718112945557
INFO:root:current mean train loss 2266.3778114033257
INFO:root:current train perplexity5.957353591918945
INFO:root:current mean train loss 2265.061759440104
INFO:root:current train perplexity5.956414699554443
INFO:root:current mean train loss 2262.3300641433784
INFO:root:current train perplexity5.949367523193359
INFO:root:current mean train loss 2260.350867835906
INFO:root:current train perplexity5.945217609405518
INFO:root:current mean train loss 2261.142046227616
INFO:root:current train perplexity5.947260856628418
INFO:root:current mean train loss 2260.626178595247
INFO:root:current train perplexity5.945281505584717
INFO:root:current mean train loss 2261.2395215957094
INFO:root:current train perplexity5.9434733390808105
INFO:root:current mean train loss 2260.53991826142
INFO:root:current train perplexity5.94300651550293
INFO:root:current mean train loss 2259.3744047049486
INFO:root:current train perplexity5.938758373260498
INFO:root:current mean train loss 2258.0847530520905
INFO:root:current train perplexity5.933922290802002
INFO:root:current mean train loss 2258.1488722217177
INFO:root:current train perplexity5.933765411376953

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.96s/it]
INFO:root:final mean train loss: 2258.341532974128
INFO:root:final train perplexity: 5.936169147491455
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.43s/it]
INFO:root:eval mean loss: 2913.7670289918824
INFO:root:eval perplexity: 10.923959732055664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/9
  9%|â–‰         | 9/100 [48:36<8:16:06, 327.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2209.8180260291465
INFO:root:current train perplexity5.753708839416504
INFO:root:current mean train loss 2221.3353721217104
INFO:root:current train perplexity5.729138374328613
INFO:root:current mean train loss 2231.64264109778
INFO:root:current train perplexity5.781452655792236
INFO:root:current mean train loss 2227.5046032992277
INFO:root:current train perplexity5.790935039520264
INFO:root:current mean train loss 2234.625290052026
INFO:root:current train perplexity5.810929775238037
INFO:root:current mean train loss 2235.932492684627
INFO:root:current train perplexity5.814695835113525
INFO:root:current mean train loss 2238.6119993244943
INFO:root:current train perplexity5.8218278884887695
INFO:root:current mean train loss 2234.7484979832425
INFO:root:current train perplexity5.81073522567749
INFO:root:current mean train loss 2234.4018884220036
INFO:root:current train perplexity5.813389301300049
INFO:root:current mean train loss 2231.3317576175978
INFO:root:current train perplexity5.806913375854492
INFO:root:current mean train loss 2232.7314127062664
INFO:root:current train perplexity5.81153678894043
INFO:root:current mean train loss 2232.2187570995757
INFO:root:current train perplexity5.804611682891846
INFO:root:current mean train loss 2231.681678162596
INFO:root:current train perplexity5.803637981414795
INFO:root:current mean train loss 2232.3301479181596
INFO:root:current train perplexity5.80987548828125
INFO:root:current mean train loss 2231.14957556186
INFO:root:current train perplexity5.80601167678833
INFO:root:current mean train loss 2228.6075883059157
INFO:root:current train perplexity5.798370361328125
INFO:root:current mean train loss 2228.5235599397747
INFO:root:current train perplexity5.794796466827393
INFO:root:current mean train loss 2230.1635094908274
INFO:root:current train perplexity5.799159526824951
INFO:root:current mean train loss 2228.3311802511853
INFO:root:current train perplexity5.793920993804932
INFO:root:current mean train loss 2228.6294274877328
INFO:root:current train perplexity5.794956207275391

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.44s/it]
INFO:root:final mean train loss: 2227.8252025763913
INFO:root:final train perplexity: 5.795008659362793
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.43s/it]
INFO:root:eval mean loss: 2897.6476478920326
INFO:root:eval perplexity: 10.780417442321777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/10
 10%|â–ˆ         | 10/100 [54:01<8:09:54, 326.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2222.1966057376585
INFO:root:current train perplexity5.712640762329102
INFO:root:current mean train loss 2221.9732203737517
INFO:root:current train perplexity5.689927577972412
INFO:root:current mean train loss 2203.8112134968924
INFO:root:current train perplexity5.652371406555176
INFO:root:current mean train loss 2202.30346547362
INFO:root:current train perplexity5.655150413513184
INFO:root:current mean train loss 2203.653629002032
INFO:root:current train perplexity5.6580047607421875
INFO:root:current mean train loss 2207.367616355105
INFO:root:current train perplexity5.670556545257568
INFO:root:current mean train loss 2203.581990012495
INFO:root:current train perplexity5.664253234863281
INFO:root:current mean train loss 2205.095292784613
INFO:root:current train perplexity5.676125526428223
INFO:root:current mean train loss 2206.1355327435
INFO:root:current train perplexity5.670682430267334
INFO:root:current mean train loss 2205.089918705455
INFO:root:current train perplexity5.671402931213379
INFO:root:current mean train loss 2203.780002690343
INFO:root:current train perplexity5.6738457679748535
INFO:root:current mean train loss 2203.57831546728
INFO:root:current train perplexity5.6734514236450195
INFO:root:current mean train loss 2203.129440608224
INFO:root:current train perplexity5.671056270599365
INFO:root:current mean train loss 2203.9760236607754
INFO:root:current train perplexity5.6748270988464355
INFO:root:current mean train loss 2204.615783732955
INFO:root:current train perplexity5.675675392150879
INFO:root:current mean train loss 2203.059709032301
INFO:root:current train perplexity5.673656463623047
INFO:root:current mean train loss 2202.1973461519106
INFO:root:current train perplexity5.672612190246582
INFO:root:current mean train loss 2201.1674265066335
INFO:root:current train perplexity5.671785831451416
INFO:root:current mean train loss 2200.4133176686228
INFO:root:current train perplexity5.671472072601318
INFO:root:current mean train loss 2201.9767221399466
INFO:root:current train perplexity5.675919055938721

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.72s/it]
INFO:root:final mean train loss: 2201.537949154729
INFO:root:final train perplexity: 5.676104545593262
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.03s/it]
INFO:root:eval mean loss: 2881.8202648449233
INFO:root:eval perplexity: 10.641311645507812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/11
 11%|â–ˆ         | 11/100 [59:27<8:04:04, 326.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2204.8521898846293
INFO:root:current train perplexity5.610503196716309
INFO:root:current mean train loss 2174.0623300203715
INFO:root:current train perplexity5.55185079574585
INFO:root:current mean train loss 2175.792026759861
INFO:root:current train perplexity5.553459167480469
INFO:root:current mean train loss 2185.531753777222
INFO:root:current train perplexity5.584645748138428
INFO:root:current mean train loss 2180.7570162800603
INFO:root:current train perplexity5.565218925476074
INFO:root:current mean train loss 2180.1423408586415
INFO:root:current train perplexity5.55954122543335
INFO:root:current mean train loss 2181.3041810683535
INFO:root:current train perplexity5.563758850097656
INFO:root:current mean train loss 2181.3721415978353
INFO:root:current train perplexity5.571785926818848
INFO:root:current mean train loss 2179.2161675102284
INFO:root:current train perplexity5.569211959838867
INFO:root:current mean train loss 2179.2938345083116
INFO:root:current train perplexity5.57297420501709
INFO:root:current mean train loss 2175.957831001633
INFO:root:current train perplexity5.564356803894043
INFO:root:current mean train loss 2179.1043813361284
INFO:root:current train perplexity5.569844722747803
INFO:root:current mean train loss 2177.990825742066
INFO:root:current train perplexity5.5685343742370605
INFO:root:current mean train loss 2178.0747025394853
INFO:root:current train perplexity5.569794178009033
INFO:root:current mean train loss 2177.633441252471
INFO:root:current train perplexity5.567927360534668
INFO:root:current mean train loss 2177.331155668742
INFO:root:current train perplexity5.565622806549072
INFO:root:current mean train loss 2177.509205520648
INFO:root:current train perplexity5.566194534301758
INFO:root:current mean train loss 2177.5882515731078
INFO:root:current train perplexity5.567493438720703
INFO:root:current mean train loss 2177.71221703765
INFO:root:current train perplexity5.567842960357666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.19s/it]
INFO:root:final mean train loss: 2177.5913461443756
INFO:root:final train perplexity: 5.569912910461426
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.43s/it]
INFO:root:eval mean loss: 2872.3490624413475
INFO:root:eval perplexity: 10.558930397033691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/12
 12%|â–ˆâ–        | 12/100 [1:04:53<7:58:34, 326.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2060.0804850260415
INFO:root:current train perplexity5.16064977645874
INFO:root:current mean train loss 2157.102800980355
INFO:root:current train perplexity5.470180034637451
INFO:root:current mean train loss 2160.975008659175
INFO:root:current train perplexity5.487682819366455
INFO:root:current mean train loss 2155.2482358221173
INFO:root:current train perplexity5.475797176361084
INFO:root:current mean train loss 2151.6506059897447
INFO:root:current train perplexity5.47540283203125
INFO:root:current mean train loss 2155.7555307801626
INFO:root:current train perplexity5.489181041717529
INFO:root:current mean train loss 2154.1194809238314
INFO:root:current train perplexity5.488381862640381
INFO:root:current mean train loss 2152.4631696676634
INFO:root:current train perplexity5.4833831787109375
INFO:root:current mean train loss 2152.1531714870507
INFO:root:current train perplexity5.477959632873535
INFO:root:current mean train loss 2155.637538094589
INFO:root:current train perplexity5.483335494995117
INFO:root:current mean train loss 2155.032130902215
INFO:root:current train perplexity5.479538917541504
INFO:root:current mean train loss 2153.7568755577827
INFO:root:current train perplexity5.475533485412598
INFO:root:current mean train loss 2152.7155797233804
INFO:root:current train perplexity5.4777421951293945
INFO:root:current mean train loss 2151.7416821682536
INFO:root:current train perplexity5.4751081466674805
INFO:root:current mean train loss 2151.9030639039393
INFO:root:current train perplexity5.473736763000488
INFO:root:current mean train loss 2152.5355715164724
INFO:root:current train perplexity5.47003698348999
INFO:root:current mean train loss 2154.6641050684993
INFO:root:current train perplexity5.471898555755615
INFO:root:current mean train loss 2153.8093187171994
INFO:root:current train perplexity5.471301555633545
INFO:root:current mean train loss 2154.933320632063
INFO:root:current train perplexity5.474228858947754
INFO:root:current mean train loss 2156.014721756663
INFO:root:current train perplexity5.476487159729004

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.95s/it]
INFO:root:final mean train loss: 2156.3221670699972
INFO:root:final train perplexity: 5.477262496948242
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.47s/it]
INFO:root:eval mean loss: 2873.6086073866836
INFO:root:eval perplexity: 10.569849014282227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/13
 13%|â–ˆâ–Ž        | 13/100 [1:10:20<7:53:02, 326.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2201.913153076172
INFO:root:current train perplexity5.4545745849609375
INFO:root:current mean train loss 2141.151799519857
INFO:root:current train perplexity5.369237422943115
INFO:root:current mean train loss 2145.877430308949
INFO:root:current train perplexity5.391182899475098
INFO:root:current mean train loss 2137.652862930298
INFO:root:current train perplexity5.379520416259766
INFO:root:current mean train loss 2140.7810369582403
INFO:root:current train perplexity5.380189895629883
INFO:root:current mean train loss 2141.07259756235
INFO:root:current train perplexity5.393640041351318
INFO:root:current mean train loss 2140.589938059161
INFO:root:current train perplexity5.391234397888184
INFO:root:current mean train loss 2141.584693230523
INFO:root:current train perplexity5.393390655517578
INFO:root:current mean train loss 2142.3907088116903
INFO:root:current train perplexity5.396986484527588
INFO:root:current mean train loss 2143.0021586542543
INFO:root:current train perplexity5.398099422454834
INFO:root:current mean train loss 2140.7197106454887
INFO:root:current train perplexity5.397237777709961
INFO:root:current mean train loss 2141.462562016078
INFO:root:current train perplexity5.400689601898193
INFO:root:current mean train loss 2139.0266569544056
INFO:root:current train perplexity5.400739669799805
INFO:root:current mean train loss 2137.9682496041964
INFO:root:current train perplexity5.400252342224121
INFO:root:current mean train loss 2137.5352203798966
INFO:root:current train perplexity5.394726753234863
INFO:root:current mean train loss 2136.518710407458
INFO:root:current train perplexity5.393005847930908
INFO:root:current mean train loss 2136.4875226056133
INFO:root:current train perplexity5.391005516052246
INFO:root:current mean train loss 2136.3719070789425
INFO:root:current train perplexity5.390124797821045
INFO:root:current mean train loss 2137.018365880945
INFO:root:current train perplexity5.393425941467285
INFO:root:current mean train loss 2138.019106864929
INFO:root:current train perplexity5.394685745239258

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.91s/it]
INFO:root:final mean train loss: 2136.975667748617
INFO:root:final train perplexity: 5.394324779510498
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.43s/it]
INFO:root:eval mean loss: 2861.3685379715653
INFO:root:eval perplexity: 10.464218139648438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/14
 14%|â–ˆâ–        | 14/100 [1:15:45<7:47:29, 326.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2102.5716288798562
INFO:root:current train perplexity5.2807464599609375
INFO:root:current mean train loss 2099.6890183052005
INFO:root:current train perplexity5.297479629516602
INFO:root:current mean train loss 2113.430617706685
INFO:root:current train perplexity5.313971996307373
INFO:root:current mean train loss 2109.833229857312
INFO:root:current train perplexity5.307937145233154
INFO:root:current mean train loss 2109.124684628415
INFO:root:current train perplexity5.317859649658203
INFO:root:current mean train loss 2112.8485364292364
INFO:root:current train perplexity5.321849822998047
INFO:root:current mean train loss 2112.4494119162086
INFO:root:current train perplexity5.313551425933838
INFO:root:current mean train loss 2110.025988885473
INFO:root:current train perplexity5.312350749969482
INFO:root:current mean train loss 2111.3967804356143
INFO:root:current train perplexity5.314105033874512
INFO:root:current mean train loss 2112.7111706972887
INFO:root:current train perplexity5.318562984466553
INFO:root:current mean train loss 2113.5616147842334
INFO:root:current train perplexity5.321528911590576
INFO:root:current mean train loss 2115.816650390625
INFO:root:current train perplexity5.3224310874938965
INFO:root:current mean train loss 2117.7316698152977
INFO:root:current train perplexity5.326791763305664
INFO:root:current mean train loss 2117.6779995150055
INFO:root:current train perplexity5.3259501457214355
INFO:root:current mean train loss 2118.1719939272357
INFO:root:current train perplexity5.322281360626221
INFO:root:current mean train loss 2119.2220744106316
INFO:root:current train perplexity5.327794075012207
INFO:root:current mean train loss 2119.1223209406735
INFO:root:current train perplexity5.326033115386963
INFO:root:current mean train loss 2119.885228958086
INFO:root:current train perplexity5.322912216186523
INFO:root:current mean train loss 2119.7484180033043
INFO:root:current train perplexity5.320304870605469
INFO:root:current mean train loss 2120.702939090128
INFO:root:current train perplexity5.321539402008057

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.66s/it]
INFO:root:final mean train loss: 2119.425480968112
INFO:root:final train perplexity: 5.320175647735596
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.58s/it]
INFO:root:eval mean loss: 2859.1783003706832
INFO:root:eval perplexity: 10.445428848266602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/15
 15%|â–ˆâ–Œ        | 15/100 [1:21:12<7:42:01, 326.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2110.130560980903
INFO:root:current train perplexity5.22268533706665
INFO:root:current mean train loss 2102.3008153345677
INFO:root:current train perplexity5.192781448364258
INFO:root:current mean train loss 2099.478117214413
INFO:root:current train perplexity5.225806713104248
INFO:root:current mean train loss 2095.611548127428
INFO:root:current train perplexity5.233149528503418
INFO:root:current mean train loss 2096.338000326955
INFO:root:current train perplexity5.2323713302612305
INFO:root:current mean train loss 2095.049536309087
INFO:root:current train perplexity5.2320380210876465
INFO:root:current mean train loss 2096.6188268632336
INFO:root:current train perplexity5.231281757354736
INFO:root:current mean train loss 2098.377904917264
INFO:root:current train perplexity5.239767551422119
INFO:root:current mean train loss 2099.4385973463573
INFO:root:current train perplexity5.238855838775635
INFO:root:current mean train loss 2097.9873915698295
INFO:root:current train perplexity5.237133026123047
INFO:root:current mean train loss 2098.4174056514616
INFO:root:current train perplexity5.236666202545166
INFO:root:current mean train loss 2097.787840633293
INFO:root:current train perplexity5.238448143005371
INFO:root:current mean train loss 2099.791098660069
INFO:root:current train perplexity5.243330001831055
INFO:root:current mean train loss 2101.9541347396603
INFO:root:current train perplexity5.2491655349731445
INFO:root:current mean train loss 2101.4485121862103
INFO:root:current train perplexity5.245399475097656
INFO:root:current mean train loss 2101.807810269114
INFO:root:current train perplexity5.247687816619873
INFO:root:current mean train loss 2101.3611738027366
INFO:root:current train perplexity5.247037410736084
INFO:root:current mean train loss 2101.3372169416334
INFO:root:current train perplexity5.246032238006592
INFO:root:current mean train loss 2101.24434486562
INFO:root:current train perplexity5.246438503265381
INFO:root:current mean train loss 2102.9652253915247
INFO:root:current train perplexity5.249294757843018

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.11s/it]
INFO:root:final mean train loss: 2102.721165828734
INFO:root:final train perplexity: 5.250547885894775
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.79s/it]
INFO:root:eval mean loss: 2849.2411207594314
INFO:root:eval perplexity: 10.360601425170898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/16
 16%|â–ˆâ–Œ        | 16/100 [1:26:36<7:36:03, 325.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2103.9530218419895
INFO:root:current train perplexity5.266145706176758
INFO:root:current mean train loss 2081.380261872944
INFO:root:current train perplexity5.195326805114746
INFO:root:current mean train loss 2079.252885994436
INFO:root:current train perplexity5.198504447937012
INFO:root:current mean train loss 2080.982376468792
INFO:root:current train perplexity5.192605018615723
INFO:root:current mean train loss 2082.3057267822783
INFO:root:current train perplexity5.187270164489746
INFO:root:current mean train loss 2082.985324839577
INFO:root:current train perplexity5.180092811584473
INFO:root:current mean train loss 2081.9158595350923
INFO:root:current train perplexity5.178524017333984
INFO:root:current mean train loss 2084.0620394260195
INFO:root:current train perplexity5.176618576049805
INFO:root:current mean train loss 2083.3383368613663
INFO:root:current train perplexity5.179386138916016
INFO:root:current mean train loss 2084.2452139888806
INFO:root:current train perplexity5.178391933441162
INFO:root:current mean train loss 2084.046130610447
INFO:root:current train perplexity5.17540168762207
INFO:root:current mean train loss 2084.962724459263
INFO:root:current train perplexity5.174646854400635
INFO:root:current mean train loss 2083.922231030408
INFO:root:current train perplexity5.174760818481445
INFO:root:current mean train loss 2084.372025882824
INFO:root:current train perplexity5.179052829742432
INFO:root:current mean train loss 2084.207383685498
INFO:root:current train perplexity5.179900169372559
INFO:root:current mean train loss 2085.1827091870227
INFO:root:current train perplexity5.183271884918213
INFO:root:current mean train loss 2084.9500183068944
INFO:root:current train perplexity5.178699016571045
INFO:root:current mean train loss 2086.077673870584
INFO:root:current train perplexity5.183098793029785
INFO:root:current mean train loss 2086.0515844609126
INFO:root:current train perplexity5.184309482574463
INFO:root:current mean train loss 2087.5672559113987
INFO:root:current train perplexity5.186722755432129

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.24s/it]
INFO:root:final mean train loss: 2087.440340981842
INFO:root:final train perplexity: 5.18765115737915
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.59s/it]
INFO:root:eval mean loss: 2849.537090312969
INFO:root:eval perplexity: 10.363119125366211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/17
 17%|â–ˆâ–‹        | 17/100 [1:32:03<7:30:57, 325.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2053.7778348055754
INFO:root:current train perplexity5.070121765136719
INFO:root:current mean train loss 2061.6470862855303
INFO:root:current train perplexity5.088743209838867
INFO:root:current mean train loss 2070.0866084628633
INFO:root:current train perplexity5.104002952575684
INFO:root:current mean train loss 2063.141922783606
INFO:root:current train perplexity5.098624229431152
INFO:root:current mean train loss 2066.0271794053374
INFO:root:current train perplexity5.112224102020264
INFO:root:current mean train loss 2068.546783239663
INFO:root:current train perplexity5.1155524253845215
INFO:root:current mean train loss 2069.0560937925825
INFO:root:current train perplexity5.119075298309326
INFO:root:current mean train loss 2067.393879846873
INFO:root:current train perplexity5.118251323699951
INFO:root:current mean train loss 2068.4855842934
INFO:root:current train perplexity5.119531154632568
INFO:root:current mean train loss 2071.944643707893
INFO:root:current train perplexity5.122231483459473
INFO:root:current mean train loss 2073.408796983607
INFO:root:current train perplexity5.1218132972717285
INFO:root:current mean train loss 2073.203347768045
INFO:root:current train perplexity5.117485523223877
INFO:root:current mean train loss 2071.0141660323056
INFO:root:current train perplexity5.115220546722412
INFO:root:current mean train loss 2070.2180078160177
INFO:root:current train perplexity5.112799167633057
INFO:root:current mean train loss 2070.948942943286
INFO:root:current train perplexity5.114734649658203
INFO:root:current mean train loss 2071.3262459012662
INFO:root:current train perplexity5.119327068328857
INFO:root:current mean train loss 2072.4286887363237
INFO:root:current train perplexity5.123529434204102
INFO:root:current mean train loss 2072.568456321221
INFO:root:current train perplexity5.1265482902526855
INFO:root:current mean train loss 2072.950303546453
INFO:root:current train perplexity5.12861967086792

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.95s/it]
INFO:root:final mean train loss: 2073.0376650011426
INFO:root:final train perplexity: 5.129059314727783
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.80s/it]
INFO:root:eval mean loss: 2849.3764993020363
INFO:root:eval perplexity: 10.3617525100708
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/18
 18%|â–ˆâ–Š        | 18/100 [1:37:28<7:25:16, 325.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2086.9763916015627
INFO:root:current train perplexity5.176169395446777
INFO:root:current mean train loss 2057.4701788039433
INFO:root:current train perplexity5.076757907867432
INFO:root:current mean train loss 2060.144278177401
INFO:root:current train perplexity5.072017192840576
INFO:root:current mean train loss 2062.540057072874
INFO:root:current train perplexity5.079462051391602
INFO:root:current mean train loss 2059.4297336154514
INFO:root:current train perplexity5.077844142913818
INFO:root:current mean train loss 2057.101369846457
INFO:root:current train perplexity5.069925308227539
INFO:root:current mean train loss 2061.327052395403
INFO:root:current train perplexity5.0788798332214355
INFO:root:current mean train loss 2061.1099060491465
INFO:root:current train perplexity5.083164691925049
INFO:root:current mean train loss 2061.0784150875875
INFO:root:current train perplexity5.077066898345947
INFO:root:current mean train loss 2062.6417403584687
INFO:root:current train perplexity5.082552433013916
INFO:root:current mean train loss 2065.1436773651276
INFO:root:current train perplexity5.088144302368164
INFO:root:current mean train loss 2063.079752346401
INFO:root:current train perplexity5.080769062042236
INFO:root:current mean train loss 2062.378811531542
INFO:root:current train perplexity5.077751159667969
INFO:root:current mean train loss 2061.4105212449113
INFO:root:current train perplexity5.076849460601807
INFO:root:current mean train loss 2061.339700132757
INFO:root:current train perplexity5.07597541809082
INFO:root:current mean train loss 2059.718835814213
INFO:root:current train perplexity5.0741987228393555
INFO:root:current mean train loss 2058.598418866214
INFO:root:current train perplexity5.072018623352051
INFO:root:current mean train loss 2059.427015198291
INFO:root:current train perplexity5.073910236358643
INFO:root:current mean train loss 2058.549727996234
INFO:root:current train perplexity5.071628570556641
INFO:root:current mean train loss 2059.1133264256273
INFO:root:current train perplexity5.0739569664001465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.09s/it]
INFO:root:final mean train loss: 2059.836259481225
INFO:root:final train perplexity: 5.0759358406066895
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.44s/it]
INFO:root:eval mean loss: 2841.815409159159
INFO:root:eval perplexity: 10.297663688659668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/19
 19%|â–ˆâ–‰        | 19/100 [1:42:55<7:20:06, 326.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2010.5708951083097
INFO:root:current train perplexity4.945977210998535
INFO:root:current mean train loss 2033.8517726210298
INFO:root:current train perplexity4.952581882476807
INFO:root:current mean train loss 2030.8901075758376
INFO:root:current train perplexity4.9624176025390625
INFO:root:current mean train loss 2032.0429615470935
INFO:root:current train perplexity4.965522289276123
INFO:root:current mean train loss 2040.9117801901289
INFO:root:current train perplexity4.972886085510254
INFO:root:current mean train loss 2042.1802859251527
INFO:root:current train perplexity4.983457088470459
INFO:root:current mean train loss 2041.8676522307073
INFO:root:current train perplexity4.990111827850342
INFO:root:current mean train loss 2040.4282047345698
INFO:root:current train perplexity4.9937663078308105
INFO:root:current mean train loss 2043.2723725776023
INFO:root:current train perplexity4.996883392333984
INFO:root:current mean train loss 2044.5307495381983
INFO:root:current train perplexity4.999622821807861
INFO:root:current mean train loss 2043.5890371542855
INFO:root:current train perplexity5.002896785736084
INFO:root:current mean train loss 2044.0001205471535
INFO:root:current train perplexity5.007318019866943
INFO:root:current mean train loss 2044.971807651551
INFO:root:current train perplexity5.010126113891602
INFO:root:current mean train loss 2047.1246356358147
INFO:root:current train perplexity5.017463684082031
INFO:root:current mean train loss 2047.1214777306666
INFO:root:current train perplexity5.016021728515625
INFO:root:current mean train loss 2047.9145350612887
INFO:root:current train perplexity5.019350528717041
INFO:root:current mean train loss 2047.6456539657347
INFO:root:current train perplexity5.01876974105835
INFO:root:current mean train loss 2047.9035360976518
INFO:root:current train perplexity5.023158550262451
INFO:root:current mean train loss 2048.726610202559
INFO:root:current train perplexity5.026713848114014
INFO:root:current mean train loss 2049.0691766490795
INFO:root:current train perplexity5.027782917022705

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.59s/it]
INFO:root:final mean train loss: 2047.2035862571113
INFO:root:final train perplexity: 5.025615692138672
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.61s/it]
INFO:root:eval mean loss: 2841.057495483765
INFO:root:eval perplexity: 10.291260719299316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/20
 20%|â–ˆâ–ˆ        | 20/100 [1:48:22<7:14:59, 326.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2013.111810146234
INFO:root:current train perplexity4.929355144500732
INFO:root:current mean train loss 2045.5718247667492
INFO:root:current train perplexity4.961345195770264
INFO:root:current mean train loss 2042.2304192068189
INFO:root:current train perplexity4.961208820343018
INFO:root:current mean train loss 2041.643620223774
INFO:root:current train perplexity4.964000225067139
INFO:root:current mean train loss 2038.7173835910805
INFO:root:current train perplexity4.962545871734619
INFO:root:current mean train loss 2038.4521577229968
INFO:root:current train perplexity4.969022274017334
INFO:root:current mean train loss 2036.2736168803183
INFO:root:current train perplexity4.973148345947266
INFO:root:current mean train loss 2037.3866312029559
INFO:root:current train perplexity4.9736175537109375
INFO:root:current mean train loss 2036.322526934036
INFO:root:current train perplexity4.975625991821289
INFO:root:current mean train loss 2036.1571104722027
INFO:root:current train perplexity4.972140312194824
INFO:root:current mean train loss 2035.401023416822
INFO:root:current train perplexity4.970317363739014
INFO:root:current mean train loss 2036.2640217956061
INFO:root:current train perplexity4.9728546142578125
INFO:root:current mean train loss 2034.8504858378733
INFO:root:current train perplexity4.969516277313232
INFO:root:current mean train loss 2036.2876301110903
INFO:root:current train perplexity4.972976207733154
INFO:root:current mean train loss 2036.9954669414253
INFO:root:current train perplexity4.978098392486572
INFO:root:current mean train loss 2038.3245941618188
INFO:root:current train perplexity4.98300313949585
INFO:root:current mean train loss 2037.0803939139719
INFO:root:current train perplexity4.980886459350586
INFO:root:current mean train loss 2037.1457089231644
INFO:root:current train perplexity4.982084274291992
INFO:root:current mean train loss 2036.9895602999466
INFO:root:current train perplexity4.980637550354004
INFO:root:current mean train loss 2036.1721858102799
INFO:root:current train perplexity4.9802117347717285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.38s/it]
INFO:root:final mean train loss: 2035.082941606438
INFO:root:final train perplexity: 4.977803707122803
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.64s/it]
INFO:root:eval mean loss: 2843.727000926708
INFO:root:eval perplexity: 10.313826560974121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/21
 21%|â–ˆâ–ˆ        | 21/100 [1:53:48<7:09:42, 326.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1997.9714878627233
INFO:root:current train perplexity4.918402194976807
INFO:root:current mean train loss 2006.7389588967349
INFO:root:current train perplexity4.9128193855285645
INFO:root:current mean train loss 2013.3479771614075
INFO:root:current train perplexity4.927684307098389
INFO:root:current mean train loss 2019.7604445553898
INFO:root:current train perplexity4.94159460067749
INFO:root:current mean train loss 2020.7699515359443
INFO:root:current train perplexity4.940251350402832
INFO:root:current mean train loss 2020.2220876131125
INFO:root:current train perplexity4.92606258392334
INFO:root:current mean train loss 2018.4990539550781
INFO:root:current train perplexity4.92400598526001
INFO:root:current mean train loss 2019.4307808043466
INFO:root:current train perplexity4.921427249908447
INFO:root:current mean train loss 2019.718166886089
INFO:root:current train perplexity4.923884391784668
INFO:root:current mean train loss 2021.567770219747
INFO:root:current train perplexity4.925017833709717
INFO:root:current mean train loss 2021.3368612347226
INFO:root:current train perplexity4.925149440765381
INFO:root:current mean train loss 2021.5437602006853
INFO:root:current train perplexity4.92417573928833
INFO:root:current mean train loss 2021.2659243443968
INFO:root:current train perplexity4.921685695648193
INFO:root:current mean train loss 2022.4380858654822
INFO:root:current train perplexity4.925867557525635
INFO:root:current mean train loss 2022.9428436782334
INFO:root:current train perplexity4.925286293029785
INFO:root:current mean train loss 2023.3851495659444
INFO:root:current train perplexity4.926715850830078
INFO:root:current mean train loss 2024.073911141658
INFO:root:current train perplexity4.926545143127441
INFO:root:current mean train loss 2024.3177907331115
INFO:root:current train perplexity4.928460597991943
INFO:root:current mean train loss 2024.792340640364
INFO:root:current train perplexity4.93065881729126
INFO:root:current mean train loss 2024.2846621647934
INFO:root:current train perplexity4.932657718658447

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.15s/it]
INFO:root:final mean train loss: 2023.8685607448467
INFO:root:final train perplexity: 4.933972358703613
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.99s/it]
INFO:root:eval mean loss: 2835.8574072118995
INFO:root:eval perplexity: 10.247441291809082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/22
 22%|â–ˆâ–ˆâ–       | 22/100 [1:59:14<7:04:01, 326.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2004.05393166738
INFO:root:current train perplexity4.881913661956787
INFO:root:current mean train loss 2009.932822519644
INFO:root:current train perplexity4.870871067047119
INFO:root:current mean train loss 2009.3043610848786
INFO:root:current train perplexity4.872354507446289
INFO:root:current mean train loss 2008.127387407318
INFO:root:current train perplexity4.87914514541626
INFO:root:current mean train loss 2006.1552641467363
INFO:root:current train perplexity4.862938404083252
INFO:root:current mean train loss 2008.8638553852395
INFO:root:current train perplexity4.873004913330078
INFO:root:current mean train loss 2009.367804562709
INFO:root:current train perplexity4.877243518829346
INFO:root:current mean train loss 2007.7068666998505
INFO:root:current train perplexity4.876504898071289
INFO:root:current mean train loss 2008.5946781818263
INFO:root:current train perplexity4.880040645599365
INFO:root:current mean train loss 2011.1809228816724
INFO:root:current train perplexity4.884521484375
INFO:root:current mean train loss 2013.1615719470817
INFO:root:current train perplexity4.889667510986328
INFO:root:current mean train loss 2013.1499311702432
INFO:root:current train perplexity4.8897504806518555
INFO:root:current mean train loss 2012.707857933554
INFO:root:current train perplexity4.890483856201172
INFO:root:current mean train loss 2012.1144399844377
INFO:root:current train perplexity4.890360355377197
INFO:root:current mean train loss 2012.9472380286563
INFO:root:current train perplexity4.8892502784729
INFO:root:current mean train loss 2014.3161348705448
INFO:root:current train perplexity4.895431995391846
INFO:root:current mean train loss 2014.8144908478641
INFO:root:current train perplexity4.895025253295898
INFO:root:current mean train loss 2013.7925955164048
INFO:root:current train perplexity4.891874313354492
INFO:root:current mean train loss 2014.0130695398009
INFO:root:current train perplexity4.892571926116943
INFO:root:current mean train loss 2014.5434577118244
INFO:root:current train perplexity4.895054340362549

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.20s/it]
INFO:root:final mean train loss: 2013.6313192778264
INFO:root:final train perplexity: 4.894298076629639
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.72s/it]
INFO:root:eval mean loss: 2839.2399990322356
INFO:root:eval perplexity: 10.275924682617188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/23
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [2:04:40<6:58:21, 325.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2018.2309475368925
INFO:root:current train perplexity4.844673156738281
INFO:root:current mean train loss 2000.3838346782484
INFO:root:current train perplexity4.809820652008057
INFO:root:current mean train loss 2001.7997322871768
INFO:root:current train perplexity4.825388431549072
INFO:root:current mean train loss 2006.6997567983774
INFO:root:current train perplexity4.839381217956543
INFO:root:current mean train loss 1998.7314169124681
INFO:root:current train perplexity4.827508449554443
INFO:root:current mean train loss 2001.6459708520922
INFO:root:current train perplexity4.836318492889404
INFO:root:current mean train loss 2003.9672011223392
INFO:root:current train perplexity4.844717979431152
INFO:root:current mean train loss 2004.9978603701047
INFO:root:current train perplexity4.84291410446167
INFO:root:current mean train loss 2004.3995962078652
INFO:root:current train perplexity4.844427108764648
INFO:root:current mean train loss 2006.3283409041587
INFO:root:current train perplexity4.8525390625
INFO:root:current mean train loss 2004.2057963240038
INFO:root:current train perplexity4.851693153381348
INFO:root:current mean train loss 2002.5920140370602
INFO:root:current train perplexity4.843383312225342
INFO:root:current mean train loss 2001.4638775019682
INFO:root:current train perplexity4.8385539054870605
INFO:root:current mean train loss 2001.4506436354823
INFO:root:current train perplexity4.841890811920166
INFO:root:current mean train loss 2001.9309809537542
INFO:root:current train perplexity4.845355987548828
INFO:root:current mean train loss 2003.4683557666324
INFO:root:current train perplexity4.850233554840088
INFO:root:current mean train loss 2002.8742007644923
INFO:root:current train perplexity4.8518571853637695
INFO:root:current mean train loss 2003.253328905159
INFO:root:current train perplexity4.853535175323486
INFO:root:current mean train loss 2003.7843736436632
INFO:root:current train perplexity4.855091094970703

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.86s/it]
INFO:root:final mean train loss: 2003.4502788164732
INFO:root:final train perplexity: 4.855156898498535
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.97s/it]
INFO:root:eval mean loss: 2836.7948822846283
INFO:root:eval perplexity: 10.255326271057129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/24
 24%|â–ˆâ–ˆâ–       | 24/100 [2:10:02<6:51:35, 324.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1917.6471993582588
INFO:root:current train perplexity4.679959297180176
INFO:root:current mean train loss 1964.0476450697283
INFO:root:current train perplexity4.742875099182129
INFO:root:current mean train loss 1975.528598656401
INFO:root:current train perplexity4.769567012786865
INFO:root:current mean train loss 1981.7989672931087
INFO:root:current train perplexity4.790252685546875
INFO:root:current mean train loss 1982.2872458418112
INFO:root:current train perplexity4.787186145782471
INFO:root:current mean train loss 1982.2409504245254
INFO:root:current train perplexity4.784143924713135
INFO:root:current mean train loss 1984.0915320206318
INFO:root:current train perplexity4.79326057434082
INFO:root:current mean train loss 1987.4978072235238
INFO:root:current train perplexity4.803143501281738
INFO:root:current mean train loss 1986.4339697931189
INFO:root:current train perplexity4.799869537353516
INFO:root:current mean train loss 1987.4181111429334
INFO:root:current train perplexity4.801476955413818
INFO:root:current mean train loss 1988.0045130861315
INFO:root:current train perplexity4.806373596191406
INFO:root:current mean train loss 1989.0929227448198
INFO:root:current train perplexity4.806198596954346
INFO:root:current mean train loss 1992.256136688005
INFO:root:current train perplexity4.816100120544434
INFO:root:current mean train loss 1991.8099741625622
INFO:root:current train perplexity4.81396484375
INFO:root:current mean train loss 1991.9450627200215
INFO:root:current train perplexity4.814530372619629
INFO:root:current mean train loss 1993.0393256761415
INFO:root:current train perplexity4.815316677093506
INFO:root:current mean train loss 1994.7912492829223
INFO:root:current train perplexity4.817636013031006
INFO:root:current mean train loss 1994.1302131961227
INFO:root:current train perplexity4.818019390106201
INFO:root:current mean train loss 1994.2523114996584
INFO:root:current train perplexity4.818826675415039
INFO:root:current mean train loss 1993.9378721640255
INFO:root:current train perplexity4.818287372589111

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.35s/it]
INFO:root:final mean train loss: 1993.3398261135176
INFO:root:final train perplexity: 4.8165974617004395
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.13s/it]
INFO:root:eval mean loss: 2839.0048146290824
INFO:root:eval perplexity: 10.273940086364746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/25
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [2:15:20<6:43:37, 322.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1965.8932342529297
INFO:root:current train perplexity4.737214088439941
INFO:root:current mean train loss 1959.456014325542
INFO:root:current train perplexity4.770705223083496
INFO:root:current mean train loss 1971.14056124006
INFO:root:current train perplexity4.781886577606201
INFO:root:current mean train loss 1977.1025360484182
INFO:root:current train perplexity4.768243312835693
INFO:root:current mean train loss 1976.1081456598247
INFO:root:current train perplexity4.764343738555908
INFO:root:current mean train loss 1977.41726568091
INFO:root:current train perplexity4.762226104736328
INFO:root:current mean train loss 1981.0887435521836
INFO:root:current train perplexity4.772078037261963
INFO:root:current mean train loss 1983.3618703599793
INFO:root:current train perplexity4.7793121337890625
INFO:root:current mean train loss 1983.8421456049946
INFO:root:current train perplexity4.77714729309082
INFO:root:current mean train loss 1982.8390566342837
INFO:root:current train perplexity4.771805763244629
INFO:root:current mean train loss 1983.5509234666824
INFO:root:current train perplexity4.778320789337158
INFO:root:current mean train loss 1984.3455295766375
INFO:root:current train perplexity4.775798797607422
INFO:root:current mean train loss 1983.171180475771
INFO:root:current train perplexity4.771203517913818
INFO:root:current mean train loss 1983.3629749678412
INFO:root:current train perplexity4.774419784545898
INFO:root:current mean train loss 1984.3683108211903
INFO:root:current train perplexity4.77649450302124
INFO:root:current mean train loss 1984.6569423725598
INFO:root:current train perplexity4.777231216430664
INFO:root:current mean train loss 1985.3634716466142
INFO:root:current train perplexity4.777917385101318
INFO:root:current mean train loss 1986.4871713589625
INFO:root:current train perplexity4.781332015991211
INFO:root:current mean train loss 1985.5291147064745
INFO:root:current train perplexity4.7827067375183105
INFO:root:current mean train loss 1985.6829752773356
INFO:root:current train perplexity4.782351493835449

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.15s/it]
INFO:root:final mean train loss: 1984.1612106838793
INFO:root:final train perplexity: 4.781856536865234
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.32s/it]
INFO:root:eval mean loss: 2837.597824875657
INFO:root:eval perplexity: 10.262085914611816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/26
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [2:20:38<6:36:27, 321.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1983.3971810689786
INFO:root:current train perplexity4.734996318817139
INFO:root:current mean train loss 1968.583917712489
INFO:root:current train perplexity4.738257884979248
INFO:root:current mean train loss 1970.0745915456432
INFO:root:current train perplexity4.747636795043945
INFO:root:current mean train loss 1979.2012638752062
INFO:root:current train perplexity4.756661891937256
INFO:root:current mean train loss 1972.8721176458864
INFO:root:current train perplexity4.752319812774658
INFO:root:current mean train loss 1975.15174490599
INFO:root:current train perplexity4.754290580749512
INFO:root:current mean train loss 1974.8376830483376
INFO:root:current train perplexity4.754323482513428
INFO:root:current mean train loss 1974.5176469851763
INFO:root:current train perplexity4.755688190460205
INFO:root:current mean train loss 1978.36129314409
INFO:root:current train perplexity4.762121677398682
INFO:root:current mean train loss 1976.5680366216127
INFO:root:current train perplexity4.755429744720459
INFO:root:current mean train loss 1974.5271048861896
INFO:root:current train perplexity4.750820159912109
INFO:root:current mean train loss 1975.9664962460972
INFO:root:current train perplexity4.749530792236328
INFO:root:current mean train loss 1975.9271435979679
INFO:root:current train perplexity4.747373104095459
INFO:root:current mean train loss 1976.3893623323604
INFO:root:current train perplexity4.749881267547607
INFO:root:current mean train loss 1976.770129233578
INFO:root:current train perplexity4.752315044403076
INFO:root:current mean train loss 1976.5199474456015
INFO:root:current train perplexity4.752439022064209
INFO:root:current mean train loss 1975.7942604934349
INFO:root:current train perplexity4.750553131103516
INFO:root:current mean train loss 1975.7726168733845
INFO:root:current train perplexity4.750169277191162
INFO:root:current mean train loss 1975.8977464533966
INFO:root:current train perplexity4.749423980712891
INFO:root:current mean train loss 1976.082540913994
INFO:root:current train perplexity4.749974727630615

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.49s/it]
INFO:root:final mean train loss: 1975.7868522763313
INFO:root:final train perplexity: 4.750378608703613
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.87s/it]
INFO:root:eval mean loss: 2835.6675193259666
INFO:root:eval perplexity: 10.245843887329102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/27
 27%|â–ˆâ–ˆâ–‹       | 27/100 [2:25:57<6:30:12, 320.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1980.6781574117726
INFO:root:current train perplexity4.68471622467041
INFO:root:current mean train loss 1959.6627374962916
INFO:root:current train perplexity4.672762870788574
INFO:root:current mean train loss 1950.6018430724625
INFO:root:current train perplexity4.686517715454102
INFO:root:current mean train loss 1951.8391086002969
INFO:root:current train perplexity4.68671989440918
INFO:root:current mean train loss 1955.195624605537
INFO:root:current train perplexity4.696303844451904
INFO:root:current mean train loss 1960.9233772523942
INFO:root:current train perplexity4.705751419067383
INFO:root:current mean train loss 1962.6902751516789
INFO:root:current train perplexity4.708542346954346
INFO:root:current mean train loss 1963.8080835669525
INFO:root:current train perplexity4.710044860839844
INFO:root:current mean train loss 1964.619814145815
INFO:root:current train perplexity4.71337890625
INFO:root:current mean train loss 1963.9770769027677
INFO:root:current train perplexity4.709657192230225
INFO:root:current mean train loss 1963.293721247711
INFO:root:current train perplexity4.708247661590576
INFO:root:current mean train loss 1964.7261531744184
INFO:root:current train perplexity4.709672927856445
INFO:root:current mean train loss 1966.3121085599041
INFO:root:current train perplexity4.712565898895264
INFO:root:current mean train loss 1966.1075905082153
INFO:root:current train perplexity4.710596561431885
INFO:root:current mean train loss 1966.429520134736
INFO:root:current train perplexity4.712048053741455
INFO:root:current mean train loss 1967.2519688734806
INFO:root:current train perplexity4.7141432762146
INFO:root:current mean train loss 1967.1303890582592
INFO:root:current train perplexity4.713967323303223
INFO:root:current mean train loss 1966.2667339094942
INFO:root:current train perplexity4.711287021636963
INFO:root:current mean train loss 1967.0299571584449
INFO:root:current train perplexity4.71593713760376
INFO:root:current mean train loss 1967.198857401925
INFO:root:current train perplexity4.716182231903076

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.70s/it]
INFO:root:final mean train loss: 1966.938310724163
INFO:root:final train perplexity: 4.717342853546143
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.79s/it]
INFO:root:eval mean loss: 2839.359966656109
INFO:root:eval perplexity: 10.276933670043945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/28
 28%|â–ˆâ–ˆâ–Š       | 28/100 [2:31:20<6:25:29, 321.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1980.558330078125
INFO:root:current train perplexity4.731261730194092
INFO:root:current mean train loss 1966.1952211216517
INFO:root:current train perplexity4.677759647369385
INFO:root:current mean train loss 1961.536121271307
INFO:root:current train perplexity4.678506851196289
INFO:root:current mean train loss 1962.2759212239582
INFO:root:current train perplexity4.687021255493164
INFO:root:current mean train loss 1962.6789761513157
INFO:root:current train perplexity4.6919684410095215
INFO:root:current mean train loss 1957.8284587296196
INFO:root:current train perplexity4.679239749908447
INFO:root:current mean train loss 1957.1095648871528
INFO:root:current train perplexity4.678530693054199
INFO:root:current mean train loss 1960.454330109627
INFO:root:current train perplexity4.685325622558594
INFO:root:current mean train loss 1960.9366474609376
INFO:root:current train perplexity4.685030937194824
INFO:root:current mean train loss 1962.3522310697115
INFO:root:current train perplexity4.685888290405273
INFO:root:current mean train loss 1962.9920563453852
INFO:root:current train perplexity4.68677282333374
INFO:root:current mean train loss 1961.244985767121
INFO:root:current train perplexity4.686964988708496
INFO:root:current mean train loss 1959.278721181832
INFO:root:current train perplexity4.683530807495117
INFO:root:current mean train loss 1958.2529547230113
INFO:root:current train perplexity4.684913635253906
INFO:root:current mean train loss 1958.0977056574418
INFO:root:current train perplexity4.682736873626709
INFO:root:current mean train loss 1959.6579111638146
INFO:root:current train perplexity4.684800148010254
INFO:root:current mean train loss 1959.9446924556903
INFO:root:current train perplexity4.686071395874023
INFO:root:current mean train loss 1959.3415660073724
INFO:root:current train perplexity4.685902118682861
INFO:root:current mean train loss 1959.6172119140624
INFO:root:current train perplexity4.687664031982422
INFO:root:current mean train loss 1959.0814279445215
INFO:root:current train perplexity4.6868367195129395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.93s/it]
INFO:root:final mean train loss: 1958.7651266847304
INFO:root:final train perplexity: 4.687033653259277
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.03s/it]
INFO:root:eval mean loss: 2838.337547508446
INFO:root:eval perplexity: 10.268315315246582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/29
 29%|â–ˆâ–ˆâ–‰       | 29/100 [2:36:38<6:19:11, 320.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1946.6218540357506
INFO:root:current train perplexity4.635623931884766
INFO:root:current mean train loss 1945.2254753112793
INFO:root:current train perplexity4.643862724304199
INFO:root:current mean train loss 1951.6467627956442
INFO:root:current train perplexity4.6420722007751465
INFO:root:current mean train loss 1952.883037333586
INFO:root:current train perplexity4.645168304443359
INFO:root:current mean train loss 1959.7096212743743
INFO:root:current train perplexity4.653902053833008
INFO:root:current mean train loss 1958.7117361120277
INFO:root:current train perplexity4.657146453857422
INFO:root:current mean train loss 1957.8926744405933
INFO:root:current train perplexity4.650346279144287
INFO:root:current mean train loss 1955.726966318458
INFO:root:current train perplexity4.649346351623535
INFO:root:current mean train loss 1956.9496335427323
INFO:root:current train perplexity4.650330543518066
INFO:root:current mean train loss 1956.4419709482502
INFO:root:current train perplexity4.652023792266846
INFO:root:current mean train loss 1955.049573625837
INFO:root:current train perplexity4.648111820220947
INFO:root:current mean train loss 1954.4902003755506
INFO:root:current train perplexity4.649551868438721
INFO:root:current mean train loss 1953.8207878372618
INFO:root:current train perplexity4.648846626281738
INFO:root:current mean train loss 1953.4739128200488
INFO:root:current train perplexity4.651655673980713
INFO:root:current mean train loss 1954.5968474114547
INFO:root:current train perplexity4.654476642608643
INFO:root:current mean train loss 1953.7866717774664
INFO:root:current train perplexity4.6536078453063965
INFO:root:current mean train loss 1952.7210647186207
INFO:root:current train perplexity4.65287971496582
INFO:root:current mean train loss 1950.8449300357274
INFO:root:current train perplexity4.6536173820495605
INFO:root:current mean train loss 1950.7864117289698
INFO:root:current train perplexity4.655611515045166

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.61s/it]
INFO:root:final mean train loss: 1950.399048067017
INFO:root:final train perplexity: 4.656210422515869
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.89s/it]
INFO:root:eval mean loss: 2834.6358726890953
INFO:root:eval perplexity: 10.237173080444336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/30
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [2:41:56<6:13:01, 319.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1889.3296576605903
INFO:root:current train perplexity4.641005516052246
INFO:root:current mean train loss 1925.724781841313
INFO:root:current train perplexity4.610474109649658
INFO:root:current mean train loss 1936.4557901044782
INFO:root:current train perplexity4.615917682647705
INFO:root:current mean train loss 1938.0238037109375
INFO:root:current train perplexity4.627111434936523
INFO:root:current mean train loss 1942.6923980339816
INFO:root:current train perplexity4.623640537261963
INFO:root:current mean train loss 1937.8298440569745
INFO:root:current train perplexity4.607385158538818
INFO:root:current mean train loss 1939.1569990587157
INFO:root:current train perplexity4.61024284362793
INFO:root:current mean train loss 1938.199182593772
INFO:root:current train perplexity4.610583782196045
INFO:root:current mean train loss 1939.4450093612388
INFO:root:current train perplexity4.610353469848633
INFO:root:current mean train loss 1940.2251310946524
INFO:root:current train perplexity4.614184856414795
INFO:root:current mean train loss 1941.691313094261
INFO:root:current train perplexity4.617762565612793
INFO:root:current mean train loss 1941.4703250262412
INFO:root:current train perplexity4.618466377258301
INFO:root:current mean train loss 1941.987579724333
INFO:root:current train perplexity4.62262487411499
INFO:root:current mean train loss 1942.7404690036526
INFO:root:current train perplexity4.624087810516357
INFO:root:current mean train loss 1943.3577315125422
INFO:root:current train perplexity4.623799800872803
INFO:root:current mean train loss 1943.2445557773153
INFO:root:current train perplexity4.625141143798828
INFO:root:current mean train loss 1943.3880804902356
INFO:root:current train perplexity4.625560760498047
INFO:root:current mean train loss 1943.5772915076204
INFO:root:current train perplexity4.628357410430908
INFO:root:current mean train loss 1943.412643204874
INFO:root:current train perplexity4.628992557525635
INFO:root:current mean train loss 1943.2427626180674
INFO:root:current train perplexity4.628880500793457

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.42s/it]
INFO:root:final mean train loss: 1942.863250224565
INFO:root:final train perplexity: 4.628620624542236
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.17s/it]
INFO:root:eval mean loss: 2839.064093879035
INFO:root:eval perplexity: 10.274439811706543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/31
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [2:47:15<6:07:09, 319.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1927.0536733774038
INFO:root:current train perplexity4.589325904846191
INFO:root:current mean train loss 1928.1726917085193
INFO:root:current train perplexity4.571414470672607
INFO:root:current mean train loss 1931.1666319180379
INFO:root:current train perplexity4.573822975158691
INFO:root:current mean train loss 1923.1358642578125
INFO:root:current train perplexity4.5536112785339355
INFO:root:current mean train loss 1923.2449455440324
INFO:root:current train perplexity4.555747985839844
INFO:root:current mean train loss 1926.0395315192045
INFO:root:current train perplexity4.563465595245361
INFO:root:current mean train loss 1927.7147366947258
INFO:root:current train perplexity4.569681167602539
INFO:root:current mean train loss 1930.9177392376355
INFO:root:current train perplexity4.574059009552002
INFO:root:current mean train loss 1934.5460057293244
INFO:root:current train perplexity4.58116340637207
INFO:root:current mean train loss 1932.8391954327249
INFO:root:current train perplexity4.5805463790893555
INFO:root:current mean train loss 1932.8519333510371
INFO:root:current train perplexity4.5853352546691895
INFO:root:current mean train loss 1935.0167702493616
INFO:root:current train perplexity4.593748092651367
INFO:root:current mean train loss 1935.2698386162763
INFO:root:current train perplexity4.596774578094482
INFO:root:current mean train loss 1935.9391554060026
INFO:root:current train perplexity4.596226215362549
INFO:root:current mean train loss 1935.1176364037299
INFO:root:current train perplexity4.598067760467529
INFO:root:current mean train loss 1933.9230195491687
INFO:root:current train perplexity4.598395347595215
INFO:root:current mean train loss 1935.168447046409
INFO:root:current train perplexity4.60115909576416
INFO:root:current mean train loss 1935.9072994793553
INFO:root:current train perplexity4.603107929229736
INFO:root:current mean train loss 1935.4857257287317
INFO:root:current train perplexity4.601246356964111
INFO:root:current mean train loss 1935.6466336354288
INFO:root:current train perplexity4.603057384490967

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.22s/it]
INFO:root:final mean train loss: 1935.8671578904084
INFO:root:final train perplexity: 4.603152275085449
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.02s/it]
INFO:root:eval mean loss: 2840.4106819221565
INFO:root:eval perplexity: 10.285799980163574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/32
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [2:52:31<6:01:00, 318.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1905.7347071448037
INFO:root:current train perplexity4.465522289276123
INFO:root:current mean train loss 1922.178572648055
INFO:root:current train perplexity4.513899326324463
INFO:root:current mean train loss 1929.1944379139338
INFO:root:current train perplexity4.543886184692383
INFO:root:current mean train loss 1928.978328782685
INFO:root:current train perplexity4.552971839904785
INFO:root:current mean train loss 1924.1831082242875
INFO:root:current train perplexity4.548624038696289
INFO:root:current mean train loss 1921.446082015064
INFO:root:current train perplexity4.548108100891113
INFO:root:current mean train loss 1919.1659543050764
INFO:root:current train perplexity4.551276206970215
INFO:root:current mean train loss 1920.597069885336
INFO:root:current train perplexity4.55516242980957
INFO:root:current mean train loss 1921.0436044423748
INFO:root:current train perplexity4.5578742027282715
INFO:root:current mean train loss 1924.4035344209803
INFO:root:current train perplexity4.563292503356934
INFO:root:current mean train loss 1925.1666441174048
INFO:root:current train perplexity4.566425800323486
INFO:root:current mean train loss 1925.4317091894275
INFO:root:current train perplexity4.567359447479248
INFO:root:current mean train loss 1927.0326858729195
INFO:root:current train perplexity4.5691328048706055
INFO:root:current mean train loss 1927.3659035348217
INFO:root:current train perplexity4.5683770179748535
INFO:root:current mean train loss 1927.590448010736
INFO:root:current train perplexity4.569510459899902
INFO:root:current mean train loss 1928.924630323943
INFO:root:current train perplexity4.571012496948242
INFO:root:current mean train loss 1929.6883706146816
INFO:root:current train perplexity4.572088241577148
INFO:root:current mean train loss 1929.0093854771765
INFO:root:current train perplexity4.572704792022705
INFO:root:current mean train loss 1928.694719501895
INFO:root:current train perplexity4.575259685516357
INFO:root:current mean train loss 1929.0056394850908
INFO:root:current train perplexity4.5761284828186035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.03s/it]
INFO:root:final mean train loss: 1928.1311886508959
INFO:root:final train perplexity: 4.57515287399292
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.49s/it]
INFO:root:eval mean loss: 2843.024337081222
INFO:root:eval perplexity: 10.307882308959961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/33
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [2:57:50<5:55:33, 318.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1891.6230529785157
INFO:root:current train perplexity4.478309154510498
INFO:root:current mean train loss 1903.2397956848145
INFO:root:current train perplexity4.527740955352783
INFO:root:current mean train loss 1905.3845792330228
INFO:root:current train perplexity4.5326666831970215
INFO:root:current mean train loss 1907.719384765625
INFO:root:current train perplexity4.536048889160156
INFO:root:current mean train loss 1907.2744581139607
INFO:root:current train perplexity4.539371967315674
INFO:root:current mean train loss 1909.8085364205497
INFO:root:current train perplexity4.537689208984375
INFO:root:current mean train loss 1912.3578038071141
INFO:root:current train perplexity4.543403148651123
INFO:root:current mean train loss 1914.9494320518093
INFO:root:current train perplexity4.54215669631958
INFO:root:current mean train loss 1918.160998393214
INFO:root:current train perplexity4.5449957847595215
INFO:root:current mean train loss 1919.2402333577475
INFO:root:current train perplexity4.542265892028809
INFO:root:current mean train loss 1919.1559568009286
INFO:root:current train perplexity4.542327880859375
INFO:root:current mean train loss 1918.1531502559267
INFO:root:current train perplexity4.541014671325684
INFO:root:current mean train loss 1918.8476443336124
INFO:root:current train perplexity4.543540000915527
INFO:root:current mean train loss 1918.1556073357078
INFO:root:current train perplexity4.542671203613281
INFO:root:current mean train loss 1918.1155204041363
INFO:root:current train perplexity4.541970252990723
INFO:root:current mean train loss 1917.6396846673426
INFO:root:current train perplexity4.542459964752197
INFO:root:current mean train loss 1918.1834614581373
INFO:root:current train perplexity4.543696880340576
INFO:root:current mean train loss 1920.1534787264736
INFO:root:current train perplexity4.546618461608887
INFO:root:current mean train loss 1921.3310481245799
INFO:root:current train perplexity4.549792766571045
INFO:root:current mean train loss 1922.7785612145249
INFO:root:current train perplexity4.554182052612305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.79s/it]
INFO:root:final mean train loss: 1921.946797842698
INFO:root:final train perplexity: 4.552892684936523
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.83s/it]
INFO:root:eval mean loss: 2837.1335522534255
INFO:root:eval perplexity: 10.258174896240234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/34
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [3:03:08<5:50:11, 318.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1931.4751785080155
INFO:root:current train perplexity4.497282981872559
INFO:root:current mean train loss 1923.136959442311
INFO:root:current train perplexity4.507070541381836
INFO:root:current mean train loss 1914.1755115495262
INFO:root:current train perplexity4.5023274421691895
INFO:root:current mean train loss 1912.350848858173
INFO:root:current train perplexity4.505537033081055
INFO:root:current mean train loss 1909.8541252088246
INFO:root:current train perplexity4.511074066162109
INFO:root:current mean train loss 1912.2469674941779
INFO:root:current train perplexity4.517373561859131
INFO:root:current mean train loss 1910.9053677399718
INFO:root:current train perplexity4.512569904327393
INFO:root:current mean train loss 1911.7237190629526
INFO:root:current train perplexity4.509021759033203
INFO:root:current mean train loss 1910.5547078218535
INFO:root:current train perplexity4.506843566894531
INFO:root:current mean train loss 1911.5890865892081
INFO:root:current train perplexity4.511192798614502
INFO:root:current mean train loss 1912.0725532893018
INFO:root:current train perplexity4.514157295227051
INFO:root:current mean train loss 1913.1344686944099
INFO:root:current train perplexity4.516582012176514
INFO:root:current mean train loss 1914.6609772851716
INFO:root:current train perplexity4.522475719451904
INFO:root:current mean train loss 1914.8695000099287
INFO:root:current train perplexity4.523209571838379
INFO:root:current mean train loss 1914.0009707771771
INFO:root:current train perplexity4.522280693054199
INFO:root:current mean train loss 1913.9073397310458
INFO:root:current train perplexity4.521485805511475
INFO:root:current mean train loss 1914.819441411491
INFO:root:current train perplexity4.52378511428833
INFO:root:current mean train loss 1915.0258040978256
INFO:root:current train perplexity4.5247931480407715
INFO:root:current mean train loss 1915.5017865058521
INFO:root:current train perplexity4.527105808258057
INFO:root:current mean train loss 1915.0124149891724
INFO:root:current train perplexity4.5264811515808105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.10s/it]
INFO:root:final mean train loss: 1914.4926725802131
INFO:root:final train perplexity: 4.526206970214844
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.92s/it]
INFO:root:eval mean loss: 2836.6336226363082
INFO:root:eval perplexity: 10.253969192504883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/35
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [3:08:26<5:44:57, 318.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1930.2152761905752
INFO:root:current train perplexity4.544106483459473
INFO:root:current mean train loss 1915.6969082232604
INFO:root:current train perplexity4.509881496429443
INFO:root:current mean train loss 1913.1536952427455
INFO:root:current train perplexity4.495257377624512
INFO:root:current mean train loss 1909.5127956951935
INFO:root:current train perplexity4.487573146820068
INFO:root:current mean train loss 1908.1441153707774
INFO:root:current train perplexity4.496147632598877
INFO:root:current mean train loss 1909.4615363432501
INFO:root:current train perplexity4.497138023376465
INFO:root:current mean train loss 1908.5706723787598
INFO:root:current train perplexity4.499755382537842
INFO:root:current mean train loss 1909.0937286300082
INFO:root:current train perplexity4.496634006500244
INFO:root:current mean train loss 1908.9553704656478
INFO:root:current train perplexity4.499381065368652
INFO:root:current mean train loss 1907.3372792909802
INFO:root:current train perplexity4.497077941894531
INFO:root:current mean train loss 1909.4602767135368
INFO:root:current train perplexity4.501022815704346
INFO:root:current mean train loss 1910.4687273035097
INFO:root:current train perplexity4.50065803527832
INFO:root:current mean train loss 1910.0610501556162
INFO:root:current train perplexity4.504239559173584
INFO:root:current mean train loss 1910.387260973368
INFO:root:current train perplexity4.504549026489258
INFO:root:current mean train loss 1910.543831004356
INFO:root:current train perplexity4.504443168640137
INFO:root:current mean train loss 1909.077196453865
INFO:root:current train perplexity4.502075672149658
INFO:root:current mean train loss 1908.6495236663638
INFO:root:current train perplexity4.501916408538818
INFO:root:current mean train loss 1909.4185024163662
INFO:root:current train perplexity4.504132270812988
INFO:root:current mean train loss 1909.3169722592315
INFO:root:current train perplexity4.505227088928223

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.68s/it]
INFO:root:final mean train loss: 1908.7439152289087
INFO:root:final train perplexity: 4.50573205947876
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.72s/it]
INFO:root:eval mean loss: 2843.1509375586525
INFO:root:eval perplexity: 10.308954238891602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/36
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [3:13:43<5:39:11, 318.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1924.242842240767
INFO:root:current train perplexity4.559015274047852
INFO:root:current mean train loss 1887.429293795749
INFO:root:current train perplexity4.4728899002075195
INFO:root:current mean train loss 1881.0513001934612
INFO:root:current train perplexity4.439953327178955
INFO:root:current mean train loss 1888.214926176899
INFO:root:current train perplexity4.456270217895508
INFO:root:current mean train loss 1890.654028082706
INFO:root:current train perplexity4.446678638458252
INFO:root:current mean train loss 1893.9166276487585
INFO:root:current train perplexity4.4589056968688965
INFO:root:current mean train loss 1897.3508160929828
INFO:root:current train perplexity4.467358112335205
INFO:root:current mean train loss 1897.6536576798194
INFO:root:current train perplexity4.466546058654785
INFO:root:current mean train loss 1895.4612615658234
INFO:root:current train perplexity4.4657087326049805
INFO:root:current mean train loss 1894.5132308943212
INFO:root:current train perplexity4.467021942138672
INFO:root:current mean train loss 1895.01124507855
INFO:root:current train perplexity4.468286037445068
INFO:root:current mean train loss 1895.129655482638
INFO:root:current train perplexity4.4698638916015625
INFO:root:current mean train loss 1896.679314232975
INFO:root:current train perplexity4.470816612243652
INFO:root:current mean train loss 1896.043799777871
INFO:root:current train perplexity4.4705305099487305
INFO:root:current mean train loss 1899.3564059489336
INFO:root:current train perplexity4.473268985748291
INFO:root:current mean train loss 1899.6233110509907
INFO:root:current train perplexity4.475996017456055
INFO:root:current mean train loss 1900.7121252418674
INFO:root:current train perplexity4.478342533111572
INFO:root:current mean train loss 1901.5980908088975
INFO:root:current train perplexity4.478041172027588
INFO:root:current mean train loss 1901.8213063855649
INFO:root:current train perplexity4.479559898376465
INFO:root:current mean train loss 1901.6241218730581
INFO:root:current train perplexity4.479415416717529

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.15s/it]
INFO:root:final mean train loss: 1902.0491443505146
INFO:root:final train perplexity: 4.482004642486572
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.30s/it]
INFO:root:eval mean loss: 2841.001835820195
INFO:root:eval perplexity: 10.290789604187012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/37
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [3:19:07<5:35:38, 319.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1881.3865618024554
INFO:root:current train perplexity4.399863243103027
INFO:root:current mean train loss 1886.484203338623
INFO:root:current train perplexity4.427264213562012
INFO:root:current mean train loss 1886.287279630962
INFO:root:current train perplexity4.419334888458252
INFO:root:current mean train loss 1879.9697209800163
INFO:root:current train perplexity4.414035797119141
INFO:root:current mean train loss 1880.1378088264821
INFO:root:current train perplexity4.420767784118652
INFO:root:current mean train loss 1883.4401504054215
INFO:root:current train perplexity4.431629180908203
INFO:root:current mean train loss 1885.0279368017889
INFO:root:current train perplexity4.434817314147949
INFO:root:current mean train loss 1884.1658759483923
INFO:root:current train perplexity4.43572998046875
INFO:root:current mean train loss 1884.8218590188142
INFO:root:current train perplexity4.440635681152344
INFO:root:current mean train loss 1885.3090818997086
INFO:root:current train perplexity4.442779064178467
INFO:root:current mean train loss 1887.6685944197243
INFO:root:current train perplexity4.444728851318359
INFO:root:current mean train loss 1888.7892400863323
INFO:root:current train perplexity4.444128036499023
INFO:root:current mean train loss 1888.4708102844438
INFO:root:current train perplexity4.446161270141602
INFO:root:current mean train loss 1889.5736596900297
INFO:root:current train perplexity4.447160720825195
INFO:root:current mean train loss 1889.1075479630329
INFO:root:current train perplexity4.4470109939575195
INFO:root:current mean train loss 1891.311722920203
INFO:root:current train perplexity4.451272487640381
INFO:root:current mean train loss 1894.0196156794668
INFO:root:current train perplexity4.455689907073975
INFO:root:current mean train loss 1895.624866132383
INFO:root:current train perplexity4.457385540008545
INFO:root:current mean train loss 1896.3224649575398
INFO:root:current train perplexity4.459293365478516
INFO:root:current mean train loss 1896.107810815835
INFO:root:current train perplexity4.458746433258057

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.05s/it]
INFO:root:final mean train loss: 1895.534449374862
INFO:root:final train perplexity: 4.459035873413086
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.86s/it]
INFO:root:eval mean loss: 2845.4716738222596
INFO:root:eval perplexity: 10.328605651855469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/38
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [3:24:24<5:29:38, 319.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1867.4256076388888
INFO:root:current train perplexity4.408102512359619
INFO:root:current mean train loss 1889.0620504445044
INFO:root:current train perplexity4.415529727935791
INFO:root:current mean train loss 1892.9296605947065
INFO:root:current train perplexity4.427128314971924
INFO:root:current mean train loss 1886.29428180197
INFO:root:current train perplexity4.42151403427124
INFO:root:current mean train loss 1887.9696311007724
INFO:root:current train perplexity4.424086570739746
INFO:root:current mean train loss 1886.5048324164995
INFO:root:current train perplexity4.422676086425781
INFO:root:current mean train loss 1886.9618866203368
INFO:root:current train perplexity4.420754432678223
INFO:root:current mean train loss 1885.1966123440122
INFO:root:current train perplexity4.416672229766846
INFO:root:current mean train loss 1886.5904730260725
INFO:root:current train perplexity4.417779445648193
INFO:root:current mean train loss 1886.5847999855323
INFO:root:current train perplexity4.417632102966309
INFO:root:current mean train loss 1887.0835604580966
INFO:root:current train perplexity4.421278953552246
INFO:root:current mean train loss 1888.6521192259142
INFO:root:current train perplexity4.426020622253418
INFO:root:current mean train loss 1889.1846596346322
INFO:root:current train perplexity4.428649425506592
INFO:root:current mean train loss 1887.7733907593226
INFO:root:current train perplexity4.430773735046387
INFO:root:current mean train loss 1889.218293313419
INFO:root:current train perplexity4.431706428527832
INFO:root:current mean train loss 1889.490991843017
INFO:root:current train perplexity4.432519435882568
INFO:root:current mean train loss 1889.8490431023224
INFO:root:current train perplexity4.433525085449219
INFO:root:current mean train loss 1890.4702621328797
INFO:root:current train perplexity4.435230255126953
INFO:root:current mean train loss 1890.6350741420013
INFO:root:current train perplexity4.436842918395996
INFO:root:current mean train loss 1890.457221416091
INFO:root:current train perplexity4.437710285186768

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.60s/it]
INFO:root:final mean train loss: 1890.0327342962053
INFO:root:final train perplexity: 4.4397292137146
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.86s/it]
INFO:root:eval mean loss: 2843.48266821509
INFO:root:eval perplexity: 10.311758995056152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/39
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [3:30:01<5:29:47, 324.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1868.788339922505
INFO:root:current train perplexity4.379629611968994
INFO:root:current mean train loss 1873.0526627905574
INFO:root:current train perplexity4.384192943572998
INFO:root:current mean train loss 1879.2966928263656
INFO:root:current train perplexity4.385910511016846
INFO:root:current mean train loss 1879.7744676790185
INFO:root:current train perplexity4.389902591705322
INFO:root:current mean train loss 1875.901958779339
INFO:root:current train perplexity4.3919758796691895
INFO:root:current mean train loss 1878.5815027854621
INFO:root:current train perplexity4.404998302459717
INFO:root:current mean train loss 1878.8858743996059
INFO:root:current train perplexity4.407901763916016
INFO:root:current mean train loss 1879.1333105532829
INFO:root:current train perplexity4.408281326293945
INFO:root:current mean train loss 1881.4102447580572
INFO:root:current train perplexity4.4141716957092285
INFO:root:current mean train loss 1880.7013513005945
INFO:root:current train perplexity4.41400146484375
INFO:root:current mean train loss 1882.1709014260387
INFO:root:current train perplexity4.412820339202881
INFO:root:current mean train loss 1882.1579734815377
INFO:root:current train perplexity4.409905433654785
INFO:root:current mean train loss 1881.2486906943343
INFO:root:current train perplexity4.408921241760254
INFO:root:current mean train loss 1882.4084906445025
INFO:root:current train perplexity4.412657260894775
INFO:root:current mean train loss 1882.1719735246024
INFO:root:current train perplexity4.415406227111816
INFO:root:current mean train loss 1883.1952482606935
INFO:root:current train perplexity4.416927814483643
INFO:root:current mean train loss 1884.0320604234826
INFO:root:current train perplexity4.4174275398254395
INFO:root:current mean train loss 1884.147218321022
INFO:root:current train perplexity4.418208599090576
INFO:root:current mean train loss 1884.683172797542
INFO:root:current train perplexity4.418596267700195
INFO:root:current mean train loss 1884.8690524631077
INFO:root:current train perplexity4.418603897094727

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.43s/it]
INFO:root:final mean train loss: 1884.2127858218194
INFO:root:final train perplexity: 4.419398307800293
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.85s/it]
INFO:root:eval mean loss: 2845.783840236721
INFO:root:eval perplexity: 10.33125114440918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/40
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [3:35:19<5:22:26, 322.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1874.4306300682358
INFO:root:current train perplexity4.397569179534912
INFO:root:current mean train loss 1880.1449117820357
INFO:root:current train perplexity4.3917999267578125
INFO:root:current mean train loss 1876.9833328082998
INFO:root:current train perplexity4.391177654266357
INFO:root:current mean train loss 1876.4983940829072
INFO:root:current train perplexity4.394931793212891
INFO:root:current mean train loss 1874.9966393711672
INFO:root:current train perplexity4.394372463226318
INFO:root:current mean train loss 1877.483894308614
INFO:root:current train perplexity4.389153957366943
INFO:root:current mean train loss 1877.6253038274347
INFO:root:current train perplexity4.388430595397949
INFO:root:current mean train loss 1880.1229049036224
INFO:root:current train perplexity4.3959784507751465
INFO:root:current mean train loss 1879.2251998675697
INFO:root:current train perplexity4.395909786224365
INFO:root:current mean train loss 1879.8844383169608
INFO:root:current train perplexity4.397086143493652
INFO:root:current mean train loss 1880.306241379279
INFO:root:current train perplexity4.397151947021484
INFO:root:current mean train loss 1879.9696404195822
INFO:root:current train perplexity4.3996710777282715
INFO:root:current mean train loss 1880.7982352393228
INFO:root:current train perplexity4.398367404937744
INFO:root:current mean train loss 1882.1333777059067
INFO:root:current train perplexity4.404080867767334
INFO:root:current mean train loss 1882.6374744469447
INFO:root:current train perplexity4.4052934646606445
INFO:root:current mean train loss 1881.3686779329034
INFO:root:current train perplexity4.404694557189941
INFO:root:current mean train loss 1880.4879237635637
INFO:root:current train perplexity4.401180267333984
INFO:root:current mean train loss 1879.3265478982223
INFO:root:current train perplexity4.400184631347656
INFO:root:current mean train loss 1879.0001054391257
INFO:root:current train perplexity4.400686264038086
INFO:root:current mean train loss 1879.1380771291924
INFO:root:current train perplexity4.399942874908447

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.44s/it]
INFO:root:final mean train loss: 1878.579405661009
INFO:root:final train perplexity: 4.399806976318359
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.83s/it]
INFO:root:eval mean loss: 2845.9910254492775
INFO:root:eval perplexity: 10.333006858825684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/41
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [3:40:37<5:15:42, 321.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1855.9257253011067
INFO:root:current train perplexity4.333703517913818
INFO:root:current mean train loss 1855.917885293766
INFO:root:current train perplexity4.333714008331299
INFO:root:current mean train loss 1862.2337044380806
INFO:root:current train perplexity4.351664066314697
INFO:root:current mean train loss 1864.4010364262745
INFO:root:current train perplexity4.3550333976745605
INFO:root:current mean train loss 1863.2953247562532
INFO:root:current train perplexity4.359531879425049
INFO:root:current mean train loss 1866.0568974642144
INFO:root:current train perplexity4.35429573059082
INFO:root:current mean train loss 1862.965422005489
INFO:root:current train perplexity4.350766181945801
INFO:root:current mean train loss 1864.6064253763936
INFO:root:current train perplexity4.3559722900390625
INFO:root:current mean train loss 1866.0923493249077
INFO:root:current train perplexity4.3587799072265625
INFO:root:current mean train loss 1866.1290234178903
INFO:root:current train perplexity4.360792636871338
INFO:root:current mean train loss 1866.4336142435561
INFO:root:current train perplexity4.356961727142334
INFO:root:current mean train loss 1867.6353469899666
INFO:root:current train perplexity4.359362602233887
INFO:root:current mean train loss 1869.598509894477
INFO:root:current train perplexity4.363306999206543
INFO:root:current mean train loss 1869.674407434327
INFO:root:current train perplexity4.366253852844238
INFO:root:current mean train loss 1870.6552417775526
INFO:root:current train perplexity4.3700408935546875
INFO:root:current mean train loss 1873.2523270609386
INFO:root:current train perplexity4.37460994720459
INFO:root:current mean train loss 1873.5889623390053
INFO:root:current train perplexity4.376768589019775
INFO:root:current mean train loss 1873.3840786736366
INFO:root:current train perplexity4.377514362335205
INFO:root:current mean train loss 1873.8325500488281
INFO:root:current train perplexity4.379289627075195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.89s/it]
INFO:root:final mean train loss: 1873.0494291196853
INFO:root:final train perplexity: 4.380660533905029
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.01s/it]
INFO:root:eval mean loss: 2848.499820377018
INFO:root:eval perplexity: 10.354299545288086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/42
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [3:46:14<5:14:56, 325.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1878.597412109375
INFO:root:current train perplexity4.4481987953186035
INFO:root:current mean train loss 1853.9475248893805
INFO:root:current train perplexity4.374044418334961
INFO:root:current mean train loss 1851.7188921288146
INFO:root:current train perplexity4.354874134063721
INFO:root:current mean train loss 1856.07153905314
INFO:root:current train perplexity4.340654373168945
INFO:root:current mean train loss 1855.4538337762938
INFO:root:current train perplexity4.340550422668457
INFO:root:current mean train loss 1858.629975614492
INFO:root:current train perplexity4.338296413421631
INFO:root:current mean train loss 1859.8631771019193
INFO:root:current train perplexity4.345616340637207
INFO:root:current mean train loss 1863.041627517422
INFO:root:current train perplexity4.345945358276367
INFO:root:current mean train loss 1862.5524981922183
INFO:root:current train perplexity4.349151611328125
INFO:root:current mean train loss 1864.3148127845188
INFO:root:current train perplexity4.348172664642334
INFO:root:current mean train loss 1865.897982357285
INFO:root:current train perplexity4.350993633270264
INFO:root:current mean train loss 1866.4040492247163
INFO:root:current train perplexity4.354856014251709
INFO:root:current mean train loss 1866.765243089995
INFO:root:current train perplexity4.35786247253418
INFO:root:current mean train loss 1866.7028062040354
INFO:root:current train perplexity4.357119083404541
INFO:root:current mean train loss 1868.3123848409577
INFO:root:current train perplexity4.36011266708374
INFO:root:current mean train loss 1868.159782616413
INFO:root:current train perplexity4.3609113693237305
INFO:root:current mean train loss 1866.7125113972654
INFO:root:current train perplexity4.356420040130615
INFO:root:current mean train loss 1867.22706973671
INFO:root:current train perplexity4.358617782592773
INFO:root:current mean train loss 1866.5689780755524
INFO:root:current train perplexity4.357264041900635
INFO:root:current mean train loss 1867.7204947823077
INFO:root:current train perplexity4.360323429107666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.45s/it]
INFO:root:final mean train loss: 1867.6936539935152
INFO:root:final train perplexity: 4.36219596862793
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.10s/it]
INFO:root:eval mean loss: 2848.7857354424737
INFO:root:eval perplexity: 10.356729507446289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/43
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [3:51:32<5:07:19, 323.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1876.495255533854
INFO:root:current train perplexity4.383749485015869
INFO:root:current mean train loss 1862.2764432466947
INFO:root:current train perplexity4.328893661499023
INFO:root:current mean train loss 1870.6407083262568
INFO:root:current train perplexity4.346643924713135
INFO:root:current mean train loss 1867.315056448272
INFO:root:current train perplexity4.331071376800537
INFO:root:current mean train loss 1863.7283620435137
INFO:root:current train perplexity4.332544326782227
INFO:root:current mean train loss 1863.9639058814857
INFO:root:current train perplexity4.327929973602295
INFO:root:current mean train loss 1861.9303964766245
INFO:root:current train perplexity4.328831195831299
INFO:root:current mean train loss 1862.6613292955371
INFO:root:current train perplexity4.331654071807861
INFO:root:current mean train loss 1864.2806637683548
INFO:root:current train perplexity4.33201789855957
INFO:root:current mean train loss 1864.167947748656
INFO:root:current train perplexity4.333229064941406
INFO:root:current mean train loss 1862.9967254342384
INFO:root:current train perplexity4.333755016326904
INFO:root:current mean train loss 1863.3945354630462
INFO:root:current train perplexity4.335638046264648
INFO:root:current mean train loss 1863.677195379986
INFO:root:current train perplexity4.338150501251221
INFO:root:current mean train loss 1863.317950852473
INFO:root:current train perplexity4.337441444396973
INFO:root:current mean train loss 1863.7998460889696
INFO:root:current train perplexity4.340862274169922
INFO:root:current mean train loss 1862.4426771375868
INFO:root:current train perplexity4.339854717254639
INFO:root:current mean train loss 1862.5358841784894
INFO:root:current train perplexity4.343307018280029
INFO:root:current mean train loss 1863.35995204683
INFO:root:current train perplexity4.343555927276611
INFO:root:current mean train loss 1863.2159574581626
INFO:root:current train perplexity4.3448486328125
INFO:root:current mean train loss 1862.50716350338
INFO:root:current train perplexity4.342777252197266

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.21s/it]
INFO:root:final mean train loss: 1862.4935342131753
INFO:root:final train perplexity: 4.344343185424805
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.27s/it]
INFO:root:eval mean loss: 2850.8490353146117
INFO:root:eval perplexity: 10.37427806854248
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/44
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [3:56:51<5:00:41, 322.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1850.7738660447142
INFO:root:current train perplexity4.3224639892578125
INFO:root:current mean train loss 1832.6412212345876
INFO:root:current train perplexity4.279891490936279
INFO:root:current mean train loss 1844.8839511639676
INFO:root:current train perplexity4.2829813957214355
INFO:root:current mean train loss 1852.9813686227935
INFO:root:current train perplexity4.3115973472595215
INFO:root:current mean train loss 1852.9606349185542
INFO:root:current train perplexity4.310059547424316
INFO:root:current mean train loss 1853.4439079103347
INFO:root:current train perplexity4.312523365020752
INFO:root:current mean train loss 1853.6640287278424
INFO:root:current train perplexity4.315401077270508
INFO:root:current mean train loss 1853.6846232586597
INFO:root:current train perplexity4.306783676147461
INFO:root:current mean train loss 1856.7988106863838
INFO:root:current train perplexity4.315330982208252
INFO:root:current mean train loss 1856.9633362396467
INFO:root:current train perplexity4.313241481781006
INFO:root:current mean train loss 1856.5770018831706
INFO:root:current train perplexity4.317928314208984
INFO:root:current mean train loss 1858.2572487629072
INFO:root:current train perplexity4.3207573890686035
INFO:root:current mean train loss 1856.511214904051
INFO:root:current train perplexity4.319373607635498
INFO:root:current mean train loss 1855.1660293998236
INFO:root:current train perplexity4.3177666664123535
INFO:root:current mean train loss 1856.147749789435
INFO:root:current train perplexity4.319400310516357
INFO:root:current mean train loss 1857.5358223104447
INFO:root:current train perplexity4.325973987579346
INFO:root:current mean train loss 1856.8984876029333
INFO:root:current train perplexity4.32537317276001
INFO:root:current mean train loss 1856.7866524672877
INFO:root:current train perplexity4.324131011962891
INFO:root:current mean train loss 1857.2432789288796
INFO:root:current train perplexity4.325689792633057
INFO:root:current mean train loss 1858.617722364836
INFO:root:current train perplexity4.329096794128418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.30s/it]
INFO:root:final mean train loss: 1857.9244673474534
INFO:root:final train perplexity: 4.328716278076172
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.82s/it]
INFO:root:eval mean loss: 2851.4028598911414
INFO:root:eval perplexity: 10.378995895385742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/45
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [4:02:09<4:54:05, 320.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1844.4817504882812
INFO:root:current train perplexity4.281170845031738
INFO:root:current mean train loss 1852.7984864769912
INFO:root:current train perplexity4.293843746185303
INFO:root:current mean train loss 1852.3711742054331
INFO:root:current train perplexity4.301935195922852
INFO:root:current mean train loss 1853.7515654511503
INFO:root:current train perplexity4.320191383361816
INFO:root:current mean train loss 1852.57345817829
INFO:root:current train perplexity4.310835361480713
INFO:root:current mean train loss 1851.4846022585605
INFO:root:current train perplexity4.308035850524902
INFO:root:current mean train loss 1849.0567066238586
INFO:root:current train perplexity4.30308198928833
INFO:root:current mean train loss 1848.539959013774
INFO:root:current train perplexity4.30421257019043
INFO:root:current mean train loss 1850.7356640851056
INFO:root:current train perplexity4.307434558868408
INFO:root:current mean train loss 1851.9742649442428
INFO:root:current train perplexity4.309837341308594
INFO:root:current mean train loss 1850.587012728354
INFO:root:current train perplexity4.309136390686035
INFO:root:current mean train loss 1851.7289013420184
INFO:root:current train perplexity4.308136463165283
INFO:root:current mean train loss 1852.836399995828
INFO:root:current train perplexity4.308997631072998
INFO:root:current mean train loss 1854.039909743144
INFO:root:current train perplexity4.309350967407227
INFO:root:current mean train loss 1854.8289397192782
INFO:root:current train perplexity4.309026718139648
INFO:root:current mean train loss 1854.4100600142613
INFO:root:current train perplexity4.308337211608887
INFO:root:current mean train loss 1853.3812152422393
INFO:root:current train perplexity4.310041427612305
INFO:root:current mean train loss 1853.4191324316184
INFO:root:current train perplexity4.3098344802856445
INFO:root:current mean train loss 1853.0957783711315
INFO:root:current train perplexity4.3106560707092285
INFO:root:current mean train loss 1853.0393533182241
INFO:root:current train perplexity4.309852123260498

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.89s/it]
INFO:root:final mean train loss: 1852.3574183046126
INFO:root:final train perplexity: 4.30975341796875
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.72s/it]
INFO:root:eval mean loss: 2851.222483958568
INFO:root:eval perplexity: 10.377459526062012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/46
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [4:07:27<4:48:02, 320.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1855.729059666763
INFO:root:current train perplexity4.30009651184082
INFO:root:current mean train loss 1854.6740830563708
INFO:root:current train perplexity4.286670684814453
INFO:root:current mean train loss 1853.7889360855484
INFO:root:current train perplexity4.284465312957764
INFO:root:current mean train loss 1852.4988017244914
INFO:root:current train perplexity4.279649257659912
INFO:root:current mean train loss 1848.2607353353203
INFO:root:current train perplexity4.279519557952881
INFO:root:current mean train loss 1849.1415626932956
INFO:root:current train perplexity4.28323221206665
INFO:root:current mean train loss 1850.0207227351207
INFO:root:current train perplexity4.291321754455566
INFO:root:current mean train loss 1851.3711859670095
INFO:root:current train perplexity4.292115211486816
INFO:root:current mean train loss 1853.8880079011776
INFO:root:current train perplexity4.294032573699951
INFO:root:current mean train loss 1851.0859085067455
INFO:root:current train perplexity4.292135715484619
INFO:root:current mean train loss 1850.993495944691
INFO:root:current train perplexity4.292568206787109
INFO:root:current mean train loss 1851.0902969915921
INFO:root:current train perplexity4.292943000793457
INFO:root:current mean train loss 1851.3685200770883
INFO:root:current train perplexity4.2963666915893555
INFO:root:current mean train loss 1850.752994390953
INFO:root:current train perplexity4.296084403991699
INFO:root:current mean train loss 1850.1064753973508
INFO:root:current train perplexity4.296459197998047
INFO:root:current mean train loss 1848.7440220291746
INFO:root:current train perplexity4.293878555297852
INFO:root:current mean train loss 1849.047408522062
INFO:root:current train perplexity4.292917251586914
INFO:root:current mean train loss 1849.0295932433498
INFO:root:current train perplexity4.294189929962158
INFO:root:current mean train loss 1848.010450996914
INFO:root:current train perplexity4.293690204620361
INFO:root:current mean train loss 1848.6257237949978
INFO:root:current train perplexity4.295167922973633

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.21s/it]
INFO:root:final mean train loss: 1848.0063176773078
INFO:root:final train perplexity: 4.294988632202148
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.98s/it]
INFO:root:eval mean loss: 2856.694873340137
INFO:root:eval perplexity: 10.424165725708008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/47
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [4:12:45<4:42:06, 319.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1841.8163937938457
INFO:root:current train perplexity4.238670825958252
INFO:root:current mean train loss 1840.8025759302004
INFO:root:current train perplexity4.245514392852783
INFO:root:current mean train loss 1839.4788310415793
INFO:root:current train perplexity4.264269828796387
INFO:root:current mean train loss 1836.6704386802176
INFO:root:current train perplexity4.261599063873291
INFO:root:current mean train loss 1838.5120138758157
INFO:root:current train perplexity4.26255464553833
INFO:root:current mean train loss 1838.3972300653872
INFO:root:current train perplexity4.262073993682861
INFO:root:current mean train loss 1841.847379405724
INFO:root:current train perplexity4.270570755004883
INFO:root:current mean train loss 1842.001531079897
INFO:root:current train perplexity4.273842811584473
INFO:root:current mean train loss 1842.8319165202186
INFO:root:current train perplexity4.276782512664795
INFO:root:current mean train loss 1841.341841642269
INFO:root:current train perplexity4.273862361907959
INFO:root:current mean train loss 1843.2750288610684
INFO:root:current train perplexity4.273477077484131
INFO:root:current mean train loss 1843.7856745903002
INFO:root:current train perplexity4.2757887840271
INFO:root:current mean train loss 1841.9148827598349
INFO:root:current train perplexity4.273210525512695
INFO:root:current mean train loss 1842.5548018863444
INFO:root:current train perplexity4.276157855987549
INFO:root:current mean train loss 1842.5788854540428
INFO:root:current train perplexity4.277798652648926
INFO:root:current mean train loss 1843.109301436977
INFO:root:current train perplexity4.280614376068115
INFO:root:current mean train loss 1843.3418909079617
INFO:root:current train perplexity4.280827045440674
INFO:root:current mean train loss 1843.502194346257
INFO:root:current train perplexity4.2804274559021
INFO:root:current mean train loss 1843.607019390271
INFO:root:current train perplexity4.279847145080566

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.07s/it]
INFO:root:final mean train loss: 1843.6720959946656
INFO:root:final train perplexity: 4.280333042144775
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.62s/it]
INFO:root:eval mean loss: 2856.1157351198854
INFO:root:eval perplexity: 10.41921329498291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/48
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [4:18:02<4:36:14, 318.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1778.2798502604167
INFO:root:current train perplexity4.045098304748535
INFO:root:current mean train loss 1836.4384893002718
INFO:root:current train perplexity4.250788688659668
INFO:root:current mean train loss 1840.1743964616642
INFO:root:current train perplexity4.240701198577881
INFO:root:current mean train loss 1837.3743919735864
INFO:root:current train perplexity4.23369836807251
INFO:root:current mean train loss 1839.9700462984752
INFO:root:current train perplexity4.241438865661621
INFO:root:current mean train loss 1836.0411000075849
INFO:root:current train perplexity4.233773708343506
INFO:root:current mean train loss 1832.7820487169715
INFO:root:current train perplexity4.233152866363525
INFO:root:current mean train loss 1834.4491596782125
INFO:root:current train perplexity4.241279602050781
INFO:root:current mean train loss 1833.802026816526
INFO:root:current train perplexity4.2444658279418945
INFO:root:current mean train loss 1832.9022522306182
INFO:root:current train perplexity4.246128559112549
INFO:root:current mean train loss 1835.0486912619303
INFO:root:current train perplexity4.250436782836914
INFO:root:current mean train loss 1836.112143094871
INFO:root:current train perplexity4.248068332672119
INFO:root:current mean train loss 1837.0977517963927
INFO:root:current train perplexity4.248012542724609
INFO:root:current mean train loss 1837.4063161871732
INFO:root:current train perplexity4.249955177307129
INFO:root:current mean train loss 1836.826848222173
INFO:root:current train perplexity4.251943111419678
INFO:root:current mean train loss 1836.5534439943017
INFO:root:current train perplexity4.255065441131592
INFO:root:current mean train loss 1837.3874267578126
INFO:root:current train perplexity4.256263732910156
INFO:root:current mean train loss 1837.1141662775601
INFO:root:current train perplexity4.257387161254883
INFO:root:current mean train loss 1838.0173949859031
INFO:root:current train perplexity4.258865833282471
INFO:root:current mean train loss 1838.2356063484212
INFO:root:current train perplexity4.261777877807617

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.54s/it]
INFO:root:final mean train loss: 1838.8740294702234
INFO:root:final train perplexity: 4.264166355133057
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 32.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 32.00s/it]
INFO:root:eval mean loss: 2856.846901833474
INFO:root:eval perplexity: 10.42546558380127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/49
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [4:23:19<4:30:31, 318.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1855.2835273742676
INFO:root:current train perplexity4.289453029632568
INFO:root:current mean train loss 1833.6907663056345
INFO:root:current train perplexity4.207379341125488
INFO:root:current mean train loss 1829.4899918128704
INFO:root:current train perplexity4.2048726081848145
INFO:root:current mean train loss 1831.3511084131449
INFO:root:current train perplexity4.217433929443359
INFO:root:current mean train loss 1832.6655016298648
INFO:root:current train perplexity4.224543571472168
INFO:root:current mean train loss 1830.4737569479119
INFO:root:current train perplexity4.230594635009766
INFO:root:current mean train loss 1830.9095845282832
INFO:root:current train perplexity4.235071659088135
INFO:root:current mean train loss 1831.9883683001408
INFO:root:current train perplexity4.238028049468994
INFO:root:current mean train loss 1831.272917674138
INFO:root:current train perplexity4.237431526184082
INFO:root:current mean train loss 1831.9624832873692
INFO:root:current train perplexity4.240623950958252
INFO:root:current mean train loss 1831.1306132235268
INFO:root:current train perplexity4.239081382751465
INFO:root:current mean train loss 1833.1212580920107
INFO:root:current train perplexity4.2418293952941895
INFO:root:current mean train loss 1833.5686048037046
INFO:root:current train perplexity4.242246627807617
INFO:root:current mean train loss 1832.482163712785
INFO:root:current train perplexity4.240331649780273
INFO:root:current mean train loss 1832.144128128137
INFO:root:current train perplexity4.240823268890381
INFO:root:current mean train loss 1832.3350437253946
INFO:root:current train perplexity4.240872859954834
INFO:root:current mean train loss 1833.5414876002892
INFO:root:current train perplexity4.243307113647461
INFO:root:current mean train loss 1832.9307113541743
INFO:root:current train perplexity4.243803024291992
INFO:root:current mean train loss 1834.2222589884263
INFO:root:current train perplexity4.246209621429443
INFO:root:current mean train loss 1834.0756801818468
INFO:root:current train perplexity4.2476396560668945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.58s/it]
INFO:root:final mean train loss: 1834.5890321024608
INFO:root:final train perplexity: 4.249780178070068
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.63s/it]
INFO:root:eval mean loss: 2860.228956984328
INFO:root:eval perplexity: 10.454438209533691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/50
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [4:28:37<4:25:05, 318.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1804.1056232063138
INFO:root:current train perplexity4.177927017211914
INFO:root:current mean train loss 1818.1346869756712
INFO:root:current train perplexity4.169137001037598
INFO:root:current mean train loss 1819.2523869893637
INFO:root:current train perplexity4.190735816955566
INFO:root:current mean train loss 1821.6027660643133
INFO:root:current train perplexity4.202380180358887
INFO:root:current mean train loss 1826.5927304818
INFO:root:current train perplexity4.205329418182373
INFO:root:current mean train loss 1826.9391393887324
INFO:root:current train perplexity4.208387851715088
INFO:root:current mean train loss 1824.8497989695686
INFO:root:current train perplexity4.209532737731934
INFO:root:current mean train loss 1826.4462530444239
INFO:root:current train perplexity4.213052749633789
INFO:root:current mean train loss 1826.098599742804
INFO:root:current train perplexity4.212497234344482
INFO:root:current mean train loss 1828.36561512118
INFO:root:current train perplexity4.219413757324219
INFO:root:current mean train loss 1829.3556786783545
INFO:root:current train perplexity4.225522041320801
INFO:root:current mean train loss 1829.1441993547378
INFO:root:current train perplexity4.228765487670898
INFO:root:current mean train loss 1829.271129892195
INFO:root:current train perplexity4.23172664642334
INFO:root:current mean train loss 1827.7655567709298
INFO:root:current train perplexity4.229520320892334
INFO:root:current mean train loss 1827.3859827056106
INFO:root:current train perplexity4.229125499725342
INFO:root:current mean train loss 1827.382851430106
INFO:root:current train perplexity4.229406833648682
INFO:root:current mean train loss 1827.8599753579347
INFO:root:current train perplexity4.230673789978027
INFO:root:current mean train loss 1828.3064506447881
INFO:root:current train perplexity4.232158660888672
INFO:root:current mean train loss 1828.822160653774
INFO:root:current train perplexity4.231944561004639
INFO:root:current mean train loss 1830.5239217727842
INFO:root:current train perplexity4.2346086502075195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.53s/it]
INFO:root:final mean train loss: 1829.778397198945
INFO:root:final train perplexity: 4.233686923980713
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.88s/it]
INFO:root:eval mean loss: 2860.769804716826
INFO:root:eval perplexity: 10.459080696105957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/51
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [4:33:54<4:19:31, 317.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1825.5397375858192
INFO:root:current train perplexity4.187065124511719
INFO:root:current mean train loss 1815.9557024484657
INFO:root:current train perplexity4.190966606140137
INFO:root:current mean train loss 1820.641962725417
INFO:root:current train perplexity4.184653282165527
INFO:root:current mean train loss 1820.2857079010844
INFO:root:current train perplexity4.199723243713379
INFO:root:current mean train loss 1820.8196759530915
INFO:root:current train perplexity4.199151039123535
INFO:root:current mean train loss 1827.104906924622
INFO:root:current train perplexity4.204359531402588
INFO:root:current mean train loss 1827.9390966283665
INFO:root:current train perplexity4.2063822746276855
INFO:root:current mean train loss 1825.2388259449453
INFO:root:current train perplexity4.2049641609191895
INFO:root:current mean train loss 1827.162102045143
INFO:root:current train perplexity4.210124492645264
INFO:root:current mean train loss 1825.8043666547376
INFO:root:current train perplexity4.208512783050537
INFO:root:current mean train loss 1825.65002429955
INFO:root:current train perplexity4.214097499847412
INFO:root:current mean train loss 1824.250677249444
INFO:root:current train perplexity4.210931301116943
INFO:root:current mean train loss 1825.0345822495494
INFO:root:current train perplexity4.212331771850586
INFO:root:current mean train loss 1824.2396324235908
INFO:root:current train perplexity4.214150905609131
INFO:root:current mean train loss 1823.6900350823084
INFO:root:current train perplexity4.214444160461426
INFO:root:current mean train loss 1824.9658586640924
INFO:root:current train perplexity4.217206001281738
INFO:root:current mean train loss 1824.7691033444628
INFO:root:current train perplexity4.2168378829956055
INFO:root:current mean train loss 1825.7744193849314
INFO:root:current train perplexity4.217927932739258
INFO:root:current mean train loss 1825.5340366179537
INFO:root:current train perplexity4.21817684173584
INFO:root:current mean train loss 1825.650986881974
INFO:root:current train perplexity4.218316555023193

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.92s/it]
INFO:root:final mean train loss: 1825.473216554581
INFO:root:final train perplexity: 4.219337463378906
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.77s/it]
INFO:root:eval mean loss: 2863.3101685670044
INFO:root:eval perplexity: 10.480904579162598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/52
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [4:39:12<4:14:20, 317.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1816.3984139683735
INFO:root:current train perplexity4.199643135070801
INFO:root:current mean train loss 1814.962633810408
INFO:root:current train perplexity4.194787502288818
INFO:root:current mean train loss 1810.3539210882288
INFO:root:current train perplexity4.179497241973877
INFO:root:current mean train loss 1812.0376441895805
INFO:root:current train perplexity4.186807155609131
INFO:root:current mean train loss 1810.980863267097
INFO:root:current train perplexity4.181690692901611
INFO:root:current mean train loss 1811.6778558171634
INFO:root:current train perplexity4.189453125
INFO:root:current mean train loss 1814.3811801893644
INFO:root:current train perplexity4.191718101501465
INFO:root:current mean train loss 1814.498434912047
INFO:root:current train perplexity4.188276767730713
INFO:root:current mean train loss 1816.390320446321
INFO:root:current train perplexity4.189983367919922
INFO:root:current mean train loss 1816.7135692763304
INFO:root:current train perplexity4.192200660705566
INFO:root:current mean train loss 1816.6141352913276
INFO:root:current train perplexity4.191894054412842
INFO:root:current mean train loss 1817.6454923344384
INFO:root:current train perplexity4.197896957397461
INFO:root:current mean train loss 1816.5425833198863
INFO:root:current train perplexity4.198670864105225
INFO:root:current mean train loss 1817.9353109430078
INFO:root:current train perplexity4.20157527923584
INFO:root:current mean train loss 1819.3974895824554
INFO:root:current train perplexity4.202285289764404
INFO:root:current mean train loss 1820.5754979049866
INFO:root:current train perplexity4.203066349029541
INFO:root:current mean train loss 1820.7569950713478
INFO:root:current train perplexity4.2022480964660645
INFO:root:current mean train loss 1821.6887474723299
INFO:root:current train perplexity4.2044901847839355
INFO:root:current mean train loss 1821.7713184164234
INFO:root:current train perplexity4.205286502838135
INFO:root:current mean train loss 1821.2458750329954
INFO:root:current train perplexity4.205293655395508

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.20s/it]
INFO:root:final mean train loss: 1821.2458750329954
INFO:root:final train perplexity: 4.205293655395508
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.82s/it]
INFO:root:eval mean loss: 2865.829695418074
INFO:root:eval perplexity: 10.502594947814941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/53
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [4:44:29<4:08:44, 317.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1811.221328125
INFO:root:current train perplexity4.2448883056640625
INFO:root:current mean train loss 1825.8814306640625
INFO:root:current train perplexity4.221909999847412
INFO:root:current mean train loss 1813.6152762858073
INFO:root:current train perplexity4.199026107788086
INFO:root:current mean train loss 1813.5811846923827
INFO:root:current train perplexity4.192967891693115
INFO:root:current mean train loss 1812.4831638183593
INFO:root:current train perplexity4.187939167022705
INFO:root:current mean train loss 1817.7761631266276
INFO:root:current train perplexity4.196038722991943
INFO:root:current mean train loss 1815.8392159598213
INFO:root:current train perplexity4.188706398010254
INFO:root:current mean train loss 1815.7039558410645
INFO:root:current train perplexity4.191353797912598
INFO:root:current mean train loss 1816.5552174207899
INFO:root:current train perplexity4.192033290863037
INFO:root:current mean train loss 1816.2903090820312
INFO:root:current train perplexity4.192439079284668
INFO:root:current mean train loss 1819.0364610706677
INFO:root:current train perplexity4.196467876434326
INFO:root:current mean train loss 1819.4128555297852
INFO:root:current train perplexity4.196815490722656
INFO:root:current mean train loss 1820.0125033804086
INFO:root:current train perplexity4.196259498596191
INFO:root:current mean train loss 1817.784792829241
INFO:root:current train perplexity4.193628311157227
INFO:root:current mean train loss 1817.915716796875
INFO:root:current train perplexity4.194262981414795
INFO:root:current mean train loss 1818.2550791931153
INFO:root:current train perplexity4.1947102546691895
INFO:root:current mean train loss 1819.04481107824
INFO:root:current train perplexity4.194922924041748
INFO:root:current mean train loss 1820.5704550509984
INFO:root:current train perplexity4.197912693023682
INFO:root:current mean train loss 1819.183567601254
INFO:root:current train perplexity4.196335792541504

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.85s/it]
INFO:root:final mean train loss: 1818.2324171657822
INFO:root:final train perplexity: 4.195311069488525
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.70s/it]
INFO:root:eval mean loss: 2866.3073613163947
INFO:root:eval perplexity: 10.506711959838867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/54
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [4:49:51<4:04:24, 318.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1822.0177791819854
INFO:root:current train perplexity4.26560115814209
INFO:root:current mean train loss 1804.360375559228
INFO:root:current train perplexity4.171528339385986
INFO:root:current mean train loss 1807.6006123766922
INFO:root:current train perplexity4.158496379852295
INFO:root:current mean train loss 1805.228384697851
INFO:root:current train perplexity4.15983772277832
INFO:root:current mean train loss 1812.2224920259105
INFO:root:current train perplexity4.176544189453125
INFO:root:current mean train loss 1811.2508559088642
INFO:root:current train perplexity4.172039985656738
INFO:root:current mean train loss 1809.5357705584609
INFO:root:current train perplexity4.168182849884033
INFO:root:current mean train loss 1809.571612710567
INFO:root:current train perplexity4.173625946044922
INFO:root:current mean train loss 1810.496269160706
INFO:root:current train perplexity4.176334857940674
INFO:root:current mean train loss 1811.7706718153627
INFO:root:current train perplexity4.179933071136475
INFO:root:current mean train loss 1811.9404720580214
INFO:root:current train perplexity4.180678844451904
INFO:root:current mean train loss 1812.5371154949082
INFO:root:current train perplexity4.183779239654541
INFO:root:current mean train loss 1812.833228983444
INFO:root:current train perplexity4.185446739196777
INFO:root:current mean train loss 1812.072133080925
INFO:root:current train perplexity4.18562126159668
INFO:root:current mean train loss 1812.7837505892455
INFO:root:current train perplexity4.185265064239502
INFO:root:current mean train loss 1812.5867601267664
INFO:root:current train perplexity4.18231725692749
INFO:root:current mean train loss 1813.211614133402
INFO:root:current train perplexity4.184038162231445
INFO:root:current mean train loss 1813.2950156494567
INFO:root:current train perplexity4.183691024780273
INFO:root:current mean train loss 1813.852345644542
INFO:root:current train perplexity4.183468818664551
INFO:root:current mean train loss 1814.1615457629312
INFO:root:current train perplexity4.181601524353027

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.25s/it]
INFO:root:final mean train loss: 1814.2523868962844
INFO:root:final train perplexity: 4.182162761688232
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.29s/it]
INFO:root:eval mean loss: 2864.980118301896
INFO:root:eval perplexity: 10.495275497436523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/55
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [4:55:15<4:00:16, 320.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1785.4050041647517
INFO:root:current train perplexity4.121270656585693
INFO:root:current mean train loss 1802.332275390625
INFO:root:current train perplexity4.143426895141602
INFO:root:current mean train loss 1809.398161015959
INFO:root:current train perplexity4.14605712890625
INFO:root:current mean train loss 1811.740378739591
INFO:root:current train perplexity4.153656482696533
INFO:root:current mean train loss 1811.591769873272
INFO:root:current train perplexity4.157298564910889
INFO:root:current mean train loss 1811.029636797387
INFO:root:current train perplexity4.156187057495117
INFO:root:current mean train loss 1808.5281258471757
INFO:root:current train perplexity4.150306701660156
INFO:root:current mean train loss 1808.4536352339492
INFO:root:current train perplexity4.15125036239624
INFO:root:current mean train loss 1807.692627977696
INFO:root:current train perplexity4.152059555053711
INFO:root:current mean train loss 1805.4706373847782
INFO:root:current train perplexity4.1518354415893555
INFO:root:current mean train loss 1804.836262627312
INFO:root:current train perplexity4.155301570892334
INFO:root:current mean train loss 1804.6547600747838
INFO:root:current train perplexity4.153561115264893
INFO:root:current mean train loss 1805.9579351044938
INFO:root:current train perplexity4.158498764038086
INFO:root:current mean train loss 1806.2005558500048
INFO:root:current train perplexity4.159997463226318
INFO:root:current mean train loss 1806.669756220308
INFO:root:current train perplexity4.163071155548096
INFO:root:current mean train loss 1807.9339005968873
INFO:root:current train perplexity4.164329528808594
INFO:root:current mean train loss 1808.6336492867626
INFO:root:current train perplexity4.165904521942139
INFO:root:current mean train loss 1809.7419733489673
INFO:root:current train perplexity4.168979167938232
INFO:root:current mean train loss 1809.5174301630018
INFO:root:current train perplexity4.1675872802734375
INFO:root:current mean train loss 1810.6528834093442
INFO:root:current train perplexity4.168708801269531

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.14s/it]
INFO:root:final mean train loss: 1810.2127303576985
INFO:root:final train perplexity: 4.168859958648682
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.98s/it]
INFO:root:eval mean loss: 2869.164085227806
INFO:root:eval perplexity: 10.531370162963867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/56
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [5:00:40<3:56:05, 321.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1810.878370098039
INFO:root:current train perplexity4.165130138397217
INFO:root:current mean train loss 1807.1607593258484
INFO:root:current train perplexity4.1499128341674805
INFO:root:current mean train loss 1803.6092436893052
INFO:root:current train perplexity4.150624752044678
INFO:root:current mean train loss 1802.8349501563614
INFO:root:current train perplexity4.142154693603516
INFO:root:current mean train loss 1802.699118332958
INFO:root:current train perplexity4.141943454742432
INFO:root:current mean train loss 1804.3971722666884
INFO:root:current train perplexity4.1435089111328125
INFO:root:current mean train loss 1805.6103416243639
INFO:root:current train perplexity4.147222518920898
INFO:root:current mean train loss 1803.1791790633322
INFO:root:current train perplexity4.145514011383057
INFO:root:current mean train loss 1802.8260575506297
INFO:root:current train perplexity4.146361827850342
INFO:root:current mean train loss 1802.6660045860442
INFO:root:current train perplexity4.147948741912842
INFO:root:current mean train loss 1803.8035332328586
INFO:root:current train perplexity4.151062965393066
INFO:root:current mean train loss 1804.673350767505
INFO:root:current train perplexity4.150102138519287
INFO:root:current mean train loss 1806.1370566632631
INFO:root:current train perplexity4.151093006134033
INFO:root:current mean train loss 1806.9873078499434
INFO:root:current train perplexity4.152928829193115
INFO:root:current mean train loss 1806.6894141735495
INFO:root:current train perplexity4.152990341186523
INFO:root:current mean train loss 1806.814873012245
INFO:root:current train perplexity4.1544365882873535
INFO:root:current mean train loss 1806.3579470509114
INFO:root:current train perplexity4.153500556945801
INFO:root:current mean train loss 1806.6298717278742
INFO:root:current train perplexity4.154959678649902
INFO:root:current mean train loss 1807.4050300882548
INFO:root:current train perplexity4.156236171722412
INFO:root:current mean train loss 1806.8553700175792
INFO:root:current train perplexity4.156109809875488

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.20s/it]
INFO:root:final mean train loss: 1806.3562584211895
INFO:root:final train perplexity: 4.156199932098389
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.74s/it]
INFO:root:eval mean loss: 2871.522628830002
INFO:root:eval perplexity: 10.551770210266113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/57
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [5:06:09<3:52:05, 323.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1787.6377671185662
INFO:root:current train perplexity4.08223295211792
INFO:root:current mean train loss 1783.8080611456007
INFO:root:current train perplexity4.100167751312256
INFO:root:current mean train loss 1793.2961316464553
INFO:root:current train perplexity4.108223915100098
INFO:root:current mean train loss 1791.6344146728516
INFO:root:current train perplexity4.1113386154174805
INFO:root:current mean train loss 1794.0443409976797
INFO:root:current train perplexity4.113984107971191
INFO:root:current mean train loss 1795.5130024224939
INFO:root:current train perplexity4.118985652923584
INFO:root:current mean train loss 1794.862989048758
INFO:root:current train perplexity4.117645740509033
INFO:root:current mean train loss 1795.861828804016
INFO:root:current train perplexity4.120831489562988
INFO:root:current mean train loss 1797.5431534024428
INFO:root:current train perplexity4.122771263122559
INFO:root:current mean train loss 1800.3279202043518
INFO:root:current train perplexity4.12962532043457
INFO:root:current mean train loss 1798.9549289660508
INFO:root:current train perplexity4.129793167114258
INFO:root:current mean train loss 1799.0785154577804
INFO:root:current train perplexity4.132622241973877
INFO:root:current mean train loss 1800.6633667569806
INFO:root:current train perplexity4.1348137855529785
INFO:root:current mean train loss 1799.1637697275619
INFO:root:current train perplexity4.135252952575684
INFO:root:current mean train loss 1799.9524721566597
INFO:root:current train perplexity4.139340877532959
INFO:root:current mean train loss 1800.5213869055924
INFO:root:current train perplexity4.139492511749268
INFO:root:current mean train loss 1800.8406133491644
INFO:root:current train perplexity4.13936185836792
INFO:root:current mean train loss 1801.7154880713554
INFO:root:current train perplexity4.14079475402832
INFO:root:current mean train loss 1802.28049254979
INFO:root:current train perplexity4.1421637535095215
INFO:root:current mean train loss 1802.978576846239
INFO:root:current train perplexity4.144258975982666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.30s/it]
INFO:root:final mean train loss: 1802.642517428415
INFO:root:final train perplexity: 4.144045352935791
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.76s/it]
INFO:root:eval mean loss: 2870.7978911528717
INFO:root:eval perplexity: 10.54549789428711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/58
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [5:11:33<3:46:46, 323.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1793.0783806295956
INFO:root:current train perplexity4.1214375495910645
INFO:root:current mean train loss 1792.4330982105153
INFO:root:current train perplexity4.1089067459106445
INFO:root:current mean train loss 1788.2220643160636
INFO:root:current train perplexity4.0952229499816895
INFO:root:current mean train loss 1787.9671370865462
INFO:root:current train perplexity4.095006942749023
INFO:root:current mean train loss 1790.4017842400933
INFO:root:current train perplexity4.100203514099121
INFO:root:current mean train loss 1790.6972585303151
INFO:root:current train perplexity4.102707386016846
INFO:root:current mean train loss 1787.6432980725365
INFO:root:current train perplexity4.101797103881836
INFO:root:current mean train loss 1789.6919733715665
INFO:root:current train perplexity4.103051662445068
INFO:root:current mean train loss 1791.0173272256798
INFO:root:current train perplexity4.107855319976807
INFO:root:current mean train loss 1791.6682565137214
INFO:root:current train perplexity4.112240314483643
INFO:root:current mean train loss 1792.1836938814083
INFO:root:current train perplexity4.110806465148926
INFO:root:current mean train loss 1793.3140988635614
INFO:root:current train perplexity4.113402843475342
INFO:root:current mean train loss 1792.9661110013376
INFO:root:current train perplexity4.115865230560303
INFO:root:current mean train loss 1794.1260945784916
INFO:root:current train perplexity4.116271018981934
INFO:root:current mean train loss 1794.35435104627
INFO:root:current train perplexity4.118526458740234
INFO:root:current mean train loss 1795.1621280128647
INFO:root:current train perplexity4.123898506164551
INFO:root:current mean train loss 1795.5136983175305
INFO:root:current train perplexity4.125953197479248
INFO:root:current mean train loss 1797.3437101305367
INFO:root:current train perplexity4.128576755523682
INFO:root:current mean train loss 1797.9490445488643
INFO:root:current train perplexity4.1296491622924805

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.09s/it]
INFO:root:final mean train loss: 1799.002756185142
INFO:root:final train perplexity: 4.132165908813477
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.73s/it]
INFO:root:eval mean loss: 2872.9283040364585
INFO:root:eval perplexity: 10.563948631286621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/59
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [5:17:16<3:45:20, 329.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1833.2017822265625
INFO:root:current train perplexity4.209069728851318
INFO:root:current mean train loss 1797.1838043811274
INFO:root:current train perplexity4.096179485321045
INFO:root:current mean train loss 1789.4269149327042
INFO:root:current train perplexity4.095586776733398
INFO:root:current mean train loss 1786.8364193139487
INFO:root:current train perplexity4.087368011474609
INFO:root:current mean train loss 1789.287475889595
INFO:root:current train perplexity4.093898773193359
INFO:root:current mean train loss 1793.6505812686753
INFO:root:current train perplexity4.102738380432129
INFO:root:current mean train loss 1792.1277559096632
INFO:root:current train perplexity4.102797031402588
INFO:root:current mean train loss 1795.5692898568266
INFO:root:current train perplexity4.109344482421875
INFO:root:current mean train loss 1795.4228157937675
INFO:root:current train perplexity4.117412567138672
INFO:root:current mean train loss 1794.2330123326203
INFO:root:current train perplexity4.117888927459717
INFO:root:current mean train loss 1793.1311326321966
INFO:root:current train perplexity4.1165690422058105
INFO:root:current mean train loss 1793.9470184935415
INFO:root:current train perplexity4.116555213928223
INFO:root:current mean train loss 1793.1985867670094
INFO:root:current train perplexity4.115990161895752
INFO:root:current mean train loss 1793.7364407259565
INFO:root:current train perplexity4.118074893951416
INFO:root:current mean train loss 1793.8925294535986
INFO:root:current train perplexity4.118862628936768
INFO:root:current mean train loss 1795.5061491091305
INFO:root:current train perplexity4.1186089515686035
INFO:root:current mean train loss 1796.0641285947497
INFO:root:current train perplexity4.118738651275635
INFO:root:current mean train loss 1795.818049824196
INFO:root:current train perplexity4.119440078735352
INFO:root:current mean train loss 1795.8455378355648
INFO:root:current train perplexity4.119514465332031
INFO:root:current mean train loss 1795.687314969132
INFO:root:current train perplexity4.120563507080078

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.24s/it]
INFO:root:final mean train loss: 1795.690791681687
INFO:root:final train perplexity: 4.121387004852295
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.99s/it]
INFO:root:eval mean loss: 2873.975734767971
INFO:root:eval perplexity: 10.57303524017334
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/60
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [5:22:42<3:39:05, 328.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1749.156185752467
INFO:root:current train perplexity4.066369533538818
INFO:root:current mean train loss 1776.759801528033
INFO:root:current train perplexity4.0894012451171875
INFO:root:current mean train loss 1789.9715364360375
INFO:root:current train perplexity4.097906112670898
INFO:root:current mean train loss 1790.94238625649
INFO:root:current train perplexity4.10391092300415
INFO:root:current mean train loss 1792.0717983200327
INFO:root:current train perplexity4.107638835906982
INFO:root:current mean train loss 1790.03710373013
INFO:root:current train perplexity4.109489917755127
INFO:root:current mean train loss 1789.5072386314873
INFO:root:current train perplexity4.107354164123535
INFO:root:current mean train loss 1786.4884124883192
INFO:root:current train perplexity4.103397369384766
INFO:root:current mean train loss 1786.8741768078926
INFO:root:current train perplexity4.104813098907471
INFO:root:current mean train loss 1786.4779780640047
INFO:root:current train perplexity4.101093292236328
INFO:root:current mean train loss 1788.888364243437
INFO:root:current train perplexity4.102770805358887
INFO:root:current mean train loss 1788.6744259313562
INFO:root:current train perplexity4.104085445404053
INFO:root:current mean train loss 1789.118633417344
INFO:root:current train perplexity4.103686332702637
INFO:root:current mean train loss 1788.1381490734873
INFO:root:current train perplexity4.101830005645752
INFO:root:current mean train loss 1789.2546114877885
INFO:root:current train perplexity4.104677200317383
INFO:root:current mean train loss 1789.47999734483
INFO:root:current train perplexity4.105311870574951
INFO:root:current mean train loss 1789.7724232382066
INFO:root:current train perplexity4.104994297027588
INFO:root:current mean train loss 1790.9854034015507
INFO:root:current train perplexity4.105961322784424
INFO:root:current mean train loss 1791.4897764267798
INFO:root:current train perplexity4.1073222160339355
INFO:root:current mean train loss 1792.5652214237152
INFO:root:current train perplexity4.109086036682129

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.35s/it]
INFO:root:final mean train loss: 1792.1595613803759
INFO:root:final train perplexity: 4.109925270080566
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.88s/it]
INFO:root:eval mean loss: 2877.2013478322074
INFO:root:eval perplexity: 10.601055145263672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/61
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [5:28:10<3:33:30, 328.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1791.9912923177083
INFO:root:current train perplexity4.051234245300293
INFO:root:current mean train loss 1778.9941343419691
INFO:root:current train perplexity4.052592754364014
INFO:root:current mean train loss 1784.0181341656184
INFO:root:current train perplexity4.072515487670898
INFO:root:current mean train loss 1787.1231936500185
INFO:root:current train perplexity4.094946384429932
INFO:root:current mean train loss 1788.7335308669903
INFO:root:current train perplexity4.097124099731445
INFO:root:current mean train loss 1789.8550449200532
INFO:root:current train perplexity4.097711563110352
INFO:root:current mean train loss 1788.028328757616
INFO:root:current train perplexity4.094687461853027
INFO:root:current mean train loss 1789.1518345708432
INFO:root:current train perplexity4.096684455871582
INFO:root:current mean train loss 1790.9788942473926
INFO:root:current train perplexity4.1027913093566895
INFO:root:current mean train loss 1791.2391512618105
INFO:root:current train perplexity4.102870464324951
INFO:root:current mean train loss 1790.0066971355423
INFO:root:current train perplexity4.099298477172852
INFO:root:current mean train loss 1789.8617476342429
INFO:root:current train perplexity4.097304344177246
INFO:root:current mean train loss 1789.4764134675554
INFO:root:current train perplexity4.095961093902588
INFO:root:current mean train loss 1790.0205745125959
INFO:root:current train perplexity4.097141265869141
INFO:root:current mean train loss 1789.875355160004
INFO:root:current train perplexity4.099701404571533
INFO:root:current mean train loss 1789.9135851860046
INFO:root:current train perplexity4.101394176483154
INFO:root:current mean train loss 1789.395900586415
INFO:root:current train perplexity4.100968837738037
INFO:root:current mean train loss 1789.5144249700732
INFO:root:current train perplexity4.1007466316223145
INFO:root:current mean train loss 1789.574684691585
INFO:root:current train perplexity4.100337028503418
INFO:root:current mean train loss 1790.0151398713924
INFO:root:current train perplexity4.101391315460205

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.87s/it]
INFO:root:final mean train loss: 1789.5388589263623
INFO:root:final train perplexity: 4.101439476013184
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.76s/it]
INFO:root:eval mean loss: 2877.15148669177
INFO:root:eval perplexity: 10.60062026977539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/62
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [5:33:43<3:28:48, 329.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1780.5867067732902
INFO:root:current train perplexity4.035684585571289
INFO:root:current mean train loss 1771.8510287415747
INFO:root:current train perplexity4.057195663452148
INFO:root:current mean train loss 1774.7448301051445
INFO:root:current train perplexity4.059395790100098
INFO:root:current mean train loss 1779.3560099399124
INFO:root:current train perplexity4.072024822235107
INFO:root:current mean train loss 1780.6734287691431
INFO:root:current train perplexity4.077249526977539
INFO:root:current mean train loss 1782.4117332306737
INFO:root:current train perplexity4.080416202545166
INFO:root:current mean train loss 1782.5536703720209
INFO:root:current train perplexity4.078433513641357
INFO:root:current mean train loss 1783.8767683173555
INFO:root:current train perplexity4.081920146942139
INFO:root:current mean train loss 1785.7047039000677
INFO:root:current train perplexity4.0832743644714355
INFO:root:current mean train loss 1785.4563111248196
INFO:root:current train perplexity4.081141471862793
INFO:root:current mean train loss 1786.026259955744
INFO:root:current train perplexity4.081909656524658
INFO:root:current mean train loss 1785.9361385931063
INFO:root:current train perplexity4.084001064300537
INFO:root:current mean train loss 1785.3432502229025
INFO:root:current train perplexity4.085213661193848
INFO:root:current mean train loss 1785.474091140059
INFO:root:current train perplexity4.085073471069336
INFO:root:current mean train loss 1786.641604923004
INFO:root:current train perplexity4.088558197021484
INFO:root:current mean train loss 1787.2763726111004
INFO:root:current train perplexity4.090949535369873
INFO:root:current mean train loss 1786.9514182310572
INFO:root:current train perplexity4.091314792633057
INFO:root:current mean train loss 1786.7345302166152
INFO:root:current train perplexity4.090709686279297
INFO:root:current mean train loss 1786.7633266129883
INFO:root:current train perplexity4.091559886932373
INFO:root:current mean train loss 1786.8310700009802
INFO:root:current train perplexity4.090815544128418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.04s/it]
INFO:root:final mean train loss: 1786.129221798372
INFO:root:final train perplexity: 4.090425491333008
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.85s/it]
INFO:root:eval mean loss: 2881.4549769496057
INFO:root:eval perplexity: 10.63812255859375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/63
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [5:39:02<3:21:24, 326.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1786.6546491350446
INFO:root:current train perplexity4.091804504394531
INFO:root:current mean train loss 1784.9903061810662
INFO:root:current train perplexity4.088473796844482
INFO:root:current mean train loss 1783.653365523727
INFO:root:current train perplexity4.076564311981201
INFO:root:current mean train loss 1778.9202138539906
INFO:root:current train perplexity4.063045978546143
INFO:root:current mean train loss 1780.8687629862034
INFO:root:current train perplexity4.07440710067749
INFO:root:current mean train loss 1780.1342126679003
INFO:root:current train perplexity4.079493522644043
INFO:root:current mean train loss 1781.3459008060283
INFO:root:current train perplexity4.0739665031433105
INFO:root:current mean train loss 1782.711204310826
INFO:root:current train perplexity4.076651096343994
INFO:root:current mean train loss 1784.8597576272898
INFO:root:current train perplexity4.080023288726807
INFO:root:current mean train loss 1785.8550851723583
INFO:root:current train perplexity4.080024719238281
INFO:root:current mean train loss 1785.4883830132885
INFO:root:current train perplexity4.078502178192139
INFO:root:current mean train loss 1784.8942230485443
INFO:root:current train perplexity4.074769020080566
INFO:root:current mean train loss 1784.9047177772823
INFO:root:current train perplexity4.0734782218933105
INFO:root:current mean train loss 1784.1535567012147
INFO:root:current train perplexity4.073481559753418
INFO:root:current mean train loss 1783.7728396045918
INFO:root:current train perplexity4.07434606552124
INFO:root:current mean train loss 1783.0924712162869
INFO:root:current train perplexity4.073716640472412
INFO:root:current mean train loss 1783.4860858848708
INFO:root:current train perplexity4.076213359832764
INFO:root:current mean train loss 1783.5255448335981
INFO:root:current train perplexity4.0757575035095215
INFO:root:current mean train loss 1783.2252979951747
INFO:root:current train perplexity4.076851844787598
INFO:root:current mean train loss 1783.3228891130632
INFO:root:current train perplexity4.0794172286987305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.38s/it]
INFO:root:final mean train loss: 1782.8266215591316
INFO:root:final train perplexity: 4.079784870147705
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.65s/it]
INFO:root:eval mean loss: 2882.5035711981513
INFO:root:eval perplexity: 10.647279739379883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/64
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [5:44:21<3:14:34, 324.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1782.0945680114044
INFO:root:current train perplexity4.056197166442871
INFO:root:current mean train loss 1782.3559720452456
INFO:root:current train perplexity4.065793991088867
INFO:root:current mean train loss 1780.968579441828
INFO:root:current train perplexity4.0558624267578125
INFO:root:current mean train loss 1773.628911927689
INFO:root:current train perplexity4.054745674133301
INFO:root:current mean train loss 1772.8576344327516
INFO:root:current train perplexity4.057191371917725
INFO:root:current mean train loss 1770.9882434019644
INFO:root:current train perplexity4.053877830505371
INFO:root:current mean train loss 1771.8198796567958
INFO:root:current train perplexity4.054673671722412
INFO:root:current mean train loss 1771.5581886068535
INFO:root:current train perplexity4.052931308746338
INFO:root:current mean train loss 1774.9464275097766
INFO:root:current train perplexity4.056297779083252
INFO:root:current mean train loss 1777.0316778026454
INFO:root:current train perplexity4.060565948486328
INFO:root:current mean train loss 1776.2362486164616
INFO:root:current train perplexity4.058374881744385
INFO:root:current mean train loss 1777.5777662963353
INFO:root:current train perplexity4.063294887542725
INFO:root:current mean train loss 1777.3581719387385
INFO:root:current train perplexity4.062781810760498
INFO:root:current mean train loss 1778.2946910239332
INFO:root:current train perplexity4.06516695022583
INFO:root:current mean train loss 1779.3774258909245
INFO:root:current train perplexity4.066330432891846
INFO:root:current mean train loss 1780.4199885636963
INFO:root:current train perplexity4.069643020629883
INFO:root:current mean train loss 1779.7734974135856
INFO:root:current train perplexity4.070200443267822
INFO:root:current mean train loss 1779.474432929775
INFO:root:current train perplexity4.0686354637146
INFO:root:current mean train loss 1779.5735490775703
INFO:root:current train perplexity4.068881511688232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.59s/it]
INFO:root:final mean train loss: 1779.895560075584
INFO:root:final train perplexity: 4.070364475250244
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.01s/it]
INFO:root:eval mean loss: 2881.2077673376502
INFO:root:eval perplexity: 10.635967254638672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/65
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [5:49:46<3:09:20, 324.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1751.8056945800781
INFO:root:current train perplexity4.038450717926025
INFO:root:current mean train loss 1763.4724989670974
INFO:root:current train perplexity4.029987812042236
INFO:root:current mean train loss 1778.9408264160156
INFO:root:current train perplexity4.061763286590576
INFO:root:current mean train loss 1776.0085007516961
INFO:root:current train perplexity4.050886154174805
INFO:root:current mean train loss 1774.900623283764
INFO:root:current train perplexity4.050182342529297
INFO:root:current mean train loss 1775.36600676037
INFO:root:current train perplexity4.049345016479492
INFO:root:current mean train loss 1774.8652725724985
INFO:root:current train perplexity4.04616117477417
INFO:root:current mean train loss 1774.7204189300537
INFO:root:current train perplexity4.048697471618652
INFO:root:current mean train loss 1776.8135136087142
INFO:root:current train perplexity4.053935527801514
INFO:root:current mean train loss 1777.0907656239197
INFO:root:current train perplexity4.052608489990234
INFO:root:current mean train loss 1776.4891097232164
INFO:root:current train perplexity4.04982328414917
INFO:root:current mean train loss 1775.5173517862956
INFO:root:current train perplexity4.050455570220947
INFO:root:current mean train loss 1776.236083984375
INFO:root:current train perplexity4.053160190582275
INFO:root:current mean train loss 1776.476812725418
INFO:root:current train perplexity4.054422378540039
INFO:root:current mean train loss 1776.1950570565682
INFO:root:current train perplexity4.055438995361328
INFO:root:current mean train loss 1775.8717954108056
INFO:root:current train perplexity4.055187225341797
INFO:root:current mean train loss 1776.1040574071412
INFO:root:current train perplexity4.054535388946533
INFO:root:current mean train loss 1775.1534973287805
INFO:root:current train perplexity4.055159091949463
INFO:root:current mean train loss 1775.6398027170524
INFO:root:current train perplexity4.057326316833496
INFO:root:current mean train loss 1776.4195314295152
INFO:root:current train perplexity4.058661937713623

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.75s/it]
INFO:root:final mean train loss: 1776.9182202160748
INFO:root:final train perplexity: 4.060818672180176
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.71s/it]
INFO:root:eval mean loss: 2882.047757718656
INFO:root:eval perplexity: 10.64330005645752
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/66
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [5:55:09<3:03:33, 323.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1740.6827450706846
INFO:root:current train perplexity3.9599883556365967
INFO:root:current mean train loss 1770.9129154426007
INFO:root:current train perplexity4.0026092529296875
INFO:root:current mean train loss 1765.2527982271636
INFO:root:current train perplexity4.0224528312683105
INFO:root:current mean train loss 1771.4305727949766
INFO:root:current train perplexity4.040666580200195
INFO:root:current mean train loss 1774.567803534646
INFO:root:current train perplexity4.048933506011963
INFO:root:current mean train loss 1774.0275642263225
INFO:root:current train perplexity4.050036907196045
INFO:root:current mean train loss 1773.7232953008631
INFO:root:current train perplexity4.047884941101074
INFO:root:current mean train loss 1772.5550037653866
INFO:root:current train perplexity4.039285659790039
INFO:root:current mean train loss 1773.5823974609375
INFO:root:current train perplexity4.041373252868652
INFO:root:current mean train loss 1774.405823615423
INFO:root:current train perplexity4.0429816246032715
INFO:root:current mean train loss 1772.9868303947187
INFO:root:current train perplexity4.042689323425293
INFO:root:current mean train loss 1772.9297258307315
INFO:root:current train perplexity4.043361186981201
INFO:root:current mean train loss 1773.071806936553
INFO:root:current train perplexity4.043430805206299
INFO:root:current mean train loss 1771.1837954755808
INFO:root:current train perplexity4.044224739074707
INFO:root:current mean train loss 1772.2772119724775
INFO:root:current train perplexity4.047044277191162
INFO:root:current mean train loss 1772.1074488412228
INFO:root:current train perplexity4.0482940673828125
INFO:root:current mean train loss 1773.1508295058027
INFO:root:current train perplexity4.049244403839111
INFO:root:current mean train loss 1773.3788715652918
INFO:root:current train perplexity4.051244735717773
INFO:root:current mean train loss 1774.377173535317
INFO:root:current train perplexity4.0513176918029785
INFO:root:current mean train loss 1773.6607077587153
INFO:root:current train perplexity4.049989700317383

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.88s/it]
INFO:root:final mean train loss: 1774.2629228015771
INFO:root:final train perplexity: 4.052324295043945
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.75s/it]
INFO:root:eval mean loss: 2884.9309895833335
INFO:root:eval perplexity: 10.66850757598877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/67
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [6:00:28<2:57:22, 322.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1756.345703125
INFO:root:current train perplexity4.011739253997803
INFO:root:current mean train loss 1756.5553084663723
INFO:root:current train perplexity4.009636402130127
INFO:root:current mean train loss 1759.2440565093225
INFO:root:current train perplexity4.012426376342773
INFO:root:current mean train loss 1760.7545245469676
INFO:root:current train perplexity4.022960186004639
INFO:root:current mean train loss 1763.0737343705407
INFO:root:current train perplexity4.0261945724487305
INFO:root:current mean train loss 1767.650754340076
INFO:root:current train perplexity4.030889511108398
INFO:root:current mean train loss 1770.8454186131587
INFO:root:current train perplexity4.033168792724609
INFO:root:current mean train loss 1767.6750114461595
INFO:root:current train perplexity4.030845642089844
INFO:root:current mean train loss 1768.9418104804502
INFO:root:current train perplexity4.032143592834473
INFO:root:current mean train loss 1770.9275590778668
INFO:root:current train perplexity4.034181594848633
INFO:root:current mean train loss 1770.763984459673
INFO:root:current train perplexity4.035960674285889
INFO:root:current mean train loss 1772.115906834393
INFO:root:current train perplexity4.0360026359558105
INFO:root:current mean train loss 1771.767100098445
INFO:root:current train perplexity4.035583019256592
INFO:root:current mean train loss 1770.6525347015427
INFO:root:current train perplexity4.035340309143066
INFO:root:current mean train loss 1770.7901740359332
INFO:root:current train perplexity4.036383152008057
INFO:root:current mean train loss 1771.6766759825312
INFO:root:current train perplexity4.037862777709961
INFO:root:current mean train loss 1771.3988534929697
INFO:root:current train perplexity4.038182258605957
INFO:root:current mean train loss 1771.9129859213176
INFO:root:current train perplexity4.0405049324035645
INFO:root:current mean train loss 1772.462556824461
INFO:root:current train perplexity4.041810989379883
INFO:root:current mean train loss 1771.213207768459
INFO:root:current train perplexity4.041162967681885

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.24s/it]
INFO:root:final mean train loss: 1771.0259768148894
INFO:root:final train perplexity: 4.041991710662842
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.72s/it]
INFO:root:eval mean loss: 2887.3024242504225
INFO:root:eval perplexity: 10.689291000366211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/68
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [6:05:46<2:51:21, 321.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1755.5226651278408
INFO:root:current train perplexity4.017513751983643
INFO:root:current mean train loss 1773.439587796119
INFO:root:current train perplexity4.020125389099121
INFO:root:current mean train loss 1769.5474757774202
INFO:root:current train perplexity4.0236101150512695
INFO:root:current mean train loss 1772.3890356789173
INFO:root:current train perplexity4.0328803062438965
INFO:root:current mean train loss 1771.7798618861607
INFO:root:current train perplexity4.037755966186523
INFO:root:current mean train loss 1769.2467740445525
INFO:root:current train perplexity4.031052589416504
INFO:root:current mean train loss 1768.4222553748211
INFO:root:current train perplexity4.029219150543213
INFO:root:current mean train loss 1768.1898602416184
INFO:root:current train perplexity4.023581504821777
INFO:root:current mean train loss 1766.9094355354532
INFO:root:current train perplexity4.022611618041992
INFO:root:current mean train loss 1767.6024342482003
INFO:root:current train perplexity4.024397850036621
INFO:root:current mean train loss 1767.1640358875147
INFO:root:current train perplexity4.024693965911865
INFO:root:current mean train loss 1768.6638047255478
INFO:root:current train perplexity4.027364253997803
INFO:root:current mean train loss 1769.1721714703685
INFO:root:current train perplexity4.028704643249512
INFO:root:current mean train loss 1768.895511776407
INFO:root:current train perplexity4.029436111450195
INFO:root:current mean train loss 1769.6343050298003
INFO:root:current train perplexity4.031232833862305
INFO:root:current mean train loss 1770.146205379572
INFO:root:current train perplexity4.031970024108887
INFO:root:current mean train loss 1771.3334095012744
INFO:root:current train perplexity4.035331726074219
INFO:root:current mean train loss 1770.1626441890357
INFO:root:current train perplexity4.033892631530762
INFO:root:current mean train loss 1769.730204538515
INFO:root:current train perplexity4.033944129943848
INFO:root:current mean train loss 1769.0894945851983
INFO:root:current train perplexity4.033562183380127

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.39s/it]
INFO:root:final mean train loss: 1768.5953896080553
INFO:root:final train perplexity: 4.0342512130737305
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.78s/it]
INFO:root:eval mean loss: 2887.355130765531
INFO:root:eval perplexity: 10.6897554397583
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/69
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [6:11:05<2:45:36, 320.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1750.3375786675347
INFO:root:current train perplexity4.009072303771973
INFO:root:current mean train loss 1754.7815395621367
INFO:root:current train perplexity4.011908054351807
INFO:root:current mean train loss 1756.6819323371437
INFO:root:current train perplexity4.018483638763428
INFO:root:current mean train loss 1755.835402622018
INFO:root:current train perplexity4.012453079223633
INFO:root:current mean train loss 1760.2317163499736
INFO:root:current train perplexity4.013235092163086
INFO:root:current mean train loss 1762.392989365371
INFO:root:current train perplexity4.02042818069458
INFO:root:current mean train loss 1763.2300974527996
INFO:root:current train perplexity4.023312568664551
INFO:root:current mean train loss 1761.9592373704663
INFO:root:current train perplexity4.01998233795166
INFO:root:current mean train loss 1760.1189750181425
INFO:root:current train perplexity4.019217014312744
INFO:root:current mean train loss 1760.6022151742943
INFO:root:current train perplexity4.01978874206543
INFO:root:current mean train loss 1760.6451999038013
INFO:root:current train perplexity4.020107269287109
INFO:root:current mean train loss 1762.2722490850977
INFO:root:current train perplexity4.022337436676025
INFO:root:current mean train loss 1762.4271102041569
INFO:root:current train perplexity4.021462440490723
INFO:root:current mean train loss 1761.9438071737484
INFO:root:current train perplexity4.0223894119262695
INFO:root:current mean train loss 1763.0005659849746
INFO:root:current train perplexity4.0242838859558105
INFO:root:current mean train loss 1762.9891477783824
INFO:root:current train perplexity4.024150848388672
INFO:root:current mean train loss 1764.5970096861918
INFO:root:current train perplexity4.025102615356445
INFO:root:current mean train loss 1765.1530176167025
INFO:root:current train perplexity4.024993419647217
INFO:root:current mean train loss 1766.1459392971462
INFO:root:current train perplexity4.025463581085205
INFO:root:current mean train loss 1766.3513569860866
INFO:root:current train perplexity4.0259504318237305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.99s/it]
INFO:root:final mean train loss: 1766.1657533862046
INFO:root:final train perplexity: 4.026528358459473
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.68s/it]
INFO:root:eval mean loss: 2889.863800323761
INFO:root:eval perplexity: 10.711782455444336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/70
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [6:16:22<2:39:46, 319.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1751.0776161451017
INFO:root:current train perplexity4.028161525726318
INFO:root:current mean train loss 1746.6696318772736
INFO:root:current train perplexity4.007530689239502
INFO:root:current mean train loss 1753.3755267186148
INFO:root:current train perplexity4.009359836578369
INFO:root:current mean train loss 1751.89164894712
INFO:root:current train perplexity4.004474639892578
INFO:root:current mean train loss 1756.8646215271121
INFO:root:current train perplexity4.011137962341309
INFO:root:current mean train loss 1756.7745823495861
INFO:root:current train perplexity4.012126922607422
INFO:root:current mean train loss 1757.0937508858513
INFO:root:current train perplexity4.008700370788574
INFO:root:current mean train loss 1756.3088471735384
INFO:root:current train perplexity4.003900527954102
INFO:root:current mean train loss 1758.3865466981422
INFO:root:current train perplexity4.007341384887695
INFO:root:current mean train loss 1760.7712383829546
INFO:root:current train perplexity4.007816791534424
INFO:root:current mean train loss 1758.9674433208147
INFO:root:current train perplexity4.006910800933838
INFO:root:current mean train loss 1758.5707760386551
INFO:root:current train perplexity4.008772850036621
INFO:root:current mean train loss 1758.9523287492727
INFO:root:current train perplexity4.009564399719238
INFO:root:current mean train loss 1758.8777608631153
INFO:root:current train perplexity4.010152339935303
INFO:root:current mean train loss 1759.6957887299834
INFO:root:current train perplexity4.012549877166748
INFO:root:current mean train loss 1759.5804110719694
INFO:root:current train perplexity4.013043403625488
INFO:root:current mean train loss 1760.866375938402
INFO:root:current train perplexity4.01346492767334
INFO:root:current mean train loss 1761.9013587947395
INFO:root:current train perplexity4.013533592224121
INFO:root:current mean train loss 1763.1795860439966
INFO:root:current train perplexity4.0150628089904785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.45s/it]
INFO:root:final mean train loss: 1763.4821757029476
INFO:root:final train perplexity: 4.018015384674072
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.84s/it]
INFO:root:eval mean loss: 2886.969164232592
INFO:root:eval perplexity: 10.686366081237793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/71
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [6:21:41<2:34:20, 319.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1806.7721557617188
INFO:root:current train perplexity4.032848834991455
INFO:root:current mean train loss 1755.3035669866597
INFO:root:current train perplexity3.9709465503692627
INFO:root:current mean train loss 1750.2000815382282
INFO:root:current train perplexity3.9751057624816895
INFO:root:current mean train loss 1750.8302041845384
INFO:root:current train perplexity3.9745850563049316
INFO:root:current mean train loss 1752.8200824906673
INFO:root:current train perplexity3.9847147464752197
INFO:root:current mean train loss 1751.6995198246047
INFO:root:current train perplexity3.9836432933807373
INFO:root:current mean train loss 1754.2406563837535
INFO:root:current train perplexity3.9905741214752197
INFO:root:current mean train loss 1756.4286767024832
INFO:root:current train perplexity3.99526309967041
INFO:root:current mean train loss 1757.8993864982358
INFO:root:current train perplexity3.996614933013916
INFO:root:current mean train loss 1757.760930817122
INFO:root:current train perplexity3.9961986541748047
INFO:root:current mean train loss 1759.0861221829182
INFO:root:current train perplexity4.002046585083008
INFO:root:current mean train loss 1754.7773486063234
INFO:root:current train perplexity3.9972004890441895
INFO:root:current mean train loss 1756.708475748698
INFO:root:current train perplexity3.9987666606903076
INFO:root:current mean train loss 1758.6442468243024
INFO:root:current train perplexity4.001216411590576
INFO:root:current mean train loss 1759.2302042064423
INFO:root:current train perplexity4.004587650299072
INFO:root:current mean train loss 1759.4459564087401
INFO:root:current train perplexity4.003319263458252
INFO:root:current mean train loss 1759.4010336603947
INFO:root:current train perplexity4.00592565536499
INFO:root:current mean train loss 1758.365940465178
INFO:root:current train perplexity4.004684925079346
INFO:root:current mean train loss 1759.4080411756818
INFO:root:current train perplexity4.007525444030762
INFO:root:current mean train loss 1761.455128528639
INFO:root:current train perplexity4.009516716003418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.45s/it]
INFO:root:final mean train loss: 1761.3243672904257
INFO:root:final train perplexity: 4.011183738708496
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.16s/it]
INFO:root:eval mean loss: 2890.602740680133
INFO:root:eval perplexity: 10.718276977539062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/72
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [6:27:00<2:29:00, 319.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1780.461420473845
INFO:root:current train perplexity3.9989912509918213
INFO:root:current mean train loss 1767.8058893467353
INFO:root:current train perplexity4.003039360046387
INFO:root:current mean train loss 1759.1051085604681
INFO:root:current train perplexity3.9910402297973633
INFO:root:current mean train loss 1758.12255972753
INFO:root:current train perplexity3.989450693130493
INFO:root:current mean train loss 1757.5149096044806
INFO:root:current train perplexity3.99056077003479
INFO:root:current mean train loss 1758.7991128779279
INFO:root:current train perplexity3.992495059967041
INFO:root:current mean train loss 1757.5340764273801
INFO:root:current train perplexity3.9894533157348633
INFO:root:current mean train loss 1756.912755520347
INFO:root:current train perplexity3.996150493621826
INFO:root:current mean train loss 1756.7347551533546
INFO:root:current train perplexity3.996090888977051
INFO:root:current mean train loss 1757.6341175810876
INFO:root:current train perplexity3.998448610305786
INFO:root:current mean train loss 1759.2037957304267
INFO:root:current train perplexity4.000120639801025
INFO:root:current mean train loss 1759.3225692246285
INFO:root:current train perplexity4.001245975494385
INFO:root:current mean train loss 1759.1624684992719
INFO:root:current train perplexity4.002425670623779
INFO:root:current mean train loss 1758.6008076570472
INFO:root:current train perplexity4.001805305480957
INFO:root:current mean train loss 1758.5376825821877
INFO:root:current train perplexity4.002546787261963
INFO:root:current mean train loss 1759.493116612976
INFO:root:current train perplexity4.004883289337158
INFO:root:current mean train loss 1760.2591163884397
INFO:root:current train perplexity4.005566120147705
INFO:root:current mean train loss 1760.378662109375
INFO:root:current train perplexity4.005815505981445
INFO:root:current mean train loss 1760.3867349546163
INFO:root:current train perplexity4.004056930541992
INFO:root:current mean train loss 1760.0153941899864
INFO:root:current train perplexity4.004758358001709

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.65s/it]
INFO:root:final mean train loss: 1759.5691831495446
INFO:root:final train perplexity: 4.005634307861328
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.84s/it]
INFO:root:eval mean loss: 2890.29907299878
INFO:root:eval perplexity: 10.715606689453125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/73
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [6:32:19<2:23:39, 319.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1744.8550537109375
INFO:root:current train perplexity4.022051811218262
INFO:root:current mean train loss 1745.398486328125
INFO:root:current train perplexity3.9719738960266113
INFO:root:current mean train loss 1743.7556040445963
INFO:root:current train perplexity3.9726576805114746
INFO:root:current mean train loss 1748.9130399816177
INFO:root:current train perplexity3.9834868907928467
INFO:root:current mean train loss 1754.1068073619497
INFO:root:current train perplexity3.989408254623413
INFO:root:current mean train loss 1755.3431163646558
INFO:root:current train perplexity3.997436285018921
INFO:root:current mean train loss 1755.3300065994263
INFO:root:current train perplexity3.9907262325286865
INFO:root:current mean train loss 1754.9497187434017
INFO:root:current train perplexity3.9907286167144775
INFO:root:current mean train loss 1755.6030292329333
INFO:root:current train perplexity3.992079496383667
INFO:root:current mean train loss 1755.569609946393
INFO:root:current train perplexity3.9948482513427734
INFO:root:current mean train loss 1756.3411383995642
INFO:root:current train perplexity3.9972739219665527
INFO:root:current mean train loss 1756.4549410635964
INFO:root:current train perplexity4.0004353523254395
INFO:root:current mean train loss 1757.0490195981918
INFO:root:current train perplexity4.000604629516602
INFO:root:current mean train loss 1757.441815276644
INFO:root:current train perplexity4.00042200088501
INFO:root:current mean train loss 1756.4231106228299
INFO:root:current train perplexity3.9970176219940186
INFO:root:current mean train loss 1756.2241738059304
INFO:root:current train perplexity3.9973158836364746
INFO:root:current mean train loss 1756.7843201427925
INFO:root:current train perplexity3.9972734451293945
INFO:root:current mean train loss 1757.0420211616604
INFO:root:current train perplexity3.997312068939209
INFO:root:current mean train loss 1757.4051591956097
INFO:root:current train perplexity3.9982986450195312
INFO:root:current mean train loss 1757.7288354618033
INFO:root:current train perplexity3.9981675148010254

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.87s/it]
INFO:root:final mean train loss: 1757.0966128966331
INFO:root:final train perplexity: 3.9978318214416504
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.79s/it]
INFO:root:eval mean loss: 2892.420751806494
INFO:root:eval perplexity: 10.734277725219727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/74
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [6:37:38<2:18:11, 318.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1742.4803766618695
INFO:root:current train perplexity3.951972723007202
INFO:root:current mean train loss 1760.9015359088874
INFO:root:current train perplexity3.9951367378234863
INFO:root:current mean train loss 1757.6087024258268
INFO:root:current train perplexity3.9787402153015137
INFO:root:current mean train loss 1752.4333708092613
INFO:root:current train perplexity3.9736907482147217
INFO:root:current mean train loss 1748.7088948923858
INFO:root:current train perplexity3.969996929168701
INFO:root:current mean train loss 1751.587792223617
INFO:root:current train perplexity3.97971510887146
INFO:root:current mean train loss 1752.1849220310717
INFO:root:current train perplexity3.976081132888794
INFO:root:current mean train loss 1750.5622326386022
INFO:root:current train perplexity3.9749021530151367
INFO:root:current mean train loss 1751.0472402138637
INFO:root:current train perplexity3.9787795543670654
INFO:root:current mean train loss 1750.4388449418757
INFO:root:current train perplexity3.977322816848755
INFO:root:current mean train loss 1749.7363313586507
INFO:root:current train perplexity3.9745476245880127
INFO:root:current mean train loss 1751.7934573477676
INFO:root:current train perplexity3.9757375717163086
INFO:root:current mean train loss 1750.379172338032
INFO:root:current train perplexity3.974808692932129
INFO:root:current mean train loss 1751.4593162227397
INFO:root:current train perplexity3.9792685508728027
INFO:root:current mean train loss 1751.9709140041878
INFO:root:current train perplexity3.9812865257263184
INFO:root:current mean train loss 1752.074435293483
INFO:root:current train perplexity3.982506036758423
INFO:root:current mean train loss 1752.7642056839827
INFO:root:current train perplexity3.9842939376831055
INFO:root:current mean train loss 1752.8633427367538
INFO:root:current train perplexity3.984405040740967
INFO:root:current mean train loss 1754.5086670579228
INFO:root:current train perplexity3.9895708560943604
INFO:root:current mean train loss 1754.2529420379967
INFO:root:current train perplexity3.988487720489502

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.44s/it]
INFO:root:final mean train loss: 1754.245405219266
INFO:root:final train perplexity: 3.98885178565979
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.85s/it]
INFO:root:eval mean loss: 2892.3889959295234
INFO:root:eval perplexity: 10.733999252319336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/75
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [6:42:57<2:12:52, 318.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1757.121220769109
INFO:root:current train perplexity4.001160621643066
INFO:root:current mean train loss 1743.2661287154274
INFO:root:current train perplexity3.9678077697753906
INFO:root:current mean train loss 1748.4771184990875
INFO:root:current train perplexity3.9655182361602783
INFO:root:current mean train loss 1747.9629128196023
INFO:root:current train perplexity3.960346221923828
INFO:root:current mean train loss 1750.0469429885284
INFO:root:current train perplexity3.967618227005005
INFO:root:current mean train loss 1748.8355787323742
INFO:root:current train perplexity3.972055196762085
INFO:root:current mean train loss 1747.6616379372797
INFO:root:current train perplexity3.968571424484253
INFO:root:current mean train loss 1749.4841966259387
INFO:root:current train perplexity3.9729437828063965
INFO:root:current mean train loss 1749.5658527435373
INFO:root:current train perplexity3.9717280864715576
INFO:root:current mean train loss 1751.0175975509737
INFO:root:current train perplexity3.974116563796997
INFO:root:current mean train loss 1751.1325895000437
INFO:root:current train perplexity3.9728944301605225
INFO:root:current mean train loss 1751.615402091707
INFO:root:current train perplexity3.972795009613037
INFO:root:current mean train loss 1750.423543262332
INFO:root:current train perplexity3.9726481437683105
INFO:root:current mean train loss 1752.5763177552424
INFO:root:current train perplexity3.9785633087158203
INFO:root:current mean train loss 1751.727841174101
INFO:root:current train perplexity3.978139877319336
INFO:root:current mean train loss 1751.2526938451745
INFO:root:current train perplexity3.9782752990722656
INFO:root:current mean train loss 1751.630306193763
INFO:root:current train perplexity3.9795751571655273
INFO:root:current mean train loss 1751.4347640148278
INFO:root:current train perplexity3.979414701461792
INFO:root:current mean train loss 1751.9928652703318
INFO:root:current train perplexity3.9804389476776123
INFO:root:current mean train loss 1752.2039157361123
INFO:root:current train perplexity3.9813122749328613

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.19s/it]
INFO:root:final mean train loss: 1751.9372077822625
INFO:root:final train perplexity: 3.981597423553467
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.85s/it]
INFO:root:eval mean loss: 2893.5987955729165
INFO:root:eval perplexity: 10.744660377502441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/76
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [6:48:16<2:07:38, 319.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1747.067405616844
INFO:root:current train perplexity3.984987497329712
INFO:root:current mean train loss 1750.8291488567572
INFO:root:current train perplexity3.988264560699463
INFO:root:current mean train loss 1746.0514473931487
INFO:root:current train perplexity3.971748113632202
INFO:root:current mean train loss 1745.6991853445693
INFO:root:current train perplexity3.966392993927002
INFO:root:current mean train loss 1746.7066098463754
INFO:root:current train perplexity3.9687893390655518
INFO:root:current mean train loss 1744.5546839886713
INFO:root:current train perplexity3.9582223892211914
INFO:root:current mean train loss 1745.3549267648789
INFO:root:current train perplexity3.9609973430633545
INFO:root:current mean train loss 1747.390210331315
INFO:root:current train perplexity3.9623305797576904
INFO:root:current mean train loss 1747.2312729618232
INFO:root:current train perplexity3.963991165161133
INFO:root:current mean train loss 1747.3715958272894
INFO:root:current train perplexity3.966035842895508
INFO:root:current mean train loss 1748.517931133099
INFO:root:current train perplexity3.967067241668701
INFO:root:current mean train loss 1749.4826556637345
INFO:root:current train perplexity3.9691803455352783
INFO:root:current mean train loss 1748.6554690714866
INFO:root:current train perplexity3.9687623977661133
INFO:root:current mean train loss 1749.1370228288158
INFO:root:current train perplexity3.9708011150360107
INFO:root:current mean train loss 1749.3973866801066
INFO:root:current train perplexity3.9703421592712402
INFO:root:current mean train loss 1749.8841551199864
INFO:root:current train perplexity3.971644878387451
INFO:root:current mean train loss 1749.3264121896484
INFO:root:current train perplexity3.969958782196045
INFO:root:current mean train loss 1749.936814743204
INFO:root:current train perplexity3.972379207611084
INFO:root:current mean train loss 1749.559503241609
INFO:root:current train perplexity3.972532033920288

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.77s/it]
INFO:root:final mean train loss: 1749.5607699626512
INFO:root:final train perplexity: 3.974142074584961
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.92s/it]
INFO:root:eval mean loss: 2895.9766101550767
INFO:root:eval perplexity: 10.765645980834961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/77
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [6:53:33<2:02:06, 318.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1698.0272216796875
INFO:root:current train perplexity3.8437118530273438
INFO:root:current mean train loss 1736.7368797019676
INFO:root:current train perplexity3.9480273723602295
INFO:root:current mean train loss 1744.0516463059646
INFO:root:current train perplexity3.948092222213745
INFO:root:current mean train loss 1745.146235874721
INFO:root:current train perplexity3.9536828994750977
INFO:root:current mean train loss 1746.524777281518
INFO:root:current train perplexity3.9526917934417725
INFO:root:current mean train loss 1744.5568182036632
INFO:root:current train perplexity3.9510183334350586
INFO:root:current mean train loss 1744.9582395051655
INFO:root:current train perplexity3.9544482231140137
INFO:root:current mean train loss 1744.2617515089821
INFO:root:current train perplexity3.9572649002075195
INFO:root:current mean train loss 1747.6390173883722
INFO:root:current train perplexity3.9623334407806396
INFO:root:current mean train loss 1748.309992987679
INFO:root:current train perplexity3.9651527404785156
INFO:root:current mean train loss 1748.6808193146237
INFO:root:current train perplexity3.9638521671295166
INFO:root:current mean train loss 1747.1754488617935
INFO:root:current train perplexity3.9634761810302734
INFO:root:current mean train loss 1746.1669627814892
INFO:root:current train perplexity3.9611105918884277
INFO:root:current mean train loss 1746.3777222239644
INFO:root:current train perplexity3.961779832839966
INFO:root:current mean train loss 1747.3794997822154
INFO:root:current train perplexity3.9657669067382812
INFO:root:current mean train loss 1747.3550648170694
INFO:root:current train perplexity3.965465784072876
INFO:root:current mean train loss 1746.895854209786
INFO:root:current train perplexity3.9658303260803223
INFO:root:current mean train loss 1748.2112284533034
INFO:root:current train perplexity3.966935634613037
INFO:root:current mean train loss 1748.1169097360257
INFO:root:current train perplexity3.9674999713897705
INFO:root:current mean train loss 1747.6791502754643
INFO:root:current train perplexity3.967543363571167

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.36s/it]
INFO:root:final mean train loss: 1748.1232803660214
INFO:root:final train perplexity: 3.969639301300049
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.78s/it]
INFO:root:eval mean loss: 2897.0018226234047
INFO:root:eval perplexity: 10.774707794189453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/78
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [6:58:51<1:56:42, 318.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1749.1876708984375
INFO:root:current train perplexity3.9909369945526123
INFO:root:current mean train loss 1733.3462392578126
INFO:root:current train perplexity3.937227249145508
INFO:root:current mean train loss 1743.8341362847223
INFO:root:current train perplexity3.969658136367798
INFO:root:current mean train loss 1739.2953774789664
INFO:root:current train perplexity3.9638068675994873
INFO:root:current mean train loss 1742.9398075597426
INFO:root:current train perplexity3.963212013244629
INFO:root:current mean train loss 1742.505871000744
INFO:root:current train perplexity3.9609270095825195
INFO:root:current mean train loss 1743.3129314453124
INFO:root:current train perplexity3.9578166007995605
INFO:root:current mean train loss 1743.7266867591595
INFO:root:current train perplexity3.956185817718506
INFO:root:current mean train loss 1743.522187647964
INFO:root:current train perplexity3.9589245319366455
INFO:root:current mean train loss 1742.0212480204814
INFO:root:current train perplexity3.95747447013855
INFO:root:current mean train loss 1741.835254025343
INFO:root:current train perplexity3.958510160446167
INFO:root:current mean train loss 1743.5538160807291
INFO:root:current train perplexity3.9598872661590576
INFO:root:current mean train loss 1743.9963031130421
INFO:root:current train perplexity3.9607224464416504
INFO:root:current mean train loss 1745.156892504422
INFO:root:current train perplexity3.96156907081604
INFO:root:current mean train loss 1744.529872361568
INFO:root:current train perplexity3.9597887992858887
INFO:root:current mean train loss 1744.957375288166
INFO:root:current train perplexity3.960817337036133
INFO:root:current mean train loss 1745.1223645582932
INFO:root:current train perplexity3.9595508575439453
INFO:root:current mean train loss 1746.2374603006115
INFO:root:current train perplexity3.9607417583465576
INFO:root:current mean train loss 1746.1602351107663
INFO:root:current train perplexity3.9642605781555176
INFO:root:current mean train loss 1746.6323667055601
INFO:root:current train perplexity3.964357852935791

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.15s/it]
INFO:root:final mean train loss: 1746.41747892979
INFO:root:final train perplexity: 3.9643025398254395
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.89s/it]
INFO:root:eval mean loss: 2898.3484722515486
INFO:root:eval perplexity: 10.786619186401367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/79
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [7:04:09<1:51:19, 318.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1743.9503726050966
INFO:root:current train perplexity3.9345622062683105
INFO:root:current mean train loss 1740.2803293147558
INFO:root:current train perplexity3.94585919380188
INFO:root:current mean train loss 1739.3715709339488
INFO:root:current train perplexity3.9438958168029785
INFO:root:current mean train loss 1746.2258400721857
INFO:root:current train perplexity3.9550139904022217
INFO:root:current mean train loss 1744.7570173859058
INFO:root:current train perplexity3.9470884799957275
INFO:root:current mean train loss 1746.691638003416
INFO:root:current train perplexity3.9513614177703857
INFO:root:current mean train loss 1746.1952003170024
INFO:root:current train perplexity3.9483962059020996
INFO:root:current mean train loss 1745.9281344760782
INFO:root:current train perplexity3.953146457672119
INFO:root:current mean train loss 1746.7654363854197
INFO:root:current train perplexity3.958989143371582
INFO:root:current mean train loss 1748.2616172839123
INFO:root:current train perplexity3.963709592819214
INFO:root:current mean train loss 1746.3769104823957
INFO:root:current train perplexity3.9611172676086426
INFO:root:current mean train loss 1744.906538607569
INFO:root:current train perplexity3.958033561706543
INFO:root:current mean train loss 1745.5521574404313
INFO:root:current train perplexity3.958157539367676
INFO:root:current mean train loss 1745.155779911047
INFO:root:current train perplexity3.9586408138275146
INFO:root:current mean train loss 1745.0657608518984
INFO:root:current train perplexity3.9572441577911377
INFO:root:current mean train loss 1745.0314650084104
INFO:root:current train perplexity3.9571163654327393
INFO:root:current mean train loss 1746.1916263036694
INFO:root:current train perplexity3.9598934650421143
INFO:root:current mean train loss 1745.6045757166692
INFO:root:current train perplexity3.9596352577209473
INFO:root:current mean train loss 1744.2423965172452
INFO:root:current train perplexity3.9585657119750977
INFO:root:current mean train loss 1744.3108052215418
INFO:root:current train perplexity3.957980155944824

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.29s/it]
INFO:root:final mean train loss: 1744.0711218698784
INFO:root:final train perplexity: 3.9569735527038574
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.66s/it]
INFO:root:eval mean loss: 2899.434865773977
INFO:root:eval perplexity: 10.796241760253906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/80
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [7:09:26<1:45:58, 317.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1724.9214694782838
INFO:root:current train perplexity3.957857608795166
INFO:root:current mean train loss 1744.505007186026
INFO:root:current train perplexity3.963759183883667
INFO:root:current mean train loss 1736.062662603312
INFO:root:current train perplexity3.940443515777588
INFO:root:current mean train loss 1734.4281699517976
INFO:root:current train perplexity3.940199375152588
INFO:root:current mean train loss 1735.539460092848
INFO:root:current train perplexity3.9382283687591553
INFO:root:current mean train loss 1735.9295761299475
INFO:root:current train perplexity3.933798313140869
INFO:root:current mean train loss 1736.9934369146551
INFO:root:current train perplexity3.9326424598693848
INFO:root:current mean train loss 1738.625060954741
INFO:root:current train perplexity3.938211679458618
INFO:root:current mean train loss 1739.4508620807262
INFO:root:current train perplexity3.94256591796875
INFO:root:current mean train loss 1738.6166481757934
INFO:root:current train perplexity3.9428842067718506
INFO:root:current mean train loss 1738.7112611765226
INFO:root:current train perplexity3.944164752960205
INFO:root:current mean train loss 1740.2424168952896
INFO:root:current train perplexity3.9450652599334717
INFO:root:current mean train loss 1741.4039966925636
INFO:root:current train perplexity3.9477975368499756
INFO:root:current mean train loss 1741.4804540189248
INFO:root:current train perplexity3.949796438217163
INFO:root:current mean train loss 1742.0469533124144
INFO:root:current train perplexity3.9518625736236572
INFO:root:current mean train loss 1742.1542742461866
INFO:root:current train perplexity3.9509222507476807
INFO:root:current mean train loss 1742.5082100562981
INFO:root:current train perplexity3.9526426792144775
INFO:root:current mean train loss 1742.33891160194
INFO:root:current train perplexity3.951977491378784
INFO:root:current mean train loss 1742.3122842921052
INFO:root:current train perplexity3.9511046409606934
INFO:root:current mean train loss 1742.669163157223
INFO:root:current train perplexity3.9521753787994385

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.81s/it]
INFO:root:final mean train loss: 1742.6752588038364
INFO:root:final train perplexity: 3.9526195526123047
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.19s/it]
INFO:root:eval mean loss: 2899.733673370636
INFO:root:eval perplexity: 10.798888206481934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/81
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [7:14:47<1:40:55, 318.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1742.8428184107731
INFO:root:current train perplexity3.9808361530303955
INFO:root:current mean train loss 1748.6377570412376
INFO:root:current train perplexity3.9703245162963867
INFO:root:current mean train loss 1748.7630960215693
INFO:root:current train perplexity3.9611215591430664
INFO:root:current mean train loss 1741.9138664083277
INFO:root:current train perplexity3.9456770420074463
INFO:root:current mean train loss 1740.8209728593586
INFO:root:current train perplexity3.9456348419189453
INFO:root:current mean train loss 1741.4645072089302
INFO:root:current train perplexity3.9459357261657715
INFO:root:current mean train loss 1741.1091258032081
INFO:root:current train perplexity3.944688081741333
INFO:root:current mean train loss 1739.92866531844
INFO:root:current train perplexity3.94523549079895
INFO:root:current mean train loss 1741.948319944617
INFO:root:current train perplexity3.942660331726074
INFO:root:current mean train loss 1742.4098474471296
INFO:root:current train perplexity3.9442789554595947
INFO:root:current mean train loss 1739.882865139986
INFO:root:current train perplexity3.9415273666381836
INFO:root:current mean train loss 1739.734403649155
INFO:root:current train perplexity3.943878412246704
INFO:root:current mean train loss 1741.6040507827806
INFO:root:current train perplexity3.9469199180603027
INFO:root:current mean train loss 1742.1084977970568
INFO:root:current train perplexity3.9464824199676514
INFO:root:current mean train loss 1742.542320851065
INFO:root:current train perplexity3.945566177368164
INFO:root:current mean train loss 1742.727533020949
INFO:root:current train perplexity3.9462673664093018
INFO:root:current mean train loss 1743.3533412596491
INFO:root:current train perplexity3.946974515914917
INFO:root:current mean train loss 1742.4508039457303
INFO:root:current train perplexity3.9471166133880615
INFO:root:current mean train loss 1741.833698915266
INFO:root:current train perplexity3.947988271713257
INFO:root:current mean train loss 1741.890495825393
INFO:root:current train perplexity3.9484710693359375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.69s/it]
INFO:root:final mean train loss: 1741.1711817292692
INFO:root:final train perplexity: 3.9479336738586426
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.04s/it]
INFO:root:eval mean loss: 2900.5393748240426
INFO:root:eval perplexity: 10.8060302734375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/82
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [7:20:06<1:35:40, 318.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1745.1638249222951
INFO:root:current train perplexity3.9553322792053223
INFO:root:current mean train loss 1753.2428016464944
INFO:root:current train perplexity3.9581189155578613
INFO:root:current mean train loss 1737.869193952645
INFO:root:current train perplexity3.9404313564300537
INFO:root:current mean train loss 1737.8253677018727
INFO:root:current train perplexity3.9404079914093018
INFO:root:current mean train loss 1737.613050727767
INFO:root:current train perplexity3.9381556510925293
INFO:root:current mean train loss 1735.926012627793
INFO:root:current train perplexity3.938603639602661
INFO:root:current mean train loss 1736.9418126225987
INFO:root:current train perplexity3.942864418029785
INFO:root:current mean train loss 1736.537881204189
INFO:root:current train perplexity3.9435672760009766
INFO:root:current mean train loss 1737.8416301048082
INFO:root:current train perplexity3.949305772781372
INFO:root:current mean train loss 1739.4916023492574
INFO:root:current train perplexity3.95078444480896
INFO:root:current mean train loss 1739.014846899481
INFO:root:current train perplexity3.948761463165283
INFO:root:current mean train loss 1738.089375933178
INFO:root:current train perplexity3.946084499359131
INFO:root:current mean train loss 1738.236171689959
INFO:root:current train perplexity3.9458582401275635
INFO:root:current mean train loss 1738.9440990702676
INFO:root:current train perplexity3.944628953933716
INFO:root:current mean train loss 1738.7832323139494
INFO:root:current train perplexity3.943291187286377
INFO:root:current mean train loss 1739.6845903127207
INFO:root:current train perplexity3.9442734718322754
INFO:root:current mean train loss 1739.9881841273118
INFO:root:current train perplexity3.9437971115112305
INFO:root:current mean train loss 1739.9316490671188
INFO:root:current train perplexity3.945016860961914
INFO:root:current mean train loss 1740.3743839737479
INFO:root:current train perplexity3.9437246322631836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.15s/it]
INFO:root:final mean train loss: 1739.3723632689382
INFO:root:final train perplexity: 3.9423370361328125
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.24s/it]
INFO:root:eval mean loss: 2901.581647076764
INFO:root:eval perplexity: 10.815275192260742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/83
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [7:25:25<1:30:21, 318.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1764.4819946289062
INFO:root:current train perplexity3.9540584087371826
INFO:root:current mean train loss 1737.2018277254972
INFO:root:current train perplexity3.915771722793579
INFO:root:current mean train loss 1739.672179594494
INFO:root:current train perplexity3.918458938598633
INFO:root:current mean train loss 1738.7540881741431
INFO:root:current train perplexity3.9256057739257812
INFO:root:current mean train loss 1734.1427460461127
INFO:root:current train perplexity3.924542188644409
INFO:root:current mean train loss 1733.243530512791
INFO:root:current train perplexity3.9312283992767334
INFO:root:current mean train loss 1734.6356889568392
INFO:root:current train perplexity3.9367475509643555
INFO:root:current mean train loss 1734.291728618783
INFO:root:current train perplexity3.9373648166656494
INFO:root:current mean train loss 1735.042125259211
INFO:root:current train perplexity3.936537265777588
INFO:root:current mean train loss 1735.9473737444196
INFO:root:current train perplexity3.9360034465789795
INFO:root:current mean train loss 1735.4071312026222
INFO:root:current train perplexity3.932882070541382
INFO:root:current mean train loss 1735.6375863290048
INFO:root:current train perplexity3.934739589691162
INFO:root:current mean train loss 1736.5216758538868
INFO:root:current train perplexity3.936582326889038
INFO:root:current mean train loss 1737.5833006880666
INFO:root:current train perplexity3.9373042583465576
INFO:root:current mean train loss 1737.153497184591
INFO:root:current train perplexity3.9379289150238037
INFO:root:current mean train loss 1738.0529424604201
INFO:root:current train perplexity3.938413381576538
INFO:root:current mean train loss 1738.1266781256065
INFO:root:current train perplexity3.9375510215759277
INFO:root:current mean train loss 1738.028115291484
INFO:root:current train perplexity3.9371578693389893
INFO:root:current mean train loss 1736.9892434473195
INFO:root:current train perplexity3.937331438064575
INFO:root:current mean train loss 1737.4829474803664
INFO:root:current train perplexity3.936030626296997

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.04s/it]
INFO:root:final mean train loss: 1737.1036598563376
INFO:root:final train perplexity: 3.935289144515991
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.97s/it]
INFO:root:eval mean loss: 2902.0874829908034
INFO:root:eval perplexity: 10.819765090942383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/84
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [7:30:45<1:25:05, 319.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1715.5244050202546
INFO:root:current train perplexity3.908564805984497
INFO:root:current mean train loss 1720.3859103946236
INFO:root:current train perplexity3.9140613079071045
INFO:root:current mean train loss 1727.7327746420706
INFO:root:current train perplexity3.9248197078704834
INFO:root:current mean train loss 1731.6767753577742
INFO:root:current train perplexity3.9240708351135254
INFO:root:current mean train loss 1731.4783798324977
INFO:root:current train perplexity3.9181716442108154
INFO:root:current mean train loss 1730.5638247061047
INFO:root:current train perplexity3.922377347946167
INFO:root:current mean train loss 1730.742169393877
INFO:root:current train perplexity3.925753593444824
INFO:root:current mean train loss 1730.6634795177097
INFO:root:current train perplexity3.924851179122925
INFO:root:current mean train loss 1730.665883369861
INFO:root:current train perplexity3.924180269241333
INFO:root:current mean train loss 1732.4743811680403
INFO:root:current train perplexity3.92577862739563
INFO:root:current mean train loss 1733.078531267116
INFO:root:current train perplexity3.9262852668762207
INFO:root:current mean train loss 1734.6255330150912
INFO:root:current train perplexity3.928586959838867
INFO:root:current mean train loss 1735.3874208283987
INFO:root:current train perplexity3.9291269779205322
INFO:root:current mean train loss 1735.988799979836
INFO:root:current train perplexity3.9310357570648193
INFO:root:current mean train loss 1737.3019912602103
INFO:root:current train perplexity3.9327750205993652
INFO:root:current mean train loss 1737.9611020990658
INFO:root:current train perplexity3.9332809448242188
INFO:root:current mean train loss 1737.99175436422
INFO:root:current train perplexity3.933220148086548
INFO:root:current mean train loss 1737.842799873109
INFO:root:current train perplexity3.934108257293701
INFO:root:current mean train loss 1737.0397718708307
INFO:root:current train perplexity3.9332895278930664
INFO:root:current mean train loss 1736.690293680774
INFO:root:current train perplexity3.932932138442993

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.38s/it]
INFO:root:final mean train loss: 1736.5939831216708
INFO:root:final train perplexity: 3.9337077140808105
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.69s/it]
INFO:root:eval mean loss: 2901.302927927928
INFO:root:eval perplexity: 10.8128023147583
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/85
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [7:36:03<1:19:44, 318.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1710.4817615855825
INFO:root:current train perplexity3.9252912998199463
INFO:root:current mean train loss 1712.4680667453342
INFO:root:current train perplexity3.9307937622070312
INFO:root:current mean train loss 1726.533175609151
INFO:root:current train perplexity3.937497138977051
INFO:root:current mean train loss 1728.5921382460483
INFO:root:current train perplexity3.9278860092163086
INFO:root:current mean train loss 1731.0375355213612
INFO:root:current train perplexity3.9295737743377686
INFO:root:current mean train loss 1734.47920182172
INFO:root:current train perplexity3.9305782318115234
INFO:root:current mean train loss 1737.150486158288
INFO:root:current train perplexity3.9279046058654785
INFO:root:current mean train loss 1735.10330183788
INFO:root:current train perplexity3.9244818687438965
INFO:root:current mean train loss 1737.1420279407953
INFO:root:current train perplexity3.9280171394348145
INFO:root:current mean train loss 1736.0559146687135
INFO:root:current train perplexity3.9274659156799316
INFO:root:current mean train loss 1735.4251245959051
INFO:root:current train perplexity3.932051181793213
INFO:root:current mean train loss 1735.3671235838137
INFO:root:current train perplexity3.9301869869232178
INFO:root:current mean train loss 1735.0566058879497
INFO:root:current train perplexity3.9295058250427246
INFO:root:current mean train loss 1733.918278830392
INFO:root:current train perplexity3.9286956787109375
INFO:root:current mean train loss 1734.7269480697337
INFO:root:current train perplexity3.9294397830963135
INFO:root:current mean train loss 1734.940435379898
INFO:root:current train perplexity3.9291133880615234
INFO:root:current mean train loss 1735.4937401838836
INFO:root:current train perplexity3.929394006729126
INFO:root:current mean train loss 1735.52939717704
INFO:root:current train perplexity3.9281880855560303
INFO:root:current mean train loss 1735.5795253662639
INFO:root:current train perplexity3.9288618564605713
INFO:root:current mean train loss 1735.6686872945402
INFO:root:current train perplexity3.9277572631835938

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.58s/it]
INFO:root:final mean train loss: 1734.6190445938919
INFO:root:final train perplexity: 3.9275858402252197
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.41s/it]
INFO:root:eval mean loss: 2904.221096829251
INFO:root:eval perplexity: 10.83872127532959
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/86
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [7:41:21<1:14:19, 318.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1729.7534619941086
INFO:root:current train perplexity3.9114644527435303
INFO:root:current mean train loss 1715.975374399505
INFO:root:current train perplexity3.904017210006714
INFO:root:current mean train loss 1720.7381844356141
INFO:root:current train perplexity3.903831958770752
INFO:root:current mean train loss 1723.928012330116
INFO:root:current train perplexity3.907891273498535
INFO:root:current mean train loss 1725.2925712932993
INFO:root:current train perplexity3.9171745777130127
INFO:root:current mean train loss 1726.271666283701
INFO:root:current train perplexity3.9225759506225586
INFO:root:current mean train loss 1726.8277504786781
INFO:root:current train perplexity3.9207980632781982
INFO:root:current mean train loss 1727.850094929318
INFO:root:current train perplexity3.921588897705078
INFO:root:current mean train loss 1729.3996882599267
INFO:root:current train perplexity3.922332763671875
INFO:root:current mean train loss 1729.8984362297574
INFO:root:current train perplexity3.920647144317627
INFO:root:current mean train loss 1731.1846846743197
INFO:root:current train perplexity3.9246914386749268
INFO:root:current mean train loss 1732.2363951007012
INFO:root:current train perplexity3.9242591857910156
INFO:root:current mean train loss 1731.673832287588
INFO:root:current train perplexity3.92108416557312
INFO:root:current mean train loss 1732.0738199809998
INFO:root:current train perplexity3.922161102294922
INFO:root:current mean train loss 1733.199140628342
INFO:root:current train perplexity3.9266791343688965
INFO:root:current mean train loss 1733.4207816065923
INFO:root:current train perplexity3.925628662109375
INFO:root:current mean train loss 1732.9875153157454
INFO:root:current train perplexity3.923293352127075
INFO:root:current mean train loss 1733.0141362412826
INFO:root:current train perplexity3.923088550567627
INFO:root:current mean train loss 1733.6197863316934
INFO:root:current train perplexity3.9234538078308105
INFO:root:current mean train loss 1733.9123028449292
INFO:root:current train perplexity3.923999547958374

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.36s/it]
INFO:root:final mean train loss: 1733.4110960005753
INFO:root:final train perplexity: 3.9238457679748535
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.67s/it]
INFO:root:eval mean loss: 2902.737227706222
INFO:root:eval perplexity: 10.82553482055664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/87
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [7:46:37<1:08:53, 317.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1736.0094635792268
INFO:root:current train perplexity3.926619052886963
INFO:root:current mean train loss 1734.7232885467872
INFO:root:current train perplexity3.90641713142395
INFO:root:current mean train loss 1737.4085605539005
INFO:root:current train perplexity3.911346197128296
INFO:root:current mean train loss 1738.5447594375207
INFO:root:current train perplexity3.920149803161621
INFO:root:current mean train loss 1738.6977807208584
INFO:root:current train perplexity3.9211809635162354
INFO:root:current mean train loss 1737.7921326317178
INFO:root:current train perplexity3.924042224884033
INFO:root:current mean train loss 1735.7048078778923
INFO:root:current train perplexity3.9204680919647217
INFO:root:current mean train loss 1732.4013039557058
INFO:root:current train perplexity3.9167754650115967
INFO:root:current mean train loss 1731.0941908712539
INFO:root:current train perplexity3.913748025894165
INFO:root:current mean train loss 1729.8045219936255
INFO:root:current train perplexity3.9119467735290527
INFO:root:current mean train loss 1730.4143682419701
INFO:root:current train perplexity3.911752700805664
INFO:root:current mean train loss 1730.7980364295947
INFO:root:current train perplexity3.909484386444092
INFO:root:current mean train loss 1731.265106630997
INFO:root:current train perplexity3.9102249145507812
INFO:root:current mean train loss 1729.8832271670049
INFO:root:current train perplexity3.909684181213379
INFO:root:current mean train loss 1730.604560986262
INFO:root:current train perplexity3.9134933948516846
INFO:root:current mean train loss 1730.9978534809688
INFO:root:current train perplexity3.9140424728393555
INFO:root:current mean train loss 1732.3224090830788
INFO:root:current train perplexity3.917369842529297
INFO:root:current mean train loss 1731.869262008753
INFO:root:current train perplexity3.918102979660034
INFO:root:current mean train loss 1732.0153178742137
INFO:root:current train perplexity3.9185893535614014
INFO:root:current mean train loss 1732.2154360810714
INFO:root:current train perplexity3.91890287399292

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.07s/it]
INFO:root:final mean train loss: 1731.77057140233
INFO:root:final train perplexity: 3.918771982192993
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.71s/it]
INFO:root:eval mean loss: 2905.0471044775245
INFO:root:eval perplexity: 10.846073150634766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/88
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [7:51:56<1:03:36, 318.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1750.5365439967106
INFO:root:current train perplexity3.9491593837738037
INFO:root:current mean train loss 1741.7364063752004
INFO:root:current train perplexity3.92521333694458
INFO:root:current mean train loss 1739.0128587625795
INFO:root:current train perplexity3.9279088973999023
INFO:root:current mean train loss 1733.5445735883109
INFO:root:current train perplexity3.917454242706299
INFO:root:current mean train loss 1732.0240919941602
INFO:root:current train perplexity3.9109787940979004
INFO:root:current mean train loss 1730.0397889722294
INFO:root:current train perplexity3.9069082736968994
INFO:root:current mean train loss 1731.24890435308
INFO:root:current train perplexity3.9148166179656982
INFO:root:current mean train loss 1733.2047750221109
INFO:root:current train perplexity3.9174654483795166
INFO:root:current mean train loss 1732.5763052657996
INFO:root:current train perplexity3.9192955493927
INFO:root:current mean train loss 1731.7624759539888
INFO:root:current train perplexity3.9164135456085205
INFO:root:current mean train loss 1732.0906000285388
INFO:root:current train perplexity3.916196823120117
INFO:root:current mean train loss 1731.3833371469666
INFO:root:current train perplexity3.9142394065856934
INFO:root:current mean train loss 1731.2884270745355
INFO:root:current train perplexity3.913757085800171
INFO:root:current mean train loss 1730.0272210671483
INFO:root:current train perplexity3.914776563644409
INFO:root:current mean train loss 1730.5523822899247
INFO:root:current train perplexity3.9122605323791504
INFO:root:current mean train loss 1730.2355756514498
INFO:root:current train perplexity3.912012815475464
INFO:root:current mean train loss 1730.6230177077573
INFO:root:current train perplexity3.913705587387085
INFO:root:current mean train loss 1731.3717040335569
INFO:root:current train perplexity3.917226791381836
INFO:root:current mean train loss 1731.7655454449414
INFO:root:current train perplexity3.917896032333374

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.04s/it]
INFO:root:final mean train loss: 1731.3420083281133
INFO:root:final train perplexity: 3.9174487590789795
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.85s/it]
INFO:root:eval mean loss: 2904.6215637023743
INFO:root:eval perplexity: 10.842286109924316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/89
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [7:57:15<58:23, 318.49s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1719.841552734375
INFO:root:current train perplexity3.8969175815582275
INFO:root:current mean train loss 1735.3398600987025
INFO:root:current train perplexity3.9177088737487793
INFO:root:current mean train loss 1728.165048851157
INFO:root:current train perplexity3.911440372467041
INFO:root:current mean train loss 1726.955837543194
INFO:root:current train perplexity3.9115681648254395
INFO:root:current mean train loss 1729.1691986380272
INFO:root:current train perplexity3.9169397354125977
INFO:root:current mean train loss 1727.7025697231293
INFO:root:current train perplexity3.91221022605896
INFO:root:current mean train loss 1726.3138764823964
INFO:root:current train perplexity3.911224842071533
INFO:root:current mean train loss 1725.8321946390558
INFO:root:current train perplexity3.909449338912964
INFO:root:current mean train loss 1725.1655787576008
INFO:root:current train perplexity3.904566764831543
INFO:root:current mean train loss 1724.8775052522358
INFO:root:current train perplexity3.903169870376587
INFO:root:current mean train loss 1726.3419747936866
INFO:root:current train perplexity3.9042470455169678
INFO:root:current mean train loss 1726.322120831167
INFO:root:current train perplexity3.906834840774536
INFO:root:current mean train loss 1726.2286138251277
INFO:root:current train perplexity3.907484531402588
INFO:root:current mean train loss 1727.7631019964451
INFO:root:current train perplexity3.9075422286987305
INFO:root:current mean train loss 1728.9331847452916
INFO:root:current train perplexity3.9081149101257324
INFO:root:current mean train loss 1728.7958944007833
INFO:root:current train perplexity3.9079601764678955
INFO:root:current mean train loss 1727.9213136431597
INFO:root:current train perplexity3.907454252243042
INFO:root:current mean train loss 1728.8133954199675
INFO:root:current train perplexity3.9103591442108154
INFO:root:current mean train loss 1729.1044877412303
INFO:root:current train perplexity3.9107651710510254
INFO:root:current mean train loss 1730.1805603793475
INFO:root:current train perplexity3.9127907752990723

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.47s/it]
INFO:root:final mean train loss: 1729.8429298574013
INFO:root:final train perplexity: 3.9128189086914062
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.48s/it]
INFO:root:eval mean loss: 2903.7547904349663
INFO:root:eval perplexity: 10.834574699401855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/90
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [8:02:36<53:10, 319.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1711.4508645945582
INFO:root:current train perplexity3.941880702972412
INFO:root:current mean train loss 1721.8579016397166
INFO:root:current train perplexity3.89399790763855
INFO:root:current mean train loss 1728.9310873106579
INFO:root:current train perplexity3.8969666957855225
INFO:root:current mean train loss 1731.7036745019234
INFO:root:current train perplexity3.902777910232544
INFO:root:current mean train loss 1735.0599678235176
INFO:root:current train perplexity3.903007984161377
INFO:root:current mean train loss 1732.9158275582615
INFO:root:current train perplexity3.9047162532806396
INFO:root:current mean train loss 1733.5818789046975
INFO:root:current train perplexity3.9089908599853516
INFO:root:current mean train loss 1733.1503698613255
INFO:root:current train perplexity3.903898000717163
INFO:root:current mean train loss 1733.0146490265004
INFO:root:current train perplexity3.9053502082824707
INFO:root:current mean train loss 1731.4325432094743
INFO:root:current train perplexity3.9048149585723877
INFO:root:current mean train loss 1731.6514116737656
INFO:root:current train perplexity3.905815362930298
INFO:root:current mean train loss 1729.1072222808486
INFO:root:current train perplexity3.9028828144073486
INFO:root:current mean train loss 1729.4692072918785
INFO:root:current train perplexity3.904370069503784
INFO:root:current mean train loss 1728.7094791776888
INFO:root:current train perplexity3.905681848526001
INFO:root:current mean train loss 1728.2039568549358
INFO:root:current train perplexity3.907493829727173
INFO:root:current mean train loss 1728.3238959702267
INFO:root:current train perplexity3.9083192348480225
INFO:root:current mean train loss 1727.8840500636654
INFO:root:current train perplexity3.9067342281341553
INFO:root:current mean train loss 1728.3234171384743
INFO:root:current train perplexity3.9079651832580566
INFO:root:current mean train loss 1729.1980860789922
INFO:root:current train perplexity3.908754587173462
INFO:root:current mean train loss 1728.8771435395
INFO:root:current train perplexity3.907874345779419

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.34s/it]
INFO:root:final mean train loss: 1728.2600530719612
INFO:root:final train perplexity: 3.90793776512146
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.49s/it]
INFO:root:eval mean loss: 2905.277373809356
INFO:root:eval perplexity: 10.848121643066406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/91
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [8:07:53<47:47, 318.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1735.475859268852
INFO:root:current train perplexity3.9456024169921875
INFO:root:current mean train loss 1727.051976870184
INFO:root:current train perplexity3.9120521545410156
INFO:root:current mean train loss 1727.663061126461
INFO:root:current train perplexity3.9092819690704346
INFO:root:current mean train loss 1725.4721778472724
INFO:root:current train perplexity3.902693748474121
INFO:root:current mean train loss 1727.488713148998
INFO:root:current train perplexity3.91194486618042
INFO:root:current mean train loss 1727.407993861607
INFO:root:current train perplexity3.910503625869751
INFO:root:current mean train loss 1727.3603562865833
INFO:root:current train perplexity3.9094245433807373
INFO:root:current mean train loss 1725.4673880814867
INFO:root:current train perplexity3.905709743499756
INFO:root:current mean train loss 1724.0946154583148
INFO:root:current train perplexity3.9055850505828857
INFO:root:current mean train loss 1725.2853110960623
INFO:root:current train perplexity3.9066267013549805
INFO:root:current mean train loss 1727.3439014792214
INFO:root:current train perplexity3.9105801582336426
INFO:root:current mean train loss 1727.7302363264207
INFO:root:current train perplexity3.9107377529144287
INFO:root:current mean train loss 1727.6688891758315
INFO:root:current train perplexity3.9070961475372314
INFO:root:current mean train loss 1727.7497444322878
INFO:root:current train perplexity3.9089622497558594
INFO:root:current mean train loss 1728.01273287909
INFO:root:current train perplexity3.9070258140563965
INFO:root:current mean train loss 1728.145171369032
INFO:root:current train perplexity3.9073164463043213
INFO:root:current mean train loss 1727.5639697384283
INFO:root:current train perplexity3.9066121578216553
INFO:root:current mean train loss 1727.666994284928
INFO:root:current train perplexity3.906834840774536
INFO:root:current mean train loss 1727.7299081258886
INFO:root:current train perplexity3.9062447547912598
INFO:root:current mean train loss 1727.628712606087
INFO:root:current train perplexity3.905416488647461

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.21s/it]
INFO:root:final mean train loss: 1727.443015694438
INFO:root:final train perplexity: 3.9054205417633057
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.07s/it]
INFO:root:eval mean loss: 2905.477313983906
INFO:root:eval perplexity: 10.84990406036377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/92
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [8:13:11<42:26, 318.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1725.959732297867
INFO:root:current train perplexity3.8993473052978516
INFO:root:current mean train loss 1722.829839975556
INFO:root:current train perplexity3.8725881576538086
INFO:root:current mean train loss 1723.7729111588046
INFO:root:current train perplexity3.894402265548706
INFO:root:current mean train loss 1722.60304550297
INFO:root:current train perplexity3.899620294570923
INFO:root:current mean train loss 1727.5603095892955
INFO:root:current train perplexity3.9042744636535645
INFO:root:current mean train loss 1728.474264195715
INFO:root:current train perplexity3.906740188598633
INFO:root:current mean train loss 1728.581320554063
INFO:root:current train perplexity3.906010150909424
INFO:root:current mean train loss 1729.799063306336
INFO:root:current train perplexity3.90310001373291
INFO:root:current mean train loss 1730.1357714674011
INFO:root:current train perplexity3.907945156097412
INFO:root:current mean train loss 1730.4445833738966
INFO:root:current train perplexity3.909200429916382
INFO:root:current mean train loss 1730.7816185076508
INFO:root:current train perplexity3.9106006622314453
INFO:root:current mean train loss 1728.9188957706363
INFO:root:current train perplexity3.90647292137146
INFO:root:current mean train loss 1727.7377944185162
INFO:root:current train perplexity3.903141975402832
INFO:root:current mean train loss 1727.2698490089647
INFO:root:current train perplexity3.9004595279693604
INFO:root:current mean train loss 1726.424282530278
INFO:root:current train perplexity3.9009299278259277
INFO:root:current mean train loss 1726.6337357982945
INFO:root:current train perplexity3.9017927646636963
INFO:root:current mean train loss 1726.28052866208
INFO:root:current train perplexity3.900223731994629
INFO:root:current mean train loss 1725.9223947854996
INFO:root:current train perplexity3.8996071815490723
INFO:root:current mean train loss 1725.5643029450987
INFO:root:current train perplexity3.898134469985962
INFO:root:current mean train loss 1726.6462895475477
INFO:root:current train perplexity3.9009835720062256

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.12s/it]
INFO:root:final mean train loss: 1726.0896550427167
INFO:root:final train perplexity: 3.901254653930664
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.71s/it]
INFO:root:eval mean loss: 2906.1817000105575
INFO:root:eval perplexity: 10.856179237365723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/93
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [8:18:28<37:06, 318.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1714.6747650146485
INFO:root:current train perplexity3.892636775970459
INFO:root:current mean train loss 1722.324978298611
INFO:root:current train perplexity3.8828327655792236
INFO:root:current mean train loss 1727.3855477469308
INFO:root:current train perplexity3.889179229736328
INFO:root:current mean train loss 1726.119168251439
INFO:root:current train perplexity3.9009792804718018
INFO:root:current mean train loss 1725.6108764648438
INFO:root:current train perplexity3.900149345397949
INFO:root:current mean train loss 1725.6629186169855
INFO:root:current train perplexity3.9013607501983643
INFO:root:current mean train loss 1725.903381168141
INFO:root:current train perplexity3.901918411254883
INFO:root:current mean train loss 1725.6281260955027
INFO:root:current train perplexity3.9033544063568115
INFO:root:current mean train loss 1724.9922346635299
INFO:root:current train perplexity3.9004738330841064
INFO:root:current mean train loss 1725.0427602339764
INFO:root:current train perplexity3.9012420177459717
INFO:root:current mean train loss 1725.045122160735
INFO:root:current train perplexity3.9010701179504395
INFO:root:current mean train loss 1724.5292087360965
INFO:root:current train perplexity3.9013853073120117
INFO:root:current mean train loss 1725.3984606742858
INFO:root:current train perplexity3.9029407501220703
INFO:root:current mean train loss 1725.8166080198425
INFO:root:current train perplexity3.901322603225708
INFO:root:current mean train loss 1727.4430774585621
INFO:root:current train perplexity3.9029664993286133
INFO:root:current mean train loss 1727.4818830659117
INFO:root:current train perplexity3.902250051498413
INFO:root:current mean train loss 1726.841957237607
INFO:root:current train perplexity3.9021482467651367
INFO:root:current mean train loss 1727.3241487310174
INFO:root:current train perplexity3.9024980068206787
INFO:root:current mean train loss 1726.735216505984
INFO:root:current train perplexity3.9017601013183594
INFO:root:current mean train loss 1726.8652828948666
INFO:root:current train perplexity3.9023146629333496

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.01s/it]
INFO:root:final mean train loss: 1726.4190335872495
INFO:root:final train perplexity: 3.902268648147583
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.64s/it]
INFO:root:eval mean loss: 2907.57360363293
INFO:root:eval perplexity: 10.868583679199219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/94
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [8:23:45<31:46, 317.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1729.248668552674
INFO:root:current train perplexity3.9244604110717773
INFO:root:current mean train loss 1729.039905838555
INFO:root:current train perplexity3.916989803314209
INFO:root:current mean train loss 1728.5142493456704
INFO:root:current train perplexity3.9010579586029053
INFO:root:current mean train loss 1728.262068356915
INFO:root:current train perplexity3.907662868499756
INFO:root:current mean train loss 1727.7427457813285
INFO:root:current train perplexity3.9040205478668213
INFO:root:current mean train loss 1728.779605220111
INFO:root:current train perplexity3.8972506523132324
INFO:root:current mean train loss 1727.6106901018316
INFO:root:current train perplexity3.8935835361480713
INFO:root:current mean train loss 1725.6449772584692
INFO:root:current train perplexity3.8938405513763428
INFO:root:current mean train loss 1725.9526613505523
INFO:root:current train perplexity3.893195390701294
INFO:root:current mean train loss 1726.556949780004
INFO:root:current train perplexity3.896489143371582
INFO:root:current mean train loss 1727.1504458181403
INFO:root:current train perplexity3.8999977111816406
INFO:root:current mean train loss 1726.6750120132688
INFO:root:current train perplexity3.8997397422790527
INFO:root:current mean train loss 1726.9299427464823
INFO:root:current train perplexity3.9015448093414307
INFO:root:current mean train loss 1726.613683461631
INFO:root:current train perplexity3.8990871906280518
INFO:root:current mean train loss 1726.482487354266
INFO:root:current train perplexity3.8996050357818604
INFO:root:current mean train loss 1726.6023984179321
INFO:root:current train perplexity3.8997862339019775
INFO:root:current mean train loss 1726.0485117636363
INFO:root:current train perplexity3.899343252182007
INFO:root:current mean train loss 1725.9221494374303
INFO:root:current train perplexity3.899976968765259
INFO:root:current mean train loss 1726.2836073662772
INFO:root:current train perplexity3.901487112045288

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.28s/it]
INFO:root:final mean train loss: 1725.2333670427147
INFO:root:final train perplexity: 3.898620367050171
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.89s/it]
INFO:root:eval mean loss: 2907.0305241765204
INFO:root:eval perplexity: 10.863739013671875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/95
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [8:29:03<26:28, 317.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1705.3227800641741
INFO:root:current train perplexity3.8617990016937256
INFO:root:current mean train loss 1716.8416619551808
INFO:root:current train perplexity3.869133472442627
INFO:root:current mean train loss 1720.3581651348934
INFO:root:current train perplexity3.8655171394348145
INFO:root:current mean train loss 1719.6555964961933
INFO:root:current train perplexity3.869990110397339
INFO:root:current mean train loss 1718.7113992442255
INFO:root:current train perplexity3.8700690269470215
INFO:root:current mean train loss 1720.0089056705222
INFO:root:current train perplexity3.875166893005371
INFO:root:current mean train loss 1721.5648219204882
INFO:root:current train perplexity3.885322093963623
INFO:root:current mean train loss 1723.3668069278492
INFO:root:current train perplexity3.884538412094116
INFO:root:current mean train loss 1722.3627769226523
INFO:root:current train perplexity3.883955478668213
INFO:root:current mean train loss 1723.018325772275
INFO:root:current train perplexity3.8849658966064453
INFO:root:current mean train loss 1723.1206441123104
INFO:root:current train perplexity3.883314371109009
INFO:root:current mean train loss 1724.2885487965664
INFO:root:current train perplexity3.886033535003662
INFO:root:current mean train loss 1724.244596427905
INFO:root:current train perplexity3.8874382972717285
INFO:root:current mean train loss 1723.5865073472578
INFO:root:current train perplexity3.8876523971557617
INFO:root:current mean train loss 1723.628172619508
INFO:root:current train perplexity3.8900797367095947
INFO:root:current mean train loss 1724.7639278678944
INFO:root:current train perplexity3.8908028602600098
INFO:root:current mean train loss 1724.7418900386995
INFO:root:current train perplexity3.892781972885132
INFO:root:current mean train loss 1725.4733264259864
INFO:root:current train perplexity3.8940556049346924
INFO:root:current mean train loss 1725.5981659978595
INFO:root:current train perplexity3.893606662750244
INFO:root:current mean train loss 1725.5496259826853
INFO:root:current train perplexity3.8945236206054688

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.97s/it]
INFO:root:final mean train loss: 1723.871308096358
INFO:root:final train perplexity: 3.8944344520568848
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.20s/it]
INFO:root:eval mean loss: 2907.118016698339
INFO:root:eval perplexity: 10.864519119262695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/96
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [8:34:22<21:12, 318.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1748.4236312373991
INFO:root:current train perplexity3.9671244621276855
INFO:root:current mean train loss 1732.2532250790196
INFO:root:current train perplexity3.9411816596984863
INFO:root:current mean train loss 1728.8442409234647
INFO:root:current train perplexity3.9205100536346436
INFO:root:current mean train loss 1728.8225038649452
INFO:root:current train perplexity3.910588502883911
INFO:root:current mean train loss 1731.1024354018634
INFO:root:current train perplexity3.9095869064331055
INFO:root:current mean train loss 1729.9682971214395
INFO:root:current train perplexity3.9061553478240967
INFO:root:current mean train loss 1728.8129693226279
INFO:root:current train perplexity3.901350498199463
INFO:root:current mean train loss 1728.2540899399366
INFO:root:current train perplexity3.8993771076202393
INFO:root:current mean train loss 1727.7929245343994
INFO:root:current train perplexity3.8999485969543457
INFO:root:current mean train loss 1726.0944502981085
INFO:root:current train perplexity3.897059679031372
INFO:root:current mean train loss 1725.1066188867755
INFO:root:current train perplexity3.8963518142700195
INFO:root:current mean train loss 1724.751506505236
INFO:root:current train perplexity3.8951809406280518
INFO:root:current mean train loss 1725.3198441506206
INFO:root:current train perplexity3.895901679992676
INFO:root:current mean train loss 1725.1655756766236
INFO:root:current train perplexity3.8948192596435547
INFO:root:current mean train loss 1723.8204438684704
INFO:root:current train perplexity3.895019292831421
INFO:root:current mean train loss 1723.582723327278
INFO:root:current train perplexity3.8959248065948486
INFO:root:current mean train loss 1725.117494733987
INFO:root:current train perplexity3.8985557556152344
INFO:root:current mean train loss 1725.1301844975358
INFO:root:current train perplexity3.8969454765319824
INFO:root:current mean train loss 1724.6176259797626
INFO:root:current train perplexity3.8966736793518066
INFO:root:current mean train loss 1724.5774130601453
INFO:root:current train perplexity3.8957998752593994

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.13s/it]
INFO:root:final mean train loss: 1724.0667438362802
INFO:root:final train perplexity: 3.895035743713379
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.88s/it]
INFO:root:eval mean loss: 2907.0661973008164
INFO:root:eval perplexity: 10.864057540893555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/97
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [8:39:39<15:53, 317.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1721.550028483073
INFO:root:current train perplexity3.896419048309326
INFO:root:current mean train loss 1719.159734777502
INFO:root:current train perplexity3.9068222045898438
INFO:root:current mean train loss 1724.3274398311491
INFO:root:current train perplexity3.9147584438323975
INFO:root:current mean train loss 1723.0420770754758
INFO:root:current train perplexity3.9012982845306396
INFO:root:current mean train loss 1726.0447278703962
INFO:root:current train perplexity3.9014439582824707
INFO:root:current mean train loss 1727.3800002049356
INFO:root:current train perplexity3.8944547176361084
INFO:root:current mean train loss 1728.4957987467449
INFO:root:current train perplexity3.8947932720184326
INFO:root:current mean train loss 1727.8294038007605
INFO:root:current train perplexity3.891767740249634
INFO:root:current mean train loss 1725.4071946054135
INFO:root:current train perplexity3.8918168544769287
INFO:root:current mean train loss 1725.218300477362
INFO:root:current train perplexity3.891558885574341
INFO:root:current mean train loss 1725.0967526035454
INFO:root:current train perplexity3.892869234085083
INFO:root:current mean train loss 1723.1016112005254
INFO:root:current train perplexity3.8924832344055176
INFO:root:current mean train loss 1723.8000299502642
INFO:root:current train perplexity3.8918216228485107
INFO:root:current mean train loss 1724.8821258997705
INFO:root:current train perplexity3.8929378986358643
INFO:root:current mean train loss 1724.5653830681058
INFO:root:current train perplexity3.8929443359375
INFO:root:current mean train loss 1723.7958327497931
INFO:root:current train perplexity3.8912596702575684
INFO:root:current mean train loss 1724.050148973187
INFO:root:current train perplexity3.8910000324249268
INFO:root:current mean train loss 1723.7698345402557
INFO:root:current train perplexity3.89054274559021
INFO:root:current mean train loss 1723.063622676965
INFO:root:current train perplexity3.8910717964172363
INFO:root:current mean train loss 1722.7753917529599
INFO:root:current train perplexity3.8910231590270996

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.43s/it]
INFO:root:final mean train loss: 1722.6343587239583
INFO:root:final train perplexity: 3.8906376361846924
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.49s/it]
INFO:root:eval mean loss: 2907.104183529232
INFO:root:eval perplexity: 10.864399909973145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/98
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [8:44:58<10:36, 318.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1727.2822979266828
INFO:root:current train perplexity3.87198543548584
INFO:root:current mean train loss 1720.5891157670455
INFO:root:current train perplexity3.888291597366333
INFO:root:current mean train loss 1720.0228907171286
INFO:root:current train perplexity3.891843795776367
INFO:root:current mean train loss 1719.7643788794949
INFO:root:current train perplexity3.893479585647583
INFO:root:current mean train loss 1722.8388640372984
INFO:root:current train perplexity3.8941688537597656
INFO:root:current mean train loss 1726.495402162265
INFO:root:current train perplexity3.8936192989349365
INFO:root:current mean train loss 1725.914477355498
INFO:root:current train perplexity3.889798402786255
INFO:root:current mean train loss 1726.359184315002
INFO:root:current train perplexity3.889702320098877
INFO:root:current mean train loss 1726.1663482489614
INFO:root:current train perplexity3.89068865776062
INFO:root:current mean train loss 1726.210367627712
INFO:root:current train perplexity3.891782522201538
INFO:root:current mean train loss 1725.4159933887177
INFO:root:current train perplexity3.8885719776153564
INFO:root:current mean train loss 1725.2252266421337
INFO:root:current train perplexity3.8918874263763428
INFO:root:current mean train loss 1725.2293795740181
INFO:root:current train perplexity3.8924636840820312
INFO:root:current mean train loss 1725.3763863252632
INFO:root:current train perplexity3.893537998199463
INFO:root:current mean train loss 1724.0605836210805
INFO:root:current train perplexity3.891467571258545
INFO:root:current mean train loss 1723.5060666995307
INFO:root:current train perplexity3.8906757831573486
INFO:root:current mean train loss 1723.249781226539
INFO:root:current train perplexity3.8896889686584473
INFO:root:current mean train loss 1723.5334114398902
INFO:root:current train perplexity3.8898539543151855
INFO:root:current mean train loss 1722.980738221033
INFO:root:current train perplexity3.8889822959899902
INFO:root:current mean train loss 1723.2878434120546
INFO:root:current train perplexity3.8906261920928955

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.54s/it]
INFO:root:final mean train loss: 1722.7616427253727
INFO:root:final train perplexity: 3.891028642654419
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.95s/it]
INFO:root:eval mean loss: 2907.5152664871903
INFO:root:eval perplexity: 10.868062973022461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/99
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [8:50:16<05:18, 318.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1714.5581129120617
INFO:root:current train perplexity3.837578058242798
INFO:root:current mean train loss 1711.3795514787946
INFO:root:current train perplexity3.856710195541382
INFO:root:current mean train loss 1716.6395419506316
INFO:root:current train perplexity3.8682668209075928
INFO:root:current mean train loss 1718.6225515635226
INFO:root:current train perplexity3.867971658706665
INFO:root:current mean train loss 1719.1824892922555
INFO:root:current train perplexity3.868706464767456
INFO:root:current mean train loss 1719.8941348360986
INFO:root:current train perplexity3.877318859100342
INFO:root:current mean train loss 1721.3581619933902
INFO:root:current train perplexity3.8814473152160645
INFO:root:current mean train loss 1722.2904335275634
INFO:root:current train perplexity3.8842740058898926
INFO:root:current mean train loss 1721.358473589631
INFO:root:current train perplexity3.8827924728393555
INFO:root:current mean train loss 1721.6905661775236
INFO:root:current train perplexity3.8834192752838135
INFO:root:current mean train loss 1721.655467824883
INFO:root:current train perplexity3.8834166526794434
INFO:root:current mean train loss 1721.7229642141895
INFO:root:current train perplexity3.882852792739868
INFO:root:current mean train loss 1721.66365477373
INFO:root:current train perplexity3.882805585861206
INFO:root:current mean train loss 1721.9289140935916
INFO:root:current train perplexity3.883852243423462
INFO:root:current mean train loss 1723.9601153786848
INFO:root:current train perplexity3.887850284576416
INFO:root:current mean train loss 1722.2343264650906
INFO:root:current train perplexity3.8857948780059814
INFO:root:current mean train loss 1721.0980772546866
INFO:root:current train perplexity3.8851826190948486
INFO:root:current mean train loss 1720.853249152769
INFO:root:current train perplexity3.8848273754119873
INFO:root:current mean train loss 1721.5761778423055
INFO:root:current train perplexity3.8867015838623047
INFO:root:current mean train loss 1722.2004151252877
INFO:root:current train perplexity3.8878633975982666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.20s/it]
INFO:root:final mean train loss: 1721.6868680722173
INFO:root:final train perplexity: 3.8877313137054443
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.82s/it]
INFO:root:eval mean loss: 2907.5370983776747
INFO:root:eval perplexity: 10.868254661560059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_23/100
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [8:55:35<00:00, 318.23s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [8:55:35<00:00, 321.35s/it]
INFO:root:evaluating final model
INFO:root:start evaluating
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.20s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.20s/it]
INFO:root:eval mean loss: 2907.5370983776747
INFO:root:eval perplexity: 10.868254661560059
INFO:root:evalaution complete
INFO:root:save model final: std_23/final
