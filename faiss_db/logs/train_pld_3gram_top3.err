INFO:root:Output: pld_33
INFO:root:Steps per epochs:1983
INFO:root:Total steps:198300
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.value.weight', 'cls.predictions.decoder.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.query.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.key.weight', 'cls.predictions.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.query.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
INFO:root:current mean train loss 12223.9020083649
INFO:root:current train perplexity16512.375
INFO:root:current mean train loss 10533.464024222676
INFO:root:current train perplexity4077.650634765625
INFO:root:current mean train loss 9164.01141173704
INFO:root:current train perplexity1373.6580810546875
INFO:root:current mean train loss 8217.23278900376
INFO:root:current train perplexity650.3746337890625
INFO:root:current mean train loss 7526.407448686436
INFO:root:current train perplexity377.9500427246094
INFO:root:current mean train loss 7002.350201181657
INFO:root:current train perplexity249.9554443359375
INFO:root:current mean train loss 6593.3799215816125
INFO:root:current train perplexity180.47425842285156
INFO:root:current mean train loss 6268.785694642717
INFO:root:current train perplexity139.26419067382812
INFO:root:current mean train loss 5992.480617026731
INFO:root:current train perplexity112.55951690673828
INFO:root:current mean train loss 5768.686284184575
INFO:root:current train perplexity93.85995483398438
INFO:root:current mean train loss 5569.350719892729
INFO:root:current train perplexity80.39380645751953
INFO:root:current mean train loss 5399.880233039252
INFO:root:current train perplexity70.3791275024414
INFO:root:current mean train loss 5253.601545397
INFO:root:current train perplexity62.540191650390625
INFO:root:current mean train loss 5117.978021410382
INFO:root:current train perplexity56.34135437011719
INFO:root:current mean train loss 4999.395368070901
INFO:root:current train perplexity51.38488006591797
INFO:root:current mean train loss 4892.750294220753
INFO:root:current train perplexity47.26644515991211
INFO:root:current mean train loss 4797.28027602404
INFO:root:current train perplexity43.80780792236328
INFO:root:current mean train loss 4708.803180857855
INFO:root:current train perplexity40.90239334106445
INFO:root:current mean train loss 4626.141819862016
INFO:root:current train perplexity38.38032913208008

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:26<00:00, 266.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:26<00:00, 266.38s/it]
INFO:root:final mean train loss: 4561.978182101574
INFO:root:final train perplexity: 36.51963424682617
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.73s/it]
INFO:root:eval mean loss: 3469.188579937359
INFO:root:eval perplexity: 17.231210708618164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/1
  1%|          | 1/100 [04:55<8:07:25, 295.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3080.20703125
INFO:root:current train perplexity11.268625259399414
INFO:root:current mean train loss 3083.0629335600756
INFO:root:current train perplexity11.397640228271484
INFO:root:current mean train loss 3065.412763807509
INFO:root:current train perplexity11.336849212646484
INFO:root:current mean train loss 3063.4086048753957
INFO:root:current train perplexity11.310580253601074
INFO:root:current mean train loss 3055.7156289907603
INFO:root:current train perplexity11.210627555847168
INFO:root:current mean train loss 3045.85082061531
INFO:root:current train perplexity11.074210166931152
INFO:root:current mean train loss 3027.764430454799
INFO:root:current train perplexity10.943777084350586
INFO:root:current mean train loss 3016.824076902933
INFO:root:current train perplexity10.844002723693848
INFO:root:current mean train loss 3007.6895009957107
INFO:root:current train perplexity10.765132904052734
INFO:root:current mean train loss 3001.360433120394
INFO:root:current train perplexity10.68685531616211
INFO:root:current mean train loss 2988.2743294783463
INFO:root:current train perplexity10.596891403198242
INFO:root:current mean train loss 2979.6595224906896
INFO:root:current train perplexity10.504240036010742
INFO:root:current mean train loss 2972.249489432887
INFO:root:current train perplexity10.427772521972656
INFO:root:current mean train loss 2963.0760605646847
INFO:root:current train perplexity10.344980239868164
INFO:root:current mean train loss 2953.9231429450256
INFO:root:current train perplexity10.27305793762207
INFO:root:current mean train loss 2945.686036444591
INFO:root:current train perplexity10.199853897094727
INFO:root:current mean train loss 2936.2636827525525
INFO:root:current train perplexity10.126763343811035
INFO:root:current mean train loss 2928.537830557301
INFO:root:current train perplexity10.06318473815918
INFO:root:current mean train loss 2918.206229995526
INFO:root:current train perplexity9.992304801940918
INFO:root:current mean train loss 2910.022257189661
INFO:root:current train perplexity9.921290397644043

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:26<00:00, 266.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:26<00:00, 266.90s/it]
INFO:root:final mean train loss: 2904.1362654339227
INFO:root:final train perplexity: 9.878658294677734
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it]
INFO:root:eval mean loss: 3222.997453752581
INFO:root:eval perplexity: 14.079288482666016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/2
  2%|â–         | 2/100 [09:52<8:03:42, 296.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2776.0538810961175
INFO:root:current train perplexity8.90534782409668
INFO:root:current mean train loss 2725.6858112077066
INFO:root:current train perplexity8.65326976776123
INFO:root:current mean train loss 2722.924104747854
INFO:root:current train perplexity8.614794731140137
INFO:root:current mean train loss 2709.7540726761918
INFO:root:current train perplexity8.539346694946289
INFO:root:current mean train loss 2712.3218489508154
INFO:root:current train perplexity8.5066556930542
INFO:root:current mean train loss 2707.479905806608
INFO:root:current train perplexity8.459552764892578
INFO:root:current mean train loss 2702.6952199348343
INFO:root:current train perplexity8.418132781982422
INFO:root:current mean train loss 2696.4917415186947
INFO:root:current train perplexity8.380882263183594
INFO:root:current mean train loss 2691.5912786989797
INFO:root:current train perplexity8.347923278808594
INFO:root:current mean train loss 2685.048188596932
INFO:root:current train perplexity8.313931465148926
INFO:root:current mean train loss 2679.9578315018452
INFO:root:current train perplexity8.281362533569336
INFO:root:current mean train loss 2674.67741567775
INFO:root:current train perplexity8.255943298339844
INFO:root:current mean train loss 2669.048470527296
INFO:root:current train perplexity8.223348617553711
INFO:root:current mean train loss 2662.2314106969125
INFO:root:current train perplexity8.183030128479004
INFO:root:current mean train loss 2660.842427926553
INFO:root:current train perplexity8.163620948791504
INFO:root:current mean train loss 2659.141527030333
INFO:root:current train perplexity8.137550354003906
INFO:root:current mean train loss 2654.5564694425043
INFO:root:current train perplexity8.108244895935059
INFO:root:current mean train loss 2650.6805476977243
INFO:root:current train perplexity8.078320503234863
INFO:root:current mean train loss 2646.212083482508
INFO:root:current train perplexity8.045754432678223
INFO:root:current mean train loss 2641.2681584799775
INFO:root:current train perplexity8.019166946411133

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.77s/it]
INFO:root:final mean train loss: 2637.1153925185363
INFO:root:final train perplexity: 8.002772331237793
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.27s/it]
INFO:root:eval mean loss: 3118.0673050980668
INFO:root:eval perplexity: 12.917743682861328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/3
  3%|â–Ž         | 3/100 [14:49<7:59:44, 296.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2559.1130517578126
INFO:root:current train perplexity7.482341766357422
INFO:root:current mean train loss 2545.2318391927083
INFO:root:current train perplexity7.436691761016846
INFO:root:current mean train loss 2536.076189453125
INFO:root:current train perplexity7.400798320770264
INFO:root:current mean train loss 2529.201746651786
INFO:root:current train perplexity7.349513530731201
INFO:root:current mean train loss 2532.4050065104166
INFO:root:current train perplexity7.337189197540283
INFO:root:current mean train loss 2524.5739537464488
INFO:root:current train perplexity7.299971580505371
INFO:root:current mean train loss 2520.9484318659856
INFO:root:current train perplexity7.28548526763916
INFO:root:current mean train loss 2517.466359700521
INFO:root:current train perplexity7.268364906311035
INFO:root:current mean train loss 2514.711971507353
INFO:root:current train perplexity7.261549949645996
INFO:root:current mean train loss 2511.1812600226153
INFO:root:current train perplexity7.239206790924072
INFO:root:current mean train loss 2506.9788406808034
INFO:root:current train perplexity7.2167487144470215
INFO:root:current mean train loss 2505.9742705502717
INFO:root:current train perplexity7.20697021484375
INFO:root:current mean train loss 2502.2608076171873
INFO:root:current train perplexity7.190420150756836
INFO:root:current mean train loss 2499.5545616319446
INFO:root:current train perplexity7.17392635345459
INFO:root:current mean train loss 2498.518659247037
INFO:root:current train perplexity7.166218280792236
INFO:root:current mean train loss 2495.1528600680444
INFO:root:current train perplexity7.149988651275635
INFO:root:current mean train loss 2493.192268436316
INFO:root:current train perplexity7.137002944946289
INFO:root:current mean train loss 2489.9756083984375
INFO:root:current train perplexity7.118113994598389
INFO:root:current mean train loss 2488.1427667071366
INFO:root:current train perplexity7.107756614685059
INFO:root:current mean train loss 2485.53178898738
INFO:root:current train perplexity7.095612049102783

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.46s/it]
INFO:root:final mean train loss: 2483.7799367745956
INFO:root:final train perplexity: 7.091224193572998
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.51s/it]
INFO:root:eval mean loss: 3072.5685851867493
INFO:root:eval perplexity: 12.444353103637695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/4
  4%|â–         | 4/100 [19:46<7:55:13, 297.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2451.7972976912315
INFO:root:current train perplexity6.776183128356934
INFO:root:current mean train loss 2416.2231255262914
INFO:root:current train perplexity6.693636894226074
INFO:root:current mean train loss 2413.116394271565
INFO:root:current train perplexity6.697128772735596
INFO:root:current mean train loss 2412.2489622360354
INFO:root:current train perplexity6.699333667755127
INFO:root:current mean train loss 2412.84293863758
INFO:root:current train perplexity6.707458019256592
INFO:root:current mean train loss 2407.233655495618
INFO:root:current train perplexity6.6724324226379395
INFO:root:current mean train loss 2407.494824548175
INFO:root:current train perplexity6.666778087615967
INFO:root:current mean train loss 2404.077145095288
INFO:root:current train perplexity6.650847434997559
INFO:root:current mean train loss 2403.9862313980047
INFO:root:current train perplexity6.639156818389893
INFO:root:current mean train loss 2399.9494033071837
INFO:root:current train perplexity6.621779918670654
INFO:root:current mean train loss 2398.6285049166763
INFO:root:current train perplexity6.6134819984436035
INFO:root:current mean train loss 2397.629047671647
INFO:root:current train perplexity6.604822158813477
INFO:root:current mean train loss 2394.210048805002
INFO:root:current train perplexity6.591812610626221
INFO:root:current mean train loss 2393.070832214132
INFO:root:current train perplexity6.583540916442871
INFO:root:current mean train loss 2390.018571662513
INFO:root:current train perplexity6.575894832611084
INFO:root:current mean train loss 2387.2659634004067
INFO:root:current train perplexity6.568578243255615
INFO:root:current mean train loss 2383.432219415492
INFO:root:current train perplexity6.55225944519043
INFO:root:current mean train loss 2381.6149837405383
INFO:root:current train perplexity6.539509296417236
INFO:root:current mean train loss 2379.2634158346445
INFO:root:current train perplexity6.5280890464782715
INFO:root:current mean train loss 2376.9430012938087
INFO:root:current train perplexity6.514406204223633

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.50s/it]
INFO:root:final mean train loss: 2375.928263346354
INFO:root:final train perplexity: 6.512999057769775
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.44s/it]
INFO:root:eval mean loss: 3056.93628149634
INFO:root:eval perplexity: 12.285740852355957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/5
  5%|â–Œ         | 5/100 [24:45<7:51:01, 297.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2323.499241420201
INFO:root:current train perplexity6.195566654205322
INFO:root:current mean train loss 2321.634910915209
INFO:root:current train perplexity6.224867343902588
INFO:root:current mean train loss 2318.595223870076
INFO:root:current train perplexity6.239780426025391
INFO:root:current mean train loss 2319.7102588017783
INFO:root:current train perplexity6.242215633392334
INFO:root:current mean train loss 2324.698560226062
INFO:root:current train perplexity6.250041484832764
INFO:root:current mean train loss 2318.6520088927386
INFO:root:current train perplexity6.220785617828369
INFO:root:current mean train loss 2316.401851185581
INFO:root:current train perplexity6.2000932693481445
INFO:root:current mean train loss 2316.169894627162
INFO:root:current train perplexity6.204595565795898
INFO:root:current mean train loss 2313.6744035401493
INFO:root:current train perplexity6.1895904541015625
INFO:root:current mean train loss 2309.2959259777535
INFO:root:current train perplexity6.17188024520874
INFO:root:current mean train loss 2308.1745785646335
INFO:root:current train perplexity6.169310092926025
INFO:root:current mean train loss 2306.0942749848236
INFO:root:current train perplexity6.160225868225098
INFO:root:current mean train loss 2304.264272529388
INFO:root:current train perplexity6.152139186859131
INFO:root:current mean train loss 2303.978646162617
INFO:root:current train perplexity6.147923946380615
INFO:root:current mean train loss 2303.98415422054
INFO:root:current train perplexity6.147916316986084
INFO:root:current mean train loss 2302.7830426765213
INFO:root:current train perplexity6.138306140899658
INFO:root:current mean train loss 2301.7227986895273
INFO:root:current train perplexity6.132015228271484
INFO:root:current mean train loss 2298.3909542614033
INFO:root:current train perplexity6.124495029449463
INFO:root:current mean train loss 2297.5911999356217
INFO:root:current train perplexity6.117429256439209

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.28s/it]
INFO:root:final mean train loss: 2294.672635554065
INFO:root:final train perplexity: 6.108717918395996
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.70s/it]
INFO:root:eval mean loss: 3062.5010902015297
INFO:root:eval perplexity: 12.341968536376953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/6
  6%|â–Œ         | 6/100 [29:43<7:46:34, 297.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2392.834716796875
INFO:root:current train perplexity5.779272079467773
INFO:root:current mean train loss 2229.6801854501855
INFO:root:current train perplexity5.819340705871582
INFO:root:current mean train loss 2241.9510637729322
INFO:root:current train perplexity5.874588966369629
INFO:root:current mean train loss 2250.933386514353
INFO:root:current train perplexity5.888059139251709
INFO:root:current mean train loss 2247.857023091685
INFO:root:current train perplexity5.8838887214660645
INFO:root:current mean train loss 2245.5630128902353
INFO:root:current train perplexity5.88587760925293
INFO:root:current mean train loss 2242.2313327884517
INFO:root:current train perplexity5.874202251434326
INFO:root:current mean train loss 2243.763999775711
INFO:root:current train perplexity5.874128818511963
INFO:root:current mean train loss 2243.7883978949653
INFO:root:current train perplexity5.8723931312561035
INFO:root:current mean train loss 2242.62808698343
INFO:root:current train perplexity5.864328384399414
INFO:root:current mean train loss 2239.537791554149
INFO:root:current train perplexity5.853863716125488
INFO:root:current mean train loss 2238.243204198243
INFO:root:current train perplexity5.845498561859131
INFO:root:current mean train loss 2237.5252554430554
INFO:root:current train perplexity5.840938568115234
INFO:root:current mean train loss 2236.9286509813664
INFO:root:current train perplexity5.839219570159912
INFO:root:current mean train loss 2236.4874723272437
INFO:root:current train perplexity5.837797164916992
INFO:root:current mean train loss 2236.7462313535766
INFO:root:current train perplexity5.83391809463501
INFO:root:current mean train loss 2235.151204401668
INFO:root:current train perplexity5.826695919036865
INFO:root:current mean train loss 2234.6402989050557
INFO:root:current train perplexity5.825128555297852
INFO:root:current mean train loss 2234.1390538107084
INFO:root:current train perplexity5.820132255554199
INFO:root:current mean train loss 2233.57739232127
INFO:root:current train perplexity5.817412853240967

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.63s/it]
INFO:root:final mean train loss: 2232.1425715998093
INFO:root:final train perplexity: 5.8147735595703125
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.49s/it]
INFO:root:eval mean loss: 3062.2832434485267
INFO:root:eval perplexity: 12.339764595031738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/7
  7%|â–‹         | 7/100 [34:42<7:42:00, 298.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2181.7784762912324
INFO:root:current train perplexity5.573851108551025
INFO:root:current mean train loss 2176.485953638109
INFO:root:current train perplexity5.627864837646484
INFO:root:current mean train loss 2192.288349116614
INFO:root:current train perplexity5.668127059936523
INFO:root:current mean train loss 2195.9408584690696
INFO:root:current train perplexity5.669214248657227
INFO:root:current mean train loss 2194.3393026105523
INFO:root:current train perplexity5.643950462341309
INFO:root:current mean train loss 2194.409535529531
INFO:root:current train perplexity5.641552448272705
INFO:root:current mean train loss 2193.8055289555523
INFO:root:current train perplexity5.634176254272461
INFO:root:current mean train loss 2194.755422608102
INFO:root:current train perplexity5.637184143066406
INFO:root:current mean train loss 2193.252614811755
INFO:root:current train perplexity5.626585006713867
INFO:root:current mean train loss 2191.691513161254
INFO:root:current train perplexity5.6227593421936035
INFO:root:current mean train loss 2189.1372274162727
INFO:root:current train perplexity5.615348815917969
INFO:root:current mean train loss 2189.2004405449884
INFO:root:current train perplexity5.609531879425049
INFO:root:current mean train loss 2188.515867436852
INFO:root:current train perplexity5.604123115539551
INFO:root:current mean train loss 2189.004962926931
INFO:root:current train perplexity5.609447002410889
INFO:root:current mean train loss 2189.021656547514
INFO:root:current train perplexity5.6066155433654785
INFO:root:current mean train loss 2188.779266960536
INFO:root:current train perplexity5.60196590423584
INFO:root:current mean train loss 2186.9635764217496
INFO:root:current train perplexity5.5966572761535645
INFO:root:current mean train loss 2184.8864903833037
INFO:root:current train perplexity5.589295387268066
INFO:root:current mean train loss 2183.8320224539543
INFO:root:current train perplexity5.588412284851074
INFO:root:current mean train loss 2181.3280641557776
INFO:root:current train perplexity5.583625793457031

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:28<00:00, 268.09s/it]
INFO:root:final mean train loss: 2180.6419920890066
INFO:root:final train perplexity: 5.583331108093262
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.31s/it]
INFO:root:eval mean loss: 3054.276080523883
INFO:root:eval perplexity: 12.258951187133789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/8
  8%|â–Š         | 8/100 [39:40<7:36:55, 298.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2142.4425083705355
INFO:root:current train perplexity5.392404556274414
INFO:root:current mean train loss 2151.3673213252314
INFO:root:current train perplexity5.414730548858643
INFO:root:current mean train loss 2142.6902961893284
INFO:root:current train perplexity5.413740158081055
INFO:root:current mean train loss 2145.462110832556
INFO:root:current train perplexity5.430312633514404
INFO:root:current mean train loss 2142.987439385776
INFO:root:current train perplexity5.43507719039917
INFO:root:current mean train loss 2141.2880341431805
INFO:root:current train perplexity5.421486854553223
INFO:root:current mean train loss 2144.3343071404406
INFO:root:current train perplexity5.420156002044678
INFO:root:current mean train loss 2146.2716296968006
INFO:root:current train perplexity5.422482013702393
INFO:root:current mean train loss 2146.4603224702937
INFO:root:current train perplexity5.42502498626709
INFO:root:current mean train loss 2148.281077534885
INFO:root:current train perplexity5.428336143493652
INFO:root:current mean train loss 2146.2662479713917
INFO:root:current train perplexity5.424246311187744
INFO:root:current mean train loss 2143.251884077299
INFO:root:current train perplexity5.416345119476318
INFO:root:current mean train loss 2141.0979392356717
INFO:root:current train perplexity5.411576747894287
INFO:root:current mean train loss 2141.764443615403
INFO:root:current train perplexity5.412982940673828
INFO:root:current mean train loss 2140.8758989819253
INFO:root:current train perplexity5.409570693969727
INFO:root:current mean train loss 2141.159056424318
INFO:root:current train perplexity5.40674352645874
INFO:root:current mean train loss 2140.3385578680477
INFO:root:current train perplexity5.40566873550415
INFO:root:current mean train loss 2138.826474412374
INFO:root:current train perplexity5.400269985198975
INFO:root:current mean train loss 2137.2128469191716
INFO:root:current train perplexity5.394435405731201
INFO:root:current mean train loss 2137.251297225755
INFO:root:current train perplexity5.394206523895264

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.61s/it]
INFO:root:final mean train loss: 2137.5481352236197
INFO:root:final train perplexity: 5.396761894226074
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.45s/it]
INFO:root:eval mean loss: 3055.702755489865
INFO:root:eval perplexity: 12.273309707641602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/9
  9%|â–‰         | 9/100 [44:39<7:32:40, 298.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2089.0223224346455
INFO:root:current train perplexity5.228855609893799
INFO:root:current mean train loss 2096.7395902934827
INFO:root:current train perplexity5.194787502288818
INFO:root:current mean train loss 2106.582676478795
INFO:root:current train perplexity5.240018844604492
INFO:root:current mean train loss 2102.0008492903276
INFO:root:current train perplexity5.245336055755615
INFO:root:current mean train loss 2108.773378355313
INFO:root:current train perplexity5.2626447677612305
INFO:root:current mean train loss 2110.836193361144
INFO:root:current train perplexity5.269301414489746
INFO:root:current mean train loss 2113.565742539482
INFO:root:current train perplexity5.276233673095703
INFO:root:current mean train loss 2109.8748584503824
INFO:root:current train perplexity5.266562461853027
INFO:root:current mean train loss 2109.2413655312407
INFO:root:current train perplexity5.267563343048096
INFO:root:current mean train loss 2106.085238929556
INFO:root:current train perplexity5.260952949523926
INFO:root:current mean train loss 2107.1181135866577
INFO:root:current train perplexity5.2637104988098145
INFO:root:current mean train loss 2106.346663898892
INFO:root:current train perplexity5.256600379943848
INFO:root:current mean train loss 2105.8588244160906
INFO:root:current train perplexity5.25584602355957
INFO:root:current mean train loss 2106.433352950057
INFO:root:current train perplexity5.261021137237549
INFO:root:current mean train loss 2104.7439432275523
INFO:root:current train perplexity5.255335330963135
INFO:root:current mean train loss 2101.9181898451343
INFO:root:current train perplexity5.247040271759033
INFO:root:current mean train loss 2101.6973375962375
INFO:root:current train perplexity5.243404865264893
INFO:root:current mean train loss 2103.049130513788
INFO:root:current train perplexity5.246323108673096
INFO:root:current mean train loss 2101.206685340173
INFO:root:current train perplexity5.241378307342529
INFO:root:current mean train loss 2101.233516192827
INFO:root:current train perplexity5.241211891174316

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.14s/it]
INFO:root:final mean train loss: 2100.3424123974683
INFO:root:final train perplexity: 5.240707874298096
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.92s/it]
INFO:root:eval mean loss: 3059.9761827256943
INFO:root:eval perplexity: 12.316423416137695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/10
 10%|â–ˆ         | 10/100 [49:39<7:28:10, 298.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2086.6028185858245
INFO:root:current train perplexity5.136369705200195
INFO:root:current mean train loss 2089.2851822531434
INFO:root:current train perplexity5.128786087036133
INFO:root:current mean train loss 2072.3331838841773
INFO:root:current train perplexity5.0974507331848145
INFO:root:current mean train loss 2071.404349143589
INFO:root:current train perplexity5.10176944732666
INFO:root:current mean train loss 2073.0211327396223
INFO:root:current train perplexity5.105583667755127
INFO:root:current mean train loss 2076.8912902724765
INFO:root:current train perplexity5.117751598358154
INFO:root:current mean train loss 2072.659674720023
INFO:root:current train perplexity5.109706878662109
INFO:root:current mean train loss 2074.048436992035
INFO:root:current train perplexity5.119638442993164
INFO:root:current mean train loss 2075.0619612892424
INFO:root:current train perplexity5.115163326263428
INFO:root:current mean train loss 2074.131759722289
INFO:root:current train perplexity5.115989685058594
INFO:root:current mean train loss 2072.5314215150697
INFO:root:current train perplexity5.116576671600342
INFO:root:current mean train loss 2072.240843786757
INFO:root:current train perplexity5.115837574005127
INFO:root:current mean train loss 2071.357522494028
INFO:root:current train perplexity5.1119465827941895
INFO:root:current mean train loss 2071.6331198603852
INFO:root:current train perplexity5.113047122955322
INFO:root:current mean train loss 2072.041521190542
INFO:root:current train perplexity5.11298942565918
INFO:root:current mean train loss 2070.1496729853807
INFO:root:current train perplexity5.109550952911377
INFO:root:current mean train loss 2069.130476853889
INFO:root:current train perplexity5.107825756072998
INFO:root:current mean train loss 2067.9007924426537
INFO:root:current train perplexity5.1060709953308105
INFO:root:current mean train loss 2066.9255910580523
INFO:root:current train perplexity5.104732036590576
INFO:root:current mean train loss 2068.0998525856835
INFO:root:current train perplexity5.107306957244873

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.39s/it]
INFO:root:final mean train loss: 2067.706407355589
INFO:root:final train perplexity: 5.10753870010376
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it]
INFO:root:eval mean loss: 3067.7045553854637
INFO:root:eval perplexity: 12.394782066345215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/11
 11%|â–ˆ         | 11/100 [54:38<7:23:23, 298.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2072.4774127339206
INFO:root:current train perplexity5.0586323738098145
INFO:root:current mean train loss 2039.4100899645077
INFO:root:current train perplexity4.992642402648926
INFO:root:current mean train loss 2039.3093846461156
INFO:root:current train perplexity4.987222194671631
INFO:root:current mean train loss 2048.831254237674
INFO:root:current train perplexity5.015018463134766
INFO:root:current mean train loss 2043.4725226257074
INFO:root:current train perplexity4.99519157409668
INFO:root:current mean train loss 2043.178898417502
INFO:root:current train perplexity4.991525173187256
INFO:root:current mean train loss 2044.260831693866
INFO:root:current train perplexity4.9950456619262695
INFO:root:current mean train loss 2043.9829516228829
INFO:root:current train perplexity5.000454425811768
INFO:root:current mean train loss 2041.6780905282255
INFO:root:current train perplexity4.997169494628906
INFO:root:current mean train loss 2041.4219095411938
INFO:root:current train perplexity4.999034881591797
INFO:root:current mean train loss 2037.8917711795364
INFO:root:current train perplexity4.990200042724609
INFO:root:current mean train loss 2040.844605521448
INFO:root:current train perplexity4.994831562042236
INFO:root:current mean train loss 2039.545149309268
INFO:root:current train perplexity4.992720603942871
INFO:root:current mean train loss 2039.498597248292
INFO:root:current train perplexity4.9932861328125
INFO:root:current mean train loss 2039.1413748370205
INFO:root:current train perplexity4.991940498352051
INFO:root:current mean train loss 2038.8822831951204
INFO:root:current train perplexity4.99009895324707
INFO:root:current mean train loss 2038.9414643890634
INFO:root:current train perplexity4.990156650543213
INFO:root:current mean train loss 2039.0725505696432
INFO:root:current train perplexity4.991471290588379
INFO:root:current mean train loss 2039.077638854657
INFO:root:current train perplexity4.991328239440918

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.16s/it]
INFO:root:final mean train loss: 2038.8329623208404
INFO:root:final train perplexity: 4.992547512054443
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.29s/it]
INFO:root:eval mean loss: 3070.0002829978416
INFO:root:eval perplexity: 12.418149948120117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/12
 12%|â–ˆâ–        | 12/100 [59:37<7:18:24, 298.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1916.5037841796875
INFO:root:current train perplexity4.602911949157715
INFO:root:current mean train loss 2013.3328774461468
INFO:root:current train perplexity4.884432792663574
INFO:root:current mean train loss 2018.2180596713363
INFO:root:current train perplexity4.903926372528076
INFO:root:current mean train loss 2013.0066050916614
INFO:root:current train perplexity4.894534587860107
INFO:root:current mean train loss 2009.168893515916
INFO:root:current train perplexity4.892360210418701
INFO:root:current mean train loss 2012.9497812927125
INFO:root:current train perplexity4.903652191162109
INFO:root:current mean train loss 2010.9963518588697
INFO:root:current train perplexity4.901336193084717
INFO:root:current mean train loss 2009.524712553065
INFO:root:current train perplexity4.897456169128418
INFO:root:current mean train loss 2009.360514677625
INFO:root:current train perplexity4.893418312072754
INFO:root:current mean train loss 2012.781059527054
INFO:root:current train perplexity4.898548603057861
INFO:root:current mean train loss 2012.489814126955
INFO:root:current train perplexity4.896440505981445
INFO:root:current mean train loss 2011.35762429259
INFO:root:current train perplexity4.893326282501221
INFO:root:current mean train loss 2010.1919921469114
INFO:root:current train perplexity4.894423007965088
INFO:root:current mean train loss 2009.0667420136224
INFO:root:current train perplexity4.891390323638916
INFO:root:current mean train loss 2009.112636443809
INFO:root:current train perplexity4.889842510223389
INFO:root:current mean train loss 2009.5874703230259
INFO:root:current train perplexity4.8863091468811035
INFO:root:current mean train loss 2011.4555689192384
INFO:root:current train perplexity4.8874030113220215
INFO:root:current mean train loss 2010.5883180502926
INFO:root:current train perplexity4.886637210845947
INFO:root:current mean train loss 2011.6687681988353
INFO:root:current train perplexity4.889198303222656
INFO:root:current mean train loss 2012.6589842980245
INFO:root:current train perplexity4.891005992889404

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.48s/it]
INFO:root:final mean train loss: 2012.8804087674923
INFO:root:final train perplexity: 4.89139986038208
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it]
INFO:root:eval mean loss: 3063.535442180462
INFO:root:eval perplexity: 12.35245132446289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/13
 13%|â–ˆâ–Ž        | 13/100 [1:04:49<7:19:26, 303.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2057.2991455078127
INFO:root:current train perplexity4.8794732093811035
INFO:root:current mean train loss 1998.2696278889973
INFO:root:current train perplexity4.799592971801758
INFO:root:current mean train loss 2003.0990312056108
INFO:root:current train perplexity4.819485664367676
INFO:root:current mean train loss 1993.4163417816162
INFO:root:current train perplexity4.80216646194458
INFO:root:current mean train loss 1995.4803597586495
INFO:root:current train perplexity4.799503803253174
INFO:root:current mean train loss 1995.6153510460488
INFO:root:current train perplexity4.810169696807861
INFO:root:current mean train loss 1995.5811663227696
INFO:root:current train perplexity4.8097429275512695
INFO:root:current mean train loss 1996.9487479315865
INFO:root:current train perplexity4.813201904296875
INFO:root:current mean train loss 1996.929215742902
INFO:root:current train perplexity4.813272476196289
INFO:root:current mean train loss 1997.2028247335684
INFO:root:current train perplexity4.813076019287109
INFO:root:current mean train loss 1994.9486003800935
INFO:root:current train perplexity4.8118791580200195
INFO:root:current mean train loss 1995.599337550572
INFO:root:current train perplexity4.81458854675293
INFO:root:current mean train loss 1992.8529054735527
INFO:root:current train perplexity4.812824249267578
INFO:root:current mean train loss 1991.7503539114286
INFO:root:current train perplexity4.811975479125977
INFO:root:current mean train loss 1991.1617046517385
INFO:root:current train perplexity4.806686878204346
INFO:root:current mean train loss 1990.0667453163549
INFO:root:current train perplexity4.804697036743164
INFO:root:current mean train loss 1989.8218358169368
INFO:root:current train perplexity4.802219390869141
INFO:root:current mean train loss 1989.4684969170148
INFO:root:current train perplexity4.800559997558594
INFO:root:current mean train loss 1990.0413091303228
INFO:root:current train perplexity4.803186416625977
INFO:root:current mean train loss 1991.058575820923
INFO:root:current train perplexity4.804554462432861

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.03s/it]
INFO:root:final mean train loss: 1989.8784316962738
INFO:root:final train perplexity: 4.803465843200684
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.36s/it]
INFO:root:eval mean loss: 3078.200533296969
INFO:root:eval perplexity: 12.501995086669922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/14
 14%|â–ˆâ–        | 14/100 [1:09:49<7:12:59, 302.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1946.258445945946
INFO:root:current train perplexity4.666243076324463
INFO:root:current mean train loss 1948.08965396185
INFO:root:current train perplexity4.696679592132568
INFO:root:current mean train loss 1964.039161392405
INFO:root:current train perplexity4.722171306610107
INFO:root:current mean train loss 1960.4303072694502
INFO:root:current train perplexity4.716195106506348
INFO:root:current mean train loss 1959.3431228882116
INFO:root:current train perplexity4.722781658172607
INFO:root:current mean train loss 1962.2750653314856
INFO:root:current train perplexity4.724101543426514
INFO:root:current mean train loss 1961.6327028858418
INFO:root:current train perplexity4.71624755859375
INFO:root:current mean train loss 1959.0913167096867
INFO:root:current train perplexity4.714170932769775
INFO:root:current mean train loss 1960.1509548902795
INFO:root:current train perplexity4.714822769165039
INFO:root:current mean train loss 1961.6551498038536
INFO:root:current train perplexity4.7195539474487305
INFO:root:current mean train loss 1962.3738436869048
INFO:root:current train perplexity4.721733093261719
INFO:root:current mean train loss 1965.0167193383425
INFO:root:current train perplexity4.724526405334473
INFO:root:current mean train loss 1966.9208493922733
INFO:root:current train perplexity4.728590965270996
INFO:root:current mean train loss 1966.7389032881742
INFO:root:current train perplexity4.727402687072754
INFO:root:current mean train loss 1966.934393195867
INFO:root:current train perplexity4.723397254943848
INFO:root:current mean train loss 1968.0520840745974
INFO:root:current train perplexity4.728471755981445
INFO:root:current mean train loss 1967.878318418434
INFO:root:current train perplexity4.726717472076416
INFO:root:current mean train loss 1968.527286544914
INFO:root:current train perplexity4.723923206329346
INFO:root:current mean train loss 1968.4767215834665
INFO:root:current train perplexity4.722060203552246
INFO:root:current mean train loss 1969.332371748657
INFO:root:current train perplexity4.722962379455566

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.33s/it]
INFO:root:final mean train loss: 1968.1563602510992
INFO:root:final train perplexity: 4.721877574920654
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.63s/it]
INFO:root:eval mean loss: 3078.526101052224
INFO:root:eval perplexity: 12.50533676147461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/15
 15%|â–ˆâ–Œ        | 15/100 [1:14:49<7:06:48, 301.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1957.0864280418114
INFO:root:current train perplexity4.632614612579346
INFO:root:current mean train loss 1950.1779230291193
INFO:root:current train perplexity4.6092848777771
INFO:root:current mean train loss 1946.3191456231546
INFO:root:current train perplexity4.63194465637207
INFO:root:current mean train loss 1942.7755002813824
INFO:root:current train perplexity4.638127326965332
INFO:root:current mean train loss 1943.5944259576336
INFO:root:current train perplexity4.6380205154418945
INFO:root:current mean train loss 1942.1192131180196
INFO:root:current train perplexity4.636719226837158
INFO:root:current mean train loss 1944.000517772243
INFO:root:current train perplexity4.637657642364502
INFO:root:current mean train loss 1944.915282555537
INFO:root:current train perplexity4.642007827758789
INFO:root:current mean train loss 1946.148372319599
INFO:root:current train perplexity4.642175197601318
INFO:root:current mean train loss 1944.8581934515034
INFO:root:current train perplexity4.640961170196533
INFO:root:current mean train loss 1945.5196101208567
INFO:root:current train perplexity4.641539573669434
INFO:root:current mean train loss 1944.649779427196
INFO:root:current train perplexity4.641956329345703
INFO:root:current mean train loss 1946.1071035576779
INFO:root:current train perplexity4.644500732421875
INFO:root:current mean train loss 1948.30222121088
INFO:root:current train perplexity4.649989604949951
INFO:root:current mean train loss 1947.6657618295703
INFO:root:current train perplexity4.646282196044922
INFO:root:current mean train loss 1948.0586989315627
INFO:root:current train perplexity4.648380756378174
INFO:root:current mean train loss 1947.397483521246
INFO:root:current train perplexity4.646940231323242
INFO:root:current mean train loss 1947.310914060273
INFO:root:current train perplexity4.64587926864624
INFO:root:current mean train loss 1947.1343420660355
INFO:root:current train perplexity4.645881175994873
INFO:root:current mean train loss 1948.3548268500713
INFO:root:current train perplexity4.646853923797607

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.23s/it]
INFO:root:final mean train loss: 1948.0727163556244
INFO:root:final train perplexity: 4.64767599105835
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.52s/it]
INFO:root:eval mean loss: 3081.0803303303305
INFO:root:eval perplexity: 12.531574249267578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/16
 16%|â–ˆâ–Œ        | 16/100 [1:19:49<7:01:21, 300.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1943.3717935051716
INFO:root:current train perplexity4.639016628265381
INFO:root:current mean train loss 1922.8685424090827
INFO:root:current train perplexity4.582620620727539
INFO:root:current mean train loss 1921.3718509462926
INFO:root:current train perplexity4.586915493011475
INFO:root:current mean train loss 1923.0415993250926
INFO:root:current train perplexity4.582364082336426
INFO:root:current mean train loss 1924.5144027418391
INFO:root:current train perplexity4.578916072845459
INFO:root:current mean train loss 1925.5629592067098
INFO:root:current train perplexity4.574580192565918
INFO:root:current mean train loss 1924.474805669884
INFO:root:current train perplexity4.572939395904541
INFO:root:current mean train loss 1926.5072008818195
INFO:root:current train perplexity4.571559429168701
INFO:root:current mean train loss 1925.602801282425
INFO:root:current train perplexity4.572968482971191
INFO:root:current mean train loss 1927.0481662298453
INFO:root:current train perplexity4.574347972869873
INFO:root:current mean train loss 1926.5129334122971
INFO:root:current train perplexity4.570639610290527
INFO:root:current mean train loss 1927.409888654362
INFO:root:current train perplexity4.570201873779297
INFO:root:current mean train loss 1926.1176146980724
INFO:root:current train perplexity4.569104194641113
INFO:root:current mean train loss 1926.5949699908256
INFO:root:current train perplexity4.572829246520996
INFO:root:current mean train loss 1926.6862211246867
INFO:root:current train perplexity4.574399471282959
INFO:root:current mean train loss 1927.5591163756665
INFO:root:current train perplexity4.577048301696777
INFO:root:current mean train loss 1927.1437390713832
INFO:root:current train perplexity4.5725932121276855
INFO:root:current mean train loss 1928.0886432425846
INFO:root:current train perplexity4.575832366943359
INFO:root:current mean train loss 1928.2179840430417
INFO:root:current train perplexity4.577374458312988
INFO:root:current mean train loss 1929.7326428526128
INFO:root:current train perplexity4.579754829406738

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.53s/it]
INFO:root:final mean train loss: 1929.6187759222435
INFO:root:final train perplexity: 4.58052396774292
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.83s/it]
INFO:root:eval mean loss: 3085.9790596260323
INFO:root:eval perplexity: 12.582049369812012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/17
 17%|â–ˆâ–‹        | 17/100 [1:24:49<6:55:52, 300.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1897.5152171741831
INFO:root:current train perplexity4.481018543243408
INFO:root:current mean train loss 1903.7225296345164
INFO:root:current train perplexity4.492450714111328
INFO:root:current mean train loss 1910.5267287360298
INFO:root:current train perplexity4.501382827758789
INFO:root:current mean train loss 1903.0912463001368
INFO:root:current train perplexity4.493362903594971
INFO:root:current mean train loss 1907.3627071693295
INFO:root:current train perplexity4.510148048400879
INFO:root:current mean train loss 1908.857121889283
INFO:root:current train perplexity4.5098981857299805
INFO:root:current mean train loss 1910.0215017629225
INFO:root:current train perplexity4.515238285064697
INFO:root:current mean train loss 1907.7915080888622
INFO:root:current train perplexity4.512088298797607
INFO:root:current mean train loss 1908.7829532107792
INFO:root:current train perplexity4.513072490692139
INFO:root:current mean train loss 1912.6049462445835
INFO:root:current train perplexity4.51751184463501
INFO:root:current mean train loss 1913.8689721051385
INFO:root:current train perplexity4.516860485076904
INFO:root:current mean train loss 1913.7718162665062
INFO:root:current train perplexity4.513666152954102
INFO:root:current mean train loss 1911.6918549152635
INFO:root:current train perplexity4.5116119384765625
INFO:root:current mean train loss 1910.6552217247163
INFO:root:current train perplexity4.508568286895752
INFO:root:current mean train loss 1911.0036927910262
INFO:root:current train perplexity4.508983135223389
INFO:root:current mean train loss 1911.1482354843947
INFO:root:current train perplexity4.511995315551758
INFO:root:current mean train loss 1912.3372245173884
INFO:root:current train perplexity4.516023635864258
INFO:root:current mean train loss 1912.2292250392154
INFO:root:current train perplexity4.517635345458984
INFO:root:current mean train loss 1912.2379885528046
INFO:root:current train perplexity4.518095970153809

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.03s/it]
INFO:root:final mean train loss: 1912.3867495292013
INFO:root:final train perplexity: 4.518694877624512
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.32s/it]
INFO:root:eval mean loss: 3101.9320885827233
INFO:root:eval perplexity: 12.747836112976074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/18
 18%|â–ˆâ–Š        | 18/100 [1:29:48<6:50:06, 300.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1916.963525390625
INFO:root:current train perplexity4.527335166931152
INFO:root:current mean train loss 1892.4340576171876
INFO:root:current train perplexity4.456450939178467
INFO:root:current mean train loss 1896.0602771293827
INFO:root:current train perplexity4.456719875335693
INFO:root:current mean train loss 1899.31630098937
INFO:root:current train perplexity4.466437339782715
INFO:root:current mean train loss 1895.4672447675541
INFO:root:current train perplexity4.461658954620361
INFO:root:current mean train loss 1893.721506613552
INFO:root:current train perplexity4.45665168762207
INFO:root:current mean train loss 1897.1501180349303
INFO:root:current train perplexity4.462273597717285
INFO:root:current mean train loss 1896.5194251094304
INFO:root:current train perplexity4.4642205238342285
INFO:root:current mean train loss 1897.1390297457299
INFO:root:current train perplexity4.461573123931885
INFO:root:current mean train loss 1898.933504861231
INFO:root:current train perplexity4.46726131439209
INFO:root:current mean train loss 1901.3639860997746
INFO:root:current train perplexity4.47223424911499
INFO:root:current mean train loss 1899.4969047166644
INFO:root:current train perplexity4.466381549835205
INFO:root:current mean train loss 1898.3723847575206
INFO:root:current train perplexity4.462254047393799
INFO:root:current mean train loss 1897.4519419936842
INFO:root:current train perplexity4.461423873901367
INFO:root:current mean train loss 1896.9908670554382
INFO:root:current train perplexity4.459323883056641
INFO:root:current mean train loss 1895.5390067775384
INFO:root:current train perplexity4.458027362823486
INFO:root:current mean train loss 1894.5256394811138
INFO:root:current train perplexity4.456326961517334
INFO:root:current mean train loss 1895.1797667562087
INFO:root:current train perplexity4.457474708557129
INFO:root:current mean train loss 1894.3392855403827
INFO:root:current train perplexity4.455514430999756
INFO:root:current mean train loss 1894.7521013395053
INFO:root:current train perplexity4.457024097442627

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.86s/it]
INFO:root:final mean train loss: 1895.598108581143
INFO:root:final train perplexity: 4.459259510040283
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.41s/it]
INFO:root:eval mean loss: 3098.1195702538475
INFO:root:eval perplexity: 12.708019256591797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/19
 19%|â–ˆâ–‰        | 19/100 [1:34:47<6:44:57, 299.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1849.415682705966
INFO:root:current train perplexity4.351160049438477
INFO:root:current mean train loss 1866.7707709640754
INFO:root:current train perplexity4.34261417388916
INFO:root:current mean train loss 1864.008708232158
INFO:root:current train perplexity4.35037899017334
INFO:root:current mean train loss 1865.0879857791876
INFO:root:current train perplexity4.352949142456055
INFO:root:current mean train loss 1874.4719718463048
INFO:root:current train perplexity4.363137245178223
INFO:root:current mean train loss 1876.8385379250478
INFO:root:current train perplexity4.375788688659668
INFO:root:current mean train loss 1877.2489755513966
INFO:root:current train perplexity4.383566379547119
INFO:root:current mean train loss 1875.7771437372858
INFO:root:current train perplexity4.386003494262695
INFO:root:current mean train loss 1878.0452205166039
INFO:root:current train perplexity4.387322902679443
INFO:root:current mean train loss 1879.5407283228544
INFO:root:current train perplexity4.39070463180542
INFO:root:current mean train loss 1878.8925261674794
INFO:root:current train perplexity4.394100189208984
INFO:root:current mean train loss 1878.891797288429
INFO:root:current train perplexity4.396358489990234
INFO:root:current mean train loss 1880.1076356478877
INFO:root:current train perplexity4.39974308013916
INFO:root:current mean train loss 1881.7832098656452
INFO:root:current train perplexity4.404613494873047
INFO:root:current mean train loss 1881.7613997533183
INFO:root:current train perplexity4.403384208679199
INFO:root:current mean train loss 1882.2079990702766
INFO:root:current train perplexity4.40509033203125
INFO:root:current mean train loss 1881.8938579065439
INFO:root:current train perplexity4.404388427734375
INFO:root:current mean train loss 1882.0431418601645
INFO:root:current train perplexity4.4076247215271
INFO:root:current mean train loss 1882.5518563665228
INFO:root:current train perplexity4.409630298614502
INFO:root:current mean train loss 1882.839207993586
INFO:root:current train perplexity4.410397052764893

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.84s/it]
INFO:root:final mean train loss: 1880.9993423715841
INFO:root:final train perplexity: 4.408212184906006
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.46s/it]
INFO:root:eval mean loss: 3098.2710136894707
INFO:root:eval perplexity: 12.70959758758545
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/20
 20%|â–ˆâ–ˆ        | 20/100 [1:39:47<6:39:52, 299.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1848.027096479367
INFO:root:current train perplexity4.3249192237854
INFO:root:current mean train loss 1875.7209709771246
INFO:root:current train perplexity4.3435163497924805
INFO:root:current mean train loss 1872.8169466282034
INFO:root:current train perplexity4.34395170211792
INFO:root:current mean train loss 1871.3703065945335
INFO:root:current train perplexity4.3430962562561035
INFO:root:current mean train loss 1869.417700417764
INFO:root:current train perplexity4.344419002532959
INFO:root:current mean train loss 1869.1433990988085
INFO:root:current train perplexity4.34951114654541
INFO:root:current mean train loss 1867.531355068344
INFO:root:current train perplexity4.354144096374512
INFO:root:current mean train loss 1869.01593224057
INFO:root:current train perplexity4.356112003326416
INFO:root:current mean train loss 1867.147721082576
INFO:root:current train perplexity4.354663372039795
INFO:root:current mean train loss 1867.4598356171791
INFO:root:current train perplexity4.353456497192383
INFO:root:current mean train loss 1866.9073809420868
INFO:root:current train perplexity4.352475166320801
INFO:root:current mean train loss 1867.7945376589594
INFO:root:current train perplexity4.354841232299805
INFO:root:current mean train loss 1866.526671230264
INFO:root:current train perplexity4.352258682250977
INFO:root:current mean train loss 1867.9650637318252
INFO:root:current train perplexity4.35545015335083
INFO:root:current mean train loss 1868.703042290789
INFO:root:current train perplexity4.359869480133057
INFO:root:current mean train loss 1869.9674898758578
INFO:root:current train perplexity4.3639655113220215
INFO:root:current mean train loss 1868.353207954188
INFO:root:current train perplexity4.3606390953063965
INFO:root:current mean train loss 1868.7326376565645
INFO:root:current train perplexity4.362700462341309
INFO:root:current mean train loss 1868.613446864698
INFO:root:current train perplexity4.361620903015137
INFO:root:current mean train loss 1867.5588220258912
INFO:root:current train perplexity4.360230922698975

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.61s/it]
INFO:root:final mean train loss: 1866.6041358874654
INFO:root:final train perplexity: 4.358449459075928
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.30s/it]
INFO:root:eval mean loss: 3106.2545382296357
INFO:root:eval perplexity: 12.793128967285156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/21
 21%|â–ˆâ–ˆ        | 21/100 [1:44:47<6:35:03, 300.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1823.6257803780693
INFO:root:current train perplexity4.280106544494629
INFO:root:current mean train loss 1835.12161333133
INFO:root:current train perplexity4.287537574768066
INFO:root:current mean train loss 1841.953049659729
INFO:root:current train perplexity4.302082538604736
INFO:root:current mean train loss 1847.0122913832074
INFO:root:current train perplexity4.310437202453613
INFO:root:current mean train loss 1848.3623523377535
INFO:root:current train perplexity4.310820579528809
INFO:root:current mean train loss 1848.5129297928845
INFO:root:current train perplexity4.301706790924072
INFO:root:current mean train loss 1847.384625132491
INFO:root:current train perplexity4.301584720611572
INFO:root:current mean train loss 1848.6566233155588
INFO:root:current train perplexity4.300946235656738
INFO:root:current mean train loss 1848.845229246906
INFO:root:current train perplexity4.302659511566162
INFO:root:current mean train loss 1850.6374810510101
INFO:root:current train perplexity4.303902626037598
INFO:root:current mean train loss 1850.4728651335745
INFO:root:current train perplexity4.304167747497559
INFO:root:current mean train loss 1850.8282820229713
INFO:root:current train perplexity4.30394983291626
INFO:root:current mean train loss 1850.534012326769
INFO:root:current train perplexity4.301822662353516
INFO:root:current mean train loss 1851.6762846550055
INFO:root:current train perplexity4.305404186248779
INFO:root:current mean train loss 1852.0357344071945
INFO:root:current train perplexity4.304589748382568
INFO:root:current mean train loss 1852.6133337339584
INFO:root:current train perplexity4.306318283081055
INFO:root:current mean train loss 1853.21717598588
INFO:root:current train perplexity4.306092262268066
INFO:root:current mean train loss 1853.5835170876192
INFO:root:current train perplexity4.308111190795898
INFO:root:current mean train loss 1853.8376041938518
INFO:root:current train perplexity4.309257984161377
INFO:root:current mean train loss 1853.3083070470268
INFO:root:current train perplexity4.310637950897217

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.76s/it]
INFO:root:final mean train loss: 1852.9737190558221
INFO:root:final train perplexity: 4.311847686767578
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.67s/it]
INFO:root:eval mean loss: 3106.9848772111955
INFO:root:eval perplexity: 12.800802230834961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/22
 22%|â–ˆâ–ˆâ–       | 22/100 [1:49:47<6:30:00, 300.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1833.7372361274615
INFO:root:current train perplexity4.266478538513184
INFO:root:current mean train loss 1839.1710557882495
INFO:root:current train perplexity4.2578301429748535
INFO:root:current mean train loss 1838.8445325020032
INFO:root:current train perplexity4.259850025177002
INFO:root:current mean train loss 1836.1154415345384
INFO:root:current train perplexity4.2597270011901855
INFO:root:current mean train loss 1833.459311616345
INFO:root:current train perplexity4.243932723999023
INFO:root:current mean train loss 1835.623171714796
INFO:root:current train perplexity4.250916004180908
INFO:root:current mean train loss 1836.4323877388442
INFO:root:current train perplexity4.255464553833008
INFO:root:current mean train loss 1834.827412001991
INFO:root:current train perplexity4.254583835601807
INFO:root:current mean train loss 1835.3909903719664
INFO:root:current train perplexity4.256569862365723
INFO:root:current mean train loss 1837.9315519264276
INFO:root:current train perplexity4.260737419128418
INFO:root:current mean train loss 1840.0086029422473
INFO:root:current train perplexity4.265738010406494
INFO:root:current mean train loss 1840.1558785857244
INFO:root:current train perplexity4.266334533691406
INFO:root:current mean train loss 1839.8373152739591
INFO:root:current train perplexity4.267207622528076
INFO:root:current mean train loss 1839.1160513481257
INFO:root:current train perplexity4.266506671905518
INFO:root:current mean train loss 1840.141437476133
INFO:root:current train perplexity4.266510486602783
INFO:root:current mean train loss 1841.6628397015804
INFO:root:current train perplexity4.272351264953613
INFO:root:current mean train loss 1841.948851225694
INFO:root:current train perplexity4.271455764770508
INFO:root:current mean train loss 1841.04977322324
INFO:root:current train perplexity4.269059658050537
INFO:root:current mean train loss 1841.166660648963
INFO:root:current train perplexity4.2693305015563965
INFO:root:current mean train loss 1841.6464408182337
INFO:root:current train perplexity4.271294593811035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.57s/it]
INFO:root:final mean train loss: 1840.827908529877
INFO:root:final train perplexity: 4.2707414627075195
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.30s/it]
INFO:root:eval mean loss: 3115.765940256663
INFO:root:eval perplexity: 12.8933687210083
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/23
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [1:54:47<6:24:45, 299.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1844.6099148220487
INFO:root:current train perplexity4.229740142822266
INFO:root:current mean train loss 1825.8749498869242
INFO:root:current train perplexity4.193933486938477
INFO:root:current mean train loss 1826.8596178778287
INFO:root:current train perplexity4.20530366897583
INFO:root:current mean train loss 1832.1246309720552
INFO:root:current train perplexity4.21906042098999
INFO:root:current mean train loss 1824.2179547991072
INFO:root:current train perplexity4.207515239715576
INFO:root:current mean train loss 1827.5635949086334
INFO:root:current train perplexity4.216798782348633
INFO:root:current mean train loss 1829.6363477623981
INFO:root:current train perplexity4.223330020904541
INFO:root:current mean train loss 1830.3320684891712
INFO:root:current train perplexity4.2210798263549805
INFO:root:current mean train loss 1829.8432426538361
INFO:root:current train perplexity4.222474575042725
INFO:root:current mean train loss 1831.5300978535354
INFO:root:current train perplexity4.228682518005371
INFO:root:current mean train loss 1829.3839801193378
INFO:root:current train perplexity4.227313995361328
INFO:root:current mean train loss 1827.7405575022979
INFO:root:current train perplexity4.220139026641846
INFO:root:current mean train loss 1826.7049834022225
INFO:root:current train perplexity4.216278553009033
INFO:root:current mean train loss 1826.6894773634217
INFO:root:current train perplexity4.218920707702637
INFO:root:current mean train loss 1826.77799064073
INFO:root:current train perplexity4.2205119132995605
INFO:root:current mean train loss 1828.2097648572621
INFO:root:current train perplexity4.224485397338867
INFO:root:current mean train loss 1827.574236013198
INFO:root:current train perplexity4.2254638671875
INFO:root:current mean train loss 1827.9744334300804
INFO:root:current train perplexity4.226978302001953
INFO:root:current mean train loss 1828.6404619812336
INFO:root:current train perplexity4.228820323944092

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.88s/it]
INFO:root:final mean train loss: 1828.3843188341134
INFO:root:final train perplexity: 4.229034900665283
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it]
INFO:root:eval mean loss: 3108.18152551966
INFO:root:eval perplexity: 12.813376426696777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/24
 24%|â–ˆâ–ˆâ–       | 24/100 [1:59:47<6:19:48, 299.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1744.8377511160713
INFO:root:current train perplexity4.072329521179199
INFO:root:current mean train loss 1785.4060708874854
INFO:root:current train perplexity4.116724491119385
INFO:root:current mean train loss 1797.3129051319067
INFO:root:current train perplexity4.142592906951904
INFO:root:current mean train loss 1803.4269685527788
INFO:root:current train perplexity4.160280704498291
INFO:root:current mean train loss 1804.3513123608338
INFO:root:current train perplexity4.159434795379639
INFO:root:current mean train loss 1804.7449917464096
INFO:root:current train perplexity4.15846061706543
INFO:root:current mean train loss 1806.8522372049397
INFO:root:current train perplexity4.167063236236572
INFO:root:current mean train loss 1809.8860123997192
INFO:root:current train perplexity4.174662113189697
INFO:root:current mean train loss 1809.5567345601476
INFO:root:current train perplexity4.174178123474121
INFO:root:current mean train loss 1811.2120774509888
INFO:root:current train perplexity4.177954196929932
INFO:root:current mean train loss 1811.5699825343688
INFO:root:current train perplexity4.181253910064697
INFO:root:current mean train loss 1812.572685758596
INFO:root:current train perplexity4.181151390075684
INFO:root:current mean train loss 1815.8301822943636
INFO:root:current train perplexity4.190239906311035
INFO:root:current mean train loss 1815.0018085459305
INFO:root:current train perplexity4.187152862548828
INFO:root:current mean train loss 1814.7372486410027
INFO:root:current train perplexity4.1863203048706055
INFO:root:current mean train loss 1815.7252846093231
INFO:root:current train perplexity4.18691349029541
INFO:root:current mean train loss 1817.7460726326715
INFO:root:current train perplexity4.1901535987854
INFO:root:current mean train loss 1817.233707439152
INFO:root:current train perplexity4.1907548904418945
INFO:root:current mean train loss 1817.0664068579872
INFO:root:current train perplexity4.190473556518555
INFO:root:current mean train loss 1816.80930415185
INFO:root:current train perplexity4.190143585205078

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.13s/it]
INFO:root:final mean train loss: 1815.985071348651
INFO:root:final train perplexity: 4.187881946563721
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.42s/it]
INFO:root:eval mean loss: 3135.7974263325827
INFO:root:eval perplexity: 13.107054710388184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/25
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [2:04:47<6:14:51, 299.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1782.2696787516277
INFO:root:current train perplexity4.096622467041016
INFO:root:current mean train loss 1776.2487251527848
INFO:root:current train perplexity4.122264385223389
INFO:root:current mean train loss 1790.4890627179827
INFO:root:current train perplexity4.143002986907959
INFO:root:current mean train loss 1797.935607533396
INFO:root:current train perplexity4.138899326324463
INFO:root:current mean train loss 1796.4765031922539
INFO:root:current train perplexity4.13400936126709
INFO:root:current mean train loss 1798.4147268979605
INFO:root:current train perplexity4.134779453277588
INFO:root:current mean train loss 1802.1297104664338
INFO:root:current train perplexity4.1437859535217285
INFO:root:current mean train loss 1804.4170758157804
INFO:root:current train perplexity4.150219917297363
INFO:root:current mean train loss 1805.480498971291
INFO:root:current train perplexity4.150558948516846
INFO:root:current mean train loss 1804.3643414385906
INFO:root:current train perplexity4.145669460296631
INFO:root:current mean train loss 1805.5378457307816
INFO:root:current train perplexity4.152542591094971
INFO:root:current mean train loss 1805.7951690565224
INFO:root:current train perplexity4.149022579193115
INFO:root:current mean train loss 1804.6093399945428
INFO:root:current train perplexity4.1450066566467285
INFO:root:current mean train loss 1804.6904271059525
INFO:root:current train perplexity4.147244453430176
INFO:root:current mean train loss 1805.6396308641756
INFO:root:current train perplexity4.148996353149414
INFO:root:current mean train loss 1805.9074554042866
INFO:root:current train perplexity4.149595737457275
INFO:root:current mean train loss 1806.6214698077422
INFO:root:current train perplexity4.1503705978393555
INFO:root:current mean train loss 1807.4861533746919
INFO:root:current train perplexity4.152553081512451
INFO:root:current mean train loss 1806.727447175143
INFO:root:current train perplexity4.1540093421936035
INFO:root:current mean train loss 1807.0191584406673
INFO:root:current train perplexity4.154226303100586

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.67s/it]
INFO:root:final mean train loss: 1805.7440248644239
INFO:root:final train perplexity: 4.15419340133667
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.47s/it]
INFO:root:eval mean loss: 3117.6917588975693
INFO:root:eval perplexity: 12.913762092590332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/26
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [2:09:46<6:09:44, 299.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1798.035037157012
INFO:root:current train perplexity4.0945515632629395
INFO:root:current mean train loss 1783.3288600191156
INFO:root:current train perplexity4.092975616455078
INFO:root:current mean train loss 1787.2856318683546
INFO:root:current train perplexity4.108772277832031
INFO:root:current mean train loss 1797.5804271530196
INFO:root:current train perplexity4.122396945953369
INFO:root:current mean train loss 1790.659128755669
INFO:root:current train perplexity4.115163326263428
INFO:root:current mean train loss 1793.5161412603975
INFO:root:current train perplexity4.119273662567139
INFO:root:current mean train loss 1793.9780578137188
INFO:root:current train perplexity4.121729850769043
INFO:root:current mean train loss 1793.7887144101614
INFO:root:current train perplexity4.123135566711426
INFO:root:current mean train loss 1798.0329446146236
INFO:root:current train perplexity4.130652904510498
INFO:root:current mean train loss 1796.3169311134266
INFO:root:current train perplexity4.125097274780273
INFO:root:current mean train loss 1794.463719319427
INFO:root:current train perplexity4.121467590332031
INFO:root:current mean train loss 1795.8636589083726
INFO:root:current train perplexity4.120748519897461
INFO:root:current mean train loss 1795.6649807323668
INFO:root:current train perplexity4.118519306182861
INFO:root:current mean train loss 1795.849860433853
INFO:root:current train perplexity4.11973237991333
INFO:root:current mean train loss 1796.0078149566546
INFO:root:current train perplexity4.121039390563965
INFO:root:current mean train loss 1795.8865462989486
INFO:root:current train perplexity4.1214823722839355
INFO:root:current mean train loss 1795.180204197374
INFO:root:current train perplexity4.119842529296875
INFO:root:current mean train loss 1795.275864041858
INFO:root:current train perplexity4.119915008544922
INFO:root:current mean train loss 1795.347229368592
INFO:root:current train perplexity4.119190692901611
INFO:root:current mean train loss 1795.4931404157007
INFO:root:current train perplexity4.119553089141846

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.14s/it]
INFO:root:final mean train loss: 1795.2825728592943
INFO:root:final train perplexity: 4.120060443878174
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.03s/it]
INFO:root:eval mean loss: 3127.124483125704
INFO:root:eval perplexity: 13.014102935791016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/27
 27%|â–ˆâ–ˆâ–‹       | 27/100 [2:14:47<6:05:03, 300.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1804.283548289332
INFO:root:current train perplexity4.082759380340576
INFO:root:current mean train loss 1780.737557326691
INFO:root:current train perplexity4.0591864585876465
INFO:root:current mean train loss 1769.561234348504
INFO:root:current train perplexity4.060568332672119
INFO:root:current mean train loss 1769.0632937980097
INFO:root:current train perplexity4.05552339553833
INFO:root:current mean train loss 1772.199018320142
INFO:root:current train perplexity4.063340187072754
INFO:root:current mean train loss 1777.517593000952
INFO:root:current train perplexity4.071156978607178
INFO:root:current mean train loss 1778.7727779863815
INFO:root:current train perplexity4.072230815887451
INFO:root:current mean train loss 1780.8552756598883
INFO:root:current train perplexity4.076848030090332
INFO:root:current mean train loss 1781.8207997853383
INFO:root:current train perplexity4.080203533172607
INFO:root:current mean train loss 1781.1909772199976
INFO:root:current train perplexity4.077130317687988
INFO:root:current mean train loss 1780.470639666898
INFO:root:current train perplexity4.0757012367248535
INFO:root:current mean train loss 1782.1756915420242
INFO:root:current train perplexity4.078124523162842
INFO:root:current mean train loss 1783.665822913044
INFO:root:current train perplexity4.080562114715576
INFO:root:current mean train loss 1783.138268539586
INFO:root:current train perplexity4.077916622161865
INFO:root:current mean train loss 1783.6525356465406
INFO:root:current train perplexity4.079771041870117
INFO:root:current mean train loss 1784.540147813202
INFO:root:current train perplexity4.081872940063477
INFO:root:current mean train loss 1784.4657834999812
INFO:root:current train perplexity4.081849575042725
INFO:root:current mean train loss 1783.7957072078977
INFO:root:current train perplexity4.080108165740967
INFO:root:current mean train loss 1784.6987744876462
INFO:root:current train perplexity4.084440231323242
INFO:root:current mean train loss 1785.0634464501604
INFO:root:current train perplexity4.085312843322754

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.44s/it]
INFO:root:final mean train loss: 1784.9677149570175
INFO:root:final train perplexity: 4.0866804122924805
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.45s/it]
INFO:root:eval mean loss: 3140.0439394472596
INFO:root:eval perplexity: 13.152809143066406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/28
 28%|â–ˆâ–ˆâ–Š       | 28/100 [2:19:46<5:59:48, 299.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1794.843447265625
INFO:root:current train perplexity4.089639663696289
INFO:root:current mean train loss 1780.5875941685267
INFO:root:current train perplexity4.0437726974487305
INFO:root:current mean train loss 1776.4278746448863
INFO:root:current train perplexity4.0445475578308105
INFO:root:current mean train loss 1776.8892483723957
INFO:root:current train perplexity4.0505475997924805
INFO:root:current mean train loss 1777.692376644737
INFO:root:current train perplexity4.0558180809021
INFO:root:current mean train loss 1773.7598783542799
INFO:root:current train perplexity4.04732084274292
INFO:root:current mean train loss 1773.0623101128472
INFO:root:current train perplexity4.046617031097412
INFO:root:current mean train loss 1776.992121030746
INFO:root:current train perplexity4.054813385009766
INFO:root:current mean train loss 1777.2253059430805
INFO:root:current train perplexity4.053932189941406
INFO:root:current mean train loss 1778.3556301332133
INFO:root:current train perplexity4.054117202758789
INFO:root:current mean train loss 1779.2310084711119
INFO:root:current train perplexity4.0557541847229
INFO:root:current mean train loss 1777.8083988530584
INFO:root:current train perplexity4.0564188957214355
INFO:root:current mean train loss 1775.6591777726715
INFO:root:current train perplexity4.052552223205566
INFO:root:current mean train loss 1774.6765712890624
INFO:root:current train perplexity4.053468227386475
INFO:root:current mean train loss 1774.4723000529661
INFO:root:current train perplexity4.051558017730713
INFO:root:current mean train loss 1775.9628917100695
INFO:root:current train perplexity4.053420066833496
INFO:root:current mean train loss 1776.3968395085121
INFO:root:current train perplexity4.0549726486206055
INFO:root:current mean train loss 1775.615955862126
INFO:root:current train perplexity4.054091930389404
INFO:root:current mean train loss 1775.8023304036458
INFO:root:current train perplexity4.055271148681641
INFO:root:current mean train loss 1775.3566555206685
INFO:root:current train perplexity4.054749011993408

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.62s/it]
INFO:root:final mean train loss: 1775.0863718560893
INFO:root:final train perplexity: 4.054955959320068
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.49s/it]
INFO:root:eval mean loss: 3135.8562143686654
INFO:root:eval perplexity: 13.107686042785645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/29
 29%|â–ˆâ–ˆâ–‰       | 29/100 [2:24:47<5:55:05, 300.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1759.9735253375509
INFO:root:current train perplexity4.001655101776123
INFO:root:current mean train loss 1760.0448741912842
INFO:root:current train perplexity4.012306213378906
INFO:root:current mean train loss 1766.2583835549551
INFO:root:current train perplexity4.012179851531982
INFO:root:current mean train loss 1767.331734482123
INFO:root:current train perplexity4.014458179473877
INFO:root:current mean train loss 1774.3892529495363
INFO:root:current train perplexity4.0240654945373535
INFO:root:current mean train loss 1774.287031225256
INFO:root:current train perplexity4.029139518737793
INFO:root:current mean train loss 1773.892211384856
INFO:root:current train perplexity4.024905681610107
INFO:root:current mean train loss 1772.0917663574219
INFO:root:current train perplexity4.024632930755615
INFO:root:current mean train loss 1773.0268925551343
INFO:root:current train perplexity4.024859428405762
INFO:root:current mean train loss 1772.1924214516916
INFO:root:current train perplexity4.025002956390381
INFO:root:current mean train loss 1770.9968003493088
INFO:root:current train perplexity4.022143840789795
INFO:root:current mean train loss 1770.2429648789785
INFO:root:current train perplexity4.022490978240967
INFO:root:current mean train loss 1769.749409017179
INFO:root:current train perplexity4.022294998168945
INFO:root:current mean train loss 1769.1813903457817
INFO:root:current train perplexity4.023693561553955
INFO:root:current mean train loss 1770.052107823758
INFO:root:current train perplexity4.025439739227295
INFO:root:current mean train loss 1769.2686282977386
INFO:root:current train perplexity4.024601459503174
INFO:root:current mean train loss 1768.1626205985428
INFO:root:current train perplexity4.023583889007568
INFO:root:current mean train loss 1766.3439984321594
INFO:root:current train perplexity4.023782253265381
INFO:root:current mean train loss 1766.2903680458633
INFO:root:current train perplexity4.025341033935547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.73s/it]
INFO:root:final mean train loss: 1765.7082182806787
INFO:root:final train perplexity: 4.025075912475586
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.48s/it]
INFO:root:eval mean loss: 3144.1301100905594
INFO:root:eval perplexity: 13.196983337402344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/30
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [2:29:46<5:49:56, 299.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1719.1266954210068
INFO:root:current train perplexity4.041656970977783
INFO:root:current mean train loss 1741.466615449398
INFO:root:current train perplexity3.9832425117492676
INFO:root:current mean train loss 1753.4069631476152
INFO:root:current train perplexity3.994544506072998
INFO:root:current mean train loss 1754.040469666515
INFO:root:current train perplexity4.000826835632324
INFO:root:current mean train loss 1757.4275209757984
INFO:root:current train perplexity3.9954702854156494
INFO:root:current mean train loss 1752.659210384946
INFO:root:current train perplexity3.981600761413574
INFO:root:current mean train loss 1753.0230700863992
INFO:root:current train perplexity3.981207847595215
INFO:root:current mean train loss 1752.417639900498
INFO:root:current train perplexity3.982292413711548
INFO:root:current mean train loss 1753.6113634333476
INFO:root:current train perplexity3.98232364654541
INFO:root:current mean train loss 1754.2890000547907
INFO:root:current train perplexity3.9852287769317627
INFO:root:current mean train loss 1755.8450001016245
INFO:root:current train perplexity3.9887468814849854
INFO:root:current mean train loss 1755.279383061704
INFO:root:current train perplexity3.988147258758545
INFO:root:current mean train loss 1756.085199423917
INFO:root:current train perplexity3.992457389831543
INFO:root:current mean train loss 1756.5927683084954
INFO:root:current train perplexity3.993054151535034
INFO:root:current mean train loss 1757.457698868047
INFO:root:current train perplexity3.993795394897461
INFO:root:current mean train loss 1757.4535930575403
INFO:root:current train perplexity3.9951515197753906
INFO:root:current mean train loss 1757.5784315793244
INFO:root:current train perplexity3.9954640865325928
INFO:root:current mean train loss 1757.7052349807088
INFO:root:current train perplexity3.9975087642669678
INFO:root:current mean train loss 1757.447500790859
INFO:root:current train perplexity3.997661828994751
INFO:root:current mean train loss 1757.4407942358769
INFO:root:current train perplexity3.998037815093994

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.52s/it]
INFO:root:final mean train loss: 1757.1206829092205
INFO:root:final train perplexity: 3.9979071617126465
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.20s/it]
INFO:root:eval mean loss: 3151.046119117164
INFO:root:eval perplexity: 13.272089958190918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/31
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [2:34:47<5:45:01, 300.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1738.302509014423
INFO:root:current train perplexity3.9530460834503174
INFO:root:current mean train loss 1740.559858049665
INFO:root:current train perplexity3.9430041313171387
INFO:root:current mean train loss 1742.1028960911574
INFO:root:current train perplexity3.9412784576416016
INFO:root:current mean train loss 1734.741679372963
INFO:root:current train perplexity3.9252023696899414
INFO:root:current mean train loss 1734.4428719534
INFO:root:current train perplexity3.92563533782959
INFO:root:current mean train loss 1737.0669676341938
INFO:root:current train perplexity3.9319534301757812
INFO:root:current mean train loss 1739.51278520773
INFO:root:current train perplexity3.9396841526031494
INFO:root:current mean train loss 1742.4464286194689
INFO:root:current train perplexity3.943225383758545
INFO:root:current mean train loss 1746.5110203186478
INFO:root:current train perplexity3.9512085914611816
INFO:root:current mean train loss 1745.0736384546267
INFO:root:current train perplexity3.9510505199432373
INFO:root:current mean train loss 1745.425904034174
INFO:root:current train perplexity3.955841064453125
INFO:root:current mean train loss 1747.406533060023
INFO:root:current train perplexity3.9624745845794678
INFO:root:current mean train loss 1747.422787839009
INFO:root:current train perplexity3.96416974067688
INFO:root:current mean train loss 1748.311980510729
INFO:root:current train perplexity3.9646315574645996
INFO:root:current mean train loss 1747.6362606011132
INFO:root:current train perplexity3.966273307800293
INFO:root:current mean train loss 1746.367597227484
INFO:root:current train perplexity3.9659337997436523
INFO:root:current mean train loss 1747.5528657544876
INFO:root:current train perplexity3.9682774543762207
INFO:root:current mean train loss 1748.322293985484
INFO:root:current train perplexity3.9701149463653564
INFO:root:current mean train loss 1747.9654176676522
INFO:root:current train perplexity3.9687392711639404
INFO:root:current mean train loss 1748.1335831401504
INFO:root:current train perplexity3.970221757888794

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.26s/it]
INFO:root:final mean train loss: 1748.4033375180736
INFO:root:final train perplexity: 3.970515727996826
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it]
INFO:root:eval mean loss: 3153.9389817063156
INFO:root:eval perplexity: 13.303630828857422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/32
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [2:39:47<5:40:03, 300.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1715.365103788154
INFO:root:current train perplexity3.845515251159668
INFO:root:current mean train loss 1736.126738861724
INFO:root:current train perplexity3.9011831283569336
INFO:root:current mean train loss 1743.591108659658
INFO:root:current train perplexity3.9280574321746826
INFO:root:current mean train loss 1744.1337605912902
INFO:root:current train perplexity3.937438488006592
INFO:root:current mean train loss 1738.7495387230178
INFO:root:current train perplexity3.930793046951294
INFO:root:current mean train loss 1734.7886364903459
INFO:root:current train perplexity3.9257826805114746
INFO:root:current mean train loss 1731.671896262636
INFO:root:current train perplexity3.924970865249634
INFO:root:current mean train loss 1733.145952884474
INFO:root:current train perplexity3.928562641143799
INFO:root:current mean train loss 1733.7918082856056
INFO:root:current train perplexity3.9314260482788086
INFO:root:current mean train loss 1736.8267115474632
INFO:root:current train perplexity3.9356510639190674
INFO:root:current mean train loss 1737.4365453235484
INFO:root:current train perplexity3.93784499168396
INFO:root:current mean train loss 1737.674709423529
INFO:root:current train perplexity3.9385688304901123
INFO:root:current mean train loss 1739.204108338728
INFO:root:current train perplexity3.9402124881744385
INFO:root:current mean train loss 1739.620024930339
INFO:root:current train perplexity3.939980983734131
INFO:root:current mean train loss 1739.5967957515809
INFO:root:current train perplexity3.9401612281799316
INFO:root:current mean train loss 1740.9582483930706
INFO:root:current train perplexity3.941819667816162
INFO:root:current mean train loss 1741.7522833017917
INFO:root:current train perplexity3.942981481552124
INFO:root:current mean train loss 1741.2190007939123
INFO:root:current train perplexity3.9437077045440674
INFO:root:current mean train loss 1740.5742807455574
INFO:root:current train perplexity3.9445762634277344
INFO:root:current mean train loss 1740.8726650832918
INFO:root:current train perplexity3.9453070163726807

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.32s/it]
INFO:root:final mean train loss: 1739.925181548041
INFO:root:final train perplexity: 3.9440560340881348
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.49s/it]
INFO:root:eval mean loss: 3163.7766743794577
INFO:root:eval perplexity: 13.411460876464844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/33
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [2:44:47<5:35:07, 300.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1702.105623372396
INFO:root:current train perplexity3.853722095489502
INFO:root:current mean train loss 1712.7014457702637
INFO:root:current train perplexity3.892418146133423
INFO:root:current mean train loss 1717.602846116286
INFO:root:current train perplexity3.9054224491119385
INFO:root:current mean train loss 1719.3651275634766
INFO:root:current train perplexity3.9069888591766357
INFO:root:current mean train loss 1717.779859990659
INFO:root:current train perplexity3.9058969020843506
INFO:root:current mean train loss 1720.4714418683734
INFO:root:current train perplexity3.9058597087860107
INFO:root:current mean train loss 1723.0645576245856
INFO:root:current train perplexity3.9112071990966797
INFO:root:current mean train loss 1725.757356824373
INFO:root:current train perplexity3.9113471508026123
INFO:root:current mean train loss 1728.9681952897893
INFO:root:current train perplexity3.9145278930664062
INFO:root:current mean train loss 1729.7273440043132
INFO:root:current train perplexity3.911749839782715
INFO:root:current mean train loss 1729.5054517062206
INFO:root:current train perplexity3.911348819732666
INFO:root:current mean train loss 1728.5241723422346
INFO:root:current train perplexity3.9100892543792725
INFO:root:current mean train loss 1728.9980916341146
INFO:root:current train perplexity3.9115796089172363
INFO:root:current mean train loss 1728.495387986127
INFO:root:current train perplexity3.911278009414673
INFO:root:current mean train loss 1728.6006423741171
INFO:root:current train perplexity3.911170721054077
INFO:root:current mean train loss 1728.1968167818509
INFO:root:current train perplexity3.9116291999816895
INFO:root:current mean train loss 1728.2165425128248
INFO:root:current train perplexity3.9111363887786865
INFO:root:current mean train loss 1730.2157433249733
INFO:root:current train perplexity3.9140942096710205
INFO:root:current mean train loss 1731.5332316080728
INFO:root:current train perplexity3.9173479080200195
INFO:root:current mean train loss 1732.9933172731983
INFO:root:current train perplexity3.9212350845336914

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.98s/it]
INFO:root:final mean train loss: 1732.1484122918341
INFO:root:final train perplexity: 3.919940948486328
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.45s/it]
INFO:root:eval mean loss: 3158.01770642713
INFO:root:eval perplexity: 13.34823226928711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/34
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [2:49:47<5:30:03, 300.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1737.530558796672
INFO:root:current train perplexity3.8671021461486816
INFO:root:current mean train loss 1732.8421472236935
INFO:root:current train perplexity3.883214235305786
INFO:root:current mean train loss 1723.2779580677459
INFO:root:current train perplexity3.874992847442627
INFO:root:current mean train loss 1721.3973544092962
INFO:root:current train perplexity3.876753091812134
INFO:root:current mean train loss 1720.126878654432
INFO:root:current train perplexity3.884033679962158
INFO:root:current mean train loss 1721.12610963395
INFO:root:current train perplexity3.8853752613067627
INFO:root:current mean train loss 1720.649856544844
INFO:root:current train perplexity3.8838961124420166
INFO:root:current mean train loss 1721.1868597985542
INFO:root:current train perplexity3.8805344104766846
INFO:root:current mean train loss 1720.1741534138487
INFO:root:current train perplexity3.8789684772491455
INFO:root:current mean train loss 1720.9201637666326
INFO:root:current train perplexity3.8817710876464844
INFO:root:current mean train loss 1721.6749639342866
INFO:root:current train perplexity3.8850464820861816
INFO:root:current mean train loss 1722.7800211035405
INFO:root:current train perplexity3.8873817920684814
INFO:root:current mean train loss 1724.2407671062854
INFO:root:current train perplexity3.8922131061553955
INFO:root:current mean train loss 1724.388456368152
INFO:root:current train perplexity3.8926594257354736
INFO:root:current mean train loss 1723.79842769801
INFO:root:current train perplexity3.892529010772705
INFO:root:current mean train loss 1723.8488051971456
INFO:root:current train perplexity3.8923258781433105
INFO:root:current mean train loss 1724.9716167233853
INFO:root:current train perplexity3.895033359527588
INFO:root:current mean train loss 1725.1160497112628
INFO:root:current train perplexity3.895688056945801
INFO:root:current mean train loss 1725.4620491397718
INFO:root:current train perplexity3.8972268104553223
INFO:root:current mean train loss 1725.0917599513546
INFO:root:current train perplexity3.8969593048095703

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.12s/it]
INFO:root:final mean train loss: 1724.6016171023032
INFO:root:final train perplexity: 3.8966786861419678
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.80s/it]
INFO:root:eval mean loss: 3167.509062529326
INFO:root:eval perplexity: 13.45259952545166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/35
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [2:54:48<5:25:29, 300.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1739.706291036403
INFO:root:current train perplexity3.913447141647339
INFO:root:current mean train loss 1724.9055213534955
INFO:root:current train perplexity3.881631851196289
INFO:root:current mean train loss 1722.6929454154708
INFO:root:current train perplexity3.8705313205718994
INFO:root:current mean train loss 1718.1361427888048
INFO:root:current train perplexity3.860691785812378
INFO:root:current mean train loss 1715.5509213590428
INFO:root:current train perplexity3.863205909729004
INFO:root:current mean train loss 1716.971143317945
INFO:root:current train perplexity3.8646891117095947
INFO:root:current mean train loss 1716.4581608401252
INFO:root:current train perplexity3.8675899505615234
INFO:root:current mean train loss 1717.4676954908396
INFO:root:current train perplexity3.8668177127838135
INFO:root:current mean train loss 1717.510461180002
INFO:root:current train perplexity3.8694522380828857
INFO:root:current mean train loss 1715.7897169393314
INFO:root:current train perplexity3.866863489151001
INFO:root:current mean train loss 1717.5481022864417
INFO:root:current train perplexity3.8694522380828857
INFO:root:current mean train loss 1718.4969247278057
INFO:root:current train perplexity3.869298219680786
INFO:root:current mean train loss 1718.1371422226682
INFO:root:current train perplexity3.8720884323120117
INFO:root:current mean train loss 1718.29449927003
INFO:root:current train perplexity3.8719120025634766
INFO:root:current mean train loss 1718.4260203247889
INFO:root:current train perplexity3.8718016147613525
INFO:root:current mean train loss 1717.0584734410534
INFO:root:current train perplexity3.869823932647705
INFO:root:current mean train loss 1716.6664813513457
INFO:root:current train perplexity3.869678258895874
INFO:root:current mean train loss 1717.2993979905893
INFO:root:current train perplexity3.8712122440338135
INFO:root:current mean train loss 1717.3692244113813
INFO:root:current train perplexity3.8725509643554688

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.50s/it]
INFO:root:final mean train loss: 1716.8513990624408
INFO:root:final train perplexity: 3.872934103012085
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.49s/it]
INFO:root:eval mean loss: 3175.521696989959
INFO:root:eval perplexity: 13.541339874267578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/36
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [2:59:49<5:20:28, 300.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1743.558349609375
INFO:root:current train perplexity3.953699827194214
INFO:root:current mean train loss 1693.596812755138
INFO:root:current train perplexity3.83508563041687
INFO:root:current mean train loss 1684.76579450996
INFO:root:current train perplexity3.8003644943237305
INFO:root:current mean train loss 1692.6389026703175
INFO:root:current train perplexity3.8172707557678223
INFO:root:current mean train loss 1695.8159512336526
INFO:root:current train perplexity3.812882900238037
INFO:root:current mean train loss 1698.8406858201597
INFO:root:current train perplexity3.822582244873047
INFO:root:current mean train loss 1702.806514159357
INFO:root:current train perplexity3.831757068634033
INFO:root:current mean train loss 1703.6899469002726
INFO:root:current train perplexity3.8329811096191406
INFO:root:current mean train loss 1701.8602449955688
INFO:root:current train perplexity3.8327548503875732
INFO:root:current mean train loss 1701.2669577237411
INFO:root:current train perplexity3.834548234939575
INFO:root:current mean train loss 1701.805363897518
INFO:root:current train perplexity3.835798978805542
INFO:root:current mean train loss 1701.9003602997018
INFO:root:current train perplexity3.8369812965393066
INFO:root:current mean train loss 1703.558373499271
INFO:root:current train perplexity3.838522434234619
INFO:root:current mean train loss 1703.0180090490321
INFO:root:current train perplexity3.8383944034576416
INFO:root:current mean train loss 1706.1862078368622
INFO:root:current train perplexity3.841090440750122
INFO:root:current mean train loss 1706.7099404981955
INFO:root:current train perplexity3.8440542221069336
INFO:root:current mean train loss 1707.5696675201739
INFO:root:current train perplexity3.8455052375793457
INFO:root:current mean train loss 1708.752761457344
INFO:root:current train perplexity3.8464465141296387
INFO:root:current mean train loss 1709.106344137713
INFO:root:current train perplexity3.848083257675171
INFO:root:current mean train loss 1708.9455471867232
INFO:root:current train perplexity3.8480215072631836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.67s/it]
INFO:root:final mean train loss: 1709.4951389791745
INFO:root:final train perplexity: 3.850529670715332
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.55s/it]
INFO:root:eval mean loss: 3171.6379959060623
INFO:root:eval perplexity: 13.498252868652344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/37
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [3:04:49<5:15:32, 300.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1691.7803257533483
INFO:root:current train perplexity3.789599657058716
INFO:root:current mean train loss 1696.4149084091187
INFO:root:current train perplexity3.8109676837921143
INFO:root:current mean train loss 1694.6018334104303
INFO:root:current train perplexity3.799928665161133
INFO:root:current mean train loss 1687.6642995694788
INFO:root:current train perplexity3.792053461074829
INFO:root:current mean train loss 1689.0087927702432
INFO:root:current train perplexity3.8008291721343994
INFO:root:current mean train loss 1691.7550143617573
INFO:root:current train perplexity3.808554172515869
INFO:root:current mean train loss 1692.7460284384952
INFO:root:current train perplexity3.809704303741455
INFO:root:current mean train loss 1691.577637054108
INFO:root:current train perplexity3.809220790863037
INFO:root:current mean train loss 1692.6830342610676
INFO:root:current train perplexity3.814560890197754
INFO:root:current mean train loss 1692.8687269276586
INFO:root:current train perplexity3.8154542446136475
INFO:root:current mean train loss 1695.0314021129088
INFO:root:current train perplexity3.8170905113220215
INFO:root:current mean train loss 1696.3000564034103
INFO:root:current train perplexity3.817418336868286
INFO:root:current mean train loss 1696.3048161310949
INFO:root:current train perplexity3.81986403465271
INFO:root:current mean train loss 1697.087491598474
INFO:root:current train perplexity3.820007562637329
INFO:root:current mean train loss 1696.5612604905243
INFO:root:current train perplexity3.819568634033203
INFO:root:current mean train loss 1698.7115051109754
INFO:root:current train perplexity3.8233697414398193
INFO:root:current mean train loss 1701.198861611856
INFO:root:current train perplexity3.8269448280334473
INFO:root:current mean train loss 1702.6525187315765
INFO:root:current train perplexity3.8282876014709473
INFO:root:current mean train loss 1703.3105070752702
INFO:root:current train perplexity3.829854726791382
INFO:root:current mean train loss 1703.1088972289533
INFO:root:current train perplexity3.829406261444092

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.05s/it]
INFO:root:final mean train loss: 1702.6379436390964
INFO:root:final train perplexity: 3.8297619819641113
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.95s/it]
INFO:root:eval mean loss: 3186.2941000082114
INFO:root:eval perplexity: 13.661567687988281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/38
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [3:09:50<5:10:30, 300.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1675.297816297743
INFO:root:current train perplexity3.7841527462005615
INFO:root:current mean train loss 1697.0786957839439
INFO:root:current train perplexity3.7969415187835693
INFO:root:current mean train loss 1699.3798793247768
INFO:root:current train perplexity3.8023922443389893
INFO:root:current mean train loss 1693.6225900843524
INFO:root:current train perplexity3.7986605167388916
INFO:root:current mean train loss 1694.4807159080933
INFO:root:current train perplexity3.798711061477661
INFO:root:current mean train loss 1692.3295143617402
INFO:root:current train perplexity3.79512095451355
INFO:root:current mean train loss 1692.5236002604167
INFO:root:current train perplexity3.792996644973755
INFO:root:current mean train loss 1690.3977042588613
INFO:root:current train perplexity3.7882351875305176
INFO:root:current mean train loss 1691.582099002635
INFO:root:current train perplexity3.7888917922973633
INFO:root:current mean train loss 1691.5981937468998
INFO:root:current train perplexity3.788841724395752
INFO:root:current mean train loss 1692.1045224422473
INFO:root:current train perplexity3.7918224334716797
INFO:root:current mean train loss 1693.8106530601801
INFO:root:current train perplexity3.7963647842407227
INFO:root:current mean train loss 1694.224013730704
INFO:root:current train perplexity3.7981948852539062
INFO:root:current mean train loss 1692.866112827457
INFO:root:current train perplexity3.7995522022247314
INFO:root:current mean train loss 1694.3267801990971
INFO:root:current train perplexity3.80076265335083
INFO:root:current mean train loss 1694.4067016996612
INFO:root:current train perplexity3.8008954524993896
INFO:root:current mean train loss 1694.7198075964095
INFO:root:current train perplexity3.8016440868377686
INFO:root:current mean train loss 1695.5479592222198
INFO:root:current train perplexity3.8037681579589844
INFO:root:current mean train loss 1695.747854407499
INFO:root:current train perplexity3.8051645755767822
INFO:root:current mean train loss 1695.6481534433242
INFO:root:current train perplexity3.806011199951172

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.90s/it]
INFO:root:final mean train loss: 1695.2191958675105
INFO:root:final train perplexity: 3.807420253753662
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it]
INFO:root:eval mean loss: 3183.1255146748313
INFO:root:eval perplexity: 13.626093864440918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/39
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [3:14:51<5:05:40, 300.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1672.955336047757
INFO:root:current train perplexity3.751631736755371
INFO:root:current mean train loss 1677.4719758210358
INFO:root:current train perplexity3.7572033405303955
INFO:root:current mean train loss 1684.8239084491292
INFO:root:current train perplexity3.763728618621826
INFO:root:current mean train loss 1686.4345625566514
INFO:root:current train perplexity3.7703075408935547
INFO:root:current mean train loss 1683.3287440708705
INFO:root:current train perplexity3.7730002403259277
INFO:root:current mean train loss 1685.508188050837
INFO:root:current train perplexity3.7823662757873535
INFO:root:current mean train loss 1685.0726775662056
INFO:root:current train perplexity3.7824857234954834
INFO:root:current mean train loss 1685.0429815657808
INFO:root:current train perplexity3.7820258140563965
INFO:root:current mean train loss 1687.24385215954
INFO:root:current train perplexity3.7870330810546875
INFO:root:current mean train loss 1686.2707674339754
INFO:root:current train perplexity3.7858939170837402
INFO:root:current mean train loss 1688.087561425965
INFO:root:current train perplexity3.7864761352539062
INFO:root:current mean train loss 1688.1014875979924
INFO:root:current train perplexity3.7843081951141357
INFO:root:current mean train loss 1687.1996350658676
INFO:root:current train perplexity3.7832939624786377
INFO:root:current mean train loss 1688.325799300632
INFO:root:current train perplexity3.7864255905151367
INFO:root:current mean train loss 1687.9261545580487
INFO:root:current train perplexity3.787980318069458
INFO:root:current mean train loss 1688.6766866178427
INFO:root:current train perplexity3.788651466369629
INFO:root:current mean train loss 1689.5873171442538
INFO:root:current train perplexity3.789515256881714
INFO:root:current mean train loss 1689.631158523473
INFO:root:current train perplexity3.789937973022461
INFO:root:current mean train loss 1689.944332594006
INFO:root:current train perplexity3.78973650932312
INFO:root:current mean train loss 1689.9794377473759
INFO:root:current train perplexity3.7893497943878174

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.89s/it]
INFO:root:final mean train loss: 1689.4657604161741
INFO:root:final train perplexity: 3.7901837825775146
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.98s/it]
INFO:root:eval mean loss: 3187.46593688415
INFO:root:eval perplexity: 13.674713134765625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/40
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [3:19:52<5:00:51, 300.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1679.4354927932159
INFO:root:current train perplexity3.7696404457092285
INFO:root:current mean train loss 1683.9105742896736
INFO:root:current train perplexity3.763298511505127
INFO:root:current mean train loss 1680.6585667107695
INFO:root:current train perplexity3.7615742683410645
INFO:root:current mean train loss 1680.9635837524736
INFO:root:current train perplexity3.7666501998901367
INFO:root:current mean train loss 1680.0597145542472
INFO:root:current train perplexity3.76753306388855
INFO:root:current mean train loss 1682.8913780831715
INFO:root:current train perplexity3.7653119564056396
INFO:root:current mean train loss 1682.9178578260194
INFO:root:current train perplexity3.764458656311035
INFO:root:current mean train loss 1685.0874642407634
INFO:root:current train perplexity3.77005672454834
INFO:root:current mean train loss 1684.0117412476002
INFO:root:current train perplexity3.7691988945007324
INFO:root:current mean train loss 1684.8092726803898
INFO:root:current train perplexity3.7707173824310303
INFO:root:current mean train loss 1684.4658521028223
INFO:root:current train perplexity3.768625497817993
INFO:root:current mean train loss 1684.3101398704212
INFO:root:current train perplexity3.7709929943084717
INFO:root:current mean train loss 1684.6528114157788
INFO:root:current train perplexity3.7688052654266357
INFO:root:current mean train loss 1685.8912319877686
INFO:root:current train perplexity3.773315906524658
INFO:root:current mean train loss 1686.317905923819
INFO:root:current train perplexity3.7741730213165283
INFO:root:current mean train loss 1684.8209612739472
INFO:root:current train perplexity3.772642135620117
INFO:root:current mean train loss 1683.9887432850423
INFO:root:current train perplexity3.7698171138763428
INFO:root:current mean train loss 1682.9519494471085
INFO:root:current train perplexity3.7690622806549072
INFO:root:current mean train loss 1682.5412337793957
INFO:root:current train perplexity3.769094944000244
INFO:root:current mean train loss 1682.7527466128727
INFO:root:current train perplexity3.768786668777466

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.31s/it]
INFO:root:final mean train loss: 1682.2497694022236
INFO:root:final train perplexity: 3.768674373626709
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it]
INFO:root:eval mean loss: 3186.2840359891143
INFO:root:eval perplexity: 13.661453247070312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/41
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [3:24:52<4:55:40, 300.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1657.4378420511882
INFO:root:current train perplexity3.7046592235565186
INFO:root:current mean train loss 1659.0472144302057
INFO:root:current train perplexity3.709401845932007
INFO:root:current mean train loss 1665.8495149354676
INFO:root:current train perplexity3.7265353202819824
INFO:root:current mean train loss 1667.7773816657789
INFO:root:current train perplexity3.729083776473999
INFO:root:current mean train loss 1668.3056158250379
INFO:root:current train perplexity3.737006425857544
INFO:root:current mean train loss 1671.2777503096818
INFO:root:current train perplexity3.734459161758423
INFO:root:current mean train loss 1667.7779574339418
INFO:root:current train perplexity3.7295947074890137
INFO:root:current mean train loss 1668.596681527756
INFO:root:current train perplexity3.7316737174987793
INFO:root:current mean train loss 1669.7955784116473
INFO:root:current train perplexity3.733440637588501
INFO:root:current mean train loss 1669.8511060844942
INFO:root:current train perplexity3.7350504398345947
INFO:root:current mean train loss 1670.027120325687
INFO:root:current train perplexity3.731830358505249
INFO:root:current mean train loss 1671.198989306804
INFO:root:current train perplexity3.7339539527893066
INFO:root:current mean train loss 1672.8983981285567
INFO:root:current train perplexity3.7368078231811523
INFO:root:current mean train loss 1672.7558831594736
INFO:root:current train perplexity3.7384469509124756
INFO:root:current mean train loss 1673.7895027201444
INFO:root:current train perplexity3.7418086528778076
INFO:root:current mean train loss 1676.0921413641527
INFO:root:current train perplexity3.745245933532715
INFO:root:current mean train loss 1676.4321975708008
INFO:root:current train perplexity3.747014284133911
INFO:root:current mean train loss 1676.1106037233349
INFO:root:current train perplexity3.7471768856048584
INFO:root:current mean train loss 1676.4962109915818
INFO:root:current train perplexity3.748490333557129

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.41s/it]
INFO:root:final mean train loss: 1676.0252884380516
INFO:root:final train perplexity: 3.7502193450927734
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.11s/it]
INFO:root:eval mean loss: 3199.1305565819725
INFO:root:eval perplexity: 13.806233406066895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/42
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [3:29:53<4:50:43, 300.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1691.8287071814905
INFO:root:current train perplexity3.83479642868042
INFO:root:current mean train loss 1654.9510076742256
INFO:root:current train perplexity3.7333004474639893
INFO:root:current mean train loss 1654.2067510040713
INFO:root:current train perplexity3.7223715782165527
INFO:root:current mean train loss 1658.1069702538439
INFO:root:current train perplexity3.7115466594696045
INFO:root:current mean train loss 1658.4604740466102
INFO:root:current train perplexity3.7141265869140625
INFO:root:current mean train loss 1661.3704058254905
INFO:root:current train perplexity3.712610960006714
INFO:root:current mean train loss 1662.662375420575
INFO:root:current train perplexity3.718766927719116
INFO:root:current mean train loss 1665.9417323985908
INFO:root:current train perplexity3.7203030586242676
INFO:root:current mean train loss 1665.8531390538515
INFO:root:current train perplexity3.723783016204834
INFO:root:current mean train loss 1667.5831574255117
INFO:root:current train perplexity3.7234838008880615
INFO:root:current mean train loss 1668.8401078942497
INFO:root:current train perplexity3.725177526473999
INFO:root:current mean train loss 1669.385094545815
INFO:root:current train perplexity3.7284064292907715
INFO:root:current mean train loss 1669.7680567452855
INFO:root:current train perplexity3.7308850288391113
INFO:root:current mean train loss 1669.468410285665
INFO:root:current train perplexity3.7295989990234375
INFO:root:current mean train loss 1671.138884396563
INFO:root:current train perplexity3.732569694519043
INFO:root:current mean train loss 1671.0959517030785
INFO:root:current train perplexity3.733456611633301
INFO:root:current mean train loss 1669.66506623128
INFO:root:current train perplexity3.7296159267425537
INFO:root:current mean train loss 1669.7789881005317
INFO:root:current train perplexity3.7302803993225098
INFO:root:current mean train loss 1668.947968084774
INFO:root:current train perplexity3.7285313606262207
INFO:root:current mean train loss 1669.9015961411233
INFO:root:current train perplexity3.7306485176086426

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.91s/it]
INFO:root:final mean train loss: 1670.071406023465
INFO:root:final train perplexity: 3.7326512336730957
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.58s/it]
INFO:root:eval mean loss: 3198.8015495964714
INFO:root:eval perplexity: 13.802507400512695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/43
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [3:34:53<4:45:29, 300.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1674.0088419596354
INFO:root:current train perplexity3.737543821334839
INFO:root:current mean train loss 1669.4222355769232
INFO:root:current train perplexity3.719416618347168
INFO:root:current mean train loss 1674.6500058381455
INFO:root:current train perplexity3.726433515548706
INFO:root:current mean train loss 1670.2872776840672
INFO:root:current train perplexity3.7104415893554688
INFO:root:current mean train loss 1666.595973950763
INFO:root:current train perplexity3.710160732269287
INFO:root:current mean train loss 1666.551342543116
INFO:root:current train perplexity3.7058827877044678
INFO:root:current mean train loss 1664.1413667224701
INFO:root:current train perplexity3.7048473358154297
INFO:root:current mean train loss 1665.2626831054688
INFO:root:current train perplexity3.708371639251709
INFO:root:current mean train loss 1666.1854752506117
INFO:root:current train perplexity3.707120418548584
INFO:root:current mean train loss 1666.077530530704
INFO:root:current train perplexity3.7080252170562744
INFO:root:current mean train loss 1665.1322746795358
INFO:root:current train perplexity3.7087244987487793
INFO:root:current mean train loss 1665.1217789641523
INFO:root:current train perplexity3.7090954780578613
INFO:root:current mean train loss 1665.296536378938
INFO:root:current train perplexity3.7107889652252197
INFO:root:current mean train loss 1664.880617620712
INFO:root:current train perplexity3.709968328475952
INFO:root:current mean train loss 1665.515971491887
INFO:root:current train perplexity3.7131829261779785
INFO:root:current mean train loss 1664.2635224385979
INFO:root:current train perplexity3.712296724319458
INFO:root:current mean train loss 1664.369440858057
INFO:root:current train perplexity3.715001106262207
INFO:root:current mean train loss 1665.4437015952403
INFO:root:current train perplexity3.7161808013916016
INFO:root:current mean train loss 1665.367579592512
INFO:root:current train perplexity3.7173237800598145
INFO:root:current mean train loss 1664.4643475626417
INFO:root:current train perplexity3.714948892593384

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.51s/it]
INFO:root:final mean train loss: 1664.2521639933084
INFO:root:final train perplexity: 3.715559720993042
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.56s/it]
INFO:root:eval mean loss: 3208.6473538968658
INFO:root:eval perplexity: 13.914466857910156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/44
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [3:39:55<4:40:45, 300.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1648.2383669589428
INFO:root:current train perplexity3.6826589107513428
INFO:root:current mean train loss 1634.8545170998086
INFO:root:current train perplexity3.6583542823791504
INFO:root:current mean train loss 1646.1991767419977
INFO:root:current train perplexity3.6619322299957275
INFO:root:current mean train loss 1653.3472963712402
INFO:root:current train perplexity3.6835317611694336
INFO:root:current mean train loss 1654.2438689024923
INFO:root:current train perplexity3.685016632080078
INFO:root:current mean train loss 1655.2014954617516
INFO:root:current train perplexity3.6884279251098633
INFO:root:current mean train loss 1654.9221987599014
INFO:root:current train perplexity3.6892402172088623
INFO:root:current mean train loss 1655.0265650819424
INFO:root:current train perplexity3.6829121112823486
INFO:root:current mean train loss 1657.8281052554512
INFO:root:current train perplexity3.6894984245300293
INFO:root:current mean train loss 1657.8099046846125
INFO:root:current train perplexity3.687424659729004
INFO:root:current mean train loss 1657.6120226549442
INFO:root:current train perplexity3.6914291381835938
INFO:root:current mean train loss 1659.1576695063889
INFO:root:current train perplexity3.6937203407287598
INFO:root:current mean train loss 1657.5475355697424
INFO:root:current train perplexity3.6925148963928223
INFO:root:current mean train loss 1656.397914147324
INFO:root:current train perplexity3.691438913345337
INFO:root:current mean train loss 1657.1761049430124
INFO:root:current train perplexity3.6923983097076416
INFO:root:current mean train loss 1658.4612307212549
INFO:root:current train perplexity3.697549343109131
INFO:root:current mean train loss 1657.9087630771621
INFO:root:current train perplexity3.697138547897339
INFO:root:current mean train loss 1657.5327158918637
INFO:root:current train perplexity3.6953861713409424
INFO:root:current mean train loss 1658.1075410373028
INFO:root:current train perplexity3.6970622539520264
INFO:root:current mean train loss 1659.1511014165424
INFO:root:current train perplexity3.6991262435913086

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.30s/it]
INFO:root:final mean train loss: 1658.7197021238142
INFO:root:final train perplexity: 3.6993837356567383
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it]
INFO:root:eval mean loss: 3209.0546244486673
INFO:root:eval perplexity: 13.919121742248535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/45
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [3:44:55<4:35:36, 300.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1645.7362422943115
INFO:root:current train perplexity3.660250663757324
INFO:root:current mean train loss 1656.995836955745
INFO:root:current train perplexity3.6810142993927
INFO:root:current mean train loss 1656.0913691665187
INFO:root:current train perplexity3.685699224472046
INFO:root:current mean train loss 1656.7036437988281
INFO:root:current train perplexity3.6978647708892822
INFO:root:current mean train loss 1655.844271955819
INFO:root:current train perplexity3.6912708282470703
INFO:root:current mean train loss 1654.6496601510555
INFO:root:current train perplexity3.688483238220215
INFO:root:current mean train loss 1651.2608252835562
INFO:root:current train perplexity3.68114972114563
INFO:root:current mean train loss 1650.7945801100807
INFO:root:current train perplexity3.681999444961548
INFO:root:current mean train loss 1652.9188488147877
INFO:root:current train perplexity3.6849353313446045
INFO:root:current mean train loss 1653.8268770716497
INFO:root:current train perplexity3.686194658279419
INFO:root:current mean train loss 1652.289221512644
INFO:root:current train perplexity3.684790849685669
INFO:root:current mean train loss 1653.3149837742967
INFO:root:current train perplexity3.6840450763702393
INFO:root:current mean train loss 1654.0487659309483
INFO:root:current train perplexity3.6839616298675537
INFO:root:current mean train loss 1655.221303542688
INFO:root:current train perplexity3.684515953063965
INFO:root:current mean train loss 1655.9781745952334
INFO:root:current train perplexity3.6844210624694824
INFO:root:current mean train loss 1655.5984437752259
INFO:root:current train perplexity3.6838786602020264
INFO:root:current mean train loss 1654.6948262728179
INFO:root:current train perplexity3.685222625732422
INFO:root:current mean train loss 1654.4315474806458
INFO:root:current train perplexity3.6842005252838135
INFO:root:current mean train loss 1654.2302332538393
INFO:root:current train perplexity3.68508243560791
INFO:root:current mean train loss 1654.2546514755838
INFO:root:current train perplexity3.684685468673706

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.44s/it]
INFO:root:final mean train loss: 1653.64430619248
INFO:root:final train perplexity: 3.684605360031128
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.44s/it]
INFO:root:eval mean loss: 3209.954281185482
INFO:root:eval perplexity: 13.929400444030762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/46
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [3:49:56<4:30:46, 300.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1658.2911813994986
INFO:root:current train perplexity3.681969165802002
INFO:root:current mean train loss 1654.9843318370165
INFO:root:current train perplexity3.6648881435394287
INFO:root:current mean train loss 1653.4724325268294
INFO:root:current train perplexity3.661130666732788
INFO:root:current mean train loss 1651.9873357657686
INFO:root:current train perplexity3.6565001010894775
INFO:root:current mean train loss 1646.316059072895
INFO:root:current train perplexity3.650963068008423
INFO:root:current mean train loss 1646.9697656418084
INFO:root:current train perplexity3.6534087657928467
INFO:root:current mean train loss 1648.0972323200601
INFO:root:current train perplexity3.66054630279541
INFO:root:current mean train loss 1649.6062066423756
INFO:root:current train perplexity3.6620311737060547
INFO:root:current mean train loss 1652.4758864715611
INFO:root:current train perplexity3.665295124053955
INFO:root:current mean train loss 1649.6303148493246
INFO:root:current train perplexity3.662848472595215
INFO:root:current mean train loss 1649.1996222256953
INFO:root:current train perplexity3.662172794342041
INFO:root:current mean train loss 1649.6651367394225
INFO:root:current train perplexity3.663551092147827
INFO:root:current mean train loss 1650.448777829363
INFO:root:current train perplexity3.667701482772827
INFO:root:current mean train loss 1650.1197250775026
INFO:root:current train perplexity3.668120861053467
INFO:root:current mean train loss 1649.1864365623417
INFO:root:current train perplexity3.667375326156616
INFO:root:current mean train loss 1647.9484076502954
INFO:root:current train perplexity3.6653435230255127
INFO:root:current mean train loss 1648.34315206606
INFO:root:current train perplexity3.664971351623535
INFO:root:current mean train loss 1648.2475049266784
INFO:root:current train perplexity3.665710210800171
INFO:root:current mean train loss 1647.206328680514
INFO:root:current train perplexity3.6649458408355713
INFO:root:current mean train loss 1647.7852103528442
INFO:root:current train perplexity3.6661579608917236

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.99s/it]
INFO:root:final mean train loss: 1647.2412495961769
INFO:root:final train perplexity: 3.666045665740967
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.99s/it]
INFO:root:eval mean loss: 3211.6838972761825
INFO:root:eval perplexity: 13.94918441772461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/47
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [3:54:58<4:25:54, 301.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1636.2511534398916
INFO:root:current train perplexity3.607651710510254
INFO:root:current mean train loss 1637.6195956143465
INFO:root:current train perplexity3.619269847869873
INFO:root:current mean train loss 1636.587096348705
INFO:root:current train perplexity3.633906126022339
INFO:root:current mean train loss 1634.4138818482058
INFO:root:current train perplexity3.63281512260437
INFO:root:current mean train loss 1635.6319732053212
INFO:root:current train perplexity3.6323342323303223
INFO:root:current mean train loss 1635.2171167482102
INFO:root:current train perplexity3.6310744285583496
INFO:root:current mean train loss 1639.1943924256245
INFO:root:current train perplexity3.640117645263672
INFO:root:current mean train loss 1639.9074081382655
INFO:root:current train perplexity3.644253730773926
INFO:root:current mean train loss 1640.6791101808271
INFO:root:current train perplexity3.646578311920166
INFO:root:current mean train loss 1639.5208467472053
INFO:root:current train perplexity3.6448469161987305
INFO:root:current mean train loss 1641.4817656081013
INFO:root:current train perplexity3.6452412605285645
INFO:root:current mean train loss 1641.9119740583265
INFO:root:current train perplexity3.6469273567199707
INFO:root:current mean train loss 1639.9399307791734
INFO:root:current train perplexity3.6440892219543457
INFO:root:current mean train loss 1640.695188246742
INFO:root:current train perplexity3.6468608379364014
INFO:root:current mean train loss 1640.8071955641376
INFO:root:current train perplexity3.648367166519165
INFO:root:current mean train loss 1641.4837987181243
INFO:root:current train perplexity3.6510941982269287
INFO:root:current mean train loss 1642.042499232208
INFO:root:current train perplexity3.6522676944732666
INFO:root:current mean train loss 1641.9463471782883
INFO:root:current train perplexity3.6512765884399414
INFO:root:current mean train loss 1642.099396684524
INFO:root:current train perplexity3.651007652282715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.43s/it]
INFO:root:final mean train loss: 1642.1654108136938
INFO:root:final train perplexity: 3.651399850845337
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.58s/it]
INFO:root:eval mean loss: 3228.3311455987237
INFO:root:eval perplexity: 14.141039848327637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/48
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [3:59:59<4:21:00, 301.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1572.7444580078125
INFO:root:current train perplexity3.4417524337768555
INFO:root:current mean train loss 1631.2046959918478
INFO:root:current train perplexity3.616046190261841
INFO:root:current mean train loss 1638.1280949082486
INFO:root:current train perplexity3.6186511516571045
INFO:root:current mean train loss 1635.5074129619295
INFO:root:current train perplexity3.6129660606384277
INFO:root:current mean train loss 1639.9147616834525
INFO:root:current train perplexity3.624809980392456
INFO:root:current mean train loss 1635.0751690021996
INFO:root:current train perplexity3.6151680946350098
INFO:root:current mean train loss 1632.020466526931
INFO:root:current train perplexity3.614262342453003
INFO:root:current mean train loss 1633.866488028573
INFO:root:current train perplexity3.6214709281921387
INFO:root:current mean train loss 1633.4475099154045
INFO:root:current train perplexity3.6243441104888916
INFO:root:current mean train loss 1632.2623637882086
INFO:root:current train perplexity3.6245110034942627
INFO:root:current mean train loss 1634.0717774640163
INFO:root:current train perplexity3.6274938583374023
INFO:root:current mean train loss 1635.2725752347253
INFO:root:current train perplexity3.6264190673828125
INFO:root:current mean train loss 1636.418546248071
INFO:root:current train perplexity3.6271419525146484
INFO:root:current mean train loss 1636.5197750193086
INFO:root:current train perplexity3.6281232833862305
INFO:root:current mean train loss 1635.9460581209971
INFO:root:current train perplexity3.6294710636138916
INFO:root:current mean train loss 1635.4797001501909
INFO:root:current train perplexity3.6312060356140137
INFO:root:current mean train loss 1636.388057744171
INFO:root:current train perplexity3.6325907707214355
INFO:root:current mean train loss 1636.1165464707087
INFO:root:current train perplexity3.633364677429199
INFO:root:current mean train loss 1636.871910040569
INFO:root:current train perplexity3.634347438812256
INFO:root:current mean train loss 1636.9192736593302
INFO:root:current train perplexity3.636138916015625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.84s/it]
INFO:root:final mean train loss: 1637.3257951375756
INFO:root:final train perplexity: 3.6374895572662354
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.55s/it]
INFO:root:eval mean loss: 3226.300877293309
INFO:root:eval perplexity: 14.117500305175781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/49
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [4:05:00<4:15:54, 301.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1653.5329055786133
INFO:root:current train perplexity3.6612730026245117
INFO:root:current mean train loss 1630.5958113236861
INFO:root:current train perplexity3.588374137878418
INFO:root:current mean train loss 1626.2442600644868
INFO:root:current train perplexity3.584738254547119
INFO:root:current mean train loss 1628.6518547333867
INFO:root:current train perplexity3.596384048461914
INFO:root:current mean train loss 1630.731923703794
INFO:root:current train perplexity3.604356527328491
INFO:root:current mean train loss 1628.1570179874736
INFO:root:current train perplexity3.607174873352051
INFO:root:current mean train loss 1628.5531898208812
INFO:root:current train perplexity3.610593318939209
INFO:root:current mean train loss 1629.449254103697
INFO:root:current train perplexity3.6126551628112793
INFO:root:current mean train loss 1629.2333170083853
INFO:root:current train perplexity3.613400459289551
INFO:root:current mean train loss 1629.7462518389134
INFO:root:current train perplexity3.615535259246826
INFO:root:current mean train loss 1628.8401427749516
INFO:root:current train perplexity3.6138923168182373
INFO:root:current mean train loss 1630.630556679446
INFO:root:current train perplexity3.6160318851470947
INFO:root:current mean train loss 1631.270715490564
INFO:root:current train perplexity3.617039442062378
INFO:root:current mean train loss 1630.021338752082
INFO:root:current train perplexity3.6147801876068115
INFO:root:current mean train loss 1629.4789610282003
INFO:root:current train perplexity3.614464521408081
INFO:root:current mean train loss 1629.446383643088
INFO:root:current train perplexity3.613924503326416
INFO:root:current mean train loss 1630.3468792485255
INFO:root:current train perplexity3.6152780055999756
INFO:root:current mean train loss 1629.9957736325869
INFO:root:current train perplexity3.616201639175415
INFO:root:current mean train loss 1631.3325403871495
INFO:root:current train perplexity3.618561029434204
INFO:root:current mean train loss 1631.3736236761815
INFO:root:current train perplexity3.6201348304748535

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.24s/it]
INFO:root:final mean train loss: 1631.9239726333503
INFO:root:final train perplexity: 3.622025728225708
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.49s/it]
INFO:root:eval mean loss: 3229.0844799878005
INFO:root:eval perplexity: 14.149785041809082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/50
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [4:10:01<4:10:54, 301.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1603.8578304368623
INFO:root:current train perplexity3.564814329147339
INFO:root:current mean train loss 1616.4543006436136
INFO:root:current train perplexity3.5584940910339355
INFO:root:current mean train loss 1617.8087839639809
INFO:root:current train perplexity3.5758957862854004
INFO:root:current mean train loss 1619.3816040388833
INFO:root:current train perplexity3.5832693576812744
INFO:root:current mean train loss 1623.047526404162
INFO:root:current train perplexity3.583333969116211
INFO:root:current mean train loss 1623.249109042364
INFO:root:current train perplexity3.5853497982025146
INFO:root:current mean train loss 1621.7436211208349
INFO:root:current train perplexity3.587207794189453
INFO:root:current mean train loss 1624.1954163168077
INFO:root:current train perplexity3.592794418334961
INFO:root:current mean train loss 1624.0360392108823
INFO:root:current train perplexity3.592796564102173
INFO:root:current mean train loss 1626.0596262667527
INFO:root:current train perplexity3.5980637073516846
INFO:root:current mean train loss 1626.4777138476377
INFO:root:current train perplexity3.601384401321411
INFO:root:current mean train loss 1625.8486881637905
INFO:root:current train perplexity3.6025900840759277
INFO:root:current mean train loss 1626.2027600596102
INFO:root:current train perplexity3.6055166721343994
INFO:root:current mean train loss 1624.9498214099565
INFO:root:current train perplexity3.60408878326416
INFO:root:current mean train loss 1624.8351841854835
INFO:root:current train perplexity3.6044235229492188
INFO:root:current mean train loss 1624.7046574591975
INFO:root:current train perplexity3.604273557662964
INFO:root:current mean train loss 1624.9854921395306
INFO:root:current train perplexity3.604825258255005
INFO:root:current mean train loss 1625.3017595573588
INFO:root:current train perplexity3.6057205200195312
INFO:root:current mean train loss 1626.1334491933985
INFO:root:current train perplexity3.6066205501556396
INFO:root:current mean train loss 1627.7380315351022
INFO:root:current train perplexity3.6088995933532715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.17s/it]
INFO:root:final mean train loss: 1627.1311283544405
INFO:root:final train perplexity: 3.6083602905273438
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.85s/it]
INFO:root:eval mean loss: 3231.7243740322356
INFO:root:eval perplexity: 14.18046760559082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/51
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [4:15:01<4:05:29, 300.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1621.4933360706675
INFO:root:current train perplexity3.5677707195281982
INFO:root:current mean train loss 1613.451707219503
INFO:root:current train perplexity3.5720510482788086
INFO:root:current mean train loss 1616.9798606929921
INFO:root:current train perplexity3.5654876232147217
INFO:root:current mean train loss 1617.1282435349428
INFO:root:current train perplexity3.578199625015259
INFO:root:current mean train loss 1617.4282003902058
INFO:root:current train perplexity3.5772757530212402
INFO:root:current mean train loss 1622.8539387733272
INFO:root:current train perplexity3.5807735919952393
INFO:root:current mean train loss 1623.5906945764123
INFO:root:current train perplexity3.5822908878326416
INFO:root:current mean train loss 1621.0829007220952
INFO:root:current train perplexity3.5809106826782227
INFO:root:current mean train loss 1623.1360786561327
INFO:root:current train perplexity3.585786819458008
INFO:root:current mean train loss 1621.8687907153776
INFO:root:current train perplexity3.584394693374634
INFO:root:current mean train loss 1622.106767092592
INFO:root:current train perplexity3.5896804332733154
INFO:root:current mean train loss 1621.30713372206
INFO:root:current train perplexity3.588538408279419
INFO:root:current mean train loss 1622.281467720984
INFO:root:current train perplexity3.590384006500244
INFO:root:current mean train loss 1621.436289484295
INFO:root:current train perplexity3.591369867324829
INFO:root:current mean train loss 1620.8707873252047
INFO:root:current train perplexity3.5913736820220947
INFO:root:current mean train loss 1622.129598995126
INFO:root:current train perplexity3.5938198566436768
INFO:root:current mean train loss 1621.976969376618
INFO:root:current train perplexity3.5936036109924316
INFO:root:current mean train loss 1622.955091880375
INFO:root:current train perplexity3.5946688652038574
INFO:root:current mean train loss 1622.8176016362918
INFO:root:current train perplexity3.595073699951172
INFO:root:current mean train loss 1622.8314874596658
INFO:root:current train perplexity3.5949246883392334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.04s/it]
INFO:root:final mean train loss: 1622.7926474766964
INFO:root:final train perplexity: 3.5960352420806885
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.51s/it]
INFO:root:eval mean loss: 3244.6592405393676
INFO:root:eval perplexity: 14.331782341003418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/52
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [4:20:02<4:00:34, 300.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1613.838323018637
INFO:root:current train perplexity3.578601837158203
INFO:root:current mean train loss 1614.6553034547899
INFO:root:current train perplexity3.5808401107788086
INFO:root:current mean train loss 1606.8710924559684
INFO:root:current train perplexity3.5588529109954834
INFO:root:current mean train loss 1608.4291829639565
INFO:root:current train perplexity3.5645558834075928
INFO:root:current mean train loss 1607.5778995616588
INFO:root:current train perplexity3.5609331130981445
INFO:root:current mean train loss 1608.5018398487753
INFO:root:current train perplexity3.567661762237549
INFO:root:current mean train loss 1611.8909865640442
INFO:root:current train perplexity3.5721638202667236
INFO:root:current mean train loss 1611.9207239845246
INFO:root:current train perplexity3.5693485736846924
INFO:root:current mean train loss 1613.3753724319613
INFO:root:current train perplexity3.5700042247772217
INFO:root:current mean train loss 1614.0522510610058
INFO:root:current train perplexity3.572780132293701
INFO:root:current mean train loss 1613.7599252293976
INFO:root:current train perplexity3.571972608566284
INFO:root:current mean train loss 1614.578309188933
INFO:root:current train perplexity3.5762405395507812
INFO:root:current mean train loss 1613.1300072614233
INFO:root:current train perplexity3.575502395629883
INFO:root:current mean train loss 1614.4564705032933
INFO:root:current train perplexity3.5779523849487305
INFO:root:current mean train loss 1616.0316055925489
INFO:root:current train perplexity3.5792713165283203
INFO:root:current mean train loss 1617.136797559766
INFO:root:current train perplexity3.5800275802612305
INFO:root:current mean train loss 1617.2121187460543
INFO:root:current train perplexity3.579165458679199
INFO:root:current mean train loss 1618.2265006775142
INFO:root:current train perplexity3.5813896656036377
INFO:root:current mean train loss 1618.5116702589783
INFO:root:current train perplexity3.5825910568237305
INFO:root:current mean train loss 1618.3132185712343
INFO:root:current train perplexity3.5833544731140137

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.94s/it]
INFO:root:final mean train loss: 1618.3132185712343
INFO:root:final train perplexity: 3.5833544731140137
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.31s/it]
INFO:root:eval mean loss: 3248.443115234375
INFO:root:eval perplexity: 14.376354217529297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/53
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [4:25:03<3:55:33, 300.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1608.9646948242187
INFO:root:current train perplexity3.612046003341675
INFO:root:current mean train loss 1621.905025024414
INFO:root:current train perplexity3.5944368839263916
INFO:root:current mean train loss 1610.217792154948
INFO:root:current train perplexity3.5748860836029053
INFO:root:current mean train loss 1609.6423098754883
INFO:root:current train perplexity3.5687685012817383
INFO:root:current mean train loss 1609.0653852539062
INFO:root:current train perplexity3.5660898685455322
INFO:root:current mean train loss 1614.10715616862
INFO:root:current train perplexity3.573178768157959
INFO:root:current mean train loss 1611.952842843192
INFO:root:current train perplexity3.5664117336273193
INFO:root:current mean train loss 1611.470549621582
INFO:root:current train perplexity3.5673930644989014
INFO:root:current mean train loss 1612.4647488064236
INFO:root:current train perplexity3.568577527999878
INFO:root:current mean train loss 1612.0449576416015
INFO:root:current train perplexity3.568364381790161
INFO:root:current mean train loss 1614.7797042569248
INFO:root:current train perplexity3.5722451210021973
INFO:root:current mean train loss 1615.0551473999024
INFO:root:current train perplexity3.572343111038208
INFO:root:current mean train loss 1615.3929355093148
INFO:root:current train perplexity3.5713741779327393
INFO:root:current mean train loss 1613.0414850725447
INFO:root:current train perplexity3.5683343410491943
INFO:root:current mean train loss 1612.988864827474
INFO:root:current train perplexity3.568338632583618
INFO:root:current mean train loss 1613.6169696044922
INFO:root:current train perplexity3.569596529006958
INFO:root:current mean train loss 1614.3057404641545
INFO:root:current train perplexity3.5697226524353027
INFO:root:current mean train loss 1615.822579820421
INFO:root:current train perplexity3.572439432144165
INFO:root:current mean train loss 1614.4995518092105
INFO:root:current train perplexity3.570988416671753

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.96s/it]
INFO:root:final mean train loss: 1613.7940416514002
INFO:root:final train perplexity: 3.5706048011779785
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it]
INFO:root:eval mean loss: 3239.6404922989395
INFO:root:eval perplexity: 14.272882461547852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/54
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [4:30:02<3:50:22, 300.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1598.096155503217
INFO:root:current train perplexity3.569087266921997
INFO:root:current mean train loss 1595.3329243456196
INFO:root:current train perplexity3.5353848934173584
INFO:root:current mean train loss 1601.3343224591374
INFO:root:current train perplexity3.53434681892395
INFO:root:current mean train loss 1600.7565105450267
INFO:root:current train perplexity3.5396132469177246
INFO:root:current mean train loss 1607.259802509555
INFO:root:current train perplexity3.553060293197632
INFO:root:current mean train loss 1605.5198927386816
INFO:root:current train perplexity3.5472042560577393
INFO:root:current mean train loss 1604.754980350043
INFO:root:current train perplexity3.5464093685150146
INFO:root:current mean train loss 1605.0062083905377
INFO:root:current train perplexity3.5511322021484375
INFO:root:current mean train loss 1605.3332453789587
INFO:root:current train perplexity3.551793098449707
INFO:root:current mean train loss 1605.8473684462751
INFO:root:current train perplexity3.5527782440185547
INFO:root:current mean train loss 1606.2607104996312
INFO:root:current train perplexity3.5540781021118164
INFO:root:current mean train loss 1606.4886442916993
INFO:root:current train perplexity3.5555689334869385
INFO:root:current mean train loss 1606.9036227299134
INFO:root:current train perplexity3.557253360748291
INFO:root:current mean train loss 1606.0853345634907
INFO:root:current train perplexity3.556981086730957
INFO:root:current mean train loss 1607.199724863681
INFO:root:current train perplexity3.5580711364746094
INFO:root:current mean train loss 1607.1260797227774
INFO:root:current train perplexity3.5561327934265137
INFO:root:current mean train loss 1607.8184201459349
INFO:root:current train perplexity3.557818651199341
INFO:root:current mean train loss 1607.9677983918855
INFO:root:current train perplexity3.5577683448791504
INFO:root:current mean train loss 1608.3327525867887
INFO:root:current train perplexity3.5572376251220703
INFO:root:current mean train loss 1608.4590497084066
INFO:root:current train perplexity3.5554161071777344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.37s/it]
INFO:root:final mean train loss: 1608.7544790509369
INFO:root:final train perplexity: 3.5564422607421875
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.49s/it]
INFO:root:eval mean loss: 3249.7579444679054
INFO:root:eval perplexity: 14.391876220703125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/55
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [4:35:03<3:45:19, 300.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1585.2816557042738
INFO:root:current train perplexity3.516359329223633
INFO:root:current mean train loss 1598.2790800635494
INFO:root:current train perplexity3.527480125427246
INFO:root:current mean train loss 1605.809807671441
INFO:root:current train perplexity3.5329766273498535
INFO:root:current mean train loss 1608.3038487234514
INFO:root:current train perplexity3.5398781299591064
INFO:root:current mean train loss 1608.5456537343389
INFO:root:current train perplexity3.5436747074127197
INFO:root:current mean train loss 1608.10029882081
INFO:root:current train perplexity3.542983293533325
INFO:root:current mean train loss 1605.504612678985
INFO:root:current train perplexity3.537490129470825
INFO:root:current mean train loss 1605.078847277067
INFO:root:current train perplexity3.5372021198272705
INFO:root:current mean train loss 1604.3514243292866
INFO:root:current train perplexity3.5376689434051514
INFO:root:current mean train loss 1601.928280685392
INFO:root:current train perplexity3.5362417697906494
INFO:root:current mean train loss 1601.2162038777276
INFO:root:current train perplexity3.5384438037872314
INFO:root:current mean train loss 1601.141429652192
INFO:root:current train perplexity3.537369966506958
INFO:root:current mean train loss 1602.120275067742
INFO:root:current train perplexity3.540605068206787
INFO:root:current mean train loss 1602.039584181298
INFO:root:current train perplexity3.540909767150879
INFO:root:current mean train loss 1602.1193122384936
INFO:root:current train perplexity3.5422894954681396
INFO:root:current mean train loss 1603.0609547840104
INFO:root:current train perplexity3.5427379608154297
INFO:root:current mean train loss 1603.818032683766
INFO:root:current train perplexity3.544307231903076
INFO:root:current mean train loss 1604.8733514171984
INFO:root:current train perplexity3.546830177307129
INFO:root:current mean train loss 1604.6471013825228
INFO:root:current train perplexity3.545703887939453
INFO:root:current mean train loss 1605.3084861968393
INFO:root:current train perplexity3.545584201812744

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.65s/it]
INFO:root:final mean train loss: 1604.9497319008447
INFO:root:final train perplexity: 3.5457863807678223
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.42s/it]
INFO:root:eval mean loss: 3256.671091990428
INFO:root:eval perplexity: 14.473745346069336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/56
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [4:40:03<3:40:20, 300.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1602.5438758999694
INFO:root:current train perplexity3.5346200466156006
INFO:root:current mean train loss 1599.5834095935948
INFO:root:current train perplexity3.5241034030914307
INFO:root:current mean train loss 1597.7883582856075
INFO:root:current train perplexity3.5283913612365723
INFO:root:current mean train loss 1597.0239692535836
INFO:root:current train perplexity3.521793842315674
INFO:root:current mean train loss 1596.6243471538942
INFO:root:current train perplexity3.520859956741333
INFO:root:current mean train loss 1597.9228677351548
INFO:root:current train perplexity3.521468162536621
INFO:root:current mean train loss 1599.2996511151714
INFO:root:current train perplexity3.5251033306121826
INFO:root:current mean train loss 1597.3826086702106
INFO:root:current train perplexity3.524472951889038
INFO:root:current mean train loss 1596.832670864011
INFO:root:current train perplexity3.5244524478912354
INFO:root:current mean train loss 1596.7043047563009
INFO:root:current train perplexity3.5256853103637695
INFO:root:current mean train loss 1597.9829046973493
INFO:root:current train perplexity3.5287835597991943
INFO:root:current mean train loss 1598.9177026558089
INFO:root:current train perplexity3.5285167694091797
INFO:root:current mean train loss 1601.0838019037894
INFO:root:current train perplexity3.5316827297210693
INFO:root:current mean train loss 1602.1274419483832
INFO:root:current train perplexity3.5338733196258545
INFO:root:current mean train loss 1602.0217658686358
INFO:root:current train perplexity3.5343616008758545
INFO:root:current mean train loss 1602.1250458058812
INFO:root:current train perplexity3.535431146621704
INFO:root:current mean train loss 1601.8313137634389
INFO:root:current train perplexity3.5350351333618164
INFO:root:current mean train loss 1601.7737326020176
INFO:root:current train perplexity3.5353035926818848
INFO:root:current mean train loss 1602.4438278717585
INFO:root:current train perplexity3.5362186431884766
INFO:root:current mean train loss 1601.6480086584204
INFO:root:current train perplexity3.5352630615234375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.77s/it]
INFO:root:final mean train loss: 1600.98757252811
INFO:root:final train perplexity: 3.5347235202789307
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.56s/it]
INFO:root:eval mean loss: 3263.7211877404748
INFO:root:eval perplexity: 14.557718276977539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/57
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [4:45:04<3:35:24, 300.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1579.967062557445
INFO:root:current train perplexity3.4668054580688477
INFO:root:current mean train loss 1576.5067145937965
INFO:root:current train perplexity3.4800562858581543
INFO:root:current mean train loss 1587.7221834552822
INFO:root:current train perplexity3.493880271911621
INFO:root:current mean train loss 1585.5355655836022
INFO:root:current train perplexity3.4942522048950195
INFO:root:current mean train loss 1588.1800198025173
INFO:root:current train perplexity3.4976532459259033
INFO:root:current mean train loss 1589.8208184040768
INFO:root:current train perplexity3.5023574829101562
INFO:root:current mean train loss 1589.058772469709
INFO:root:current train perplexity3.5008339881896973
INFO:root:current mean train loss 1589.3001818656921
INFO:root:current train perplexity3.5014562606811523
INFO:root:current mean train loss 1590.8448763377105
INFO:root:current train perplexity3.5030715465545654
INFO:root:current mean train loss 1593.4295413434997
INFO:root:current train perplexity3.5085573196411133
INFO:root:current mean train loss 1592.1616244083932
INFO:root:current train perplexity3.508537530899048
INFO:root:current mean train loss 1592.3228933255966
INFO:root:current train perplexity3.510808229446411
INFO:root:current mean train loss 1594.3233565562155
INFO:root:current train perplexity3.5141117572784424
INFO:root:current mean train loss 1593.0752930222895
INFO:root:current train perplexity3.5146636962890625
INFO:root:current mean train loss 1593.8855673142934
INFO:root:current train perplexity3.5180511474609375
INFO:root:current mean train loss 1594.6110254404496
INFO:root:current train perplexity3.518780469894409
INFO:root:current mean train loss 1595.132481197659
INFO:root:current train perplexity3.5193443298339844
INFO:root:current mean train loss 1595.6766182049366
INFO:root:current train perplexity3.519782781600952
INFO:root:current mean train loss 1596.11260430869
INFO:root:current train perplexity3.520634651184082
INFO:root:current mean train loss 1597.1384122274756
INFO:root:current train perplexity3.523343801498413

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.95s/it]
INFO:root:final mean train loss: 1596.8644745596357
INFO:root:final train perplexity: 3.5232484340667725
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.97s/it]
INFO:root:eval mean loss: 3258.5656041783973
INFO:root:eval perplexity: 14.496262550354004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/58
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [4:50:05<3:30:33, 300.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1589.6817224839153
INFO:root:current train perplexity3.509789228439331
INFO:root:current mean train loss 1588.241623997044
INFO:root:current train perplexity3.4979326725006104
INFO:root:current mean train loss 1582.3812324390076
INFO:root:current train perplexity3.481759786605835
INFO:root:current mean train loss 1581.1616283862622
INFO:root:current train perplexity3.4788691997528076
INFO:root:current mean train loss 1583.4514588031573
INFO:root:current train perplexity3.4831483364105225
INFO:root:current mean train loss 1583.8982405181623
INFO:root:current train perplexity3.485539197921753
INFO:root:current mean train loss 1581.5065543738594
INFO:root:current train perplexity3.4857075214385986
INFO:root:current mean train loss 1583.5326042807026
INFO:root:current train perplexity3.4872384071350098
INFO:root:current mean train loss 1585.5137331170552
INFO:root:current train perplexity3.493076801300049
INFO:root:current mean train loss 1585.8780072672114
INFO:root:current train perplexity3.495792865753174
INFO:root:current mean train loss 1586.8243758100518
INFO:root:current train perplexity3.4960646629333496
INFO:root:current mean train loss 1588.4956788139505
INFO:root:current train perplexity3.499870538711548
INFO:root:current mean train loss 1587.779726353508
INFO:root:current train perplexity3.5005998611450195
INFO:root:current mean train loss 1588.8970369084218
INFO:root:current train perplexity3.5011541843414307
INFO:root:current mean train loss 1589.2052900423505
INFO:root:current train perplexity3.503145933151245
INFO:root:current mean train loss 1590.1026131518631
INFO:root:current train perplexity3.5076966285705566
INFO:root:current mean train loss 1589.9739194060646
INFO:root:current train perplexity3.508025646209717
INFO:root:current mean train loss 1591.885994397759
INFO:root:current train perplexity3.510807752609253
INFO:root:current mean train loss 1592.511989895039
INFO:root:current train perplexity3.51186466217041

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.21s/it]
INFO:root:final mean train loss: 1593.470380589749
INFO:root:final train perplexity: 3.513829469680786
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.15s/it]
INFO:root:eval mean loss: 3270.627047701999
INFO:root:eval perplexity: 14.640447616577148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/59
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [4:55:07<3:25:45, 301.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1656.1470947265625
INFO:root:current train perplexity3.663539409637451
INFO:root:current mean train loss 1589.9978170955883
INFO:root:current train perplexity3.4816224575042725
INFO:root:current mean train loss 1580.2905914004486
INFO:root:current train perplexity3.4733827114105225
INFO:root:current mean train loss 1577.41262190863
INFO:root:current train perplexity3.4656145572662354
INFO:root:current mean train loss 1580.7438494174635
INFO:root:current train perplexity3.473695755004883
INFO:root:current mean train loss 1584.3764422291304
INFO:root:current train perplexity3.4797134399414062
INFO:root:current mean train loss 1583.0495974518533
INFO:root:current train perplexity3.4798073768615723
INFO:root:current mean train loss 1586.9624774639424
INFO:root:current train perplexity3.4871065616607666
INFO:root:current mean train loss 1586.6577405667958
INFO:root:current train perplexity3.4926745891571045
INFO:root:current mean train loss 1585.545216224146
INFO:root:current train perplexity3.492863655090332
INFO:root:current mean train loss 1585.558736043538
INFO:root:current train perplexity3.494595766067505
INFO:root:current mean train loss 1586.5733000102796
INFO:root:current train perplexity3.4953932762145996
INFO:root:current mean train loss 1586.285645242142
INFO:root:current train perplexity3.496001720428467
INFO:root:current mean train loss 1586.6480185044343
INFO:root:current train perplexity3.4972550868988037
INFO:root:current mean train loss 1586.8403542337676
INFO:root:current train perplexity3.497995615005493
INFO:root:current mean train loss 1588.5174919768433
INFO:root:current train perplexity3.498494863510132
INFO:root:current mean train loss 1589.1464353792378
INFO:root:current train perplexity3.498965263366699
INFO:root:current mean train loss 1589.0175296411392
INFO:root:current train perplexity3.4997365474700928
INFO:root:current mean train loss 1589.0626366347506
INFO:root:current train perplexity3.4998512268066406
INFO:root:current mean train loss 1588.8780029168515
INFO:root:current train perplexity3.500515937805176

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.22s/it]
INFO:root:final mean train loss: 1588.8751779961212
INFO:root:final train perplexity: 3.5011186599731445
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.68s/it]
INFO:root:eval mean loss: 3266.0969172297296
INFO:root:eval perplexity: 14.586127281188965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/60
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [5:00:08<3:20:35, 300.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1554.1967516447369
INFO:root:current train perplexity3.47780442237854
INFO:root:current mean train loss 1572.0281407973346
INFO:root:current train perplexity3.476799726486206
INFO:root:current mean train loss 1584.0342042130421
INFO:root:current train perplexity3.4840657711029053
INFO:root:current mean train loss 1583.925473204227
INFO:root:current train perplexity3.4859228134155273
INFO:root:current mean train loss 1584.228843379419
INFO:root:current train perplexity3.4868104457855225
INFO:root:current mean train loss 1582.6730089132495
INFO:root:current train perplexity3.4888687133789062
INFO:root:current mean train loss 1581.6436844488337
INFO:root:current train perplexity3.4857215881347656
INFO:root:current mean train loss 1578.4976755707255
INFO:root:current train perplexity3.4814388751983643
INFO:root:current mean train loss 1578.3291149768202
INFO:root:current train perplexity3.4810986518859863
INFO:root:current mean train loss 1578.1744506968766
INFO:root:current train perplexity3.4788477420806885
INFO:root:current mean train loss 1580.7586062565167
INFO:root:current train perplexity3.481355667114258
INFO:root:current mean train loss 1580.8940943495518
INFO:root:current train perplexity3.483232259750366
INFO:root:current mean train loss 1581.37371781109
INFO:root:current train perplexity3.4831721782684326
INFO:root:current mean train loss 1580.5698165372974
INFO:root:current train perplexity3.481951951980591
INFO:root:current mean train loss 1582.020463939449
INFO:root:current train perplexity3.4853639602661133
INFO:root:current mean train loss 1582.1359221990208
INFO:root:current train perplexity3.485610008239746
INFO:root:current mean train loss 1582.2938160793217
INFO:root:current train perplexity3.4850943088531494
INFO:root:current mean train loss 1583.6765256019578
INFO:root:current train perplexity3.4866738319396973
INFO:root:current mean train loss 1584.4142768444628
INFO:root:current train perplexity3.4884984493255615
INFO:root:current mean train loss 1585.738098494394
INFO:root:current train perplexity3.490849018096924

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.84s/it]
INFO:root:final mean train loss: 1585.4211979806873
INFO:root:final train perplexity: 3.4915947914123535
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.17s/it]
INFO:root:eval mean loss: 3266.4821887317003
INFO:root:eval perplexity: 14.59073543548584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/61
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [5:05:09<3:15:41, 301.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1587.2542690700955
INFO:root:current train perplexity3.452787160873413
INFO:root:current mean train loss 1570.2286466710707
INFO:root:current train perplexity3.438866376876831
INFO:root:current mean train loss 1575.9369248212395
INFO:root:current train perplexity3.4572489261627197
INFO:root:current mean train loss 1577.9037105015345
INFO:root:current train perplexity3.4719388484954834
INFO:root:current mean train loss 1578.4298106902236
INFO:root:current train perplexity3.4711170196533203
INFO:root:current mean train loss 1581.2549274501516
INFO:root:current train perplexity3.4765803813934326
INFO:root:current mean train loss 1580.1187400577953
INFO:root:current train perplexity3.4756219387054443
INFO:root:current mean train loss 1581.343452785326
INFO:root:current train perplexity3.477755069732666
INFO:root:current mean train loss 1583.571155456835
INFO:root:current train perplexity3.4840192794799805
INFO:root:current mean train loss 1584.4548933241103
INFO:root:current train perplexity3.4858741760253906
INFO:root:current mean train loss 1582.963121215349
INFO:root:current train perplexity3.4820873737335205
INFO:root:current mean train loss 1582.9695647333708
INFO:root:current train perplexity3.4809584617614746
INFO:root:current mean train loss 1582.6133092985185
INFO:root:current train perplexity3.4799063205718994
INFO:root:current mean train loss 1583.0226540022982
INFO:root:current train perplexity3.4805965423583984
INFO:root:current mean train loss 1582.3158376369636
INFO:root:current train perplexity3.4809322357177734
INFO:root:current mean train loss 1582.3980121612549
INFO:root:current train perplexity3.4823360443115234
INFO:root:current mean train loss 1581.8582683833713
INFO:root:current train perplexity3.4817917346954346
INFO:root:current mean train loss 1582.159709947999
INFO:root:current train perplexity3.4821643829345703
INFO:root:current mean train loss 1582.284275096486
INFO:root:current train perplexity3.482052803039551
INFO:root:current mean train loss 1582.5557316551524
INFO:root:current train perplexity3.4825198650360107

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.75s/it]
INFO:root:final mean train loss: 1582.175121590157
INFO:root:final train perplexity: 3.4826667308807373
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.51s/it]
INFO:root:eval mean loss: 3271.903079104495
INFO:root:eval perplexity: 14.65578556060791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/62
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [5:10:10<3:10:36, 300.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1578.8188545658904
INFO:root:current train perplexity3.4455413818359375
INFO:root:current mean train loss 1568.0546460120506
INFO:root:current train perplexity3.45357084274292
INFO:root:current mean train loss 1569.1282683964303
INFO:root:current train perplexity3.45117449760437
INFO:root:current mean train loss 1572.1784896202196
INFO:root:current train perplexity3.457862615585327
INFO:root:current mean train loss 1572.1108077767142
INFO:root:current train perplexity3.458418607711792
INFO:root:current mean train loss 1574.1792142292043
INFO:root:current train perplexity3.462247610092163
INFO:root:current mean train loss 1574.0341716491794
INFO:root:current train perplexity3.4600236415863037
INFO:root:current mean train loss 1575.6859385375167
INFO:root:current train perplexity3.4639554023742676
INFO:root:current mean train loss 1577.419551370851
INFO:root:current train perplexity3.4652957916259766
INFO:root:current mean train loss 1577.4426309239327
INFO:root:current train perplexity3.4643585681915283
INFO:root:current mean train loss 1578.5488544402526
INFO:root:current train perplexity3.4665799140930176
INFO:root:current mean train loss 1578.4450261164827
INFO:root:current train perplexity3.468083620071411
INFO:root:current mean train loss 1577.8106989514229
INFO:root:current train perplexity3.468691825866699
INFO:root:current mean train loss 1577.9532923617367
INFO:root:current train perplexity3.468660354614258
INFO:root:current mean train loss 1578.752885832921
INFO:root:current train perplexity3.4706404209136963
INFO:root:current mean train loss 1579.672275010187
INFO:root:current train perplexity3.4734151363372803
INFO:root:current mean train loss 1579.1563748765266
INFO:root:current train perplexity3.473062753677368
INFO:root:current mean train loss 1578.8703402286928
INFO:root:current train perplexity3.4723498821258545
INFO:root:current mean train loss 1578.840311477587
INFO:root:current train perplexity3.4728362560272217
INFO:root:current mean train loss 1578.9260694559453
INFO:root:current train perplexity3.472349166870117

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.36s/it]
INFO:root:final mean train loss: 1578.352806287526
INFO:root:final train perplexity: 3.472184658050537
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.79s/it]
INFO:root:eval mean loss: 3272.061107005443
INFO:root:eval perplexity: 14.657687187194824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/63
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [5:15:11<3:05:31, 300.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1569.8623203822544
INFO:root:current train perplexity3.448777914047241
INFO:root:current mean train loss 1572.501237936581
INFO:root:current train perplexity3.4574801921844482
INFO:root:current mean train loss 1573.216694245515
INFO:root:current train perplexity3.453754186630249
INFO:root:current mean train loss 1570.0047798775338
INFO:root:current train perplexity3.446263551712036
INFO:root:current mean train loss 1572.374632490442
INFO:root:current train perplexity3.4565391540527344
INFO:root:current mean train loss 1571.4714603892544
INFO:root:current train perplexity3.459652900695801
INFO:root:current mean train loss 1572.8514216636545
INFO:root:current train perplexity3.4563608169555664
INFO:root:current mean train loss 1574.5992959555094
INFO:root:current train perplexity3.459850788116455
INFO:root:current mean train loss 1576.2633811512212
INFO:root:current train perplexity3.461740255355835
INFO:root:current mean train loss 1577.174732074541
INFO:root:current train perplexity3.4618303775787354
INFO:root:current mean train loss 1576.9490445431147
INFO:root:current train perplexity3.460956335067749
INFO:root:current mean train loss 1576.3111162234575
INFO:root:current train perplexity3.457850217819214
INFO:root:current mean train loss 1576.348774490957
INFO:root:current train perplexity3.456960439682007
INFO:root:current mean train loss 1575.844144278199
INFO:root:current train perplexity3.457395553588867
INFO:root:current mean train loss 1575.5849366064785
INFO:root:current train perplexity3.4582529067993164
INFO:root:current mean train loss 1575.0398156816034
INFO:root:current train perplexity3.457933187484741
INFO:root:current mean train loss 1575.2535637221652
INFO:root:current train perplexity3.459439992904663
INFO:root:current mean train loss 1575.6050264002913
INFO:root:current train perplexity3.4599609375
INFO:root:current mean train loss 1575.2408200513871
INFO:root:current train perplexity3.460512399673462
INFO:root:current mean train loss 1575.320676294317
INFO:root:current train perplexity3.4624180793762207

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.98s/it]
INFO:root:final mean train loss: 1574.8887253076934
INFO:root:final train perplexity: 3.462712049484253
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.99s/it]
INFO:root:eval mean loss: 3276.716529273414
INFO:root:eval perplexity: 14.713788986206055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/64
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [5:20:17<3:01:31, 302.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1571.6410978470726
INFO:root:current train perplexity3.4379875659942627
INFO:root:current mean train loss 1573.536624357662
INFO:root:current train perplexity3.449676275253296
INFO:root:current mean train loss 1573.6739068114384
INFO:root:current train perplexity3.4459238052368164
INFO:root:current mean train loss 1565.6159122279755
INFO:root:current train perplexity3.4408116340637207
INFO:root:current mean train loss 1564.5358377883567
INFO:root:current train perplexity3.441559076309204
INFO:root:current mean train loss 1563.553700539688
INFO:root:current train perplexity3.4408936500549316
INFO:root:current mean train loss 1563.7192803928426
INFO:root:current train perplexity3.4399430751800537
INFO:root:current mean train loss 1562.581608579604
INFO:root:current train perplexity3.4361772537231445
INFO:root:current mean train loss 1566.2516295767423
INFO:root:current train perplexity3.4405434131622314
INFO:root:current mean train loss 1568.2706368087877
INFO:root:current train perplexity3.4442243576049805
INFO:root:current mean train loss 1567.5650032836577
INFO:root:current train perplexity3.4425742626190186
INFO:root:current mean train loss 1569.1250089470238
INFO:root:current train perplexity3.447279691696167
INFO:root:current mean train loss 1569.0602789273444
INFO:root:current train perplexity3.4472460746765137
INFO:root:current mean train loss 1569.9746321696725
INFO:root:current train perplexity3.4492716789245605
INFO:root:current mean train loss 1571.1011131302014
INFO:root:current train perplexity3.450606346130371
INFO:root:current mean train loss 1572.022788535144
INFO:root:current train perplexity3.4530913829803467
INFO:root:current mean train loss 1571.7905748838775
INFO:root:current train perplexity3.4544315338134766
INFO:root:current mean train loss 1571.6379514757186
INFO:root:current train perplexity3.4535627365112305
INFO:root:current mean train loss 1571.840051987592
INFO:root:current train perplexity3.454058885574341

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.74s/it]
INFO:root:final mean train loss: 1572.2796474808824
INFO:root:final train perplexity: 3.4555933475494385
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.45s/it]
INFO:root:eval mean loss: 3281.183879680462
INFO:root:eval perplexity: 14.767820358276367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/65
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [5:25:18<2:56:08, 301.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1566.4166870117188
INFO:root:current train perplexity3.4838593006134033
INFO:root:current mean train loss 1557.7030404897837
INFO:root:current train perplexity3.4251086711883545
INFO:root:current mean train loss 1571.7920245002297
INFO:root:current train perplexity3.4501090049743652
INFO:root:current mean train loss 1566.618174101177
INFO:root:current train perplexity3.434948205947876
INFO:root:current mean train loss 1565.7498543616568
INFO:root:current train perplexity3.4347174167633057
INFO:root:current mean train loss 1567.2749972873264
INFO:root:current train perplexity3.437107801437378
INFO:root:current mean train loss 1566.1820678710938
INFO:root:current train perplexity3.4329617023468018
INFO:root:current mean train loss 1565.8374205502596
INFO:root:current train perplexity3.4342732429504395
INFO:root:current mean train loss 1568.133009270056
INFO:root:current train perplexity3.439408779144287
INFO:root:current mean train loss 1567.911555062353
INFO:root:current train perplexity3.4371535778045654
INFO:root:current mean train loss 1567.4257727391216
INFO:root:current train perplexity3.4351911544799805
INFO:root:current mean train loss 1566.5467022881992
INFO:root:current train perplexity3.435606002807617
INFO:root:current mean train loss 1567.564808791658
INFO:root:current train perplexity3.4386703968048096
INFO:root:current mean train loss 1567.695434383088
INFO:root:current train perplexity3.4393932819366455
INFO:root:current mean train loss 1567.7537050600406
INFO:root:current train perplexity3.440986394882202
INFO:root:current mean train loss 1567.4230552835668
INFO:root:current train perplexity3.4406747817993164
INFO:root:current mean train loss 1567.4462836591383
INFO:root:current train perplexity3.43969464302063
INFO:root:current mean train loss 1566.792443073971
INFO:root:current train perplexity3.4406628608703613
INFO:root:current mean train loss 1567.2250378390902
INFO:root:current train perplexity3.442295551300049
INFO:root:current mean train loss 1568.0250685235033
INFO:root:current train perplexity3.443598747253418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.61s/it]
INFO:root:final mean train loss: 1568.5994319636834
INFO:root:final train perplexity: 3.4455788135528564
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it]
INFO:root:eval mean loss: 3282.1353338201484
INFO:root:eval perplexity: 14.779356002807617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/66
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [5:30:18<2:50:55, 301.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1543.823707217262
INFO:root:current train perplexity3.3892133235931396
INFO:root:current mean train loss 1565.5320015899406
INFO:root:current train perplexity3.4078989028930664
INFO:root:current mean train loss 1555.7230970287756
INFO:root:current train perplexity3.409886360168457
INFO:root:current mean train loss 1562.5715358650943
INFO:root:current train perplexity3.427280902862549
INFO:root:current mean train loss 1565.54353676839
INFO:root:current train perplexity3.4340193271636963
INFO:root:current mean train loss 1565.785391018624
INFO:root:current train perplexity3.436790943145752
INFO:root:current mean train loss 1565.375795127881
INFO:root:current train perplexity3.4347968101501465
INFO:root:current mean train loss 1563.8910873772863
INFO:root:current train perplexity3.4271321296691895
INFO:root:current mean train loss 1564.8873963071426
INFO:root:current train perplexity3.4289371967315674
INFO:root:current mean train loss 1565.5716083539037
INFO:root:current train perplexity3.4300270080566406
INFO:root:current mean train loss 1564.185899336588
INFO:root:current train perplexity3.4294471740722656
INFO:root:current mean train loss 1563.801191998634
INFO:root:current train perplexity3.429046154022217
INFO:root:current mean train loss 1563.9469984899672
INFO:root:current train perplexity3.4291534423828125
INFO:root:current mean train loss 1561.9778483504151
INFO:root:current train perplexity3.428924798965454
INFO:root:current mean train loss 1562.7607962214386
INFO:root:current train perplexity3.430542230606079
INFO:root:current mean train loss 1562.794347799428
INFO:root:current train perplexity3.4319729804992676
INFO:root:current mean train loss 1563.8337412133474
INFO:root:current train perplexity3.4330062866210938
INFO:root:current mean train loss 1564.2544339682597
INFO:root:current train perplexity3.4350969791412354
INFO:root:current mean train loss 1565.3634492391286
INFO:root:current train perplexity3.4357705116271973
INFO:root:current mean train loss 1564.95377767266
INFO:root:current train perplexity3.4353795051574707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.62s/it]
INFO:root:final mean train loss: 1565.6073975594309
INFO:root:final train perplexity: 3.437457323074341
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it]
INFO:root:eval mean loss: 3288.761154953782
INFO:root:eval perplexity: 14.859935760498047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/67
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [5:35:19<2:45:43, 301.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1546.593595805921
INFO:root:current train perplexity3.3984389305114746
INFO:root:current mean train loss 1545.8218100727468
INFO:root:current train perplexity3.3943030834198
INFO:root:current mean train loss 1549.497457552357
INFO:root:current train perplexity3.399895668029785
INFO:root:current mean train loss 1549.9228649252266
INFO:root:current train perplexity3.4053189754486084
INFO:root:current mean train loss 1552.7273868926584
INFO:root:current train perplexity3.4097838401794434
INFO:root:current mean train loss 1557.1479027049693
INFO:root:current train perplexity3.4143338203430176
INFO:root:current mean train loss 1560.9450748646896
INFO:root:current train perplexity3.41867995262146
INFO:root:current mean train loss 1557.9752896936927
INFO:root:current train perplexity3.4164717197418213
INFO:root:current mean train loss 1558.9184328502572
INFO:root:current train perplexity3.4169747829437256
INFO:root:current mean train loss 1560.8162278295326
INFO:root:current train perplexity3.4188947677612305
INFO:root:current mean train loss 1560.8298415108682
INFO:root:current train perplexity3.4206485748291016
INFO:root:current mean train loss 1562.4786000444517
INFO:root:current train perplexity3.4219114780426025
INFO:root:current mean train loss 1562.3814611481157
INFO:root:current train perplexity3.4221649169921875
INFO:root:current mean train loss 1561.3865424870376
INFO:root:current train perplexity3.421949863433838
INFO:root:current mean train loss 1561.935745430258
INFO:root:current train perplexity3.423884868621826
INFO:root:current mean train loss 1562.9262065912253
INFO:root:current train perplexity3.4255547523498535
INFO:root:current mean train loss 1562.7994293846345
INFO:root:current train perplexity3.426112174987793
INFO:root:current mean train loss 1563.1585259300382
INFO:root:current train perplexity3.4275963306427
INFO:root:current mean train loss 1563.621441165563
INFO:root:current train perplexity3.428514003753662
INFO:root:current mean train loss 1562.5425880518737
INFO:root:current train perplexity3.428091526031494

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.46s/it]
INFO:root:final mean train loss: 1562.3752192710303
INFO:root:final train perplexity: 3.428706645965576
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it]
INFO:root:eval mean loss: 3293.50597887927
INFO:root:eval perplexity: 14.917903900146484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/68
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [5:40:20<2:40:35, 301.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1542.214386541193
INFO:root:current train perplexity3.3929097652435303
INFO:root:current mean train loss 1564.4397153792843
INFO:root:current train perplexity3.4121651649475098
INFO:root:current mean train loss 1561.0258468328739
INFO:root:current train perplexity3.414825916290283
INFO:root:current mean train loss 1564.1314105826364
INFO:root:current train perplexity3.4233784675598145
INFO:root:current mean train loss 1562.7732089199862
INFO:root:current train perplexity3.4248158931732178
INFO:root:current mean train loss 1560.2906883445946
INFO:root:current train perplexity3.41913104057312
INFO:root:current mean train loss 1559.6596567867366
INFO:root:current train perplexity3.4180185794830322
INFO:root:current mean train loss 1559.7185648734996
INFO:root:current train perplexity3.4145097732543945
INFO:root:current mean train loss 1558.5080616376554
INFO:root:current train perplexity3.4135658740997314
INFO:root:current mean train loss 1559.159560214537
INFO:root:current train perplexity3.415011167526245
INFO:root:current mean train loss 1559.0964917802132
INFO:root:current train perplexity3.4161040782928467
INFO:root:current mean train loss 1560.8258393787203
INFO:root:current train perplexity3.4191970825195312
INFO:root:current mean train loss 1561.144164747261
INFO:root:current train perplexity3.4198505878448486
INFO:root:current mean train loss 1560.9127555819016
INFO:root:current train perplexity3.4204323291778564
INFO:root:current mean train loss 1561.7822921700495
INFO:root:current train perplexity3.422365188598633
INFO:root:current mean train loss 1561.6973979005477
INFO:root:current train perplexity3.4214706420898438
INFO:root:current mean train loss 1562.8879955833413
INFO:root:current train perplexity3.4243733882904053
INFO:root:current mean train loss 1561.6644331625046
INFO:root:current train perplexity3.4227821826934814
INFO:root:current mean train loss 1561.0806047053993
INFO:root:current train perplexity3.4222750663757324
INFO:root:current mean train loss 1560.5031527858257
INFO:root:current train perplexity3.4219560623168945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.54s/it]
INFO:root:final mean train loss: 1560.117993299491
INFO:root:final train perplexity: 3.4226083755493164
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.61s/it]
INFO:root:eval mean loss: 3297.771101668074
INFO:root:eval perplexity: 14.970208168029785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/69
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [5:45:20<2:35:29, 300.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1537.6720377604167
INFO:root:current train perplexity3.3866803646087646
INFO:root:current mean train loss 1547.3172444188317
INFO:root:current train perplexity3.4042229652404785
INFO:root:current mean train loss 1547.0284073773553
INFO:root:current train perplexity3.403843641281128
INFO:root:current mean train loss 1545.9784870762978
INFO:root:current train perplexity3.3985259532928467
INFO:root:current mean train loss 1549.8847079519498
INFO:root:current train perplexity3.3992042541503906
INFO:root:current mean train loss 1553.4452403675425
INFO:root:current train perplexity3.4090259075164795
INFO:root:current mean train loss 1554.26532073248
INFO:root:current train perplexity3.411402940750122
INFO:root:current mean train loss 1553.2792189207719
INFO:root:current train perplexity3.4092745780944824
INFO:root:current mean train loss 1551.9516353782165
INFO:root:current train perplexity3.4094960689544678
INFO:root:current mean train loss 1552.493979999558
INFO:root:current train perplexity3.41023850440979
INFO:root:current mean train loss 1552.454082432078
INFO:root:current train perplexity3.410266399383545
INFO:root:current mean train loss 1553.6227917980416
INFO:root:current train perplexity3.4112179279327393
INFO:root:current mean train loss 1553.559755241346
INFO:root:current train perplexity3.4100263118743896
INFO:root:current mean train loss 1552.9875623519497
INFO:root:current train perplexity3.410325765609741
INFO:root:current mean train loss 1553.6573210177214
INFO:root:current train perplexity3.4110357761383057
INFO:root:current mean train loss 1553.3170641251193
INFO:root:current train perplexity3.4100470542907715
INFO:root:current mean train loss 1555.0425293114768
INFO:root:current train perplexity3.4115896224975586
INFO:root:current mean train loss 1555.5176574844809
INFO:root:current train perplexity3.411468029022217
INFO:root:current mean train loss 1556.3584865341838
INFO:root:current train perplexity3.411726951599121
INFO:root:current mean train loss 1556.65646164219
INFO:root:current train perplexity3.412405014038086

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.29s/it]
INFO:root:final mean train loss: 1556.5867536413027
INFO:root:final train perplexity: 3.413090229034424
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it]
INFO:root:eval mean loss: 3296.2097791150527
INFO:root:eval perplexity: 14.95103931427002
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/70
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [5:50:20<2:30:21, 300.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1542.7739230380969
INFO:root:current train perplexity3.4129106998443604
INFO:root:current mean train loss 1534.4591516565395
INFO:root:current train perplexity3.385561466217041
INFO:root:current mean train loss 1542.9607423564555
INFO:root:current train perplexity3.3939285278320312
INFO:root:current mean train loss 1543.257289386347
INFO:root:current train perplexity3.394594430923462
INFO:root:current mean train loss 1547.4999398385576
INFO:root:current train perplexity3.399198532104492
INFO:root:current mean train loss 1547.8357209236392
INFO:root:current train perplexity3.401052713394165
INFO:root:current mean train loss 1548.7421451563066
INFO:root:current train perplexity3.400172472000122
INFO:root:current mean train loss 1547.8042942138982
INFO:root:current train perplexity3.3959240913391113
INFO:root:current mean train loss 1549.862647830032
INFO:root:current train perplexity3.3991057872772217
INFO:root:current mean train loss 1552.3444911852644
INFO:root:current train perplexity3.400479793548584
INFO:root:current mean train loss 1550.4360519703425
INFO:root:current train perplexity3.3989486694335938
INFO:root:current mean train loss 1549.8810599850847
INFO:root:current train perplexity3.399789571762085
INFO:root:current mean train loss 1550.265610321258
INFO:root:current train perplexity3.400510549545288
INFO:root:current mean train loss 1550.1895062945746
INFO:root:current train perplexity3.4009225368499756
INFO:root:current mean train loss 1550.629594975786
INFO:root:current train perplexity3.4019601345062256
INFO:root:current mean train loss 1550.477232542332
INFO:root:current train perplexity3.4021928310394287
INFO:root:current mean train loss 1551.70090120992
INFO:root:current train perplexity3.4027504920959473
INFO:root:current mean train loss 1552.6519139451377
INFO:root:current train perplexity3.4029064178466797
INFO:root:current mean train loss 1553.7824304438318
INFO:root:current train perplexity3.404059886932373

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.56s/it]
INFO:root:final mean train loss: 1553.9548350924263
INFO:root:final train perplexity: 3.4060122966766357
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.96s/it]
INFO:root:eval mean loss: 3296.4424180039414
INFO:root:eval perplexity: 14.95389461517334
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/71
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [5:55:21<2:25:22, 300.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1595.4275309244792
INFO:root:current train perplexity3.4258735179901123
INFO:root:current mean train loss 1546.33168346477
INFO:root:current train perplexity3.3697264194488525
INFO:root:current mean train loss 1537.964089995449
INFO:root:current train perplexity3.3625550270080566
INFO:root:current mean train loss 1539.0086191214766
INFO:root:current train perplexity3.363468647003174
INFO:root:current mean train loss 1542.2154592128811
INFO:root:current train perplexity3.374880313873291
INFO:root:current mean train loss 1539.9657824369287
INFO:root:current train perplexity3.3707191944122314
INFO:root:current mean train loss 1542.6853955964443
INFO:root:current train perplexity3.3771679401397705
INFO:root:current mean train loss 1545.101548494766
INFO:root:current train perplexity3.3819692134857178
INFO:root:current mean train loss 1546.5775658392138
INFO:root:current train perplexity3.3834612369537354
INFO:root:current mean train loss 1546.4227580561017
INFO:root:current train perplexity3.383063554763794
INFO:root:current mean train loss 1547.8017083048583
INFO:root:current train perplexity3.3879878520965576
INFO:root:current mean train loss 1543.7966527128306
INFO:root:current train perplexity3.3838062286376953
INFO:root:current mean train loss 1545.730614505597
INFO:root:current train perplexity3.3856005668640137
INFO:root:current mean train loss 1548.0450156242523
INFO:root:current train perplexity3.3890583515167236
INFO:root:current mean train loss 1548.7907733076158
INFO:root:current train perplexity3.3921866416931152
INFO:root:current mean train loss 1549.172976388716
INFO:root:current train perplexity3.3917548656463623
INFO:root:current mean train loss 1548.9315672764
INFO:root:current train perplexity3.3931586742401123
INFO:root:current mean train loss 1548.0939008348294
INFO:root:current train perplexity3.392430067062378
INFO:root:current mean train loss 1548.971273259599
INFO:root:current train perplexity3.3944411277770996
INFO:root:current mean train loss 1550.7670393760657
INFO:root:current train perplexity3.395909070968628

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.68s/it]
INFO:root:final mean train loss: 1550.706078695277
INFO:root:final train perplexity: 3.3972971439361572
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it]
INFO:root:eval mean loss: 3298.792194538288
INFO:root:eval perplexity: 14.982751846313477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/72
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [6:00:22<2:20:20, 300.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1570.4622802734375
INFO:root:current train perplexity3.395881175994873
INFO:root:current mean train loss 1558.5330760924796
INFO:root:current train perplexity3.3968706130981445
INFO:root:current mean train loss 1548.67846132287
INFO:root:current train perplexity3.382075786590576
INFO:root:current mean train loss 1547.4801951310951
INFO:root:current train perplexity3.3800036907196045
INFO:root:current mean train loss 1547.2509768510822
INFO:root:current train perplexity3.3816452026367188
INFO:root:current mean train loss 1549.2842261349037
INFO:root:current train perplexity3.3854928016662598
INFO:root:current mean train loss 1548.3518532742276
INFO:root:current train perplexity3.383704900741577
INFO:root:current mean train loss 1547.955381527976
INFO:root:current train perplexity3.3891119956970215
INFO:root:current mean train loss 1547.478618413246
INFO:root:current train perplexity3.3882131576538086
INFO:root:current mean train loss 1548.15781284386
INFO:root:current train perplexity3.3896713256835938
INFO:root:current mean train loss 1549.4355246803977
INFO:root:current train perplexity3.390639066696167
INFO:root:current mean train loss 1548.9422566115802
INFO:root:current train perplexity3.3898820877075195
INFO:root:current mean train loss 1548.8481429342548
INFO:root:current train perplexity3.3908865451812744
INFO:root:current mean train loss 1548.5164699886031
INFO:root:current train perplexity3.390859842300415
INFO:root:current mean train loss 1548.2867462522784
INFO:root:current train perplexity3.390946626663208
INFO:root:current mean train loss 1548.9826608859466
INFO:root:current train perplexity3.392301082611084
INFO:root:current mean train loss 1549.5192469457602
INFO:root:current train perplexity3.392441511154175
INFO:root:current mean train loss 1549.4574640576257
INFO:root:current train perplexity3.392181396484375
INFO:root:current mean train loss 1549.5117529002246
INFO:root:current train perplexity3.3909969329833984
INFO:root:current mean train loss 1549.438454598731
INFO:root:current train perplexity3.3921964168548584

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.57s/it]
INFO:root:final mean train loss: 1549.0075493378286
INFO:root:final train perplexity: 3.392749309539795
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.73s/it]
INFO:root:eval mean loss: 3304.678661082958
INFO:root:eval perplexity: 15.055298805236816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/73
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [6:05:24<2:15:28, 301.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1536.5543304443358
INFO:root:current train perplexity3.4063456058502197
INFO:root:current mean train loss 1539.749147251674
INFO:root:current train perplexity3.3762083053588867
INFO:root:current mean train loss 1535.8129399617512
INFO:root:current train perplexity3.370084524154663
INFO:root:current mean train loss 1539.0757352941177
INFO:root:current train perplexity3.3747596740722656
INFO:root:current mean train loss 1543.5480926513671
INFO:root:current train perplexity3.3789119720458984
INFO:root:current mean train loss 1544.0007753725406
INFO:root:current train perplexity3.3831982612609863
INFO:root:current mean train loss 1543.7788116455079
INFO:root:current train perplexity3.3776416778564453
INFO:root:current mean train loss 1543.2629759092588
INFO:root:current train perplexity3.377159833908081
INFO:root:current mean train loss 1544.124925595238
INFO:root:current train perplexity3.3789312839508057
INFO:root:current mean train loss 1544.2096440741357
INFO:root:current train perplexity3.381296157836914
INFO:root:current mean train loss 1544.9264894925632
INFO:root:current train perplexity3.3832039833068848
INFO:root:current mean train loss 1545.1774477239242
INFO:root:current train perplexity3.3859617710113525
INFO:root:current mean train loss 1546.1898996660786
INFO:root:current train perplexity3.3873960971832275
INFO:root:current mean train loss 1546.3773461185285
INFO:root:current train perplexity3.3868377208709717
INFO:root:current mean train loss 1545.4087850782607
INFO:root:current train perplexity3.384108066558838
INFO:root:current mean train loss 1545.1072328245484
INFO:root:current train perplexity3.3839926719665527
INFO:root:current mean train loss 1545.53987932903
INFO:root:current train perplexity3.383800506591797
INFO:root:current mean train loss 1545.8626314009744
INFO:root:current train perplexity3.3840856552124023
INFO:root:current mean train loss 1546.2721210645593
INFO:root:current train perplexity3.3850600719451904
INFO:root:current mean train loss 1546.4244832776255
INFO:root:current train perplexity3.3846099376678467

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.44s/it]
INFO:root:final mean train loss: 1545.8270898339006
INFO:root:final train perplexity: 3.384249210357666
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it]
INFO:root:eval mean loss: 3305.4867254950263
INFO:root:eval perplexity: 15.06528091430664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/74
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [6:10:25<2:10:31, 301.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1532.8988208436128
INFO:root:current train perplexity3.3498904705047607
INFO:root:current mean train loss 1550.1005610569268
INFO:root:current train perplexity3.384707450866699
INFO:root:current mean train loss 1546.9506612696073
INFO:root:current train perplexity3.371809959411621
INFO:root:current mean train loss 1543.394035104276
INFO:root:current train perplexity3.370692253112793
INFO:root:current mean train loss 1539.3090067055866
INFO:root:current train perplexity3.3657960891723633
INFO:root:current mean train loss 1542.6828760116275
INFO:root:current train perplexity3.375281810760498
INFO:root:current mean train loss 1543.3178435954148
INFO:root:current train perplexity3.372856855392456
INFO:root:current mean train loss 1541.9859017658107
INFO:root:current train perplexity3.3722352981567383
INFO:root:current mean train loss 1542.3070723579256
INFO:root:current train perplexity3.3748488426208496
INFO:root:current mean train loss 1541.7321796477029
INFO:root:current train perplexity3.373657464981079
INFO:root:current mean train loss 1540.327678178771
INFO:root:current train perplexity3.3694956302642822
INFO:root:current mean train loss 1542.5131026707338
INFO:root:current train perplexity3.3713784217834473
INFO:root:current mean train loss 1541.2214302056918
INFO:root:current train perplexity3.3705618381500244
INFO:root:current mean train loss 1542.1169524449326
INFO:root:current train perplexity3.3737435340881348
INFO:root:current mean train loss 1542.2843945044397
INFO:root:current train perplexity3.3744969367980957
INFO:root:current mean train loss 1542.2156241532696
INFO:root:current train perplexity3.3749804496765137
INFO:root:current mean train loss 1542.64048171288
INFO:root:current train perplexity3.375828981399536
INFO:root:current mean train loss 1542.5087407762921
INFO:root:current train perplexity3.37532901763916
INFO:root:current mean train loss 1544.225175421021
INFO:root:current train perplexity3.3798956871032715
INFO:root:current mean train loss 1543.9289213949523
INFO:root:current train perplexity3.3788981437683105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.45s/it]
INFO:root:final mean train loss: 1543.7898654678045
INFO:root:final train perplexity: 3.378816843032837
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.13s/it]
INFO:root:eval mean loss: 3313.159283795514
INFO:root:eval perplexity: 15.160436630249023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/75
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [6:15:42<2:07:28, 305.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1546.7833680848817
INFO:root:current train perplexity3.389227867126465
INFO:root:current mean train loss 1532.4254325779004
INFO:root:current train perplexity3.3586013317108154
INFO:root:current mean train loss 1537.8903844234717
INFO:root:current train perplexity3.359236717224121
INFO:root:current mean train loss 1538.2831486176678
INFO:root:current train perplexity3.3576161861419678
INFO:root:current mean train loss 1541.0286932192773
INFO:root:current train perplexity3.3654568195343018
INFO:root:current mean train loss 1538.7542565109839
INFO:root:current train perplexity3.36556339263916
INFO:root:current mean train loss 1537.6525954973804
INFO:root:current train perplexity3.362783432006836
INFO:root:current mean train loss 1539.091375779736
INFO:root:current train perplexity3.365605115890503
INFO:root:current mean train loss 1538.7070739885762
INFO:root:current train perplexity3.363490343093872
INFO:root:current mean train loss 1540.7649054869978
INFO:root:current train perplexity3.3673408031463623
INFO:root:current mean train loss 1540.6655482570995
INFO:root:current train perplexity3.3658971786499023
INFO:root:current mean train loss 1540.9882857210591
INFO:root:current train perplexity3.365553379058838
INFO:root:current mean train loss 1539.706064077524
INFO:root:current train perplexity3.364823579788208
INFO:root:current mean train loss 1541.947898009632
INFO:root:current train perplexity3.370154857635498
INFO:root:current mean train loss 1541.626647369509
INFO:root:current train perplexity3.370969295501709
INFO:root:current mean train loss 1541.2732502066044
INFO:root:current train perplexity3.3712430000305176
INFO:root:current mean train loss 1541.444414400855
INFO:root:current train perplexity3.3717830181121826
INFO:root:current mean train loss 1541.0865905830528
INFO:root:current train perplexity3.3711705207824707
INFO:root:current mean train loss 1541.5239438247274
INFO:root:current train perplexity3.3717899322509766
INFO:root:current mean train loss 1541.7122946819395
INFO:root:current train perplexity3.372448682785034

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.14s/it]
INFO:root:final mean train loss: 1541.4688051563287
INFO:root:final train perplexity: 3.3726372718811035
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.44s/it]
INFO:root:eval mean loss: 3313.2255008915167
INFO:root:eval perplexity: 15.16125774383545
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/76
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [6:21:01<2:03:51, 309.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1538.3922172797904
INFO:root:current train perplexity3.378392219543457
INFO:root:current mean train loss 1543.7330718514806
INFO:root:current train perplexity3.3862621784210205
INFO:root:current mean train loss 1538.587606633242
INFO:root:current train perplexity3.371408462524414
INFO:root:current mean train loss 1538.7292105828406
INFO:root:current train perplexity3.3686044216156006
INFO:root:current mean train loss 1540.3820492497773
INFO:root:current train perplexity3.3724334239959717
INFO:root:current mean train loss 1538.0483288966661
INFO:root:current train perplexity3.3633570671081543
INFO:root:current mean train loss 1537.5846422474222
INFO:root:current train perplexity3.3623337745666504
INFO:root:current mean train loss 1539.731415373637
INFO:root:current train perplexity3.3642685413360596
INFO:root:current mean train loss 1539.293122605175
INFO:root:current train perplexity3.3647193908691406
INFO:root:current mean train loss 1539.3071072267596
INFO:root:current train perplexity3.365957736968994
INFO:root:current mean train loss 1539.9160876811698
INFO:root:current train perplexity3.3656649589538574
INFO:root:current mean train loss 1540.5394437775503
INFO:root:current train perplexity3.3666443824768066
INFO:root:current mean train loss 1539.6604079550132
INFO:root:current train perplexity3.3659322261810303
INFO:root:current mean train loss 1539.8501234568769
INFO:root:current train perplexity3.366832733154297
INFO:root:current mean train loss 1540.1523936915764
INFO:root:current train perplexity3.3666834831237793
INFO:root:current mean train loss 1540.256297094128
INFO:root:current train perplexity3.3667941093444824
INFO:root:current mean train loss 1539.2720165466994
INFO:root:current train perplexity3.3642280101776123
INFO:root:current mean train loss 1539.6956324319078
INFO:root:current train perplexity3.3657307624816895
INFO:root:current mean train loss 1539.3630725491432
INFO:root:current train perplexity3.365844249725342

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.07s/it]
INFO:root:final mean train loss: 1539.3017288800506
INFO:root:final train perplexity: 3.366878032684326
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it]
INFO:root:eval mean loss: 3320.4182994029184
INFO:root:eval perplexity: 15.251004219055176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/77
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [6:26:01<1:57:37, 306.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1486.0814819335938
INFO:root:current train perplexity3.249098777770996
INFO:root:current mean train loss 1524.0323859320747
INFO:root:current train perplexity3.3368701934814453
INFO:root:current mean train loss 1530.229628929725
INFO:root:current train perplexity3.336336135864258
INFO:root:current mean train loss 1533.9117142318132
INFO:root:current train perplexity3.3476500511169434
INFO:root:current mean train loss 1535.245568668141
INFO:root:current train perplexity3.3472342491149902
INFO:root:current mean train loss 1533.5241494967242
INFO:root:current train perplexity3.346011161804199
INFO:root:current mean train loss 1533.9246711730957
INFO:root:current train perplexity3.3486897945404053
INFO:root:current mean train loss 1533.2853507349046
INFO:root:current train perplexity3.350715160369873
INFO:root:current mean train loss 1536.3157427192914
INFO:root:current train perplexity3.354649066925049
INFO:root:current mean train loss 1537.037178207599
INFO:root:current train perplexity3.357095718383789
INFO:root:current mean train loss 1537.2640056307353
INFO:root:current train perplexity3.3558661937713623
INFO:root:current mean train loss 1535.6403637827518
INFO:root:current train perplexity3.3547918796539307
INFO:root:current mean train loss 1534.6792118501978
INFO:root:current train perplexity3.352834939956665
INFO:root:current mean train loss 1534.8193537627521
INFO:root:current train perplexity3.353213310241699
INFO:root:current mean train loss 1535.5883733575995
INFO:root:current train perplexity3.3558833599090576
INFO:root:current mean train loss 1535.7734177485702
INFO:root:current train perplexity3.356205940246582
INFO:root:current mean train loss 1535.4562970820944
INFO:root:current train perplexity3.356706380844116
INFO:root:current mean train loss 1537.076868847885
INFO:root:current train perplexity3.3587586879730225
INFO:root:current mean train loss 1536.977736819107
INFO:root:current train perplexity3.359135389328003
INFO:root:current mean train loss 1536.529865960655
INFO:root:current train perplexity3.3590009212493896

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.15s/it]
INFO:root:final mean train loss: 1537.0172568516964
INFO:root:final train perplexity: 3.3608176708221436
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.76s/it]
INFO:root:eval mean loss: 3317.809622366507
INFO:root:eval perplexity: 15.21839427947998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/78
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [6:31:02<1:51:54, 305.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1534.1669189453125
INFO:root:current train perplexity3.3665661811828613
INFO:root:current mean train loss 1521.88185546875
INFO:root:current train perplexity3.331031084060669
INFO:root:current mean train loss 1532.3715587022568
INFO:root:current train perplexity3.358508348464966
INFO:root:current mean train loss 1530.095108548678
INFO:root:current train perplexity3.358708143234253
INFO:root:current mean train loss 1533.1390670955882
INFO:root:current train perplexity3.3578343391418457
INFO:root:current mean train loss 1531.961280924479
INFO:root:current train perplexity3.3540217876434326
INFO:root:current mean train loss 1533.0420150390626
INFO:root:current train perplexity3.3526880741119385
INFO:root:current mean train loss 1533.0645327653556
INFO:root:current train perplexity3.350571393966675
INFO:root:current mean train loss 1532.3948573626894
INFO:root:current train perplexity3.3513143062591553
INFO:root:current mean train loss 1530.2919163059544
INFO:root:current train perplexity3.3481621742248535
INFO:root:current mean train loss 1529.8295532822028
INFO:root:current train perplexity3.348141670227051
INFO:root:current mean train loss 1531.5468065321181
INFO:root:current train perplexity3.3497138023376465
INFO:root:current mean train loss 1532.3555377072705
INFO:root:current train perplexity3.351445436477661
INFO:root:current mean train loss 1533.4032945165095
INFO:root:current train perplexity3.3521485328674316
INFO:root:current mean train loss 1532.701316731771
INFO:root:current train perplexity3.350426435470581
INFO:root:current mean train loss 1533.0027359759222
INFO:root:current train perplexity3.350994825363159
INFO:root:current mean train loss 1533.1840818810097
INFO:root:current train perplexity3.3501486778259277
INFO:root:current mean train loss 1534.291146682518
INFO:root:current train perplexity3.3513715267181396
INFO:root:current mean train loss 1534.1897402745078
INFO:root:current train perplexity3.353898286819458
INFO:root:current mean train loss 1534.729330420556
INFO:root:current train perplexity3.3543007373809814

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 270.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 270.00s/it]
INFO:root:final mean train loss: 1534.6058069518642
INFO:root:final train perplexity: 3.3544323444366455
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.22s/it]
INFO:root:eval mean loss: 3320.846044042089
INFO:root:eval perplexity: 15.256361961364746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/79
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [6:36:03<1:46:20, 303.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1532.7591959635417
INFO:root:current train perplexity3.3331499099731445
INFO:root:current mean train loss 1531.8614708269147
INFO:root:current train perplexity3.347700834274292
INFO:root:current mean train loss 1531.5445506198348
INFO:root:current train perplexity3.34751033782959
INFO:root:current mean train loss 1538.322516547309
INFO:root:current train perplexity3.3577818870544434
INFO:root:current mean train loss 1536.0732076653528
INFO:root:current train perplexity3.3493337631225586
INFO:root:current mean train loss 1537.5252145014126
INFO:root:current train perplexity3.351863384246826
INFO:root:current mean train loss 1536.8414253401236
INFO:root:current train perplexity3.348999261856079
INFO:root:current mean train loss 1535.46646570581
INFO:root:current train perplexity3.3495373725891113
INFO:root:current mean train loss 1536.1155382459917
INFO:root:current train perplexity3.3536605834960938
INFO:root:current mean train loss 1537.2170289640974
INFO:root:current train perplexity3.356609582901001
INFO:root:current mean train loss 1535.4236964483864
INFO:root:current train perplexity3.3543190956115723
INFO:root:current mean train loss 1533.8631133231515
INFO:root:current train perplexity3.351315498352051
INFO:root:current mean train loss 1534.464570418648
INFO:root:current train perplexity3.351498603820801
INFO:root:current mean train loss 1533.9093402345206
INFO:root:current train perplexity3.3513107299804688
INFO:root:current mean train loss 1533.8870664218261
INFO:root:current train perplexity3.3504223823547363
INFO:root:current mean train loss 1534.2124989233746
INFO:root:current train perplexity3.3512659072875977
INFO:root:current mean train loss 1535.2998866872288
INFO:root:current train perplexity3.3535115718841553
INFO:root:current mean train loss 1534.6941242415103
INFO:root:current train perplexity3.3530831336975098
INFO:root:current mean train loss 1533.2700476962243
INFO:root:current train perplexity3.351687431335449
INFO:root:current mean train loss 1533.0816415930137
INFO:root:current train perplexity3.350594997406006

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.59s/it]
INFO:root:final mean train loss: 1532.689682737842
INFO:root:final train perplexity: 3.3493669033050537
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.14s/it]
INFO:root:eval mean loss: 3317.316310939846
INFO:root:eval perplexity: 15.212238311767578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/80
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [6:41:04<1:41:01, 303.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1511.8970326569122
INFO:root:current train perplexity3.3394501209259033
INFO:root:current mean train loss 1531.3026737237126
INFO:root:current train perplexity3.3497347831726074
INFO:root:current mean train loss 1523.494862677968
INFO:root:current train perplexity3.3313872814178467
INFO:root:current mean train loss 1522.1416246844533
INFO:root:current train perplexity3.3314199447631836
INFO:root:current mean train loss 1523.290912171075
INFO:root:current train perplexity3.3304145336151123
INFO:root:current mean train loss 1524.4334865290277
INFO:root:current train perplexity3.3292274475097656
INFO:root:current mean train loss 1525.3127980442075
INFO:root:current train perplexity3.328223943710327
INFO:root:current mean train loss 1526.4039893671772
INFO:root:current train perplexity3.331465482711792
INFO:root:current mean train loss 1526.5849642059718
INFO:root:current train perplexity3.3332691192626953
INFO:root:current mean train loss 1526.620976516676
INFO:root:current train perplexity3.335526466369629
INFO:root:current mean train loss 1526.2696162035602
INFO:root:current train perplexity3.3353331089019775
INFO:root:current mean train loss 1527.8411719887497
INFO:root:current train perplexity3.336599826812744
INFO:root:current mean train loss 1529.2748167297025
INFO:root:current train perplexity3.3397183418273926
INFO:root:current mean train loss 1529.814751608921
INFO:root:current train perplexity3.342449903488159
INFO:root:current mean train loss 1530.3336441008664
INFO:root:current train perplexity3.344041347503662
INFO:root:current mean train loss 1530.8479082989647
INFO:root:current train perplexity3.3444509506225586
INFO:root:current mean train loss 1530.989855140286
INFO:root:current train perplexity3.3452839851379395
INFO:root:current mean train loss 1530.7303133688574
INFO:root:current train perplexity3.3444972038269043
INFO:root:current mean train loss 1530.9032027730382
INFO:root:current train perplexity3.344365358352661
INFO:root:current mean train loss 1531.1726226261405
INFO:root:current train perplexity3.345046043395996

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.08s/it]
INFO:root:final mean train loss: 1531.182759510527
INFO:root:final train perplexity: 3.345388412475586
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.80s/it]
INFO:root:eval mean loss: 3314.6495687582114
INFO:root:eval perplexity: 15.178983688354492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/81
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [6:46:07<1:35:54, 302.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1534.0575866699219
INFO:root:current train perplexity3.3736491203308105
INFO:root:current mean train loss 1536.353874206543
INFO:root:current train perplexity3.358372211456299
INFO:root:current mean train loss 1535.5608135720959
INFO:root:current train perplexity3.349149703979492
INFO:root:current mean train loss 1529.119760066905
INFO:root:current train perplexity3.3365578651428223
INFO:root:current mean train loss 1527.4829078481978
INFO:root:current train perplexity3.334744691848755
INFO:root:current mean train loss 1527.9701591067844
INFO:root:current train perplexity3.334764242172241
INFO:root:current mean train loss 1527.8954408182901
INFO:root:current train perplexity3.3344624042510986
INFO:root:current mean train loss 1526.9840227893947
INFO:root:current train perplexity3.335195541381836
INFO:root:current mean train loss 1528.4507049142499
INFO:root:current train perplexity3.3324830532073975
INFO:root:current mean train loss 1529.113106149142
INFO:root:current train perplexity3.334359884262085
INFO:root:current mean train loss 1526.739561513454
INFO:root:current train perplexity3.3319082260131836
INFO:root:current mean train loss 1526.7619601917916
INFO:root:current train perplexity3.3340530395507812
INFO:root:current mean train loss 1528.2755967860685
INFO:root:current train perplexity3.335974931716919
INFO:root:current mean train loss 1529.0687304652015
INFO:root:current train perplexity3.3365721702575684
INFO:root:current mean train loss 1529.3627545116394
INFO:root:current train perplexity3.3356642723083496
INFO:root:current mean train loss 1529.8661656258676
INFO:root:current train perplexity3.337080955505371
INFO:root:current mean train loss 1530.5109134209754
INFO:root:current train perplexity3.3378560543060303
INFO:root:current mean train loss 1529.765712360004
INFO:root:current train perplexity3.3380861282348633
INFO:root:current mean train loss 1529.2596550719825
INFO:root:current train perplexity3.338827133178711
INFO:root:current mean train loss 1529.2351336768763
INFO:root:current train perplexity3.338989496231079

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.02s/it]
INFO:root:final mean train loss: 1528.6414173182009
INFO:root:final train perplexity: 3.3386902809143066
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.17s/it]
INFO:root:eval mean loss: 3319.1227396830423
INFO:root:eval perplexity: 15.234796524047852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/82
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [6:51:08<1:30:44, 302.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1528.4630848874328
INFO:root:current train perplexity3.3344902992248535
INFO:root:current mean train loss 1539.2095928290964
INFO:root:current train perplexity3.346172332763672
INFO:root:current mean train loss 1526.355424588044
INFO:root:current train perplexity3.3347315788269043
INFO:root:current mean train loss 1526.1138344490498
INFO:root:current train perplexity3.3341798782348633
INFO:root:current mean train loss 1524.9183550171147
INFO:root:current train perplexity3.329854965209961
INFO:root:current mean train loss 1523.6994497160888
INFO:root:current train perplexity3.3308753967285156
INFO:root:current mean train loss 1524.8952356644006
INFO:root:current train perplexity3.3348398208618164
INFO:root:current mean train loss 1524.5597240933855
INFO:root:current train perplexity3.3354110717773438
INFO:root:current mean train loss 1525.555589836095
INFO:root:current train perplexity3.3392791748046875
INFO:root:current mean train loss 1527.5591298513423
INFO:root:current train perplexity3.3418421745300293
INFO:root:current mean train loss 1527.2703328041014
INFO:root:current train perplexity3.3406822681427
INFO:root:current mean train loss 1526.1786964077562
INFO:root:current train perplexity3.3379578590393066
INFO:root:current mean train loss 1526.2454709365031
INFO:root:current train perplexity3.337625741958618
INFO:root:current mean train loss 1527.0106897840205
INFO:root:current train perplexity3.3370914459228516
INFO:root:current mean train loss 1527.1135911270826
INFO:root:current train perplexity3.336740255355835
INFO:root:current mean train loss 1527.7976281883878
INFO:root:current train perplexity3.337186813354492
INFO:root:current mean train loss 1528.2192283310414
INFO:root:current train perplexity3.3372414112091064
INFO:root:current mean train loss 1527.9550219576784
INFO:root:current train perplexity3.3375823497772217
INFO:root:current mean train loss 1528.3075914579413
INFO:root:current train perplexity3.3365273475646973

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.85s/it]
INFO:root:final mean train loss: 1527.3735813558312
INFO:root:final train perplexity: 3.3353538513183594
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.58s/it]
INFO:root:eval mean loss: 3325.9759180567285
INFO:root:eval perplexity: 15.320718765258789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/83
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [6:56:09<1:25:34, 302.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1548.0904907226563
INFO:root:current train perplexity3.340590715408325
INFO:root:current mean train loss 1529.1614812677558
INFO:root:current train perplexity3.3252477645874023
INFO:root:current mean train loss 1531.4937401181176
INFO:root:current train perplexity3.327667713165283
INFO:root:current mean train loss 1527.8050706432712
INFO:root:current train perplexity3.325468063354492
INFO:root:current mean train loss 1524.013602801067
INFO:root:current train perplexity3.3253586292266846
INFO:root:current mean train loss 1522.688401405484
INFO:root:current train perplexity3.328930616378784
INFO:root:current mean train loss 1523.8187119780994
INFO:root:current train perplexity3.332791805267334
INFO:root:current mean train loss 1522.2842126980634
INFO:root:current train perplexity3.3300063610076904
INFO:root:current mean train loss 1522.9393337673612
INFO:root:current train perplexity3.329383134841919
INFO:root:current mean train loss 1523.7941069550566
INFO:root:current train perplexity3.3291447162628174
INFO:root:current mean train loss 1523.1593960299351
INFO:root:current train perplexity3.3264052867889404
INFO:root:current mean train loss 1524.0353401252814
INFO:root:current train perplexity3.329554319381714
INFO:root:current mean train loss 1524.838373458484
INFO:root:current train perplexity3.33099365234375
INFO:root:current mean train loss 1525.8961118275884
INFO:root:current train perplexity3.331860303878784
INFO:root:current mean train loss 1525.722719536098
INFO:root:current train perplexity3.3328609466552734
INFO:root:current mean train loss 1526.3622455925342
INFO:root:current train perplexity3.332825183868408
INFO:root:current mean train loss 1526.3147018148293
INFO:root:current train perplexity3.3318893909454346
INFO:root:current mean train loss 1525.9078433388158
INFO:root:current train perplexity3.3307559490203857
INFO:root:current mean train loss 1524.8651817701138
INFO:root:current train perplexity3.3305413722991943
INFO:root:current mean train loss 1525.4903407231675
INFO:root:current train perplexity3.330078601837158

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.99s/it]
INFO:root:final mean train loss: 1525.1873869787728
INFO:root:final train perplexity: 3.3296077251434326
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it]
INFO:root:eval mean loss: 3324.798438819679
INFO:root:eval perplexity: 15.30592155456543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/84
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [7:01:10<1:20:28, 301.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1502.5256438078704
INFO:root:current train perplexity3.299990653991699
INFO:root:current mean train loss 1509.4485901359499
INFO:root:current train perplexity3.311046600341797
INFO:root:current mean train loss 1515.002646828538
INFO:root:current train perplexity3.316687822341919
INFO:root:current mean train loss 1518.5996664904674
INFO:root:current train perplexity3.3164963722229004
INFO:root:current mean train loss 1519.0361719779164
INFO:root:current train perplexity3.3137190341949463
INFO:root:current mean train loss 1517.8861292453598
INFO:root:current train perplexity3.3159282207489014
INFO:root:current mean train loss 1518.5624719647128
INFO:root:current train perplexity3.3197953701019287
INFO:root:current mean train loss 1519.0851132315488
INFO:root:current train perplexity3.3206772804260254
INFO:root:current mean train loss 1519.4125273957075
INFO:root:current train perplexity3.3210322856903076
INFO:root:current mean train loss 1521.4177647727465
INFO:root:current train perplexity3.323315382003784
INFO:root:current mean train loss 1521.263990422651
INFO:root:current train perplexity3.321897506713867
INFO:root:current mean train loss 1522.8232937451476
INFO:root:current train perplexity3.3241348266601562
INFO:root:current mean train loss 1523.5894619196338
INFO:root:current train perplexity3.324791193008423
INFO:root:current mean train loss 1523.731646769911
INFO:root:current train perplexity3.3251969814300537
INFO:root:current mean train loss 1524.673750793842
INFO:root:current train perplexity3.325936794281006
INFO:root:current mean train loss 1525.2808996973743
INFO:root:current train perplexity3.3263871669769287
INFO:root:current mean train loss 1525.4205992264328
INFO:root:current train perplexity3.3266377449035645
INFO:root:current mean train loss 1525.1519043110118
INFO:root:current train perplexity3.326934814453125
INFO:root:current mean train loss 1524.2682852241337
INFO:root:current train perplexity3.3258581161499023
INFO:root:current mean train loss 1523.8077872750916
INFO:root:current train perplexity3.3251898288726807

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.32s/it]
INFO:root:final mean train loss: 1523.899892555964
INFO:root:final train perplexity: 3.326228618621826
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.87s/it]
INFO:root:eval mean loss: 3326.8586550417604
INFO:root:eval perplexity: 15.331819534301758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/85
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [7:06:12<1:15:25, 301.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1495.5119490189986
INFO:root:current train perplexity3.305485725402832
INFO:root:current mean train loss 1497.6089469061958
INFO:root:current train perplexity3.310490369796753
INFO:root:current mean train loss 1513.6001221703702
INFO:root:current train perplexity3.3251545429229736
INFO:root:current mean train loss 1514.726413460665
INFO:root:current train perplexity3.316256046295166
INFO:root:current mean train loss 1518.6123022131019
INFO:root:current train perplexity3.3220791816711426
INFO:root:current mean train loss 1522.9592608283547
INFO:root:current train perplexity3.326307773590088
INFO:root:current mean train loss 1525.7257343552867
INFO:root:current train perplexity3.325422525405884
INFO:root:current mean train loss 1523.3651547995946
INFO:root:current train perplexity3.321406126022339
INFO:root:current mean train loss 1524.748620055863
INFO:root:current train perplexity3.322967529296875
INFO:root:current mean train loss 1523.5102360612254
INFO:root:current train perplexity3.321812629699707
INFO:root:current mean train loss 1522.2128361376765
INFO:root:current train perplexity3.3232650756835938
INFO:root:current mean train loss 1522.5223247821514
INFO:root:current train perplexity3.322826862335205
INFO:root:current mean train loss 1522.15133745494
INFO:root:current train perplexity3.322064161300659
INFO:root:current mean train loss 1521.1320984250024
INFO:root:current train perplexity3.32140851020813
INFO:root:current mean train loss 1521.9461729942595
INFO:root:current train perplexity3.3222343921661377
INFO:root:current mean train loss 1522.2273496321445
INFO:root:current train perplexity3.3222386837005615
INFO:root:current mean train loss 1522.472715725864
INFO:root:current train perplexity3.321816921234131
INFO:root:current mean train loss 1522.3312797196415
INFO:root:current train perplexity3.3204712867736816
INFO:root:current mean train loss 1522.4565644833117
INFO:root:current train perplexity3.321183919906616
INFO:root:current mean train loss 1522.8046558521412
INFO:root:current train perplexity3.321071147918701

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.58s/it]
INFO:root:final mean train loss: 1521.938729875327
INFO:root:final train perplexity: 3.3210880756378174
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.91s/it]
INFO:root:eval mean loss: 3329.1150510862426
INFO:root:eval perplexity: 15.360230445861816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/86
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [7:11:13<1:10:20, 301.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1514.4509297355276
INFO:root:current train perplexity3.300737142562866
INFO:root:current mean train loss 1501.6634149966033
INFO:root:current train perplexity3.293339729309082
INFO:root:current mean train loss 1505.926512268768
INFO:root:current train perplexity3.2934508323669434
INFO:root:current mean train loss 1509.7843196794927
INFO:root:current train perplexity3.2992279529571533
INFO:root:current mean train loss 1511.3958316563007
INFO:root:current train perplexity3.307180643081665
INFO:root:current mean train loss 1512.9688746814422
INFO:root:current train perplexity3.3130507469177246
INFO:root:current mean train loss 1513.6521967485344
INFO:root:current train perplexity3.3122482299804688
INFO:root:current mean train loss 1514.6837876829932
INFO:root:current train perplexity3.3131890296936035
INFO:root:current mean train loss 1516.517966594984
INFO:root:current train perplexity3.3149852752685547
INFO:root:current mean train loss 1516.7125377516097
INFO:root:current train perplexity3.313100814819336
INFO:root:current mean train loss 1518.3520625165675
INFO:root:current train perplexity3.3174378871917725
INFO:root:current mean train loss 1519.1198908159386
INFO:root:current train perplexity3.3167130947113037
INFO:root:current mean train loss 1518.509825546906
INFO:root:current train perplexity3.314054012298584
INFO:root:current mean train loss 1519.063094386452
INFO:root:current train perplexity3.315382480621338
INFO:root:current mean train loss 1520.1820052484386
INFO:root:current train perplexity3.3190770149230957
INFO:root:current mean train loss 1520.6120318474486
INFO:root:current train perplexity3.3189144134521484
INFO:root:current mean train loss 1520.3292068031305
INFO:root:current train perplexity3.3174374103546143
INFO:root:current mean train loss 1520.4544834394742
INFO:root:current train perplexity3.317552089691162
INFO:root:current mean train loss 1520.9927108084112
INFO:root:current train perplexity3.317840814590454
INFO:root:current mean train loss 1521.50295614333
INFO:root:current train perplexity3.3189096450805664

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.63s/it]
INFO:root:final mean train loss: 1521.1356478184687
INFO:root:final train perplexity: 3.3189852237701416
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.75s/it]
INFO:root:eval mean loss: 3331.34436511707
INFO:root:eval perplexity: 15.388359069824219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/87
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [7:16:14<1:05:16, 301.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1522.2427978515625
INFO:root:current train perplexity3.317976236343384
INFO:root:current mean train loss 1518.5909835301088
INFO:root:current train perplexity3.2964603900909424
INFO:root:current mean train loss 1522.082668825877
INFO:root:current train perplexity3.303058624267578
INFO:root:current mean train loss 1523.9763871450273
INFO:root:current train perplexity3.3119075298309326
INFO:root:current mean train loss 1524.3869049199955
INFO:root:current train perplexity3.3133912086486816
INFO:root:current mean train loss 1523.033870076638
INFO:root:current train perplexity3.314052104949951
INFO:root:current mean train loss 1521.4176149621474
INFO:root:current train perplexity3.311962842941284
INFO:root:current mean train loss 1519.0937586296493
INFO:root:current train perplexity3.3107197284698486
INFO:root:current mean train loss 1517.9028328654435
INFO:root:current train perplexity3.308359384536743
INFO:root:current mean train loss 1516.9096720876869
INFO:root:current train perplexity3.3073832988739014
INFO:root:current mean train loss 1517.7047942379188
INFO:root:current train perplexity3.307917594909668
INFO:root:current mean train loss 1518.1739019060378
INFO:root:current train perplexity3.3065803050994873
INFO:root:current mean train loss 1518.2851912091037
INFO:root:current train perplexity3.3063528537750244
INFO:root:current mean train loss 1517.0339559214556
INFO:root:current train perplexity3.305849552154541
INFO:root:current mean train loss 1517.722055561649
INFO:root:current train perplexity3.3088178634643555
INFO:root:current mean train loss 1518.2311965304182
INFO:root:current train perplexity3.3096542358398438
INFO:root:current mean train loss 1519.4955602925497
INFO:root:current train perplexity3.312390089035034
INFO:root:current mean train loss 1519.0275934517585
INFO:root:current train perplexity3.3127493858337402
INFO:root:current mean train loss 1519.2318334284935
INFO:root:current train perplexity3.3133084774017334
INFO:root:current mean train loss 1519.2450634963109
INFO:root:current train perplexity3.313117504119873

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.48s/it]
INFO:root:final mean train loss: 1518.89607587344
INFO:root:final train perplexity: 3.3131279945373535
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it]
INFO:root:eval mean loss: 3336.1186706726257
INFO:root:eval perplexity: 15.44876480102539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/88
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [7:21:15<1:00:16, 301.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1538.3034102590461
INFO:root:current train perplexity3.3433752059936523
INFO:root:current mean train loss 1527.8647241836939
INFO:root:current train perplexity3.3184974193573
INFO:root:current mean train loss 1523.54135121491
INFO:root:current train perplexity3.3154475688934326
INFO:root:current mean train loss 1519.4520934285997
INFO:root:current train perplexity3.3095433712005615
INFO:root:current mean train loss 1517.6455968375158
INFO:root:current train perplexity3.3035147190093994
INFO:root:current mean train loss 1515.6337609555542
INFO:root:current train perplexity3.299792528152466
INFO:root:current mean train loss 1516.7829199921314
INFO:root:current train perplexity3.3058767318725586
INFO:root:current mean train loss 1519.0168741094242
INFO:root:current train perplexity3.3091931343078613
INFO:root:current mean train loss 1518.9849422518766
INFO:root:current train perplexity3.3119027614593506
INFO:root:current mean train loss 1518.0984719741284
INFO:root:current train perplexity3.3093159198760986
INFO:root:current mean train loss 1518.8031342528182
INFO:root:current train perplexity3.3102433681488037
INFO:root:current mean train loss 1517.5170488812435
INFO:root:current train perplexity3.3070569038391113
INFO:root:current mean train loss 1517.5761125837053
INFO:root:current train perplexity3.3070695400238037
INFO:root:current mean train loss 1516.0557801824316
INFO:root:current train perplexity3.3067426681518555
INFO:root:current mean train loss 1516.771865201714
INFO:root:current train perplexity3.3055472373962402
INFO:root:current mean train loss 1516.7778845329644
INFO:root:current train perplexity3.306102991104126
INFO:root:current mean train loss 1516.9839960418972
INFO:root:current train perplexity3.307008743286133
INFO:root:current mean train loss 1517.6699877045612
INFO:root:current train perplexity3.309694528579712
INFO:root:current mean train loss 1518.390506086123
INFO:root:current train perplexity3.311169385910034

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.15s/it]
INFO:root:final mean train loss: 1518.3477968186126
INFO:root:final train perplexity: 3.3116958141326904
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it]
INFO:root:eval mean loss: 3335.6376278622374
INFO:root:eval perplexity: 15.442662239074707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/89
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [7:26:17<55:14, 301.36s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1506.959208170573
INFO:root:current train perplexity3.2930750846862793
INFO:root:current mean train loss 1525.8120912824359
INFO:root:current train perplexity3.322221040725708
INFO:root:current mean train loss 1516.433672059257
INFO:root:current train perplexity3.309518575668335
INFO:root:current mean train loss 1514.6483991574019
INFO:root:current train perplexity3.307720899581909
INFO:root:current mean train loss 1517.078399361916
INFO:root:current train perplexity3.3129827976226807
INFO:root:current mean train loss 1515.6593339443207
INFO:root:current train perplexity3.3091275691986084
INFO:root:current mean train loss 1513.6665936638328
INFO:root:current train perplexity3.3063716888427734
INFO:root:current mean train loss 1513.2285590011081
INFO:root:current train perplexity3.3050150871276855
INFO:root:current mean train loss 1512.3030810426608
INFO:root:current train perplexity3.300506114959717
INFO:root:current mean train loss 1511.9077875237715
INFO:root:current train perplexity3.299100160598755
INFO:root:current mean train loss 1513.2311952613559
INFO:root:current train perplexity3.300001382827759
INFO:root:current mean train loss 1513.7393601232295
INFO:root:current train perplexity3.3032889366149902
INFO:root:current mean train loss 1513.9223789932705
INFO:root:current train perplexity3.3044614791870117
INFO:root:current mean train loss 1515.4759420999667
INFO:root:current train perplexity3.305046558380127
INFO:root:current mean train loss 1516.6425261673103
INFO:root:current train perplexity3.3058369159698486
INFO:root:current mean train loss 1516.6753075816644
INFO:root:current train perplexity3.3061211109161377
INFO:root:current mean train loss 1515.883296692046
INFO:root:current train perplexity3.3056812286376953
INFO:root:current mean train loss 1516.5123980513242
INFO:root:current train perplexity3.307436227798462
INFO:root:current mean train loss 1516.421886385145
INFO:root:current train perplexity3.306835651397705
INFO:root:current mean train loss 1517.4372692028348
INFO:root:current train perplexity3.3085246086120605

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.83s/it]
INFO:root:final mean train loss: 1517.1854256049467
INFO:root:final train perplexity: 3.3086609840393066
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it]
INFO:root:eval mean loss: 3335.696235542183
INFO:root:eval perplexity: 15.443406105041504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/90
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [7:31:18<50:12, 301.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1495.799594221444
INFO:root:current train perplexity3.3162097930908203
INFO:root:current mean train loss 1511.1902934229652
INFO:root:current train perplexity3.2973222732543945
INFO:root:current mean train loss 1519.8153236089315
INFO:root:current train perplexity3.305809259414673
INFO:root:current mean train loss 1520.7469538077032
INFO:root:current train perplexity3.306225538253784
INFO:root:current mean train loss 1522.4476571605478
INFO:root:current train perplexity3.3031625747680664
INFO:root:current mean train loss 1520.4721301246454
INFO:root:current train perplexity3.304187297821045
INFO:root:current mean train loss 1520.600554304017
INFO:root:current train perplexity3.3061747550964355
INFO:root:current mean train loss 1519.7711617007994
INFO:root:current train perplexity3.30122709274292
INFO:root:current mean train loss 1519.7864302576522
INFO:root:current train perplexity3.302651882171631
INFO:root:current mean train loss 1518.1463182857913
INFO:root:current train perplexity3.30159854888916
INFO:root:current mean train loss 1518.3117857285213
INFO:root:current train perplexity3.302271604537964
INFO:root:current mean train loss 1516.5298906838186
INFO:root:current train perplexity3.3012642860412598
INFO:root:current mean train loss 1516.7659727365046
INFO:root:current train perplexity3.3021562099456787
INFO:root:current mean train loss 1515.7551951067533
INFO:root:current train perplexity3.302231788635254
INFO:root:current mean train loss 1515.4884529514193
INFO:root:current train perplexity3.304035186767578
INFO:root:current mean train loss 1515.9629517799112
INFO:root:current train perplexity3.3056094646453857
INFO:root:current mean train loss 1515.682745927093
INFO:root:current train perplexity3.304708957672119
INFO:root:current mean train loss 1516.1035065879844
INFO:root:current train perplexity3.3057148456573486
INFO:root:current mean train loss 1516.7880177943678
INFO:root:current train perplexity3.3060853481292725
INFO:root:current mean train loss 1516.3994305157303
INFO:root:current train perplexity3.3051528930664062

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.40s/it]
INFO:root:final mean train loss: 1515.7774061086618
INFO:root:final train perplexity: 3.304989814758301
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.58s/it]
INFO:root:eval mean loss: 3331.8450557491083
INFO:root:eval perplexity: 15.394678115844727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/91
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [7:36:20<45:14, 301.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1524.8902481742527
INFO:root:current train perplexity3.340257406234741
INFO:root:current mean train loss 1512.5606145989404
INFO:root:current train perplexity3.3024086952209473
INFO:root:current mean train loss 1515.2947352959857
INFO:root:current train perplexity3.306093454360962
INFO:root:current mean train loss 1513.6183926797326
INFO:root:current train perplexity3.301844596862793
INFO:root:current mean train loss 1514.5208258521932
INFO:root:current train perplexity3.3064465522766113
INFO:root:current mean train loss 1514.7511225550165
INFO:root:current train perplexity3.306164026260376
INFO:root:current mean train loss 1514.49559072961
INFO:root:current train perplexity3.3048062324523926
INFO:root:current mean train loss 1513.0846955245686
INFO:root:current train perplexity3.302700996398926
INFO:root:current mean train loss 1511.7210269143395
INFO:root:current train perplexity3.302192449569702
INFO:root:current mean train loss 1513.025899294315
INFO:root:current train perplexity3.303644895553589
INFO:root:current mean train loss 1514.550537926289
INFO:root:current train perplexity3.3058440685272217
INFO:root:current mean train loss 1514.767220009476
INFO:root:current train perplexity3.305642604827881
INFO:root:current mean train loss 1514.7485830634594
INFO:root:current train perplexity3.303035020828247
INFO:root:current mean train loss 1514.8693121219992
INFO:root:current train perplexity3.3045480251312256
INFO:root:current mean train loss 1515.3030029972228
INFO:root:current train perplexity3.3036413192749023
INFO:root:current mean train loss 1515.4925833994482
INFO:root:current train perplexity3.304049491882324
INFO:root:current mean train loss 1515.1926612900354
INFO:root:current train perplexity3.3040730953216553
INFO:root:current mean train loss 1515.4293431722285
INFO:root:current train perplexity3.304619789123535
INFO:root:current mean train loss 1515.1390294894366
INFO:root:current train perplexity3.30328106880188
INFO:root:current mean train loss 1514.9472010143002
INFO:root:current train perplexity3.302399158477783

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.01s/it]
INFO:root:final mean train loss: 1514.8165810143053
INFO:root:final train perplexity: 3.3024861812591553
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it]
INFO:root:eval mean loss: 3334.428248316676
INFO:root:eval perplexity: 15.427346229553223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/92
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [7:41:21<40:11, 301.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1509.8015524243551
INFO:root:current train perplexity3.2883379459381104
INFO:root:current mean train loss 1511.3988478958972
INFO:root:current train perplexity3.279744863510132
INFO:root:current mean train loss 1513.7571924013782
INFO:root:current train perplexity3.2999281883239746
INFO:root:current mean train loss 1511.7343985397297
INFO:root:current train perplexity3.301213502883911
INFO:root:current mean train loss 1517.5864445004556
INFO:root:current train perplexity3.3085851669311523
INFO:root:current mean train loss 1517.0076568224079
INFO:root:current train perplexity3.3068175315856934
INFO:root:current mean train loss 1516.3195824716606
INFO:root:current train perplexity3.3042373657226562
INFO:root:current mean train loss 1517.4940023959698
INFO:root:current train perplexity3.302354335784912
INFO:root:current mean train loss 1517.7994930757984
INFO:root:current train perplexity3.305976390838623
INFO:root:current mean train loss 1517.7857745874708
INFO:root:current train perplexity3.306166887283325
INFO:root:current mean train loss 1517.5763254102849
INFO:root:current train perplexity3.3058888912200928
INFO:root:current mean train loss 1516.087196304177
INFO:root:current train perplexity3.3032047748565674
INFO:root:current mean train loss 1515.2690916808938
INFO:root:current train perplexity3.3013010025024414
INFO:root:current mean train loss 1514.6611044219724
INFO:root:current train perplexity3.298797845840454
INFO:root:current mean train loss 1513.737471397332
INFO:root:current train perplexity3.2986719608306885
INFO:root:current mean train loss 1514.1829257606316
INFO:root:current train perplexity3.2999935150146484
INFO:root:current mean train loss 1513.8091349553001
INFO:root:current train perplexity3.298663377761841
INFO:root:current mean train loss 1513.3561004967562
INFO:root:current train perplexity3.297844409942627
INFO:root:current mean train loss 1513.2147033986262
INFO:root:current train perplexity3.297200918197632
INFO:root:current mean train loss 1514.2918248460783
INFO:root:current train perplexity3.299647808074951

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.86s/it]
INFO:root:final mean train loss: 1513.7621751439974
INFO:root:final train perplexity: 3.2997405529022217
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it]
INFO:root:eval mean loss: 3336.389019390484
INFO:root:eval perplexity: 15.452186584472656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/93
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [7:46:22<35:08, 301.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1497.4276062011718
INFO:root:current train perplexity3.276880979537964
INFO:root:current mean train loss 1507.9500155978733
INFO:root:current train perplexity3.279580593109131
INFO:root:current mean train loss 1512.990745326451
INFO:root:current train perplexity3.2858495712280273
INFO:root:current mean train loss 1513.0404839766652
INFO:root:current train perplexity3.2975919246673584
INFO:root:current mean train loss 1511.971155802409
INFO:root:current train perplexity3.2953555583953857
INFO:root:current mean train loss 1511.8993517645474
INFO:root:current train perplexity3.2959468364715576
INFO:root:current mean train loss 1511.7014438404756
INFO:root:current train perplexity3.295297384262085
INFO:root:current mean train loss 1511.789429336939
INFO:root:current train perplexity3.297215700149536
INFO:root:current mean train loss 1511.2808223377574
INFO:root:current train perplexity3.295210599899292
INFO:root:current mean train loss 1511.2551123794244
INFO:root:current train perplexity3.2955968379974365
INFO:root:current mean train loss 1511.2739035147208
INFO:root:current train perplexity3.2955126762390137
INFO:root:current mean train loss 1510.633266849841
INFO:root:current train perplexity3.295255422592163
INFO:root:current mean train loss 1511.9835876464845
INFO:root:current train perplexity3.297938585281372
INFO:root:current mean train loss 1512.6650090756623
INFO:root:current train perplexity3.2975592613220215
INFO:root:current mean train loss 1514.3089336498363
INFO:root:current train perplexity3.299344778060913
INFO:root:current mean train loss 1514.569208768048
INFO:root:current train perplexity3.2994022369384766
INFO:root:current mean train loss 1513.9611703055245
INFO:root:current train perplexity3.2992048263549805
INFO:root:current mean train loss 1514.1848547088966
INFO:root:current train perplexity3.2989461421966553
INFO:root:current mean train loss 1513.337793098612
INFO:root:current train perplexity3.2975399494171143
INFO:root:current mean train loss 1513.412335020123
INFO:root:current train perplexity3.2978477478027344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.80s/it]
INFO:root:final mean train loss: 1513.002284247648
INFO:root:final train perplexity: 3.2977638244628906
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.10s/it]
INFO:root:eval mean loss: 3337.2328265765764
INFO:root:eval perplexity: 15.462888717651367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/94
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [7:51:22<30:05, 300.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1516.68580485865
INFO:root:current train perplexity3.317350387573242
INFO:root:current mean train loss 1519.7940475541322
INFO:root:current train perplexity3.3204290866851807
INFO:root:current mean train loss 1519.1832517887206
INFO:root:current train perplexity3.3081676959991455
INFO:root:current mean train loss 1516.9149760287114
INFO:root:current train perplexity3.307746410369873
INFO:root:current mean train loss 1516.5340686698314
INFO:root:current train perplexity3.3052361011505127
INFO:root:current mean train loss 1517.8322731414232
INFO:root:current train perplexity3.301212787628174
INFO:root:current mean train loss 1516.1283060563687
INFO:root:current train perplexity3.2967259883880615
INFO:root:current mean train loss 1514.0732075728317
INFO:root:current train perplexity3.2960610389709473
INFO:root:current mean train loss 1514.1575221441262
INFO:root:current train perplexity3.2950997352600098
INFO:root:current mean train loss 1514.5561001853216
INFO:root:current train perplexity3.2972030639648438
INFO:root:current mean train loss 1515.1745106950063
INFO:root:current train perplexity3.300062417984009
INFO:root:current mean train loss 1514.7239480333321
INFO:root:current train perplexity3.2997829914093018
INFO:root:current mean train loss 1514.6338044977592
INFO:root:current train perplexity3.300306558609009
INFO:root:current mean train loss 1514.2234269444568
INFO:root:current train perplexity3.2981371879577637
INFO:root:current mean train loss 1514.1368894201162
INFO:root:current train perplexity3.298595666885376
INFO:root:current mean train loss 1513.8852465682726
INFO:root:current train perplexity3.297802686691284
INFO:root:current mean train loss 1513.320536715182
INFO:root:current train perplexity3.297268867492676
INFO:root:current mean train loss 1513.0617001915084
INFO:root:current train perplexity3.2973532676696777
INFO:root:current mean train loss 1513.3223625348
INFO:root:current train perplexity3.2983267307281494

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.03s/it]
INFO:root:final mean train loss: 1512.3187140129578
INFO:root:final train perplexity: 3.2959861755371094
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.84s/it]
INFO:root:eval mean loss: 3335.430663329345
INFO:root:eval perplexity: 15.440041542053223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/95
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [7:56:23<25:03, 300.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1474.283211844308
INFO:root:current train perplexity3.2158102989196777
INFO:root:current mean train loss 1499.28612317537
INFO:root:current train perplexity3.2595090866088867
INFO:root:current mean train loss 1505.2145111939617
INFO:root:current train perplexity3.2641713619232178
INFO:root:current mean train loss 1505.3479847513186
INFO:root:current train perplexity3.269399881362915
INFO:root:current mean train loss 1504.0101766540233
INFO:root:current train perplexity3.2681424617767334
INFO:root:current mean train loss 1506.676107087488
INFO:root:current train perplexity3.275855779647827
INFO:root:current mean train loss 1507.5413019136809
INFO:root:current train perplexity3.28208589553833
INFO:root:current mean train loss 1509.5487248610382
INFO:root:current train perplexity3.282616138458252
INFO:root:current mean train loss 1509.6973061151527
INFO:root:current train perplexity3.2848434448242188
INFO:root:current mean train loss 1510.294027983751
INFO:root:current train perplexity3.2856502532958984
INFO:root:current mean train loss 1510.3501308824889
INFO:root:current train perplexity3.2843387126922607
INFO:root:current mean train loss 1511.319206415858
INFO:root:current train perplexity3.2862131595611572
INFO:root:current mean train loss 1511.32655688919
INFO:root:current train perplexity3.2873728275299072
INFO:root:current mean train loss 1510.8338288607663
INFO:root:current train perplexity3.287750244140625
INFO:root:current mean train loss 1510.6467128036045
INFO:root:current train perplexity3.2889695167541504
INFO:root:current mean train loss 1511.3437440335515
INFO:root:current train perplexity3.288731575012207
INFO:root:current mean train loss 1511.4457613012605
INFO:root:current train perplexity3.2905125617980957
INFO:root:current mean train loss 1511.9346985789136
INFO:root:current train perplexity3.2910614013671875
INFO:root:current mean train loss 1512.0192427629936
INFO:root:current train perplexity3.2906649112701416
INFO:root:current mean train loss 1512.0940132101252
INFO:root:current train perplexity3.2916481494903564

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.98s/it]
INFO:root:final mean train loss: 1510.488503537392
INFO:root:final train perplexity: 3.2912325859069824
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.68s/it]
INFO:root:eval mean loss: 3336.0242256416573
INFO:root:eval perplexity: 15.44756031036377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/96
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [8:01:24<20:03, 300.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1537.3617888419858
INFO:root:current train perplexity3.359158754348755
INFO:root:current mean train loss 1518.4692587816078
INFO:root:current train perplexity3.3274989128112793
INFO:root:current mean train loss 1516.1557638325216
INFO:root:current train perplexity3.313961982727051
INFO:root:current mean train loss 1515.612839436603
INFO:root:current train perplexity3.305239677429199
INFO:root:current mean train loss 1519.4236222198558
INFO:root:current train perplexity3.309216022491455
INFO:root:current mean train loss 1517.1685719750471
INFO:root:current train perplexity3.3033881187438965
INFO:root:current mean train loss 1515.6686638349966
INFO:root:current train perplexity3.2985599040985107
INFO:root:current mean train loss 1515.834761884405
INFO:root:current train perplexity3.2988014221191406
INFO:root:current mean train loss 1514.7922897981537
INFO:root:current train perplexity3.29756760597229
INFO:root:current mean train loss 1513.2376826990048
INFO:root:current train perplexity3.295255661010742
INFO:root:current mean train loss 1511.6458717738392
INFO:root:current train perplexity3.292846202850342
INFO:root:current mean train loss 1511.5530655082614
INFO:root:current train perplexity3.292546033859253
INFO:root:current mean train loss 1512.0003950675264
INFO:root:current train perplexity3.2929487228393555
INFO:root:current mean train loss 1511.698090310387
INFO:root:current train perplexity3.291713237762451
INFO:root:current mean train loss 1510.175328540602
INFO:root:current train perplexity3.290968179702759
INFO:root:current mean train loss 1510.0010433782556
INFO:root:current train perplexity3.29172682762146
INFO:root:current mean train loss 1511.6778303248104
INFO:root:current train perplexity3.294536590576172
INFO:root:current mean train loss 1511.7490531264668
INFO:root:current train perplexity3.2935001850128174
INFO:root:current mean train loss 1511.2160977207852
INFO:root:current train perplexity3.293081045150757
INFO:root:current mean train loss 1511.057604291413
INFO:root:current train perplexity3.292114734649658

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.89s/it]
INFO:root:final mean train loss: 1510.5914456227542
INFO:root:final train perplexity: 3.291499614715576
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.68s/it]
INFO:root:eval mean loss: 3336.6501083603134
INFO:root:eval perplexity: 15.455498695373535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/97
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [8:06:25<15:02, 300.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1514.2018508911133
INFO:root:current train perplexity3.3076860904693604
INFO:root:current mean train loss 1510.9238470953865
INFO:root:current train perplexity3.3123648166656494
INFO:root:current mean train loss 1513.2024472144342
INFO:root:current train perplexity3.312338352203369
INFO:root:current mean train loss 1510.9900449555496
INFO:root:current train perplexity3.299513578414917
INFO:root:current mean train loss 1513.830537523542
INFO:root:current train perplexity3.300161838531494
INFO:root:current mean train loss 1514.0697502637431
INFO:root:current train perplexity3.29256010055542
INFO:root:current mean train loss 1515.139264518832
INFO:root:current train perplexity3.293048858642578
INFO:root:current mean train loss 1514.6035262327143
INFO:root:current train perplexity3.290931224822998
INFO:root:current mean train loss 1512.3386758768333
INFO:root:current train perplexity3.290600538253784
INFO:root:current mean train loss 1512.4814912820163
INFO:root:current train perplexity3.291208267211914
INFO:root:current mean train loss 1512.303641632313
INFO:root:current train perplexity3.2919952869415283
INFO:root:current mean train loss 1510.5414906146218
INFO:root:current train perplexity3.291675090789795
INFO:root:current mean train loss 1511.279948210105
INFO:root:current train perplexity3.2915115356445312
INFO:root:current mean train loss 1511.8959631311434
INFO:root:current train perplexity3.2914769649505615
INFO:root:current mean train loss 1511.6107792301073
INFO:root:current train perplexity3.291461944580078
INFO:root:current mean train loss 1510.7398772325935
INFO:root:current train perplexity3.2897043228149414
INFO:root:current mean train loss 1510.7439093728667
INFO:root:current train perplexity3.288944721221924
INFO:root:current mean train loss 1510.3937300413643
INFO:root:current train perplexity3.288334846496582
INFO:root:current mean train loss 1509.77717676204
INFO:root:current train perplexity3.2887327671051025
INFO:root:current mean train loss 1509.3647074924602
INFO:root:current train perplexity3.2882814407348633

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.06s/it]
INFO:root:final mean train loss: 1509.3019777298935
INFO:root:final train perplexity: 3.288154125213623
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it]
INFO:root:eval mean loss: 3338.1054342917137
INFO:root:eval perplexity: 15.473963737487793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/98
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [8:11:25<10:01, 300.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1514.2194673978365
INFO:root:current train perplexity3.27650785446167
INFO:root:current mean train loss 1505.0303296638258
INFO:root:current train perplexity3.279991865158081
INFO:root:current mean train loss 1505.5564946012678
INFO:root:current train perplexity3.285261631011963
INFO:root:current mean train loss 1506.4531938944776
INFO:root:current train perplexity3.289389133453369
INFO:root:current mean train loss 1510.0119040868615
INFO:root:current train perplexity3.2921481132507324
INFO:root:current mean train loss 1512.9524984444138
INFO:root:current train perplexity3.2910547256469727
INFO:root:current mean train loss 1512.1974304658129
INFO:root:current train perplexity3.287588119506836
INFO:root:current mean train loss 1513.0974909364788
INFO:root:current train perplexity3.2888376712799072
INFO:root:current mean train loss 1513.0028004199783
INFO:root:current train perplexity3.289761543273926
INFO:root:current mean train loss 1512.764973157181
INFO:root:current train perplexity3.2898552417755127
INFO:root:current mean train loss 1511.9916545169453
INFO:root:current train perplexity3.2872776985168457
INFO:root:current mean train loss 1511.219914749866
INFO:root:current train perplexity3.2881674766540527
INFO:root:current mean train loss 1511.1740978376667
INFO:root:current train perplexity3.2884652614593506
INFO:root:current mean train loss 1511.371243364383
INFO:root:current train perplexity3.2894387245178223
INFO:root:current mean train loss 1510.2466815206378
INFO:root:current train perplexity3.287978410720825
INFO:root:current mean train loss 1509.9885583067094
INFO:root:current train perplexity3.2879819869995117
INFO:root:current mean train loss 1509.5690085837791
INFO:root:current train perplexity3.2867462635040283
INFO:root:current mean train loss 1509.7217750614157
INFO:root:current train perplexity3.2866201400756836
INFO:root:current mean train loss 1509.3365505351458
INFO:root:current train perplexity3.286231279373169
INFO:root:current mean train loss 1509.5217833696126
INFO:root:current train perplexity3.2872314453125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.44s/it]
INFO:root:final mean train loss: 1509.0493932003574
INFO:root:final train perplexity: 3.287499189376831
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.79s/it]
INFO:root:eval mean loss: 3337.985935887059
INFO:root:eval perplexity: 15.472447395324707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/99
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [8:16:27<05:01, 301.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1505.7400855087653
INFO:root:current train perplexity3.257798671722412
INFO:root:current mean train loss 1499.3652813251201
INFO:root:current train perplexity3.2628228664398193
INFO:root:current mean train loss 1503.8805741113974
INFO:root:current train perplexity3.2711472511291504
INFO:root:current mean train loss 1505.838257794605
INFO:root:current train perplexity3.271496534347534
INFO:root:current mean train loss 1508.5299039342096
INFO:root:current train perplexity3.27771258354187
INFO:root:current mean train loss 1508.302123394209
INFO:root:current train perplexity3.2819106578826904
INFO:root:current mean train loss 1509.475399073268
INFO:root:current train perplexity3.2846884727478027
INFO:root:current mean train loss 1510.0256433511329
INFO:root:current train perplexity3.2860941886901855
INFO:root:current mean train loss 1509.360519997387
INFO:root:current train perplexity3.2853877544403076
INFO:root:current mean train loss 1509.9412652848937
INFO:root:current train perplexity3.2866034507751465
INFO:root:current mean train loss 1509.7904844724758
INFO:root:current train perplexity3.2862906455993652
INFO:root:current mean train loss 1509.4211926661974
INFO:root:current train perplexity3.2847635746002197
INFO:root:current mean train loss 1509.4486185868334
INFO:root:current train perplexity3.284933567047119
INFO:root:current mean train loss 1509.544083900286
INFO:root:current train perplexity3.2853548526763916
INFO:root:current mean train loss 1511.0858559550545
INFO:root:current train perplexity3.2877018451690674
INFO:root:current mean train loss 1509.3139805076396
INFO:root:current train perplexity3.2855064868927
INFO:root:current mean train loss 1507.9740790005387
INFO:root:current train perplexity3.284161329269409
INFO:root:current mean train loss 1507.5835437710439
INFO:root:current train perplexity3.2834420204162598
INFO:root:current mean train loss 1508.5950921248173
INFO:root:current train perplexity3.2858097553253174
INFO:root:current mean train loss 1509.3992053974048
INFO:root:current train perplexity3.287336587905884

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.31s/it]
INFO:root:final mean train loss: 1508.9404098656944
INFO:root:final train perplexity: 3.2872166633605957
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it]
INFO:root:eval mean loss: 3337.8743518909537
INFO:root:eval perplexity: 15.471038818359375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_33/100
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [8:21:27<00:00, 300.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [8:21:27<00:00, 300.88s/it]
INFO:root:evaluating final model
INFO:root:start evaluating
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.19s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.19s/it]
INFO:root:eval mean loss: 3337.8743518909537
INFO:root:eval perplexity: 15.471038818359375
INFO:root:evalaution complete
INFO:root:save model final: pld_33/final
