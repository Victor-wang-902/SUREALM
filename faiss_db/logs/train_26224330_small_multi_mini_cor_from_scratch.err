INFO:root:Output: small_multiqa_minilm_corrected_from_scratch
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24879.7116082702
INFO:root:current train perplexity17277.759765625
INFO:root:current mean train loss 24011.10670540201
INFO:root:current train perplexity12429.9375
INFO:root:current mean train loss 23057.515892819814
INFO:root:current train perplexity8685.7490234375
INFO:root:current mean train loss 22045.93427905702
INFO:root:current train perplexity5889.23583984375
INFO:root:current mean train loss 20960.388908676727
INFO:root:current train perplexity3881.315185546875
INFO:root:current mean train loss 19875.790017868323
INFO:root:current train perplexity2533.2294921875
INFO:root:current mean train loss 18867.92386305213
INFO:root:current train perplexity1703.46337890625
INFO:root:current mean train loss 17991.897178602158
INFO:root:current train perplexity1200.9560546875
INFO:root:current mean train loss 17232.152008090587
INFO:root:current train perplexity890.184326171875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.66s/it]
INFO:root:final mean train loss: 16598.944117146155
INFO:root:final train perplexity: 698.3802490234375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.01s/it]
INFO:root:eval mean loss: 9950.253566877216
INFO:root:eval perplexity: 55.90146255493164
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.10s/it]
INFO:root:eval mean loss: 10243.365743434175
INFO:root:eval perplexity: 65.93391418457031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/1
  0%|          | 1/200 [07:05<23:32:25, 425.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10394.603934151786
INFO:root:current train perplexity60.63248062133789
INFO:root:current mean train loss 10133.642039646613
INFO:root:current train perplexity55.27873229980469
INFO:root:current mean train loss 9968.751023739433
INFO:root:current train perplexity51.16575622558594
INFO:root:current mean train loss 9804.162586522802
INFO:root:current train perplexity47.75049591064453
INFO:root:current mean train loss 9636.220763110412
INFO:root:current train perplexity44.79926681518555
INFO:root:current mean train loss 9494.443779277613
INFO:root:current train perplexity42.36387252807617
INFO:root:current mean train loss 9358.770490919738
INFO:root:current train perplexity40.141204833984375
INFO:root:current mean train loss 9245.946780796941
INFO:root:current train perplexity38.24956130981445
INFO:root:current mean train loss 9124.482265165156
INFO:root:current train perplexity36.54063415527344
INFO:root:current mean train loss 9018.568425053403
INFO:root:current train perplexity34.999977111816406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.33s/it]
INFO:root:final mean train loss: 8926.869387595883
INFO:root:final train perplexity: 33.848968505859375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.54s/it]
INFO:root:eval mean loss: 7583.66513948914
INFO:root:eval perplexity: 21.469032287597656
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.48s/it]
INFO:root:eval mean loss: 8048.126485621676
INFO:root:eval perplexity: 26.869441986083984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/2
  1%|          | 2/200 [14:16<23:35:33, 428.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7976.143912760416
INFO:root:current train perplexity22.701478958129883
INFO:root:current mean train loss 7918.040824558424
INFO:root:current train perplexity22.411117553710938
INFO:root:current mean train loss 7854.554008448401
INFO:root:current train perplexity21.828956604003906
INFO:root:current mean train loss 7764.577757626488
INFO:root:current train perplexity21.26287269592285
INFO:root:current mean train loss 7703.009652673193
INFO:root:current train perplexity20.774904251098633
INFO:root:current mean train loss 7647.697110133495
INFO:root:current train perplexity20.339641571044922
INFO:root:current mean train loss 7585.282356770834
INFO:root:current train perplexity19.922683715820312
INFO:root:current mean train loss 7533.136014668925
INFO:root:current train perplexity19.532365798950195
INFO:root:current mean train loss 7497.772079299271
INFO:root:current train perplexity19.20016860961914
INFO:root:current mean train loss 7454.206002924351
INFO:root:current train perplexity18.87362289428711

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:11<00:00, 371.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:11<00:00, 371.59s/it]
INFO:root:final mean train loss: 7413.0130371585965
INFO:root:final train perplexity: 18.627668380737305
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.41s/it]
INFO:root:eval mean loss: 6633.60704787234
INFO:root:eval perplexity: 14.620662689208984
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it]
INFO:root:eval mean loss: 7180.289474595523
INFO:root:eval perplexity: 18.84257698059082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/3
  2%|â–         | 3/200 [21:30<23:35:47, 431.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6987.249299422554
INFO:root:current train perplexity15.556046485900879
INFO:root:current mean train loss 6933.91832999873
INFO:root:current train perplexity15.387764930725098
INFO:root:current mean train loss 6879.974164885791
INFO:root:current train perplexity15.146982192993164
INFO:root:current mean train loss 6838.917840254934
INFO:root:current train perplexity14.919166564941406
INFO:root:current mean train loss 6822.565839474365
INFO:root:current train perplexity14.73253059387207
INFO:root:current mean train loss 6792.349895061544
INFO:root:current train perplexity14.560863494873047
INFO:root:current mean train loss 6758.306580275632
INFO:root:current train perplexity14.377063751220703
INFO:root:current mean train loss 6731.260631429374
INFO:root:current train perplexity14.2262544631958
INFO:root:current mean train loss 6707.038724915515
INFO:root:current train perplexity14.075489044189453
INFO:root:current mean train loss 6672.094911188889
INFO:root:current train perplexity13.900216102600098

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.57s/it]
INFO:root:final mean train loss: 6655.198202194706
INFO:root:final train perplexity: 13.813802719116211
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.01s/it]
INFO:root:eval mean loss: 6080.972046764185
INFO:root:eval perplexity: 11.692720413208008
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.03s/it]
INFO:root:eval mean loss: 6690.416739389406
INFO:root:eval perplexity: 15.422127723693848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/4
  2%|â–         | 4/200 [28:43<23:30:11, 431.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6330.799946446573
INFO:root:current train perplexity12.150725364685059
INFO:root:current mean train loss 6341.451965797948
INFO:root:current train perplexity12.19525146484375
INFO:root:current mean train loss 6347.600363991477
INFO:root:current train perplexity12.18796443939209
INFO:root:current mean train loss 6322.94139887415
INFO:root:current train perplexity12.055261611938477
INFO:root:current mean train loss 6304.899305303799
INFO:root:current train perplexity11.968168258666992
INFO:root:current mean train loss 6272.521568973634
INFO:root:current train perplexity11.827584266662598
INFO:root:current mean train loss 6251.947743072752
INFO:root:current train perplexity11.756224632263184
INFO:root:current mean train loss 6233.762418107686
INFO:root:current train perplexity11.666133880615234
INFO:root:current mean train loss 6212.743305082356
INFO:root:current train perplexity11.577742576599121
INFO:root:current mean train loss 6197.40483078511
INFO:root:current train perplexity11.504379272460938

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.27s/it]
INFO:root:final mean train loss: 6180.679735614407
INFO:root:final train perplexity: 11.45534896850586
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.29s/it]
INFO:root:eval mean loss: 5723.635762965426
INFO:root:eval perplexity: 10.119561195373535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.76s/it]
INFO:root:eval mean loss: 6378.309778091755
INFO:root:eval perplexity: 13.574304580688477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/5
  2%|â–Ž         | 5/200 [35:41<23:07:33, 426.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5960.547688802083
INFO:root:current train perplexity10.404871940612793
INFO:root:current mean train loss 5933.9442762196495
INFO:root:current train perplexity10.415206909179688
INFO:root:current mean train loss 5937.665069707767
INFO:root:current train perplexity10.400410652160645
INFO:root:current mean train loss 5932.831766224189
INFO:root:current train perplexity10.396716117858887
INFO:root:current mean train loss 5926.329055959923
INFO:root:current train perplexity10.341937065124512
INFO:root:current mean train loss 5911.840062978316
INFO:root:current train perplexity10.286332130432129
INFO:root:current mean train loss 5898.169779746186
INFO:root:current train perplexity10.241195678710938
INFO:root:current mean train loss 5885.288795564107
INFO:root:current train perplexity10.179269790649414
INFO:root:current mean train loss 5876.208937816597
INFO:root:current train perplexity10.140068054199219
INFO:root:current mean train loss 5862.632877500167
INFO:root:current train perplexity10.088781356811523

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.11s/it]
INFO:root:final mean train loss: 5851.653171293197
INFO:root:final train perplexity: 10.060797691345215
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.60s/it]
INFO:root:eval mean loss: 5467.891459580009
INFO:root:eval perplexity: 9.125334739685059
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.63s/it]
INFO:root:eval mean loss: 6155.397585605053
INFO:root:eval perplexity: 12.39169692993164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/6
  3%|â–Ž         | 6/200 [42:46<22:57:50, 426.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5763.083101313165
INFO:root:current train perplexity9.565361976623535
INFO:root:current mean train loss 5747.6481319090135
INFO:root:current train perplexity9.540596961975098
INFO:root:current mean train loss 5717.766508650683
INFO:root:current train perplexity9.439090728759766
INFO:root:current mean train loss 5696.288568590147
INFO:root:current train perplexity9.392643928527832
INFO:root:current mean train loss 5686.704104839555
INFO:root:current train perplexity9.362556457519531
INFO:root:current mean train loss 5662.004050859803
INFO:root:current train perplexity9.295694351196289
INFO:root:current mean train loss 5652.606899632921
INFO:root:current train perplexity9.25493335723877
INFO:root:current mean train loss 5636.448976897172
INFO:root:current train perplexity9.213323593139648
INFO:root:current mean train loss 5625.6555438081095
INFO:root:current train perplexity9.178533554077148
INFO:root:current mean train loss 5617.51091749439
INFO:root:current train perplexity9.154914855957031

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.19s/it]
INFO:root:final mean train loss: 5609.622513432657
INFO:root:final train perplexity: 9.14455509185791
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.50s/it]
INFO:root:eval mean loss: 5285.604499113475
INFO:root:eval perplexity: 8.476887702941895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it]
INFO:root:eval mean loss: 6007.43622215758
INFO:root:eval perplexity: 11.664186477661133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/7
  4%|â–Ž         | 7/200 [49:54<22:53:06, 426.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5520.679554332386
INFO:root:current train perplexity8.696100234985352
INFO:root:current mean train loss 5476.5219569052415
INFO:root:current train perplexity8.67858600616455
INFO:root:current mean train loss 5457.32536573223
INFO:root:current train perplexity8.640185356140137
INFO:root:current mean train loss 5453.007736850792
INFO:root:current train perplexity8.609203338623047
INFO:root:current mean train loss 5456.226268458105
INFO:root:current train perplexity8.610825538635254
INFO:root:current mean train loss 5451.537585339245
INFO:root:current train perplexity8.602157592773438
INFO:root:current mean train loss 5440.6620743380245
INFO:root:current train perplexity8.561845779418945
INFO:root:current mean train loss 5431.1937726355545
INFO:root:current train perplexity8.535921096801758
INFO:root:current mean train loss 5429.525790958516
INFO:root:current train perplexity8.522088050842285
INFO:root:current mean train loss 5425.691546343259
INFO:root:current train perplexity8.497712135314941

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:13<00:00, 373.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:13<00:00, 373.22s/it]
INFO:root:final mean train loss: 5422.533498087237
INFO:root:final train perplexity: 8.493884086608887
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.53s/it]
INFO:root:eval mean loss: 5136.326556266622
INFO:root:eval perplexity: 7.9803290367126465
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.71s/it]
INFO:root:eval mean loss: 5873.693979249779
INFO:root:eval perplexity: 11.043411254882812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/8
  4%|â–         | 8/200 [57:11<22:56:03, 430.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5335.809151785715
INFO:root:current train perplexity8.169522285461426
INFO:root:current mean train loss 5342.417576327645
INFO:root:current train perplexity8.17699146270752
INFO:root:current mean train loss 5319.91963967443
INFO:root:current train perplexity8.137150764465332
INFO:root:current mean train loss 5313.306533014807
INFO:root:current train perplexity8.139405250549316
INFO:root:current mean train loss 5319.209539096248
INFO:root:current train perplexity8.127453804016113
INFO:root:current mean train loss 5305.039549913965
INFO:root:current train perplexity8.090155601501465
INFO:root:current mean train loss 5301.846578790771
INFO:root:current train perplexity8.079961776733398
INFO:root:current mean train loss 5292.933761416694
INFO:root:current train perplexity8.055418014526367
INFO:root:current mean train loss 5288.796925355772
INFO:root:current train perplexity8.0400972366333
INFO:root:current mean train loss 5278.570061007269
INFO:root:current train perplexity8.01253890991211

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:10<00:00, 370.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:10<00:00, 370.25s/it]
INFO:root:final mean train loss: 5273.50411064394
INFO:root:final train perplexity: 8.008872032165527
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.28s/it]
INFO:root:eval mean loss: 5016.735749806073
INFO:root:eval perplexity: 7.603591442108154
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.15s/it]
INFO:root:eval mean loss: 5771.932270888741
INFO:root:eval perplexity: 10.59330940246582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/9
  4%|â–         | 9/200 [1:04:22<22:49:45, 430.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5158.876925616197
INFO:root:current train perplexity7.7306742668151855
INFO:root:current mean train loss 5176.07017258315
INFO:root:current train perplexity7.751669883728027
INFO:root:current mean train loss 5170.884156624769
INFO:root:current train perplexity7.717319011688232
INFO:root:current mean train loss 5175.827066837938
INFO:root:current train perplexity7.7181782722473145
INFO:root:current mean train loss 5176.593942824443
INFO:root:current train perplexity7.713623523712158
INFO:root:current mean train loss 5174.256348511383
INFO:root:current train perplexity7.699877738952637
INFO:root:current mean train loss 5165.530485195836
INFO:root:current train perplexity7.67149019241333
INFO:root:current mean train loss 5161.702483457969
INFO:root:current train perplexity7.660494327545166
INFO:root:current mean train loss 5157.073809513132
INFO:root:current train perplexity7.636489391326904
INFO:root:current mean train loss 5153.055063642508
INFO:root:current train perplexity7.624727725982666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.62s/it]
INFO:root:final mean train loss: 5149.210542863415
INFO:root:final train perplexity: 7.625611305236816
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.54s/it]
INFO:root:eval mean loss: 4922.909647190824
INFO:root:eval perplexity: 7.3205108642578125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.53s/it]
INFO:root:eval mean loss: 5694.414526540337
INFO:root:eval perplexity: 10.262785911560059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/10
  5%|â–Œ         | 10/200 [1:11:32<22:42:13, 430.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5007.6013090882125
INFO:root:current train perplexity7.378481388092041
INFO:root:current mean train loss 5077.318804010999
INFO:root:current train perplexity7.402317523956299
INFO:root:current mean train loss 5082.248015372984
INFO:root:current train perplexity7.40371036529541
INFO:root:current mean train loss 5082.835493022345
INFO:root:current train perplexity7.399064064025879
INFO:root:current mean train loss 5076.4662066561195
INFO:root:current train perplexity7.382238864898682
INFO:root:current mean train loss 5068.331982337543
INFO:root:current train perplexity7.368135929107666
INFO:root:current mean train loss 5066.6436524875735
INFO:root:current train perplexity7.365270137786865
INFO:root:current mean train loss 5064.798707778402
INFO:root:current train perplexity7.356137752532959
INFO:root:current mean train loss 5056.848232299666
INFO:root:current train perplexity7.338606834411621
INFO:root:current mean train loss 5051.712416308893
INFO:root:current train perplexity7.325779914855957

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.43s/it]
INFO:root:final mean train loss: 5047.165535711473
INFO:root:final train perplexity: 7.324704170227051
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.44s/it]
INFO:root:eval mean loss: 4839.129425698138
INFO:root:eval perplexity: 7.076659679412842
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.32s/it]
INFO:root:eval mean loss: 5621.709053634751
INFO:root:eval perplexity: 9.96216106414795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/11
  6%|â–Œ         | 11/200 [1:18:38<22:31:24, 429.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5039.680669674928
INFO:root:current train perplexity7.168112754821777
INFO:root:current mean train loss 5013.875746783088
INFO:root:current train perplexity7.1631293296813965
INFO:root:current mean train loss 5001.966017666594
INFO:root:current train perplexity7.130443572998047
INFO:root:current mean train loss 4987.614030704942
INFO:root:current train perplexity7.117705821990967
INFO:root:current mean train loss 4984.8803259753595
INFO:root:current train perplexity7.1205573081970215
INFO:root:current mean train loss 4980.985656842259
INFO:root:current train perplexity7.113463878631592
INFO:root:current mean train loss 4974.267248339702
INFO:root:current train perplexity7.099242687225342
INFO:root:current mean train loss 4968.614913610824
INFO:root:current train perplexity7.086704730987549
INFO:root:current mean train loss 4962.372934575817
INFO:root:current train perplexity7.072630882263184
INFO:root:current mean train loss 4961.790592151089
INFO:root:current train perplexity7.071438789367676

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.25s/it]
INFO:root:final mean train loss: 4957.618155325613
INFO:root:final train perplexity: 7.070448398590088
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.11s/it]
INFO:root:eval mean loss: 4773.61369680851
INFO:root:eval perplexity: 6.891640663146973
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.63s/it]
INFO:root:eval mean loss: 5564.916098736702
INFO:root:eval perplexity: 9.733471870422363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/12
  6%|â–Œ         | 12/200 [1:25:48<22:25:23, 429.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4895.857437294408
INFO:root:current train perplexity6.9462504386901855
INFO:root:current mean train loss 4887.06012870593
INFO:root:current train perplexity6.897878170013428
INFO:root:current mean train loss 4896.485369769597
INFO:root:current train perplexity6.898022174835205
INFO:root:current mean train loss 4897.043660996836
INFO:root:current train perplexity6.894165515899658
INFO:root:current mean train loss 4895.255908696338
INFO:root:current train perplexity6.891915798187256
INFO:root:current mean train loss 4891.214156873687
INFO:root:current train perplexity6.889583110809326
INFO:root:current mean train loss 4893.816234122078
INFO:root:current train perplexity6.883012294769287
INFO:root:current mean train loss 4892.737022159984
INFO:root:current train perplexity6.879450798034668
INFO:root:current mean train loss 4887.11236851868
INFO:root:current train perplexity6.868818283081055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.13s/it]
INFO:root:final mean train loss: 4880.489747570407
INFO:root:final train perplexity: 6.85853910446167
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.78s/it]
INFO:root:eval mean loss: 4720.01348487367
INFO:root:eval perplexity: 6.743875503540039
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.25s/it]
INFO:root:eval mean loss: 5523.393170295878
INFO:root:eval perplexity: 9.569602012634277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/13
  6%|â–‹         | 13/200 [1:33:00<22:20:04, 429.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4508.544759114583
INFO:root:current train perplexity6.30267333984375
INFO:root:current mean train loss 4777.47593200091
INFO:root:current train perplexity6.6415863037109375
INFO:root:current mean train loss 4788.31689453125
INFO:root:current train perplexity6.661820888519287
INFO:root:current mean train loss 4827.233469343028
INFO:root:current train perplexity6.699929237365723
INFO:root:current mean train loss 4818.640944866625
INFO:root:current train perplexity6.692938804626465
INFO:root:current mean train loss 4818.319199063432
INFO:root:current train perplexity6.689228057861328
INFO:root:current mean train loss 4819.4879775925065
INFO:root:current train perplexity6.684783458709717
INFO:root:current mean train loss 4821.88133098662
INFO:root:current train perplexity6.68190336227417
INFO:root:current mean train loss 4818.050237634262
INFO:root:current train perplexity6.680135726928711
INFO:root:current mean train loss 4818.831788461206
INFO:root:current train perplexity6.681621074676514

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.01s/it]
INFO:root:final mean train loss: 4812.175203261837
INFO:root:final train perplexity: 6.676156044006348
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.64s/it]
INFO:root:eval mean loss: 4662.919932263962
INFO:root:eval perplexity: 6.589963912963867
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.65s/it]
INFO:root:eval mean loss: 5471.0242547650705
INFO:root:eval perplexity: 9.366852760314941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/14
  7%|â–‹         | 14/200 [1:40:07<22:10:35, 429.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4778.084383877841
INFO:root:current train perplexity6.629261493682861
INFO:root:current mean train loss 4777.234823690878
INFO:root:current train perplexity6.569669723510742
INFO:root:current mean train loss 4762.392536470676
INFO:root:current train perplexity6.555778503417969
INFO:root:current mean train loss 4775.448356800141
INFO:root:current train perplexity6.567981719970703
INFO:root:current mean train loss 4766.480218075198
INFO:root:current train perplexity6.554516792297363
INFO:root:current mean train loss 4764.449023819716
INFO:root:current train perplexity6.545605659484863
INFO:root:current mean train loss 4758.962602131495
INFO:root:current train perplexity6.53810453414917
INFO:root:current mean train loss 4755.030448559467
INFO:root:current train perplexity6.528229236602783
INFO:root:current mean train loss 4751.554124862727
INFO:root:current train perplexity6.520959854125977
INFO:root:current mean train loss 4752.726020888361
INFO:root:current train perplexity6.519077301025391

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.56s/it]
INFO:root:final mean train loss: 4750.765485578968
INFO:root:final train perplexity: 6.516350746154785
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.74s/it]
INFO:root:eval mean loss: 4621.433314979499
INFO:root:eval perplexity: 6.480335235595703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.03s/it]
INFO:root:eval mean loss: 5438.34492741578
INFO:root:eval perplexity: 9.242514610290527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/15
  8%|â–Š         | 15/200 [1:47:17<22:03:44, 429.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4613.050729851973
INFO:root:current train perplexity6.289677143096924
INFO:root:current mean train loss 4682.497964810925
INFO:root:current train perplexity6.392276763916016
INFO:root:current mean train loss 4691.810513431079
INFO:root:current train perplexity6.374639987945557
INFO:root:current mean train loss 4699.042475876763
INFO:root:current train perplexity6.374496936798096
INFO:root:current mean train loss 4695.842862004028
INFO:root:current train perplexity6.370014190673828
INFO:root:current mean train loss 4704.023599319605
INFO:root:current train perplexity6.378781795501709
INFO:root:current mean train loss 4703.46322981876
INFO:root:current train perplexity6.382190227508545
INFO:root:current mean train loss 4701.618677470879
INFO:root:current train perplexity6.377479553222656
INFO:root:current mean train loss 4701.899022364354
INFO:root:current train perplexity6.382281303405762
INFO:root:current mean train loss 4702.903492459534
INFO:root:current train perplexity6.379331111907959

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.48s/it]
INFO:root:final mean train loss: 4696.229702303486
INFO:root:final train perplexity: 6.37764310836792
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.11s/it]
INFO:root:eval mean loss: 4580.384469539561
INFO:root:eval perplexity: 6.373654842376709
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.89s/it]
INFO:root:eval mean loss: 5410.031440464318
INFO:root:eval perplexity: 9.136125564575195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/16
  8%|â–Š         | 16/200 [1:54:31<22:01:31, 430.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4667.518825954861
INFO:root:current train perplexity6.296837329864502
INFO:root:current mean train loss 4648.6545775406
INFO:root:current train perplexity6.257336139678955
INFO:root:current mean train loss 4668.0385570106
INFO:root:current train perplexity6.273408889770508
INFO:root:current mean train loss 4678.101683450402
INFO:root:current train perplexity6.296483039855957
INFO:root:current mean train loss 4664.266412882392
INFO:root:current train perplexity6.287229537963867
INFO:root:current mean train loss 4656.647165374467
INFO:root:current train perplexity6.278183460235596
INFO:root:current mean train loss 4656.212903863886
INFO:root:current train perplexity6.2689409255981445
INFO:root:current mean train loss 4655.297363952888
INFO:root:current train perplexity6.269725322723389
INFO:root:current mean train loss 4653.2363871674725
INFO:root:current train perplexity6.262483596801758
INFO:root:current mean train loss 4651.712446852666
INFO:root:current train perplexity6.255690574645996

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.10s/it]
INFO:root:final mean train loss: 4646.202065190962
INFO:root:final train perplexity: 6.252999305725098
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.59s/it]
INFO:root:eval mean loss: 4541.821266553081
INFO:root:eval perplexity: 6.275035858154297
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.27s/it]
INFO:root:eval mean loss: 5370.491891414561
INFO:root:eval perplexity: 8.98959732055664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/17
  8%|â–Š         | 17/200 [2:01:47<21:58:13, 432.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4611.1029017857145
INFO:root:current train perplexity6.064789772033691
INFO:root:current mean train loss 4601.207506872107
INFO:root:current train perplexity6.121521949768066
INFO:root:current mean train loss 4596.14608543883
INFO:root:current train perplexity6.121705055236816
INFO:root:current mean train loss 4592.90558098181
INFO:root:current train perplexity6.110905170440674
INFO:root:current mean train loss 4604.453869769217
INFO:root:current train perplexity6.125912666320801
INFO:root:current mean train loss 4608.378328982914
INFO:root:current train perplexity6.1442742347717285
INFO:root:current mean train loss 4606.031339582308
INFO:root:current train perplexity6.145870685577393
INFO:root:current mean train loss 4608.77952606824
INFO:root:current train perplexity6.1464457511901855
INFO:root:current mean train loss 4610.652899279566
INFO:root:current train perplexity6.148628234863281
INFO:root:current mean train loss 4607.250706571691
INFO:root:current train perplexity6.146195888519287

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.35s/it]
INFO:root:final mean train loss: 4600.924456565611
INFO:root:final train perplexity: 6.142291069030762
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.47s/it]
INFO:root:eval mean loss: 4511.920881122562
INFO:root:eval perplexity: 6.199622631072998
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.45s/it]
INFO:root:eval mean loss: 5349.052012342087
INFO:root:eval perplexity: 8.911127090454102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/18
  9%|â–‰         | 18/200 [2:08:50<21:43:02, 429.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4534.09418718205
INFO:root:current train perplexity5.929035663604736
INFO:root:current mean train loss 4559.174563961429
INFO:root:current train perplexity6.029757499694824
INFO:root:current mean train loss 4566.328166192451
INFO:root:current train perplexity6.048380374908447
INFO:root:current mean train loss 4580.472617102087
INFO:root:current train perplexity6.051663398742676
INFO:root:current mean train loss 4575.970195554987
INFO:root:current train perplexity6.042202949523926
INFO:root:current mean train loss 4567.388205624856
INFO:root:current train perplexity6.037414073944092
INFO:root:current mean train loss 4560.528958191582
INFO:root:current train perplexity6.03294038772583
INFO:root:current mean train loss 4561.9910719449235
INFO:root:current train perplexity6.041409969329834
INFO:root:current mean train loss 4563.972526794651
INFO:root:current train perplexity6.044930934906006
INFO:root:current mean train loss 4564.601374281299
INFO:root:current train perplexity6.04656982421875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.29s/it]
INFO:root:final mean train loss: 4559.908822459559
INFO:root:final train perplexity: 6.043698310852051
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.58s/it]
INFO:root:eval mean loss: 4482.213936447251
INFO:root:eval perplexity: 6.125594615936279
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.71s/it]
INFO:root:eval mean loss: 5324.369062707779
INFO:root:eval perplexity: 8.821639060974121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/19
 10%|â–‰         | 19/200 [2:15:48<21:25:10, 426.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4526.027401194853
INFO:root:current train perplexity5.922971725463867
INFO:root:current mean train loss 4483.552480533423
INFO:root:current train perplexity5.903843879699707
INFO:root:current mean train loss 4508.864699405503
INFO:root:current train perplexity5.9265971183776855
INFO:root:current mean train loss 4505.71529029781
INFO:root:current train perplexity5.928092956542969
INFO:root:current mean train loss 4512.899748064197
INFO:root:current train perplexity5.938575267791748
INFO:root:current mean train loss 4522.7632478412825
INFO:root:current train perplexity5.952420711517334
INFO:root:current mean train loss 4524.662206131193
INFO:root:current train perplexity5.955482006072998
INFO:root:current mean train loss 4526.301666462945
INFO:root:current train perplexity5.957213878631592
INFO:root:current mean train loss 4524.0446481850395
INFO:root:current train perplexity5.95530891418457
INFO:root:current mean train loss 4524.999406977031
INFO:root:current train perplexity5.953114032745361

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.90s/it]
INFO:root:final mean train loss: 4521.79831781695
INFO:root:final train perplexity: 5.953505039215088
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it]
INFO:root:eval mean loss: 4455.587714012633
INFO:root:eval perplexity: 6.059993267059326
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.01s/it]
INFO:root:eval mean loss: 5303.708653659685
INFO:root:eval perplexity: 8.747425079345703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/20
 10%|â–ˆ         | 20/200 [2:22:49<21:13:49, 424.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4490.4511429091635
INFO:root:current train perplexity5.8567070960998535
INFO:root:current mean train loss 4499.1985124312105
INFO:root:current train perplexity5.882171154022217
INFO:root:current mean train loss 4495.055692341337
INFO:root:current train perplexity5.875138759613037
INFO:root:current mean train loss 4495.878169747781
INFO:root:current train perplexity5.879971981048584
INFO:root:current mean train loss 4493.892726524204
INFO:root:current train perplexity5.880620956420898
INFO:root:current mean train loss 4491.49133278944
INFO:root:current train perplexity5.875694751739502
INFO:root:current mean train loss 4491.726909261191
INFO:root:current train perplexity5.871981620788574
INFO:root:current mean train loss 4494.99020928545
INFO:root:current train perplexity5.8734588623046875
INFO:root:current mean train loss 4493.909124549804
INFO:root:current train perplexity5.87202262878418
INFO:root:current mean train loss 4491.542446609831
INFO:root:current train perplexity5.86981201171875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.12s/it]
INFO:root:final mean train loss: 4485.78665321104
INFO:root:final train perplexity: 5.869518280029297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it]
INFO:root:eval mean loss: 4436.8561163286795
INFO:root:eval perplexity: 6.0142669677734375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.58s/it]
INFO:root:eval mean loss: 5291.8180078817595
INFO:root:eval perplexity: 8.704995155334473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/21
 10%|â–ˆ         | 21/200 [2:29:52<21:04:58, 424.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4452.135884299207
INFO:root:current train perplexity5.775134086608887
INFO:root:current mean train loss 4436.995057248783
INFO:root:current train perplexity5.774777412414551
INFO:root:current mean train loss 4445.30476705144
INFO:root:current train perplexity5.779297351837158
INFO:root:current mean train loss 4452.226388208873
INFO:root:current train perplexity5.782088756561279
INFO:root:current mean train loss 4454.29105378831
INFO:root:current train perplexity5.787629127502441
INFO:root:current mean train loss 4457.663032975777
INFO:root:current train perplexity5.797240734100342
INFO:root:current mean train loss 4455.57503133199
INFO:root:current train perplexity5.796988487243652
INFO:root:current mean train loss 4457.560782421366
INFO:root:current train perplexity5.7988691329956055
INFO:root:current mean train loss 4459.768989747783
INFO:root:current train perplexity5.79818868637085
INFO:root:current mean train loss 4458.283053661453
INFO:root:current train perplexity5.794801712036133

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.98s/it]
INFO:root:final mean train loss: 4453.598042826498
INFO:root:final train perplexity: 5.795450210571289
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.79s/it]
INFO:root:eval mean loss: 4415.454833984375
INFO:root:eval perplexity: 5.962442874908447
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.05s/it]
INFO:root:eval mean loss: 5274.009396816822
INFO:root:eval perplexity: 8.641833305358887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/22
 11%|â–ˆ         | 22/200 [2:36:54<20:56:02, 423.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4386.113229166666
INFO:root:current train perplexity5.70999002456665
INFO:root:current mean train loss 4381.202925502233
INFO:root:current train perplexity5.698742866516113
INFO:root:current mean train loss 4412.899303089489
INFO:root:current train perplexity5.721531867980957
INFO:root:current mean train loss 4412.030548177083
INFO:root:current train perplexity5.704209327697754
INFO:root:current mean train loss 4417.835334601151
INFO:root:current train perplexity5.718621730804443
INFO:root:current mean train loss 4416.272739470109
INFO:root:current train perplexity5.718966484069824
INFO:root:current mean train loss 4420.200792462384
INFO:root:current train perplexity5.7190022468566895
INFO:root:current mean train loss 4422.4048828125
INFO:root:current train perplexity5.716722011566162
INFO:root:current mean train loss 4422.83325390625
INFO:root:current train perplexity5.715073585510254
INFO:root:current mean train loss 4424.934243539664
INFO:root:current train perplexity5.722615718841553

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.08s/it]
INFO:root:final mean train loss: 4421.969079417567
INFO:root:final train perplexity: 5.723580360412598
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.95s/it]
INFO:root:eval mean loss: 4392.270088791001
INFO:root:eval perplexity: 5.906805038452148
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.45s/it]
INFO:root:eval mean loss: 5254.431346271055
INFO:root:eval perplexity: 8.57292652130127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/23
 12%|â–ˆâ–        | 23/200 [2:43:58<20:50:06, 423.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4365.991999246988
INFO:root:current train perplexity5.618187427520752
INFO:root:current mean train loss 4382.623536490351
INFO:root:current train perplexity5.626326084136963
INFO:root:current mean train loss 4397.054413165305
INFO:root:current train perplexity5.644345283508301
INFO:root:current mean train loss 4397.309145138096
INFO:root:current train perplexity5.647652626037598
INFO:root:current mean train loss 4396.575738689668
INFO:root:current train perplexity5.652096748352051
INFO:root:current mean train loss 4392.560919158046
INFO:root:current train perplexity5.6491570472717285
INFO:root:current mean train loss 4391.949535811104
INFO:root:current train perplexity5.654109001159668
INFO:root:current mean train loss 4395.757201680735
INFO:root:current train perplexity5.6563310623168945
INFO:root:current mean train loss 4394.741089558413
INFO:root:current train perplexity5.658574104309082
INFO:root:current mean train loss 4395.631777075519
INFO:root:current train perplexity5.65664529800415

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.81s/it]
INFO:root:final mean train loss: 4392.198293932022
INFO:root:final train perplexity: 5.656749725341797
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.85s/it]
INFO:root:eval mean loss: 4376.885749113475
INFO:root:eval perplexity: 5.87017297744751
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.87s/it]
INFO:root:eval mean loss: 5248.360554147274
INFO:root:eval perplexity: 8.551671028137207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/24
 12%|â–ˆâ–        | 24/200 [2:51:03<20:43:54, 424.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4375.639085036058
INFO:root:current train perplexity5.578222274780273
INFO:root:current mean train loss 4355.322780748937
INFO:root:current train perplexity5.568736553192139
INFO:root:current mean train loss 4354.090243939272
INFO:root:current train perplexity5.565112113952637
INFO:root:current mean train loss 4357.2398815886745
INFO:root:current train perplexity5.563523769378662
INFO:root:current mean train loss 4374.097008357466
INFO:root:current train perplexity5.585784435272217
INFO:root:current mean train loss 4365.940784951354
INFO:root:current train perplexity5.581882476806641
INFO:root:current mean train loss 4365.795029282743
INFO:root:current train perplexity5.587646007537842
INFO:root:current mean train loss 4369.042364725723
INFO:root:current train perplexity5.5914812088012695
INFO:root:current mean train loss 4366.18031470302
INFO:root:current train perplexity5.591961860656738
INFO:root:current mean train loss 4369.023419762235
INFO:root:current train perplexity5.597559928894043

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.45s/it]
INFO:root:final mean train loss: 4365.6816736036735
INFO:root:final train perplexity: 5.597878932952881
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.09s/it]
INFO:root:eval mean loss: 4358.3395961463875
INFO:root:eval perplexity: 5.8263139724731445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it]
INFO:root:eval mean loss: 5231.072577293883
INFO:root:eval perplexity: 8.491430282592773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/25
 12%|â–ˆâ–Ž        | 25/200 [2:58:07<20:36:41, 424.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4279.392827197759
INFO:root:current train perplexity5.470056056976318
INFO:root:current mean train loss 4313.808163130104
INFO:root:current train perplexity5.51269006729126
INFO:root:current mean train loss 4326.776755036319
INFO:root:current train perplexity5.519424915313721
INFO:root:current mean train loss 4324.639343108748
INFO:root:current train perplexity5.522210597991943
INFO:root:current mean train loss 4326.863162849136
INFO:root:current train perplexity5.523294448852539
INFO:root:current mean train loss 4327.84662018077
INFO:root:current train perplexity5.524088382720947
INFO:root:current mean train loss 4333.829373994099
INFO:root:current train perplexity5.531588077545166
INFO:root:current mean train loss 4336.264570520279
INFO:root:current train perplexity5.535470008850098
INFO:root:current mean train loss 4338.903138632769
INFO:root:current train perplexity5.537504196166992

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.19s/it]
INFO:root:final mean train loss: 4338.913847400296
INFO:root:final train perplexity: 5.539071083068848
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it]
INFO:root:eval mean loss: 4341.689901581893
INFO:root:eval perplexity: 5.787220001220703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it]
INFO:root:eval mean loss: 5218.977627368684
INFO:root:eval perplexity: 8.44953727722168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/26
 13%|â–ˆâ–Ž        | 26/200 [3:05:05<20:24:08, 422.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4274.427315848215
INFO:root:current train perplexity5.468973636627197
INFO:root:current mean train loss 4296.343939380111
INFO:root:current train perplexity5.449256420135498
INFO:root:current mean train loss 4310.546938688859
INFO:root:current train perplexity5.457133769989014
INFO:root:current mean train loss 4313.388702889607
INFO:root:current train perplexity5.470308780670166
INFO:root:current mean train loss 4315.606970184851
INFO:root:current train perplexity5.479159355163574
INFO:root:current mean train loss 4316.488371779463
INFO:root:current train perplexity5.4794840812683105
INFO:root:current mean train loss 4318.276745263592
INFO:root:current train perplexity5.486076354980469
INFO:root:current mean train loss 4316.676595857828
INFO:root:current train perplexity5.486442565917969
INFO:root:current mean train loss 4318.344416470628
INFO:root:current train perplexity5.482352256774902
INFO:root:current mean train loss 4320.092987161487
INFO:root:current train perplexity5.485487461090088

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.39s/it]
INFO:root:final mean train loss: 4314.837046777048
INFO:root:final train perplexity: 5.486705303192139
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.46s/it]
INFO:root:eval mean loss: 4329.116437763187
INFO:root:eval perplexity: 5.757868766784668
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.67s/it]
INFO:root:eval mean loss: 5209.525288466866
INFO:root:eval perplexity: 8.416942596435547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/27
 14%|â–ˆâ–Ž        | 27/200 [3:12:03<20:14:07, 421.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4252.500667317709
INFO:root:current train perplexity5.4338603019714355
INFO:root:current mean train loss 4280.413158118206
INFO:root:current train perplexity5.422176837921143
INFO:root:current mean train loss 4287.840285474201
INFO:root:current train perplexity5.426752090454102
INFO:root:current mean train loss 4298.535938275049
INFO:root:current train perplexity5.428004741668701
INFO:root:current mean train loss 4292.446843232304
INFO:root:current train perplexity5.428921699523926
INFO:root:current mean train loss 4292.440370430067
INFO:root:current train perplexity5.4276957511901855
INFO:root:current mean train loss 4295.5042250222305
INFO:root:current train perplexity5.431319713592529
INFO:root:current mean train loss 4297.621723052338
INFO:root:current train perplexity5.435093402862549
INFO:root:current mean train loss 4297.754712962519
INFO:root:current train perplexity5.434732437133789
INFO:root:current mean train loss 4298.007285796619
INFO:root:current train perplexity5.438749313354492

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.98s/it]
INFO:root:final mean train loss: 4291.886432647705
INFO:root:final train perplexity: 5.437250137329102
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it]
INFO:root:eval mean loss: 4315.825235136857
INFO:root:eval perplexity: 5.7270073890686035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it]
INFO:root:eval mean loss: 5197.5840397828015
INFO:root:eval perplexity: 8.37594223022461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/28
 14%|â–ˆâ–        | 28/200 [3:19:04<20:06:37, 420.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4206.617835003397
INFO:root:current train perplexity5.317755699157715
INFO:root:current mean train loss 4228.861153455285
INFO:root:current train perplexity5.355851650238037
INFO:root:current mean train loss 4257.587639915569
INFO:root:current train perplexity5.375274181365967
INFO:root:current mean train loss 4264.229867090751
INFO:root:current train perplexity5.388764381408691
INFO:root:current mean train loss 4263.443602938461
INFO:root:current train perplexity5.3887763023376465
INFO:root:current mean train loss 4265.093258917902
INFO:root:current train perplexity5.3918561935424805
INFO:root:current mean train loss 4262.824776001957
INFO:root:current train perplexity5.386350631713867
INFO:root:current mean train loss 4270.058789940461
INFO:root:current train perplexity5.3859992027282715
INFO:root:current mean train loss 4268.816523128987
INFO:root:current train perplexity5.385374069213867
INFO:root:current mean train loss 4271.772916948808
INFO:root:current train perplexity5.390192031860352

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.66s/it]
INFO:root:final mean train loss: 4268.698568282589
INFO:root:final train perplexity: 5.387734889984131
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.77s/it]
INFO:root:eval mean loss: 4305.08718763852
INFO:root:eval perplexity: 5.702192783355713
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.37s/it]
INFO:root:eval mean loss: 5191.068257216866
INFO:root:eval perplexity: 8.353655815124512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/29
 14%|â–ˆâ–        | 29/200 [3:26:09<20:03:04, 422.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4269.962914251512
INFO:root:current train perplexity5.378170490264893
INFO:root:current mean train loss 4264.4241430850425
INFO:root:current train perplexity5.367306709289551
INFO:root:current mean train loss 4248.696438083401
INFO:root:current train perplexity5.3491291999816895
INFO:root:current mean train loss 4258.595851379579
INFO:root:current train perplexity5.358676910400391
INFO:root:current mean train loss 4255.636824109992
INFO:root:current train perplexity5.35668420791626
INFO:root:current mean train loss 4249.858492691414
INFO:root:current train perplexity5.351222515106201
INFO:root:current mean train loss 4253.267847801729
INFO:root:current train perplexity5.346810340881348
INFO:root:current mean train loss 4250.898858316946
INFO:root:current train perplexity5.346467971801758
INFO:root:current mean train loss 4251.353547942051
INFO:root:current train perplexity5.345014572143555
INFO:root:current mean train loss 4251.551244356707
INFO:root:current train perplexity5.343825817108154

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.75s/it]
INFO:root:final mean train loss: 4248.119381320092
INFO:root:final train perplexity: 5.3441691398620605
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.49s/it]
INFO:root:eval mean loss: 4291.625465771831
INFO:root:eval perplexity: 5.671237468719482
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.22s/it]
INFO:root:eval mean loss: 5179.08462329621
INFO:root:eval perplexity: 8.312819480895996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/30
 15%|â–ˆâ–Œ        | 30/200 [3:33:05<19:50:30, 420.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4225.223958333333
INFO:root:current train perplexity5.327038288116455
INFO:root:current mean train loss 4227.933959082734
INFO:root:current train perplexity5.306851387023926
INFO:root:current mean train loss 4217.716763165206
INFO:root:current train perplexity5.284191131591797
INFO:root:current mean train loss 4224.695855514841
INFO:root:current train perplexity5.280319690704346
INFO:root:current mean train loss 4227.838952275235
INFO:root:current train perplexity5.287603855133057
INFO:root:current mean train loss 4227.645201164628
INFO:root:current train perplexity5.291268348693848
INFO:root:current mean train loss 4227.29596568124
INFO:root:current train perplexity5.293375492095947
INFO:root:current mean train loss 4229.111590435767
INFO:root:current train perplexity5.295647621154785
INFO:root:current mean train loss 4228.809253424371
INFO:root:current train perplexity5.2952880859375
INFO:root:current mean train loss 4229.6514558477265
INFO:root:current train perplexity5.298654556274414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.09s/it]
INFO:root:final mean train loss: 4227.022239685059
INFO:root:final train perplexity: 5.299871444702148
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.92s/it]
INFO:root:eval mean loss: 4285.44374722961
INFO:root:eval perplexity: 5.657078742980957
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.28s/it]
INFO:root:eval mean loss: 5180.811549409907
INFO:root:eval perplexity: 8.318689346313477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/31
 16%|â–ˆâ–Œ        | 31/200 [3:40:12<19:49:39, 422.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4204.101515749668
INFO:root:current train perplexity5.236375331878662
INFO:root:current mean train loss 4208.89435686384
INFO:root:current train perplexity5.255713939666748
INFO:root:current mean train loss 4210.662763711412
INFO:root:current train perplexity5.255959510803223
INFO:root:current mean train loss 4200.963525953485
INFO:root:current train perplexity5.252978324890137
INFO:root:current mean train loss 4199.758605547399
INFO:root:current train perplexity5.24502420425415
INFO:root:current mean train loss 4203.494294607661
INFO:root:current train perplexity5.248132228851318
INFO:root:current mean train loss 4208.369659848338
INFO:root:current train perplexity5.253931045532227
INFO:root:current mean train loss 4212.48464463322
INFO:root:current train perplexity5.258657455444336
INFO:root:current mean train loss 4211.279212996698
INFO:root:current train perplexity5.257183074951172
INFO:root:current mean train loss 4210.374309342414
INFO:root:current train perplexity5.258026123046875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.54s/it]
INFO:root:final mean train loss: 4207.62293834071
INFO:root:final train perplexity: 5.259463787078857
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.31s/it]
INFO:root:eval mean loss: 4272.687468833112
INFO:root:eval perplexity: 5.6279730796813965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it]
INFO:root:eval mean loss: 5167.425810685395
INFO:root:eval perplexity: 8.273284912109375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/32
 16%|â–ˆâ–Œ        | 32/200 [3:47:21<19:48:32, 424.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4164.960089666193
INFO:root:current train perplexity5.179234981536865
INFO:root:current mean train loss 4169.965232799899
INFO:root:current train perplexity5.199840545654297
INFO:root:current mean train loss 4181.457531020221
INFO:root:current train perplexity5.207714080810547
INFO:root:current mean train loss 4182.593346996039
INFO:root:current train perplexity5.200909614562988
INFO:root:current mean train loss 4180.678783911401
INFO:root:current train perplexity5.201374053955078
INFO:root:current mean train loss 4182.322064153997
INFO:root:current train perplexity5.205154895782471
INFO:root:current mean train loss 4189.809465201574
INFO:root:current train perplexity5.217560291290283
INFO:root:current mean train loss 4189.388742045219
INFO:root:current train perplexity5.219903469085693
INFO:root:current mean train loss 4188.74492558708
INFO:root:current train perplexity5.215217590332031
INFO:root:current mean train loss 4187.18280534195
INFO:root:current train perplexity5.214193344116211

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.23s/it]
INFO:root:final mean train loss: 4188.215639360489
INFO:root:final train perplexity: 5.219346523284912
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.02s/it]
INFO:root:eval mean loss: 4264.42464019559
INFO:root:eval perplexity: 5.609199047088623
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it]
INFO:root:eval mean loss: 5164.52582869293
INFO:root:eval perplexity: 8.263479232788086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/33
 16%|â–ˆâ–‹        | 33/200 [3:54:19<19:35:50, 422.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4179.599132719494
INFO:root:current train perplexity5.176580905914307
INFO:root:current mean train loss 4165.372796743194
INFO:root:current train perplexity5.159428596496582
INFO:root:current mean train loss 4161.488203273527
INFO:root:current train perplexity5.168353080749512
INFO:root:current mean train loss 4159.279190609935
INFO:root:current train perplexity5.158799171447754
INFO:root:current mean train loss 4165.830242643088
INFO:root:current train perplexity5.168643474578857
INFO:root:current mean train loss 4162.295247540381
INFO:root:current train perplexity5.170643329620361
INFO:root:current mean train loss 4167.03107877015
INFO:root:current train perplexity5.17431640625
INFO:root:current mean train loss 4170.93389932575
INFO:root:current train perplexity5.1751298904418945
INFO:root:current mean train loss 4171.409167522904
INFO:root:current train perplexity5.177958011627197
INFO:root:current mean train loss 4173.384391681675
INFO:root:current train perplexity5.1825361251831055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.38s/it]
INFO:root:final mean train loss: 4170.064346559586
INFO:root:final train perplexity: 5.182103633880615
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.85s/it]
INFO:root:eval mean loss: 4254.322016289893
INFO:root:eval perplexity: 5.586331844329834
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.33s/it]
INFO:root:eval mean loss: 5161.245972545435
INFO:root:eval perplexity: 8.25240421295166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/34
 17%|â–ˆâ–‹        | 34/200 [4:01:17<19:24:51, 421.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4135.493776133363
INFO:root:current train perplexity5.092128276824951
INFO:root:current mean train loss 4154.701831483005
INFO:root:current train perplexity5.106173038482666
INFO:root:current mean train loss 4148.7685114448805
INFO:root:current train perplexity5.125341892242432
INFO:root:current mean train loss 4150.892139856384
INFO:root:current train perplexity5.126836776733398
INFO:root:current mean train loss 4146.710405677747
INFO:root:current train perplexity5.129492282867432
INFO:root:current mean train loss 4146.091534349004
INFO:root:current train perplexity5.13425350189209
INFO:root:current mean train loss 4147.329530173016
INFO:root:current train perplexity5.134834289550781
INFO:root:current mean train loss 4147.754593706935
INFO:root:current train perplexity5.13889217376709
INFO:root:current mean train loss 4150.784806997166
INFO:root:current train perplexity5.141944408416748
INFO:root:current mean train loss 4153.876495518473
INFO:root:current train perplexity5.144150257110596

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.65s/it]
INFO:root:final mean train loss: 4151.995005453787
INFO:root:final train perplexity: 5.145292282104492
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.14s/it]
INFO:root:eval mean loss: 4246.621469484154
INFO:root:eval perplexity: 5.56896448135376
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.67s/it]
INFO:root:eval mean loss: 5155.52320028535
INFO:root:eval perplexity: 8.233114242553711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/35
 18%|â–ˆâ–Š        | 35/200 [4:08:18<19:17:33, 420.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4117.734748936907
INFO:root:current train perplexity5.109767913818359
INFO:root:current mean train loss 4113.109807360772
INFO:root:current train perplexity5.092393398284912
INFO:root:current mean train loss 4125.503047820061
INFO:root:current train perplexity5.097725868225098
INFO:root:current mean train loss 4127.977935227366
INFO:root:current train perplexity5.10507345199585
INFO:root:current mean train loss 4127.198963905924
INFO:root:current train perplexity5.0938310623168945
INFO:root:current mean train loss 4131.261009941035
INFO:root:current train perplexity5.100129127502441
INFO:root:current mean train loss 4137.226450317563
INFO:root:current train perplexity5.107635021209717
INFO:root:current mean train loss 4137.083303977956
INFO:root:current train perplexity5.108312129974365
INFO:root:current mean train loss 4137.319820330275
INFO:root:current train perplexity5.107460975646973
INFO:root:current mean train loss 4138.40901659458
INFO:root:current train perplexity5.10982084274292

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.11s/it]
INFO:root:final mean train loss: 4134.934264029226
INFO:root:final train perplexity: 5.110775947570801
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.76s/it]
INFO:root:eval mean loss: 4239.615885416667
INFO:root:eval perplexity: 5.553211212158203
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.50s/it]
INFO:root:eval mean loss: 5148.5362921099295
INFO:root:eval perplexity: 8.209626197814941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/36
 18%|â–ˆâ–Š        | 36/200 [4:15:14<19:06:54, 419.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4164.522199959591
INFO:root:current train perplexity5.133110523223877
INFO:root:current mean train loss 4134.771862988803
INFO:root:current train perplexity5.0908684730529785
INFO:root:current mean train loss 4132.722971846418
INFO:root:current train perplexity5.090736389160156
INFO:root:current mean train loss 4129.867037987524
INFO:root:current train perplexity5.079464435577393
INFO:root:current mean train loss 4125.853434411897
INFO:root:current train perplexity5.069602966308594
INFO:root:current mean train loss 4127.407897845241
INFO:root:current train perplexity5.0815749168396
INFO:root:current mean train loss 4123.007149375682
INFO:root:current train perplexity5.078379154205322
INFO:root:current mean train loss 4123.267136066054
INFO:root:current train perplexity5.078320503234863
INFO:root:current mean train loss 4123.832321356222
INFO:root:current train perplexity5.078063011169434
INFO:root:current mean train loss 4120.347624341043
INFO:root:current train perplexity5.075700283050537

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.44s/it]
INFO:root:final mean train loss: 4117.594195335142
INFO:root:final train perplexity: 5.075931549072266
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.92s/it]
INFO:root:eval mean loss: 4234.293223279587
INFO:root:eval perplexity: 5.5412702560424805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.26s/it]
INFO:root:eval mean loss: 5148.648127562611
INFO:root:eval perplexity: 8.20999813079834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/37
 18%|â–ˆâ–Š        | 37/200 [4:22:09<18:56:01, 418.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4093.252690686678
INFO:root:current train perplexity5.0604143142700195
INFO:root:current mean train loss 4092.740636268029
INFO:root:current train perplexity5.066851615905762
INFO:root:current mean train loss 4099.384254998676
INFO:root:current train perplexity5.061183929443359
INFO:root:current mean train loss 4099.709801473497
INFO:root:current train perplexity5.047802448272705
INFO:root:current mean train loss 4100.123100142046
INFO:root:current train perplexity5.044933319091797
INFO:root:current mean train loss 4100.27613904937
INFO:root:current train perplexity5.045372486114502
INFO:root:current mean train loss 4100.940842443233
INFO:root:current train perplexity5.049748420715332
INFO:root:current mean train loss 4101.136594376474
INFO:root:current train perplexity5.047966957092285
INFO:root:current mean train loss 4101.682041070181
INFO:root:current train perplexity5.0445332527160645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.23s/it]
INFO:root:final mean train loss: 4101.885782610985
INFO:root:final train perplexity: 5.0445709228515625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.42s/it]
INFO:root:eval mean loss: 4226.210904601618
INFO:root:eval perplexity: 5.523190498352051
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.95s/it]
INFO:root:eval mean loss: 5142.057710688165
INFO:root:eval perplexity: 8.187904357910156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/38
 19%|â–ˆâ–‰        | 38/200 [4:29:05<18:47:06, 417.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4174.752034505208
INFO:root:current train perplexity4.9425883293151855
INFO:root:current mean train loss 4093.6319544523667
INFO:root:current train perplexity4.975657939910889
INFO:root:current mean train loss 4082.8118313192736
INFO:root:current train perplexity4.981157302856445
INFO:root:current mean train loss 4075.120789178527
INFO:root:current train perplexity4.98887300491333
INFO:root:current mean train loss 4081.283380020937
INFO:root:current train perplexity5.000205039978027
INFO:root:current mean train loss 4085.5645866014847
INFO:root:current train perplexity5.002355575561523
INFO:root:current mean train loss 4087.1594319256583
INFO:root:current train perplexity5.00478458404541
INFO:root:current mean train loss 4085.0496907783604
INFO:root:current train perplexity5.005407333374023
INFO:root:current mean train loss 4085.451306258756
INFO:root:current train perplexity5.008108139038086
INFO:root:current mean train loss 4087.2635558879256
INFO:root:current train perplexity5.010438442230225

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.86s/it]
INFO:root:final mean train loss: 4086.4372130363217
INFO:root:final train perplexity: 5.013918876647949
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.63s/it]
INFO:root:eval mean loss: 4219.554052041777
INFO:root:eval perplexity: 5.508342742919922
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.24s/it]
INFO:root:eval mean loss: 5137.475883754432
INFO:root:eval perplexity: 8.172578811645508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/39
 20%|â–ˆâ–‰        | 39/200 [4:36:00<18:38:51, 416.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4029.0501598011365
INFO:root:current train perplexity4.977982997894287
INFO:root:current mean train loss 4061.0626605609514
INFO:root:current train perplexity4.990856170654297
INFO:root:current mean train loss 4067.8612610152545
INFO:root:current train perplexity4.984668254852295
INFO:root:current mean train loss 4057.690671473071
INFO:root:current train perplexity4.972202777862549
INFO:root:current mean train loss 4065.17784307995
INFO:root:current train perplexity4.966700553894043
INFO:root:current mean train loss 4069.444753030975
INFO:root:current train perplexity4.974532604217529
INFO:root:current mean train loss 4069.1474913052375
INFO:root:current train perplexity4.979318618774414
INFO:root:current mean train loss 4068.196124928578
INFO:root:current train perplexity4.980334281921387
INFO:root:current mean train loss 4072.30758076208
INFO:root:current train perplexity4.983872890472412
INFO:root:current mean train loss 4075.491679387349
INFO:root:current train perplexity4.986206531524658

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.39s/it]
INFO:root:final mean train loss: 4071.508632906022
INFO:root:final train perplexity: 4.9844746589660645
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.73s/it]
INFO:root:eval mean loss: 4214.002323664672
INFO:root:eval perplexity: 5.495990753173828
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.90s/it]
INFO:root:eval mean loss: 5134.02550490359
INFO:root:eval perplexity: 8.161056518554688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/40
 20%|â–ˆâ–ˆ        | 40/200 [4:42:57<18:31:17, 416.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4072.782830489309
INFO:root:current train perplexity5.006315231323242
INFO:root:current mean train loss 4040.745004349396
INFO:root:current train perplexity4.9218339920043945
INFO:root:current mean train loss 4056.3113439551225
INFO:root:current train perplexity4.932794570922852
INFO:root:current mean train loss 4057.8594186238734
INFO:root:current train perplexity4.941579818725586
INFO:root:current mean train loss 4052.4940264207935
INFO:root:current train perplexity4.933316707611084
INFO:root:current mean train loss 4058.2738862671604
INFO:root:current train perplexity4.939711093902588
INFO:root:current mean train loss 4054.859270875404
INFO:root:current train perplexity4.943121910095215
INFO:root:current mean train loss 4056.3070246626176
INFO:root:current train perplexity4.944047451019287
INFO:root:current mean train loss 4058.8411729600693
INFO:root:current train perplexity4.9497904777526855
INFO:root:current mean train loss 4058.608875295413
INFO:root:current train perplexity4.951301097869873

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.77s/it]
INFO:root:final mean train loss: 4055.7926490537584
INFO:root:final train perplexity: 4.953664302825928
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.50s/it]
INFO:root:eval mean loss: 4211.006614306294
INFO:root:eval perplexity: 5.4893364906311035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.16s/it]
INFO:root:eval mean loss: 5138.634911070479
INFO:root:eval perplexity: 8.176451683044434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/41
 20%|â–ˆâ–ˆ        | 41/200 [4:49:55<18:25:48, 417.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3944.4970793547454
INFO:root:current train perplexity4.8151535987854
INFO:root:current mean train loss 4019.3652228407973
INFO:root:current train perplexity4.9072394371032715
INFO:root:current mean train loss 4043.147969653428
INFO:root:current train perplexity4.942566871643066
INFO:root:current mean train loss 4040.391998757645
INFO:root:current train perplexity4.93093729019165
INFO:root:current mean train loss 4048.8977262331673
INFO:root:current train perplexity4.928117752075195
INFO:root:current mean train loss 4048.5241977177716
INFO:root:current train perplexity4.928915977478027
INFO:root:current mean train loss 4048.706053519363
INFO:root:current train perplexity4.928618431091309
INFO:root:current mean train loss 4047.0596912074448
INFO:root:current train perplexity4.9277167320251465
INFO:root:current mean train loss 4047.67526049539
INFO:root:current train perplexity4.929406642913818
INFO:root:current mean train loss 4045.5043097272787
INFO:root:current train perplexity4.927729606628418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.55s/it]
INFO:root:final mean train loss: 4042.3791203037385
INFO:root:final train perplexity: 4.92751932144165
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it]
INFO:root:eval mean loss: 4204.3848729776155
INFO:root:eval perplexity: 5.4746575355529785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.55s/it]
INFO:root:eval mean loss: 5131.426390735815
INFO:root:eval perplexity: 8.152386665344238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/42
 21%|â–ˆâ–ˆ        | 42/200 [4:56:51<18:17:54, 416.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3994.122816685268
INFO:root:current train perplexity4.869518280029297
INFO:root:current mean train loss 4022.5457953559026
INFO:root:current train perplexity4.880336761474609
INFO:root:current mean train loss 4012.9809580701462
INFO:root:current train perplexity4.869882583618164
INFO:root:current mean train loss 4023.406337453358
INFO:root:current train perplexity4.872227191925049
INFO:root:current mean train loss 4023.4771327227013
INFO:root:current train perplexity4.880749225616455
INFO:root:current mean train loss 4023.033041125146
INFO:root:current train perplexity4.883556365966797
INFO:root:current mean train loss 4024.116366649237
INFO:root:current train perplexity4.887949466705322
INFO:root:current mean train loss 4029.7206795413476
INFO:root:current train perplexity4.896670818328857
INFO:root:current mean train loss 4029.255767274046
INFO:root:current train perplexity4.893176078796387
INFO:root:current mean train loss 4032.169067774482
INFO:root:current train perplexity4.898236274719238

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.81s/it]
INFO:root:final mean train loss: 4027.794833644744
INFO:root:final train perplexity: 4.899247169494629
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.18s/it]
INFO:root:eval mean loss: 4197.59810816988
INFO:root:eval perplexity: 5.459654808044434
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.09s/it]
INFO:root:eval mean loss: 5123.342619334552
INFO:root:eval perplexity: 8.125483512878418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/43
 22%|â–ˆâ–ˆâ–       | 43/200 [5:03:55<18:15:56, 418.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4045.1623762263807
INFO:root:current train perplexity4.900649070739746
INFO:root:current mean train loss 4032.7302980222903
INFO:root:current train perplexity4.889545917510986
INFO:root:current mean train loss 4025.8995999308772
INFO:root:current train perplexity4.872847557067871
INFO:root:current mean train loss 4016.4146034529886
INFO:root:current train perplexity4.860971927642822
INFO:root:current mean train loss 4011.885780765025
INFO:root:current train perplexity4.86256217956543
INFO:root:current mean train loss 4017.212038156077
INFO:root:current train perplexity4.867588043212891
INFO:root:current mean train loss 4015.3951114162132
INFO:root:current train perplexity4.869539737701416
INFO:root:current mean train loss 4021.9789556038654
INFO:root:current train perplexity4.876626014709473
INFO:root:current mean train loss 4014.70573177315
INFO:root:current train perplexity4.870574474334717
INFO:root:current mean train loss 4015.6205026863236
INFO:root:current train perplexity4.871049880981445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.98s/it]
INFO:root:final mean train loss: 4014.613444912818
INFO:root:final train perplexity: 4.873835563659668
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.54s/it]
INFO:root:eval mean loss: 4194.087748642509
INFO:root:eval perplexity: 5.451910018920898
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.07s/it]
INFO:root:eval mean loss: 5130.543877784242
INFO:root:eval perplexity: 8.149446487426758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/44
 22%|â–ˆâ–ˆâ–       | 44/200 [5:10:58<18:12:47, 420.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3963.224068435968
INFO:root:current train perplexity4.835013389587402
INFO:root:current mean train loss 3999.163915368895
INFO:root:current train perplexity4.846355438232422
INFO:root:current mean train loss 4000.207010823892
INFO:root:current train perplexity4.85284423828125
INFO:root:current mean train loss 4004.3622546073716
INFO:root:current train perplexity4.85688591003418
INFO:root:current mean train loss 4006.5732762914013
INFO:root:current train perplexity4.857858180999756
INFO:root:current mean train loss 4006.66619950587
INFO:root:current train perplexity4.853679656982422
INFO:root:current mean train loss 4003.505365093366
INFO:root:current train perplexity4.847721099853516
INFO:root:current mean train loss 4003.9335774956307
INFO:root:current train perplexity4.8495073318481445
INFO:root:current mean train loss 4004.824025101443
INFO:root:current train perplexity4.847513198852539
INFO:root:current mean train loss 4002.6240637425244
INFO:root:current train perplexity4.845201015472412

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.69s/it]
INFO:root:final mean train loss: 4000.661941159156
INFO:root:final train perplexity: 4.847082138061523
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.82s/it]
INFO:root:eval mean loss: 4186.838756371897
INFO:root:eval perplexity: 5.4359517097473145
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.87s/it]
INFO:root:eval mean loss: 5127.0006475786795
INFO:root:eval perplexity: 8.137645721435547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [5:17:56<18:03:39, 419.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3978.5086069915255
INFO:root:current train perplexity4.800843715667725
INFO:root:current mean train loss 3985.644770784198
INFO:root:current train perplexity4.812129020690918
INFO:root:current mean train loss 3987.3135170954997
INFO:root:current train perplexity4.811699390411377
INFO:root:current mean train loss 3984.190200508139
INFO:root:current train perplexity4.818497657775879
INFO:root:current mean train loss 3988.8223618983184
INFO:root:current train perplexity4.817469120025635
INFO:root:current mean train loss 3989.6053268077762
INFO:root:current train perplexity4.8172287940979
INFO:root:current mean train loss 3989.089820780776
INFO:root:current train perplexity4.818014621734619
INFO:root:current mean train loss 3992.435431077075
INFO:root:current train perplexity4.821298122406006
INFO:root:current mean train loss 3994.410572056443
INFO:root:current train perplexity4.824210166931152
INFO:root:current mean train loss 3990.2836048496156
INFO:root:current train perplexity4.819938659667969

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.50s/it]
INFO:root:final mean train loss: 3986.595444525442
INFO:root:final train perplexity: 4.82025671005249
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.31s/it]
INFO:root:eval mean loss: 4184.791271886082
INFO:root:eval perplexity: 5.431453227996826
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.02s/it]
INFO:root:eval mean loss: 5124.62446150543
INFO:root:eval perplexity: 8.129744529724121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [5:24:55<17:56:16, 419.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3948.333590834888
INFO:root:current train perplexity4.789864540100098
INFO:root:current mean train loss 3962.817691277601
INFO:root:current train perplexity4.781867027282715
INFO:root:current mean train loss 3958.229540649871
INFO:root:current train perplexity4.776662349700928
INFO:root:current mean train loss 3968.753497796747
INFO:root:current train perplexity4.788228511810303
INFO:root:current mean train loss 3970.685235295102
INFO:root:current train perplexity4.786978721618652
INFO:root:current mean train loss 3969.900447031388
INFO:root:current train perplexity4.783237934112549
INFO:root:current mean train loss 3973.590192574611
INFO:root:current train perplexity4.7929863929748535
INFO:root:current mean train loss 3974.0646565224697
INFO:root:current train perplexity4.791059970855713
INFO:root:current mean train loss 3972.2374674479165
INFO:root:current train perplexity4.795054912567139
INFO:root:current mean train loss 3978.1237197134337
INFO:root:current train perplexity4.798238277435303

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.89s/it]
INFO:root:final mean train loss: 3975.3795648390246
INFO:root:final train perplexity: 4.798974514007568
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.10s/it]
INFO:root:eval mean loss: 4181.220542096077
INFO:root:eval perplexity: 5.4236159324646
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it]
INFO:root:eval mean loss: 5119.6139582640735
INFO:root:eval perplexity: 8.113104820251465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [5:32:03<17:55:47, 421.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3963.0144140625
INFO:root:current train perplexity4.761103630065918
INFO:root:current mean train loss 3936.4938113839285
INFO:root:current train perplexity4.74673318862915
INFO:root:current mean train loss 3950.1524476207387
INFO:root:current train perplexity4.763537883758545
INFO:root:current mean train loss 3948.4819375
INFO:root:current train perplexity4.756213188171387
INFO:root:current mean train loss 3954.3120250822367
INFO:root:current train perplexity4.762575149536133
INFO:root:current mean train loss 3954.1373789911686
INFO:root:current train perplexity4.76036262512207
INFO:root:current mean train loss 3957.382769820602
INFO:root:current train perplexity4.7617106437683105
INFO:root:current mean train loss 3958.200755418347
INFO:root:current train perplexity4.764098167419434
INFO:root:current mean train loss 3961.362263950893
INFO:root:current train perplexity4.768391132354736
INFO:root:current mean train loss 3965.0253192608175
INFO:root:current train perplexity4.774046421051025

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.43s/it]
INFO:root:final mean train loss: 3962.2761446429836
INFO:root:final train perplexity: 4.774230003356934
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.18s/it]
INFO:root:eval mean loss: 4175.977083679632
INFO:root:eval perplexity: 5.412128925323486
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.19s/it]
INFO:root:eval mean loss: 5118.371081629543
INFO:root:eval perplexity: 8.108981132507324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/48
 24%|â–ˆâ–ˆâ–       | 48/200 [5:39:04<17:48:02, 421.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3936.766413309488
INFO:root:current train perplexity4.74614143371582
INFO:root:current mean train loss 3942.9620194565405
INFO:root:current train perplexity4.74267053604126
INFO:root:current mean train loss 3954.1102928997348
INFO:root:current train perplexity4.7421135902404785
INFO:root:current mean train loss 3952.532793249225
INFO:root:current train perplexity4.743223667144775
INFO:root:current mean train loss 3947.011504937403
INFO:root:current train perplexity4.740985870361328
INFO:root:current mean train loss 3950.385704917319
INFO:root:current train perplexity4.749133586883545
INFO:root:current mean train loss 3948.99119270738
INFO:root:current train perplexity4.745238780975342
INFO:root:current mean train loss 3949.287987720007
INFO:root:current train perplexity4.7446818351745605
INFO:root:current mean train loss 3952.016036140554
INFO:root:current train perplexity4.7486748695373535
INFO:root:current mean train loss 3953.3776900174053
INFO:root:current train perplexity4.750495910644531

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.23s/it]
INFO:root:final mean train loss: 3949.3151876388056
INFO:root:final train perplexity: 4.749879360198975
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it]
INFO:root:eval mean loss: 4173.509178648604
INFO:root:eval perplexity: 5.4067301750183105
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.83s/it]
INFO:root:eval mean loss: 5124.131913854721
INFO:root:eval perplexity: 8.128105163574219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/49
 24%|â–ˆâ–ˆâ–       | 49/200 [5:46:00<17:37:07, 420.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3949.7841287130836
INFO:root:current train perplexity4.7174482345581055
INFO:root:current mean train loss 3921.1770837594077
INFO:root:current train perplexity4.703884601593018
INFO:root:current mean train loss 3925.758045733999
INFO:root:current train perplexity4.710671901702881
INFO:root:current mean train loss 3927.641672119765
INFO:root:current train perplexity4.70683479309082
INFO:root:current mean train loss 3935.6764316286913
INFO:root:current train perplexity4.719344139099121
INFO:root:current mean train loss 3940.372737878067
INFO:root:current train perplexity4.726739883422852
INFO:root:current mean train loss 3942.0579991209524
INFO:root:current train perplexity4.7257890701293945
INFO:root:current mean train loss 3941.741485325636
INFO:root:current train perplexity4.729269027709961
INFO:root:current mean train loss 3938.780420579493
INFO:root:current train perplexity4.7285003662109375
INFO:root:current mean train loss 3940.626092843403
INFO:root:current train perplexity4.727680206298828

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.98s/it]
INFO:root:final mean train loss: 3937.39022298013
INFO:root:final train perplexity: 4.7275848388671875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it]
INFO:root:eval mean loss: 4169.872830438276
INFO:root:eval perplexity: 5.398787021636963
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.90s/it]
INFO:root:eval mean loss: 5116.554841602948
INFO:root:eval perplexity: 8.102959632873535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [5:52:51<17:23:00, 417.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3896.686247238005
INFO:root:current train perplexity4.6758131980896
INFO:root:current mean train loss 3909.368067142352
INFO:root:current train perplexity4.685495376586914
INFO:root:current mean train loss 3916.962066752456
INFO:root:current train perplexity4.686652183532715
INFO:root:current mean train loss 3921.3396381578946
INFO:root:current train perplexity4.694192886352539
INFO:root:current mean train loss 3924.368398907189
INFO:root:current train perplexity4.697985649108887
INFO:root:current mean train loss 3925.4148324192665
INFO:root:current train perplexity4.697274208068848
INFO:root:current mean train loss 3930.1234534267705
INFO:root:current train perplexity4.702023506164551
INFO:root:current mean train loss 3926.67739673371
INFO:root:current train perplexity4.701723098754883
INFO:root:current mean train loss 3929.126576458652
INFO:root:current train perplexity4.705566883087158

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.53s/it]
INFO:root:final mean train loss: 3926.6621491216843
INFO:root:final train perplexity: 4.707616806030273
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.50s/it]
INFO:root:eval mean loss: 4167.936403964428
INFO:root:eval perplexity: 5.39456033706665
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.65s/it]
INFO:root:eval mean loss: 5115.93564730164
INFO:root:eval perplexity: 8.100912094116211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [5:59:51<17:18:42, 418.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3812.078543526786
INFO:root:current train perplexity4.689462184906006
INFO:root:current mean train loss 3907.245037328417
INFO:root:current train perplexity4.646581649780273
INFO:root:current mean train loss 3913.714298856431
INFO:root:current train perplexity4.66598653793335
INFO:root:current mean train loss 3908.478064720328
INFO:root:current train perplexity4.660350322723389
INFO:root:current mean train loss 3903.8308549360795
INFO:root:current train perplexity4.65883207321167
INFO:root:current mean train loss 3902.140905737642
INFO:root:current train perplexity4.659379482269287
INFO:root:current mean train loss 3908.935625707887
INFO:root:current train perplexity4.67227840423584
INFO:root:current mean train loss 3909.8537207445634
INFO:root:current train perplexity4.67481803894043
INFO:root:current mean train loss 3913.995980604283
INFO:root:current train perplexity4.67868185043335
INFO:root:current mean train loss 3918.2238131589374
INFO:root:current train perplexity4.683859348297119

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.22s/it]
INFO:root:final mean train loss: 3913.697204159152
INFO:root:final train perplexity: 4.68359899520874
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.22s/it]
INFO:root:eval mean loss: 4163.150762896165
INFO:root:eval perplexity: 5.384131908416748
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.08s/it]
INFO:root:eval mean loss: 5113.278569647607
INFO:root:eval perplexity: 8.092111587524414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [6:06:52<17:13:30, 418.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3854.4505208333335
INFO:root:current train perplexity4.60025691986084
INFO:root:current mean train loss 3906.591062330163
INFO:root:current train perplexity4.626584529876709
INFO:root:current mean train loss 3907.265629542151
INFO:root:current train perplexity4.643704891204834
INFO:root:current mean train loss 3909.7347237723216
INFO:root:current train perplexity4.6509246826171875
INFO:root:current mean train loss 3912.549811746988
INFO:root:current train perplexity4.653609752655029
INFO:root:current mean train loss 3910.02327774196
INFO:root:current train perplexity4.655445575714111
INFO:root:current mean train loss 3910.0789086318596
INFO:root:current train perplexity4.6573967933654785
INFO:root:current mean train loss 3908.2950622131775
INFO:root:current train perplexity4.66032075881958
INFO:root:current mean train loss 3906.1748792777034
INFO:root:current train perplexity4.66594934463501
INFO:root:current mean train loss 3907.316678940403
INFO:root:current train perplexity4.664868354797363

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.54s/it]
INFO:root:final mean train loss: 3901.840726175616
INFO:root:final train perplexity: 4.661741256713867
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.07s/it]
INFO:root:eval mean loss: 4160.407432610262
INFO:root:eval perplexity: 5.378161430358887
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.87s/it]
INFO:root:eval mean loss: 5119.565258269615
INFO:root:eval perplexity: 8.11294174194336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [6:13:46<17:02:32, 417.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3877.309474779212
INFO:root:current train perplexity4.6079421043396
INFO:root:current mean train loss 3885.6518336350355
INFO:root:current train perplexity4.639575004577637
INFO:root:current mean train loss 3886.112624369395
INFO:root:current train perplexity4.624063968658447
INFO:root:current mean train loss 3883.5154556888547
INFO:root:current train perplexity4.6267900466918945
INFO:root:current mean train loss 3888.1333850472815
INFO:root:current train perplexity4.628936767578125
INFO:root:current mean train loss 3889.0323469989844
INFO:root:current train perplexity4.631119251251221
INFO:root:current mean train loss 3888.79886770478
INFO:root:current train perplexity4.632306098937988
INFO:root:current mean train loss 3889.595788557335
INFO:root:current train perplexity4.637601375579834
INFO:root:current mean train loss 3890.7721171234243
INFO:root:current train perplexity4.635423183441162
INFO:root:current mean train loss 3891.0300911916815
INFO:root:current train perplexity4.6375274658203125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.44s/it]
INFO:root:final mean train loss: 3891.047958743188
INFO:root:final train perplexity: 4.641933917999268
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.76s/it]
INFO:root:eval mean loss: 4159.68415475399
INFO:root:eval perplexity: 5.376589775085449
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it]
INFO:root:eval mean loss: 5116.251431945368
INFO:root:eval perplexity: 8.101957321166992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [6:20:40<16:53:20, 416.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3880.2204353578627
INFO:root:current train perplexity4.620320796966553
INFO:root:current mean train loss 3848.3768058951573
INFO:root:current train perplexity4.596646785736084
INFO:root:current mean train loss 3861.9551996668697
INFO:root:current train perplexity4.610043525695801
INFO:root:current mean train loss 3872.861408521762
INFO:root:current train perplexity4.6161980628967285
INFO:root:current mean train loss 3875.265047785854
INFO:root:current train perplexity4.620492935180664
INFO:root:current mean train loss 3882.6399767169846
INFO:root:current train perplexity4.624734401702881
INFO:root:current mean train loss 3880.990207291254
INFO:root:current train perplexity4.626406669616699
INFO:root:current mean train loss 3882.5822262953147
INFO:root:current train perplexity4.626247882843018
INFO:root:current mean train loss 3883.692473594032
INFO:root:current train perplexity4.624907970428467
INFO:root:current mean train loss 3884.715188851034
INFO:root:current train perplexity4.625518321990967

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.73s/it]
INFO:root:final mean train loss: 3880.7420703518774
INFO:root:final train perplexity: 4.623098373413086
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.03s/it]
INFO:root:eval mean loss: 4158.04660142398
INFO:root:eval perplexity: 5.373029708862305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it]
INFO:root:eval mean loss: 5122.68762293606
INFO:root:eval perplexity: 8.123306274414062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [6:27:34<16:44:44, 415.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3868.4891200921475
INFO:root:current train perplexity4.578908443450928
INFO:root:current mean train loss 3878.239544106902
INFO:root:current train perplexity4.596571922302246
INFO:root:current mean train loss 3864.678709915991
INFO:root:current train perplexity4.578191757202148
INFO:root:current mean train loss 3871.94284012606
INFO:root:current train perplexity4.583072662353516
INFO:root:current mean train loss 3872.2882794703874
INFO:root:current train perplexity4.58837366104126
INFO:root:current mean train loss 3870.063492868738
INFO:root:current train perplexity4.591214656829834
INFO:root:current mean train loss 3872.7121138833872
INFO:root:current train perplexity4.59761905670166
INFO:root:current mean train loss 3871.907630270002
INFO:root:current train perplexity4.598943710327148
INFO:root:current mean train loss 3872.2111100570805
INFO:root:current train perplexity4.599783420562744
INFO:root:current mean train loss 3869.7991216657515
INFO:root:current train perplexity4.598419666290283

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.89s/it]
INFO:root:final mean train loss: 3869.08059360135
INFO:root:final train perplexity: 4.601876735687256
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.82s/it]
INFO:root:eval mean loss: 4155.595952460107
INFO:root:eval perplexity: 5.3677077293396
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.79s/it]
INFO:root:eval mean loss: 5121.076648035793
INFO:root:eval perplexity: 8.11795711517334
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [6:34:27<16:35:34, 414.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3856.610813871343
INFO:root:current train perplexity4.60249662399292
INFO:root:current mean train loss 3846.1325899500425
INFO:root:current train perplexity4.548776149749756
INFO:root:current mean train loss 3859.375016803201
INFO:root:current train perplexity4.5755133628845215
INFO:root:current mean train loss 3857.740227339247
INFO:root:current train perplexity4.574866771697998
INFO:root:current mean train loss 3859.250294388807
INFO:root:current train perplexity4.573470115661621
INFO:root:current mean train loss 3862.847188053445
INFO:root:current train perplexity4.579150199890137
INFO:root:current mean train loss 3864.8304396191556
INFO:root:current train perplexity4.58045768737793
INFO:root:current mean train loss 3867.225814390374
INFO:root:current train perplexity4.585257530212402
INFO:root:current mean train loss 3862.9648590268043
INFO:root:current train perplexity4.5820536613464355
INFO:root:current mean train loss 3863.1870253823754
INFO:root:current train perplexity4.583365440368652

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.46s/it]
INFO:root:final mean train loss: 3860.2068818000057
INFO:root:final train perplexity: 4.585793495178223
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.29s/it]
INFO:root:eval mean loss: 4153.390874335107
INFO:root:eval perplexity: 5.362924098968506
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.95s/it]
INFO:root:eval mean loss: 5116.578956117021
INFO:root:eval perplexity: 8.10304069519043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [6:41:31<16:35:04, 417.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3845.7382679332386
INFO:root:current train perplexity4.538357257843018
INFO:root:current mean train loss 3835.3919449344758
INFO:root:current train perplexity4.540655612945557
INFO:root:current mean train loss 3840.8744198069853
INFO:root:current train perplexity4.549856662750244
INFO:root:current mean train loss 3843.260809584067
INFO:root:current train perplexity4.553850173950195
INFO:root:current mean train loss 3841.157050030048
INFO:root:current train perplexity4.549276828765869
INFO:root:current mean train loss 3841.6272553315034
INFO:root:current train perplexity4.549210071563721
INFO:root:current mean train loss 3843.3449584029104
INFO:root:current train perplexity4.5560150146484375
INFO:root:current mean train loss 3846.028934059396
INFO:root:current train perplexity4.5561137199401855
INFO:root:current mean train loss 3845.1841091579863
INFO:root:current train perplexity4.558438301086426
INFO:root:current mean train loss 3850.373087522497
INFO:root:current train perplexity4.564726829528809

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.75s/it]
INFO:root:final mean train loss: 3848.023225661247
INFO:root:final train perplexity: 4.5638041496276855
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.19s/it]
INFO:root:eval mean loss: 4152.216265306405
INFO:root:eval perplexity: 5.360377311706543
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.72s/it]
INFO:root:eval mean loss: 5119.531765985151
INFO:root:eval perplexity: 8.112832069396973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [6:48:29<16:28:59, 417.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3819.213127015129
INFO:root:current train perplexity4.523586273193359
INFO:root:current mean train loss 3831.8231178704946
INFO:root:current train perplexity4.514226913452148
INFO:root:current mean train loss 3823.3555383718513
INFO:root:current train perplexity4.514892578125
INFO:root:current mean train loss 3830.358936488464
INFO:root:current train perplexity4.529599189758301
INFO:root:current mean train loss 3829.025404334841
INFO:root:current train perplexity4.532540321350098
INFO:root:current mean train loss 3832.610659448546
INFO:root:current train perplexity4.535643577575684
INFO:root:current mean train loss 3834.4580475820135
INFO:root:current train perplexity4.539898872375488
INFO:root:current mean train loss 3836.2614074147077
INFO:root:current train perplexity4.5405755043029785
INFO:root:current mean train loss 3838.403718349417
INFO:root:current train perplexity4.542886734008789
INFO:root:current mean train loss 3841.4541228582552
INFO:root:current train perplexity4.544066905975342

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.00s/it]
INFO:root:final mean train loss: 3838.015323146697
INFO:root:final train perplexity: 4.545819282531738
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.99s/it]
INFO:root:eval mean loss: 4147.41534034242
INFO:root:eval perplexity: 5.349981307983398
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.05s/it]
INFO:root:eval mean loss: 5114.647653133311
INFO:root:eval perplexity: 8.096644401550293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [6:55:33<16:26:29, 419.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3799.543223206426
INFO:root:current train perplexity4.472554683685303
INFO:root:current mean train loss 3810.6388831779973
INFO:root:current train perplexity4.502206802368164
INFO:root:current mean train loss 3806.299060554082
INFO:root:current train perplexity4.5034589767456055
INFO:root:current mean train loss 3807.0127163704515
INFO:root:current train perplexity4.504326343536377
INFO:root:current mean train loss 3812.6564360859543
INFO:root:current train perplexity4.511363506317139
INFO:root:current mean train loss 3816.365883421355
INFO:root:current train perplexity4.5127763748168945
INFO:root:current mean train loss 3818.1207746571117
INFO:root:current train perplexity4.5169878005981445
INFO:root:current mean train loss 3820.6943881854936
INFO:root:current train perplexity4.520159721374512
INFO:root:current mean train loss 3824.6164769414645
INFO:root:current train perplexity4.525364398956299
INFO:root:current mean train loss 3828.497697635733
INFO:root:current train perplexity4.526338577270508

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.06s/it]
INFO:root:final mean train loss: 3827.7445694708053
INFO:root:final train perplexity: 4.52743673324585
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.27s/it]
INFO:root:eval mean loss: 4144.891994611591
INFO:root:eval perplexity: 5.344525337219238
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.58s/it]
INFO:root:eval mean loss: 5113.217215896499
INFO:root:eval perplexity: 8.091910362243652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [7:02:35<16:20:21, 420.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3791.9448458514635
INFO:root:current train perplexity4.466203689575195
INFO:root:current mean train loss 3793.4753336133904
INFO:root:current train perplexity4.486789703369141
INFO:root:current mean train loss 3793.9673770371305
INFO:root:current train perplexity4.490157604217529
INFO:root:current mean train loss 3803.9352782558954
INFO:root:current train perplexity4.494338512420654
INFO:root:current mean train loss 3814.830699944546
INFO:root:current train perplexity4.5033087730407715
INFO:root:current mean train loss 3816.736409083549
INFO:root:current train perplexity4.500595569610596
INFO:root:current mean train loss 3819.7868213681654
INFO:root:current train perplexity4.503040313720703
INFO:root:current mean train loss 3820.00135389923
INFO:root:current train perplexity4.503396511077881
INFO:root:current mean train loss 3819.9804379199554
INFO:root:current train perplexity4.5074944496154785
INFO:root:current mean train loss 3820.4903792633586
INFO:root:current train perplexity4.510326862335205

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.20s/it]
INFO:root:final mean train loss: 3818.022784940658
INFO:root:final train perplexity: 4.510105133056641
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.93s/it]
INFO:root:eval mean loss: 4146.244426321476
INFO:root:eval perplexity: 5.34744930267334
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.12s/it]
INFO:root:eval mean loss: 5125.733940395057
INFO:root:eval perplexity: 8.133434295654297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [7:09:30<16:10:05, 418.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3828.029044315733
INFO:root:current train perplexity4.511490821838379
INFO:root:current mean train loss 3819.42248469878
INFO:root:current train perplexity4.505093574523926
INFO:root:current mean train loss 3812.462787694632
INFO:root:current train perplexity4.494145393371582
INFO:root:current mean train loss 3809.4062335977874
INFO:root:current train perplexity4.491563320159912
INFO:root:current mean train loss 3805.146496907886
INFO:root:current train perplexity4.485633850097656
INFO:root:current mean train loss 3807.248038972663
INFO:root:current train perplexity4.481003284454346
INFO:root:current mean train loss 3808.2114503019243
INFO:root:current train perplexity4.4845194816589355
INFO:root:current mean train loss 3809.434513542825
INFO:root:current train perplexity4.489637851715088
INFO:root:current mean train loss 3809.5786231900015
INFO:root:current train perplexity4.490527153015137
INFO:root:current mean train loss 3811.7420249869397
INFO:root:current train perplexity4.493403434753418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.24s/it]
INFO:root:final mean train loss: 3808.167104167323
INFO:root:final train perplexity: 4.492602825164795
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it]
INFO:root:eval mean loss: 4147.292438912899
INFO:root:eval perplexity: 5.349715232849121
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.03s/it]
INFO:root:eval mean loss: 5121.815052221853
INFO:root:eval perplexity: 8.120408058166504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [7:16:33<16:05:56, 419.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3776.979731188322
INFO:root:current train perplexity4.47209358215332
INFO:root:current mean train loss 3777.7802271133814
INFO:root:current train perplexity4.46490478515625
INFO:root:current mean train loss 3795.0682112354343
INFO:root:current train perplexity4.466789245605469
INFO:root:current mean train loss 3797.494780335245
INFO:root:current train perplexity4.466822147369385
INFO:root:current mean train loss 3797.8908079821654
INFO:root:current train perplexity4.470255374908447
INFO:root:current mean train loss 3798.8047900800943
INFO:root:current train perplexity4.476539611816406
INFO:root:current mean train loss 3798.4699271442223
INFO:root:current train perplexity4.475014686584473
INFO:root:current mean train loss 3799.7658458013952
INFO:root:current train perplexity4.474359035491943
INFO:root:current mean train loss 3802.0223291833972
INFO:root:current train perplexity4.475534915924072

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.44s/it]
INFO:root:final mean train loss: 3799.023974510931
INFO:root:final train perplexity: 4.476424694061279
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.60s/it]
INFO:root:eval mean loss: 4143.108730884309
INFO:root:eval perplexity: 5.340672016143799
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.19s/it]
INFO:root:eval mean loss: 5125.173206518728
INFO:root:eval perplexity: 8.131567001342773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [7:24:43<16:46:52, 440.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3635.5408528645835
INFO:root:current train perplexity4.557182312011719
INFO:root:current mean train loss 3769.484962833738
INFO:root:current train perplexity4.428112983703613
INFO:root:current mean train loss 3770.641275640779
INFO:root:current train perplexity4.431188583374023
INFO:root:current mean train loss 3775.2683226330446
INFO:root:current train perplexity4.433682441711426
INFO:root:current mean train loss 3780.6378013289004
INFO:root:current train perplexity4.442044258117676
INFO:root:current mean train loss 3787.439128898484
INFO:root:current train perplexity4.449856281280518
INFO:root:current mean train loss 3789.495824911899
INFO:root:current train perplexity4.455973148345947
INFO:root:current mean train loss 3788.260690094906
INFO:root:current train perplexity4.45361328125
INFO:root:current mean train loss 3786.766393602117
INFO:root:current train perplexity4.450546741485596
INFO:root:current mean train loss 3788.7017407253597
INFO:root:current train perplexity4.455080986022949

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.53s/it]
INFO:root:final mean train loss: 3788.114749539283
INFO:root:final train perplexity: 4.457200050354004
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.97s/it]
INFO:root:eval mean loss: 4143.111906443927
INFO:root:eval perplexity: 5.34067964553833
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.31s/it]
INFO:root:eval mean loss: 5128.557956560284
INFO:root:eval perplexity: 8.142828941345215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [7:31:35<16:19:46, 432.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3753.3924449573865
INFO:root:current train perplexity4.442976474761963
INFO:root:current mean train loss 3764.842359938063
INFO:root:current train perplexity4.41404390335083
INFO:root:current mean train loss 3759.087179030287
INFO:root:current train perplexity4.417464733123779
INFO:root:current mean train loss 3758.0445756820236
INFO:root:current train perplexity4.4156174659729
INFO:root:current mean train loss 3764.7278449808014
INFO:root:current train perplexity4.424959182739258
INFO:root:current mean train loss 3771.128498234161
INFO:root:current train perplexity4.429167747497559
INFO:root:current mean train loss 3774.3066865761816
INFO:root:current train perplexity4.4274582862854
INFO:root:current mean train loss 3777.0127955784105
INFO:root:current train perplexity4.43354606628418
INFO:root:current mean train loss 3776.9443503872535
INFO:root:current train perplexity4.438479423522949
INFO:root:current mean train loss 3781.3523549520614
INFO:root:current train perplexity4.440733909606934

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.71s/it]
INFO:root:final mean train loss: 3780.437813112813
INFO:root:final train perplexity: 4.443720817565918
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.79s/it]
INFO:root:eval mean loss: 4138.673369279145
INFO:root:eval perplexity: 5.3311028480529785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.30s/it]
INFO:root:eval mean loss: 5121.843578582115
INFO:root:eval perplexity: 8.120504379272461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [7:39:21<16:35:54, 442.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3740.0979903371713
INFO:root:current train perplexity4.3979315757751465
INFO:root:current mean train loss 3752.5811777836134
INFO:root:current train perplexity4.401256084442139
INFO:root:current mean train loss 3751.9900337114727
INFO:root:current train perplexity4.405484199523926
INFO:root:current mean train loss 3762.189383479869
INFO:root:current train perplexity4.424620151519775
INFO:root:current mean train loss 3764.9911136308547
INFO:root:current train perplexity4.428322792053223
INFO:root:current mean train loss 3763.2124639669137
INFO:root:current train perplexity4.423943519592285
INFO:root:current mean train loss 3763.7358098684876
INFO:root:current train perplexity4.421285152435303
INFO:root:current mean train loss 3769.2716684142474
INFO:root:current train perplexity4.422948837280273
INFO:root:current mean train loss 3773.685277992407
INFO:root:current train perplexity4.426757335662842
INFO:root:current mean train loss 3773.8555160373026
INFO:root:current train perplexity4.428084850311279

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.43s/it]
INFO:root:final mean train loss: 3770.807533694852
INFO:root:final train perplexity: 4.426868915557861
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.07s/it]
INFO:root:eval mean loss: 4141.845729097407
INFO:root:eval perplexity: 5.337945461273193
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.16s/it]
INFO:root:eval mean loss: 5133.577641913232
INFO:root:eval perplexity: 8.159562110900879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [7:46:26<16:16:35, 437.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3751.1252170138887
INFO:root:current train perplexity4.378908157348633
INFO:root:current mean train loss 3769.0391624630906
INFO:root:current train perplexity4.397883892059326
INFO:root:current mean train loss 3762.651419887459
INFO:root:current train perplexity4.391880035400391
INFO:root:current mean train loss 3760.5752333894784
INFO:root:current train perplexity4.400911808013916
INFO:root:current mean train loss 3762.138891430035
INFO:root:current train perplexity4.4024271965026855
INFO:root:current mean train loss 3760.830559920541
INFO:root:current train perplexity4.4015278816223145
INFO:root:current mean train loss 3761.5140709884618
INFO:root:current train perplexity4.404118537902832
INFO:root:current mean train loss 3764.0796318211615
INFO:root:current train perplexity4.403641223907471
INFO:root:current mean train loss 3766.9155028411237
INFO:root:current train perplexity4.406030654907227
INFO:root:current mean train loss 3765.5654599746326
INFO:root:current train perplexity4.409855842590332

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.65s/it]
INFO:root:final mean train loss: 3761.8353681871968
INFO:root:final train perplexity: 4.411226749420166
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.70s/it]
INFO:root:eval mean loss: 4137.558287275599
INFO:root:eval perplexity: 5.328699111938477
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it]
INFO:root:eval mean loss: 5128.616513948914
INFO:root:eval perplexity: 8.143025398254395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [7:53:34<16:03:13, 434.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3765.993603515625
INFO:root:current train perplexity4.389566421508789
INFO:root:current mean train loss 3769.053973162616
INFO:root:current train perplexity4.40474271774292
INFO:root:current mean train loss 3767.1492540724735
INFO:root:current train perplexity4.391730308532715
INFO:root:current mean train loss 3750.865410739272
INFO:root:current train perplexity4.381224155426025
INFO:root:current mean train loss 3747.0367142600576
INFO:root:current train perplexity4.3842878341674805
INFO:root:current mean train loss 3749.098501843604
INFO:root:current train perplexity4.383182048797607
INFO:root:current mean train loss 3747.5720364788385
INFO:root:current train perplexity4.385364055633545
INFO:root:current mean train loss 3747.7903596008714
INFO:root:current train perplexity4.3865180015563965
INFO:root:current mean train loss 3750.3902776478294
INFO:root:current train perplexity4.392200469970703
INFO:root:current mean train loss 3755.6797418114975
INFO:root:current train perplexity4.396884918212891

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.56s/it]
INFO:root:final mean train loss: 3753.582992738293
INFO:root:final train perplexity: 4.396888256072998
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.97s/it]
INFO:root:eval mean loss: 4139.277411278258
INFO:root:eval perplexity: 5.332404613494873
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.55s/it]
INFO:root:eval mean loss: 5130.474337530474
INFO:root:eval perplexity: 8.149212837219238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [8:00:36<15:47:12, 430.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3715.7683957122094
INFO:root:current train perplexity4.370387077331543
INFO:root:current mean train loss 3724.1418917996066
INFO:root:current train perplexity4.374599456787109
INFO:root:current mean train loss 3724.877669471772
INFO:root:current train perplexity4.359418869018555
INFO:root:current mean train loss 3735.416883285122
INFO:root:current train perplexity4.357529163360596
INFO:root:current mean train loss 3739.463770192579
INFO:root:current train perplexity4.361203670501709
INFO:root:current mean train loss 3744.919183158523
INFO:root:current train perplexity4.368297576904297
INFO:root:current mean train loss 3746.577024658583
INFO:root:current train perplexity4.374491214752197
INFO:root:current mean train loss 3745.1639948109437
INFO:root:current train perplexity4.37606954574585
INFO:root:current mean train loss 3746.270057759675
INFO:root:current train perplexity4.380594730377197
INFO:root:current mean train loss 3748.0079533404028
INFO:root:current train perplexity4.380644798278809

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.74s/it]
INFO:root:final mean train loss: 3744.688274568127
INFO:root:final train perplexity: 4.381485939025879
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.37s/it]
INFO:root:eval mean loss: 4138.475606715426
INFO:root:eval perplexity: 5.3306756019592285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.61s/it]
INFO:root:eval mean loss: 5134.181638893506
INFO:root:eval perplexity: 8.161575317382812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [8:07:29<15:28:27, 425.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3711.6369964001224
INFO:root:current train perplexity4.3194451332092285
INFO:root:current mean train loss 3718.6088155784355
INFO:root:current train perplexity4.328457832336426
INFO:root:current mean train loss 3716.5836740926916
INFO:root:current train perplexity4.331182956695557
INFO:root:current mean train loss 3728.071572849893
INFO:root:current train perplexity4.339522838592529
INFO:root:current mean train loss 3732.6058736661585
INFO:root:current train perplexity4.345652103424072
INFO:root:current mean train loss 3730.124614071716
INFO:root:current train perplexity4.34730863571167
INFO:root:current mean train loss 3736.070798531106
INFO:root:current train perplexity4.354194641113281
INFO:root:current mean train loss 3736.204091484791
INFO:root:current train perplexity4.35693883895874
INFO:root:current mean train loss 3736.8942303057984
INFO:root:current train perplexity4.361103534698486
INFO:root:current mean train loss 3738.546624954817
INFO:root:current train perplexity4.365091323852539

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.89s/it]
INFO:root:final mean train loss: 3735.8695858370875
INFO:root:final train perplexity: 4.366268157958984
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.18s/it]
INFO:root:eval mean loss: 4137.090576171875
INFO:root:eval perplexity: 5.327691078186035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.74s/it]
INFO:root:eval mean loss: 5131.488584261414
INFO:root:eval perplexity: 8.152594566345215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [8:14:23<15:14:02, 421.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3711.9476918365995
INFO:root:current train perplexity4.348374366760254
INFO:root:current mean train loss 3726.1020830262382
INFO:root:current train perplexity4.346118927001953
INFO:root:current mean train loss 3734.7280584504706
INFO:root:current train perplexity4.35353946685791
INFO:root:current mean train loss 3728.148972705214
INFO:root:current train perplexity4.345278739929199
INFO:root:current mean train loss 3725.153118191721
INFO:root:current train perplexity4.338444232940674
INFO:root:current mean train loss 3725.7284405048076
INFO:root:current train perplexity4.343596935272217
INFO:root:current mean train loss 3725.1918441471453
INFO:root:current train perplexity4.343234539031982
INFO:root:current mean train loss 3727.8558856225295
INFO:root:current train perplexity4.346307277679443
INFO:root:current mean train loss 3728.698193586747
INFO:root:current train perplexity4.349518775939941
INFO:root:current mean train loss 3729.435299934013
INFO:root:current train perplexity4.351463794708252

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.77s/it]
INFO:root:final mean train loss: 3727.2326123022262
INFO:root:final train perplexity: 4.351415157318115
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.30s/it]
INFO:root:eval mean loss: 4139.18118870512
INFO:root:eval perplexity: 5.332197189331055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.26s/it]
INFO:root:eval mean loss: 5137.93475731383
INFO:root:eval perplexity: 8.174112319946289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [8:21:19<15:03:31, 420.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3721.135698460821
INFO:root:current train perplexity4.335669040679932
INFO:root:current mean train loss 3727.27002391701
INFO:root:current train perplexity4.328369617462158
INFO:root:current mean train loss 3724.1318267936563
INFO:root:current train perplexity4.331540584564209
INFO:root:current mean train loss 3724.6204584521884
INFO:root:current train perplexity4.332945346832275
INFO:root:current mean train loss 3722.6726581320263
INFO:root:current train perplexity4.3350830078125
INFO:root:current mean train loss 3723.322014164462
INFO:root:current train perplexity4.336920738220215
INFO:root:current mean train loss 3723.4198431789964
INFO:root:current train perplexity4.336691856384277
INFO:root:current mean train loss 3721.938474652665
INFO:root:current train perplexity4.33595085144043
INFO:root:current mean train loss 3723.485822948205
INFO:root:current train perplexity4.339907169342041
INFO:root:current mean train loss 3723.400558266546
INFO:root:current train perplexity4.339667320251465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.98s/it]
INFO:root:final mean train loss: 3720.272718860257
INFO:root:final train perplexity: 4.33948278427124
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.57s/it]
INFO:root:eval mean loss: 4134.892301085993
INFO:root:eval perplexity: 5.322958469390869
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.33s/it]
INFO:root:eval mean loss: 5137.095734291888
INFO:root:eval perplexity: 8.171308517456055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [8:29:19<15:35:02, 438.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3709.9701399739583
INFO:root:current train perplexity4.316999435424805
INFO:root:current mean train loss 3705.9819545200894
INFO:root:current train perplexity4.299040794372559
INFO:root:current mean train loss 3706.9983513849434
INFO:root:current train perplexity4.300699234008789
INFO:root:current mean train loss 3715.1658756510415
INFO:root:current train perplexity4.310972690582275
INFO:root:current mean train loss 3714.003987972862
INFO:root:current train perplexity4.313290119171143
INFO:root:current mean train loss 3713.472993800951
INFO:root:current train perplexity4.3154754638671875
INFO:root:current mean train loss 3714.8104712818285
INFO:root:current train perplexity4.317437171936035
INFO:root:current mean train loss 3713.5399152595764
INFO:root:current train perplexity4.318113327026367
INFO:root:current mean train loss 3714.3195337611605
INFO:root:current train perplexity4.320251941680908
INFO:root:current mean train loss 3712.9812915665066
INFO:root:current train perplexity4.323147773742676

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.64s/it]
INFO:root:final mean train loss: 3711.3511810302734
INFO:root:final train perplexity: 4.324235916137695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.72s/it]
INFO:root:eval mean loss: 4135.565751745346
INFO:root:eval perplexity: 5.324406623840332
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.12s/it]
INFO:root:eval mean loss: 5141.877635333555
INFO:root:eval perplexity: 8.187301635742188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [8:36:12<15:11:13, 430.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3672.0024472891564
INFO:root:current train perplexity4.255264759063721
INFO:root:current mean train loss 3694.075559522285
INFO:root:current train perplexity4.296473979949951
INFO:root:current mean train loss 3691.6446356352144
INFO:root:current train perplexity4.290729522705078
INFO:root:current mean train loss 3699.906371114148
INFO:root:current train perplexity4.291764259338379
INFO:root:current mean train loss 3703.469906003332
INFO:root:current train perplexity4.2993574142456055
INFO:root:current mean train loss 3701.993491118809
INFO:root:current train perplexity4.298581600189209
INFO:root:current mean train loss 3701.84762622392
INFO:root:current train perplexity4.300955772399902
INFO:root:current mean train loss 3703.144937215637
INFO:root:current train perplexity4.30526876449585
INFO:root:current mean train loss 3706.386001811562
INFO:root:current train perplexity4.309106349945068
INFO:root:current mean train loss 3705.985612343432
INFO:root:current train perplexity4.31097936630249

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.54s/it]
INFO:root:final mean train loss: 3703.9464964097547
INFO:root:final train perplexity: 4.311621189117432
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.80s/it]
INFO:root:eval mean loss: 4136.81191129211
INFO:root:eval perplexity: 5.327091217041016
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.58s/it]
INFO:root:eval mean loss: 5140.129264669215
INFO:root:eval perplexity: 8.181451797485352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [8:43:16<14:59:59, 428.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3682.9251641912774
INFO:root:current train perplexity4.29009485244751
INFO:root:current mean train loss 3674.755842758099
INFO:root:current train perplexity4.281083583831787
INFO:root:current mean train loss 3677.929898081776
INFO:root:current train perplexity4.276576995849609
INFO:root:current mean train loss 3681.1548232446853
INFO:root:current train perplexity4.280833721160889
INFO:root:current mean train loss 3684.268243420634
INFO:root:current train perplexity4.28323221206665
INFO:root:current mean train loss 3689.053341628331
INFO:root:current train perplexity4.287240982055664
INFO:root:current mean train loss 3690.0580835632236
INFO:root:current train perplexity4.290289878845215
INFO:root:current mean train loss 3692.338731690996
INFO:root:current train perplexity4.289549350738525
INFO:root:current mean train loss 3696.1189112807765
INFO:root:current train perplexity4.293516159057617
INFO:root:current mean train loss 3698.4891410388814
INFO:root:current train perplexity4.297509670257568

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.98s/it]
INFO:root:final mean train loss: 3695.620304292248
INFO:root:final train perplexity: 4.297481536865234
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.30s/it]
INFO:root:eval mean loss: 4134.9889288286795
INFO:root:eval perplexity: 5.323165416717529
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.89s/it]
INFO:root:eval mean loss: 5144.007883491246
INFO:root:eval perplexity: 8.194435119628906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [8:50:30<14:56:41, 430.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3679.7677532157513
INFO:root:current train perplexity4.264057636260986
INFO:root:current mean train loss 3668.033985847205
INFO:root:current train perplexity4.256961345672607
INFO:root:current mean train loss 3660.241089275449
INFO:root:current train perplexity4.246905326843262
INFO:root:current mean train loss 3673.1006055177004
INFO:root:current train perplexity4.258143424987793
INFO:root:current mean train loss 3673.4058429358715
INFO:root:current train perplexity4.261263847351074
INFO:root:current mean train loss 3679.301559728454
INFO:root:current train perplexity4.2694091796875
INFO:root:current mean train loss 3684.940165638412
INFO:root:current train perplexity4.276660919189453
INFO:root:current mean train loss 3684.8720403678426
INFO:root:current train perplexity4.2782487869262695
INFO:root:current mean train loss 3689.9496125252017
INFO:root:current train perplexity4.279279708862305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.21s/it]
INFO:root:final mean train loss: 3686.597837140483
INFO:root:final train perplexity: 4.282210826873779
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.55s/it]
INFO:root:eval mean loss: 4137.196635361259
INFO:root:eval perplexity: 5.327919006347656
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.89s/it]
INFO:root:eval mean loss: 5147.082090120789
INFO:root:eval perplexity: 8.204745292663574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [8:57:31<14:43:34, 427.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3606.5911690848216
INFO:root:current train perplexity4.196266174316406
INFO:root:current mean train loss 3697.3724148474007
INFO:root:current train perplexity4.265326499938965
INFO:root:current mean train loss 3689.478312764191
INFO:root:current train perplexity4.274143218994141
INFO:root:current mean train loss 3690.349953716663
INFO:root:current train perplexity4.271299362182617
INFO:root:current mean train loss 3689.0553863300447
INFO:root:current train perplexity4.273469924926758
INFO:root:current mean train loss 3683.360976601023
INFO:root:current train perplexity4.265497207641602
INFO:root:current mean train loss 3681.012119751982
INFO:root:current train perplexity4.260736465454102
INFO:root:current mean train loss 3677.998341432218
INFO:root:current train perplexity4.259565353393555
INFO:root:current mean train loss 3681.9581049241983
INFO:root:current train perplexity4.263920307159424
INFO:root:current mean train loss 3680.3754056448975
INFO:root:current train perplexity4.267158508300781

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.67s/it]
INFO:root:final mean train loss: 3678.9345274894467
INFO:root:final train perplexity: 4.269284248352051
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.67s/it]
INFO:root:eval mean loss: 4138.598090854943
INFO:root:eval perplexity: 5.330939292907715
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.44s/it]
INFO:root:eval mean loss: 5151.494244514628
INFO:root:eval perplexity: 8.219561576843262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [9:04:25<14:28:07, 423.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3644.6707682291667
INFO:root:current train perplexity4.232794761657715
INFO:root:current mean train loss 3675.345556640625
INFO:root:current train perplexity4.240607261657715
INFO:root:current mean train loss 3674.6287268350293
INFO:root:current train perplexity4.242704391479492
INFO:root:current mean train loss 3674.3359987289186
INFO:root:current train perplexity4.2425856590271
INFO:root:current mean train loss 3673.395813135354
INFO:root:current train perplexity4.246041297912598
INFO:root:current mean train loss 3671.5798629020023
INFO:root:current train perplexity4.249763488769531
INFO:root:current mean train loss 3666.815177210366
INFO:root:current train perplexity4.2497477531433105
INFO:root:current mean train loss 3670.9077008440777
INFO:root:current train perplexity4.251894950866699
INFO:root:current mean train loss 3672.3430181772433
INFO:root:current train perplexity4.2535600662231445
INFO:root:current mean train loss 3674.609250928535
INFO:root:current train perplexity4.257349014282227

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.39s/it]
INFO:root:final mean train loss: 3672.352755515806
INFO:root:final train perplexity: 4.258212089538574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it]
INFO:root:eval mean loss: 4137.180883962212
INFO:root:eval perplexity: 5.327884674072266
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.49s/it]
INFO:root:eval mean loss: 5153.958504751219
INFO:root:eval perplexity: 8.227849006652832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [9:11:20<14:15:37, 420.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3587.542183254076
INFO:root:current train perplexity4.18292236328125
INFO:root:current mean train loss 3633.043226784807
INFO:root:current train perplexity4.209575653076172
INFO:root:current mean train loss 3643.3387697502103
INFO:root:current train perplexity4.218096733093262
INFO:root:current mean train loss 3642.970929125145
INFO:root:current train perplexity4.2223968505859375
INFO:root:current mean train loss 3650.811844918181
INFO:root:current train perplexity4.224842548370361
INFO:root:current mean train loss 3654.4100740917784
INFO:root:current train perplexity4.229916095733643
INFO:root:current mean train loss 3655.5166677900534
INFO:root:current train perplexity4.235164642333984
INFO:root:current mean train loss 3661.159259041645
INFO:root:current train perplexity4.2357177734375
INFO:root:current mean train loss 3662.0733359280075
INFO:root:current train perplexity4.23853063583374
INFO:root:current mean train loss 3665.343733865029
INFO:root:current train perplexity4.24163293838501

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.71s/it]
INFO:root:final mean train loss: 3663.8262892077046
INFO:root:final train perplexity: 4.2439117431640625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.06s/it]
INFO:root:eval mean loss: 4138.338889696919
INFO:root:eval perplexity: 5.330380916595459
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.21s/it]
INFO:root:eval mean loss: 5155.761626980829
INFO:root:eval perplexity: 8.233917236328125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [9:18:20<14:08:10, 420.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3634.074525894657
INFO:root:current train perplexity4.155316352844238
INFO:root:current mean train loss 3648.129064661856
INFO:root:current train perplexity4.198265552520752
INFO:root:current mean train loss 3645.835522143872
INFO:root:current train perplexity4.2012434005737305
INFO:root:current mean train loss 3644.2012375200625
INFO:root:current train perplexity4.2153801918029785
INFO:root:current mean train loss 3653.665386863762
INFO:root:current train perplexity4.222655296325684
INFO:root:current mean train loss 3655.2434091226755
INFO:root:current train perplexity4.228088855743408
INFO:root:current mean train loss 3655.0385185036153
INFO:root:current train perplexity4.223306655883789
INFO:root:current mean train loss 3653.9607177400394
INFO:root:current train perplexity4.221884727478027
INFO:root:current mean train loss 3654.0131741924265
INFO:root:current train perplexity4.224245071411133
INFO:root:current mean train loss 3659.4009300420416
INFO:root:current train perplexity4.230240345001221

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.52s/it]
INFO:root:final mean train loss: 3656.821694650958
INFO:root:final train perplexity: 4.2322001457214355
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.06s/it]
INFO:root:eval mean loss: 4134.927308427526
INFO:root:eval perplexity: 5.323032855987549
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.75s/it]
INFO:root:eval mean loss: 5156.351553842531
INFO:root:eval perplexity: 8.235901832580566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [9:26:38<14:47:48, 443.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3631.002447666266
INFO:root:current train perplexity4.203086853027344
INFO:root:current mean train loss 3634.7160381070144
INFO:root:current train perplexity4.189516067504883
INFO:root:current mean train loss 3646.6055698793803
INFO:root:current train perplexity4.20172119140625
INFO:root:current mean train loss 3638.887114848359
INFO:root:current train perplexity4.2104716300964355
INFO:root:current mean train loss 3638.295663751068
INFO:root:current train perplexity4.217267990112305
INFO:root:current mean train loss 3641.2216647401146
INFO:root:current train perplexity4.216609001159668
INFO:root:current mean train loss 3643.3564319401653
INFO:root:current train perplexity4.218052864074707
INFO:root:current mean train loss 3644.764890926294
INFO:root:current train perplexity4.215527057647705
INFO:root:current mean train loss 3649.045195987597
INFO:root:current train perplexity4.219659805297852
INFO:root:current mean train loss 3652.075812034079
INFO:root:current train perplexity4.220177173614502

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.84s/it]
INFO:root:final mean train loss: 3648.6636756158646
INFO:root:final train perplexity: 4.218600273132324
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it]
INFO:root:eval mean loss: 4140.570418121121
INFO:root:eval perplexity: 5.335193157196045
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.68s/it]
INFO:root:eval mean loss: 5160.665795725288
INFO:root:eval perplexity: 8.250445365905762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [9:33:44<14:29:31, 438.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3591.572946102061
INFO:root:current train perplexity4.141822338104248
INFO:root:current mean train loss 3637.6567482461733
INFO:root:current train perplexity4.170170307159424
INFO:root:current mean train loss 3644.3568446356276
INFO:root:current train perplexity4.189820289611816
INFO:root:current mean train loss 3643.9936509365994
INFO:root:current train perplexity4.1936354637146
INFO:root:current mean train loss 3642.684138833543
INFO:root:current train perplexity4.191478252410889
INFO:root:current mean train loss 3642.206559929159
INFO:root:current train perplexity4.187948226928711
INFO:root:current mean train loss 3643.146488525768
INFO:root:current train perplexity4.196991443634033
INFO:root:current mean train loss 3642.067642640876
INFO:root:current train perplexity4.198430061340332
INFO:root:current mean train loss 3644.651066551524
INFO:root:current train perplexity4.204683780670166
INFO:root:current mean train loss 3643.527461308738
INFO:root:current train perplexity4.206662178039551

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.55s/it]
INFO:root:final mean train loss: 3640.6522707170056
INFO:root:final train perplexity: 4.205287456512451
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.56s/it]
INFO:root:eval mean loss: 4140.530053537788
INFO:root:eval perplexity: 5.33510684967041
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.27s/it]
INFO:root:eval mean loss: 5161.918197307181
INFO:root:eval perplexity: 8.254671096801758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [9:41:22<14:33:50, 444.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3613.3461692116475
INFO:root:current train perplexity4.147247791290283
INFO:root:current mean train loss 3622.0796575730847
INFO:root:current train perplexity4.168501377105713
INFO:root:current mean train loss 3630.5757199754903
INFO:root:current train perplexity4.178813457489014
INFO:root:current mean train loss 3629.259609512544
INFO:root:current train perplexity4.178136348724365
INFO:root:current mean train loss 3636.6790044428226
INFO:root:current train perplexity4.184944152832031
INFO:root:current mean train loss 3631.9183743313624
INFO:root:current train perplexity4.184324264526367
INFO:root:current mean train loss 3633.7528920413883
INFO:root:current train perplexity4.189875602722168
INFO:root:current mean train loss 3630.549615842301
INFO:root:current train perplexity4.190277099609375
INFO:root:current mean train loss 3631.9035972907527
INFO:root:current train perplexity4.190369606018066
INFO:root:current mean train loss 3635.4165542682426
INFO:root:current train perplexity4.193112373352051

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.00s/it]
INFO:root:final mean train loss: 3634.3727570810624
INFO:root:final train perplexity: 4.194881439208984
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.94s/it]
INFO:root:eval mean loss: 4139.230640167885
INFO:root:eval perplexity: 5.332303524017334
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.00s/it]
INFO:root:eval mean loss: 5161.14217641844
INFO:root:eval perplexity: 8.252050399780273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [9:48:28<14:15:53, 438.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3597.6513478112597
INFO:root:current train perplexity4.138634204864502
INFO:root:current mean train loss 3610.574010556461
INFO:root:current train perplexity4.16493034362793
INFO:root:current mean train loss 3617.9419882886764
INFO:root:current train perplexity4.176148414611816
INFO:root:current mean train loss 3624.3331456880596
INFO:root:current train perplexity4.178452968597412
INFO:root:current mean train loss 3624.562156199379
INFO:root:current train perplexity4.179412364959717
INFO:root:current mean train loss 3624.933785853547
INFO:root:current train perplexity4.1781392097473145
INFO:root:current mean train loss 3629.091228686487
INFO:root:current train perplexity4.177750110626221
INFO:root:current mean train loss 3630.176879082876
INFO:root:current train perplexity4.1802873611450195
INFO:root:current mean train loss 3629.518277730754
INFO:root:current train perplexity4.181354999542236
INFO:root:current mean train loss 3630.45718640479
INFO:root:current train perplexity4.182509422302246

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.36s/it]
INFO:root:final mean train loss: 3627.435289752099
INFO:root:final train perplexity: 4.183416366577148
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.76s/it]
INFO:root:eval mean loss: 4141.18782378934
INFO:root:eval perplexity: 5.336524486541748
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.86s/it]
INFO:root:eval mean loss: 5162.3520542442375
INFO:root:eval perplexity: 8.256135940551758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [9:56:48<14:44:03, 457.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3630.302603708187
INFO:root:current train perplexity4.1695661544799805
INFO:root:current mean train loss 3626.1198930349965
INFO:root:current train perplexity4.173730373382568
INFO:root:current mean train loss 3615.62964948253
INFO:root:current train perplexity4.164738655090332
INFO:root:current mean train loss 3612.094275132665
INFO:root:current train perplexity4.162342548370361
INFO:root:current mean train loss 3617.02189801453
INFO:root:current train perplexity4.160898208618164
INFO:root:current mean train loss 3618.230561104422
INFO:root:current train perplexity4.164603233337402
INFO:root:current mean train loss 3620.8991153449842
INFO:root:current train perplexity4.16684627532959
INFO:root:current mean train loss 3621.1466921003566
INFO:root:current train perplexity4.167973041534424
INFO:root:current mean train loss 3622.441904341723
INFO:root:current train perplexity4.169710159301758
INFO:root:current mean train loss 3623.4162605199213
INFO:root:current train perplexity4.171420574188232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.20s/it]
INFO:root:final mean train loss: 3620.7380671962615
INFO:root:final train perplexity: 4.172378063201904
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.13s/it]
INFO:root:eval mean loss: 4139.798400446033
INFO:root:eval perplexity: 5.333528995513916
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.29s/it]
INFO:root:eval mean loss: 5171.006325146831
INFO:root:eval perplexity: 8.285405158996582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [10:03:47<14:13:59, 445.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3623.228667053995
INFO:root:current train perplexity4.148318767547607
INFO:root:current mean train loss 3626.3315238739524
INFO:root:current train perplexity4.149672031402588
INFO:root:current mean train loss 3623.9278665084566
INFO:root:current train perplexity4.155679225921631
INFO:root:current mean train loss 3621.7978399674307
INFO:root:current train perplexity4.1534600257873535
INFO:root:current mean train loss 3615.6280219410555
INFO:root:current train perplexity4.152491092681885
INFO:root:current mean train loss 3617.628620786782
INFO:root:current train perplexity4.154171466827393
INFO:root:current mean train loss 3617.406330541237
INFO:root:current train perplexity4.1533684730529785
INFO:root:current mean train loss 3617.8147326801186
INFO:root:current train perplexity4.154139995574951
INFO:root:current mean train loss 3614.7224629372868
INFO:root:current train perplexity4.156553745269775
INFO:root:current mean train loss 3614.931851847788
INFO:root:current train perplexity4.158576965332031

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.11s/it]
INFO:root:final mean train loss: 3612.43079345457
INFO:root:final train perplexity: 4.158724784851074
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.12s/it]
INFO:root:eval mean loss: 4138.766883795988
INFO:root:eval perplexity: 5.331303596496582
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.43s/it]
INFO:root:eval mean loss: 5166.022523271276
INFO:root:eval perplexity: 8.268536567687988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [10:12:21<14:46:00, 466.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3589.9755326194327
INFO:root:current train perplexity4.1204071044921875
INFO:root:current mean train loss 3599.9764358602106
INFO:root:current train perplexity4.136023044586182
INFO:root:current mean train loss 3588.018148070013
INFO:root:current train perplexity4.127015113830566
INFO:root:current mean train loss 3595.147477970567
INFO:root:current train perplexity4.131770133972168
INFO:root:current mean train loss 3601.6512177954955
INFO:root:current train perplexity4.137687683105469
INFO:root:current mean train loss 3598.9473242686595
INFO:root:current train perplexity4.139154434204102
INFO:root:current mean train loss 3604.343460371748
INFO:root:current train perplexity4.14325475692749
INFO:root:current mean train loss 3604.6938715429437
INFO:root:current train perplexity4.143468379974365
INFO:root:current mean train loss 3607.1863247119854
INFO:root:current train perplexity4.147309303283691
INFO:root:current mean train loss 3608.7460141012853
INFO:root:current train perplexity4.148146629333496

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.90s/it]
INFO:root:final mean train loss: 3605.7725459683325
INFO:root:final train perplexity: 4.1478142738342285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.52s/it]
INFO:root:eval mean loss: 4141.415011358599
INFO:root:eval perplexity: 5.337015628814697
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.95s/it]
INFO:root:eval mean loss: 5173.738430158466
INFO:root:eval perplexity: 8.294666290283203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [10:19:21<14:11:46, 452.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3565.804420230263
INFO:root:current train perplexity4.079812049865723
INFO:root:current mean train loss 3579.623656600561
INFO:root:current train perplexity4.084310531616211
INFO:root:current mean train loss 3595.239631885593
INFO:root:current train perplexity4.103308200836182
INFO:root:current mean train loss 3596.9209015278875
INFO:root:current train perplexity4.1116461753845215
INFO:root:current mean train loss 3597.4202493686867
INFO:root:current train perplexity4.115933895111084
INFO:root:current mean train loss 3599.225478433561
INFO:root:current train perplexity4.122084140777588
INFO:root:current mean train loss 3596.5893284200765
INFO:root:current train perplexity4.122450351715088
INFO:root:current mean train loss 3597.666781827339
INFO:root:current train perplexity4.12742280960083
INFO:root:current mean train loss 3600.4806346019554
INFO:root:current train perplexity4.133779048919678

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.27s/it]
INFO:root:final mean train loss: 3599.5954658139135
INFO:root:final train perplexity: 4.137718677520752
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.25s/it]
INFO:root:eval mean loss: 4140.340461893285
INFO:root:eval perplexity: 5.334697246551514
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.56s/it]
INFO:root:eval mean loss: 5176.84923537234
INFO:root:eval perplexity: 8.305224418640137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [10:26:18<13:44:37, 441.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3532.5439453125
INFO:root:current train perplexity4.085270404815674
INFO:root:current mean train loss 3574.1302383570996
INFO:root:current train perplexity4.107407093048096
INFO:root:current mean train loss 3573.7668914043256
INFO:root:current train perplexity4.099404811859131
INFO:root:current mean train loss 3580.1186418690695
INFO:root:current train perplexity4.110169887542725
INFO:root:current mean train loss 3580.2246881300402
INFO:root:current train perplexity4.11155366897583
INFO:root:current mean train loss 3584.3283613747203
INFO:root:current train perplexity4.117612838745117
INFO:root:current mean train loss 3584.177448936956
INFO:root:current train perplexity4.114719867706299
INFO:root:current mean train loss 3589.325578019426
INFO:root:current train perplexity4.119870185852051
INFO:root:current mean train loss 3591.5940634607527
INFO:root:current train perplexity4.122242450714111
INFO:root:current mean train loss 3595.6201791013464
INFO:root:current train perplexity4.127388954162598

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.28s/it]
INFO:root:final mean train loss: 3594.1441716224917
INFO:root:final train perplexity: 4.128829479217529
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.41s/it]
INFO:root:eval mean loss: 4141.601600592863
INFO:root:eval perplexity: 5.337418556213379
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.08s/it]
INFO:root:eval mean loss: 5175.566376814605
INFO:root:eval perplexity: 8.300867080688477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [10:33:20<13:26:14, 435.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3567.157137784091
INFO:root:current train perplexity4.125870227813721
INFO:root:current mean train loss 3580.0990089210304
INFO:root:current train perplexity4.083330154418945
INFO:root:current mean train loss 3583.622984393513
INFO:root:current train perplexity4.094444751739502
INFO:root:current mean train loss 3581.712174688505
INFO:root:current train perplexity4.105095386505127
INFO:root:current mean train loss 3583.3549620542503
INFO:root:current train perplexity4.109572410583496
INFO:root:current mean train loss 3586.697194914995
INFO:root:current train perplexity4.116187572479248
INFO:root:current mean train loss 3587.617186700849
INFO:root:current train perplexity4.119108200073242
INFO:root:current mean train loss 3585.9640711530856
INFO:root:current train perplexity4.113753318786621
INFO:root:current mean train loss 3589.835293281828
INFO:root:current train perplexity4.11582612991333
INFO:root:current mean train loss 3587.178416682389
INFO:root:current train perplexity4.114821434020996

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.46s/it]
INFO:root:final mean train loss: 3586.475295343707
INFO:root:final train perplexity: 4.1163554191589355
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.96s/it]
INFO:root:eval mean loss: 4146.875041555851
INFO:root:eval perplexity: 5.348812103271484
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.03s/it]
INFO:root:eval mean loss: 5182.847439813276
INFO:root:eval perplexity: 8.325618743896484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [10:40:15<13:07:17, 429.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3637.6713096217104
INFO:root:current train perplexity4.146083831787109
INFO:root:current mean train loss 3566.3373736213234
INFO:root:current train perplexity4.09255838394165
INFO:root:current mean train loss 3569.465045528325
INFO:root:current train perplexity4.092076778411865
INFO:root:current mean train loss 3572.1871992248725
INFO:root:current train perplexity4.099029064178467
INFO:root:current mean train loss 3575.7487752181532
INFO:root:current train perplexity4.09885311126709
INFO:root:current mean train loss 3577.1882884001684
INFO:root:current train perplexity4.099752426147461
INFO:root:current mean train loss 3580.491645973218
INFO:root:current train perplexity4.102921009063721
INFO:root:current mean train loss 3579.2740741671373
INFO:root:current train perplexity4.100523948669434
INFO:root:current mean train loss 3580.3746094942385
INFO:root:current train perplexity4.102124214172363
INFO:root:current mean train loss 3583.447264562364
INFO:root:current train perplexity4.105493545532227

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.80s/it]
INFO:root:final mean train loss: 3580.2364588706723
INFO:root:final train perplexity: 4.106235980987549
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.84s/it]
INFO:root:eval mean loss: 4142.58090404754
INFO:root:eval perplexity: 5.339531898498535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.95s/it]
INFO:root:eval mean loss: 5176.572748711768
INFO:root:eval perplexity: 8.304285049438477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [10:47:16<12:55:57, 427.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3544.8056369357637
INFO:root:current train perplexity4.113337993621826
INFO:root:current mean train loss 3565.0883577602117
INFO:root:current train perplexity4.0768866539001465
INFO:root:current mean train loss 3574.2015246420706
INFO:root:current train perplexity4.08526086807251
INFO:root:current mean train loss 3583.810956015864
INFO:root:current train perplexity4.091307640075684
INFO:root:current mean train loss 3578.9820673850995
INFO:root:current train perplexity4.094553470611572
INFO:root:current mean train loss 3582.256545470381
INFO:root:current train perplexity4.098006725311279
INFO:root:current mean train loss 3580.0642529842007
INFO:root:current train perplexity4.09809684753418
INFO:root:current mean train loss 3576.4277998597618
INFO:root:current train perplexity4.093161582946777
INFO:root:current mean train loss 3579.8265544702235
INFO:root:current train perplexity4.095468997955322
INFO:root:current mean train loss 3577.04698456041
INFO:root:current train perplexity4.09665060043335

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.49s/it]
INFO:root:final mean train loss: 3573.1883605833978
INFO:root:final train perplexity: 4.094833850860596
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.04s/it]
INFO:root:eval mean loss: 4145.7613672567595
INFO:root:eval perplexity: 5.346404552459717
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.79s/it]
INFO:root:eval mean loss: 5185.597900390625
INFO:root:eval perplexity: 8.334988594055176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [10:55:41<13:30:55, 450.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3562.0498116629465
INFO:root:current train perplexity4.0533037185668945
INFO:root:current mean train loss 3543.7736201533567
INFO:root:current train perplexity4.059775352478027
INFO:root:current mean train loss 3561.9391061336437
INFO:root:current train perplexity4.070748329162598
INFO:root:current mean train loss 3566.095547166511
INFO:root:current train perplexity4.078108310699463
INFO:root:current mean train loss 3565.491412423671
INFO:root:current train perplexity4.077886581420898
INFO:root:current mean train loss 3569.575558557243
INFO:root:current train perplexity4.079463958740234
INFO:root:current mean train loss 3569.4562899852363
INFO:root:current train perplexity4.081289291381836
INFO:root:current mean train loss 3568.254103887649
INFO:root:current train perplexity4.079644680023193
INFO:root:current mean train loss 3568.202846358065
INFO:root:current train perplexity4.079623699188232
INFO:root:current mean train loss 3569.3105400860627
INFO:root:current train perplexity4.083067893981934

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.11s/it]
INFO:root:final mean train loss: 3567.4935748807848
INFO:root:final train perplexity: 4.085644721984863
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.77s/it]
INFO:root:eval mean loss: 4142.889934133976
INFO:root:eval perplexity: 5.340198993682861
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.23s/it]
INFO:root:eval mean loss: 5184.76917109929
INFO:root:eval perplexity: 8.332165718078613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [11:04:05<13:51:44, 466.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3578.6980775345205
INFO:root:current train perplexity4.087172985076904
INFO:root:current mean train loss 3569.602590280813
INFO:root:current train perplexity4.058495044708252
INFO:root:current mean train loss 3549.50755429366
INFO:root:current train perplexity4.055634021759033
INFO:root:current mean train loss 3560.5887881798926
INFO:root:current train perplexity4.0698370933532715
INFO:root:current mean train loss 3558.8411355459934
INFO:root:current train perplexity4.070718288421631
INFO:root:current mean train loss 3560.0035627445905
INFO:root:current train perplexity4.072790145874023
INFO:root:current mean train loss 3552.997113217462
INFO:root:current train perplexity4.068458080291748
INFO:root:current mean train loss 3557.0740051680264
INFO:root:current train perplexity4.070077419281006
INFO:root:current mean train loss 3561.5137636811423
INFO:root:current train perplexity4.070910930633545
INFO:root:current mean train loss 3563.087883116964
INFO:root:current train perplexity4.073586940765381

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.27s/it]
INFO:root:final mean train loss: 3560.8249260071784
INFO:root:final train perplexity: 4.074909687042236
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.04s/it]
INFO:root:eval mean loss: 4146.952948387633
INFO:root:eval perplexity: 5.348979949951172
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.82s/it]
INFO:root:eval mean loss: 5192.51885596742
INFO:root:eval perplexity: 8.358610153198242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [11:11:02<13:17:53, 451.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3520.7155618106617
INFO:root:current train perplexity4.020229816436768
INFO:root:current mean train loss 3545.0904484426737
INFO:root:current train perplexity4.041025638580322
INFO:root:current mean train loss 3537.759381419634
INFO:root:current train perplexity4.0460124015808105
INFO:root:current mean train loss 3544.0952224948805
INFO:root:current train perplexity4.052776336669922
INFO:root:current mean train loss 3547.93166823292
INFO:root:current train perplexity4.0566301345825195
INFO:root:current mean train loss 3548.702694763073
INFO:root:current train perplexity4.056830883026123
INFO:root:current mean train loss 3551.2039343017955
INFO:root:current train perplexity4.058709144592285
INFO:root:current mean train loss 3555.357668616324
INFO:root:current train perplexity4.062310218811035
INFO:root:current mean train loss 3555.726617869143
INFO:root:current train perplexity4.062787055969238
INFO:root:current mean train loss 3558.311476457758
INFO:root:current train perplexity4.064291000366211

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.62s/it]
INFO:root:final mean train loss: 3554.1468870716712
INFO:root:final train perplexity: 4.064187049865723
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.56s/it]
INFO:root:eval mean loss: 4148.031251731494
INFO:root:eval perplexity: 5.35131311416626
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.29s/it]
INFO:root:eval mean loss: 5195.692621758643
INFO:root:eval perplexity: 8.369466781616211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [11:19:10<13:29:35, 462.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3541.178508176642
INFO:root:current train perplexity4.060625076293945
INFO:root:current mean train loss 3538.621219659002
INFO:root:current train perplexity4.036925315856934
INFO:root:current mean train loss 3532.6354829648285
INFO:root:current train perplexity4.03835916519165
INFO:root:current mean train loss 3539.9918869146068
INFO:root:current train perplexity4.039984226226807
INFO:root:current mean train loss 3544.628008940121
INFO:root:current train perplexity4.0430145263671875
INFO:root:current mean train loss 3544.530726779126
INFO:root:current train perplexity4.039129734039307
INFO:root:current mean train loss 3545.530211198312
INFO:root:current train perplexity4.045058250427246
INFO:root:current mean train loss 3547.974942937356
INFO:root:current train perplexity4.050269603729248
INFO:root:current mean train loss 3550.7241401361503
INFO:root:current train perplexity4.053543567657471
INFO:root:current mean train loss 3551.539222884352
INFO:root:current train perplexity4.056339263916016

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.95s/it]
INFO:root:final mean train loss: 3549.412044955838
INFO:root:final train perplexity: 4.056602478027344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it]
INFO:root:eval mean loss: 4148.068949814384
INFO:root:eval perplexity: 5.351396083831787
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.01s/it]
INFO:root:eval mean loss: 5194.792511635638
INFO:root:eval perplexity: 8.366386413574219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [11:26:12<13:00:39, 450.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3567.8956681436566
INFO:root:current train perplexity4.029933929443359
INFO:root:current mean train loss 3548.8793258210144
INFO:root:current train perplexity4.0364179611206055
INFO:root:current mean train loss 3553.3122512874534
INFO:root:current train perplexity4.049107551574707
INFO:root:current mean train loss 3550.8539167606864
INFO:root:current train perplexity4.043790817260742
INFO:root:current mean train loss 3550.9219283240764
INFO:root:current train perplexity4.043707847595215
INFO:root:current mean train loss 3547.213200214258
INFO:root:current train perplexity4.041345119476318
INFO:root:current mean train loss 3546.7077358537526
INFO:root:current train perplexity4.0438151359558105
INFO:root:current mean train loss 3547.011174128606
INFO:root:current train perplexity4.04543399810791
INFO:root:current mean train loss 3545.9827155758903
INFO:root:current train perplexity4.047039031982422
INFO:root:current mean train loss 3546.5712754290007
INFO:root:current train perplexity4.045924186706543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.16s/it]
INFO:root:final mean train loss: 3543.102927607875
INFO:root:final train perplexity: 4.046517372131348
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.76s/it]
INFO:root:eval mean loss: 4148.178227850732
INFO:root:eval perplexity: 5.351632118225098
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.06s/it]
INFO:root:eval mean loss: 5197.445812901707
INFO:root:eval perplexity: 8.375469207763672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [11:34:22<13:13:23, 462.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3543.6102766927083
INFO:root:current train perplexity4.043228626251221
INFO:root:current mean train loss 3546.3663351004466
INFO:root:current train perplexity4.0348310470581055
INFO:root:current mean train loss 3539.1820419034093
INFO:root:current train perplexity4.023799896240234
INFO:root:current mean train loss 3536.2920026041666
INFO:root:current train perplexity4.0284624099731445
INFO:root:current mean train loss 3536.92543020148
INFO:root:current train perplexity4.031091690063477
INFO:root:current mean train loss 3538.18009765625
INFO:root:current train perplexity4.031953811645508
INFO:root:current mean train loss 3539.4909997106483
INFO:root:current train perplexity4.03271484375
INFO:root:current mean train loss 3539.1775557585684
INFO:root:current train perplexity4.033073902130127
INFO:root:current mean train loss 3539.340961216518
INFO:root:current train perplexity4.034674167633057
INFO:root:current mean train loss 3539.090225360577
INFO:root:current train perplexity4.035087585449219

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.14s/it]
INFO:root:final mean train loss: 3536.2573725177394
INFO:root:final train perplexity: 4.0356035232543945
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.32s/it]
INFO:root:eval mean loss: 4149.283300088652
INFO:root:eval perplexity: 5.354023456573486
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it]
INFO:root:eval mean loss: 5195.8155664755095
INFO:root:eval perplexity: 8.369885444641113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [11:42:41<13:24:41, 473.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3530.4664174275226
INFO:root:current train perplexity3.996764659881592
INFO:root:current mean train loss 3532.8946166325136
INFO:root:current train perplexity4.004922389984131
INFO:root:current mean train loss 3529.0046852570117
INFO:root:current train perplexity4.011662483215332
INFO:root:current mean train loss 3534.949024967363
INFO:root:current train perplexity4.017197132110596
INFO:root:current mean train loss 3535.14885703772
INFO:root:current train perplexity4.0241193771362305
INFO:root:current mean train loss 3534.2306982338123
INFO:root:current train perplexity4.026371955871582
INFO:root:current mean train loss 3536.1881530672354
INFO:root:current train perplexity4.026500701904297
INFO:root:current mean train loss 3533.4159828858355
INFO:root:current train perplexity4.025056838989258
INFO:root:current mean train loss 3533.471316656197
INFO:root:current train perplexity4.025235176086426
INFO:root:current mean train loss 3534.1440948765735
INFO:root:current train perplexity4.027433395385742

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.10s/it]
INFO:root:final mean train loss: 3530.998568934779
INFO:root:final train perplexity: 4.0272393226623535
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.11s/it]
INFO:root:eval mean loss: 4150.5958918578235
INFO:root:eval perplexity: 5.356866836547852
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.83s/it]
INFO:root:eval mean loss: 5203.492739846521
INFO:root:eval perplexity: 8.396203994750977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [11:51:04<13:31:43, 482.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3532.5233570140795
INFO:root:current train perplexity4.009644031524658
INFO:root:current mean train loss 3519.4966382730695
INFO:root:current train perplexity4.006289958953857
INFO:root:current mean train loss 3515.8197453554553
INFO:root:current train perplexity4.001218795776367
INFO:root:current mean train loss 3512.507212451047
INFO:root:current train perplexity3.998185634613037
INFO:root:current mean train loss 3517.735988515943
INFO:root:current train perplexity4.005115032196045
INFO:root:current mean train loss 3520.7306980191147
INFO:root:current train perplexity4.004491806030273
INFO:root:current mean train loss 3525.9454071884043
INFO:root:current train perplexity4.0092058181762695
INFO:root:current mean train loss 3526.656145676952
INFO:root:current train perplexity4.012784957885742
INFO:root:current mean train loss 3527.831236628437
INFO:root:current train perplexity4.015877723693848
INFO:root:current mean train loss 3527.750234532669
INFO:root:current train perplexity4.017673492431641

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.69s/it]
INFO:root:final mean train loss: 3524.9547289571456
INFO:root:final train perplexity: 4.017648220062256
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.23s/it]
INFO:root:eval mean loss: 4152.043086491578
INFO:root:eval perplexity: 5.3600029945373535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it]
INFO:root:eval mean loss: 5203.293396428967
INFO:root:eval perplexity: 8.39552116394043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [11:59:29<13:35:07, 489.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3494.939643012153
INFO:root:current train perplexity3.9656500816345215
INFO:root:current mean train loss 3501.8889859453516
INFO:root:current train perplexity3.9865946769714355
INFO:root:current mean train loss 3517.855832103104
INFO:root:current train perplexity3.998147487640381
INFO:root:current mean train loss 3513.2208989270052
INFO:root:current train perplexity3.993328809738159
INFO:root:current mean train loss 3513.24180538812
INFO:root:current train perplexity3.9945669174194336
INFO:root:current mean train loss 3513.638020154033
INFO:root:current train perplexity3.9958298206329346
INFO:root:current mean train loss 3517.0058300362125
INFO:root:current train perplexity4.000948905944824
INFO:root:current mean train loss 3520.5446713176625
INFO:root:current train perplexity4.005234241485596
INFO:root:current mean train loss 3523.7214472243463
INFO:root:current train perplexity4.008650302886963

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.08s/it]
INFO:root:final mean train loss: 3520.205808885636
INFO:root:final train perplexity: 4.010127544403076
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.13s/it]
INFO:root:eval mean loss: 4153.112159242021
INFO:root:eval perplexity: 5.362319469451904
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.20s/it]
INFO:root:eval mean loss: 5207.864761677194
INFO:root:eval perplexity: 8.411227226257324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [12:07:55<13:35:14, 494.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3509.199637276786
INFO:root:current train perplexity4.036217212677002
INFO:root:current mean train loss 3493.2293872298483
INFO:root:current train perplexity3.9939041137695312
INFO:root:current mean train loss 3504.079543846241
INFO:root:current train perplexity3.9977810382843018
INFO:root:current mean train loss 3504.9611212019036
INFO:root:current train perplexity3.98940110206604
INFO:root:current mean train loss 3507.7044242840143
INFO:root:current train perplexity3.995614528656006
INFO:root:current mean train loss 3510.2255016680533
INFO:root:current train perplexity3.994575262069702
INFO:root:current mean train loss 3513.4992896995986
INFO:root:current train perplexity3.999223232269287
INFO:root:current mean train loss 3515.8224824854137
INFO:root:current train perplexity4.000475883483887
INFO:root:current mean train loss 3514.143048859588
INFO:root:current train perplexity3.9993553161621094
INFO:root:current mean train loss 3516.0433291737013
INFO:root:current train perplexity4.0012736320495605

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.34s/it]
INFO:root:final mean train loss: 3514.317575454712
INFO:root:final train perplexity: 4.0008225440979
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.86s/it]
INFO:root:eval mean loss: 4151.755265472629
INFO:root:eval perplexity: 5.359378337860107
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.25s/it]
INFO:root:eval mean loss: 5208.783559812721
INFO:root:eval perplexity: 8.414388656616211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [12:16:31<13:37:57, 500.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3524.29697265625
INFO:root:current train perplexity3.973552703857422
INFO:root:current mean train loss 3511.06631920856
INFO:root:current train perplexity3.9583916664123535
INFO:root:current mean train loss 3509.443604651163
INFO:root:current train perplexity3.97776460647583
INFO:root:current mean train loss 3498.040929594494
INFO:root:current train perplexity3.968695878982544
INFO:root:current mean train loss 3502.489446065512
INFO:root:current train perplexity3.9791769981384277
INFO:root:current mean train loss 3503.627430028823
INFO:root:current train perplexity3.980996608734131
INFO:root:current mean train loss 3505.0775418413364
INFO:root:current train perplexity3.983914375305176
INFO:root:current mean train loss 3504.232311243444
INFO:root:current train perplexity3.9842934608459473
INFO:root:current mean train loss 3507.285601694306
INFO:root:current train perplexity3.988145351409912
INFO:root:current mean train loss 3509.827721033982
INFO:root:current train perplexity3.9897677898406982

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.27s/it]
INFO:root:final mean train loss: 3507.457551525485
INFO:root:final train perplexity: 3.99000883102417
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.68s/it]
INFO:root:eval mean loss: 4155.300282579788
INFO:root:eval perplexity: 5.367065906524658
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it]
INFO:root:eval mean loss: 5215.898955216645
INFO:root:eval perplexity: 8.4389066696167
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [12:25:00<13:33:31, 503.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3453.0028023097825
INFO:root:current train perplexity3.8765687942504883
INFO:root:current mean train loss 3494.2645968305387
INFO:root:current train perplexity3.9597957134246826
INFO:root:current mean train loss 3485.337527151065
INFO:root:current train perplexity3.9552247524261475
INFO:root:current mean train loss 3497.8721451419797
INFO:root:current train perplexity3.967913866043091
INFO:root:current mean train loss 3501.103610857159
INFO:root:current train perplexity3.973064422607422
INFO:root:current mean train loss 3502.185297599486
INFO:root:current train perplexity3.97627592086792
INFO:root:current mean train loss 3506.0637026766904
INFO:root:current train perplexity3.981687545776367
INFO:root:current mean train loss 3500.895659767246
INFO:root:current train perplexity3.9818992614746094
INFO:root:current mean train loss 3504.4666099872798
INFO:root:current train perplexity3.983146905899048
INFO:root:current mean train loss 3507.2859976490554
INFO:root:current train perplexity3.9853603839874268

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.74s/it]
INFO:root:final mean train loss: 3504.2610951085244
INFO:root:final train perplexity: 3.984980821609497
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.90s/it]
INFO:root:eval mean loss: 4157.361792165337
INFO:root:eval perplexity: 5.371541976928711
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.18s/it]
INFO:root:eval mean loss: 5217.375567929965
INFO:root:eval perplexity: 8.444003105163574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [12:33:33<13:29:52, 506.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3445.1925875756046
INFO:root:current train perplexity3.890073299407959
INFO:root:current mean train loss 3485.147341662691
INFO:root:current train perplexity3.9548556804656982
INFO:root:current mean train loss 3481.1510490648675
INFO:root:current train perplexity3.949732780456543
INFO:root:current mean train loss 3483.207177291824
INFO:root:current train perplexity3.953533887863159
INFO:root:current mean train loss 3488.1406986387037
INFO:root:current train perplexity3.960196018218994
INFO:root:current mean train loss 3491.776628339807
INFO:root:current train perplexity3.965546131134033
INFO:root:current mean train loss 3496.7860318288185
INFO:root:current train perplexity3.969633102416992
INFO:root:current mean train loss 3496.48007064381
INFO:root:current train perplexity3.9720728397369385
INFO:root:current mean train loss 3497.541245957431
INFO:root:current train perplexity3.9747045040130615
INFO:root:current mean train loss 3499.3326330789305
INFO:root:current train perplexity3.974275827407837

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.76s/it]
INFO:root:final mean train loss: 3497.1287494167204
INFO:root:final train perplexity: 3.973783016204834
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.44s/it]
INFO:root:eval mean loss: 4156.934005845523
INFO:root:eval perplexity: 5.370613098144531
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.84s/it]
INFO:root:eval mean loss: 5219.301316281582
INFO:root:eval perplexity: 8.450654983520508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [12:41:57<13:20:26, 505.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3486.639147636218
INFO:root:current train perplexity3.9669301509857178
INFO:root:current mean train loss 3493.6478965265287
INFO:root:current train perplexity3.9664812088012695
INFO:root:current mean train loss 3495.005335340939
INFO:root:current train perplexity3.961512565612793
INFO:root:current mean train loss 3494.9014320035953
INFO:root:current train perplexity3.9626498222351074
INFO:root:current mean train loss 3487.757514414863
INFO:root:current train perplexity3.9567861557006836
INFO:root:current mean train loss 3486.874097268524
INFO:root:current train perplexity3.956197500228882
INFO:root:current mean train loss 3487.9937960008315
INFO:root:current train perplexity3.958545446395874
INFO:root:current mean train loss 3490.3920049396356
INFO:root:current train perplexity3.9607863426208496
INFO:root:current mean train loss 3491.394271686904
INFO:root:current train perplexity3.9628331661224365
INFO:root:current mean train loss 3490.0671423118843
INFO:root:current train perplexity3.96054744720459

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.83s/it]
INFO:root:final mean train loss: 3489.880899552376
INFO:root:final train perplexity: 3.9624364376068115
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.49s/it]
INFO:root:eval mean loss: 4155.359837308843
INFO:root:eval perplexity: 5.367196083068848
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it]
INFO:root:eval mean loss: 5219.571250969637
INFO:root:eval perplexity: 8.451587677001953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [12:50:28<13:14:32, 507.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3462.6904764378323
INFO:root:current train perplexity3.909288167953491
INFO:root:current mean train loss 3478.305660740859
INFO:root:current train perplexity3.9338150024414062
INFO:root:current mean train loss 3480.9288947842865
INFO:root:current train perplexity3.9446518421173096
INFO:root:current mean train loss 3485.8250137900754
INFO:root:current train perplexity3.9467737674713135
INFO:root:current mean train loss 3485.671101614933
INFO:root:current train perplexity3.9478278160095215
INFO:root:current mean train loss 3481.9678729683214
INFO:root:current train perplexity3.9450700283050537
INFO:root:current mean train loss 3485.7416705407168
INFO:root:current train perplexity3.946303606033325
INFO:root:current mean train loss 3487.806918102096
INFO:root:current train perplexity3.949450731277466
INFO:root:current mean train loss 3489.66098753874
INFO:root:current train perplexity3.953941583633423
INFO:root:current mean train loss 3488.6651362547022
INFO:root:current train perplexity3.955024480819702

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.16s/it]
INFO:root:final mean train loss: 3486.5982600796606
INFO:root:final train perplexity: 3.9573075771331787
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.52s/it]
INFO:root:eval mean loss: 4156.363097711658
INFO:root:eval perplexity: 5.369372844696045
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.88s/it]
INFO:root:eval mean loss: 5224.069029463099
INFO:root:eval perplexity: 8.467147827148438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [12:58:53<13:04:48, 506.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3472.4783735795454
INFO:root:current train perplexity3.9588844776153564
INFO:root:current mean train loss 3472.1001307333668
INFO:root:current train perplexity3.9368174076080322
INFO:root:current mean train loss 3474.7774519378063
INFO:root:current train perplexity3.9332191944122314
INFO:root:current mean train loss 3478.733293216329
INFO:root:current train perplexity3.934600591659546
INFO:root:current mean train loss 3478.666137963599
INFO:root:current train perplexity3.9334497451782227
INFO:root:current mean train loss 3485.8820409276464
INFO:root:current train perplexity3.943188190460205
INFO:root:current mean train loss 3484.467537497018
INFO:root:current train perplexity3.9463775157928467
INFO:root:current mean train loss 3484.113878505277
INFO:root:current train perplexity3.949951648712158
INFO:root:current mean train loss 3484.1756901612757
INFO:root:current train perplexity3.9500439167022705
INFO:root:current mean train loss 3484.6721183736913
INFO:root:current train perplexity3.948943853378296

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.90s/it]
INFO:root:final mean train loss: 3481.870538465438
INFO:root:final train perplexity: 3.949932813644409
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.17s/it]
INFO:root:eval mean loss: 4158.644339054189
INFO:root:eval perplexity: 5.374329090118408
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it]
INFO:root:eval mean loss: 5224.137785350177
INFO:root:eval perplexity: 8.467384338378906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [13:07:20<12:56:48, 506.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3465.166496155754
INFO:root:current train perplexity3.9099438190460205
INFO:root:current mean train loss 3467.831158035372
INFO:root:current train perplexity3.905550479888916
INFO:root:current mean train loss 3481.2322937707936
INFO:root:current train perplexity3.918274402618408
INFO:root:current mean train loss 3478.1897073540804
INFO:root:current train perplexity3.919837713241577
INFO:root:current mean train loss 3475.198872312871
INFO:root:current train perplexity3.919264793395996
INFO:root:current mean train loss 3477.370413365203
INFO:root:current train perplexity3.924268960952759
INFO:root:current mean train loss 3477.454972809436
INFO:root:current train perplexity3.9252402782440186
INFO:root:current mean train loss 3475.308738698497
INFO:root:current train perplexity3.9287171363830566
INFO:root:current mean train loss 3477.2050119269625
INFO:root:current train perplexity3.935349225997925
INFO:root:current mean train loss 3478.311369043273
INFO:root:current train perplexity3.9394121170043945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.88s/it]
INFO:root:final mean train loss: 3475.8919810018233
INFO:root:final train perplexity: 3.940627336502075
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.29s/it]
INFO:root:eval mean loss: 4159.558271692154
INFO:root:eval perplexity: 5.376316070556641
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.98s/it]
INFO:root:eval mean loss: 5228.0804590536345
INFO:root:eval perplexity: 8.481046676635742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [13:15:46<12:48:16, 506.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3492.0700236575703
INFO:root:current train perplexity3.918957471847534
INFO:root:current mean train loss 3457.7561363532527
INFO:root:current train perplexity3.914679527282715
INFO:root:current mean train loss 3453.995744205489
INFO:root:current train perplexity3.9134743213653564
INFO:root:current mean train loss 3460.9800765456534
INFO:root:current train perplexity3.919800281524658
INFO:root:current mean train loss 3466.384416260284
INFO:root:current train perplexity3.9267282485961914
INFO:root:current mean train loss 3469.555201435256
INFO:root:current train perplexity3.928739547729492
INFO:root:current mean train loss 3466.866870954033
INFO:root:current train perplexity3.92911958694458
INFO:root:current mean train loss 3466.254467045132
INFO:root:current train perplexity3.9292895793914795
INFO:root:current mean train loss 3467.21310393271
INFO:root:current train perplexity3.929680585861206
INFO:root:current mean train loss 3472.027469466079
INFO:root:current train perplexity3.9319214820861816

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.29s/it]
INFO:root:final mean train loss: 3470.534813727102
INFO:root:final train perplexity: 3.932307720184326
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.21s/it]
INFO:root:eval mean loss: 4161.431251038896
INFO:root:eval perplexity: 5.3803887367248535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 29.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 29.00s/it]
INFO:root:eval mean loss: 5229.2470668495125
INFO:root:eval perplexity: 8.485093116760254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/110
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [13:24:05<12:36:22, 504.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3440.9701901206486
INFO:root:current train perplexity3.89831280708313
INFO:root:current mean train loss 3449.9414908126746
INFO:root:current train perplexity3.90981388092041
INFO:root:current mean train loss 3461.5760292408713
INFO:root:current train perplexity3.908637523651123
INFO:root:current mean train loss 3462.395929744187
INFO:root:current train perplexity3.9107601642608643
INFO:root:current mean train loss 3459.7809299158403
INFO:root:current train perplexity3.910952091217041
INFO:root:current mean train loss 3464.409965238423
INFO:root:current train perplexity3.9146649837493896
INFO:root:current mean train loss 3464.308998253981
INFO:root:current train perplexity3.918003559112549
INFO:root:current mean train loss 3464.882429835426
INFO:root:current train perplexity3.919312000274658
INFO:root:current mean train loss 3464.7017251493176
INFO:root:current train perplexity3.9206597805023193
INFO:root:current mean train loss 3468.012924989227
INFO:root:current train perplexity3.9235219955444336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.42s/it]
INFO:root:final mean train loss: 3465.1972010827835
INFO:root:final train perplexity: 3.9240355491638184
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.25s/it]
INFO:root:eval mean loss: 4162.085790323027
INFO:root:eval perplexity: 5.3818135261535645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it]
INFO:root:eval mean loss: 5235.468966436724
INFO:root:eval perplexity: 8.506710052490234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/111
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [13:32:52<12:37:43, 510.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3426.519539668642
INFO:root:current train perplexity3.897632122039795
INFO:root:current mean train loss 3444.297620477523
INFO:root:current train perplexity3.906834840774536
INFO:root:current mean train loss 3450.6497806987695
INFO:root:current train perplexity3.9108774662017822
INFO:root:current mean train loss 3451.1093996033187
INFO:root:current train perplexity3.911884307861328
INFO:root:current mean train loss 3456.9161625104275
INFO:root:current train perplexity3.9172520637512207
INFO:root:current mean train loss 3455.2668885421103
INFO:root:current train perplexity3.913919448852539
INFO:root:current mean train loss 3455.9576542172717
INFO:root:current train perplexity3.913865804672241
INFO:root:current mean train loss 3459.5723254968434
INFO:root:current train perplexity3.91439151763916
INFO:root:current mean train loss 3462.525047947347
INFO:root:current train perplexity3.9164695739746094
INFO:root:current mean train loss 3463.33880312223
INFO:root:current train perplexity3.9171438217163086

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.44s/it]
INFO:root:final mean train loss: 3460.5379620828935
INFO:root:final train perplexity: 3.9168291091918945
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.50s/it]
INFO:root:eval mean loss: 4164.539668522828
INFO:root:eval perplexity: 5.387155532836914
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.04s/it]
INFO:root:eval mean loss: 5234.8378871620125
INFO:root:eval perplexity: 8.5045166015625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/112
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [13:39:47<11:47:22, 482.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3420.9679456208883
INFO:root:current train perplexity3.877603054046631
INFO:root:current mean train loss 3447.7850448217146
INFO:root:current train perplexity3.8912973403930664
INFO:root:current mean train loss 3453.9222134864935
INFO:root:current train perplexity3.889787197113037
INFO:root:current mean train loss 3452.151942617682
INFO:root:current train perplexity3.8945772647857666
INFO:root:current mean train loss 3450.858712121212
INFO:root:current train perplexity3.899475336074829
INFO:root:current mean train loss 3452.625342617516
INFO:root:current train perplexity3.903533697128296
INFO:root:current mean train loss 3455.8581855609264
INFO:root:current train perplexity3.9038031101226807
INFO:root:current mean train loss 3452.975237384532
INFO:root:current train perplexity3.9026169776916504
INFO:root:current mean train loss 3455.2834955481844
INFO:root:current train perplexity3.9069125652313232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.80s/it]
INFO:root:final mean train loss: 3454.387010451286
INFO:root:final train perplexity: 3.9073355197906494
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.45s/it]
INFO:root:eval mean loss: 4165.343774240913
INFO:root:eval perplexity: 5.388907432556152
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.67s/it]
INFO:root:eval mean loss: 5237.371807125443
INFO:root:eval perplexity: 8.513328552246094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/113
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [13:46:39<11:08:47, 461.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3440.5867513020835
INFO:root:current train perplexity3.8868165016174316
INFO:root:current mean train loss 3433.3666233692356
INFO:root:current train perplexity3.8822760581970215
INFO:root:current mean train loss 3438.2068628771553
INFO:root:current train perplexity3.901249408721924
INFO:root:current mean train loss 3445.5736829298166
INFO:root:current train perplexity3.9034759998321533
INFO:root:current mean train loss 3445.680457481971
INFO:root:current train perplexity3.8966875076293945
INFO:root:current mean train loss 3446.8990097500932
INFO:root:current train perplexity3.895746946334839
INFO:root:current mean train loss 3450.343805872979
INFO:root:current train perplexity3.896555185317993
INFO:root:current mean train loss 3451.017478454503
INFO:root:current train perplexity3.896878480911255
INFO:root:current mean train loss 3449.889197552635
INFO:root:current train perplexity3.8970277309417725
INFO:root:current mean train loss 3451.1701741266093
INFO:root:current train perplexity3.8984904289245605

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.78s/it]
INFO:root:final mean train loss: 3451.231867882513
INFO:root:final train perplexity: 3.9024741649627686
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.43s/it]
INFO:root:eval mean loss: 4165.701166680518
INFO:root:eval perplexity: 5.3896870613098145
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.97s/it]
INFO:root:eval mean loss: 5241.953779504654
INFO:root:eval perplexity: 8.529297828674316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/114
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [13:54:34<11:06:51, 465.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3466.758855646307
INFO:root:current train perplexity3.890151262283325
INFO:root:current mean train loss 3456.2964768968186
INFO:root:current train perplexity3.905514717102051
INFO:root:current mean train loss 3445.8946203439723
INFO:root:current train perplexity3.8985283374786377
INFO:root:current mean train loss 3444.631915224327
INFO:root:current train perplexity3.8963429927825928
INFO:root:current mean train loss 3444.249167189401
INFO:root:current train perplexity3.892580032348633
INFO:root:current mean train loss 3449.331221429336
INFO:root:current train perplexity3.8945040702819824
INFO:root:current mean train loss 3445.7529081104235
INFO:root:current train perplexity3.8909926414489746
INFO:root:current mean train loss 3447.8358035832016
INFO:root:current train perplexity3.890855312347412
INFO:root:current mean train loss 3448.843625370877
INFO:root:current train perplexity3.8934271335601807
INFO:root:current mean train loss 3448.19361262735
INFO:root:current train perplexity3.8945119380950928

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.63s/it]
INFO:root:final mean train loss: 3446.349373417516
INFO:root:final train perplexity: 3.8949642181396484
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.89s/it]
INFO:root:eval mean loss: 4168.5352930380095
INFO:root:eval perplexity: 5.395867824554443
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.90s/it]
INFO:root:eval mean loss: 5244.695530668218
INFO:root:eval perplexity: 8.538864135742188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/115
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [14:02:39<11:07:41, 471.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3460.9796592310854
INFO:root:current train perplexity3.8939948081970215
INFO:root:current mean train loss 3444.2803390887607
INFO:root:current train perplexity3.8761634826660156
INFO:root:current mean train loss 3441.4306060930367
INFO:root:current train perplexity3.8722286224365234
INFO:root:current mean train loss 3438.711438791879
INFO:root:current train perplexity3.878899574279785
INFO:root:current mean train loss 3441.5176969906024
INFO:root:current train perplexity3.8860321044921875
INFO:root:current mean train loss 3440.9499662248613
INFO:root:current train perplexity3.8842272758483887
INFO:root:current mean train loss 3440.2955395231725
INFO:root:current train perplexity3.882864236831665
INFO:root:current mean train loss 3444.085256690608
INFO:root:current train perplexity3.8856067657470703
INFO:root:current mean train loss 3442.4161667596727
INFO:root:current train perplexity3.885558605194092
INFO:root:current mean train loss 3443.6780016279586
INFO:root:current train perplexity3.8865880966186523

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.13s/it]
INFO:root:final mean train loss: 3441.496363670595
INFO:root:final train perplexity: 3.8875138759613037
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.23s/it]
INFO:root:eval mean loss: 4167.684288079012
INFO:root:eval perplexity: 5.3940110206604
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.44s/it]
INFO:root:eval mean loss: 5242.964674063608
INFO:root:eval perplexity: 8.532824516296387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/116
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [14:09:30<10:34:29, 453.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3393.656195746528
INFO:root:current train perplexity3.876424551010132
INFO:root:current mean train loss 3411.8889237050935
INFO:root:current train perplexity3.851228713989258
INFO:root:current mean train loss 3424.174543338725
INFO:root:current train perplexity3.866866111755371
INFO:root:current mean train loss 3427.7314266473145
INFO:root:current train perplexity3.8713595867156982
INFO:root:current mean train loss 3433.653665082516
INFO:root:current train perplexity3.8718764781951904
INFO:root:current mean train loss 3440.3764801314933
INFO:root:current train perplexity3.8741064071655273
INFO:root:current mean train loss 3438.7077582205693
INFO:root:current train perplexity3.8747498989105225
INFO:root:current mean train loss 3437.6433689794317
INFO:root:current train perplexity3.87526535987854
INFO:root:current mean train loss 3436.545728985603
INFO:root:current train perplexity3.8762431144714355
INFO:root:current mean train loss 3438.396638707693
INFO:root:current train perplexity3.8784232139587402

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.50s/it]
INFO:root:final mean train loss: 3436.4142770459575
INFO:root:final train perplexity: 3.8797268867492676
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.37s/it]
INFO:root:eval mean loss: 4168.24304112644
INFO:root:eval perplexity: 5.395228862762451
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 5249.193641608488
INFO:root:eval perplexity: 8.554583549499512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/117
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [14:16:28<10:12:07, 442.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3446.7148088727677
INFO:root:current train perplexity3.8702566623687744
INFO:root:current mean train loss 3416.1580928096064
INFO:root:current train perplexity3.838921070098877
INFO:root:current mean train loss 3423.7159314744017
INFO:root:current train perplexity3.8472981452941895
INFO:root:current mean train loss 3433.9171729244404
INFO:root:current train perplexity3.8639304637908936
INFO:root:current mean train loss 3429.2268296515804
INFO:root:current train perplexity3.8628556728363037
INFO:root:current mean train loss 3432.6800443560164
INFO:root:current train perplexity3.8643016815185547
INFO:root:current mean train loss 3434.811408479946
INFO:root:current train perplexity3.866072416305542
INFO:root:current mean train loss 3433.1722064997875
INFO:root:current train perplexity3.8683700561523438
INFO:root:current mean train loss 3434.8152086452096
INFO:root:current train perplexity3.8712270259857178
INFO:root:current mean train loss 3434.021744704629
INFO:root:current train perplexity3.8719444274902344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.93s/it]
INFO:root:final mean train loss: 3432.3005699649934
INFO:root:final train perplexity: 3.8734359741210938
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.22s/it]
INFO:root:eval mean loss: 4170.7351922650705
INFO:root:eval perplexity: 5.400669574737549
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.06s/it]
INFO:root:eval mean loss: 5248.398529269171
INFO:root:eval perplexity: 8.551803588867188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/118
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [14:23:19<9:51:58, 433.15s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3403.880138308503
INFO:root:current train perplexity3.8371875286102295
INFO:root:current mean train loss 3426.1546724759614
INFO:root:current train perplexity3.8498618602752686
INFO:root:current mean train loss 3422.716537663966
INFO:root:current train perplexity3.8504254817962646
INFO:root:current mean train loss 3414.1987439925747
INFO:root:current train perplexity3.8443245887756348
INFO:root:current mean train loss 3420.0993971986104
INFO:root:current train perplexity3.8486123085021973
INFO:root:current mean train loss 3421.756594944176
INFO:root:current train perplexity3.8506503105163574
INFO:root:current mean train loss 3424.847586766743
INFO:root:current train perplexity3.8554515838623047
INFO:root:current mean train loss 3429.838073319734
INFO:root:current train perplexity3.858275890350342
INFO:root:current mean train loss 3429.3004948264197
INFO:root:current train perplexity3.861315965652466
INFO:root:current mean train loss 3429.9475900239427
INFO:root:current train perplexity3.8633506298065186

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.29s/it]
INFO:root:final mean train loss: 3427.2218702377813
INFO:root:final train perplexity: 3.8656821250915527
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.48s/it]
INFO:root:eval mean loss: 4172.628165170656
INFO:root:eval perplexity: 5.404804706573486
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.56s/it]
INFO:root:eval mean loss: 5252.069275335217
INFO:root:eval perplexity: 8.564650535583496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/119
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [14:30:13<9:36:46, 427.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3405.187509574142
INFO:root:current train perplexity3.821906089782715
INFO:root:current mean train loss 3423.4600773489237
INFO:root:current train perplexity3.8374862670898438
INFO:root:current mean train loss 3417.6698168264443
INFO:root:current train perplexity3.846184730529785
INFO:root:current mean train loss 3416.2644036013176
INFO:root:current train perplexity3.8467788696289062
INFO:root:current mean train loss 3421.2863645024945
INFO:root:current train perplexity3.8527491092681885
INFO:root:current mean train loss 3419.673835657469
INFO:root:current train perplexity3.8565473556518555
INFO:root:current mean train loss 3421.7388707877303
INFO:root:current train perplexity3.85725998878479
INFO:root:current mean train loss 3425.1510616053597
INFO:root:current train perplexity3.8573672771453857
INFO:root:current mean train loss 3422.947959890937
INFO:root:current train perplexity3.8556888103485107
INFO:root:current mean train loss 3424.8861585871778
INFO:root:current train perplexity3.858571767807007

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.50s/it]
INFO:root:final mean train loss: 3422.6256725557387
INFO:root:final train perplexity: 3.8586788177490234
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.66s/it]
INFO:root:eval mean loss: 4174.047827321587
INFO:root:eval perplexity: 5.4079084396362305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.19s/it]
INFO:root:eval mean loss: 5252.308093348293
INFO:root:eval perplexity: 8.5654878616333
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/120
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [14:37:05<9:23:44, 422.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3383.6996615135063
INFO:root:current train perplexity3.8347456455230713
INFO:root:current mean train loss 3393.7074565767493
INFO:root:current train perplexity3.8355796337127686
INFO:root:current mean train loss 3399.368107504826
INFO:root:current train perplexity3.8346145153045654
INFO:root:current mean train loss 3400.27130824012
INFO:root:current train perplexity3.835592746734619
INFO:root:current mean train loss 3407.1343209592865
INFO:root:current train perplexity3.834254264831543
INFO:root:current mean train loss 3407.0646902777003
INFO:root:current train perplexity3.8366734981536865
INFO:root:current mean train loss 3408.822606088178
INFO:root:current train perplexity3.8406622409820557
INFO:root:current mean train loss 3413.9840337177825
INFO:root:current train perplexity3.846006393432617
INFO:root:current mean train loss 3418.336112292182
INFO:root:current train perplexity3.8486387729644775
INFO:root:current mean train loss 3419.612829882609
INFO:root:current train perplexity3.8493363857269287

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.25s/it]
INFO:root:final mean train loss: 3416.9781040068597
INFO:root:final train perplexity: 3.850090265274048
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it]
INFO:root:eval mean loss: 4173.644598778258
INFO:root:eval perplexity: 5.407026767730713
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.49s/it]
INFO:root:eval mean loss: 5259.940765597296
INFO:root:eval perplexity: 8.592263221740723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/121
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [14:44:00<9:13:36, 420.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3420.4692492129197
INFO:root:current train perplexity3.846562147140503
INFO:root:current mean train loss 3423.483528548372
INFO:root:current train perplexity3.8468196392059326
INFO:root:current mean train loss 3415.3683387099136
INFO:root:current train perplexity3.839885950088501
INFO:root:current mean train loss 3417.729275986674
INFO:root:current train perplexity3.840080976486206
INFO:root:current mean train loss 3419.410602708445
INFO:root:current train perplexity3.8389828205108643
INFO:root:current mean train loss 3420.623444303213
INFO:root:current train perplexity3.8428211212158203
INFO:root:current mean train loss 3417.652041776963
INFO:root:current train perplexity3.8439435958862305
INFO:root:current mean train loss 3419.738295892071
INFO:root:current train perplexity3.8440611362457275
INFO:root:current mean train loss 3417.7346526501224
INFO:root:current train perplexity3.8444738388061523
INFO:root:current mean train loss 3415.4841982694543
INFO:root:current train perplexity3.8445115089416504

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.71s/it]
INFO:root:final mean train loss: 3413.937809851862
INFO:root:final train perplexity: 3.845475435256958
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.93s/it]
INFO:root:eval mean loss: 4175.640657898382
INFO:root:eval perplexity: 5.411392688751221
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.94s/it]
INFO:root:eval mean loss: 5257.573063843639
INFO:root:eval perplexity: 8.583948135375977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/122
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [14:50:52<9:03:11, 417.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3406.280504557292
INFO:root:current train perplexity3.8224306106567383
INFO:root:current mean train loss 3403.7706375558037
INFO:root:current train perplexity3.8309385776519775
INFO:root:current mean train loss 3401.047666903409
INFO:root:current train perplexity3.826349973678589
INFO:root:current mean train loss 3407.680828776042
INFO:root:current train perplexity3.8353848457336426
INFO:root:current mean train loss 3407.4708932976973
INFO:root:current train perplexity3.8346643447875977
INFO:root:current mean train loss 3403.9441355298914
INFO:root:current train perplexity3.831301689147949
INFO:root:current mean train loss 3408.0265776909723
INFO:root:current train perplexity3.835294723510742
INFO:root:current mean train loss 3409.2109642767136
INFO:root:current train perplexity3.8368992805480957
INFO:root:current mean train loss 3409.149761439732
INFO:root:current train perplexity3.835726737976074
INFO:root:current mean train loss 3411.143792317708
INFO:root:current train perplexity3.838249683380127

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.92s/it]
INFO:root:final mean train loss: 3409.584111613612
INFO:root:final train perplexity: 3.8388757705688477
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.83s/it]
INFO:root:eval mean loss: 4174.799925892065
INFO:root:eval perplexity: 5.4095540046691895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.09s/it]
INFO:root:eval mean loss: 5259.541079690271
INFO:root:eval perplexity: 8.590858459472656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/123
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [14:57:40<8:52:25, 414.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3398.579045674887
INFO:root:current train perplexity3.8077566623687744
INFO:root:current mean train loss 3390.5474660070868
INFO:root:current train perplexity3.816277027130127
INFO:root:current mean train loss 3403.6477275080056
INFO:root:current train perplexity3.8286993503570557
INFO:root:current mean train loss 3403.3070422140177
INFO:root:current train perplexity3.8290789127349854
INFO:root:current mean train loss 3402.831573296778
INFO:root:current train perplexity3.8290982246398926
INFO:root:current mean train loss 3402.2961559786395
INFO:root:current train perplexity3.8282597064971924
INFO:root:current mean train loss 3406.812712684732
INFO:root:current train perplexity3.831268310546875
INFO:root:current mean train loss 3408.376168320462
INFO:root:current train perplexity3.830841302871704
INFO:root:current mean train loss 3407.956536056501
INFO:root:current train perplexity3.8319082260131836
INFO:root:current mean train loss 3408.2926674859327
INFO:root:current train perplexity3.832598924636841

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.38s/it]
INFO:root:final mean train loss: 3405.645411399103
INFO:root:final train perplexity: 3.8329148292541504
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.32s/it]
INFO:root:eval mean loss: 4176.9964227338205
INFO:root:eval perplexity: 5.414360046386719
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.06s/it]
INFO:root:eval mean loss: 5261.836720135195
INFO:root:eval perplexity: 8.598925590515137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/124
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [15:04:32<8:44:22, 413.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3383.6326273823834
INFO:root:current train perplexity3.830533504486084
INFO:root:current mean train loss 3395.588441539185
INFO:root:current train perplexity3.813966751098633
INFO:root:current mean train loss 3392.475371160868
INFO:root:current train perplexity3.811678171157837
INFO:root:current mean train loss 3394.683782318974
INFO:root:current train perplexity3.8122048377990723
INFO:root:current mean train loss 3396.470700638843
INFO:root:current train perplexity3.8135297298431396
INFO:root:current mean train loss 3396.836923150645
INFO:root:current train perplexity3.814650535583496
INFO:root:current mean train loss 3399.2253022256014
INFO:root:current train perplexity3.8180484771728516
INFO:root:current mean train loss 3402.876769479397
INFO:root:current train perplexity3.821131706237793
INFO:root:current mean train loss 3402.2093520929784
INFO:root:current train perplexity3.8220126628875732
INFO:root:current mean train loss 3403.49220351326
INFO:root:current train perplexity3.825756072998047

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.66s/it]
INFO:root:final mean train loss: 3400.8703621895083
INFO:root:final train perplexity: 3.8257012367248535
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.76s/it]
INFO:root:eval mean loss: 4180.630435159021
INFO:root:eval perplexity: 5.4223222732543945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.83s/it]
INFO:root:eval mean loss: 5270.339977075022
INFO:root:eval perplexity: 8.628877639770508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/125
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [15:11:22<8:36:08, 412.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3399.0863394689077
INFO:root:current train perplexity3.7774834632873535
INFO:root:current mean train loss 3399.345419725581
INFO:root:current train perplexity3.800175428390503
INFO:root:current mean train loss 3395.156340634145
INFO:root:current train perplexity3.8045146465301514
INFO:root:current mean train loss 3399.7319488907815
INFO:root:current train perplexity3.8097312450408936
INFO:root:current mean train loss 3396.534769734782
INFO:root:current train perplexity3.8121888637542725
INFO:root:current mean train loss 3397.699698879643
INFO:root:current train perplexity3.8169808387756348
INFO:root:current mean train loss 3399.6685883572513
INFO:root:current train perplexity3.815809488296509
INFO:root:current mean train loss 3398.7844207725475
INFO:root:current train perplexity3.8165524005889893
INFO:root:current mean train loss 3396.8887251025444
INFO:root:current train perplexity3.8156187534332275

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.42s/it]
INFO:root:final mean train loss: 3396.611048729189
INFO:root:final train perplexity: 3.819277763366699
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.52s/it]
INFO:root:eval mean loss: 4177.337095869349
INFO:root:eval perplexity: 5.415106296539307
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.82s/it]
INFO:root:eval mean loss: 5268.920261247784
INFO:root:eval perplexity: 8.62386703491211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/126
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [15:18:17<8:29:58, 413.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3310.609200613839
INFO:root:current train perplexity3.8032140731811523
INFO:root:current mean train loss 3376.713102821992
INFO:root:current train perplexity3.7826991081237793
INFO:root:current mean train loss 3382.0730228147645
INFO:root:current train perplexity3.7986061573028564
INFO:root:current mean train loss 3390.115267775346
INFO:root:current train perplexity3.802832841873169
INFO:root:current mean train loss 3391.0453609682127
INFO:root:current train perplexity3.806419610977173
INFO:root:current mean train loss 3395.245512531589
INFO:root:current train perplexity3.8080921173095703
INFO:root:current mean train loss 3391.201004958428
INFO:root:current train perplexity3.8062567710876465
INFO:root:current mean train loss 3396.64821511448
INFO:root:current train perplexity3.8114304542541504
INFO:root:current mean train loss 3398.0856367865163
INFO:root:current train perplexity3.8137435913085938
INFO:root:current mean train loss 3396.682725664536
INFO:root:current train perplexity3.814911127090454

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.99s/it]
INFO:root:final mean train loss: 3393.8033491565334
INFO:root:final train perplexity: 3.815049409866333
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.39s/it]
INFO:root:eval mean loss: 4178.959758352726
INFO:root:eval perplexity: 5.418660640716553
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.11s/it]
INFO:root:eval mean loss: 5268.11511143894
INFO:root:eval perplexity: 8.621030807495117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/127
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [15:25:09<8:22:22, 412.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3414.466650390625
INFO:root:current train perplexity3.7481095790863037
INFO:root:current mean train loss 3370.744527004076
INFO:root:current train perplexity3.774420738220215
INFO:root:current mean train loss 3375.493963481105
INFO:root:current train perplexity3.779832601547241
INFO:root:current mean train loss 3377.649897693452
INFO:root:current train perplexity3.7886483669281006
INFO:root:current mean train loss 3383.0293145237197
INFO:root:current train perplexity3.7994096279144287
INFO:root:current mean train loss 3384.3376957865594
INFO:root:current train perplexity3.803358793258667
INFO:root:current mean train loss 3385.627691501524
INFO:root:current train perplexity3.8058037757873535
INFO:root:current mean train loss 3389.1629169170674
INFO:root:current train perplexity3.809619903564453
INFO:root:current mean train loss 3389.495079143501
INFO:root:current train perplexity3.8076624870300293
INFO:root:current mean train loss 3391.9666279777152
INFO:root:current train perplexity3.8094322681427

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.64s/it]
INFO:root:final mean train loss: 3389.556852955972
INFO:root:final train perplexity: 3.8086631298065186
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.38s/it]
INFO:root:eval mean loss: 4182.223502950465
INFO:root:eval perplexity: 5.425816535949707
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.46s/it]
INFO:root:eval mean loss: 5275.747953374335
INFO:root:eval perplexity: 8.647981643676758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/128
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [15:32:04<8:16:27, 413.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3336.792777683424
INFO:root:current train perplexity3.7625887393951416
INFO:root:current mean train loss 3349.954159124111
INFO:root:current train perplexity3.7622156143188477
INFO:root:current mean train loss 3360.420291917741
INFO:root:current train perplexity3.7713277339935303
INFO:root:current mean train loss 3369.3700060770607
INFO:root:current train perplexity3.77900767326355
INFO:root:current mean train loss 3371.9611106493794
INFO:root:current train perplexity3.7845730781555176
INFO:root:current mean train loss 3376.0797350210623
INFO:root:current train perplexity3.789149761199951
INFO:root:current mean train loss 3377.658241921022
INFO:root:current train perplexity3.788726568222046
INFO:root:current mean train loss 3383.612686600428
INFO:root:current train perplexity3.795971632003784
INFO:root:current mean train loss 3385.944458156136
INFO:root:current train perplexity3.798489809036255
INFO:root:current mean train loss 3387.098996775122
INFO:root:current train perplexity3.8016607761383057

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.07s/it]
INFO:root:final mean train loss: 3384.6105859818
INFO:root:final train perplexity: 3.8012380599975586
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.12s/it]
INFO:root:eval mean loss: 4181.202868738918
INFO:root:eval perplexity: 5.423577785491943
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it]
INFO:root:eval mean loss: 5272.3827051473845
INFO:root:eval perplexity: 8.636087417602539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/129
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [15:38:57<8:09:09, 413.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3316.6731035786293
INFO:root:current train perplexity3.7565836906433105
INFO:root:current mean train loss 3367.646478783993
INFO:root:current train perplexity3.7751200199127197
INFO:root:current mean train loss 3377.0993440966586
INFO:root:current train perplexity3.773533582687378
INFO:root:current mean train loss 3379.8775726963745
INFO:root:current train perplexity3.7777321338653564
INFO:root:current mean train loss 3383.7663710167126
INFO:root:current train perplexity3.781602144241333
INFO:root:current mean train loss 3382.731540485964
INFO:root:current train perplexity3.7823667526245117
INFO:root:current mean train loss 3381.1655726122967
INFO:root:current train perplexity3.7867186069488525
INFO:root:current mean train loss 3380.711999895798
INFO:root:current train perplexity3.7866034507751465
INFO:root:current mean train loss 3382.201685128516
INFO:root:current train perplexity3.791656017303467
INFO:root:current mean train loss 3383.644467264702
INFO:root:current train perplexity3.795271635055542

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.62s/it]
INFO:root:final mean train loss: 3380.4219221299695
INFO:root:final train perplexity: 3.7949612140655518
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.89s/it]
INFO:root:eval mean loss: 4183.931818968861
INFO:root:eval perplexity: 5.4295654296875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.95s/it]
INFO:root:eval mean loss: 5272.645412580341
INFO:root:eval perplexity: 8.637015342712402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/130
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [15:45:49<8:01:59, 413.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3371.353521885016
INFO:root:current train perplexity3.7836523056030273
INFO:root:current mean train loss 3385.479548392536
INFO:root:current train perplexity3.799429416656494
INFO:root:current mean train loss 3379.8351744328584
INFO:root:current train perplexity3.792595148086548
INFO:root:current mean train loss 3378.7630582826328
INFO:root:current train perplexity3.7894785404205322
INFO:root:current mean train loss 3375.302405702769
INFO:root:current train perplexity3.784996271133423
INFO:root:current mean train loss 3376.162666957763
INFO:root:current train perplexity3.786914825439453
INFO:root:current mean train loss 3379.445286519464
INFO:root:current train perplexity3.7875781059265137
INFO:root:current mean train loss 3378.9687364549854
INFO:root:current train perplexity3.7896745204925537
INFO:root:current mean train loss 3377.2206292135356
INFO:root:current train perplexity3.788188934326172
INFO:root:current mean train loss 3380.371598411292
INFO:root:current train perplexity3.7916035652160645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.68s/it]
INFO:root:final mean train loss: 3378.2238990414526
INFO:root:final train perplexity: 3.791672468185425
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.05s/it]
INFO:root:eval mean loss: 4188.158559812721
INFO:root:eval perplexity: 5.438854694366455
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.71s/it]
INFO:root:eval mean loss: 5287.298469705785
INFO:root:eval perplexity: 8.688921928405762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/131
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [15:52:47<7:56:37, 414.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3343.6491075880986
INFO:root:current train perplexity3.780576229095459
INFO:root:current mean train loss 3359.0563084608843
INFO:root:current train perplexity3.7898480892181396
INFO:root:current mean train loss 3359.833657206794
INFO:root:current train perplexity3.7788941860198975
INFO:root:current mean train loss 3364.756296295254
INFO:root:current train perplexity3.7801926136016846
INFO:root:current mean train loss 3363.3958289639263
INFO:root:current train perplexity3.7783918380737305
INFO:root:current mean train loss 3369.2931932522565
INFO:root:current train perplexity3.780139923095703
INFO:root:current mean train loss 3373.8194970627655
INFO:root:current train perplexity3.780669927597046
INFO:root:current mean train loss 3372.9895611090196
INFO:root:current train perplexity3.782585859298706
INFO:root:current mean train loss 3372.52137916682
INFO:root:current train perplexity3.780428886413574
INFO:root:current mean train loss 3372.613798405326
INFO:root:current train perplexity3.7816665172576904

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.98s/it]
INFO:root:final mean train loss: 3372.265953617711
INFO:root:final train perplexity: 3.7827701568603516
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.28s/it]
INFO:root:eval mean loss: 4186.031168619792
INFO:root:eval perplexity: 5.434176445007324
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.01s/it]
INFO:root:eval mean loss: 5279.650544727948
INFO:root:eval perplexity: 8.661792755126953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/132
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [15:59:39<7:49:00, 413.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3362.6612082741476
INFO:root:current train perplexity3.766590118408203
INFO:root:current mean train loss 3352.109734122984
INFO:root:current train perplexity3.7702486515045166
INFO:root:current mean train loss 3358.747762522978
INFO:root:current train perplexity3.772069215774536
INFO:root:current mean train loss 3355.847087505502
INFO:root:current train perplexity3.768350124359131
INFO:root:current mean train loss 3357.476605962397
INFO:root:current train perplexity3.7705392837524414
INFO:root:current mean train loss 3363.695777906813
INFO:root:current train perplexity3.772310733795166
INFO:root:current mean train loss 3365.9063402015745
INFO:root:current train perplexity3.775099039077759
INFO:root:current mean train loss 3369.140790562914
INFO:root:current train perplexity3.7746427059173584
INFO:root:current mean train loss 3371.4275804664658
INFO:root:current train perplexity3.777756929397583
INFO:root:current mean train loss 3371.4782704617965
INFO:root:current train perplexity3.777163028717041

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.73s/it]
INFO:root:final mean train loss: 3369.409642065725
INFO:root:final train perplexity: 3.7785089015960693
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.19s/it]
INFO:root:eval mean loss: 4187.792719414893
INFO:root:eval perplexity: 5.438049793243408
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.03s/it]
INFO:root:eval mean loss: 5286.073912275599
INFO:root:eval perplexity: 8.684574127197266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/133
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [16:06:33<7:42:11, 413.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3360.8129069010415
INFO:root:current train perplexity3.7684106826782227
INFO:root:current mean train loss 3343.979650953796
INFO:root:current train perplexity3.7505924701690674
INFO:root:current mean train loss 3342.190865056143
INFO:root:current train perplexity3.7508840560913086
INFO:root:current mean train loss 3347.4838221526343
INFO:root:current train perplexity3.7565598487854004
INFO:root:current mean train loss 3351.873617415294
INFO:root:current train perplexity3.758577823638916
INFO:root:current mean train loss 3355.5513736054063
INFO:root:current train perplexity3.761024236679077
INFO:root:current mean train loss 3362.0967290311555
INFO:root:current train perplexity3.764946460723877
INFO:root:current mean train loss 3363.3065980683773
INFO:root:current train perplexity3.765096426010132
INFO:root:current mean train loss 3366.0414518530924
INFO:root:current train perplexity3.769028425216675
INFO:root:current mean train loss 3367.1163577261
INFO:root:current train perplexity3.7721006870269775

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.97s/it]
INFO:root:final mean train loss: 3365.7696783619544
INFO:root:final train perplexity: 3.7730870246887207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.80s/it]
INFO:root:eval mean loss: 4189.196534934619
INFO:root:eval perplexity: 5.441137313842773
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.09s/it]
INFO:root:eval mean loss: 5287.377422359818
INFO:root:eval perplexity: 8.689205169677734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/134
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [16:13:25<7:34:40, 413.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3334.1258390184857
INFO:root:current train perplexity3.744539260864258
INFO:root:current mean train loss 3364.8689093338817
INFO:root:current train perplexity3.764075994491577
INFO:root:current mean train loss 3365.7391605166054
INFO:root:current train perplexity3.7643299102783203
INFO:root:current mean train loss 3361.976886924065
INFO:root:current train perplexity3.761463165283203
INFO:root:current mean train loss 3361.4617704808584
INFO:root:current train perplexity3.757547378540039
INFO:root:current mean train loss 3361.424603303552
INFO:root:current train perplexity3.7587199211120605
INFO:root:current mean train loss 3363.6528906104463
INFO:root:current train perplexity3.759512186050415
INFO:root:current mean train loss 3363.7063491761915
INFO:root:current train perplexity3.7629454135894775
INFO:root:current mean train loss 3365.1228484231488
INFO:root:current train perplexity3.7659175395965576
INFO:root:current mean train loss 3365.297687125869
INFO:root:current train perplexity3.768232822418213

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.40s/it]
INFO:root:final mean train loss: 3363.003470205492
INFO:root:final train perplexity: 3.7689714431762695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.06s/it]
INFO:root:eval mean loss: 4189.459427637411
INFO:root:eval perplexity: 5.441715240478516
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.42s/it]
INFO:root:eval mean loss: 5288.005343389849
INFO:root:eval perplexity: 8.691434860229492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/135
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [16:20:14<7:26:23, 412.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3352.8385426967957
INFO:root:current train perplexity3.766207456588745
INFO:root:current mean train loss 3349.3196782799405
INFO:root:current train perplexity3.751133918762207
INFO:root:current mean train loss 3349.3373262138775
INFO:root:current train perplexity3.7499630451202393
INFO:root:current mean train loss 3352.114605664578
INFO:root:current train perplexity3.750875234603882
INFO:root:current mean train loss 3355.8629137648422
INFO:root:current train perplexity3.7539615631103516
INFO:root:current mean train loss 3358.024543511847
INFO:root:current train perplexity3.7550971508026123
INFO:root:current mean train loss 3358.009674656549
INFO:root:current train perplexity3.7544379234313965
INFO:root:current mean train loss 3357.468677290597
INFO:root:current train perplexity3.75917649269104
INFO:root:current mean train loss 3357.184251179874
INFO:root:current train perplexity3.758631706237793
INFO:root:current mean train loss 3360.488847586424
INFO:root:current train perplexity3.7619473934173584

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.44s/it]
INFO:root:final mean train loss: 3358.1845584377165
INFO:root:final train perplexity: 3.761812925338745
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.51s/it]
INFO:root:eval mean loss: 4189.749042483932
INFO:root:eval perplexity: 5.442352294921875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.06s/it]
INFO:root:eval mean loss: 5289.358001925421
INFO:root:eval perplexity: 8.696243286132812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/136
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [16:27:08<7:20:10, 412.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3333.1435322377874
INFO:root:current train perplexity3.7595102787017822
INFO:root:current mean train loss 3338.5958127924464
INFO:root:current train perplexity3.756788730621338
INFO:root:current mean train loss 3347.7703249196975
INFO:root:current train perplexity3.759819984436035
INFO:root:current mean train loss 3349.6673486201953
INFO:root:current train perplexity3.754991054534912
INFO:root:current mean train loss 3348.7197937387705
INFO:root:current train perplexity3.7542977333068848
INFO:root:current mean train loss 3356.5750360180205
INFO:root:current train perplexity3.757359266281128
INFO:root:current mean train loss 3354.473318308201
INFO:root:current train perplexity3.756392478942871
INFO:root:current mean train loss 3355.6970791847007
INFO:root:current train perplexity3.757544755935669
INFO:root:current mean train loss 3358.3305999859076
INFO:root:current train perplexity3.7579286098480225
INFO:root:current mean train loss 3359.088775418329
INFO:root:current train perplexity3.7586939334869385

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.93s/it]
INFO:root:final mean train loss: 3356.1431939524987
INFO:root:final train perplexity: 3.758784294128418
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.42s/it]
INFO:root:eval mean loss: 4194.154359208776
INFO:root:eval perplexity: 5.452056407928467
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.91s/it]
INFO:root:eval mean loss: 5293.11587329621
INFO:root:eval perplexity: 8.709616661071777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/137
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [16:34:00<7:12:53, 412.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3333.91421926398
INFO:root:current train perplexity3.7306628227233887
INFO:root:current mean train loss 3326.1859938401444
INFO:root:current train perplexity3.7431037425994873
INFO:root:current mean train loss 3333.3862379171082
INFO:root:current train perplexity3.7395946979522705
INFO:root:current mean train loss 3341.220245129549
INFO:root:current train perplexity3.7408480644226074
INFO:root:current mean train loss 3348.7173734414455
INFO:root:current train perplexity3.7432796955108643
INFO:root:current mean train loss 3349.144772928703
INFO:root:current train perplexity3.744542360305786
INFO:root:current mean train loss 3352.2455650713805
INFO:root:current train perplexity3.7462687492370605
INFO:root:current mean train loss 3352.3524601390527
INFO:root:current train perplexity3.748924732208252
INFO:root:current mean train loss 3352.3475441362607
INFO:root:current train perplexity3.750016689300537

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.90s/it]
INFO:root:final mean train loss: 3352.2318652983636
INFO:root:final train perplexity: 3.752988338470459
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.41s/it]
INFO:root:eval mean loss: 4191.920063857491
INFO:root:eval perplexity: 5.4471330642700195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.99s/it]
INFO:root:eval mean loss: 5295.455221838985
INFO:root:eval perplexity: 8.7179536819458
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/138
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [16:42:35<7:37:52, 443.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3344.1429850260415
INFO:root:current train perplexity3.6981711387634277
INFO:root:current mean train loss 3360.047484166414
INFO:root:current train perplexity3.7431671619415283
INFO:root:current mean train loss 3348.41658328202
INFO:root:current train perplexity3.739309787750244
INFO:root:current mean train loss 3338.256480604115
INFO:root:current train perplexity3.7317159175872803
INFO:root:current mean train loss 3337.2909447454635
INFO:root:current train perplexity3.7360727787017822
INFO:root:current mean train loss 3338.993251428926
INFO:root:current train perplexity3.7352254390716553
INFO:root:current mean train loss 3342.853118440998
INFO:root:current train perplexity3.7373054027557373
INFO:root:current mean train loss 3345.6117042335304
INFO:root:current train perplexity3.7388627529144287
INFO:root:current mean train loss 3348.9525172327403
INFO:root:current train perplexity3.7444441318511963
INFO:root:current mean train loss 3351.4771135061947
INFO:root:current train perplexity3.74654483795166

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.46s/it]
INFO:root:final mean train loss: 3347.298182395197
INFO:root:final train perplexity: 3.7456905841827393
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.34s/it]
INFO:root:eval mean loss: 4192.538402800865
INFO:root:eval perplexity: 5.4484944343566895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it]
INFO:root:eval mean loss: 5293.543919340093
INFO:root:eval perplexity: 8.711142539978027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/139
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [16:51:00<7:49:19, 461.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3289.9786265980115
INFO:root:current train perplexity3.6322991847991943
INFO:root:current mean train loss 3333.9076818517738
INFO:root:current train perplexity3.7143843173980713
INFO:root:current mean train loss 3334.71401644883
INFO:root:current train perplexity3.7183918952941895
INFO:root:current mean train loss 3340.1014745779744
INFO:root:current train perplexity3.721766710281372
INFO:root:current mean train loss 3340.661043116066
INFO:root:current train perplexity3.72795033454895
INFO:root:current mean train loss 3337.8917171829135
INFO:root:current train perplexity3.730797529220581
INFO:root:current mean train loss 3342.029929003427
INFO:root:current train perplexity3.7340340614318848
INFO:root:current mean train loss 3341.7409022421107
INFO:root:current train perplexity3.7343602180480957
INFO:root:current mean train loss 3344.4359433401087
INFO:root:current train perplexity3.738909959793091
INFO:root:current mean train loss 3345.2293991943093
INFO:root:current train perplexity3.739727020263672

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.08s/it]
INFO:root:final mean train loss: 3344.565194899036
INFO:root:final train perplexity: 3.7416534423828125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.11s/it]
INFO:root:eval mean loss: 4197.434106272163
INFO:root:eval perplexity: 5.459291458129883
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.11s/it]
INFO:root:eval mean loss: 5304.480333693484
INFO:root:eval perplexity: 8.750186920166016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/140
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [16:59:24<7:54:21, 474.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3356.2386153371713
INFO:root:current train perplexity3.7092957496643066
INFO:root:current mean train loss 3341.9073311941966
INFO:root:current train perplexity3.7223803997039795
INFO:root:current mean train loss 3338.364734945776
INFO:root:current train perplexity3.7275381088256836
INFO:root:current mean train loss 3338.4482865767045
INFO:root:current train perplexity3.72647762298584
INFO:root:current mean train loss 3341.700505295346
INFO:root:current train perplexity3.7298836708068848
INFO:root:current mean train loss 3343.056527727601
INFO:root:current train perplexity3.731142282485962
INFO:root:current mean train loss 3344.36461159948
INFO:root:current train perplexity3.7322943210601807
INFO:root:current mean train loss 3343.6115597020603
INFO:root:current train perplexity3.7310492992401123
INFO:root:current mean train loss 3343.787534757994
INFO:root:current train perplexity3.73148512840271
INFO:root:current mean train loss 3343.036518018056
INFO:root:current train perplexity3.73348331451416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.38s/it]
INFO:root:final mean train loss: 3341.2157212534257
INFO:root:final train perplexity: 3.736713409423828
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.93s/it]
INFO:root:eval mean loss: 4196.754633477393
INFO:root:eval perplexity: 5.457791805267334
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.39s/it]
INFO:root:eval mean loss: 5304.086145279255
INFO:root:eval perplexity: 8.748774528503418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/141
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [17:07:49<7:55:27, 483.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3293.86328125
INFO:root:current train perplexity3.6825358867645264
INFO:root:current mean train loss 3311.0159710260828
INFO:root:current train perplexity3.69987416267395
INFO:root:current mean train loss 3323.0628323323926
INFO:root:current train perplexity3.6974849700927734
INFO:root:current mean train loss 3330.1713822391057
INFO:root:current train perplexity3.712575912475586
INFO:root:current mean train loss 3333.373268717067
INFO:root:current train perplexity3.7175676822662354
INFO:root:current mean train loss 3336.5857781368595
INFO:root:current train perplexity3.724269390106201
INFO:root:current mean train loss 3334.742495888158
INFO:root:current train perplexity3.7260591983795166
INFO:root:current mean train loss 3337.9812434851056
INFO:root:current train perplexity3.7293434143066406
INFO:root:current mean train loss 3341.5984093367406
INFO:root:current train perplexity3.7330493927001953
INFO:root:current mean train loss 3341.066464453968
INFO:root:current train perplexity3.7325916290283203

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.29s/it]
INFO:root:final mean train loss: 3338.5286935990857
INFO:root:final train perplexity: 3.7327535152435303
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.59s/it]
INFO:root:eval mean loss: 4201.7264551473845
INFO:root:eval perplexity: 5.468775272369385
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.05s/it]
INFO:root:eval mean loss: 5306.528377451795
INFO:root:eval perplexity: 8.757515907287598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/142
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [17:16:14<7:53:45, 490.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3313.2035365513393
INFO:root:current train perplexity3.705554246902466
INFO:root:current mean train loss 3323.4581181278936
INFO:root:current train perplexity3.6963651180267334
INFO:root:current mean train loss 3327.0658639461435
INFO:root:current train perplexity3.7035977840423584
INFO:root:current mean train loss 3330.6943133453824
INFO:root:current train perplexity3.7054636478424072
INFO:root:current mean train loss 3331.1811063218393
INFO:root:current train perplexity3.7122764587402344
INFO:root:current mean train loss 3334.68075213566
INFO:root:current train perplexity3.7141611576080322
INFO:root:current mean train loss 3335.4571665846456
INFO:root:current train perplexity3.717682361602783
INFO:root:current mean train loss 3333.5652675914116
INFO:root:current train perplexity3.7197349071502686
INFO:root:current mean train loss 3333.9819102030315
INFO:root:current train perplexity3.7230820655822754
INFO:root:current mean train loss 3336.973380577373
INFO:root:current train perplexity3.7253494262695312

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.88s/it]
INFO:root:final mean train loss: 3334.0116484242103
INFO:root:final train perplexity: 3.726106643676758
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.41s/it]
INFO:root:eval mean loss: 4199.962724401596
INFO:root:eval perplexity: 5.464877128601074
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.50s/it]
INFO:root:eval mean loss: 5307.446697695035
INFO:root:eval perplexity: 8.760805130004883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/143
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [17:24:47<7:52:12, 497.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3352.7568586482557
INFO:root:current train perplexity3.708130359649658
INFO:root:current mean train loss 3313.2589871066434
INFO:root:current train perplexity3.714970588684082
INFO:root:current mean train loss 3319.881144708076
INFO:root:current train perplexity3.7113494873046875
INFO:root:current mean train loss 3318.835492637345
INFO:root:current train perplexity3.7122347354888916
INFO:root:current mean train loss 3318.9098068478415
INFO:root:current train perplexity3.7145893573760986
INFO:root:current mean train loss 3326.450423267006
INFO:root:current train perplexity3.7193150520324707
INFO:root:current mean train loss 3330.8966575136083
INFO:root:current train perplexity3.719464063644409
INFO:root:current mean train loss 3335.1772842099176
INFO:root:current train perplexity3.723700761795044
INFO:root:current mean train loss 3333.2959554905287
INFO:root:current train perplexity3.7223470211029053
INFO:root:current mean train loss 3334.9311544149323
INFO:root:current train perplexity3.7227416038513184

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.72s/it]
INFO:root:final mean train loss: 3332.168969062067
INFO:root:final train perplexity: 3.7233994007110596
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.65s/it]
INFO:root:eval mean loss: 4200.283429950687
INFO:root:eval perplexity: 5.4655866622924805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.89s/it]
INFO:root:eval mean loss: 5311.561611743684
INFO:root:eval perplexity: 8.77556037902832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/144
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [17:33:13<7:46:17, 499.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3294.334400850184
INFO:root:current train perplexity3.714553117752075
INFO:root:current mean train loss 3305.4921519298427
INFO:root:current train perplexity3.707636594772339
INFO:root:current mean train loss 3314.1439058220244
INFO:root:current train perplexity3.7018229961395264
INFO:root:current mean train loss 3319.875781806446
INFO:root:current train perplexity3.6994640827178955
INFO:root:current mean train loss 3321.216076362424
INFO:root:current train perplexity3.7049636840820312
INFO:root:current mean train loss 3324.3397250028356
INFO:root:current train perplexity3.7086334228515625
INFO:root:current mean train loss 3327.7863383256527
INFO:root:current train perplexity3.71101713180542
INFO:root:current mean train loss 3329.355627067556
INFO:root:current train perplexity3.7128968238830566
INFO:root:current mean train loss 3330.446088528661
INFO:root:current train perplexity3.714534044265747
INFO:root:current mean train loss 3331.550411059904
INFO:root:current train perplexity3.7180957794189453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.47s/it]
INFO:root:final mean train loss: 3328.482430119668
INFO:root:final train perplexity: 3.7179882526397705
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 4201.539192362035
INFO:root:eval perplexity: 5.4683613777160645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it]
INFO:root:eval mean loss: 5310.987666569703
INFO:root:eval perplexity: 8.7735013961792
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/145
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [17:42:18<7:50:27, 513.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3306.124379303496
INFO:root:current train perplexity3.6809847354888916
INFO:root:current mean train loss 3325.8501606107507
INFO:root:current train perplexity3.6899056434631348
INFO:root:current mean train loss 3323.2998895240107
INFO:root:current train perplexity3.6879279613494873
INFO:root:current mean train loss 3326.771045737944
INFO:root:current train perplexity3.6972789764404297
INFO:root:current mean train loss 3324.16443323206
INFO:root:current train perplexity3.6992263793945312
INFO:root:current mean train loss 3325.5965984528734
INFO:root:current train perplexity3.706000804901123
INFO:root:current mean train loss 3322.7656946486154
INFO:root:current train perplexity3.7053534984588623
INFO:root:current mean train loss 3324.8098784636445
INFO:root:current train perplexity3.70984148979187
INFO:root:current mean train loss 3325.542606944394
INFO:root:current train perplexity3.712625026702881
INFO:root:current mean train loss 3326.9549877496906
INFO:root:current train perplexity3.713085412979126

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.00s/it]
INFO:root:final mean train loss: 3325.6724521267797
INFO:root:final train perplexity: 3.7138681411743164
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.67s/it]
INFO:root:eval mean loss: 4204.660095647717
INFO:root:eval perplexity: 5.4752678871154785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.40s/it]
INFO:root:eval mean loss: 5314.63317784519
INFO:root:eval perplexity: 8.786588668823242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/146
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [17:51:09<7:46:36, 518.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3320.9906971490204
INFO:root:current train perplexity3.680452585220337
INFO:root:current mean train loss 3322.9286071411866
INFO:root:current train perplexity3.692552328109741
INFO:root:current mean train loss 3325.2144423352647
INFO:root:current train perplexity3.6978557109832764
INFO:root:current mean train loss 3319.6684257652846
INFO:root:current train perplexity3.6984000205993652
INFO:root:current mean train loss 3318.754466675589
INFO:root:current train perplexity3.6964311599731445
INFO:root:current mean train loss 3319.5889851672728
INFO:root:current train perplexity3.6970388889312744
INFO:root:current mean train loss 3319.5407594054536
INFO:root:current train perplexity3.6997058391571045
INFO:root:current mean train loss 3321.031405651585
INFO:root:current train perplexity3.7037994861602783
INFO:root:current mean train loss 3323.7345146698385
INFO:root:current train perplexity3.70631742477417
INFO:root:current mean train loss 3324.256114119458
INFO:root:current train perplexity3.706347942352295

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.34s/it]
INFO:root:final mean train loss: 3320.741569519043
INFO:root:final train perplexity: 3.706650733947754
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.96s/it]
INFO:root:eval mean loss: 4201.755085397274
INFO:root:eval perplexity: 5.4688401222229
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.85s/it]
INFO:root:eval mean loss: 5312.13564176086
INFO:root:eval perplexity: 8.777619361877441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/147
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [17:59:35<7:34:46, 514.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3330.359248046875
INFO:root:current train perplexity3.714841842651367
INFO:root:current mean train loss 3333.7573200334823
INFO:root:current train perplexity3.7039217948913574
INFO:root:current mean train loss 3329.6577503551134
INFO:root:current train perplexity3.706472158432007
INFO:root:current mean train loss 3323.0029973958335
INFO:root:current train perplexity3.7010347843170166
INFO:root:current mean train loss 3317.4738049958883
INFO:root:current train perplexity3.702916145324707
INFO:root:current mean train loss 3319.826891134511
INFO:root:current train perplexity3.700483798980713
INFO:root:current mean train loss 3318.55521556713
INFO:root:current train perplexity3.7008869647979736
INFO:root:current mean train loss 3318.451681577621
INFO:root:current train perplexity3.7012903690338135
INFO:root:current mean train loss 3319.3361498325894
INFO:root:current train perplexity3.702439785003662
INFO:root:current mean train loss 3321.753587740385
INFO:root:current train perplexity3.704521894454956

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.29s/it]
INFO:root:final mean train loss: 3319.206723982288
INFO:root:final train perplexity: 3.70440673828125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.83s/it]
INFO:root:eval mean loss: 4207.77571441434
INFO:root:eval perplexity: 5.482170104980469
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.35s/it]
INFO:root:eval mean loss: 5319.06994715481
INFO:root:eval perplexity: 8.802543640136719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/148
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [18:07:57<7:22:49, 510.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3281.0984475009413
INFO:root:current train perplexity3.7014267444610596
INFO:root:current mean train loss 3310.042038881062
INFO:root:current train perplexity3.6938278675079346
INFO:root:current mean train loss 3312.7807082321115
INFO:root:current train perplexity3.690201759338379
INFO:root:current mean train loss 3311.3431699269745
INFO:root:current train perplexity3.687183380126953
INFO:root:current mean train loss 3313.3857214633476
INFO:root:current train perplexity3.689351797103882
INFO:root:current mean train loss 3310.847693938947
INFO:root:current train perplexity3.6866190433502197
INFO:root:current mean train loss 3314.847618359947
INFO:root:current train perplexity3.690924882888794
INFO:root:current mean train loss 3316.018622660241
INFO:root:current train perplexity3.694074869155884
INFO:root:current mean train loss 3317.7379961888623
INFO:root:current train perplexity3.698742628097534
INFO:root:current mean train loss 3320.26186106188
INFO:root:current train perplexity3.701305627822876

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.37s/it]
INFO:root:final mean train loss: 3317.0627254978303
INFO:root:final train perplexity: 3.7012743949890137
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.81s/it]
INFO:root:eval mean loss: 4203.400738655253
INFO:root:eval perplexity: 5.472479820251465
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.58s/it]
INFO:root:eval mean loss: 5315.9279819786125
INFO:root:eval perplexity: 8.791243553161621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/149
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [18:16:15<7:11:00, 507.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3321.4972634787086
INFO:root:current train perplexity3.6909756660461426
INFO:root:current mean train loss 3318.62286536731
INFO:root:current train perplexity3.6903579235076904
INFO:root:current mean train loss 3312.352149779854
INFO:root:current train perplexity3.692730665206909
INFO:root:current mean train loss 3312.041266634031
INFO:root:current train perplexity3.6937222480773926
INFO:root:current mean train loss 3309.466864001241
INFO:root:current train perplexity3.690098762512207
INFO:root:current mean train loss 3308.177051937923
INFO:root:current train perplexity3.6901581287384033
INFO:root:current mean train loss 3311.5461408115502
INFO:root:current train perplexity3.69205641746521
INFO:root:current mean train loss 3311.6063058035716
INFO:root:current train perplexity3.6936850547790527
INFO:root:current mean train loss 3312.9601234239094
INFO:root:current train perplexity3.6929028034210205
INFO:root:current mean train loss 3316.2732271104
INFO:root:current train perplexity3.6963553428649902

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.92s/it]
INFO:root:final mean train loss: 3313.6178552566034
INFO:root:final train perplexity: 3.696246862411499
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.12s/it]
INFO:root:eval mean loss: 4205.858001925421
INFO:root:eval perplexity: 5.4779205322265625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.82s/it]
INFO:root:eval mean loss: 5318.1417902953235
INFO:root:eval perplexity: 8.799202919006348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/150
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [18:23:21<6:42:24, 482.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3325.4852997750945
INFO:root:current train perplexity3.706759452819824
INFO:root:current mean train loss 3321.375779041693
INFO:root:current train perplexity3.698887348175049
INFO:root:current mean train loss 3314.5161296117267
INFO:root:current train perplexity3.693434238433838
INFO:root:current mean train loss 3310.2744581179513
INFO:root:current train perplexity3.6882591247558594
INFO:root:current mean train loss 3310.9194693097133
INFO:root:current train perplexity3.688352346420288
INFO:root:current mean train loss 3308.1484497274105
INFO:root:current train perplexity3.6856932640075684
INFO:root:current mean train loss 3314.510188243249
INFO:root:current train perplexity3.688231945037842
INFO:root:current mean train loss 3313.378819777163
INFO:root:current train perplexity3.6895527839660645
INFO:root:current mean train loss 3314.1673131821817
INFO:root:current train perplexity3.6913208961486816

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.59s/it]
INFO:root:final mean train loss: 3310.34697809527
INFO:root:final train perplexity: 3.6914801597595215
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.75s/it]
INFO:root:eval mean loss: 4211.110829454788
INFO:root:eval perplexity: 5.489569187164307
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it]
INFO:root:eval mean loss: 5326.48265908965
INFO:root:eval perplexity: 8.829266548156738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/151
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [18:30:13<6:16:59, 461.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3269.2504534040177
INFO:root:current train perplexity3.582475423812866
INFO:root:current mean train loss 3285.711587781104
INFO:root:current train perplexity3.6630899906158447
INFO:root:current mean train loss 3287.7781622697767
INFO:root:current train perplexity3.666006088256836
INFO:root:current mean train loss 3291.6039060909507
INFO:root:current train perplexity3.672496795654297
INFO:root:current mean train loss 3300.8021555157784
INFO:root:current train perplexity3.6803245544433594
INFO:root:current mean train loss 3305.4639408630733
INFO:root:current train perplexity3.6844801902770996
INFO:root:current mean train loss 3303.8297290079286
INFO:root:current train perplexity3.6816413402557373
INFO:root:current mean train loss 3306.2071303565904
INFO:root:current train perplexity3.6833455562591553
INFO:root:current mean train loss 3308.323176236253
INFO:root:current train perplexity3.6864607334136963
INFO:root:current mean train loss 3309.699360335412
INFO:root:current train perplexity3.6869451999664307

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.06s/it]
INFO:root:final mean train loss: 3308.3998373093145
INFO:root:final train perplexity: 3.688645601272583
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.15s/it]
INFO:root:eval mean loss: 4207.63811087101
INFO:root:eval perplexity: 5.481865406036377
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.96s/it]
INFO:root:eval mean loss: 5321.806495179521
INFO:root:eval perplexity: 8.812397956848145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/152
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [18:37:04<5:56:58, 446.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3281.0578450520834
INFO:root:current train perplexity3.6479547023773193
INFO:root:current mean train loss 3296.7682383661686
INFO:root:current train perplexity3.661176919937134
INFO:root:current mean train loss 3296.2432265170787
INFO:root:current train perplexity3.65714955329895
INFO:root:current mean train loss 3300.999386935764
INFO:root:current train perplexity3.6673688888549805
INFO:root:current mean train loss 3302.9681299416416
INFO:root:current train perplexity3.6720046997070312
INFO:root:current mean train loss 3301.4743372648663
INFO:root:current train perplexity3.672475576400757
INFO:root:current mean train loss 3303.3395607056655
INFO:root:current train perplexity3.677198886871338
INFO:root:current mean train loss 3303.3486106178975
INFO:root:current train perplexity3.6785805225372314
INFO:root:current mean train loss 3306.5749541674654
INFO:root:current train perplexity3.681955099105835
INFO:root:current mean train loss 3307.0868908491293
INFO:root:current train perplexity3.6824519634246826

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.76s/it]
INFO:root:final mean train loss: 3304.4406821958482
INFO:root:final train perplexity: 3.682888984680176
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.86s/it]
INFO:root:eval mean loss: 4209.734347296099
INFO:root:eval perplexity: 5.486513614654541
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.50s/it]
INFO:root:eval mean loss: 5325.47058018894
INFO:root:eval perplexity: 8.825613021850586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/153
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [18:43:50<5:40:08, 434.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3294.7855277683425
INFO:root:current train perplexity3.6704723834991455
INFO:root:current mean train loss 3290.5715550368395
INFO:root:current train perplexity3.672835111618042
INFO:root:current mean train loss 3293.6677924870373
INFO:root:current train perplexity3.670780897140503
INFO:root:current mean train loss 3295.421430558243
INFO:root:current train perplexity3.6758739948272705
INFO:root:current mean train loss 3293.1997318493277
INFO:root:current train perplexity3.674945592880249
INFO:root:current mean train loss 3300.2256718301865
INFO:root:current train perplexity3.675656318664551
INFO:root:current mean train loss 3299.72521678747
INFO:root:current train perplexity3.675908327102661
INFO:root:current mean train loss 3304.559578416753
INFO:root:current train perplexity3.679333209991455
INFO:root:current mean train loss 3306.1940182283756
INFO:root:current train perplexity3.6822972297668457
INFO:root:current mean train loss 3305.906182286024
INFO:root:current train perplexity3.6802070140838623

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.01s/it]
INFO:root:final mean train loss: 3303.358442860265
INFO:root:final train perplexity: 3.681316614151001
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.39s/it]
INFO:root:eval mean loss: 4209.426986369681
INFO:root:eval perplexity: 5.4858317375183105
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.88s/it]
INFO:root:eval mean loss: 5324.877192071143
INFO:root:eval perplexity: 8.823471069335938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/154
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [18:50:42<5:27:52, 427.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3255.2345010080644
INFO:root:current train perplexity3.6390039920806885
INFO:root:current mean train loss 3281.3381161289362
INFO:root:current train perplexity3.6666147708892822
INFO:root:current mean train loss 3299.803045099432
INFO:root:current train perplexity3.6701643466949463
INFO:root:current mean train loss 3302.044064801265
INFO:root:current train perplexity3.667715549468994
INFO:root:current mean train loss 3307.6584410346577
INFO:root:current train perplexity3.671320915222168
INFO:root:current mean train loss 3305.9212975223636
INFO:root:current train perplexity3.6683807373046875
INFO:root:current mean train loss 3310.6797401198496
INFO:root:current train perplexity3.6728901863098145
INFO:root:current mean train loss 3308.1458818720075
INFO:root:current train perplexity3.6737678050994873
INFO:root:current mean train loss 3306.9825555500715
INFO:root:current train perplexity3.6765103340148926
INFO:root:current mean train loss 3304.7681768071125
INFO:root:current train perplexity3.6753146648406982

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.49s/it]
INFO:root:final mean train loss: 3300.0743317757883
INFO:root:final train perplexity: 3.6765503883361816
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.72s/it]
INFO:root:eval mean loss: 4211.788683302859
INFO:root:eval perplexity: 5.491073131561279
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.02s/it]
INFO:root:eval mean loss: 5330.791806917664
INFO:root:eval perplexity: 8.844837188720703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/155
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [18:57:33<5:16:51, 422.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3297.07086338141
INFO:root:current train perplexity3.6992688179016113
INFO:root:current mean train loss 3309.4876629946043
INFO:root:current train perplexity3.659149408340454
INFO:root:current mean train loss 3304.7742209973194
INFO:root:current train perplexity3.667006492614746
INFO:root:current mean train loss 3304.78879675401
INFO:root:current train perplexity3.667886972427368
INFO:root:current mean train loss 3298.2069211364606
INFO:root:current train perplexity3.6625585556030273
INFO:root:current mean train loss 3300.340168062964
INFO:root:current train perplexity3.6615052223205566
INFO:root:current mean train loss 3300.5667879346393
INFO:root:current train perplexity3.6655304431915283
INFO:root:current mean train loss 3300.3981371971204
INFO:root:current train perplexity3.667450189590454
INFO:root:current mean train loss 3300.5038166250747
INFO:root:current train perplexity3.6708168983459473
INFO:root:current mean train loss 3300.449466790635
INFO:root:current train perplexity3.672848701477051

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.70s/it]
INFO:root:final mean train loss: 3296.7732457806987
INFO:root:final train perplexity: 3.671764850616455
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.86s/it]
INFO:root:eval mean loss: 4212.653981743129
INFO:root:eval perplexity: 5.492995262145996
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.41s/it]
INFO:root:eval mean loss: 5331.276623448582
INFO:root:eval perplexity: 8.846589088439941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/156
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [19:04:20<5:06:26, 417.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3256.945229388298
INFO:root:current train perplexity3.646711826324463
INFO:root:current mean train loss 3275.3534574962796
INFO:root:current train perplexity3.6671717166900635
INFO:root:current mean train loss 3279.6178448016826
INFO:root:current train perplexity3.6628305912017822
INFO:root:current mean train loss 3286.828474676918
INFO:root:current train perplexity3.6620421409606934
INFO:root:current mean train loss 3288.8220072838017
INFO:root:current train perplexity3.6621556282043457
INFO:root:current mean train loss 3291.1329039969437
INFO:root:current train perplexity3.6640892028808594
INFO:root:current mean train loss 3294.625755817113
INFO:root:current train perplexity3.6666948795318604
INFO:root:current mean train loss 3294.4986828825718
INFO:root:current train perplexity3.6672110557556152
INFO:root:current mean train loss 3297.0459609859245
INFO:root:current train perplexity3.6672844886779785
INFO:root:current mean train loss 3297.219038482956
INFO:root:current train perplexity3.666808843612671

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.07s/it]
INFO:root:final mean train loss: 3294.540629479193
INFO:root:final train perplexity: 3.668531894683838
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.65s/it]
INFO:root:eval mean loss: 4214.488165239915
INFO:root:eval perplexity: 5.4970703125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 5332.549598639738
INFO:root:eval perplexity: 8.851197242736816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/157
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [19:11:12<4:58:16, 416.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3275.752197265625
INFO:root:current train perplexity3.6368138790130615
INFO:root:current mean train loss 3287.09544953377
INFO:root:current train perplexity3.664095878601074
INFO:root:current mean train loss 3293.252348537071
INFO:root:current train perplexity3.6626813411712646
INFO:root:current mean train loss 3288.632018871039
INFO:root:current train perplexity3.658267021179199
INFO:root:current mean train loss 3288.999555181147
INFO:root:current train perplexity3.6618189811706543
INFO:root:current mean train loss 3292.921336131053
INFO:root:current train perplexity3.665938138961792
INFO:root:current mean train loss 3291.089474743559
INFO:root:current train perplexity3.661334991455078
INFO:root:current mean train loss 3293.6218830841267
INFO:root:current train perplexity3.6659045219421387
INFO:root:current mean train loss 3295.3380919339365
INFO:root:current train perplexity3.666701316833496
INFO:root:current mean train loss 3296.5889873404776
INFO:root:current train perplexity3.667060136795044

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.12s/it]
INFO:root:final mean train loss: 3294.0990630119077
INFO:root:final train perplexity: 3.667893171310425
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.01s/it]
INFO:root:eval mean loss: 4213.350277731604
INFO:root:eval perplexity: 5.494541645050049
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.86s/it]
INFO:root:eval mean loss: 5330.073321836215
INFO:root:eval perplexity: 8.842241287231445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/158
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [19:18:02<4:50:03, 414.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3275.8670596168154
INFO:root:current train perplexity3.659789800643921
INFO:root:current mean train loss 3277.7876920173503
INFO:root:current train perplexity3.657392740249634
INFO:root:current mean train loss 3288.515760530537
INFO:root:current train perplexity3.662637233734131
INFO:root:current mean train loss 3292.3141188608383
INFO:root:current train perplexity3.6623315811157227
INFO:root:current mean train loss 3289.6532090518695
INFO:root:current train perplexity3.657261610031128
INFO:root:current mean train loss 3293.8204425926956
INFO:root:current train perplexity3.6559813022613525
INFO:root:current mean train loss 3292.362413685426
INFO:root:current train perplexity3.658290147781372
INFO:root:current mean train loss 3292.036443507843
INFO:root:current train perplexity3.659980535507202
INFO:root:current mean train loss 3290.1265737593244
INFO:root:current train perplexity3.661158323287964
INFO:root:current mean train loss 3291.249238423222
INFO:root:current train perplexity3.662252902984619

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.15s/it]
INFO:root:final mean train loss: 3289.650929850917
INFO:root:final train perplexity: 3.661461591720581
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.25s/it]
INFO:root:eval mean loss: 4213.473380014406
INFO:root:eval perplexity: 5.494815349578857
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.72s/it]
INFO:root:eval mean loss: 5332.437567528258
INFO:root:eval perplexity: 8.850793838500977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/159
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [19:28:46<5:30:09, 483.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3265.646075181558
INFO:root:current train perplexity3.642653226852417
INFO:root:current mean train loss 3282.190369723136
INFO:root:current train perplexity3.640639305114746
INFO:root:current mean train loss 3288.509595357184
INFO:root:current train perplexity3.651563882827759
INFO:root:current mean train loss 3292.2274107406083
INFO:root:current train perplexity3.648805618286133
INFO:root:current mean train loss 3292.6815856804005
INFO:root:current train perplexity3.654418706893921
INFO:root:current mean train loss 3292.965107558696
INFO:root:current train perplexity3.655784845352173
INFO:root:current mean train loss 3290.8081454918033
INFO:root:current train perplexity3.6554744243621826
INFO:root:current mean train loss 3289.695110791079
INFO:root:current train perplexity3.6577136516571045
INFO:root:current mean train loss 3289.213894376525
INFO:root:current train perplexity3.658951759338379
INFO:root:current mean train loss 3290.9732571728564
INFO:root:current train perplexity3.659090042114258

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.32s/it]
INFO:root:final mean train loss: 3287.773676656908
INFO:root:final train perplexity: 3.6587512493133545
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.20s/it]
INFO:root:eval mean loss: 4214.939475634419
INFO:root:eval perplexity: 5.498074531555176
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.64s/it]
INFO:root:eval mean loss: 5333.593353487921
INFO:root:eval perplexity: 8.854975700378418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/160
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [19:40:10<6:02:13, 543.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3296.110697685918
INFO:root:current train perplexity3.6714439392089844
INFO:root:current mean train loss 3278.149572276536
INFO:root:current train perplexity3.650639057159424
INFO:root:current mean train loss 3277.8958805863576
INFO:root:current train perplexity3.65429425239563
INFO:root:current mean train loss 3284.0484931563324
INFO:root:current train perplexity3.657400608062744
INFO:root:current mean train loss 3287.630059164601
INFO:root:current train perplexity3.6592047214508057
INFO:root:current mean train loss 3288.1369506625106
INFO:root:current train perplexity3.655841112136841
INFO:root:current mean train loss 3288.4438613194957
INFO:root:current train perplexity3.6561691761016846
INFO:root:current mean train loss 3287.2464895774833
INFO:root:current train perplexity3.655346393585205
INFO:root:current mean train loss 3286.494459757626
INFO:root:current train perplexity3.653878688812256
INFO:root:current mean train loss 3287.776728784953
INFO:root:current train perplexity3.655203104019165

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.61s/it]
INFO:root:final mean train loss: 3285.0887924932663
INFO:root:final train perplexity: 3.6548776626586914
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.05s/it]
INFO:root:eval mean loss: 4214.621348279587
INFO:root:eval perplexity: 5.497366428375244
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it]
INFO:root:eval mean loss: 5333.448901886635
INFO:root:eval perplexity: 8.854455947875977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/161
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [19:52:02<6:26:07, 594.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3260.6452833153735
INFO:root:current train perplexity3.6376750469207764
INFO:root:current mean train loss 3275.038234771892
INFO:root:current train perplexity3.637211561203003
INFO:root:current mean train loss 3271.4986142680204
INFO:root:current train perplexity3.639692544937134
INFO:root:current mean train loss 3277.235716196302
INFO:root:current train perplexity3.6478066444396973
INFO:root:current mean train loss 3276.6287688895663
INFO:root:current train perplexity3.6495954990386963
INFO:root:current mean train loss 3279.6156561102534
INFO:root:current train perplexity3.651155948638916
INFO:root:current mean train loss 3280.1712356856124
INFO:root:current train perplexity3.6494598388671875
INFO:root:current mean train loss 3283.8915786064563
INFO:root:current train perplexity3.6509182453155518
INFO:root:current mean train loss 3283.520614606821
INFO:root:current train perplexity3.651470184326172
INFO:root:current mean train loss 3286.4135494831244
INFO:root:current train perplexity3.6529736518859863

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.43s/it]
INFO:root:final mean train loss: 3283.9857086058587
INFO:root:final train perplexity: 3.653287172317505
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.78s/it]
INFO:root:eval mean loss: 4215.777459760085
INFO:root:eval perplexity: 5.499937534332275
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.58s/it]
INFO:root:eval mean loss: 5338.6869978668
INFO:root:eval perplexity: 8.87343978881836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/162
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [20:03:52<6:38:18, 628.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3277.876254111842
INFO:root:current train perplexity3.6435821056365967
INFO:root:current mean train loss 3268.184199719551
INFO:root:current train perplexity3.633420944213867
INFO:root:current mean train loss 3267.7402277542374
INFO:root:current train perplexity3.6383719444274902
INFO:root:current mean train loss 3270.3050391861157
INFO:root:current train perplexity3.6399624347686768
INFO:root:current mean train loss 3278.120323843908
INFO:root:current train perplexity3.6431899070739746
INFO:root:current mean train loss 3277.7385056952467
INFO:root:current train perplexity3.6433091163635254
INFO:root:current mean train loss 3279.631415453575
INFO:root:current train perplexity3.6444170475006104
INFO:root:current mean train loss 3280.258246732508
INFO:root:current train perplexity3.644418478012085
INFO:root:current mean train loss 3282.70211270295
INFO:root:current train perplexity3.6480438709259033

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.83s/it]
INFO:root:final mean train loss: 3280.5785544610794
INFO:root:final train perplexity: 3.648379325866699
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.14s/it]
INFO:root:eval mean loss: 4219.0904688192595
INFO:root:eval perplexity: 5.507309913635254
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.40s/it]
INFO:root:eval mean loss: 5342.665536001219
INFO:root:eval perplexity: 8.887886047363281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/163
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [20:15:04<6:35:40, 641.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3330.9969075520835
INFO:root:current train perplexity3.6624350547790527
INFO:root:current mean train loss 3282.168613470874
INFO:root:current train perplexity3.649507522583008
INFO:root:current mean train loss 3285.154121286176
INFO:root:current train perplexity3.6482818126678467
INFO:root:current mean train loss 3287.2690598893873
INFO:root:current train perplexity3.644726037979126
INFO:root:current mean train loss 3284.263688231816
INFO:root:current train perplexity3.6472294330596924
INFO:root:current mean train loss 3281.7226208180605
INFO:root:current train perplexity3.645582914352417
INFO:root:current mean train loss 3283.6298443492174
INFO:root:current train perplexity3.6462931632995605
INFO:root:current mean train loss 3283.713379253534
INFO:root:current train perplexity3.645860195159912
INFO:root:current mean train loss 3283.4743059474235
INFO:root:current train perplexity3.6473031044006348
INFO:root:current mean train loss 3282.8920363112543
INFO:root:current train perplexity3.647801637649536

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.54s/it]
INFO:root:final mean train loss: 3278.9062521534584
INFO:root:final train perplexity: 3.6459732055664062
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.99s/it]
INFO:root:eval mean loss: 4219.246971617354
INFO:root:eval perplexity: 5.5076584815979
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.79s/it]
INFO:root:eval mean loss: 5341.932676058289
INFO:root:eval perplexity: 8.885223388671875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/164
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [20:25:21<6:20:36, 634.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3272.4741654829545
INFO:root:current train perplexity3.6312453746795654
INFO:root:current mean train loss 3239.2237647804054
INFO:root:current train perplexity3.622248888015747
INFO:root:current mean train loss 3266.0792392531844
INFO:root:current train perplexity3.636380434036255
INFO:root:current mean train loss 3275.610514846262
INFO:root:current train perplexity3.6382827758789062
INFO:root:current mean train loss 3273.7126447023265
INFO:root:current train perplexity3.6421451568603516
INFO:root:current mean train loss 3274.5952965424717
INFO:root:current train perplexity3.6423375606536865
INFO:root:current mean train loss 3275.8681668595286
INFO:root:current train perplexity3.644007444381714
INFO:root:current mean train loss 3277.2065989391044
INFO:root:current train perplexity3.64312481880188
INFO:root:current mean train loss 3278.896132463298
INFO:root:current train perplexity3.644381523132324
INFO:root:current mean train loss 3280.142515950878
INFO:root:current train perplexity3.6444849967956543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.87s/it]
INFO:root:final mean train loss: 3276.7107897112446
INFO:root:final train perplexity: 3.6428170204162598
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.36s/it]
INFO:root:eval mean loss: 4220.780990275931
INFO:root:eval perplexity: 5.5110764503479
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.19s/it]
INFO:root:eval mean loss: 5344.659345910904
INFO:root:eval perplexity: 8.895136833190918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/165
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [20:32:13<5:31:12, 567.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3268.8318642064146
INFO:root:current train perplexity3.6286637783050537
INFO:root:current mean train loss 3269.324405445772
INFO:root:current train perplexity3.6269845962524414
INFO:root:current mean train loss 3267.485937945919
INFO:root:current train perplexity3.628338575363159
INFO:root:current mean train loss 3271.754611885286
INFO:root:current train perplexity3.635997772216797
INFO:root:current mean train loss 3269.6810492103596
INFO:root:current train perplexity3.6346001625061035
INFO:root:current mean train loss 3270.2921831722665
INFO:root:current train perplexity3.635307788848877
INFO:root:current mean train loss 3274.0744621018025
INFO:root:current train perplexity3.6358776092529297
INFO:root:current mean train loss 3275.5951282570195
INFO:root:current train perplexity3.637190341949463
INFO:root:current mean train loss 3276.2340336800785
INFO:root:current train perplexity3.6378142833709717
INFO:root:current mean train loss 3276.883557142189
INFO:root:current train perplexity3.6385090351104736

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.70s/it]
INFO:root:final mean train loss: 3274.312789055609
INFO:root:final train perplexity: 3.639371871948242
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.90s/it]
INFO:root:eval mean loss: 4219.292584358378
INFO:root:eval perplexity: 5.507760047912598
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.03s/it]
INFO:root:eval mean loss: 5344.870579496343
INFO:root:eval perplexity: 8.895904541015625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/166
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [20:39:06<4:55:23, 521.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3275.1996979890046
INFO:root:current train perplexity3.639000177383423
INFO:root:current mean train loss 3268.0744532787894
INFO:root:current train perplexity3.6297407150268555
INFO:root:current mean train loss 3282.9313878803
INFO:root:current train perplexity3.638347625732422
INFO:root:current mean train loss 3285.419815856747
INFO:root:current train perplexity3.6381187438964844
INFO:root:current mean train loss 3284.89650896059
INFO:root:current train perplexity3.6372592449188232
INFO:root:current mean train loss 3285.341452669147
INFO:root:current train perplexity3.6378138065338135
INFO:root:current mean train loss 3280.151896742923
INFO:root:current train perplexity3.635953903198242
INFO:root:current mean train loss 3276.229562373732
INFO:root:current train perplexity3.634303331375122
INFO:root:current mean train loss 3277.2027734020744
INFO:root:current train perplexity3.636967420578003
INFO:root:current mean train loss 3274.5639772219693
INFO:root:current train perplexity3.634788990020752

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.78s/it]
INFO:root:final mean train loss: 3272.3876299704275
INFO:root:final train perplexity: 3.636608839035034
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.59s/it]
INFO:root:eval mean loss: 4220.667904684729
INFO:root:eval perplexity: 5.510824680328369
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.08s/it]
INFO:root:eval mean loss: 5347.94274815769
INFO:root:eval perplexity: 8.907086372375488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/167
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [20:45:57<4:28:26, 488.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3249.393882533482
INFO:root:current train perplexity3.648062229156494
INFO:root:current mean train loss 3258.0772786458333
INFO:root:current train perplexity3.6244754791259766
INFO:root:current mean train loss 3268.286655377327
INFO:root:current train perplexity3.6300618648529053
INFO:root:current mean train loss 3267.170251282649
INFO:root:current train perplexity3.6285462379455566
INFO:root:current mean train loss 3267.3665639592314
INFO:root:current train perplexity3.6301231384277344
INFO:root:current mean train loss 3276.0157924759055
INFO:root:current train perplexity3.6334619522094727
INFO:root:current mean train loss 3274.8782799427904
INFO:root:current train perplexity3.633878707885742
INFO:root:current mean train loss 3272.998575348108
INFO:root:current train perplexity3.6335079669952393
INFO:root:current mean train loss 3272.4515531437128
INFO:root:current train perplexity3.6358935832977295
INFO:root:current mean train loss 3273.036327863887
INFO:root:current train perplexity3.634500503540039

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.02s/it]
INFO:root:final mean train loss: 3271.0515377906063
INFO:root:final train perplexity: 3.634692430496216
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.91s/it]
INFO:root:eval mean loss: 4222.119931917664
INFO:root:eval perplexity: 5.5140604972839355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.85s/it]
INFO:root:eval mean loss: 5347.456955064273
INFO:root:eval perplexity: 8.905318260192871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/168
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [20:52:51<4:08:25, 465.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3269.3604367278344
INFO:root:current train perplexity3.6210813522338867
INFO:root:current mean train loss 3273.696900267701
INFO:root:current train perplexity3.6195363998413086
INFO:root:current mean train loss 3269.793125482253
INFO:root:current train perplexity3.6183788776397705
INFO:root:current mean train loss 3274.845703125
INFO:root:current train perplexity3.6230552196502686
INFO:root:current mean train loss 3275.375988135758
INFO:root:current train perplexity3.6257364749908447
INFO:root:current mean train loss 3276.015863745252
INFO:root:current train perplexity3.629016876220703
INFO:root:current mean train loss 3274.958041984594
INFO:root:current train perplexity3.6297454833984375
INFO:root:current mean train loss 3271.7341357881896
INFO:root:current train perplexity3.6314003467559814
INFO:root:current mean train loss 3270.775798684479
INFO:root:current train perplexity3.629223585128784
INFO:root:current mean train loss 3270.0057985340172
INFO:root:current train perplexity3.629979133605957

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.11s/it]
INFO:root:final mean train loss: 3267.519966248543
INFO:root:final train perplexity: 3.629631996154785
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.07s/it]
INFO:root:eval mean loss: 4221.935233474624
INFO:root:eval perplexity: 5.513648986816406
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.61s/it]
INFO:root:eval mean loss: 5347.38205064273
INFO:root:eval perplexity: 8.905043601989746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/169
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [21:03:01<4:23:09, 509.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3276.7309713924633
INFO:root:current train perplexity3.6421568393707275
INFO:root:current mean train loss 3272.4488258614447
INFO:root:current train perplexity3.625563144683838
INFO:root:current mean train loss 3261.699369514131
INFO:root:current train perplexity3.620462417602539
INFO:root:current mean train loss 3259.9098015157588
INFO:root:current train perplexity3.621838331222534
INFO:root:current mean train loss 3270.3362081658815
INFO:root:current train perplexity3.62648868560791
INFO:root:current mean train loss 3271.355015472578
INFO:root:current train perplexity3.6254332065582275
INFO:root:current mean train loss 3270.7751648605513
INFO:root:current train perplexity3.6252079010009766
INFO:root:current mean train loss 3270.0141734848326
INFO:root:current train perplexity3.6260037422180176
INFO:root:current mean train loss 3269.4161312403608
INFO:root:current train perplexity3.6267237663269043
INFO:root:current mean train loss 3268.543104811547
INFO:root:current train perplexity3.627741813659668

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.81s/it]
INFO:root:final mean train loss: 3266.4427762185373
INFO:root:final train perplexity: 3.628089427947998
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.14s/it]
INFO:root:eval mean loss: 4223.751118544991
INFO:root:eval perplexity: 5.517698764801025
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.31s/it]
INFO:root:eval mean loss: 5348.776684050865
INFO:root:eval perplexity: 8.910123825073242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/170
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [21:09:55<4:00:17, 480.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3280.9522270590573
INFO:root:current train perplexity3.613217830657959
INFO:root:current mean train loss 3271.208711060338
INFO:root:current train perplexity3.6078948974609375
INFO:root:current mean train loss 3267.02455734194
INFO:root:current train perplexity3.6105949878692627
INFO:root:current mean train loss 3258.753190149504
INFO:root:current train perplexity3.6120076179504395
INFO:root:current mean train loss 3261.71466503268
INFO:root:current train perplexity3.62046217918396
INFO:root:current mean train loss 3262.4685106635734
INFO:root:current train perplexity3.6197376251220703
INFO:root:current mean train loss 3265.331788220789
INFO:root:current train perplexity3.623310089111328
INFO:root:current mean train loss 3263.9370631844945
INFO:root:current train perplexity3.6222407817840576
INFO:root:current mean train loss 3266.98588020227
INFO:root:current train perplexity3.624255657196045
INFO:root:current mean train loss 3267.4357294076676
INFO:root:current train perplexity3.6260697841644287

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.89s/it]
INFO:root:final mean train loss: 3265.0857531024562
INFO:root:final train perplexity: 3.626147508621216
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.09s/it]
INFO:root:eval mean loss: 4222.613660447141
INFO:root:eval perplexity: 5.515161514282227
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.58s/it]
INFO:root:eval mean loss: 5350.364065616689
INFO:root:eval perplexity: 8.915910720825195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/171
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [21:16:46<3:42:08, 459.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3254.3324029267724
INFO:root:current train perplexity3.6058034896850586
INFO:root:current mean train loss 3249.5590074733345
INFO:root:current train perplexity3.6048386096954346
INFO:root:current mean train loss 3259.0165265829824
INFO:root:current train perplexity3.6080048084259033
INFO:root:current mean train loss 3260.1736751213384
INFO:root:current train perplexity3.6156697273254395
INFO:root:current mean train loss 3260.4281604448274
INFO:root:current train perplexity3.617729902267456
INFO:root:current mean train loss 3264.578429422261
INFO:root:current train perplexity3.622283935546875
INFO:root:current mean train loss 3265.2210018037854
INFO:root:current train perplexity3.6249403953552246
INFO:root:current mean train loss 3267.8394468225433
INFO:root:current train perplexity3.624117851257324
INFO:root:current mean train loss 3266.9475125815493
INFO:root:current train perplexity3.6236822605133057
INFO:root:current mean train loss 3267.354722947098
INFO:root:current train perplexity3.6256916522979736

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.32s/it]
INFO:root:final mean train loss: 3264.414746930522
INFO:root:final train perplexity: 3.625187635421753
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.64s/it]
INFO:root:eval mean loss: 4224.5504297567595
INFO:root:eval perplexity: 5.519482135772705
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.01s/it]
INFO:root:eval mean loss: 5351.301955202793
INFO:root:eval perplexity: 8.919329643249512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/172
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [21:23:36<3:27:33, 444.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3256.605673828125
INFO:root:current train perplexity3.602992534637451
INFO:root:current mean train loss 3256.490908203125
INFO:root:current train perplexity3.60760498046875
INFO:root:current mean train loss 3258.141662819602
INFO:root:current train perplexity3.612868309020996
INFO:root:current mean train loss 3261.926803385417
INFO:root:current train perplexity3.6172378063201904
INFO:root:current mean train loss 3261.0223046875
INFO:root:current train perplexity3.6163077354431152
INFO:root:current mean train loss 3259.119051460598
INFO:root:current train perplexity3.6162633895874023
INFO:root:current mean train loss 3259.606810257523
INFO:root:current train perplexity3.617173910140991
INFO:root:current mean train loss 3262.349115423387
INFO:root:current train perplexity3.6212329864501953
INFO:root:current mean train loss 3264.6850811941963
INFO:root:current train perplexity3.6208717823028564
INFO:root:current mean train loss 3264.038596504407
INFO:root:current train perplexity3.6207637786865234

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.89s/it]
INFO:root:final mean train loss: 3261.6044008193476
INFO:root:final train perplexity: 3.6211702823638916
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.30s/it]
INFO:root:eval mean loss: 4226.34546591035
INFO:root:eval perplexity: 5.523488998413086
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it]
INFO:root:eval mean loss: 5355.328966505984
INFO:root:eval perplexity: 8.934029579162598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/173
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [21:30:28<3:15:41, 434.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3249.676590149661
INFO:root:current train perplexity3.6041359901428223
INFO:root:current mean train loss 3250.202248495133
INFO:root:current train perplexity3.601038694381714
INFO:root:current mean train loss 3249.7924054149184
INFO:root:current train perplexity3.608787775039673
INFO:root:current mean train loss 3257.4116472289084
INFO:root:current train perplexity3.6098923683166504
INFO:root:current mean train loss 3258.209488325731
INFO:root:current train perplexity3.6121935844421387
INFO:root:current mean train loss 3260.369305618836
INFO:root:current train perplexity3.613673448562622
INFO:root:current mean train loss 3259.762794684526
INFO:root:current train perplexity3.6157326698303223
INFO:root:current mean train loss 3261.3864502888528
INFO:root:current train perplexity3.615910291671753
INFO:root:current mean train loss 3263.4480655104226
INFO:root:current train perplexity3.6178622245788574
INFO:root:current mean train loss 3262.2603803229113
INFO:root:current train perplexity3.618271589279175

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.43s/it]
INFO:root:final mean train loss: 3259.491972338769
INFO:root:final train perplexity: 3.618154287338257
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.03s/it]
INFO:root:eval mean loss: 4226.878383338874
INFO:root:eval perplexity: 5.5246806144714355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.93s/it]
INFO:root:eval mean loss: 5354.625209510749
INFO:root:eval perplexity: 8.931458473205566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/174
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [21:37:18<3:05:17, 427.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3234.665731241415
INFO:root:current train perplexity3.5889041423797607
INFO:root:current mean train loss 3246.1332598781087
INFO:root:current train perplexity3.5984365940093994
INFO:root:current mean train loss 3252.8988670532644
INFO:root:current train perplexity3.609341621398926
INFO:root:current mean train loss 3259.7116917758954
INFO:root:current train perplexity3.6147406101226807
INFO:root:current mean train loss 3259.835436290733
INFO:root:current train perplexity3.6191532611846924
INFO:root:current mean train loss 3259.0862493886157
INFO:root:current train perplexity3.6168603897094727
INFO:root:current mean train loss 3260.0076079306486
INFO:root:current train perplexity3.617276668548584
INFO:root:current mean train loss 3260.149222700695
INFO:root:current train perplexity3.6187801361083984
INFO:root:current mean train loss 3261.0300213506594
INFO:root:current train perplexity3.6178536415100098
INFO:root:current mean train loss 3261.314067082256
INFO:root:current train perplexity3.6169795989990234

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.43s/it]
INFO:root:final mean train loss: 3258.731502348377
INFO:root:final train perplexity: 3.6170687675476074
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.17s/it]
INFO:root:eval mean loss: 4225.751754003214
INFO:root:eval perplexity: 5.522165775299072
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.71s/it]
INFO:root:eval mean loss: 5353.851230053191
INFO:root:eval perplexity: 8.928633689880371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/175
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [21:44:11<2:56:15, 423.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3235.5001282354797
INFO:root:current train perplexity3.5961928367614746
INFO:root:current mean train loss 3245.982967817604
INFO:root:current train perplexity3.598573923110962
INFO:root:current mean train loss 3247.397718142506
INFO:root:current train perplexity3.602440118789673
INFO:root:current mean train loss 3250.141007425791
INFO:root:current train perplexity3.6014645099639893
INFO:root:current mean train loss 3248.7174715642223
INFO:root:current train perplexity3.60280442237854
INFO:root:current mean train loss 3252.239195860288
INFO:root:current train perplexity3.6055803298950195
INFO:root:current mean train loss 3255.1174246551996
INFO:root:current train perplexity3.6086833477020264
INFO:root:current mean train loss 3258.0701172486115
INFO:root:current train perplexity3.612703800201416
INFO:root:current mean train loss 3259.5981200900305
INFO:root:current train perplexity3.612753391265869

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.01s/it]
INFO:root:final mean train loss: 3256.6242558879235
INFO:root:final train perplexity: 3.614062786102295
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.14s/it]
INFO:root:eval mean loss: 4226.32906520113
INFO:root:eval perplexity: 5.523453712463379
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.95s/it]
INFO:root:eval mean loss: 5354.200709566157
INFO:root:eval perplexity: 8.929908752441406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/176
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [21:51:02<2:47:47, 419.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3302.985665457589
INFO:root:current train perplexity3.628916025161743
INFO:root:current mean train loss 3259.8491325021905
INFO:root:current train perplexity3.607306957244873
INFO:root:current mean train loss 3257.8808688103863
INFO:root:current train perplexity3.6145031452178955
INFO:root:current mean train loss 3255.6749406746235
INFO:root:current train perplexity3.6128950119018555
INFO:root:current mean train loss 3257.1240000431894
INFO:root:current train perplexity3.6174979209899902
INFO:root:current mean train loss 3258.0034694934975
INFO:root:current train perplexity3.61547589302063
INFO:root:current mean train loss 3258.423620987567
INFO:root:current train perplexity3.6124494075775146
INFO:root:current mean train loss 3259.8918056461057
INFO:root:current train perplexity3.6135928630828857
INFO:root:current mean train loss 3259.5762278428015
INFO:root:current train perplexity3.6141042709350586
INFO:root:current mean train loss 3259.6298443206483
INFO:root:current train perplexity3.6133577823638916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.37s/it]
INFO:root:final mean train loss: 3256.2775490053236
INFO:root:final train perplexity: 3.61356782913208
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.18s/it]
INFO:root:eval mean loss: 4226.07530959109
INFO:root:eval perplexity: 5.522887229919434
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.58s/it]
INFO:root:eval mean loss: 5354.323264696919
INFO:root:eval perplexity: 8.930357933044434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/177
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [21:57:53<2:39:51, 417.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3211.606754557292
INFO:root:current train perplexity3.5550668239593506
INFO:root:current mean train loss 3231.297405740489
INFO:root:current train perplexity3.5908617973327637
INFO:root:current mean train loss 3239.5974722928777
INFO:root:current train perplexity3.590090274810791
INFO:root:current mean train loss 3246.0839874751982
INFO:root:current train perplexity3.6000494956970215
INFO:root:current mean train loss 3250.443701171875
INFO:root:current train perplexity3.606203556060791
INFO:root:current mean train loss 3257.191479729217
INFO:root:current train perplexity3.6092000007629395
INFO:root:current mean train loss 3255.7338331269057
INFO:root:current train perplexity3.6071245670318604
INFO:root:current mean train loss 3256.471863390516
INFO:root:current train perplexity3.6072988510131836
INFO:root:current mean train loss 3254.806128079467
INFO:root:current train perplexity3.6079280376434326
INFO:root:current mean train loss 3256.3203074304133
INFO:root:current train perplexity3.6085309982299805

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.17s/it]
INFO:root:final mean train loss: 3254.7097652189195
INFO:root:final train perplexity: 3.6113340854644775
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.03s/it]
INFO:root:eval mean loss: 4227.195805975732
INFO:root:eval perplexity: 5.525390625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it]
INFO:root:eval mean loss: 5356.060822182513
INFO:root:eval perplexity: 8.936704635620117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/178
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [22:04:47<2:32:34, 416.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3246.6414211107335
INFO:root:current train perplexity3.6230931282043457
INFO:root:current mean train loss 3227.9574361661585
INFO:root:current train perplexity3.5889217853546143
INFO:root:current mean train loss 3246.0152264924327
INFO:root:current train perplexity3.6047937870025635
INFO:root:current mean train loss 3240.8010012033187
INFO:root:current train perplexity3.6052498817443848
INFO:root:current mean train loss 3240.6512113530584
INFO:root:current train perplexity3.6034395694732666
INFO:root:current mean train loss 3245.9596883215822
INFO:root:current train perplexity3.6052708625793457
INFO:root:current mean train loss 3250.682495313127
INFO:root:current train perplexity3.6065096855163574
INFO:root:current mean train loss 3253.7263494256786
INFO:root:current train perplexity3.607316493988037
INFO:root:current mean train loss 3255.0251129632443
INFO:root:current train perplexity3.6068623065948486
INFO:root:current mean train loss 3254.88685444246
INFO:root:current train perplexity3.607314348220825

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.84s/it]
INFO:root:final mean train loss: 3251.1993451272288
INFO:root:final train perplexity: 3.6063361167907715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.99s/it]
INFO:root:eval mean loss: 4226.987446669991
INFO:root:eval perplexity: 5.5249247550964355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it]
INFO:root:eval mean loss: 5358.07002507203
INFO:root:eval perplexity: 8.944049835205078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/179
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [22:11:31<2:24:23, 412.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3257.2071966355848
INFO:root:current train perplexity3.6014621257781982
INFO:root:current mean train loss 3273.3685889790077
INFO:root:current train perplexity3.6014139652252197
INFO:root:current mean train loss 3258.9946172805057
INFO:root:current train perplexity3.598062515258789
INFO:root:current mean train loss 3256.913529963652
INFO:root:current train perplexity3.6030852794647217
INFO:root:current mean train loss 3253.3237961771315
INFO:root:current train perplexity3.6014857292175293
INFO:root:current mean train loss 3253.0562493563148
INFO:root:current train perplexity3.6024856567382812
INFO:root:current mean train loss 3252.890435026867
INFO:root:current train perplexity3.601705551147461
INFO:root:current mean train loss 3251.7476684737303
INFO:root:current train perplexity3.6002931594848633
INFO:root:current mean train loss 3253.5793498162043
INFO:root:current train perplexity3.6026041507720947
INFO:root:current mean train loss 3255.4928228949884
INFO:root:current train perplexity3.6056559085845947

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.04s/it]
INFO:root:final mean train loss: 3250.6010683736495
INFO:root:final train perplexity: 3.6054844856262207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.02s/it]
INFO:root:eval mean loss: 4226.446955687611
INFO:root:eval perplexity: 5.523718357086182
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.09s/it]
INFO:root:eval mean loss: 5356.719527440714
INFO:root:eval perplexity: 8.939112663269043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/180
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [22:18:24<2:17:29, 412.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3223.0818997896636
INFO:root:current train perplexity3.5915985107421875
INFO:root:current mean train loss 3248.885643828687
INFO:root:current train perplexity3.592388153076172
INFO:root:current mean train loss 3244.14107650693
INFO:root:current train perplexity3.600978136062622
INFO:root:current mean train loss 3250.734008428973
INFO:root:current train perplexity3.6015658378601074
INFO:root:current mean train loss 3248.641673303139
INFO:root:current train perplexity3.6009416580200195
INFO:root:current mean train loss 3248.783386117231
INFO:root:current train perplexity3.5967857837677
INFO:root:current mean train loss 3252.8391950007335
INFO:root:current train perplexity3.5988423824310303
INFO:root:current mean train loss 3251.3228074255753
INFO:root:current train perplexity3.600372076034546
INFO:root:current mean train loss 3250.175664563003
INFO:root:current train perplexity3.6021387577056885
INFO:root:current mean train loss 3251.576168494991
INFO:root:current train perplexity3.602701187133789

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.96s/it]
INFO:root:final mean train loss: 3249.592522221227
INFO:root:final train perplexity: 3.6040496826171875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.07s/it]
INFO:root:eval mean loss: 4227.4606864334
INFO:root:eval perplexity: 5.525981903076172
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.89s/it]
INFO:root:eval mean loss: 5359.484066794104
INFO:root:eval perplexity: 8.949222564697266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/181
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [22:25:15<2:10:29, 412.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3235.6351811835107
INFO:root:current train perplexity3.605053424835205
INFO:root:current mean train loss 3239.243361700149
INFO:root:current train perplexity3.61253023147583
INFO:root:current mean train loss 3243.068113257528
INFO:root:current train perplexity3.609304189682007
INFO:root:current mean train loss 3248.1446740757833
INFO:root:current train perplexity3.6077661514282227
INFO:root:current mean train loss 3245.604524958054
INFO:root:current train perplexity3.6062865257263184
INFO:root:current mean train loss 3247.6062788326954
INFO:root:current train perplexity3.6066577434539795
INFO:root:current mean train loss 3249.417640461988
INFO:root:current train perplexity3.605623722076416
INFO:root:current mean train loss 3249.515909013659
INFO:root:current train perplexity3.6043131351470947
INFO:root:current mean train loss 3250.2191391261435
INFO:root:current train perplexity3.603938341140747
INFO:root:current mean train loss 3250.6872852490596
INFO:root:current train perplexity3.6028378009796143

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.84s/it]
INFO:root:final mean train loss: 3249.050907688756
INFO:root:final train perplexity: 3.6032803058624268
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.67s/it]
INFO:root:eval mean loss: 4228.747541278812
INFO:root:eval perplexity: 5.528858661651611
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.44s/it]
INFO:root:eval mean loss: 5359.042007770944
INFO:root:eval perplexity: 8.947606086730957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/182
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [22:32:09<2:03:48, 412.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3231.0956187855113
INFO:root:current train perplexity3.5830156803131104
INFO:root:current mean train loss 3246.065420236895
INFO:root:current train perplexity3.601358652114868
INFO:root:current mean train loss 3239.2074774050243
INFO:root:current train perplexity3.588486671447754
INFO:root:current mean train loss 3247.0582492022445
INFO:root:current train perplexity3.5960230827331543
INFO:root:current mean train loss 3245.7307418655564
INFO:root:current train perplexity3.594187021255493
INFO:root:current mean train loss 3249.455791631475
INFO:root:current train perplexity3.596508502960205
INFO:root:current mean train loss 3248.68567807729
INFO:root:current train perplexity3.5962915420532227
INFO:root:current mean train loss 3249.608509998448
INFO:root:current train perplexity3.5981130599975586
INFO:root:current mean train loss 3248.08068833379
INFO:root:current train perplexity3.5977394580841064
INFO:root:current mean train loss 3248.459835927274
INFO:root:current train perplexity3.598602056503296

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.66s/it]
INFO:root:final mean train loss: 3245.3700631049373
INFO:root:final train perplexity: 3.5980513095855713
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.13s/it]
INFO:root:eval mean loss: 4229.904882119902
INFO:root:eval perplexity: 5.53144645690918
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.62s/it]
INFO:root:eval mean loss: 5364.294468223626
INFO:root:eval perplexity: 8.966842651367188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/183
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [22:39:03<1:57:04, 413.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3225.0304361979165
INFO:root:current train perplexity3.6162357330322266
INFO:root:current mean train loss 3236.148804459835
INFO:root:current train perplexity3.6024980545043945
INFO:root:current mean train loss 3231.30549882664
INFO:root:current train perplexity3.5923147201538086
INFO:root:current mean train loss 3236.2855127087637
INFO:root:current train perplexity3.5944511890411377
INFO:root:current mean train loss 3241.0642327129453
INFO:root:current train perplexity3.591538906097412
INFO:root:current mean train loss 3240.626211162994
INFO:root:current train perplexity3.594236373901367
INFO:root:current mean train loss 3242.843072077088
INFO:root:current train perplexity3.59385347366333
INFO:root:current mean train loss 3243.9086648483576
INFO:root:current train perplexity3.5931341648101807
INFO:root:current mean train loss 3245.6321343944633
INFO:root:current train perplexity3.5948989391326904
INFO:root:current mean train loss 3248.3785122785243
INFO:root:current train perplexity3.5975239276885986

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.45s/it]
INFO:root:final mean train loss: 3245.6081202107093
INFO:root:final train perplexity: 3.598388910293579
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.73s/it]
INFO:root:eval mean loss: 4229.644811751995
INFO:root:eval perplexity: 5.530864238739014
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.60s/it]
INFO:root:eval mean loss: 5362.544327972629
INFO:root:eval perplexity: 8.960429191589355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/184
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [22:45:56<1:50:10, 413.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3227.8019675671217
INFO:root:current train perplexity3.5695486068725586
INFO:root:current mean train loss 3235.6005045572915
INFO:root:current train perplexity3.5895426273345947
INFO:root:current mean train loss 3251.477985002018
INFO:root:current train perplexity3.596564531326294
INFO:root:current mean train loss 3249.2287354173686
INFO:root:current train perplexity3.5987660884857178
INFO:root:current mean train loss 3246.997425379014
INFO:root:current train perplexity3.5974204540252686
INFO:root:current mean train loss 3243.13381813704
INFO:root:current train perplexity3.593391180038452
INFO:root:current mean train loss 3246.452272508965
INFO:root:current train perplexity3.593761682510376
INFO:root:current mean train loss 3246.690807456327
INFO:root:current train perplexity3.5934040546417236
INFO:root:current mean train loss 3246.6413669520484
INFO:root:current train perplexity3.5949854850769043
INFO:root:current mean train loss 3246.8992903578783
INFO:root:current train perplexity3.597513437271118

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.47s/it]
INFO:root:final mean train loss: 3245.1100663215884
INFO:root:final train perplexity: 3.597681999206543
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.94s/it]
INFO:root:eval mean loss: 4231.677585466534
INFO:root:eval perplexity: 5.535412311553955
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.12s/it]
INFO:root:eval mean loss: 5364.024001966977
INFO:root:eval perplexity: 8.965850830078125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/185
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [22:52:47<1:43:05, 412.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3235.3170984968356
INFO:root:current train perplexity3.600627899169922
INFO:root:current mean train loss 3247.876977675454
INFO:root:current train perplexity3.6005609035491943
INFO:root:current mean train loss 3249.9891799325155
INFO:root:current train perplexity3.600303888320923
INFO:root:current mean train loss 3253.54946714215
INFO:root:current train perplexity3.6005094051361084
INFO:root:current mean train loss 3252.0886556669166
INFO:root:current train perplexity3.5939998626708984
INFO:root:current mean train loss 3251.337573537349
INFO:root:current train perplexity3.5948543548583984
INFO:root:current mean train loss 3251.00470411163
INFO:root:current train perplexity3.5982515811920166
INFO:root:current mean train loss 3247.9944139120666
INFO:root:current train perplexity3.5962040424346924
INFO:root:current mean train loss 3246.1657745396046
INFO:root:current train perplexity3.596090793609619
INFO:root:current mean train loss 3245.048074007278
INFO:root:current train perplexity3.5944018363952637

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.99s/it]
INFO:root:final mean train loss: 3243.2935470458
INFO:root:final train perplexity: 3.595104694366455
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.31s/it]
INFO:root:eval mean loss: 4231.14394254211
INFO:root:eval perplexity: 5.534217834472656
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.11s/it]
INFO:root:eval mean loss: 5365.672422152039
INFO:root:eval perplexity: 8.971898078918457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/186
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [22:59:39<1:36:13, 412.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3257.9875235721984
INFO:root:current train perplexity3.5917696952819824
INFO:root:current mean train loss 3249.2721658798464
INFO:root:current train perplexity3.588481903076172
INFO:root:current mean train loss 3243.339972200294
INFO:root:current train perplexity3.5858161449432373
INFO:root:current mean train loss 3249.0438733951064
INFO:root:current train perplexity3.589306354522705
INFO:root:current mean train loss 3241.9494303051206
INFO:root:current train perplexity3.5921623706817627
INFO:root:current mean train loss 3246.036521274755
INFO:root:current train perplexity3.593921184539795
INFO:root:current mean train loss 3244.8215314262648
INFO:root:current train perplexity3.5932040214538574
INFO:root:current mean train loss 3245.469442403907
INFO:root:current train perplexity3.5937461853027344
INFO:root:current mean train loss 3245.2539376277127
INFO:root:current train perplexity3.594651937484741
INFO:root:current mean train loss 3244.955491457304
INFO:root:current train perplexity3.5935373306274414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.74s/it]
INFO:root:final mean train loss: 3242.311657198014
INFO:root:final train perplexity: 3.593712091445923
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.42s/it]
INFO:root:eval mean loss: 4229.394018727837
INFO:root:eval perplexity: 5.530303955078125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.64s/it]
INFO:root:eval mean loss: 5363.5694727255095
INFO:root:eval perplexity: 8.96418571472168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/187
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [23:06:30<1:29:15, 411.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3242.334724506579
INFO:root:current train perplexity3.5880961418151855
INFO:root:current mean train loss 3242.568951572516
INFO:root:current train perplexity3.579606294631958
INFO:root:current mean train loss 3247.9844569319384
INFO:root:current train perplexity3.589712619781494
INFO:root:current mean train loss 3249.1484220480615
INFO:root:current train perplexity3.598684549331665
INFO:root:current mean train loss 3249.2412227746213
INFO:root:current train perplexity3.5957260131835938
INFO:root:current mean train loss 3248.111778246455
INFO:root:current train perplexity3.5945146083831787
INFO:root:current mean train loss 3247.088995405238
INFO:root:current train perplexity3.594161033630371
INFO:root:current mean train loss 3247.4514556308964
INFO:root:current train perplexity3.593449831008911
INFO:root:current mean train loss 3244.4033846892457
INFO:root:current train perplexity3.593576192855835

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.36s/it]
INFO:root:final mean train loss: 3242.1207104959794
INFO:root:final train perplexity: 3.5934417247772217
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.04s/it]
INFO:root:eval mean loss: 4231.570077016844
INFO:root:eval perplexity: 5.535173416137695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.87s/it]
INFO:root:eval mean loss: 5366.381984845966
INFO:root:eval perplexity: 8.974501609802246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/188
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [23:13:22<1:22:21, 411.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3195.3150227864585
INFO:root:current train perplexity3.547133684158325
INFO:root:current mean train loss 3228.1979577518205
INFO:root:current train perplexity3.581815242767334
INFO:root:current mean train loss 3237.997488839286
INFO:root:current train perplexity3.583808660507202
INFO:root:current mean train loss 3232.1282036406765
INFO:root:current train perplexity3.583317756652832
INFO:root:current mean train loss 3235.3646255379576
INFO:root:current train perplexity3.581434726715088
INFO:root:current mean train loss 3240.818458875652
INFO:root:current train perplexity3.5897648334503174
INFO:root:current mean train loss 3244.0619198117483
INFO:root:current train perplexity3.591378927230835
INFO:root:current mean train loss 3243.5535706347796
INFO:root:current train perplexity3.5887348651885986
INFO:root:current mean train loss 3244.209364115524
INFO:root:current train perplexity3.5889804363250732
INFO:root:current mean train loss 3242.0212661895243
INFO:root:current train perplexity3.5899319648742676

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.18s/it]
INFO:root:final mean train loss: 3240.0609612618723
INFO:root:final train perplexity: 3.5905227661132812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.17s/it]
INFO:root:eval mean loss: 4231.461103723404
INFO:root:eval perplexity: 5.534928321838379
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.72s/it]
INFO:root:eval mean loss: 5366.962833485705
INFO:root:eval perplexity: 8.976633071899414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/189
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [23:20:11<1:15:21, 411.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3140.9726118607955
INFO:root:current train perplexity3.511430501937866
INFO:root:current mean train loss 3225.677914731137
INFO:root:current train perplexity3.5649380683898926
INFO:root:current mean train loss 3234.4713325681278
INFO:root:current train perplexity3.5756804943084717
INFO:root:current mean train loss 3230.7816487891882
INFO:root:current train perplexity3.575320243835449
INFO:root:current mean train loss 3232.6231448876597
INFO:root:current train perplexity3.5802459716796875
INFO:root:current mean train loss 3231.323609115093
INFO:root:current train perplexity3.5785105228424072
INFO:root:current mean train loss 3233.0178945887887
INFO:root:current train perplexity3.579988718032837
INFO:root:current mean train loss 3237.3907987484617
INFO:root:current train perplexity3.5810928344726562
INFO:root:current mean train loss 3239.579651255202
INFO:root:current train perplexity3.5853793621063232
INFO:root:current mean train loss 3240.1400147824334
INFO:root:current train perplexity3.588552474975586

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.41s/it]
INFO:root:final mean train loss: 3238.461190315985
INFO:root:final train perplexity: 3.588257312774658
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.08s/it]
INFO:root:eval mean loss: 4231.775653812057
INFO:root:eval perplexity: 5.535632610321045
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.97s/it]
INFO:root:eval mean loss: 5366.067311821254
INFO:root:eval perplexity: 8.973346710205078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/190
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [23:27:03<1:08:35, 411.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3235.7789756373354
INFO:root:current train perplexity3.582249879837036
INFO:root:current mean train loss 3253.780138031775
INFO:root:current train perplexity3.5984652042388916
INFO:root:current mean train loss 3241.718445660317
INFO:root:current train perplexity3.592824935913086
INFO:root:current mean train loss 3240.740297132151
INFO:root:current train perplexity3.5867581367492676
INFO:root:current mean train loss 3243.3425456117616
INFO:root:current train perplexity3.5892832279205322
INFO:root:current mean train loss 3246.029214083574
INFO:root:current train perplexity3.587635040283203
INFO:root:current mean train loss 3242.5378268092436
INFO:root:current train perplexity3.58506178855896
INFO:root:current mean train loss 3241.860360051395
INFO:root:current train perplexity3.5844485759735107
INFO:root:current mean train loss 3242.120604574462
INFO:root:current train perplexity3.5870206356048584
INFO:root:current mean train loss 3239.783737365258
INFO:root:current train perplexity3.5851104259490967

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.95s/it]
INFO:root:final mean train loss: 3238.9356229843634
INFO:root:final train perplexity: 3.5889289379119873
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.69s/it]
INFO:root:eval mean loss: 4232.046059466423
INFO:root:eval perplexity: 5.536237716674805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.37s/it]
INFO:root:eval mean loss: 5365.205467711104
INFO:root:eval perplexity: 8.970185279846191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/191
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [23:33:54<1:01:39, 411.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3250.056902850116
INFO:root:current train perplexity3.558217763900757
INFO:root:current mean train loss 3243.2061162032483
INFO:root:current train perplexity3.5790512561798096
INFO:root:current mean train loss 3238.329756547701
INFO:root:current train perplexity3.5703511238098145
INFO:root:current mean train loss 3235.2686509998566
INFO:root:current train perplexity3.5765488147735596
INFO:root:current mean train loss 3235.0983069104946
INFO:root:current train perplexity3.5794124603271484
INFO:root:current mean train loss 3234.5919719891485
INFO:root:current train perplexity3.578963279724121
INFO:root:current mean train loss 3235.626980770908
INFO:root:current train perplexity3.580552816390991
INFO:root:current mean train loss 3236.8334541163385
INFO:root:current train perplexity3.5820987224578857
INFO:root:current mean train loss 3238.3545804559967
INFO:root:current train perplexity3.585141658782959
INFO:root:current mean train loss 3236.8353022603155
INFO:root:current train perplexity3.5835423469543457

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.43s/it]
INFO:root:final mean train loss: 3236.959897933468
INFO:root:final train perplexity: 3.586132526397705
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it]
INFO:root:eval mean loss: 4232.498214829898
INFO:root:eval perplexity: 5.53725004196167
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.09s/it]
INFO:root:eval mean loss: 5366.905017176418
INFO:root:eval perplexity: 8.976421356201172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/192
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [23:40:40<54:36, 409.56s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3227.7126395089285
INFO:root:current train perplexity3.569456100463867
INFO:root:current mean train loss 3234.4066786024305
INFO:root:current train perplexity3.5768980979919434
INFO:root:current mean train loss 3240.362511427859
INFO:root:current train perplexity3.5844533443450928
INFO:root:current mean train loss 3239.1213750583024
INFO:root:current train perplexity3.5824873447418213
INFO:root:current mean train loss 3238.23642970995
INFO:root:current train perplexity3.581955671310425
INFO:root:current mean train loss 3238.2795866493866
INFO:root:current train perplexity3.5787503719329834
INFO:root:current mean train loss 3240.8953878567913
INFO:root:current train perplexity3.581726551055908
INFO:root:current mean train loss 3241.8567455888606
INFO:root:current train perplexity3.58495831489563
INFO:root:current mean train loss 3242.055161162051
INFO:root:current train perplexity3.586449384689331
INFO:root:current mean train loss 3238.5735568286264
INFO:root:current train perplexity3.5853989124298096

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.27s/it]
INFO:root:final mean train loss: 3237.6424065251504
INFO:root:final train perplexity: 3.5870978832244873
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it]
INFO:root:eval mean loss: 4232.2244500775705
INFO:root:eval perplexity: 5.536636829376221
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.40s/it]
INFO:root:eval mean loss: 5367.468891982491
INFO:root:eval perplexity: 8.978490829467773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/193
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [23:47:33<47:54, 410.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3256.4307378724566
INFO:root:current train perplexity3.572885751724243
INFO:root:current mean train loss 3225.266584489729
INFO:root:current train perplexity3.5642929077148438
INFO:root:current mean train loss 3230.698047276878
INFO:root:current train perplexity3.5802886486053467
INFO:root:current mean train loss 3234.095493149827
INFO:root:current train perplexity3.5833356380462646
INFO:root:current mean train loss 3240.130446595478
INFO:root:current train perplexity3.587073564529419
INFO:root:current mean train loss 3238.598461959024
INFO:root:current train perplexity3.583768367767334
INFO:root:current mean train loss 3237.484550416748
INFO:root:current train perplexity3.585261344909668
INFO:root:current mean train loss 3236.6439670650025
INFO:root:current train perplexity3.5823140144348145
INFO:root:current mean train loss 3236.689450808126
INFO:root:current train perplexity3.5823349952697754
INFO:root:current mean train loss 3238.7317808440484
INFO:root:current train perplexity3.5853965282440186

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.99s/it]
INFO:root:final mean train loss: 3236.3950006423456
INFO:root:final train perplexity: 3.5853335857391357
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.62s/it]
INFO:root:eval mean loss: 4232.574386704898
INFO:root:eval perplexity: 5.537421226501465
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.79s/it]
INFO:root:eval mean loss: 5367.725163453014
INFO:root:eval perplexity: 8.97943115234375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/194
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [23:54:27<41:10, 411.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3246.0003781786154
INFO:root:current train perplexity3.604844570159912
INFO:root:current mean train loss 3233.8933719862375
INFO:root:current train perplexity3.579648017883301
INFO:root:current mean train loss 3233.817933344746
INFO:root:current train perplexity3.5818750858306885
INFO:root:current mean train loss 3237.41096309651
INFO:root:current train perplexity3.584083318710327
INFO:root:current mean train loss 3237.113704030107
INFO:root:current train perplexity3.582902193069458
INFO:root:current mean train loss 3238.033599244272
INFO:root:current train perplexity3.583376169204712
INFO:root:current mean train loss 3239.0322599396363
INFO:root:current train perplexity3.584271192550659
INFO:root:current mean train loss 3240.1158364368343
INFO:root:current train perplexity3.5829575061798096
INFO:root:current mean train loss 3238.186258641029
INFO:root:current train perplexity3.5817904472351074
INFO:root:current mean train loss 3238.27904041182
INFO:root:current train perplexity3.5833587646484375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.65s/it]
INFO:root:final mean train loss: 3235.651223890243
INFO:root:final train perplexity: 3.5842814445495605
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.96s/it]
INFO:root:eval mean loss: 4232.262059854277
INFO:root:eval perplexity: 5.536721706390381
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 5367.6070409463655
INFO:root:eval perplexity: 8.978998184204102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/195
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [24:01:13<34:10, 410.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3220.534870729608
INFO:root:current train perplexity3.5530881881713867
INFO:root:current mean train loss 3233.637334475727
INFO:root:current train perplexity3.571687936782837
INFO:root:current mean train loss 3237.4295847535595
INFO:root:current train perplexity3.5765280723571777
INFO:root:current mean train loss 3243.208090779509
INFO:root:current train perplexity3.5788044929504395
INFO:root:current mean train loss 3244.487153628813
INFO:root:current train perplexity3.5889830589294434
INFO:root:current mean train loss 3245.004991998826
INFO:root:current train perplexity3.5866358280181885
INFO:root:current mean train loss 3240.9803335279544
INFO:root:current train perplexity3.584993839263916
INFO:root:current mean train loss 3240.7071920804515
INFO:root:current train perplexity3.586656332015991
INFO:root:current mean train loss 3240.437740730046
INFO:root:current train perplexity3.585977792739868
INFO:root:current mean train loss 3238.2846763698353
INFO:root:current train perplexity3.5839436054229736

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.08s/it]
INFO:root:final mean train loss: 3235.366333561559
INFO:root:final train perplexity: 3.583878517150879
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.12s/it]
INFO:root:eval mean loss: 4232.759097268396
INFO:root:eval perplexity: 5.5378336906433105
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.16s/it]
INFO:root:eval mean loss: 5368.0014786957
INFO:root:eval perplexity: 8.980445861816406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/196
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [24:08:05<27:21, 410.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3222.372904763293
INFO:root:current train perplexity3.563467502593994
INFO:root:current mean train loss 3234.262873666729
INFO:root:current train perplexity3.585557699203491
INFO:root:current mean train loss 3239.954308213366
INFO:root:current train perplexity3.5939865112304688
INFO:root:current mean train loss 3240.8035925259705
INFO:root:current train perplexity3.5929293632507324
INFO:root:current mean train loss 3239.4498366819457
INFO:root:current train perplexity3.59039044380188
INFO:root:current mean train loss 3237.511214537175
INFO:root:current train perplexity3.584319591522217
INFO:root:current mean train loss 3239.265090233204
INFO:root:current train perplexity3.583681344985962
INFO:root:current mean train loss 3235.7845266409304
INFO:root:current train perplexity3.5816051959991455
INFO:root:current mean train loss 3237.2365517093785
INFO:root:current train perplexity3.5827550888061523
INFO:root:current mean train loss 3236.5079856959346
INFO:root:current train perplexity3.582453966140747

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.54s/it]
INFO:root:final mean train loss: 3234.219436030234
INFO:root:final train perplexity: 3.5822577476501465
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.60s/it]
INFO:root:eval mean loss: 4232.385752576462
INFO:root:eval perplexity: 5.536998271942139
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it]
INFO:root:eval mean loss: 5367.151176723182
INFO:root:eval perplexity: 8.977324485778809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/197
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [24:14:59<20:35, 411.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3248.857877604167
INFO:root:current train perplexity3.5968759059906006
INFO:root:current mean train loss 3237.324454520089
INFO:root:current train perplexity3.5917277336120605
INFO:root:current mean train loss 3244.871446200284
INFO:root:current train perplexity3.594576597213745
INFO:root:current mean train loss 3243.73841015625
INFO:root:current train perplexity3.59165358543396
INFO:root:current mean train loss 3236.7577960526314
INFO:root:current train perplexity3.5874085426330566
INFO:root:current mean train loss 3234.377839673913
INFO:root:current train perplexity3.585688352584839
INFO:root:current mean train loss 3236.280337818287
INFO:root:current train perplexity3.584946870803833
INFO:root:current mean train loss 3238.6344405241935
INFO:root:current train perplexity3.585252523422241
INFO:root:current mean train loss 3237.756017857143
INFO:root:current train perplexity3.5835487842559814
INFO:root:current mean train loss 3236.517102363782
INFO:root:current train perplexity3.581653356552124

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.77s/it]
INFO:root:final mean train loss: 3234.130568350515
INFO:root:final train perplexity: 3.5821316242218018
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.98s/it]
INFO:root:eval mean loss: 4232.663266012854
INFO:root:eval perplexity: 5.537619113922119
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.28s/it]
INFO:root:eval mean loss: 5367.584405127992
INFO:root:eval perplexity: 8.978913307189941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/198
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [24:21:49<13:41, 410.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3236.453275014119
INFO:root:current train perplexity3.57865309715271
INFO:root:current mean train loss 3243.383515571636
INFO:root:current train perplexity3.5867114067077637
INFO:root:current mean train loss 3238.583981786937
INFO:root:current train perplexity3.578089952468872
INFO:root:current mean train loss 3237.0427348084613
INFO:root:current train perplexity3.5754544734954834
INFO:root:current mean train loss 3235.142509886937
INFO:root:current train perplexity3.5762171745300293
INFO:root:current mean train loss 3237.6535171325577
INFO:root:current train perplexity3.5797154903411865
INFO:root:current mean train loss 3234.1343255999495
INFO:root:current train perplexity3.577986478805542
INFO:root:current mean train loss 3237.4904738386017
INFO:root:current train perplexity3.582689046859741
INFO:root:current mean train loss 3236.5521606583557
INFO:root:current train perplexity3.5831198692321777
INFO:root:current mean train loss 3237.5618587272697
INFO:root:current train perplexity3.582968235015869

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.78s/it]
INFO:root:final mean train loss: 3234.4225437410414
INFO:root:final train perplexity: 3.5825445652008057
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.61s/it]
INFO:root:eval mean loss: 4233.021706006206
INFO:root:eval perplexity: 5.538422584533691
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 5368.060520902593
INFO:root:eval perplexity: 8.98066234588623
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/199
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [24:28:38<06:50, 410.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3240.3383279318336
INFO:root:current train perplexity3.5837059020996094
INFO:root:current mean train loss 3240.247864089087
INFO:root:current train perplexity3.586259126663208
INFO:root:current mean train loss 3232.6115588420853
INFO:root:current train perplexity3.5881526470184326
INFO:root:current mean train loss 3231.991122897019
INFO:root:current train perplexity3.584472179412842
INFO:root:current mean train loss 3234.0898815395876
INFO:root:current train perplexity3.578908681869507
INFO:root:current mean train loss 3233.8852696039553
INFO:root:current train perplexity3.5794804096221924
INFO:root:current mean train loss 3235.9297394372966
INFO:root:current train perplexity3.5812013149261475
INFO:root:current mean train loss 3233.9770924487398
INFO:root:current train perplexity3.5787670612335205
INFO:root:current mean train loss 3234.975820487865
INFO:root:current train perplexity3.580214500427246
INFO:root:current mean train loss 3235.353527203819
INFO:root:current train perplexity3.5802977085113525

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.57s/it]
INFO:root:final mean train loss: 3232.78772212613
INFO:root:final train perplexity: 3.5802340507507324
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.85s/it]
INFO:root:eval mean loss: 4232.857797609154
INFO:root:eval perplexity: 5.538055419921875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.90s/it]
INFO:root:eval mean loss: 5367.711486383533
INFO:root:eval perplexity: 8.979381561279297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_minilm_corrected_from_scratch/200
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [24:35:27<00:00, 410.11s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [24:35:27<00:00, 442.64s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.05s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.05s/it]
INFO:root:eval mean loss: 4232.857797609154
INFO:root:eval perplexity: 5.538055419921875
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.55s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.55s/it]
INFO:root:eval mean loss: 5367.711486383533
INFO:root:eval perplexity: 8.979381561279297
INFO:root:evalaution complete
INFO:root:save model final: small_multiqa_minilm_corrected_from_scratch/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x1552e1453f06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x1552e144b8e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x1552e1370e09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x1552e1454a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x1552e136e948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x1552e1454a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x1552e1329b46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x1552e0d8e46a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x1553dd5aaa27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x1553dd5aabe0]
python(+0x24a989) [0x55a5a5b1e989]
python(+0x24a9bd) [0x55a5a5b1e9bd]
python(+0x24aa14) [0x55a5a5b1ea14]
python(+0x108f75) [0x55a5a59dcf75]
python(Py_RunMain+0x313) [0x55a5a5b21983]
python(Py_BytesMain+0x39) [0x55a5a5b21bc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x1553dd5880b3]
python(+0x1d6e13) [0x55a5a5aaae13]
/opt/slurm/data/slurmd/job26224330/slurm_script: line 165: 2980284 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --from_scratch --model_path nreimers/MiniLM-L6-H384-uncased --data_config data_config.json --data_folder fast_processed_data_opt_multiqa_corrected  --output small_multiqa_minilm_corrected_from_scratch --batch_size 128 --epochs 200 --save_head  --save_epochs 1 --external_embedding --test_eval
"
