INFO:root:Output: small_window_4
INFO:root:Steps per epochs:248
INFO:root:Total steps:49600
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.key.bias', 'cls.predictions.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.query.weight', 'cls.predictions.decoder.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.key.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'cls.predictions.transform.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/200 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
INFO:root:current mean train loss 97828.84493371213
INFO:root:current train perplexity15172.244140625
INFO:root:current mean train loss 81424.73553313442
INFO:root:current train perplexity3045.276611328125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.95s/it]
INFO:root:final mean train loss: 75053.70844884073
INFO:root:final train perplexity: 1640.4324951171875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.73s/it]
INFO:root:eval mean loss: 44166.198521205355
INFO:root:eval perplexity: 96.64176940917969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/1

  0%|          | 1/200 [05:36<18:35:47, 336.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 42875.55629595588
INFO:root:current train perplexity69.33321380615234
INFO:root:current mean train loss 39107.07644350165
INFO:root:current train perplexity47.22951889038086


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.09s/it]
INFO:root:final mean train loss: 36518.48869077621
INFO:root:final train perplexity: 36.667823791503906
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.49s/it]
INFO:root:eval mean loss: 31773.497907366072
INFO:root:eval perplexity: 26.80048370361328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/2

  1%|          | 2/200 [11:01<18:07:26, 329.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 31215.710286458332
INFO:root:current train perplexity22.06365966796875
INFO:root:current mean train loss 29706.19743628641
INFO:root:current train perplexity18.681814193725586
INFO:root:current mean train loss 28795.49641125308
INFO:root:current train perplexity17.078556060791016


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.36s/it]
INFO:root:final mean train loss: 28413.517869518648
INFO:root:final train perplexity: 16.485620498657227
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.43s/it]
INFO:root:eval mean loss: 28537.073195684523
INFO:root:eval perplexity: 19.172256469726562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/3

  2%|â–         | 3/200 [16:29<17:59:42, 328.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 26387.55284090909
INFO:root:current train perplexity13.425159454345703
INFO:root:current mean train loss 25907.748525705647
INFO:root:current train perplexity12.844648361206055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.61s/it]
INFO:root:final mean train loss: 25532.55806609123
INFO:root:final train perplexity: 12.40789794921875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.42s/it]
INFO:root:eval mean loss: 27118.14327566964
INFO:root:eval perplexity: 16.553720474243164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/4

  2%|â–         | 4/200 [21:45<17:38:20, 323.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24891.88839285714
INFO:root:current train perplexity11.330855369567871
INFO:root:current mean train loss 24373.243611273363
INFO:root:current train perplexity11.012801170349121
INFO:root:current mean train loss 24091.940858997583
INFO:root:current train perplexity10.756143569946289


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.73s/it]
INFO:root:final mean train loss: 23980.71710401966
INFO:root:final train perplexity: 10.646932601928711
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.22s/it]
INFO:root:eval mean loss: 26303.41345796131
INFO:root:eval perplexity: 15.215118408203125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/5

  2%|â–Ž         | 5/200 [27:09<17:33:17, 324.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 23355.75258209746
INFO:root:current train perplexity10.004049301147461
INFO:root:current mean train loss 23112.752948113208
INFO:root:current train perplexity9.758366584777832


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.26s/it]
INFO:root:final mean train loss: 22963.70736202117
INFO:root:final train perplexity: 9.630756378173828
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.46s/it]
INFO:root:eval mean loss: 25736.269577752977
INFO:root:eval perplexity: 14.347744941711426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/6

  3%|â–Ž         | 6/200 [32:55<17:51:58, 331.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 22358.014026988636
INFO:root:current train perplexity9.125543594360352
INFO:root:current mean train loss 22385.310423704956
INFO:root:current train perplexity9.08871841430664
INFO:root:current mean train loss 22266.54082123815
INFO:root:current train perplexity8.97988224029541


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.35s/it]
INFO:root:final mean train loss: 22218.94054782006
INFO:root:final train perplexity: 8.948657989501953
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.30s/it]
INFO:root:eval mean loss: 25306.593424479168
INFO:root:eval perplexity: 13.723689079284668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/7

  4%|â–Ž         | 7/200 [38:35<17:54:24, 334.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 21860.01785714286
INFO:root:current train perplexity8.623795509338379
INFO:root:current mean train loss 21766.3724477569
INFO:root:current train perplexity8.529104232788086


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.23s/it]
INFO:root:final mean train loss: 21646.62674048639
INFO:root:final train perplexity: 8.457511901855469
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.68s/it]
INFO:root:eval mean loss: 24995.57645089286
INFO:root:eval perplexity: 13.288972854614258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/8

  4%|â–         | 8/200 [44:12<17:52:27, 335.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 21405.951302083333
INFO:root:current train perplexity8.182987213134766
INFO:root:current mean train loss 21334.895295516304
INFO:root:current train perplexity8.169892311096191
INFO:root:current mean train loss 21219.84937318314
INFO:root:current train perplexity8.096092224121094


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.45s/it]
INFO:root:final mean train loss: 21184.413841985886
INFO:root:final train perplexity: 8.080599784851074
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.96s/it]
INFO:root:eval mean loss: 24708.355398995536
INFO:root:eval perplexity: 12.899751663208008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/9

  4%|â–         | 9/200 [49:51<17:50:51, 336.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20944.721373600747
INFO:root:current train perplexity7.852828025817871
INFO:root:current mean train loss 20886.051038547903
INFO:root:current train perplexity7.824850559234619


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.57s/it]
INFO:root:final mean train loss: 20791.505989320816
INFO:root:final train perplexity: 7.773440361022949
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.61s/it]
INFO:root:eval mean loss: 24493.632789248513
INFO:root:eval perplexity: 12.61624813079834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/10

  5%|â–Œ         | 10/200 [55:29<17:46:36, 336.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20773.849300986843
INFO:root:current train perplexity7.627547740936279
INFO:root:current mean train loss 20587.669872636554
INFO:root:current train perplexity7.571512699127197
INFO:root:current mean train loss 20497.907980165524
INFO:root:current train perplexity7.539593696594238


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.25s/it]
INFO:root:final mean train loss: 20472.231236611642
INFO:root:final train perplexity: 7.532460689544678
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.15s/it]
INFO:root:eval mean loss: 24273.951357886905
INFO:root:eval perplexity: 12.332637786865234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/11

  6%|â–Œ         | 11/200 [1:01:05<17:40:07, 336.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20288.456893705985
INFO:root:current train perplexity7.349428653717041
INFO:root:current mean train loss 20223.198350694445
INFO:root:current train perplexity7.33539342880249


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.23s/it]
INFO:root:final mean train loss: 20175.05217127646
INFO:root:final train perplexity: 7.314878940582275
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.31s/it]
INFO:root:eval mean loss: 24113.839680989582
INFO:root:eval perplexity: 12.129962921142578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/12

  6%|â–Œ         | 12/200 [1:06:38<17:31:26, 335.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20050.550441576088
INFO:root:current train perplexity7.19633674621582
INFO:root:current mean train loss 19949.796192200203
INFO:root:current train perplexity7.159098148345947
INFO:root:current mean train loss 19926.215956067826
INFO:root:current train perplexity7.134264945983887


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.87s/it]
INFO:root:final mean train loss: 19921.43252268145
INFO:root:final train perplexity: 7.134166717529297
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.61s/it]
INFO:root:eval mean loss: 23950.121907552082
INFO:root:eval perplexity: 11.926161766052246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/13

  6%|â–‹         | 13/200 [1:12:09<17:20:53, 333.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19802.19390625
INFO:root:current train perplexity7.006369590759277
INFO:root:current mean train loss 19732.44814732143
INFO:root:current train perplexity6.992905139923096


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.88s/it]
INFO:root:final mean train loss: 19694.834303332915
INFO:root:final train perplexity: 6.976487159729004
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.17s/it]
INFO:root:eval mean loss: 23821.163969494046
INFO:root:eval perplexity: 11.768045425415039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/14

  7%|â–‹         | 14/200 [1:17:33<17:06:24, 331.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19500.943214699073
INFO:root:current train perplexity6.872113227844238
INFO:root:current mean train loss 19464.38768762303
INFO:root:current train perplexity6.848641872406006
INFO:root:current mean train loss 19504.30201163271
INFO:root:current train perplexity6.839131832122803


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.17s/it]
INFO:root:final mean train loss: 19483.997074250252
INFO:root:final train perplexity: 6.832906246185303
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.42s/it]
INFO:root:eval mean loss: 23714.25806826637
INFO:root:eval perplexity: 11.63856029510498
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/15

  8%|â–Š         | 15/200 [1:23:08<17:04:39, 332.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19308.915150316454
INFO:root:current train perplexity6.723505020141602
INFO:root:current mean train loss 19316.664204347067
INFO:root:current train perplexity6.718636989593506


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.18s/it]
INFO:root:final mean train loss: 19303.789027060233
INFO:root:final train perplexity: 6.712530136108398
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.41s/it]
INFO:root:eval mean loss: 23596.176432291668
INFO:root:eval perplexity: 11.497190475463867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/16

  8%|â–Š         | 16/200 [1:28:44<17:02:00, 333.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19100.587260584678
INFO:root:current train perplexity6.642335414886475
INFO:root:current mean train loss 19139.479738191792
INFO:root:current train perplexity6.601462364196777
INFO:root:current mean train loss 19135.100175865802
INFO:root:current train perplexity6.597598075866699


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.51s/it]
INFO:root:final mean train loss: 19131.554033833167
INFO:root:final train perplexity: 6.599460601806641
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.33s/it]
INFO:root:eval mean loss: 23490.839378720237
INFO:root:eval perplexity: 11.372529029846191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/17

  8%|â–Š         | 17/200 [1:34:11<16:51:00, 331.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18973.837043486445
INFO:root:current train perplexity6.49513578414917
INFO:root:current mean train loss 18990.580462346312
INFO:root:current train perplexity6.491591453552246


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.39s/it]
INFO:root:final mean train loss: 18974.58646909652
INFO:root:final train perplexity: 6.498072624206543
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.60s/it]
INFO:root:eval mean loss: 23422.89453125
INFO:root:eval perplexity: 11.29283618927002
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/18

  9%|â–‰         | 18/200 [1:39:44<16:46:40, 331.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18907.175
INFO:root:current train perplexity6.445107460021973
INFO:root:current mean train loss 18901.029730902777
INFO:root:current train perplexity6.433471202850342
INFO:root:current mean train loss 18831.166663896278
INFO:root:current train perplexity6.402698993682861


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.82s/it]
INFO:root:final mean train loss: 18830.194828156502
INFO:root:final train perplexity: 6.406187057495117
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.34s/it]
INFO:root:eval mean loss: 23341.586774553572
INFO:root:eval perplexity: 11.198208808898926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/19

 10%|â–‰         | 19/200 [1:45:30<16:54:33, 336.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18683.514390265806
INFO:root:current train perplexity6.2993364334106445
INFO:root:current mean train loss 18718.15193641377
INFO:root:current train perplexity6.316237449645996


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.32s/it]
INFO:root:final mean train loss: 18689.230551442794
INFO:root:final train perplexity: 6.317732810974121
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.21s/it]
INFO:root:eval mean loss: 23263.594401041668
INFO:root:eval perplexity: 11.108181953430176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/20

 10%|â–ˆ         | 20/200 [1:51:10<16:51:32, 337.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18713.549278846152
INFO:root:current train perplexity6.266164302825928
INFO:root:current mean train loss 18599.065647482013
INFO:root:current train perplexity6.247474193572998
INFO:root:current mean train loss 18589.71984505753
INFO:root:current train perplexity6.2452168464660645


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.11s/it]
INFO:root:final mean train loss: 18567.47396358367
INFO:root:final train perplexity: 6.242316722869873
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.96s/it]
INFO:root:eval mean loss: 23210.736281622023
INFO:root:eval perplexity: 11.047577857971191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/21

 10%|â–ˆ         | 21/200 [1:56:43<16:42:43, 336.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18433.194132039836
INFO:root:current train perplexity6.162922382354736
INFO:root:current mean train loss 18456.847738056284
INFO:root:current train perplexity6.1607561111450195


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.83s/it]
INFO:root:final mean train loss: 18443.569930538055
INFO:root:final train perplexity: 6.166494369506836
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.37s/it]
INFO:root:eval mean loss: 23127.86356026786
INFO:root:eval perplexity: 10.953227043151855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/22

 11%|â–ˆ         | 22/200 [2:02:13<16:31:39, 334.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18383.696584302324
INFO:root:current train perplexity6.122241497039795
INFO:root:current mean train loss 18353.41482736014
INFO:root:current train perplexity6.105420112609863
INFO:root:current mean train loss 18354.956589184672
INFO:root:current train perplexity6.100965976715088


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.63s/it]
INFO:root:final mean train loss: 18332.507391160536
INFO:root:final train perplexity: 6.099313259124756
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.95s/it]
INFO:root:eval mean loss: 23099.378022693454
INFO:root:eval perplexity: 10.92098331451416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/23

 12%|â–ˆâ–        | 23/200 [2:07:46<16:25:01, 333.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18288.502981085527
INFO:root:current train perplexity6.042757511138916
INFO:root:current mean train loss 18250.219541266026
INFO:root:current train perplexity6.035007953643799


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.23s/it]
INFO:root:final mean train loss: 18228.47611753402
INFO:root:final train perplexity: 6.037049293518066
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.22s/it]
INFO:root:eval mean loss: 23024.026925223214
INFO:root:eval perplexity: 10.836148262023926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/24

 12%|â–ˆâ–        | 24/200 [2:13:16<16:15:57, 332.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18077.09886136968
INFO:root:current train perplexity5.966285228729248
INFO:root:current mean train loss 18134.51209077381
INFO:root:current train perplexity5.980846405029297
INFO:root:current mean train loss 18141.989799468625
INFO:root:current train perplexity5.978543758392334


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.47s/it]
INFO:root:final mean train loss: 18129.12960716986
INFO:root:final train perplexity: 5.978181838989258
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.73s/it]
INFO:root:eval mean loss: 23020.87813895089
INFO:root:eval perplexity: 10.83261489868164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/25

 12%|â–ˆâ–Ž        | 25/200 [2:18:44<16:06:00, 331.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18083.192964804293
INFO:root:current train perplexity5.939377307891846
INFO:root:current mean train loss 18063.653413552136
INFO:root:current train perplexity5.9215312004089355


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.51s/it]
INFO:root:final mean train loss: 18034.547528666833
INFO:root:final train perplexity: 5.922671318054199
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.03s/it]
INFO:root:eval mean loss: 22972.29903738839
INFO:root:eval perplexity: 10.778289794921875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/26

 13%|â–ˆâ–Ž        | 26/200 [2:24:11<15:56:50, 329.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17956.15736060049
INFO:root:current train perplexity5.886904239654541
INFO:root:current mean train loss 17976.389680774006
INFO:root:current train perplexity5.881227493286133


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.94s/it]
INFO:root:final mean train loss: 17943.31924143145
INFO:root:final train perplexity: 5.869617938995361
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.04s/it]
INFO:root:eval mean loss: 22913.962379092263
INFO:root:eval perplexity: 10.713409423828125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/27

 14%|â–ˆâ–Ž        | 27/200 [2:29:53<16:01:37, 333.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18033.961588541668
INFO:root:current train perplexity5.8233442306518555
INFO:root:current mean train loss 17896.05802487864
INFO:root:current train perplexity5.838387489318848
INFO:root:current mean train loss 17890.604410406402
INFO:root:current train perplexity5.824811935424805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.25s/it]
INFO:root:final mean train loss: 17863.183767011087
INFO:root:final train perplexity: 5.823407173156738
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.01s/it]
INFO:root:eval mean loss: 22870.30784970238
INFO:root:eval perplexity: 10.665118217468262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/28

 14%|â–ˆâ–        | 28/200 [2:35:27<15:56:21, 333.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17843.603053977273
INFO:root:current train perplexity5.796096324920654
INFO:root:current mean train loss 17820.88937752016
INFO:root:current train perplexity5.785052299499512


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.57s/it]
INFO:root:final mean train loss: 17782.756568170364
INFO:root:final train perplexity: 5.777395725250244
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.70s/it]
INFO:root:eval mean loss: 22843.16076078869
INFO:root:eval perplexity: 10.6351957321167
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/29

 14%|â–ˆâ–        | 29/200 [2:40:57<15:47:45, 332.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17818.26339285714
INFO:root:current train perplexity5.739112377166748
INFO:root:current mean train loss 17816.95383688668
INFO:root:current train perplexity5.744098663330078
INFO:root:current mean train loss 17754.3270776721
INFO:root:current train perplexity5.736915111541748


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.59s/it]
INFO:root:final mean train loss: 17709.150162235383
INFO:root:final train perplexity: 5.735602855682373
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.92s/it]
INFO:root:eval mean loss: 22799.440476190477
INFO:root:eval perplexity: 10.587181091308594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/30

 15%|â–ˆâ–Œ        | 30/200 [2:46:28<15:40:46, 332.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17660.61496954449
INFO:root:current train perplexity5.69987678527832
INFO:root:current mean train loss 17653.862237126574
INFO:root:current train perplexity5.695855140686035


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.06s/it]
INFO:root:final mean train loss: 17633.31238580519
INFO:root:final train perplexity: 5.692861557006836
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.12s/it]
INFO:root:eval mean loss: 22760.567359561013
INFO:root:eval perplexity: 10.544671058654785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/31

 16%|â–ˆâ–Œ        | 31/200 [2:51:49<15:26:42, 329.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17488.75
INFO:root:current train perplexity5.6211700439453125
INFO:root:current mean train loss 17564.56149704392
INFO:root:current train perplexity5.634036064147949
INFO:root:current mean train loss 17573.068405657585
INFO:root:current train perplexity5.654709339141846


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.43s/it]
INFO:root:final mean train loss: 17559.641286542337
INFO:root:final train perplexity: 5.651644706726074
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.05s/it]
INFO:root:eval mean loss: 22750.294875372023
INFO:root:eval perplexity: 10.533467292785645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/32

 16%|â–ˆâ–Œ        | 32/200 [2:57:30<15:30:46, 332.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17500.75945560516
INFO:root:current train perplexity5.600855350494385
INFO:root:current mean train loss 17513.109027511502
INFO:root:current train perplexity5.616554260253906


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.59s/it]
INFO:root:final mean train loss: 17493.899091166833
INFO:root:final train perplexity: 5.615116596221924
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.45s/it]
INFO:root:eval mean loss: 22749.157900855655
INFO:root:eval perplexity: 10.532228469848633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/33

 16%|â–ˆâ–‹        | 33/200 [3:02:55<15:19:29, 330.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17272.048177083332
INFO:root:current train perplexity5.530346393585205
INFO:root:current mean train loss 17424.60210597826
INFO:root:current train perplexity5.576987266540527
INFO:root:current mean train loss 17410.440216206396
INFO:root:current train perplexity5.566807270050049


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.28s/it]
INFO:root:final mean train loss: 17426.318304246473
INFO:root:final train perplexity: 5.577812671661377
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.16s/it]
INFO:root:eval mean loss: 22676.95726376488
INFO:root:eval perplexity: 10.45382022857666
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/34

 17%|â–ˆâ–‹        | 34/200 [3:08:26<15:13:57, 330.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17355.725367304105
INFO:root:current train perplexity5.537382125854492
INFO:root:current mean train loss 17382.151419816615
INFO:root:current train perplexity5.542418956756592


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.50s/it]
INFO:root:final mean train loss: 17361.981866651964
INFO:root:final train perplexity: 5.542530059814453
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.67s/it]
INFO:root:eval mean loss: 22651.156110491072
INFO:root:eval perplexity: 10.425939559936523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/35

 18%|â–ˆâ–Š        | 35/200 [3:13:53<15:06:13, 329.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17501.888569078947
INFO:root:current train perplexity5.569607734680176
INFO:root:current mean train loss 17347.440249146533
INFO:root:current train perplexity5.522770404815674
INFO:root:current mean train loss 17322.23439283676
INFO:root:current train perplexity5.510589599609375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.57s/it]
INFO:root:final mean train loss: 17304.55060011341
INFO:root:final train perplexity: 5.511222839355469
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.97s/it]
INFO:root:eval mean loss: 22666.130673363095
INFO:root:eval perplexity: 10.44211196899414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/36

 18%|â–ˆâ–Š        | 36/200 [3:19:17<14:55:34, 327.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17225.184336487677
INFO:root:current train perplexity5.467369556427002
INFO:root:current mean train loss 17240.163222998905
INFO:root:current train perplexity5.47947883605957


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.76s/it]
INFO:root:final mean train loss: 17247.726275044104
INFO:root:final train perplexity: 5.480420112609863
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.41s/it]
INFO:root:eval mean loss: 22609.791038876487
INFO:root:eval perplexity: 10.381401062011719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/37

 18%|â–ˆâ–Š        | 37/200 [3:24:50<14:55:10, 329.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17120.617484714672
INFO:root:current train perplexity5.413493633270264
INFO:root:current mean train loss 17131.715415396342
INFO:root:current train perplexity5.434285640716553
INFO:root:current mean train loss 17202.789272701793
INFO:root:current train perplexity5.449195861816406


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.14s/it]
INFO:root:final mean train loss: 17188.26150217364
INFO:root:final train perplexity: 5.448370933532715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.55s/it]
INFO:root:eval mean loss: 22598.62325613839
INFO:root:eval perplexity: 10.36940860748291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/38

 19%|â–ˆâ–‰        | 38/200 [3:30:19<14:48:30, 329.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17159.45953125
INFO:root:current train perplexity5.414932727813721
INFO:root:current mean train loss 17139.842466517857
INFO:root:current train perplexity5.414777755737305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.22s/it]
INFO:root:final mean train loss: 17135.896862399193
INFO:root:final train perplexity: 5.4203033447265625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.59s/it]
INFO:root:eval mean loss: 22590.395321800595
INFO:root:eval perplexity: 10.360584259033203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/39

 20%|â–ˆâ–‰        | 39/200 [3:35:59<14:52:00, 332.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17002.301106770832
INFO:root:current train perplexity5.354571342468262
INFO:root:current mean train loss 17091.43112543061
INFO:root:current train perplexity5.393804550170898
INFO:root:current mean train loss 17094.867613401708
INFO:root:current train perplexity5.392096519470215


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.27s/it]
INFO:root:final mean train loss: 17084.395472372733
INFO:root:final train perplexity: 5.392839431762695
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.58s/it]
INFO:root:eval mean loss: 22570.68526785714
INFO:root:eval perplexity: 10.339468955993652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/40

 20%|â–ˆâ–ˆ        | 40/200 [3:41:31<14:46:30, 332.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17067.12870846519
INFO:root:current train perplexity5.3699445724487305
INFO:root:current mean train loss 17083.470190293297
INFO:root:current train perplexity5.37711763381958


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.12s/it]
INFO:root:final mean train loss: 17030.68490108367
INFO:root:final train perplexity: 5.364345550537109
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.55s/it]
INFO:root:eval mean loss: 22567.058756510418
INFO:root:eval perplexity: 10.335592269897461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/41

 20%|â–ˆâ–ˆ        | 41/200 [3:47:08<14:44:40, 333.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16907.1015625
INFO:root:current train perplexity5.307942867279053
INFO:root:current mean train loss 16960.208820372136
INFO:root:current train perplexity5.323761463165283
INFO:root:current mean train loss 17002.99854572511
INFO:root:current train perplexity5.338868141174316


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.19s/it]
INFO:root:final mean train loss: 16982.896468623992
INFO:root:final train perplexity: 5.339121341705322
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.56s/it]
INFO:root:eval mean loss: 22519.283877418155
INFO:root:eval perplexity: 10.284610748291016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/42

 21%|â–ˆâ–ˆ        | 42/200 [3:52:33<14:31:28, 330.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16932.381624152862
INFO:root:current train perplexity5.3148298263549805
INFO:root:current mean train loss 16963.258116675206
INFO:root:current train perplexity5.317222595214844


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.99s/it]
INFO:root:final mean train loss: 16938.76775532384
INFO:root:final train perplexity: 5.3159332275390625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.76s/it]
INFO:root:eval mean loss: 22542.928641183036
INFO:root:eval perplexity: 10.309808731079102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/43

 22%|â–ˆâ–ˆâ–       | 43/200 [3:58:37<14:52:39, 341.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17027.892885044643
INFO:root:current train perplexity5.330933094024658
INFO:root:current mean train loss 16939.286552372687
INFO:root:current train perplexity5.294144630432129
INFO:root:current mean train loss 16908.57273520612
INFO:root:current train perplexity5.292820930480957


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.74s/it]
INFO:root:final mean train loss: 16891.78513656124
INFO:root:final train perplexity: 5.291355609893799
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.07s/it]
INFO:root:eval mean loss: 22520.36011904762
INFO:root:eval perplexity: 10.285758018493652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/44

 22%|â–ˆâ–ˆâ–       | 44/200 [4:04:12<14:41:43, 339.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16832.351495150862
INFO:root:current train perplexity5.254233360290527
INFO:root:current mean train loss 16850.38420684325
INFO:root:current train perplexity5.26043176651001


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.51s/it]
INFO:root:final mean train loss: 16843.057487241684
INFO:root:final train perplexity: 5.26598596572876
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.62s/it]
INFO:root:eval mean loss: 22502.132975260418
INFO:root:eval perplexity: 10.266371726989746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/45

 22%|â–ˆâ–ˆâ–Ž       | 45/200 [4:09:48<14:33:27, 338.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16830.4068760016
INFO:root:current train perplexity5.251158237457275
INFO:root:current mean train loss 16805.85392311151
INFO:root:current train perplexity5.245195388793945
INFO:root:current mean train loss 16814.782091723326
INFO:root:current train perplexity5.243973731994629


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.84s/it]
INFO:root:final mean train loss: 16798.98890341482
INFO:root:final train perplexity: 5.243146896362305
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.97s/it]
INFO:root:eval mean loss: 22492.275530133928
INFO:root:eval perplexity: 10.255903244018555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/46

 23%|â–ˆâ–ˆâ–Ž       | 46/200 [4:15:29<14:30:28, 339.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16793.280359289147
INFO:root:current train perplexity5.217344760894775
INFO:root:current mean train loss 16788.35257485275
INFO:root:current train perplexity5.2255940437316895


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.95s/it]
INFO:root:final mean train loss: 16757.333295268396
INFO:root:final train perplexity: 5.221648693084717
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.63s/it]
INFO:root:eval mean loss: 22483.577287946428
INFO:root:eval perplexity: 10.246676445007324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/47

 24%|â–ˆâ–ˆâ–Ž       | 47/200 [4:21:18<14:32:25, 342.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16717.204442223836
INFO:root:current train perplexity5.196481704711914
INFO:root:current mean train loss 16729.36365685096
INFO:root:current train perplexity5.199656009674072
INFO:root:current mean train loss 16728.180394804527
INFO:root:current train perplexity5.201576232910156


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.73s/it]
INFO:root:final mean train loss: 16717.535164125504
INFO:root:final train perplexity: 5.201192378997803
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.83s/it]
INFO:root:eval mean loss: 22468.064499627977
INFO:root:eval perplexity: 10.230238914489746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/48

 24%|â–ˆâ–ˆâ–       | 48/200 [4:26:49<14:18:05, 338.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16661.612232730262
INFO:root:current train perplexity5.1644415855407715
INFO:root:current mean train loss 16672.365084134617
INFO:root:current train perplexity5.169616222381592


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.66s/it]
INFO:root:final mean train loss: 16675.722140404487
INFO:root:final train perplexity: 5.17978572845459
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.23s/it]
INFO:root:eval mean loss: 22439.090773809523
INFO:root:eval perplexity: 10.199605941772461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/49

 24%|â–ˆâ–ˆâ–       | 49/200 [4:32:31<14:15:15, 339.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16652.232733543882
INFO:root:current train perplexity5.133562088012695
INFO:root:current mean train loss 16643.652264030614
INFO:root:current train perplexity5.156290054321289
INFO:root:current mean train loss 16648.320170167004
INFO:root:current train perplexity5.159984588623047


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.23s/it]
INFO:root:final mean train loss: 16637.751429403983
INFO:root:final train perplexity: 5.1604228019714355
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.20s/it]
INFO:root:eval mean loss: 22456.729538690477
INFO:root:eval perplexity: 10.218242645263672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/50

 25%|â–ˆâ–ˆâ–Œ       | 50/200 [4:37:59<14:00:29, 336.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16616.492937184343
INFO:root:current train perplexity5.12864351272583
INFO:root:current mean train loss 16583.254127080716
INFO:root:current train perplexity5.136561393737793


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.35s/it]
INFO:root:final mean train loss: 16595.47136860509
INFO:root:final train perplexity: 5.138948440551758
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.80s/it]
INFO:root:eval mean loss: 22449.589867001487
INFO:root:eval perplexity: 10.21069622039795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/51

 26%|â–ˆâ–ˆâ–Œ       | 51/200 [4:43:32<13:52:11, 335.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16564.581878063724
INFO:root:current train perplexity5.1127424240112305
INFO:root:current mean train loss 16584.128059033526
INFO:root:current train perplexity5.1213788986206055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.76s/it]
INFO:root:final mean train loss: 16562.38265105217
INFO:root:final train perplexity: 5.122204303741455
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.36s/it]
INFO:root:eval mean loss: 22434.291806175595
INFO:root:eval perplexity: 10.194541931152344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/52

 26%|â–ˆâ–ˆâ–Œ       | 52/200 [4:49:01<13:42:36, 333.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16635.93359375
INFO:root:current train perplexity5.223841667175293
INFO:root:current mean train loss 16492.87859337075
INFO:root:current train perplexity5.086214065551758
INFO:root:current mean train loss 16534.219668834667
INFO:root:current train perplexity5.102319240570068


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.10s/it]
INFO:root:final mean train loss: 16526.576715284777
INFO:root:final train perplexity: 5.104146480560303
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.49s/it]
INFO:root:eval mean loss: 22423.638857886905
INFO:root:eval perplexity: 10.183308601379395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/53

 26%|â–ˆâ–ˆâ–‹       | 53/200 [4:54:31<13:34:29, 332.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16481.191495028408
INFO:root:current train perplexity5.092351913452148
INFO:root:current mean train loss 16529.82718623992
INFO:root:current train perplexity5.097721099853516


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.06s/it]
INFO:root:final mean train loss: 16489.22156155494
INFO:root:final train perplexity: 5.085374355316162
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.42s/it]
INFO:root:eval mean loss: 22422.392066592263
INFO:root:eval perplexity: 10.18199348449707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/54

 27%|â–ˆâ–ˆâ–‹       | 54/200 [4:59:55<13:22:39, 329.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16352.470982142857
INFO:root:current train perplexity5.081398010253906
INFO:root:current mean train loss 16455.66281213493
INFO:root:current train perplexity5.071545600891113
INFO:root:current mean train loss 16458.43623094052
INFO:root:current train perplexity5.072819709777832


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.29s/it]
INFO:root:final mean train loss: 16456.112761466735
INFO:root:final train perplexity: 5.068795680999756
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.39s/it]
INFO:root:eval mean loss: 22402.427804129464
INFO:root:eval perplexity: 10.160980224609375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/55

 28%|â–ˆâ–ˆâ–Š       | 55/200 [5:05:21<13:14:26, 328.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16441.726728019068
INFO:root:current train perplexity5.040788173675537
INFO:root:current mean train loss 16396.06845150354
INFO:root:current train perplexity5.041186809539795


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.80s/it]
INFO:root:final mean train loss: 16417.553155714464
INFO:root:final train perplexity: 5.049554347991943
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.37s/it]
INFO:root:eval mean loss: 22400.322172619046
INFO:root:eval perplexity: 10.158763885498047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/56

 28%|â–ˆâ–ˆâ–Š       | 56/200 [5:10:55<13:12:46, 330.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16535.821200284092
INFO:root:current train perplexity5.078772068023682
INFO:root:current mean train loss 16378.6860131616
INFO:root:current train perplexity5.028737545013428
INFO:root:current mean train loss 16414.54489410545
INFO:root:current train perplexity5.037841320037842


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.96s/it]
INFO:root:final mean train loss: 16386.59382875504
INFO:root:final train perplexity: 5.034158706665039
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.15s/it]
INFO:root:eval mean loss: 22398.40843563988
INFO:root:eval perplexity: 10.156750679016113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/57

 28%|â–ˆâ–ˆâ–Š       | 57/200 [5:16:26<13:07:26, 330.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16330.076140873016
INFO:root:current train perplexity4.996203422546387
INFO:root:current mean train loss 16356.678195695935
INFO:root:current train perplexity5.015355110168457


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.70s/it]
INFO:root:final mean train loss: 16356.7158203125
INFO:root:final train perplexity: 5.019344806671143
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.33s/it]
INFO:root:eval mean loss: 22391.46944754464
INFO:root:eval perplexity: 10.14946174621582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/58

 29%|â–ˆâ–ˆâ–‰       | 58/200 [5:22:00<13:04:49, 331.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16345.0865234375
INFO:root:current train perplexity5.019983291625977
INFO:root:current mean train loss 16275.550178328804
INFO:root:current train perplexity4.98029899597168
INFO:root:current mean train loss 16312.556754178779
INFO:root:current train perplexity4.999222755432129


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.47s/it]
INFO:root:final mean train loss: 16329.545933877269
INFO:root:final train perplexity: 5.005911827087402
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.72s/it]
INFO:root:eval mean loss: 22370.426688058036
INFO:root:eval perplexity: 10.127381324768066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/59

 30%|â–ˆâ–ˆâ–‰       | 59/200 [5:27:29<12:57:10, 330.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16300.811435984142
INFO:root:current train perplexity4.9707794189453125
INFO:root:current mean train loss 16298.704312078968
INFO:root:current train perplexity4.989453315734863


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.68s/it]
INFO:root:final mean train loss: 16294.371239446824
INFO:root:final train perplexity: 4.988574504852295
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.34s/it]
INFO:root:eval mean loss: 22393.92406063988
INFO:root:eval perplexity: 10.152037620544434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/60

 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [5:32:53<12:46:35, 328.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16243.152857730263
INFO:root:current train perplexity4.971699237823486
INFO:root:current mean train loss 16243.22188484769
INFO:root:current train perplexity4.969491004943848
INFO:root:current mean train loss 16264.66432559218
INFO:root:current train perplexity4.971225738525391


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.68s/it]
INFO:root:final mean train loss: 16266.161605342742
INFO:root:final train perplexity: 4.974714279174805
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.22s/it]
INFO:root:eval mean loss: 22365.755789620536
INFO:root:eval perplexity: 10.122486114501953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/61

 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [5:38:11<12:34:02, 325.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16263.613556338029
INFO:root:current train perplexity4.963332176208496
INFO:root:current mean train loss 16264.263786092837
INFO:root:current train perplexity4.9626007080078125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.98s/it]
INFO:root:final mean train loss: 16236.0886702999
INFO:root:final train perplexity: 4.959980010986328
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.23s/it]
INFO:root:eval mean loss: 22366.592215401786
INFO:root:eval perplexity: 10.123361587524414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/62

 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [5:43:33<12:26:03, 324.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16121.423530910326
INFO:root:current train perplexity4.907362461090088
INFO:root:current mean train loss 16217.752627985265
INFO:root:current train perplexity4.937417984008789
INFO:root:current mean train loss 16222.45111932455
INFO:root:current train perplexity4.947841167449951


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.88s/it]
INFO:root:final mean train loss: 16205.985516948085
INFO:root:final train perplexity: 4.945274829864502
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.67s/it]
INFO:root:eval mean loss: 22360.72433035714
INFO:root:eval perplexity: 10.117218971252441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/63

 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [5:48:52<12:17:05, 322.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16163.987864583334
INFO:root:current train perplexity4.931633472442627
INFO:root:current mean train loss 16197.401880580357
INFO:root:current train perplexity4.926853656768799


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.84s/it]
INFO:root:final mean train loss: 16174.828440020161
INFO:root:final train perplexity: 4.930100917816162
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.09s/it]
INFO:root:eval mean loss: 22344.173642113095
INFO:root:eval perplexity: 10.099900245666504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/64

 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [5:54:24<12:18:09, 325.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16259.698169849536
INFO:root:current train perplexity4.930173873901367
INFO:root:current mean train loss 16125.930294968011
INFO:root:current train perplexity4.903234004974365
INFO:root:current mean train loss 16151.587008707324
INFO:root:current train perplexity4.913805961608887


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.89s/it]
INFO:root:final mean train loss: 16145.42488344254
INFO:root:final train perplexity: 4.915823459625244
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.04s/it]
INFO:root:eval mean loss: 22366.99669828869
INFO:root:eval perplexity: 10.123784065246582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/65

 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [6:00:03<12:21:38, 329.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16144.494375494462
INFO:root:current train perplexity4.90110445022583
INFO:root:current mean train loss 16137.479104835895
INFO:root:current train perplexity4.904282093048096


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.13s/it]
INFO:root:final mean train loss: 16127.526827904487
INFO:root:final train perplexity: 4.907153606414795
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.65s/it]
INFO:root:eval mean loss: 22346.561988467263
INFO:root:eval perplexity: 10.102399826049805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/66

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [6:05:24<12:10:33, 327.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16051.812783518146
INFO:root:current train perplexity4.862046241760254
INFO:root:current mean train loss 16109.597715887405
INFO:root:current train perplexity4.885641574859619
INFO:root:current mean train loss 16105.953653442912
INFO:root:current train perplexity4.891175270080566


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.81s/it]
INFO:root:final mean train loss: 16097.005564043598
INFO:root:final train perplexity: 4.892402648925781
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.25s/it]
INFO:root:eval mean loss: 22341.926850818454
INFO:root:eval perplexity: 10.097550392150879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/67

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [6:10:58<12:09:18, 329.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16077.56148814006
INFO:root:current train perplexity4.8733696937561035
INFO:root:current mean train loss 16087.623105575478
INFO:root:current train perplexity4.876376152038574


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.16s/it]
INFO:root:final mean train loss: 16070.704810357864
INFO:root:final train perplexity: 4.879727840423584
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.10s/it]
INFO:root:eval mean loss: 22341.116187686013
INFO:root:eval perplexity: 10.096704483032227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/68

 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [6:16:29<12:05:29, 329.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16133.2466796875
INFO:root:current train perplexity4.8892717361450195
INFO:root:current mean train loss 16067.744249131945
INFO:root:current train perplexity4.866833209991455
INFO:root:current mean train loss 16063.564066655585
INFO:root:current train perplexity4.86755895614624


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.55s/it]
INFO:root:final mean train loss: 16047.224916519657
INFO:root:final train perplexity: 4.868440628051758
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.08s/it]
INFO:root:eval mean loss: 22337.41434151786
INFO:root:eval perplexity: 10.0928373336792
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/69

 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [6:22:05<12:04:00, 331.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16025.766163793103
INFO:root:current train perplexity4.862395763397217
INFO:root:current mean train loss 16003.603458180147
INFO:root:current train perplexity4.853673458099365


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.22s/it]
INFO:root:final mean train loss: 16023.562531502017
INFO:root:final train perplexity: 4.857091426849365
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.25s/it]
INFO:root:eval mean loss: 22350.453473772322
INFO:root:eval perplexity: 10.106468200683594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/70

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [6:27:31<11:55:00, 330.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15888.35211338141
INFO:root:current train perplexity4.830023765563965
INFO:root:current mean train loss 15955.640842794515
INFO:root:current train perplexity4.82710599899292
INFO:root:current mean train loss 16001.63325379184
INFO:root:current train perplexity4.840290069580078


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.83s/it]
INFO:root:final mean train loss: 15995.213977444557
INFO:root:final train perplexity: 4.843528747558594
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.47s/it]
INFO:root:eval mean loss: 22325.74825613839
INFO:root:eval perplexity: 10.080658912658691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/71

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [6:33:06<11:52:30, 331.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15945.143533224587
INFO:root:current train perplexity4.815590858459473
INFO:root:current mean train loss 15961.66708933246
INFO:root:current train perplexity4.823943138122559


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.78s/it]
INFO:root:final mean train loss: 15967.05459299395
INFO:root:final train perplexity: 4.8300957679748535
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.08s/it]
INFO:root:eval mean loss: 22327.560686383928
INFO:root:eval perplexity: 10.082551002502441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/72

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [6:38:43<11:50:49, 333.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15949.129519440407
INFO:root:current train perplexity4.796760082244873
INFO:root:current mean train loss 15950.36378660402
INFO:root:current train perplexity4.815438747406006
INFO:root:current mean train loss 15957.224127121914
INFO:root:current train perplexity4.818854808807373


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.08s/it]
INFO:root:final mean train loss: 15943.508737871723
INFO:root:final train perplexity: 4.8188910484313965
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.61s/it]
INFO:root:eval mean loss: 22329.85265531994
INFO:root:eval perplexity: 10.084939956665039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/73

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [6:44:15<11:43:53, 332.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15914.761245888158
INFO:root:current train perplexity4.801647663116455
INFO:root:current mean train loss 15927.837795472757
INFO:root:current train perplexity4.808687686920166


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.19s/it]
INFO:root:final mean train loss: 15923.770133726059
INFO:root:final train perplexity: 4.809518814086914
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.77s/it]
INFO:root:eval mean loss: 22334.384626116072
INFO:root:eval perplexity: 10.089673042297363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/74

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [6:49:45<11:36:59, 331.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15883.207550698138
INFO:root:current train perplexity4.779298782348633
INFO:root:current mean train loss 15891.113307823129
INFO:root:current train perplexity4.782612323760986
INFO:root:current mean train loss 15910.770950626265
INFO:root:current train perplexity4.7969818115234375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.19s/it]
INFO:root:final mean train loss: 15898.064598821824
INFO:root:final train perplexity: 4.797340393066406
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.12s/it]
INFO:root:eval mean loss: 22322.166899181546
INFO:root:eval perplexity: 10.076925277709961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/75

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [6:55:15<11:30:10, 331.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15873.96819760101
INFO:root:current train perplexity4.77964973449707
INFO:root:current mean train loss 15882.496594299622
INFO:root:current train perplexity4.784078598022461


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.17s/it]
INFO:root:final mean train loss: 15874.538526965725
INFO:root:final train perplexity: 4.786221027374268
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.80s/it]
INFO:root:eval mean loss: 22334.76697358631
INFO:root:eval perplexity: 10.090072631835938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/76

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [7:00:43<11:22:46, 330.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15852.787779564951
INFO:root:current train perplexity4.778844833374023
INFO:root:current mean train loss 15871.631810068295
INFO:root:current train perplexity4.7757086753845215


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.23s/it]
INFO:root:final mean train loss: 15852.241183373237
INFO:root:final train perplexity: 4.775706768035889
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.44s/it]
INFO:root:eval mean loss: 22336.910109747023
INFO:root:eval perplexity: 10.092312812805176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/77

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [7:06:19<11:20:52, 332.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15448.4580078125
INFO:root:current train perplexity4.649702548980713
INFO:root:current mean train loss 15834.958282766991
INFO:root:current train perplexity4.756864547729492
INFO:root:current mean train loss 15832.952648745382
INFO:root:current train perplexity4.761816501617432


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.47s/it]
INFO:root:final mean train loss: 15831.983512632309
INFO:root:final train perplexity: 4.766173839569092
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.59s/it]
INFO:root:eval mean loss: 22329.304827008928
INFO:root:eval perplexity: 10.084370613098145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/78

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [7:11:52<11:15:35, 332.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15788.080095880681
INFO:root:current train perplexity4.7613301277160645
INFO:root:current mean train loss 15806.17681451613
INFO:root:current train perplexity4.753744125366211


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.11s/it]
INFO:root:final mean train loss: 15808.020204605595
INFO:root:final train perplexity: 4.754922389984131
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.21s/it]
INFO:root:eval mean loss: 22328.44022042411
INFO:root:eval perplexity: 10.083471298217773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/79

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [7:17:18<11:06:39, 330.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15715.6748046875
INFO:root:current train perplexity4.707873821258545
INFO:root:current mean train loss 15815.03921765479
INFO:root:current train perplexity4.745820999145508
INFO:root:current mean train loss 15818.86466353412
INFO:root:current train perplexity4.752251625061035


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.07s/it]
INFO:root:final mean train loss: 15789.43947281376
INFO:root:final train perplexity: 4.7462158203125
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.45s/it]
INFO:root:eval mean loss: 22328.31617373512
INFO:root:eval perplexity: 10.083338737487793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/80

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [7:22:48<11:00:16, 330.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15711.322447695975
INFO:root:current train perplexity4.7106757164001465
INFO:root:current mean train loss 15759.376756584119
INFO:root:current train perplexity4.728420734405518


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.40s/it]
INFO:root:final mean train loss: 15770.413148941532
INFO:root:final train perplexity: 4.7373175621032715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.36s/it]
INFO:root:eval mean loss: 22320.69554501488
INFO:root:eval perplexity: 10.075389862060547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/81

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [7:28:09<10:49:27, 327.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15848.255859375
INFO:root:current train perplexity4.80384635925293
INFO:root:current mean train loss 15780.535833685248
INFO:root:current train perplexity4.726595878601074
INFO:root:current mean train loss 15779.068285322868
INFO:root:current train perplexity4.727574825286865


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.15s/it]
INFO:root:final mean train loss: 15748.372184507309
INFO:root:final train perplexity: 4.727029800415039
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.67s/it]
INFO:root:eval mean loss: 22333.245930989582
INFO:root:eval perplexity: 10.088484764099121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/82

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [7:33:41<10:46:52, 328.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15728.928385416666
INFO:root:current train perplexity4.717520713806152
INFO:root:current mean train loss 15727.987520370016
INFO:root:current train perplexity4.722403049468994


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.16s/it]
INFO:root:final mean train loss: 15727.758836315525
INFO:root:final train perplexity: 4.717428684234619
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.28s/it]
INFO:root:eval mean loss: 22316.391694568454
INFO:root:eval perplexity: 10.070903778076172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/83

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [7:39:18<10:45:57, 331.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15720.310481770834
INFO:root:current train perplexity4.681591987609863
INFO:root:current mean train loss 15696.2482421875
INFO:root:current train perplexity4.705130577087402
INFO:root:current mean train loss 15721.130886627907
INFO:root:current train perplexity4.709448337554932


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.59s/it]
INFO:root:final mean train loss: 15708.570946478074
INFO:root:final train perplexity: 4.7085089683532715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.55s/it]
INFO:root:eval mean loss: 22330.093889508928
INFO:root:eval perplexity: 10.085195541381836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/84

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [7:44:49<10:40:35, 331.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15635.601868586753
INFO:root:current train perplexity4.6813459396362305
INFO:root:current mean train loss 15692.427991672905
INFO:root:current train perplexity4.696247577667236


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.02s/it]
INFO:root:final mean train loss: 15688.506257087955
INFO:root:final train perplexity: 4.699200630187988
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.71s/it]
INFO:root:eval mean loss: 22314.021089099704
INFO:root:eval perplexity: 10.068432807922363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/85

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [7:50:22<10:35:32, 331.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15470.284693667763
INFO:root:current train perplexity4.685934543609619
INFO:root:current mean train loss 15691.551511620273
INFO:root:current train perplexity4.690021514892578
INFO:root:current mean train loss 15684.678755529396
INFO:root:current train perplexity4.69040060043335


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.55s/it]
INFO:root:final mean train loss: 15670.834897933468
INFO:root:final train perplexity: 4.691017150878906
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.47s/it]
INFO:root:eval mean loss: 22318.703125
INFO:root:eval perplexity: 10.073311805725098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/86

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [7:55:49<10:27:32, 330.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15592.090160101232
INFO:root:current train perplexity4.678971767425537
INFO:root:current mean train loss 15644.705346536915
INFO:root:current train perplexity4.678336143493652


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.76s/it]
INFO:root:final mean train loss: 15650.317170173892
INFO:root:final train perplexity: 4.681533336639404
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.91s/it]
INFO:root:eval mean loss: 22327.67843191964
INFO:root:eval perplexity: 10.082673072814941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/87

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [8:01:15<10:19:34, 328.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15659.644361413044
INFO:root:current train perplexity4.6620354652404785
INFO:root:current mean train loss 15628.671438325711
INFO:root:current train perplexity4.666086673736572
INFO:root:current mean train loss 15637.85203983324
INFO:root:current train perplexity4.670671463012695


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.28s/it]
INFO:root:final mean train loss: 15628.417571037045
INFO:root:final train perplexity: 4.6714324951171875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.09s/it]
INFO:root:eval mean loss: 22333.629743303572
INFO:root:eval perplexity: 10.088887214660645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/88

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [8:06:38<10:11:06, 327.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15626.496171875
INFO:root:current train perplexity4.657660961151123
INFO:root:current mean train loss 15615.726858258928
INFO:root:current train perplexity4.663328647613525


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.34s/it]
INFO:root:final mean train loss: 15617.646291425152
INFO:root:final train perplexity: 4.6664719581604
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.82s/it]
INFO:root:eval mean loss: 22307.53487723214
INFO:root:eval perplexity: 10.061675071716309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/89

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [8:12:15<10:10:41, 330.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15567.926142939816
INFO:root:current train perplexity4.646124362945557
INFO:root:current mean train loss 15558.037739911417
INFO:root:current train perplexity4.63979959487915
INFO:root:current mean train loss 15597.511611199065
INFO:root:current train perplexity4.65352201461792


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.13s/it]
INFO:root:final mean train loss: 15597.757017074093
INFO:root:final train perplexity: 4.6573262214660645
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.68s/it]
INFO:root:eval mean loss: 22314.686058407737
INFO:root:eval perplexity: 10.069124221801758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/90

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [8:17:37<10:00:42, 327.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15644.897769976265
INFO:root:current train perplexity4.654572486877441
INFO:root:current mean train loss 15584.235438853002
INFO:root:current train perplexity4.6478271484375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.62s/it]
INFO:root:final mean train loss: 15582.340977822581
INFO:root:final train perplexity: 4.65024995803833
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.05s/it]
INFO:root:eval mean loss: 22300.075032552082
INFO:root:eval perplexity: 10.053911209106445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/91
####################best#################
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [8:23:08<9:57:02, 328.64s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15567.056388608871
INFO:root:current train perplexity4.6431965827941895
INFO:root:current mean train loss 15554.028417223282
INFO:root:current train perplexity4.640821933746338
INFO:root:current mean train loss 15571.81130360525
INFO:root:current train perplexity4.642122268676758


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.64s/it]
INFO:root:final mean train loss: 15561.354693012852
INFO:root:final train perplexity: 4.640635013580322
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.12s/it]
INFO:root:eval mean loss: 22333.247651599704
INFO:root:eval perplexity: 10.08848762512207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/92

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [8:28:33<9:49:34, 327.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15576.223032756025
INFO:root:current train perplexity4.640439510345459
INFO:root:current mean train loss 15556.294751109972
INFO:root:current train perplexity4.6328654289245605


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.02s/it]
INFO:root:final mean train loss: 15546.980141916583
INFO:root:final train perplexity: 4.634059906005859
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.38s/it]
INFO:root:eval mean loss: 22316.544968377977
INFO:root:eval perplexity: 10.071062088012695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/93

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [8:34:28<9:59:08, 335.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15519.69642857143
INFO:root:current train perplexity4.596713066101074
INFO:root:current mean train loss 15511.61556712963
INFO:root:current train perplexity4.618393421173096
INFO:root:current mean train loss 15538.542021276597
INFO:root:current train perplexity4.624655246734619


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.17s/it]
INFO:root:final mean train loss: 15528.716277091733
INFO:root:final train perplexity: 4.6257195472717285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.37s/it]
INFO:root:eval mean loss: 22330.043619791668
INFO:root:eval perplexity: 10.085142135620117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/94

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [8:40:03<9:52:59, 335.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15542.352045168822
INFO:root:current train perplexity4.6116228103637695
INFO:root:current mean train loss 15529.693646599264
INFO:root:current train perplexity4.618908882141113


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.15s/it]
INFO:root:final mean train loss: 15510.501437279487
INFO:root:final train perplexity: 4.617416858673096
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.48s/it]
INFO:root:eval mean loss: 22326.185081845237
INFO:root:eval perplexity: 10.08111572265625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/95

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [8:45:25<9:40:21, 331.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15443.687825520834
INFO:root:current train perplexity4.5671892166137695
INFO:root:current mean train loss 15499.595253484713
INFO:root:current train perplexity4.595545768737793
INFO:root:current mean train loss 15514.523498790533
INFO:root:current train perplexity4.609195232391357


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.72s/it]
INFO:root:final mean train loss: 15492.119223317792
INFO:root:final train perplexity: 4.609051704406738
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.81s/it]
INFO:root:eval mean loss: 22327.1083984375
INFO:root:eval perplexity: 10.082077026367188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/96

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [8:50:47<9:29:44, 328.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15515.905659769918
INFO:root:current train perplexity4.605867862701416
INFO:root:current mean train loss 15478.805628272252
INFO:root:current train perplexity4.602687358856201


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.09s/it]
INFO:root:final mean train loss: 15477.652371314263
INFO:root:final train perplexity: 4.602480411529541
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.91s/it]
INFO:root:eval mean loss: 22338.375930059523
INFO:root:eval perplexity: 10.093843460083008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/97

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [8:56:05<9:18:33, 325.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15458.696629723838
INFO:root:current train perplexity4.601851940155029
INFO:root:current mean train loss 15473.676109047203
INFO:root:current train perplexity4.598518371582031
INFO:root:current mean train loss 15465.255811149691
INFO:root:current train perplexity4.593111038208008


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.78s/it]
INFO:root:final mean train loss: 15455.599321919102
INFO:root:final train perplexity: 4.592480182647705
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.25s/it]
INFO:root:eval mean loss: 22327.089169456845
INFO:root:eval perplexity: 10.08205795288086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/98

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [9:01:21<9:08:28, 322.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15492.624516858552
INFO:root:current train perplexity4.588354110717773
INFO:root:current mean train loss 15463.080794270832
INFO:root:current train perplexity4.589094638824463


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.79s/it]
INFO:root:final mean train loss: 15447.126590851814
INFO:root:final train perplexity: 4.588643550872803
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.99s/it]
INFO:root:eval mean loss: 22315.318266369046
INFO:root:eval perplexity: 10.06978702545166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/99

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [9:06:48<9:05:18, 323.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15361.056931515957
INFO:root:current train perplexity4.535408020019531
INFO:root:current mean train loss 15425.464205994898
INFO:root:current train perplexity4.570165634155273
INFO:root:current mean train loss 15441.3283345458
INFO:root:current train perplexity4.580515384674072


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.19s/it]
INFO:root:final mean train loss: 15430.596022082913
INFO:root:final train perplexity: 4.5811686515808105
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.50s/it]
INFO:root:eval mean loss: 22329.500581287204
INFO:root:eval perplexity: 10.084577560424805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/100

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [9:12:03<8:55:19, 321.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15368.648940577652
INFO:root:current train perplexity4.5576605796813965
INFO:root:current mean train loss 15432.640065562186
INFO:root:current train perplexity4.573122024536133


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.77s/it]
INFO:root:final mean train loss: 15414.96832078503
INFO:root:final train perplexity: 4.574112892150879
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.98s/it]
INFO:root:eval mean loss: 22317.46642485119
INFO:root:eval perplexity: 10.072022438049316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/101

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [9:17:30<8:52:50, 322.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15457.326708026962
INFO:root:current train perplexity4.565054893493652
INFO:root:current mean train loss 15428.79252897351
INFO:root:current train perplexity4.570406436920166


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.33s/it]
INFO:root:final mean train loss: 15402.30795189642
INFO:root:final train perplexity: 4.568404674530029
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.97s/it]
INFO:root:eval mean loss: 22318.315941220237
INFO:root:eval perplexity: 10.072908401489258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/102

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [9:22:50<8:46:15, 322.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15444.313802083334
INFO:root:current train perplexity4.495148658752441
INFO:root:current mean train loss 15421.317297481795
INFO:root:current train perplexity4.5555315017700195
INFO:root:current mean train loss 15387.779205472598
INFO:root:current train perplexity4.556906223297119


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.64s/it]
INFO:root:final mean train loss: 15389.74455015121
INFO:root:final train perplexity: 4.562747001647949
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.09s/it]
INFO:root:eval mean loss: 22321.231352306546
INFO:root:eval perplexity: 10.075946807861328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/103

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [9:28:08<8:38:47, 320.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15343.1861328125
INFO:root:current train perplexity4.526642322540283
INFO:root:current mean train loss 15365.341916582662
INFO:root:current train perplexity4.551029205322266


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.18s/it]
INFO:root:final mean train loss: 15372.88798670615
INFO:root:final train perplexity: 4.5551676750183105
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.91s/it]
INFO:root:eval mean loss: 22322.983351934523
INFO:root:eval perplexity: 10.077775001525879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/104

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [9:33:27<8:32:21, 320.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15178.616908482143
INFO:root:current train perplexity4.4926862716674805
INFO:root:current mean train loss 15292.043771904206
INFO:root:current train perplexity4.5362629890441895
INFO:root:current mean train loss 15374.994282155798
INFO:root:current train perplexity4.553605556488037


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.14s/it]
INFO:root:final mean train loss: 15363.776662518902
INFO:root:final train perplexity: 4.5510759353637695
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.46s/it]
INFO:root:eval mean loss: 22331.353562127977
INFO:root:eval perplexity: 10.08651065826416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/105

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [9:38:49<8:27:47, 320.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15350.253624867584
INFO:root:current train perplexity4.542533874511719
INFO:root:current mean train loss 15383.358134335691
INFO:root:current train perplexity4.545888900756836


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.04s/it]
INFO:root:final mean train loss: 15342.036317886845
INFO:root:final train perplexity: 4.541327476501465
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.57s/it]
INFO:root:eval mean loss: 22332.67752511161
INFO:root:eval perplexity: 10.08789348602295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/106

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [9:44:12<8:23:26, 321.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15075.1455078125
INFO:root:current train perplexity4.49928617477417
INFO:root:current mean train loss 15302.179705095721
INFO:root:current train perplexity4.5225019454956055
INFO:root:current mean train loss 15342.293089084716
INFO:root:current train perplexity4.535406112670898


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.86s/it]
INFO:root:final mean train loss: 15332.651977539062
INFO:root:final train perplexity: 4.537125587463379
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.10s/it]
INFO:root:eval mean loss: 22343.892415364582
INFO:root:eval perplexity: 10.099608421325684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/107

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [9:49:29<8:16:10, 320.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15289.015066964286
INFO:root:current train perplexity4.523080348968506
INFO:root:current mean train loss 15326.829017685966
INFO:root:current train perplexity4.530492305755615


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.63s/it]
INFO:root:final mean train loss: 15320.28564453125
INFO:root:final train perplexity: 4.531594753265381
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.34s/it]
INFO:root:eval mean loss: 22343.456891741072
INFO:root:eval perplexity: 10.099150657653809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/108

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [9:55:35<8:32:03, 333.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15073.00546875
INFO:root:current train perplexity4.511445045471191
INFO:root:current mean train loss 15286.844896399456
INFO:root:current train perplexity4.516249179840088
INFO:root:current mean train loss 15310.051844113372
INFO:root:current train perplexity4.521273612976074


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.98s/it]
INFO:root:final mean train loss: 15304.737438571068
INFO:root:final train perplexity: 4.524651050567627
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.24s/it]
INFO:root:eval mean loss: 22345.851376488095
INFO:root:eval perplexity: 10.101655006408691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/109

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [10:00:53<8:19:07, 329.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15219.74029267724
INFO:root:current train perplexity4.499881744384766
INFO:root:current mean train loss 15283.809125888847
INFO:root:current train perplexity4.517434120178223


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.06s/it]
INFO:root:final mean train loss: 15293.109654580394
INFO:root:final train perplexity: 4.519464492797852
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.87s/it]
INFO:root:eval mean loss: 22342.591331845237
INFO:root:eval perplexity: 10.098248481750488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/110

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [10:06:18<8:11:52, 327.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15291.577097039473
INFO:root:current train perplexity4.50281286239624
INFO:root:current mean train loss 15331.973288143383
INFO:root:current train perplexity4.516154766082764
INFO:root:current mean train loss 15289.778454088186
INFO:root:current train perplexity4.513059616088867


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.52s/it]
INFO:root:final mean train loss: 15281.466481854839
INFO:root:final train perplexity: 4.514277458190918
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.90s/it]
INFO:root:eval mean loss: 22352.227143787204
INFO:root:eval perplexity: 10.10832691192627
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/111

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [10:11:46<8:06:24, 327.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15297.630254181338
INFO:root:current train perplexity4.512543201446533
INFO:root:current mean train loss 15285.926894873903
INFO:root:current train perplexity4.512192249298096


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.79s/it]
INFO:root:final mean train loss: 15267.878599105343
INFO:root:final train perplexity: 4.508231163024902
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.18s/it]
INFO:root:eval mean loss: 22351.617978050595
INFO:root:eval perplexity: 10.107685089111328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/112

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [10:17:09<7:58:53, 326.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15180.932744565218
INFO:root:current train perplexity4.47895622253418
INFO:root:current mean train loss 15233.950473196139
INFO:root:current train perplexity4.498080730438232
INFO:root:current mean train loss 15258.717059627243
INFO:root:current train perplexity4.5030598640441895


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.14s/it]
INFO:root:final mean train loss: 15253.076392389114
INFO:root:final train perplexity: 4.501654148101807
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.61s/it]
INFO:root:eval mean loss: 22350.957101004464
INFO:root:eval perplexity: 10.106993675231934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/113

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [10:23:13<8:09:40, 337.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15240.000247395834
INFO:root:current train perplexity4.49751091003418
INFO:root:current mean train loss 15256.804285714286
INFO:root:current train perplexity4.500534534454346


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.66s/it]
INFO:root:final mean train loss: 15244.202589465725
INFO:root:final train perplexity: 4.497715473175049
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.84s/it]
INFO:root:eval mean loss: 22346.92015438988
INFO:root:eval perplexity: 10.10277271270752
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/114

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [10:28:50<8:03:50, 337.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15202.122432002316
INFO:root:current train perplexity4.510105609893799
INFO:root:current mean train loss 15224.19438207431
INFO:root:current train perplexity4.493002414703369
INFO:root:current mean train loss 15236.16752994218
INFO:root:current train perplexity4.4885735511779785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.54s/it]
INFO:root:final mean train loss: 15230.20964985509
INFO:root:final train perplexity: 4.491512775421143
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.68s/it]
INFO:root:eval mean loss: 22332.117047991072
INFO:root:eval perplexity: 10.087308883666992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/115

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [10:34:21<7:55:24, 335.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15196.787381329113
INFO:root:current train perplexity4.478240489959717
INFO:root:current mean train loss 15231.24798686278
INFO:root:current train perplexity4.48146915435791


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.19s/it]
INFO:root:final mean train loss: 15217.627858807964
INFO:root:final train perplexity: 4.485942840576172
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 53.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 53.00s/it]
INFO:root:eval mean loss: 22345.716889880954
INFO:root:eval perplexity: 10.101515769958496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/116

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [10:40:17<7:58:09, 341.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15266.70303049395
INFO:root:current train perplexity4.491062164306641
INFO:root:current mean train loss 15242.15311903626
INFO:root:current train perplexity4.484124660491943
INFO:root:current mean train loss 15222.134533110118
INFO:root:current train perplexity4.482336521148682


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.99s/it]
INFO:root:final mean train loss: 15204.615218623992
INFO:root:final train perplexity: 4.480188369750977
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.11s/it]
INFO:root:eval mean loss: 22356.36886160714
INFO:root:eval perplexity: 10.112658500671387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/117

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [10:45:52<7:50:00, 339.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15208.042415756778
INFO:root:current train perplexity4.4706220626831055
INFO:root:current mean train loss 15221.172792862022
INFO:root:current train perplexity4.4762492179870605


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.24s/it]
INFO:root:final mean train loss: 15192.523736769153
INFO:root:final train perplexity: 4.474848747253418
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.67s/it]
INFO:root:eval mean loss: 22354.582077752977
INFO:root:eval perplexity: 10.110787391662598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/118

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [10:51:15<7:37:31, 334.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15154.374469866072
INFO:root:current train perplexity4.451661109924316
INFO:root:current mean train loss 15197.566232638888
INFO:root:current train perplexity4.462182521820068
INFO:root:current mean train loss 15194.498690990691
INFO:root:current train perplexity4.471208095550537


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.55s/it]
INFO:root:final mean train loss: 15182.890849451866
INFO:root:final train perplexity: 4.470599174499512
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.37s/it]
INFO:root:eval mean loss: 22359.599423363095
INFO:root:eval perplexity: 10.116039276123047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/119

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [10:56:35<7:25:38, 330.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15122.866603807472
INFO:root:current train perplexity4.459834575653076
INFO:root:current mean train loss 15174.570991393717
INFO:root:current train perplexity4.463620185852051


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.75s/it]
INFO:root:final mean train loss: 15170.269267420616
INFO:root:final train perplexity: 4.465036869049072
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.51s/it]
INFO:root:eval mean loss: 22365.374930245536
INFO:root:eval perplexity: 10.122087478637695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/120

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [11:01:58<7:17:16, 327.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15116.323292267629
INFO:root:current train perplexity4.4398908615112305
INFO:root:current mean train loss 15136.400088522932
INFO:root:current train perplexity4.454458713531494
INFO:root:current mean train loss 15165.419742089434
INFO:root:current train perplexity4.458378314971924


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.58s/it]
INFO:root:final mean train loss: 15156.993270381805
INFO:root:final train perplexity: 4.459194183349609
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.87s/it]
INFO:root:eval mean loss: 22361.49190848214
INFO:root:eval perplexity: 10.118019104003906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/121

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [11:07:22<7:10:36, 327.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15121.917518028846
INFO:root:current train perplexity4.445204257965088
INFO:root:current mean train loss 15141.377648478403
INFO:root:current train perplexity4.445115566253662


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.43s/it]
INFO:root:final mean train loss: 15147.472908266129
INFO:root:final train perplexity: 4.455009460449219
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.29s/it]
INFO:root:eval mean loss: 22352.612490699405
INFO:root:eval perplexity: 10.108726501464844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/122

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [11:12:42<7:02:04, 324.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15129.827080305233
INFO:root:current train perplexity4.468108654022217
INFO:root:current mean train loss 15169.699942635489
INFO:root:current train perplexity4.458168983459473
INFO:root:current mean train loss 15155.759817869084
INFO:root:current train perplexity4.453582286834717


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.85s/it]
INFO:root:final mean train loss: 15143.39812641759
INFO:root:final train perplexity: 4.453218936920166
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.10s/it]
INFO:root:eval mean loss: 22370.72188895089
INFO:root:eval perplexity: 10.127687454223633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/123

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [11:18:01<6:54:30, 322.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15108.550678453947
INFO:root:current train perplexity4.443047046661377
INFO:root:current mean train loss 15148.794946915064
INFO:root:current train perplexity4.445860862731934


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.64s/it]
INFO:root:final mean train loss: 15131.064205046623
INFO:root:final train perplexity: 4.4478044509887695
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.35s/it]
INFO:root:eval mean loss: 22371.76976376488
INFO:root:eval perplexity: 10.128788948059082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/124

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [11:23:16<6:46:16, 320.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15112.382874833776
INFO:root:current train perplexity4.429086208343506
INFO:root:current mean train loss 15133.86141448767
INFO:root:current train perplexity4.439622402191162
INFO:root:current mean train loss 15135.250652359564
INFO:root:current train perplexity4.4439377784729


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.66s/it]
INFO:root:final mean train loss: 15121.624283329133
INFO:root:final train perplexity: 4.443665504455566
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.45s/it]
INFO:root:eval mean loss: 22365.27657645089
INFO:root:eval perplexity: 10.121983528137207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/125

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [11:28:32<6:38:53, 319.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15104.323755129419
INFO:root:current train perplexity4.435593128204346
INFO:root:current mean train loss 15120.12682553392
INFO:root:current train perplexity4.436526775360107


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.61s/it]
INFO:root:final mean train loss: 15111.797950006301
INFO:root:final train perplexity: 4.439361095428467
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.94s/it]
INFO:root:eval mean loss: 22363.790852864582
INFO:root:eval perplexity: 10.120429992675781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/126

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [11:34:09<6:40:23, 324.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15100.24333639706
INFO:root:current train perplexity4.427309989929199
INFO:root:current mean train loss 15088.405014745447
INFO:root:current train perplexity4.428314685821533


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.37s/it]
INFO:root:final mean train loss: 15101.953128937752
INFO:root:final train perplexity: 4.435052394866943
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.91s/it]
INFO:root:eval mean loss: 22369.54227120536
INFO:root:eval perplexity: 10.126456260681152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/127

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [11:39:33<6:34:38, 324.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14933.274088541666
INFO:root:current train perplexity4.442378520965576
INFO:root:current mean train loss 15087.385002654733
INFO:root:current train perplexity4.431079864501953
INFO:root:current mean train loss 15083.40995901324
INFO:root:current train perplexity4.423497200012207


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.13s/it]
INFO:root:final mean train loss: 15087.604677261845
INFO:root:final train perplexity: 4.4287800788879395
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.39s/it]
INFO:root:eval mean loss: 22368.604027157737
INFO:root:eval perplexity: 10.125471115112305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/128

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [11:45:05<6:32:14, 326.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15104.7458984375
INFO:root:current train perplexity4.42901086807251
INFO:root:current mean train loss 15088.381218497983
INFO:root:current train perplexity4.427829265594482


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.52s/it]
INFO:root:final mean train loss: 15080.504563854587
INFO:root:final train perplexity: 4.425680160522461
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.65s/it]
INFO:root:eval mean loss: 22368.939360119046
INFO:root:eval perplexity: 10.125823974609375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/129

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [11:50:35<6:27:41, 327.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15134.154296875
INFO:root:current train perplexity4.39244270324707
INFO:root:current mean train loss 15095.031624196847
INFO:root:current train perplexity4.430202007293701
INFO:root:current mean train loss 15078.053640172102
INFO:root:current train perplexity4.4207024574279785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.93s/it]
INFO:root:final mean train loss: 15066.55904265373
INFO:root:final train perplexity: 4.419596195220947
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.02s/it]
INFO:root:eval mean loss: 22403.838076636905
INFO:root:eval perplexity: 10.162460327148438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/130

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [11:56:04<6:22:46, 328.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15097.92079912606
INFO:root:current train perplexity4.425774097442627
INFO:root:current mean train loss 15051.402540290881
INFO:root:current train perplexity4.416411399841309


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.65s/it]
INFO:root:final mean train loss: 15058.390877016129
INFO:root:final train perplexity: 4.416037082672119
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.56s/it]
INFO:root:eval mean loss: 22384.536179315477
INFO:root:eval perplexity: 10.142181396484375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/131

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [12:01:39<6:19:35, 330.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14938.82315340909
INFO:root:current train perplexity4.420421600341797
INFO:root:current mean train loss 15047.749612894144
INFO:root:current train perplexity4.4050612449646
INFO:root:current mean train loss 15049.311398474527
INFO:root:current train perplexity4.409367561340332


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.97s/it]
INFO:root:final mean train loss: 15045.698226436492
INFO:root:final train perplexity: 4.4105119705200195
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.16s/it]
INFO:root:eval mean loss: 22379.215169270832
INFO:root:eval perplexity: 10.1365966796875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/132

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [12:07:08<6:13:53, 329.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14938.376209077382
INFO:root:current train perplexity4.394279479980469
INFO:root:current mean train loss 14998.97783862155
INFO:root:current train perplexity4.395381450653076


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.78s/it]
INFO:root:final mean train loss: 15036.012277910786
INFO:root:final train perplexity: 4.406301021575928
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.76s/it]
INFO:root:eval mean loss: 22379.006277901786
INFO:root:eval perplexity: 10.136377334594727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/133

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [12:12:35<6:07:22, 328.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15002.1046875
INFO:root:current train perplexity4.4151997566223145
INFO:root:current mean train loss 15043.895762567934
INFO:root:current train perplexity4.409663200378418
INFO:root:current mean train loss 15039.763835392441
INFO:root:current train perplexity4.402369022369385


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.18s/it]
INFO:root:final mean train loss: 15032.18693296371
INFO:root:final train perplexity: 4.404638767242432
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.46s/it]
INFO:root:eval mean loss: 22387.916015625
INFO:root:eval perplexity: 10.145729064941406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/134

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [12:18:04<6:01:52, 328.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14986.954203591418
INFO:root:current train perplexity4.386101722717285
INFO:root:current mean train loss 15062.254812640344
INFO:root:current train perplexity4.408915996551514


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.94s/it]
INFO:root:final mean train loss: 15026.954763104839
INFO:root:final train perplexity: 4.402365684509277
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.28s/it]
INFO:root:eval mean loss: 22378.97498139881
INFO:root:eval perplexity: 10.136343002319336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/135

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [12:23:32<5:55:54, 328.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15057.567228618422
INFO:root:current train perplexity4.395962238311768
INFO:root:current mean train loss 15049.494633009454
INFO:root:current train perplexity4.407285690307617
INFO:root:current mean train loss 15050.529082833904
INFO:root:current train perplexity4.401218414306641


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.96s/it]
INFO:root:final mean train loss: 15017.152347687752
INFO:root:final train perplexity: 4.398111820220947
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.32s/it]
INFO:root:eval mean loss: 22391.076311383928
INFO:root:eval perplexity: 10.149048805236816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/136

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [12:29:02<5:51:03, 329.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14987.1044921875
INFO:root:current train perplexity4.381433010101318
INFO:root:current mean train loss 15027.872892680922
INFO:root:current train perplexity4.391465663909912


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.24s/it]
INFO:root:final mean train loss: 14999.90734469506
INFO:root:final train perplexity: 4.390636920928955
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.67s/it]
INFO:root:eval mean loss: 22381.03929501488
INFO:root:eval perplexity: 10.138510704040527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/137

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [12:34:36<5:47:13, 330.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14885.046492866848
INFO:root:current train perplexity4.35333776473999
INFO:root:current mean train loss 14987.033052273882
INFO:root:current train perplexity4.387046813964844
INFO:root:current mean train loss 14998.328335201793
INFO:root:current train perplexity4.387852668762207


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.13s/it]
INFO:root:final mean train loss: 14993.885171213458
INFO:root:final train perplexity: 4.388030052185059
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.54s/it]
INFO:root:eval mean loss: 22393.791527157737
INFO:root:eval perplexity: 10.151901245117188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/138

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [12:40:00<5:39:36, 328.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14935.807174479167
INFO:root:current train perplexity4.366387844085693
INFO:root:current mean train loss 14988.478203125
INFO:root:current train perplexity4.37673282623291


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.32s/it]
INFO:root:final mean train loss: 14987.288432459678
INFO:root:final train perplexity: 4.385176181793213
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.71s/it]
INFO:root:eval mean loss: 22383.867280505954
INFO:root:eval perplexity: 10.141477584838867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/139

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [12:45:30<5:34:19, 328.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14997.761357060184
INFO:root:current train perplexity4.387032985687256
INFO:root:current mean train loss 14948.255374938484
INFO:root:current train perplexity4.3711771965026855
INFO:root:current mean train loss 14989.979225461178
INFO:root:current train perplexity4.379965305328369


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.25s/it]
INFO:root:final mean train loss: 14979.821860036542
INFO:root:final train perplexity: 4.3819475173950195
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.87s/it]
INFO:root:eval mean loss: 22380.710309709822
INFO:root:eval perplexity: 10.138162612915039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/140

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [12:51:08<5:31:42, 331.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14934.252410502373
INFO:root:current train perplexity4.375986576080322
INFO:root:current mean train loss 14959.959388093575
INFO:root:current train perplexity4.3739142417907715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.12s/it]
INFO:root:final mean train loss: 14969.386978641633
INFO:root:final train perplexity: 4.377440452575684
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.91s/it]
INFO:root:eval mean loss: 22384.26843843006
INFO:root:eval perplexity: 10.141898155212402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/141

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [12:56:40<5:26:08, 331.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14949.529265372983
INFO:root:current train perplexity4.378324508666992
INFO:root:current mean train loss 14973.674208313454
INFO:root:current train perplexity4.3783769607543945
INFO:root:current mean train loss 14970.69582826028
INFO:root:current train perplexity4.375397205352783


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.44s/it]
INFO:root:final mean train loss: 14959.912995369205
INFO:root:final train perplexity: 4.373351097106934
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.27s/it]
INFO:root:eval mean loss: 22409.035109747023
INFO:root:eval perplexity: 10.167930603027344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/142

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [13:02:10<5:20:09, 331.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15031.684629141566
INFO:root:current train perplexity4.369113445281982
INFO:root:current mean train loss 14977.112486125341
INFO:root:current train perplexity4.367221355438232


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.84s/it]
INFO:root:final mean train loss: 14957.383363785282
INFO:root:final train perplexity: 4.372260093688965
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.50s/it]
INFO:root:eval mean loss: 22392.225771949405
INFO:root:eval perplexity: 10.150256156921387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/143

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [13:07:47<5:16:28, 333.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14887.5201171875
INFO:root:current train perplexity4.334177494049072
INFO:root:current mean train loss 14934.243974247685
INFO:root:current train perplexity4.3548383712768555
INFO:root:current mean train loss 14950.973150764628
INFO:root:current train perplexity4.36857795715332


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.79s/it]
INFO:root:final mean train loss: 14949.49185279108
INFO:root:final train perplexity: 4.368858337402344
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.12s/it]
INFO:root:eval mean loss: 22398.205078125
INFO:root:eval perplexity: 10.156538009643555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/144

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [13:13:11<5:08:23, 330.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14914.912075700431
INFO:root:current train perplexity4.351447582244873
INFO:root:current mean train loss 14959.403440424465
INFO:root:current train perplexity4.366232395172119


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.55s/it]
INFO:root:final mean train loss: 14939.379859185989
INFO:root:final train perplexity: 4.364502906799316
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.76s/it]
INFO:root:eval mean loss: 22405.61400204613
INFO:root:eval perplexity: 10.16433048248291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/145

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [13:18:40<5:02:25, 329.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14933.892603165064
INFO:root:current train perplexity4.349902153015137
INFO:root:current mean train loss 14936.048905406924
INFO:root:current train perplexity4.360291957855225
INFO:root:current mean train loss 14942.922120162133
INFO:root:current train perplexity4.361333847045898


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.48s/it]
INFO:root:final mean train loss: 14932.39638986895
INFO:root:final train perplexity: 4.3614983558654785
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.22s/it]
INFO:root:eval mean loss: 22397.718610491072
INFO:root:eval perplexity: 10.156026840209961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/146

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [13:24:13<4:57:49, 330.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14971.351498111264
INFO:root:current train perplexity4.351236343383789
INFO:root:current mean train loss 14928.769567040248
INFO:root:current train perplexity4.348917007446289


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.02s/it]
INFO:root:final mean train loss: 14924.76966907132
INFO:root:final train perplexity: 4.358218669891357
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.09s/it]
INFO:root:eval mean loss: 22407.686988467263
INFO:root:eval perplexity: 10.16650676727295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/147

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [13:29:42<4:51:38, 330.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14903.306504360466
INFO:root:current train perplexity4.349030017852783
INFO:root:current mean train loss 14908.347137237763
INFO:root:current train perplexity4.345640659332275
INFO:root:current mean train loss 14931.751028806584
INFO:root:current train perplexity4.3545732498168945


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.72s/it]
INFO:root:final mean train loss: 14916.727483933972
INFO:root:final train perplexity: 4.354763031005859
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.17s/it]
INFO:root:eval mean loss: 22404.118071056546
INFO:root:eval perplexity: 10.162755966186523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/148

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [13:35:08<4:45:06, 328.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14925.88302837171
INFO:root:current train perplexity4.350341320037842
INFO:root:current mean train loss 14912.79662459936
INFO:root:current train perplexity4.349827289581299


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.93s/it]
INFO:root:final mean train loss: 14912.327510710686
INFO:root:final train perplexity: 4.3528733253479
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.79s/it]
INFO:root:eval mean loss: 22401.313616071428
INFO:root:eval perplexity: 10.159810066223145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/149

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [13:40:43<4:41:15, 330.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14893.9892578125
INFO:root:current train perplexity4.339024543762207
INFO:root:current mean train loss 14885.547080941751
INFO:root:current train perplexity4.340129375457764
INFO:root:current mean train loss 14916.980674342105
INFO:root:current train perplexity4.3503007888793945


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.54s/it]
INFO:root:final mean train loss: 14906.195410943801
INFO:root:final train perplexity: 4.350241184234619
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.21s/it]
INFO:root:eval mean loss: 22410.884626116072
INFO:root:eval perplexity: 10.169877052307129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/150

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [13:46:13<4:35:22, 330.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14886.32120028409
INFO:root:current train perplexity4.337507724761963
INFO:root:current mean train loss 14881.077953242777
INFO:root:current train perplexity4.343789100646973


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.39s/it]
INFO:root:final mean train loss: 14898.256729618195
INFO:root:final train perplexity: 4.346836090087891
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.19s/it]
INFO:root:eval mean loss: 22412.483979724704
INFO:root:eval perplexity: 10.171560287475586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/151

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [13:51:35<4:27:44, 327.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14892.679170496323
INFO:root:current train perplexity4.347809791564941
INFO:root:current mean train loss 14884.428187086092
INFO:root:current train perplexity4.34136438369751


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.22s/it]
INFO:root:final mean train loss: 14900.167523784023
INFO:root:final train perplexity: 4.34765625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.68s/it]
INFO:root:eval mean loss: 22409.552432105655
INFO:root:eval perplexity: 10.16847038269043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/152

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [13:57:03<4:22:23, 327.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14914.138671875
INFO:root:current train perplexity4.3329267501831055
INFO:root:current mean train loss 14881.217545888956
INFO:root:current train perplexity4.336212635040283
INFO:root:current mean train loss 14898.566343711514
INFO:root:current train perplexity4.341928958892822


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.43s/it]
INFO:root:final mean train loss: 14886.567642704133
INFO:root:final train perplexity: 4.341827869415283
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.47s/it]
INFO:root:eval mean loss: 22416.00525483631
INFO:root:eval perplexity: 10.175268173217773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/153

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [14:02:30<4:16:43, 327.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14845.28799715909
INFO:root:current train perplexity4.319174766540527
INFO:root:current mean train loss 14864.728629032257
INFO:root:current train perplexity4.329784393310547


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.82s/it]
INFO:root:final mean train loss: 14880.426745999244
INFO:root:final train perplexity: 4.339199066162109
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.07s/it]
INFO:root:eval mean loss: 22411.28445870536
INFO:root:eval perplexity: 10.170293807983398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/154

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [14:08:02<4:12:18, 329.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14979.06821986607
INFO:root:current train perplexity4.388358116149902
INFO:root:current mean train loss 14846.46152161215
INFO:root:current train perplexity4.332525730133057
INFO:root:current mean train loss 14890.039614470108
INFO:root:current train perplexity4.337801933288574


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.87s/it]
INFO:root:final mean train loss: 14872.841592111896
INFO:root:final train perplexity: 4.335953712463379
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.60s/it]
INFO:root:eval mean loss: 22416.477678571428
INFO:root:eval perplexity: 10.175763130187988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/155

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [14:13:30<4:06:32, 328.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14900.249519994702
INFO:root:current train perplexity4.333186626434326
INFO:root:current mean train loss 14861.851666912342
INFO:root:current train perplexity4.330641746520996


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.30s/it]
INFO:root:final mean train loss: 14866.124558971775
INFO:root:final train perplexity: 4.33308219909668
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.20s/it]
INFO:root:eval mean loss: 22416.846237909227
INFO:root:eval perplexity: 10.176151275634766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/156

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [14:19:02<4:01:41, 329.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14842.570490056818
INFO:root:current train perplexity4.284976482391357
INFO:root:current mean train loss 14873.611328125
INFO:root:current train perplexity4.326590061187744
INFO:root:current mean train loss 14872.129470897511
INFO:root:current train perplexity4.328756809234619


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.49s/it]
INFO:root:final mean train loss: 14862.507686491936
INFO:root:final train perplexity: 4.331536769866943
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.88s/it]
INFO:root:eval mean loss: 22414.608468191964
INFO:root:eval perplexity: 10.173795700073242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/157

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [14:24:34<3:56:51, 330.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14791.324652777777
INFO:root:current train perplexity4.3177361488342285
INFO:root:current mean train loss 14868.156082246933
INFO:root:current train perplexity4.331132888793945


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.40s/it]
INFO:root:final mean train loss: 14856.550052765877
INFO:root:final train perplexity: 4.328991413116455
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.81s/it]
INFO:root:eval mean loss: 22416.194986979168
INFO:root:eval perplexity: 10.175464630126953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/158

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [14:30:17<3:53:52, 334.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14939.910807291666
INFO:root:current train perplexity4.332455158233643
INFO:root:current mean train loss 14871.967229959238
INFO:root:current train perplexity4.335009574890137
INFO:root:current mean train loss 14865.721829578488
INFO:root:current train perplexity4.328365325927734


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.76s/it]
INFO:root:final mean train loss: 14851.43115234375
INFO:root:final train perplexity: 4.326806545257568
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.52s/it]
INFO:root:eval mean loss: 22413.42898995536
INFO:root:eval perplexity: 10.172554016113281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/159

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [14:35:44<3:46:49, 331.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14834.54296875
INFO:root:current train perplexity4.312984943389893
INFO:root:current mean train loss 14839.411471977919
INFO:root:current train perplexity4.318685054779053


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.67s/it]
INFO:root:final mean train loss: 14847.342474168347
INFO:root:final train perplexity: 4.325062274932861
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.19s/it]
INFO:root:eval mean loss: 22416.199637276786
INFO:root:eval perplexity: 10.175472259521484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/160

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [14:41:04<3:39:03, 328.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14822.241365131578
INFO:root:current train perplexity4.3019280433654785
INFO:root:current mean train loss 14855.662265296743
INFO:root:current train perplexity4.320959568023682
INFO:root:current mean train loss 14840.251752461472
INFO:root:current train perplexity4.321928977966309


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.19s/it]
INFO:root:final mean train loss: 14840.11925875756
INFO:root:final train perplexity: 4.321981906890869
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.05s/it]
INFO:root:eval mean loss: 22424.162992931546
INFO:root:eval perplexity: 10.183859825134277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/161

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [14:46:27<3:32:23, 326.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14845.863611355633
INFO:root:current train perplexity4.308829307556152
INFO:root:current mean train loss 14839.401127330044
INFO:root:current train perplexity4.312549591064453


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.21s/it]
INFO:root:final mean train loss: 14835.06454763105
INFO:root:final train perplexity: 4.319828033447266
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.87s/it]
INFO:root:eval mean loss: 22422.096121651786
INFO:root:eval perplexity: 10.181682586669922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/162

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [14:51:51<3:26:28, 326.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14805.567255434782
INFO:root:current train perplexity4.319850444793701
INFO:root:current mean train loss 14875.388147865853
INFO:root:current train perplexity4.321488857269287
INFO:root:current mean train loss 14837.57033439602
INFO:root:current train perplexity4.313778400421143


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.66s/it]
INFO:root:final mean train loss: 14826.74404611895
INFO:root:final train perplexity: 4.316283226013184
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.47s/it]
INFO:root:eval mean loss: 22417.371744791668
INFO:root:eval perplexity: 10.17670726776123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/163

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [14:57:09<3:19:25, 323.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14814.188645833334
INFO:root:current train perplexity4.32570219039917
INFO:root:current mean train loss 14820.8751953125
INFO:root:current train perplexity4.315279006958008


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:30<00:00, 270.42s/it]
INFO:root:final mean train loss: 14827.853499873992
INFO:root:final train perplexity: 4.316756248474121
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.67s/it]
INFO:root:eval mean loss: 22423.475771949405
INFO:root:eval perplexity: 10.183136940002441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/164

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [15:02:24<3:12:34, 320.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14860.844147858796
INFO:root:current train perplexity4.305840492248535
INFO:root:current mean train loss 14856.237473855806
INFO:root:current train perplexity4.326502799987793
INFO:root:current mean train loss 14836.800854384637
INFO:root:current train perplexity4.31603479385376


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.73s/it]
INFO:root:final mean train loss: 14817.427734375
INFO:root:final train perplexity: 4.312320232391357
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.76s/it]
INFO:root:eval mean loss: 22422.796944754464
INFO:root:eval perplexity: 10.182422637939453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/165

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [15:07:49<3:07:53, 322.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14850.178958168513
INFO:root:current train perplexity4.319223403930664
INFO:root:current mean train loss 14840.60571425454
INFO:root:current train perplexity4.314676761627197


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.41s/it]
INFO:root:final mean train loss: 14813.086441532258
INFO:root:final train perplexity: 4.310473442077637
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.97s/it]
INFO:root:eval mean loss: 22426.76648530506
INFO:root:eval perplexity: 10.186606407165527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/166

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [15:13:19<3:03:57, 324.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14833.963237147178
INFO:root:current train perplexity4.306792736053467
INFO:root:current mean train loss 14832.363012881679
INFO:root:current train perplexity4.305077075958252
INFO:root:current mean train loss 14825.365564123376
INFO:root:current train perplexity4.310573101043701


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.65s/it]
INFO:root:final mean train loss: 14810.734130859375
INFO:root:final train perplexity: 4.309473991394043
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.26s/it]
INFO:root:eval mean loss: 22428.833937872023
INFO:root:eval perplexity: 10.188785552978516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/167

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [15:18:46<2:58:50, 325.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14792.20938441265
INFO:root:current train perplexity4.297293186187744
INFO:root:current mean train loss 14822.564341060452
INFO:root:current train perplexity4.304574966430664


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.49s/it]
INFO:root:final mean train loss: 14802.277044480847
INFO:root:final train perplexity: 4.305880069732666
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.66s/it]
INFO:root:eval mean loss: 22428.140648251487
INFO:root:eval perplexity: 10.188054084777832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/168

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [15:24:06<2:52:37, 323.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14941.161690848214
INFO:root:current train perplexity4.336910724639893
INFO:root:current mean train loss 14798.69581886574
INFO:root:current train perplexity4.299719333648682
INFO:root:current mean train loss 14818.178586269947
INFO:root:current train perplexity4.3066205978393555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.63s/it]
INFO:root:final mean train loss: 14798.92964812248
INFO:root:final train perplexity: 4.3044586181640625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.41s/it]
INFO:root:eval mean loss: 22424.454148065477
INFO:root:eval perplexity: 10.184168815612793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/169

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [15:29:36<2:48:16, 325.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14791.764300466954
INFO:root:current train perplexity4.302546501159668
INFO:root:current mean train loss 14792.18497242647
INFO:root:current train perplexity4.300689697265625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.95s/it]
INFO:root:final mean train loss: 14794.388585244456
INFO:root:final train perplexity: 4.302531719207764
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.56s/it]
INFO:root:eval mean loss: 22432.571126302082
INFO:root:eval perplexity: 10.192728996276855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/170

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [15:35:15<2:44:48, 329.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14708.455528846154
INFO:root:current train perplexity4.267036437988281
INFO:root:current mean train loss 14766.655238309353
INFO:root:current train perplexity4.29784631729126
INFO:root:current mean train loss 14799.474642063284
INFO:root:current train perplexity4.302554607391357


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.74s/it]
INFO:root:final mean train loss: 14791.260289346019
INFO:root:final train perplexity: 4.301204681396484
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.45s/it]
INFO:root:eval mean loss: 22432.061430431546
INFO:root:eval perplexity: 10.19218921661377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/171

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [15:40:47<2:39:39, 330.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14834.201450892857
INFO:root:current train perplexity4.318620204925537
INFO:root:current mean train loss 14788.348244232657
INFO:root:current train perplexity4.300538063049316


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.67s/it]
INFO:root:final mean train loss: 14790.822627898186
INFO:root:final train perplexity: 4.301018238067627
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.72s/it]
INFO:root:eval mean loss: 22430.35086495536
INFO:root:eval perplexity: 10.190385818481445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/172

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [15:46:14<2:33:46, 329.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14755.015011809593
INFO:root:current train perplexity4.292806148529053
INFO:root:current mean train loss 14805.818284254809
INFO:root:current train perplexity4.3011794090271
INFO:root:current mean train loss 14800.417767811214
INFO:root:current train perplexity4.298943042755127


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.01s/it]
INFO:root:final mean train loss: 14786.415917181199
INFO:root:final train perplexity: 4.299149990081787
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.73s/it]
INFO:root:eval mean loss: 22434.704427083332
INFO:root:eval perplexity: 10.194978713989258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/173

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [15:51:45<2:28:27, 329.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14806.944058388159
INFO:root:current train perplexity4.295241832733154
INFO:root:current mean train loss 14801.099814703526
INFO:root:current train perplexity4.296954154968262


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.00s/it]
INFO:root:final mean train loss: 14779.886435231854
INFO:root:final train perplexity: 4.296382427215576
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.40s/it]
INFO:root:eval mean loss: 22435.610398065477
INFO:root:eval perplexity: 10.195934295654297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/174

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [15:57:20<2:23:35, 331.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14694.240213597075
INFO:root:current train perplexity4.268365859985352
INFO:root:current mean train loss 14763.349881749575
INFO:root:current train perplexity4.283480644226074
INFO:root:current mean train loss 14785.829587866903
INFO:root:current train perplexity4.294213771820068


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.37s/it]
INFO:root:final mean train loss: 14773.951593214466
INFO:root:final train perplexity: 4.293867111206055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.44s/it]
INFO:root:eval mean loss: 22433.91580636161
INFO:root:eval perplexity: 10.194145202636719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/175

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [16:02:50<2:17:54, 330.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14769.026081123737
INFO:root:current train perplexity4.2877984046936035
INFO:root:current mean train loss 14779.275694880653
INFO:root:current train perplexity4.291447639465332


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.31s/it]
INFO:root:final mean train loss: 14777.25105531754
INFO:root:final train perplexity: 4.295265197753906
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.62s/it]
INFO:root:eval mean loss: 22432.50695219494
INFO:root:eval perplexity: 10.192660331726074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/176

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [16:08:25<2:12:54, 332.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14769.638671875
INFO:root:current train perplexity4.273004531860352
INFO:root:current mean train loss 14767.439718284355
INFO:root:current train perplexity4.283962249755859


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.66s/it]
INFO:root:final mean train loss: 14771.176100207913
INFO:root:final train perplexity: 4.292692184448242
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.92s/it]
INFO:root:eval mean loss: 22436.674665178572
INFO:root:eval perplexity: 10.197054862976074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/177

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [16:14:02<2:07:54, 333.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14777.483723958334
INFO:root:current train perplexity4.266778469085693
INFO:root:current mean train loss 14754.688969584344
INFO:root:current train perplexity4.28499698638916
INFO:root:current mean train loss 14784.045855141625
INFO:root:current train perplexity4.289010047912598


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:32<00:00, 272.01s/it]
INFO:root:final mean train loss: 14762.841029013356
INFO:root:final train perplexity: 4.2891645431518555
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.95s/it]
INFO:root:eval mean loss: 22442.144066220237
INFO:root:eval perplexity: 10.202828407287598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/178

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [16:19:26<2:01:11, 330.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14829.5728515625
INFO:root:current train perplexity4.2842841148376465
INFO:root:current mean train loss 14802.537701612904
INFO:root:current train perplexity4.292410373687744


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.15s/it]
INFO:root:final mean train loss: 14767.912396830898
INFO:root:final train perplexity: 4.291310787200928
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.90s/it]
INFO:root:eval mean loss: 22437.575520833332
INFO:root:eval perplexity: 10.198005676269531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/179

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [16:25:04<1:56:30, 332.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14692.618722098214
INFO:root:current train perplexity4.2734174728393555
INFO:root:current mean train loss 14745.067045122663
INFO:root:current train perplexity4.287908554077148
INFO:root:current mean train loss 14771.336961239433
INFO:root:current train perplexity4.287991046905518


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:36<00:00, 276.52s/it]
INFO:root:final mean train loss: 14763.054348853326
INFO:root:final train perplexity: 4.289255142211914
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.66s/it]
INFO:root:eval mean loss: 22437.812546502977
INFO:root:eval perplexity: 10.198258399963379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/180

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [16:30:30<1:50:19, 330.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14734.961649231991
INFO:root:current train perplexity4.285560607910156
INFO:root:current mean train loss 14743.91166715802
INFO:root:current train perplexity4.278986930847168


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.06s/it]
INFO:root:final mean train loss: 14758.727535124748
INFO:root:final train perplexity: 4.2874250411987305
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.06s/it]
INFO:root:eval mean loss: 22441.975120907737
INFO:root:eval perplexity: 10.202655792236328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/181

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [16:36:01<1:44:44, 330.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14847.541459517046
INFO:root:current train perplexity4.269299507141113
INFO:root:current mean train loss 14783.661308769708
INFO:root:current train perplexity4.289336204528809
INFO:root:current mean train loss 14771.269725636848
INFO:root:current train perplexity4.287575721740723


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:34<00:00, 274.79s/it]
INFO:root:final mean train loss: 14752.432751071068
INFO:root:final train perplexity: 4.284763336181641
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.69s/it]
INFO:root:eval mean loss: 22440.642136346727
INFO:root:eval perplexity: 10.201245307922363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/182

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [16:41:23<1:38:27, 328.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14702.456922743055
INFO:root:current train perplexity4.274028778076172
INFO:root:current mean train loss 14746.3469313171
INFO:root:current train perplexity4.277527809143066


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.35s/it]
INFO:root:final mean train loss: 14753.36749858241
INFO:root:final train perplexity: 4.285158634185791
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.93s/it]
INFO:root:eval mean loss: 22439.87765066964
INFO:root:eval perplexity: 10.200437545776367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/183

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [16:46:52<1:33:01, 328.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14726.4640625
INFO:root:current train perplexity4.296812057495117
INFO:root:current mean train loss 14763.781844429348
INFO:root:current train perplexity4.288070201873779
INFO:root:current mean train loss 14759.736950399709
INFO:root:current train perplexity4.283209323883057


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.29s/it]
INFO:root:final mean train loss: 14748.242707283267
INFO:root:final train perplexity: 4.282993316650391
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.13s/it]
INFO:root:eval mean loss: 22438.60621279762
INFO:root:eval perplexity: 10.199097633361816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/184

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [16:52:26<1:28:03, 330.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14770.200763759329
INFO:root:current train perplexity4.271941184997559
INFO:root:current mean train loss 14748.168576908683
INFO:root:current train perplexity4.27564811706543


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.98s/it]
INFO:root:final mean train loss: 14744.2330046623
INFO:root:final train perplexity: 4.281299591064453
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.69s/it]
INFO:root:eval mean loss: 22443.529761904763
INFO:root:eval perplexity: 10.204293251037598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/185

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [16:57:51<1:22:10, 328.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14685.298159950658
INFO:root:current train perplexity4.259681701660156
INFO:root:current mean train loss 14737.615989364496
INFO:root:current train perplexity4.2805962562561035
INFO:root:current mean train loss 14765.143327268835
INFO:root:current train perplexity4.283763885498047


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.88s/it]
INFO:root:final mean train loss: 14743.937925277218
INFO:root:final train perplexity: 4.281174659729004
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.41s/it]
INFO:root:eval mean loss: 22437.002859933036
INFO:root:eval perplexity: 10.197402954101562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/186

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [17:03:17<1:16:29, 327.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14764.279228102992
INFO:root:current train perplexity4.277860641479492
INFO:root:current mean train loss 14773.794253700658
INFO:root:current train perplexity4.282128810882568


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.44s/it]
INFO:root:final mean train loss: 14741.815307617188
INFO:root:final train perplexity: 4.280279159545898
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.78s/it]
INFO:root:eval mean loss: 22441.801199776786
INFO:root:eval perplexity: 10.202467918395996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/187

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [17:08:51<1:11:23, 329.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14789.903532608696
INFO:root:current train perplexity4.265395641326904
INFO:root:current mean train loss 14737.675757431403
INFO:root:current train perplexity4.275301456451416
INFO:root:current mean train loss 14757.015686308856
INFO:root:current train perplexity4.281914234161377


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.78s/it]
INFO:root:final mean train loss: 14743.134167086693
INFO:root:final train perplexity: 4.28083610534668
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.08s/it]
INFO:root:eval mean loss: 22440.751627604168
INFO:root:eval perplexity: 10.201358795166016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/188

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [17:14:13<1:05:28, 327.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14764.118658854166
INFO:root:current train perplexity4.283787727355957
INFO:root:current mean train loss 14730.554034598214
INFO:root:current train perplexity4.274511814117432


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.17s/it]
INFO:root:final mean train loss: 14738.097156155494
INFO:root:final train perplexity: 4.278709411621094
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.36s/it]
INFO:root:eval mean loss: 22441.702962239582
INFO:root:eval perplexity: 10.202363967895508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/189

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [17:19:37<59:49, 326.32s/it]  

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14684.355649594907
INFO:root:current train perplexity4.26268196105957
INFO:root:current mean train loss 14722.86266609252
INFO:root:current train perplexity4.276248455047607
INFO:root:current mean train loss 14738.698956325716
INFO:root:current train perplexity4.275906085968018


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:35<00:00, 275.40s/it]
INFO:root:final mean train loss: 14737.015404485886
INFO:root:final train perplexity: 4.278253078460693
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.08s/it]
INFO:root:eval mean loss: 22445.69556826637
INFO:root:eval perplexity: 10.206582069396973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/190

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [17:24:58<54:06, 324.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14800.128473595727
INFO:root:current train perplexity4.282326698303223
INFO:root:current mean train loss 14746.696747337639
INFO:root:current train perplexity4.277324199676514


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.78s/it]
INFO:root:final mean train loss: 14737.40665952621
INFO:root:final train perplexity: 4.278417587280273
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.77s/it]
INFO:root:eval mean loss: 22441.84591238839
INFO:root:eval perplexity: 10.2025146484375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/191

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [17:30:18<48:29, 323.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14840.461473034275
INFO:root:current train perplexity4.280062675476074
INFO:root:current mean train loss 14785.702707538168
INFO:root:current train perplexity4.281350135803223
INFO:root:current mean train loss 14740.434540719696
INFO:root:current train perplexity4.276042938232422


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.20s/it]
INFO:root:final mean train loss: 14735.540365895917
INFO:root:final train perplexity: 4.277630805969238
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.77s/it]
INFO:root:eval mean loss: 22444.71168154762
INFO:root:eval perplexity: 10.205540657043457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/192

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [17:35:38<42:58, 322.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14723.796627917922
INFO:root:current train perplexity4.273858547210693
INFO:root:current mean train loss 14728.808348275274
INFO:root:current train perplexity4.2733635902404785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.22s/it]
INFO:root:final mean train loss: 14730.252307522682
INFO:root:final train perplexity: 4.275399684906006
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.95s/it]
INFO:root:eval mean loss: 22445.549246651786
INFO:root:eval perplexity: 10.206426620483398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/193

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [17:40:52<37:18, 319.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14745.952036830357
INFO:root:current train perplexity4.299441337585449
INFO:root:current mean train loss 14743.197142650462
INFO:root:current train perplexity4.275285720825195
INFO:root:current mean train loss 14743.139295212766
INFO:root:current train perplexity4.273418426513672


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:33<00:00, 273.08s/it]
INFO:root:final mean train loss: 14727.308971774193
INFO:root:final train perplexity: 4.274158954620361
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.86s/it]
INFO:root:eval mean loss: 22441.192964099704
INFO:root:eval perplexity: 10.201826095581055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/194

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [17:46:10<31:55, 319.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14701.14712419181
INFO:root:current train perplexity4.269649982452393
INFO:root:current mean train loss 14724.18204796123
INFO:root:current train perplexity4.2719502449035645


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:29<00:00, 269.48s/it]
INFO:root:final mean train loss: 14727.139152280746
INFO:root:final train perplexity: 4.274087905883789
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.51s/it]
INFO:root:eval mean loss: 22442.850655691964
INFO:root:eval perplexity: 10.203575134277344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/195

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [17:51:27<26:33, 318.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14804.529071514424
INFO:root:current train perplexity4.292519569396973
INFO:root:current mean train loss 14732.310603080035
INFO:root:current train perplexity4.273274898529053
INFO:root:current mean train loss 14738.155976235617
INFO:root:current train perplexity4.27399206161499


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:27<00:00, 267.76s/it]
INFO:root:final mean train loss: 14726.345687373992
INFO:root:final train perplexity: 4.273753643035889
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.27s/it]
INFO:root:eval mean loss: 22446.7333984375
INFO:root:eval perplexity: 10.207677841186523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/196

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [17:56:50<21:20, 320.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14772.782913375688
INFO:root:current train perplexity4.282255172729492
INFO:root:current mean train loss 14751.627674042866
INFO:root:current train perplexity4.278916358947754


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.46s/it]
INFO:root:final mean train loss: 14725.217119770665
INFO:root:final train perplexity: 4.273277282714844
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.87s/it]
INFO:root:eval mean loss: 22443.363304501487
INFO:root:eval perplexity: 10.204117774963379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/197

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [18:02:37<16:23, 327.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14739.72417787064
INFO:root:current train perplexity4.269434452056885
INFO:root:current mean train loss 14736.11408708479
INFO:root:current train perplexity4.268019676208496
INFO:root:current mean train loss 14739.932986914866
INFO:root:current train perplexity4.274608612060547


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:31<00:00, 271.41s/it]
INFO:root:final mean train loss: 14727.67704920615
INFO:root:final train perplexity: 4.274313449859619
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.81s/it]
INFO:root:eval mean loss: 22445.926083519345
INFO:root:eval perplexity: 10.206826210021973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/198

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [18:07:59<10:52, 326.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14757.445518092105
INFO:root:current train perplexity4.283154487609863
INFO:root:current mean train loss 14744.486438301283
INFO:root:current train perplexity4.2762556076049805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:38<00:00, 278.64s/it]
INFO:root:final mean train loss: 14727.21330015121
INFO:root:final train perplexity: 4.274118900299072
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.93s/it]
INFO:root:eval mean loss: 22445.707124255954
INFO:root:eval perplexity: 10.206592559814453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [18:13:24<05:25, 325.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14709.52455950798
INFO:root:current train perplexity4.262057781219482
INFO:root:current mean train loss 14720.24767485119
INFO:root:current train perplexity4.270634174346924
INFO:root:current mean train loss 14734.83520606655
INFO:root:current train perplexity4.27255916595459


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.36s/it]
INFO:root:final mean train loss: 14723.034388388356
INFO:root:final train perplexity: 4.2723565101623535
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.36s/it]
INFO:root:eval mean loss: 22445.113234747023
INFO:root:eval perplexity: 10.20596694946289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_4/200

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [18:19:07<00:00, 331.03s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [18:19:07<00:00, 329.74s/it]
INFO:root:evaluating final model
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.81s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.81s/it]
INFO:root:eval mean loss: 22445.113234747023
INFO:root:eval perplexity: 10.20596694946289
INFO:root:evalaution complete
INFO:root:save model final: small_window_4/final
