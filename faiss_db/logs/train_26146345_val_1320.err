INFO:root:Output: small_val_1320
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.query.bias', 'cls.predictions.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'cls.predictions.decoder.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.key.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.key.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.value.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/200 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24457.64912799874
INFO:root:current train perplexity15517.4013671875
INFO:root:current mean train loss 20541.513117344533
INFO:root:current train perplexity3280.17041015625
INFO:root:current mean train loss 17747.43378318353
INFO:root:current train perplexity1093.3885498046875
INFO:root:current mean train loss 15854.553608141447
INFO:root:current train perplexity514.058837890625
INFO:root:current mean train loss 14480.90223904841
INFO:root:current train perplexity299.12554931640625
INFO:root:current mean train loss 13438.16680225506
INFO:root:current train perplexity198.94281005859375
INFO:root:current mean train loss 12626.943067384209
INFO:root:current train perplexity144.4793243408203
INFO:root:current mean train loss 11976.554888556986
INFO:root:current train perplexity112.0719985961914
INFO:root:current mean train loss 11444.111610556869
INFO:root:current train perplexity90.89804077148438


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.07s/it]
INFO:root:final mean train loss: 11014.745699728688
INFO:root:final train perplexity: 77.14107513427734
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.03s/it]
INFO:root:eval mean loss: 6415.216900764628
INFO:root:eval perplexity: 13.38487720489502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/1

  0%|          | 1/200 [03:09<10:29:46, 189.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6822.295340401785
INFO:root:current train perplexity14.503082275390625
INFO:root:current mean train loss 6731.059246312792
INFO:root:current train perplexity14.398280143737793
INFO:root:current mean train loss 6702.426802630585
INFO:root:current train perplexity14.159919738769531
INFO:root:current mean train loss 6630.102749007533
INFO:root:current train perplexity13.736698150634766
INFO:root:current mean train loss 6576.365188786087
INFO:root:current train perplexity13.435806274414062
INFO:root:current mean train loss 6526.401920958148
INFO:root:current train perplexity13.165980339050293
INFO:root:current mean train loss 6483.721722321612
INFO:root:current train perplexity12.895609855651855
INFO:root:current mean train loss 6436.004429063163
INFO:root:current train perplexity12.653849601745605
INFO:root:current mean train loss 6391.83387183434
INFO:root:current train perplexity12.428101539611816
INFO:root:current mean train loss 6347.222228802026
INFO:root:current train perplexity12.223557472229004


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:37<00:00, 157.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:37<00:00, 157.29s/it]
INFO:root:final mean train loss: 6310.10290404289
INFO:root:final train perplexity: 12.055465698242188
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.96s/it]
INFO:root:eval mean loss: 5542.52315007203
INFO:root:eval perplexity: 9.404926300048828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/2

  1%|          | 2/200 [06:47<11:19:43, 205.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5986.01630859375
INFO:root:current train perplexity10.632960319519043
INFO:root:current mean train loss 5881.399222995924
INFO:root:current train perplexity10.239191055297852
INFO:root:current mean train loss 5860.117048964389
INFO:root:current train perplexity10.102493286132812
INFO:root:current mean train loss 5839.727869233631
INFO:root:current train perplexity9.988853454589844
INFO:root:current mean train loss 5815.5556875941265
INFO:root:current train perplexity9.899792671203613
INFO:root:current mean train loss 5790.832512894417
INFO:root:current train perplexity9.816007614135742
INFO:root:current mean train loss 5766.298832094766
INFO:root:current train perplexity9.736795425415039
INFO:root:current mean train loss 5747.45667340472
INFO:root:current train perplexity9.658775329589844
INFO:root:current mean train loss 5734.41383243865
INFO:root:current train perplexity9.588340759277344
INFO:root:current mean train loss 5715.749388981387
INFO:root:current train perplexity9.50529670715332


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.01s/it]
INFO:root:final mean train loss: 5692.143442461567
INFO:root:final train perplexity: 9.447171211242676
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.66s/it]
INFO:root:eval mean loss: 5178.112786042775
INFO:root:eval perplexity: 8.11631965637207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/3

  2%|â–         | 3/200 [10:44<12:02:49, 220.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5564.92724609375
INFO:root:current train perplexity8.821584701538086
INFO:root:current mean train loss 5485.635404757368
INFO:root:current train perplexity8.718238830566406
INFO:root:current mean train loss 5484.150241732063
INFO:root:current train perplexity8.656365394592285
INFO:root:current mean train loss 5457.348950270898
INFO:root:current train perplexity8.576054573059082
INFO:root:current mean train loss 5444.707033558659
INFO:root:current train perplexity8.550862312316895
INFO:root:current mean train loss 5428.001477914376
INFO:root:current train perplexity8.495929718017578
INFO:root:current mean train loss 5418.340339085073
INFO:root:current train perplexity8.463842391967773
INFO:root:current mean train loss 5408.771674824948
INFO:root:current train perplexity8.429821968078613
INFO:root:current mean train loss 5397.819315172198
INFO:root:current train perplexity8.393059730529785
INFO:root:current mean train loss 5387.016482534026
INFO:root:current train perplexity8.3577299118042


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.02s/it]
INFO:root:final mean train loss: 5375.714342055782
INFO:root:final train perplexity: 8.338427543640137
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.24s/it]
INFO:root:eval mean loss: 4956.617159796099
INFO:root:eval perplexity: 7.420976161956787
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/4

  2%|â–         | 4/200 [13:40<11:02:14, 202.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5319.303474672379
INFO:root:current train perplexity7.965194225311279
INFO:root:current mean train loss 5239.957761808206
INFO:root:current train perplexity7.882691383361816
INFO:root:current mean train loss 5241.622442336309
INFO:root:current train perplexity7.902468204498291
INFO:root:current mean train loss 5230.742565143504
INFO:root:current train perplexity7.8556294441223145
INFO:root:current mean train loss 5224.667859991299
INFO:root:current train perplexity7.825003623962402
INFO:root:current mean train loss 5214.900918446916
INFO:root:current train perplexity7.797323703765869
INFO:root:current mean train loss 5207.525375922395
INFO:root:current train perplexity7.7736735343933105
INFO:root:current mean train loss 5199.427770445024
INFO:root:current train perplexity7.757144451141357
INFO:root:current mean train loss 5186.3516606263165
INFO:root:current train perplexity7.733112812042236
INFO:root:current mean train loss 5177.782123241977
INFO:root:current train perplexity7.70198392868042


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.36s/it]
INFO:root:final mean train loss: 5168.210213815012
INFO:root:final train perplexity: 7.682984828948975
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.89s/it]
INFO:root:eval mean loss: 4816.85197805851
INFO:root:eval perplexity: 7.013195991516113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/5

  2%|â–Ž         | 5/200 [16:24<10:13:53, 188.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5077.9157151442305
INFO:root:current train perplexity7.331945419311523
INFO:root:current mean train loss 5068.8101991063395
INFO:root:current train perplexity7.389825820922852
INFO:root:current mean train loss 5077.611154468488
INFO:root:current train perplexity7.403443813323975
INFO:root:current mean train loss 5060.56732087712
INFO:root:current train perplexity7.341488361358643
INFO:root:current mean train loss 5057.783612435934
INFO:root:current train perplexity7.330009937286377
INFO:root:current mean train loss 5045.923666874421
INFO:root:current train perplexity7.307467937469482
INFO:root:current mean train loss 5037.897353958822
INFO:root:current train perplexity7.286711692810059
INFO:root:current mean train loss 5038.043815808948
INFO:root:current train perplexity7.282402038574219
INFO:root:current mean train loss 5034.004541190219
INFO:root:current train perplexity7.265598773956299
INFO:root:current mean train loss 5025.9798338283745
INFO:root:current train perplexity7.250060081481934


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.51s/it]
INFO:root:final mean train loss: 5017.31540156949
INFO:root:final train perplexity: 7.238949298858643
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.70s/it]
INFO:root:eval mean loss: 4700.834870899823
INFO:root:eval perplexity: 6.691778659820557
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/6

  3%|â–Ž         | 6/200 [19:14<9:50:15, 182.56s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4891.94737990359
INFO:root:current train perplexity6.933472156524658
INFO:root:current mean train loss 4941.043958599064
INFO:root:current train perplexity6.997175693511963
INFO:root:current mean train loss 4923.4895721312
INFO:root:current train perplexity6.981865882873535
INFO:root:current mean train loss 4923.705877386527
INFO:root:current train perplexity6.974120616912842
INFO:root:current mean train loss 4920.861364172609
INFO:root:current train perplexity6.963615894317627
INFO:root:current mean train loss 4912.416423567471
INFO:root:current train perplexity6.943093299865723
INFO:root:current mean train loss 4911.5538965900305
INFO:root:current train perplexity6.9387054443359375
INFO:root:current mean train loss 4908.318025356635
INFO:root:current train perplexity6.926230430603027
INFO:root:current mean train loss 4904.823309636032
INFO:root:current train perplexity6.917798042297363
INFO:root:current mean train loss 4902.413251447829
INFO:root:current train perplexity6.906408786773682


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.75s/it]
INFO:root:final mean train loss: 4897.5479544362715
INFO:root:final train perplexity: 6.904852390289307
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.05s/it]
INFO:root:eval mean loss: 4615.464814314605
INFO:root:eval perplexity: 6.464712142944336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/7

  4%|â–Ž         | 7/200 [22:16<9:46:08, 182.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4790.457550603694
INFO:root:current train perplexity6.707231044769287
INFO:root:current mean train loss 4842.864599609375
INFO:root:current train perplexity6.769451141357422
INFO:root:current mean train loss 4833.987531594669
INFO:root:current train perplexity6.720658779144287
INFO:root:current mean train loss 4833.14228171765
INFO:root:current train perplexity6.713150501251221
INFO:root:current mean train loss 4827.039980576064
INFO:root:current train perplexity6.695424556732178
INFO:root:current mean train loss 4820.994684772663
INFO:root:current train perplexity6.677561283111572
INFO:root:current mean train loss 4819.361368007514
INFO:root:current train perplexity6.674936294555664
INFO:root:current mean train loss 4821.1756121300705
INFO:root:current train perplexity6.670335292816162
INFO:root:current mean train loss 4812.37595914428
INFO:root:current train perplexity6.654303550720215
INFO:root:current mean train loss 4805.347934135717
INFO:root:current train perplexity6.646810054779053


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.76s/it]
INFO:root:final mean train loss: 4800.754096738754
INFO:root:final train perplexity: 6.64614200592041
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.75s/it]
INFO:root:eval mean loss: 4541.144794437057
INFO:root:eval perplexity: 6.273320198059082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/8

  4%|â–         | 8/200 [25:40<10:05:17, 189.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4747.798735119048
INFO:root:current train perplexity6.451314449310303
INFO:root:current mean train loss 4734.965065423697
INFO:root:current train perplexity6.468891620635986
INFO:root:current mean train loss 4727.7935053024
INFO:root:current train perplexity6.464591979980469
INFO:root:current mean train loss 4737.437545734332
INFO:root:current train perplexity6.4619317054748535
INFO:root:current mean train loss 4741.443722158478
INFO:root:current train perplexity6.470673561096191
INFO:root:current mean train loss 4733.274780923901
INFO:root:current train perplexity6.457141876220703
INFO:root:current mean train loss 4730.396636824802
INFO:root:current train perplexity6.454217433929443
INFO:root:current mean train loss 4728.326811824214
INFO:root:current train perplexity6.446544170379639
INFO:root:current mean train loss 4723.2032053429175
INFO:root:current train perplexity6.4375
INFO:root:current mean train loss 4719.8475487571395
INFO:root:current train perplexity6.428668975830078


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:42<00:00, 162.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:42<00:00, 162.91s/it]
INFO:root:final mean train loss: 4717.69439241963
INFO:root:final train perplexity: 6.431880474090576
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.51s/it]
INFO:root:eval mean loss: 4484.083134211547
INFO:root:eval perplexity: 6.1302266120910645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/9

  4%|â–         | 9/200 [28:37<9:50:34, 185.52s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4640.7275390625
INFO:root:current train perplexity6.210853576660156
INFO:root:current mean train loss 4652.709201388889
INFO:root:current train perplexity6.263404369354248
INFO:root:current mean train loss 4674.488551516374
INFO:root:current train perplexity6.298135280609131
INFO:root:current mean train loss 4668.444542568649
INFO:root:current train perplexity6.285561561584473
INFO:root:current mean train loss 4661.980213724124
INFO:root:current train perplexity6.281851291656494
INFO:root:current mean train loss 4662.085678394538
INFO:root:current train perplexity6.2766218185424805
INFO:root:current mean train loss 4663.677316679862
INFO:root:current train perplexity6.282012462615967
INFO:root:current mean train loss 4654.002728928543
INFO:root:current train perplexity6.268316268920898
INFO:root:current mean train loss 4656.632213780856
INFO:root:current train perplexity6.266123294830322
INFO:root:current mean train loss 4652.76621234552
INFO:root:current train perplexity6.2600579261779785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.48s/it]
INFO:root:final mean train loss: 4648.532597695627
INFO:root:final train perplexity: 6.258751392364502
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.06s/it]
INFO:root:eval mean loss: 4439.534449800532
INFO:root:eval perplexity: 6.020784378051758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/10

  5%|â–Œ         | 10/200 [31:24<9:28:59, 179.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4637.868949020965
INFO:root:current train perplexity6.144427299499512
INFO:root:current mean train loss 4598.784037840433
INFO:root:current train perplexity6.107964515686035
INFO:root:current mean train loss 4608.073196684588
INFO:root:current train perplexity6.119995594024658
INFO:root:current mean train loss 4601.451633101088
INFO:root:current train perplexity6.120640277862549
INFO:root:current mean train loss 4606.472311700809
INFO:root:current train perplexity6.1224470138549805
INFO:root:current mean train loss 4599.349329393351
INFO:root:current train perplexity6.120542049407959
INFO:root:current mean train loss 4598.494211458142
INFO:root:current train perplexity6.11700439453125
INFO:root:current mean train loss 4596.582941057746
INFO:root:current train perplexity6.113806247711182
INFO:root:current mean train loss 4591.036806907263
INFO:root:current train perplexity6.109612941741943
INFO:root:current mean train loss 4590.374739400457
INFO:root:current train perplexity6.109841823577881


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.48s/it]
INFO:root:final mean train loss: 4587.566157371767
INFO:root:final train perplexity: 6.110005855560303
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.04s/it]
INFO:root:eval mean loss: 4392.64977940769
INFO:root:eval perplexity: 5.907711982727051
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/11

  6%|â–Œ         | 11/200 [34:08<9:11:24, 175.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4534.43214293732
INFO:root:current train perplexity5.965359687805176
INFO:root:current mean train loss 4555.89233267881
INFO:root:current train perplexity5.998946666717529
INFO:root:current mean train loss 4545.716847914852
INFO:root:current train perplexity5.9791951179504395
INFO:root:current mean train loss 4545.77297697634
INFO:root:current train perplexity5.991856098175049
INFO:root:current mean train loss 4542.494654473338
INFO:root:current train perplexity5.989201068878174
INFO:root:current mean train loss 4539.128825978892
INFO:root:current train perplexity5.983185768127441
INFO:root:current mean train loss 4538.1854701146285
INFO:root:current train perplexity5.9835896492004395
INFO:root:current mean train loss 4535.015172703899
INFO:root:current train perplexity5.976639747619629
INFO:root:current mean train loss 4536.130635327121
INFO:root:current train perplexity5.978494644165039
INFO:root:current mean train loss 4535.963472406915
INFO:root:current train perplexity5.978850841522217


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.63s/it]
INFO:root:final mean train loss: 4532.581301596857
INFO:root:final train perplexity: 5.978888034820557
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.46s/it]
INFO:root:eval mean loss: 4356.060579773382
INFO:root:eval perplexity: 5.820947647094727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/12

  6%|â–Œ         | 12/200 [37:02<9:06:47, 174.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4500.5628469366775
INFO:root:current train perplexity5.889614105224609
INFO:root:current mean train loss 4484.020788261218
INFO:root:current train perplexity5.880679130554199
INFO:root:current mean train loss 4488.708315677966
INFO:root:current train perplexity5.890732765197754
INFO:root:current mean train loss 4482.301574861551
INFO:root:current train perplexity5.876048564910889
INFO:root:current mean train loss 4488.274399266098
INFO:root:current train perplexity5.877264022827148
INFO:root:current mean train loss 4482.663269350709
INFO:root:current train perplexity5.873102188110352
INFO:root:current mean train loss 4480.152144222122
INFO:root:current train perplexity5.86909818649292
INFO:root:current mean train loss 4484.204750454501
INFO:root:current train perplexity5.863696098327637
INFO:root:current mean train loss 4485.939341284044
INFO:root:current train perplexity5.866238594055176


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.99s/it]
INFO:root:final mean train loss: 4485.181476593018
INFO:root:final train perplexity: 5.868117332458496
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.68s/it]
INFO:root:eval mean loss: 4322.805129030918
INFO:root:eval perplexity: 5.743193626403809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/13

  6%|â–‹         | 13/200 [39:46<8:54:35, 171.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4713.8291015625
INFO:root:current train perplexity6.055728435516357
INFO:root:current mean train loss 4460.002526736954
INFO:root:current train perplexity5.765598297119141
INFO:root:current mean train loss 4457.688857806727
INFO:root:current train perplexity5.7647857666015625
INFO:root:current mean train loss 4456.012530940594
INFO:root:current train perplexity5.77105712890625
INFO:root:current mean train loss 4457.535310125233
INFO:root:current train perplexity5.775132179260254
INFO:root:current mean train loss 4453.892490758573
INFO:root:current train perplexity5.77778959274292
INFO:root:current mean train loss 4449.987889734271
INFO:root:current train perplexity5.778639316558838
INFO:root:current mean train loss 4445.9915078652875
INFO:root:current train perplexity5.770841121673584
INFO:root:current mean train loss 4444.58388100288
INFO:root:current train perplexity5.7683610916137695
INFO:root:current mean train loss 4445.013728922256
INFO:root:current train perplexity5.768129348754883


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.27s/it]
INFO:root:final mean train loss: 4441.285488866991
INFO:root:final train perplexity: 5.767367362976074
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.25s/it]
INFO:root:eval mean loss: 4298.184263838099
INFO:root:eval perplexity: 5.6862993240356445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/14

  7%|â–‹         | 14/200 [42:35<8:48:53, 170.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4369.0361328125
INFO:root:current train perplexity5.547501087188721
INFO:root:current mean train loss 4393.487287091779
INFO:root:current train perplexity5.680110454559326
INFO:root:current mean train loss 4385.1765425984895
INFO:root:current train perplexity5.6773905754089355
INFO:root:current mean train loss 4389.643871834807
INFO:root:current train perplexity5.675271034240723
INFO:root:current mean train loss 4387.4709977569955
INFO:root:current train perplexity5.670855522155762
INFO:root:current mean train loss 4390.943428173924
INFO:root:current train perplexity5.67525053024292
INFO:root:current mean train loss 4398.269115291914
INFO:root:current train perplexity5.6800665855407715
INFO:root:current mean train loss 4399.509735751252
INFO:root:current train perplexity5.676950454711914
INFO:root:current mean train loss 4401.364274068473
INFO:root:current train perplexity5.679986953735352
INFO:root:current mean train loss 4403.277483641774
INFO:root:current train perplexity5.675516605377197


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.29s/it]
INFO:root:final mean train loss: 4399.693193497196
INFO:root:final train perplexity: 5.6735005378723145
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.47s/it]
INFO:root:eval mean loss: 4271.402497852948
INFO:root:eval perplexity: 5.625050067901611
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/15

  8%|â–Š         | 15/200 [45:19<8:39:37, 168.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4422.0780222039475
INFO:root:current train perplexity5.665318489074707
INFO:root:current mean train loss 4363.609666327468
INFO:root:current train perplexity5.573604106903076
INFO:root:current mean train loss 4360.3136560448775
INFO:root:current train perplexity5.58555793762207
INFO:root:current mean train loss 4357.641921470905
INFO:root:current train perplexity5.583714962005615
INFO:root:current mean train loss 4363.651758162105
INFO:root:current train perplexity5.591711044311523
INFO:root:current mean train loss 4361.530579201289
INFO:root:current train perplexity5.587833404541016
INFO:root:current mean train loss 4360.231266249748
INFO:root:current train perplexity5.58710241317749
INFO:root:current mean train loss 4363.301630139516
INFO:root:current train perplexity5.590478897094727
INFO:root:current mean train loss 4362.920267964458
INFO:root:current train perplexity5.591029167175293
INFO:root:current mean train loss 4363.1247648917815
INFO:root:current train perplexity5.588815689086914


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.39s/it]
INFO:root:final mean train loss: 4363.576461299773
INFO:root:final train perplexity: 5.593231678009033
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.94s/it]
INFO:root:eval mean loss: 4247.20276484929
INFO:root:eval perplexity: 5.570272922515869
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/16

  8%|â–Š         | 16/200 [48:03<8:32:56, 167.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4359.155806929977
INFO:root:current train perplexity5.590093612670898
INFO:root:current mean train loss 4311.3359624907725
INFO:root:current train perplexity5.526294708251953
INFO:root:current mean train loss 4324.435499552588
INFO:root:current train perplexity5.523655891418457
INFO:root:current mean train loss 4322.482027666284
INFO:root:current train perplexity5.515921115875244
INFO:root:current mean train loss 4328.470743148053
INFO:root:current train perplexity5.517955303192139
INFO:root:current mean train loss 4328.123432774698
INFO:root:current train perplexity5.512147426605225
INFO:root:current mean train loss 4328.782915763308
INFO:root:current train perplexity5.510907173156738
INFO:root:current mean train loss 4327.649100071462
INFO:root:current train perplexity5.515710353851318
INFO:root:current mean train loss 4327.525438744616
INFO:root:current train perplexity5.511869430541992
INFO:root:current mean train loss 4329.451589837429
INFO:root:current train perplexity5.516369342803955


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.85s/it]
INFO:root:final mean train loss: 4330.225705669773
INFO:root:final train perplexity: 5.5201191902160645
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 13.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 13.00s/it]
INFO:root:eval mean loss: 4226.503298495678
INFO:root:eval perplexity: 5.523844242095947
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/17

  8%|â–Š         | 17/200 [50:47<8:27:02, 166.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4259.4373814174105
INFO:root:current train perplexity5.415973663330078
INFO:root:current mean train loss 4296.023012514467
INFO:root:current train perplexity5.440316200256348
INFO:root:current mean train loss 4292.250714760638
INFO:root:current train perplexity5.446844100952148
INFO:root:current mean train loss 4294.549556902985
INFO:root:current train perplexity5.44431209564209
INFO:root:current mean train loss 4294.9282333198635
INFO:root:current train perplexity5.449203968048096
INFO:root:current mean train loss 4305.515495856454
INFO:root:current train perplexity5.451025009155273
INFO:root:current mean train loss 4300.887286617249
INFO:root:current train perplexity5.4444403648376465
INFO:root:current mean train loss 4299.492925568665
INFO:root:current train perplexity5.440908432006836
INFO:root:current mean train loss 4300.479748900636
INFO:root:current train perplexity5.4484052658081055
INFO:root:current mean train loss 4300.042189066678
INFO:root:current train perplexity5.451974868774414


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.09s/it]
INFO:root:final mean train loss: 4298.929274220621
INFO:root:final train perplexity: 5.45237922668457
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.28s/it]
INFO:root:eval mean loss: 4210.348799035904
INFO:root:eval perplexity: 5.487876892089844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/18

  9%|â–‰         | 18/200 [53:28<8:19:50, 164.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4261.143208348474
INFO:root:current train perplexity5.38955545425415
INFO:root:current mean train loss 4281.739281714379
INFO:root:current train perplexity5.405263900756836
INFO:root:current mean train loss 4275.372008021476
INFO:root:current train perplexity5.396388530731201
INFO:root:current mean train loss 4281.701361208546
INFO:root:current train perplexity5.41010856628418
INFO:root:current mean train loss 4282.504293127469
INFO:root:current train perplexity5.4061737060546875
INFO:root:current mean train loss 4282.781277876094
INFO:root:current train perplexity5.4037652015686035
INFO:root:current mean train loss 4278.613831041019
INFO:root:current train perplexity5.397538661956787
INFO:root:current mean train loss 4275.08529248244
INFO:root:current train perplexity5.39263916015625
INFO:root:current mean train loss 4271.4833167676825
INFO:root:current train perplexity5.390050888061523
INFO:root:current mean train loss 4270.5014280802625
INFO:root:current train perplexity5.387176990509033


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.05s/it]
INFO:root:final mean train loss: 4269.615856847456
INFO:root:final train perplexity: 5.389684677124023
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.47s/it]
INFO:root:eval mean loss: 4190.565800227172
INFO:root:eval perplexity: 5.444150447845459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/19

 10%|â–‰         | 19/200 [56:15<8:18:40, 165.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4216.195906096814
INFO:root:current train perplexity5.257405757904053
INFO:root:current mean train loss 4211.98386246637
INFO:root:current train perplexity5.263902187347412
INFO:root:current mean train loss 4241.718756808703
INFO:root:current train perplexity5.293120384216309
INFO:root:current mean train loss 4233.724334629852
INFO:root:current train perplexity5.304152011871338
INFO:root:current mean train loss 4239.493541370739
INFO:root:current train perplexity5.30808162689209
INFO:root:current mean train loss 4237.594282146807
INFO:root:current train perplexity5.312759876251221
INFO:root:current mean train loss 4245.155935729887
INFO:root:current train perplexity5.3256072998046875
INFO:root:current mean train loss 4246.2765407841625
INFO:root:current train perplexity5.326678276062012
INFO:root:current mean train loss 4246.067762937445
INFO:root:current train perplexity5.3295063972473145
INFO:root:current mean train loss 4248.291804011813
INFO:root:current train perplexity5.332479476928711


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:37<00:00, 157.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:37<00:00, 157.31s/it]
INFO:root:final mean train loss: 4241.854552176691
INFO:root:final train perplexity: 5.330976963043213
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.85s/it]
INFO:root:eval mean loss: 4175.662440090315
INFO:root:eval perplexity: 5.411440849304199
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/20

 10%|â–ˆ         | 20/200 [59:48<8:59:10, 179.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4246.052812996557
INFO:root:current train perplexity5.277016639709473
INFO:root:current mean train loss 4237.371732507861
INFO:root:current train perplexity5.272744178771973
INFO:root:current mean train loss 4229.965786377896
INFO:root:current train perplexity5.274354934692383
INFO:root:current mean train loss 4228.13448816156
INFO:root:current train perplexity5.28400182723999
INFO:root:current mean train loss 4223.6995538449755
INFO:root:current train perplexity5.2783098220825195
INFO:root:current mean train loss 4220.218408465173
INFO:root:current train perplexity5.274618148803711
INFO:root:current mean train loss 4222.658312414051
INFO:root:current train perplexity5.276661396026611
INFO:root:current mean train loss 4226.39201843503
INFO:root:current train perplexity5.286037445068359
INFO:root:current mean train loss 4224.404275843095
INFO:root:current train perplexity5.2849202156066895
INFO:root:current mean train loss 4221.588253144551
INFO:root:current train perplexity5.280829906463623


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.53s/it]
INFO:root:final mean train loss: 4217.022820380426
INFO:root:final train perplexity: 5.279003620147705
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.37s/it]
INFO:root:eval mean loss: 4165.62711761691
INFO:root:eval perplexity: 5.389525890350342
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/21

 10%|â–ˆ         | 21/200 [1:03:50<9:51:56, 198.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4165.255961403918
INFO:root:current train perplexity5.20782470703125
INFO:root:current mean train loss 4180.177762151478
INFO:root:current train perplexity5.230708599090576
INFO:root:current mean train loss 4186.573426893141
INFO:root:current train perplexity5.222691535949707
INFO:root:current mean train loss 4184.179813894329
INFO:root:current train perplexity5.213747024536133
INFO:root:current mean train loss 4189.481193852884
INFO:root:current train perplexity5.22052526473999
INFO:root:current mean train loss 4189.096553957231
INFO:root:current train perplexity5.215619087219238
INFO:root:current mean train loss 4191.056224085223
INFO:root:current train perplexity5.2170562744140625
INFO:root:current mean train loss 4191.780134974434
INFO:root:current train perplexity5.216733455657959
INFO:root:current mean train loss 4193.32795604455
INFO:root:current train perplexity5.217801570892334
INFO:root:current mean train loss 4192.522816418369
INFO:root:current train perplexity5.221526622772217


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.15s/it]
INFO:root:final mean train loss: 4190.853286866219
INFO:root:final train perplexity: 5.224781513214111
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.32s/it]
INFO:root:eval mean loss: 4143.7186945921985
INFO:root:eval perplexity: 5.341989517211914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/22

 11%|â–ˆ         | 22/200 [1:07:35<10:12:39, 206.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4180.570524088542
INFO:root:current train perplexity5.172107219696045
INFO:root:current mean train loss 4170.61878766741
INFO:root:current train perplexity5.178164958953857
INFO:root:current mean train loss 4162.640886008523
INFO:root:current train perplexity5.157578945159912
INFO:root:current mean train loss 4163.10507421875
INFO:root:current train perplexity5.165196418762207
INFO:root:current mean train loss 4165.148392783717
INFO:root:current train perplexity5.17056941986084
INFO:root:current mean train loss 4170.024134256114
INFO:root:current train perplexity5.175644397735596
INFO:root:current mean train loss 4168.120086443866
INFO:root:current train perplexity5.178095817565918
INFO:root:current mean train loss 4172.243859311996
INFO:root:current train perplexity5.180341720581055
INFO:root:current mean train loss 4172.476294921875
INFO:root:current train perplexity5.180197238922119
INFO:root:current mean train loss 4174.4907867588145
INFO:root:current train perplexity5.181703567504883


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.29s/it]
INFO:root:final mean train loss: 4169.391063321022
INFO:root:final train perplexity: 5.180727005004883
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.03s/it]
INFO:root:eval mean loss: 4136.186582308289
INFO:root:eval perplexity: 5.325744152069092
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/23

 12%|â–ˆâ–        | 23/200 [1:11:25<10:29:57, 213.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4152.292059840926
INFO:root:current train perplexity5.094675540924072
INFO:root:current mean train loss 4148.6300695867485
INFO:root:current train perplexity5.114624977111816
INFO:root:current mean train loss 4148.583361514466
INFO:root:current train perplexity5.116551876068115
INFO:root:current mean train loss 4153.680968760199
INFO:root:current train perplexity5.124850749969482
INFO:root:current mean train loss 4156.230572370762
INFO:root:current train perplexity5.131786823272705
INFO:root:current mean train loss 4149.321026496167
INFO:root:current train perplexity5.124757289886475
INFO:root:current mean train loss 4143.996829746408
INFO:root:current train perplexity5.118394374847412
INFO:root:current mean train loss 4149.548053921715
INFO:root:current train perplexity5.1299543380737305
INFO:root:current mean train loss 4148.798412284116
INFO:root:current train perplexity5.132907390594482
INFO:root:current mean train loss 4149.5290619237985
INFO:root:current train perplexity5.134005069732666


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 155.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 155.00s/it]
INFO:root:final mean train loss: 4146.329758736395
INFO:root:final train perplexity: 5.133803844451904
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.34s/it]
INFO:root:eval mean loss: 4127.137162012411
INFO:root:eval perplexity: 5.306291580200195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/24

 12%|â–ˆâ–        | 24/200 [1:15:14<10:39:18, 217.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4096.355543870192
INFO:root:current train perplexity5.053728103637695
INFO:root:current mean train loss 4111.191167222268
INFO:root:current train perplexity5.076082229614258
INFO:root:current mean train loss 4108.868275645672
INFO:root:current train perplexity5.065752983093262
INFO:root:current mean train loss 4119.922386384072
INFO:root:current train perplexity5.085795879364014
INFO:root:current mean train loss 4120.589323148708
INFO:root:current train perplexity5.089681148529053
INFO:root:current mean train loss 4126.2474334252065
INFO:root:current train perplexity5.093024730682373
INFO:root:current mean train loss 4128.502278528062
INFO:root:current train perplexity5.0957465171813965
INFO:root:current mean train loss 4132.365669568781
INFO:root:current train perplexity5.096427917480469
INFO:root:current mean train loss 4130.890554032074
INFO:root:current train perplexity5.098480224609375
INFO:root:current mean train loss 4129.846432344223
INFO:root:current train perplexity5.093940258026123


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.13s/it]
INFO:root:final mean train loss: 4126.513204636112
INFO:root:final train perplexity: 5.09382438659668
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.35s/it]
INFO:root:eval mean loss: 4114.956802692819
INFO:root:eval perplexity: 5.280219078063965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/25

 12%|â–ˆâ–Ž        | 25/200 [1:18:30<10:16:33, 211.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4081.7572847616793
INFO:root:current train perplexity5.065256118774414
INFO:root:current mean train loss 4092.096328812029
INFO:root:current train perplexity5.036574363708496
INFO:root:current mean train loss 4105.647558103836
INFO:root:current train perplexity5.047207832336426
INFO:root:current mean train loss 4111.869226288377
INFO:root:current train perplexity5.0568366050720215
INFO:root:current mean train loss 4110.789686306206
INFO:root:current train perplexity5.052688121795654
INFO:root:current mean train loss 4108.729281876043
INFO:root:current train perplexity5.04649543762207
INFO:root:current mean train loss 4109.210453759277
INFO:root:current train perplexity5.048221111297607
INFO:root:current mean train loss 4112.182418880534
INFO:root:current train perplexity5.050872325897217
INFO:root:current mean train loss 4111.855387550838
INFO:root:current train perplexity5.054827690124512


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.73s/it]
INFO:root:final mean train loss: 4106.138100470266
INFO:root:final train perplexity: 5.053040981292725
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.60s/it]
INFO:root:eval mean loss: 4107.752462184176
INFO:root:eval perplexity: 5.264859199523926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/26

 13%|â–ˆâ–Ž        | 26/200 [1:21:19<9:36:30, 198.80s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4155.496477399553
INFO:root:current train perplexity5.131871223449707
INFO:root:current mean train loss 4080.2042681257303
INFO:root:current train perplexity5.020849704742432
INFO:root:current mean train loss 4089.4789107318084
INFO:root:current train perplexity5.028775691986084
INFO:root:current mean train loss 4092.3718388958164
INFO:root:current train perplexity5.026841640472412
INFO:root:current mean train loss 4099.27791661068
INFO:root:current train perplexity5.037755966186523
INFO:root:current mean train loss 4090.178796170026
INFO:root:current train perplexity5.025338172912598
INFO:root:current mean train loss 4092.906608770078
INFO:root:current train perplexity5.018929481506348
INFO:root:current mean train loss 4093.649952415024
INFO:root:current train perplexity5.021529674530029
INFO:root:current mean train loss 4091.4607720168256
INFO:root:current train perplexity5.018354892730713
INFO:root:current mean train loss 4088.9277806728915
INFO:root:current train perplexity5.01450252532959


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:37<00:00, 157.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:37<00:00, 157.55s/it]
INFO:root:final mean train loss: 4087.0889855046426
INFO:root:final train perplexity: 5.0152082443237305
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.87s/it]
INFO:root:eval mean loss: 4096.4834832806955
INFO:root:eval perplexity: 5.2409234046936035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/27

 14%|â–ˆâ–Ž        | 27/200 [1:25:17<10:07:12, 210.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4101.135367838541
INFO:root:current train perplexity4.9510016441345215
INFO:root:current mean train loss 4051.2636315387226
INFO:root:current train perplexity4.961993217468262
INFO:root:current mean train loss 4049.1879689771076
INFO:root:current train perplexity4.959079265594482
INFO:root:current mean train loss 4062.8475337921627
INFO:root:current train perplexity4.9736785888671875
INFO:root:current mean train loss 4072.095262495294
INFO:root:current train perplexity4.984899997711182
INFO:root:current mean train loss 4066.936811191596
INFO:root:current train perplexity4.974856853485107
INFO:root:current mean train loss 4069.571363694106
INFO:root:current train perplexity4.975613594055176
INFO:root:current mean train loss 4070.6732736013987
INFO:root:current train perplexity4.974844932556152
INFO:root:current mean train loss 4073.5816553033933
INFO:root:current train perplexity4.977560997009277
INFO:root:current mean train loss 4070.748883890454
INFO:root:current train perplexity4.97673225402832


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.27s/it]
INFO:root:final mean train loss: 4069.6626161144627
INFO:root:final train perplexity: 4.980845928192139
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.03s/it]
INFO:root:eval mean loss: 4088.0940911042776
INFO:root:eval perplexity: 5.223173141479492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/28

 14%|â–ˆâ–        | 28/200 [1:29:06<10:19:15, 216.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4088.178424337636
INFO:root:current train perplexity4.966093063354492
INFO:root:current mean train loss 4054.6670120363315
INFO:root:current train perplexity4.930181980133057
INFO:root:current mean train loss 4062.4435411119675
INFO:root:current train perplexity4.953033924102783
INFO:root:current mean train loss 4052.6922437354874
INFO:root:current train perplexity4.943466663360596
INFO:root:current mean train loss 4064.6617076684397
INFO:root:current train perplexity4.953090190887451
INFO:root:current mean train loss 4065.3192173682482
INFO:root:current train perplexity4.952092170715332
INFO:root:current mean train loss 4058.0831426188806
INFO:root:current train perplexity4.9476141929626465
INFO:root:current mean train loss 4055.4102889571445
INFO:root:current train perplexity4.947037220001221
INFO:root:current mean train loss 4058.10357970079
INFO:root:current train perplexity4.94809103012085
INFO:root:current mean train loss 4056.1374025024547
INFO:root:current train perplexity4.947462558746338


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:39<00:00, 159.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:39<00:00, 159.12s/it]
INFO:root:final mean train loss: 4051.839096561555
INFO:root:final train perplexity: 4.945943355560303
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.03s/it]
INFO:root:eval mean loss: 4083.317169838763
INFO:root:eval perplexity: 5.213094711303711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/29

 14%|â–ˆâ–        | 29/200 [1:32:32<10:07:03, 213.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4060.4122275075606
INFO:root:current train perplexity4.907324314117432
INFO:root:current mean train loss 4041.500680239146
INFO:root:current train perplexity4.902741432189941
INFO:root:current mean train loss 4056.4097947950486
INFO:root:current train perplexity4.916093826293945
INFO:root:current mean train loss 4058.030589861452
INFO:root:current train perplexity4.915158748626709
INFO:root:current mean train loss 4055.0822969157844
INFO:root:current train perplexity4.910816192626953
INFO:root:current mean train loss 4050.892035130503
INFO:root:current train perplexity4.912017822265625
INFO:root:current mean train loss 4045.3395438942403
INFO:root:current train perplexity4.908078193664551
INFO:root:current mean train loss 4045.3345538138037
INFO:root:current train perplexity4.911498546600342
INFO:root:current mean train loss 4042.2246769470144
INFO:root:current train perplexity4.908275604248047
INFO:root:current mean train loss 4037.123997214017
INFO:root:current train perplexity4.910335063934326


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.88s/it]
INFO:root:final mean train loss: 4034.067692725889
INFO:root:final train perplexity: 4.911386489868164
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.87s/it]
INFO:root:eval mean loss: 4074.058773825355
INFO:root:eval perplexity: 5.193613529205322
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/30

 15%|â–ˆâ–Œ        | 30/200 [1:36:11<10:08:58, 214.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4018.556164863782
INFO:root:current train perplexity4.900773525238037
INFO:root:current mean train loss 4013.9256512758543
INFO:root:current train perplexity4.886529445648193
INFO:root:current mean train loss 4017.5464459662658
INFO:root:current train perplexity4.870301723480225
INFO:root:current mean train loss 4013.630026128088
INFO:root:current train perplexity4.867080211639404
INFO:root:current mean train loss 4020.4147565489748
INFO:root:current train perplexity4.8708815574646
INFO:root:current mean train loss 4018.6458973504173
INFO:root:current train perplexity4.87334680557251
INFO:root:current mean train loss 4017.9075887617373
INFO:root:current train perplexity4.874672889709473
INFO:root:current mean train loss 4022.6192192521567
INFO:root:current train perplexity4.878695487976074
INFO:root:current mean train loss 4022.5908959699045
INFO:root:current train perplexity4.882193088531494
INFO:root:current mean train loss 4021.665069482578
INFO:root:current train perplexity4.881811141967773


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.89s/it]
INFO:root:final mean train loss: 4018.097125330279
INFO:root:final train perplexity: 4.880537986755371
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.55s/it]
INFO:root:eval mean loss: 4066.867436835106
INFO:root:eval perplexity: 5.17853307723999
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/31

 16%|â–ˆâ–Œ        | 31/200 [1:39:10<9:34:49, 204.08s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3992.129825673205
INFO:root:current train perplexity4.822023391723633
INFO:root:current mean train loss 3991.0261047778486
INFO:root:current train perplexity4.818861961364746
INFO:root:current mean train loss 3983.932975985261
INFO:root:current train perplexity4.807042121887207
INFO:root:current mean train loss 3995.778548974469
INFO:root:current train perplexity4.8223724365234375
INFO:root:current mean train loss 4000.4013393325295
INFO:root:current train perplexity4.831104755401611
INFO:root:current mean train loss 4001.7169187221493
INFO:root:current train perplexity4.84004020690918
INFO:root:current mean train loss 4005.8512191182863
INFO:root:current train perplexity4.846004009246826
INFO:root:current mean train loss 4001.292767423862
INFO:root:current train perplexity4.846116065979004
INFO:root:current mean train loss 4003.756328632305
INFO:root:current train perplexity4.849946022033691
INFO:root:current mean train loss 4003.708510530788
INFO:root:current train perplexity4.848904132843018


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.47s/it]
INFO:root:final mean train loss: 4002.408447942426
INFO:root:final train perplexity: 4.8504228591918945
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.73s/it]
INFO:root:eval mean loss: 4059.6859624335107
INFO:root:eval perplexity: 5.163516044616699
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/32

 16%|â–ˆâ–Œ        | 32/200 [1:43:04<9:56:34, 213.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3978.442658025568
INFO:root:current train perplexity4.743823051452637
INFO:root:current mean train loss 4000.2547568044356
INFO:root:current train perplexity4.806048393249512
INFO:root:current mean train loss 3980.7411295572915
INFO:root:current train perplexity4.7971625328063965
INFO:root:current mean train loss 3974.251447650748
INFO:root:current train perplexity4.803606986999512
INFO:root:current mean train loss 3983.917095746051
INFO:root:current train perplexity4.815212726593018
INFO:root:current mean train loss 3984.790143757038
INFO:root:current train perplexity4.815290927886963
INFO:root:current mean train loss 3988.967973595539
INFO:root:current train perplexity4.817227840423584
INFO:root:current mean train loss 3990.7520129475374
INFO:root:current train perplexity4.817847728729248
INFO:root:current mean train loss 3991.279702919408
INFO:root:current train perplexity4.818164348602295
INFO:root:current mean train loss 3990.6421734395453
INFO:root:current train perplexity4.821835994720459


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.76s/it]
INFO:root:final mean train loss: 3986.5413927878103
INFO:root:final train perplexity: 4.820154190063477
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.08s/it]
INFO:root:eval mean loss: 4053.323623116135
INFO:root:eval perplexity: 5.15024995803833
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/33

 16%|â–ˆâ–‹        | 33/200 [1:45:58<9:20:29, 201.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3919.6531420510914
INFO:root:current train perplexity4.737483501434326
INFO:root:current mean train loss 3950.488525390625
INFO:root:current train perplexity4.78183126449585
INFO:root:current mean train loss 3949.474356879753
INFO:root:current train perplexity4.780933856964111
INFO:root:current mean train loss 3959.212394945549
INFO:root:current train perplexity4.782022476196289
INFO:root:current mean train loss 3968.7718118292723
INFO:root:current train perplexity4.784733772277832
INFO:root:current mean train loss 3965.4822137266874
INFO:root:current train perplexity4.778832912445068
INFO:root:current mean train loss 3968.706626558376
INFO:root:current train perplexity4.786179542541504
INFO:root:current mean train loss 3966.7390767068728
INFO:root:current train perplexity4.782100677490234
INFO:root:current mean train loss 3968.4774440089077
INFO:root:current train perplexity4.783188343048096
INFO:root:current mean train loss 3975.780160874221
INFO:root:current train perplexity4.793833255767822


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.53s/it]
INFO:root:final mean train loss: 3972.592630324825
INFO:root:final train perplexity: 4.793700695037842
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.93s/it]
INFO:root:eval mean loss: 4048.1077543218084
INFO:root:eval perplexity: 5.139398097991943
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/34

 17%|â–ˆâ–‹        | 34/200 [1:49:34<9:29:21, 205.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3989.3279908945865
INFO:root:current train perplexity4.768844127655029
INFO:root:current mean train loss 3955.112488863761
INFO:root:current train perplexity4.748694896697998
INFO:root:current mean train loss 3950.723348131919
INFO:root:current train perplexity4.75089168548584
INFO:root:current mean train loss 3952.515511813511
INFO:root:current train perplexity4.745472431182861
INFO:root:current mean train loss 3952.4073100160895
INFO:root:current train perplexity4.74618673324585
INFO:root:current mean train loss 3956.745678155101
INFO:root:current train perplexity4.7563958168029785
INFO:root:current mean train loss 3959.583788262039
INFO:root:current train perplexity4.761161804199219
INFO:root:current mean train loss 3958.1444384702295
INFO:root:current train perplexity4.760054588317871
INFO:root:current mean train loss 3961.8442144558157
INFO:root:current train perplexity4.76416540145874
INFO:root:current mean train loss 3960.6850849941266
INFO:root:current train perplexity4.765881061553955


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.66s/it]
INFO:root:final mean train loss: 3957.939995181176
INFO:root:final train perplexity: 4.766068935394287
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.23s/it]
INFO:root:eval mean loss: 4046.452503393728
INFO:root:eval perplexity: 5.135959148406982
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/35

 18%|â–ˆâ–Š        | 35/200 [1:53:47<10:04:59, 220.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3968.3827970480615
INFO:root:current train perplexity4.757010459899902
INFO:root:current mean train loss 3948.251552134253
INFO:root:current train perplexity4.726457118988037
INFO:root:current mean train loss 3952.192089668739
INFO:root:current train perplexity4.738975524902344
INFO:root:current mean train loss 3949.971082541433
INFO:root:current train perplexity4.735714435577393
INFO:root:current mean train loss 3947.991043250098
INFO:root:current train perplexity4.7380218505859375
INFO:root:current mean train loss 3951.1683895657925
INFO:root:current train perplexity4.7370381355285645
INFO:root:current mean train loss 3951.333100219187
INFO:root:current train perplexity4.739992141723633
INFO:root:current mean train loss 3948.9374050390124
INFO:root:current train perplexity4.73959493637085
INFO:root:current mean train loss 3946.811687031161
INFO:root:current train perplexity4.737617492675781
INFO:root:current mean train loss 3946.5971006368104
INFO:root:current train perplexity4.739552974700928


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.73s/it]
INFO:root:final mean train loss: 3943.565554341962
INFO:root:final train perplexity: 4.739116668701172
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.01s/it]
INFO:root:eval mean loss: 4042.1141452654033
INFO:root:eval perplexity: 5.126957416534424
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/36

 18%|â–ˆâ–Š        | 36/200 [1:57:36<10:08:30, 222.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3899.237689138829
INFO:root:current train perplexity4.689579486846924
INFO:root:current mean train loss 3908.4886024189504
INFO:root:current train perplexity4.685297966003418
INFO:root:current mean train loss 3919.0931783536585
INFO:root:current train perplexity4.692481517791748
INFO:root:current mean train loss 3923.9121043281652
INFO:root:current train perplexity4.700677871704102
INFO:root:current mean train loss 3919.981588688719
INFO:root:current train perplexity4.703386306762695
INFO:root:current mean train loss 3921.848816229903
INFO:root:current train perplexity4.707276821136475
INFO:root:current mean train loss 3927.08980288221
INFO:root:current train perplexity4.710134506225586
INFO:root:current mean train loss 3930.1587301833506
INFO:root:current train perplexity4.712713241577148
INFO:root:current mean train loss 3931.407693650032
INFO:root:current train perplexity4.71101188659668
INFO:root:current mean train loss 3933.751973160857
INFO:root:current train perplexity4.715763092041016


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.53s/it]
INFO:root:final mean train loss: 3930.908753918063
INFO:root:final train perplexity: 4.715510368347168
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.88s/it]
INFO:root:eval mean loss: 4034.3797252465647
INFO:root:eval perplexity: 5.1109466552734375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/37

 18%|â–ˆâ–Š        | 37/200 [2:00:26<9:21:26, 206.66s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3894.6705771998354
INFO:root:current train perplexity4.6477861404418945
INFO:root:current mean train loss 3895.5732634715546
INFO:root:current train perplexity4.655445575714111
INFO:root:current mean train loss 3903.954931640625
INFO:root:current train perplexity4.670174598693848
INFO:root:current mean train loss 3896.4381978095334
INFO:root:current train perplexity4.669988632202148
INFO:root:current mean train loss 3902.5095786971274
INFO:root:current train perplexity4.674337863922119
INFO:root:current mean train loss 3907.2880309545694
INFO:root:current train perplexity4.678619384765625
INFO:root:current mean train loss 3908.346702520796
INFO:root:current train perplexity4.6793084144592285
INFO:root:current mean train loss 3914.593581711871
INFO:root:current train perplexity4.685497283935547
INFO:root:current mean train loss 3920.062547464211
INFO:root:current train perplexity4.689449787139893


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:39<00:00, 159.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:39<00:00, 159.18s/it]
INFO:root:final mean train loss: 3916.8783481967066
INFO:root:final train perplexity: 4.689480781555176
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.62s/it]
INFO:root:eval mean loss: 4033.1947255236037
INFO:root:eval perplexity: 5.108498573303223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/38

 19%|â–ˆâ–‰        | 38/200 [2:03:24<8:55:08, 198.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3833.446533203125
INFO:root:current train perplexity4.4947919845581055
INFO:root:current mean train loss 3908.218913550516
INFO:root:current train perplexity4.652858257293701
INFO:root:current mean train loss 3900.7877708397477
INFO:root:current train perplexity4.6496100425720215
INFO:root:current mean train loss 3903.266574167182
INFO:root:current train perplexity4.6496357917785645
INFO:root:current mean train loss 3899.115234980808
INFO:root:current train perplexity4.646834373474121
INFO:root:current mean train loss 3901.0768848821135
INFO:root:current train perplexity4.645946502685547
INFO:root:current mean train loss 3905.5790659333543
INFO:root:current train perplexity4.653499603271484
INFO:root:current mean train loss 3903.9363907750267
INFO:root:current train perplexity4.658716678619385
INFO:root:current mean train loss 3906.365338051156
INFO:root:current train perplexity4.6606035232543945
INFO:root:current mean train loss 3908.458651554281
INFO:root:current train perplexity4.663828372955322


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.93s/it]
INFO:root:final mean train loss: 3905.422876358032
INFO:root:final train perplexity: 4.668334484100342
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.63s/it]
INFO:root:eval mean loss: 4029.8231763907356
INFO:root:eval perplexity: 5.101539611816406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/39

 20%|â–ˆâ–‰        | 39/200 [2:06:38<8:48:39, 197.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3841.904141512784
INFO:root:current train perplexity4.569540977478027
INFO:root:current mean train loss 3871.522262985642
INFO:root:current train perplexity4.6045918464660645
INFO:root:current mean train loss 3882.68712048282
INFO:root:current train perplexity4.6143479347229
INFO:root:current mean train loss 3884.02526345207
INFO:root:current train perplexity4.630808353424072
INFO:root:current mean train loss 3886.4382549944876
INFO:root:current train perplexity4.637107849121094
INFO:root:current mean train loss 3891.2595267398483
INFO:root:current train perplexity4.6397552490234375
INFO:root:current mean train loss 3890.2654455906045
INFO:root:current train perplexity4.636882305145264
INFO:root:current mean train loss 3893.1523018580783
INFO:root:current train perplexity4.643036365509033
INFO:root:current mean train loss 3893.678569751368
INFO:root:current train perplexity4.64198112487793
INFO:root:current mean train loss 3895.3980917904432
INFO:root:current train perplexity4.644726753234863


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.53s/it]
INFO:root:final mean train loss: 3893.001104600968
INFO:root:final train perplexity: 4.645511627197266
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.03s/it]
INFO:root:eval mean loss: 4025.991694024269
INFO:root:eval perplexity: 5.093640327453613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/40

 20%|â–ˆâ–ˆ        | 40/200 [2:09:28<8:23:27, 188.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3888.2304302014804
INFO:root:current train perplexity4.631422519683838
INFO:root:current mean train loss 3878.0508427980567
INFO:root:current train perplexity4.621463298797607
INFO:root:current mean train loss 3874.3789876302085
INFO:root:current train perplexity4.615566253662109
INFO:root:current mean train loss 3883.800489658846
INFO:root:current train perplexity4.618331432342529
INFO:root:current mean train loss 3883.569993777036
INFO:root:current train perplexity4.619351863861084
INFO:root:current mean train loss 3887.086505279835
INFO:root:current train perplexity4.622875213623047
INFO:root:current mean train loss 3885.679384592084
INFO:root:current train perplexity4.6213178634643555
INFO:root:current mean train loss 3890.3802244056415
INFO:root:current train perplexity4.6285905838012695
INFO:root:current mean train loss 3887.145806504693
INFO:root:current train perplexity4.625205039978027
INFO:root:current mean train loss 3883.896609234732
INFO:root:current train perplexity4.6242170333862305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.43s/it]
INFO:root:final mean train loss: 3880.612951032577
INFO:root:final train perplexity: 4.622862339019775
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.45s/it]
INFO:root:eval mean loss: 4020.5452110344636
INFO:root:eval perplexity: 5.082435131072998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/41

 20%|â–ˆâ–ˆ        | 41/200 [2:13:15<8:50:23, 200.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3827.497368706597
INFO:root:current train perplexity4.580772876739502
INFO:root:current mean train loss 3851.2756962813733
INFO:root:current train perplexity4.573202610015869
INFO:root:current mean train loss 3856.2169764850632
INFO:root:current train perplexity4.584433555603027
INFO:root:current mean train loss 3858.068192881546
INFO:root:current train perplexity4.579895973205566
INFO:root:current mean train loss 3859.7230993623757
INFO:root:current train perplexity4.586993217468262
INFO:root:current mean train loss 3860.5670631596895
INFO:root:current train perplexity4.583483695983887
INFO:root:current mean train loss 3864.07220799691
INFO:root:current train perplexity4.585068225860596
INFO:root:current mean train loss 3869.0867595856257
INFO:root:current train perplexity4.593355178833008
INFO:root:current mean train loss 3873.9092198363815
INFO:root:current train perplexity4.600645542144775
INFO:root:current mean train loss 3873.4847326515305
INFO:root:current train perplexity4.601274490356445


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.64s/it]
INFO:root:final mean train loss: 3869.7850023700344
INFO:root:final train perplexity: 4.603156089782715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.33s/it]
INFO:root:eval mean loss: 4017.9057842281695
INFO:root:eval perplexity: 5.0770134925842285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/42

 21%|â–ˆâ–ˆ        | 42/200 [2:17:27<9:28:18, 215.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3798.112967354911
INFO:root:current train perplexity4.543475151062012
INFO:root:current mean train loss 3821.491283275463
INFO:root:current train perplexity4.5544657707214355
INFO:root:current mean train loss 3839.4276273686837
INFO:root:current train perplexity4.558152198791504
INFO:root:current mean train loss 3851.636371851679
INFO:root:current train perplexity4.571712970733643
INFO:root:current mean train loss 3854.7344597476654
INFO:root:current train perplexity4.572025299072266
INFO:root:current mean train loss 3857.491101416472
INFO:root:current train perplexity4.574910640716553
INFO:root:current mean train loss 3857.2150828924705
INFO:root:current train perplexity4.577374458312988
INFO:root:current mean train loss 3861.350703523597
INFO:root:current train perplexity4.578960418701172
INFO:root:current mean train loss 3858.573008572698
INFO:root:current train perplexity4.576704502105713
INFO:root:current mean train loss 3858.6957482975436
INFO:root:current train perplexity4.577460289001465


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.96s/it]
INFO:root:final mean train loss: 3857.5107066862047
INFO:root:final train perplexity: 4.580918788909912
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.90s/it]
INFO:root:eval mean loss: 4012.7707900459886
INFO:root:eval perplexity: 5.066482067108154
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/43

 22%|â–ˆâ–ˆâ–       | 43/200 [2:20:23<8:53:16, 203.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3888.6489598473836
INFO:root:current train perplexity4.568490982055664
INFO:root:current mean train loss 3864.2113830993226
INFO:root:current train perplexity4.568785667419434
INFO:root:current mean train loss 3854.011271661201
INFO:root:current train perplexity4.548509120941162
INFO:root:current mean train loss 3851.5138861208547
INFO:root:current train perplexity4.5501322746276855
INFO:root:current mean train loss 3851.5504897141295
INFO:root:current train perplexity4.548349857330322
INFO:root:current mean train loss 3852.550821715297
INFO:root:current train perplexity4.554005146026611
INFO:root:current mean train loss 3851.3836903431184
INFO:root:current train perplexity4.554350852966309
INFO:root:current mean train loss 3848.362171938089
INFO:root:current train perplexity4.555084705352783
INFO:root:current mean train loss 3849.3482128790406
INFO:root:current train perplexity4.559275150299072
INFO:root:current mean train loss 3849.148032324944
INFO:root:current train perplexity4.560349941253662


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.39s/it]
INFO:root:final mean train loss: 3846.102625262353
INFO:root:final train perplexity: 4.560347080230713
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.27s/it]
INFO:root:eval mean loss: 4015.486513394836
INFO:root:eval perplexity: 5.072049617767334
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/44

 22%|â–ˆâ–ˆâ–       | 44/200 [2:23:59<8:59:41, 207.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3789.3046013327207
INFO:root:current train perplexity4.496216297149658
INFO:root:current mean train loss 3824.7778643677566
INFO:root:current train perplexity4.512038230895996
INFO:root:current mean train loss 3827.934575175859
INFO:root:current train perplexity4.523061275482178
INFO:root:current mean train loss 3827.4506015179845
INFO:root:current train perplexity4.523223876953125
INFO:root:current mean train loss 3833.93781938574
INFO:root:current train perplexity4.523691177368164
INFO:root:current mean train loss 3837.4073382202814
INFO:root:current train perplexity4.533045768737793
INFO:root:current mean train loss 3833.0460090695806
INFO:root:current train perplexity4.531365394592285
INFO:root:current mean train loss 3835.762039936335
INFO:root:current train perplexity4.5352559089660645
INFO:root:current mean train loss 3834.4860527137193
INFO:root:current train perplexity4.536539077758789
INFO:root:current mean train loss 3836.9536225231664
INFO:root:current train perplexity4.538008213043213


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.72s/it]
INFO:root:final mean train loss: 3834.8194486556513
INFO:root:final train perplexity: 4.540091514587402
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.16s/it]
INFO:root:eval mean loss: 4008.820508158799
INFO:root:eval perplexity: 5.0583953857421875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/45

 22%|â–ˆâ–ˆâ–Ž       | 45/200 [2:26:50<8:27:52, 196.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3819.679104045286
INFO:root:current train perplexity4.487860679626465
INFO:root:current mean train loss 3828.093991069674
INFO:root:current train perplexity4.5184173583984375
INFO:root:current mean train loss 3824.564021401424
INFO:root:current train perplexity4.519807815551758
INFO:root:current mean train loss 3822.000132611203
INFO:root:current train perplexity4.516528606414795
INFO:root:current mean train loss 3822.1711617264095
INFO:root:current train perplexity4.518317222595215
INFO:root:current mean train loss 3823.1679525904237
INFO:root:current train perplexity4.5181708335876465
INFO:root:current mean train loss 3828.081620397264
INFO:root:current train perplexity4.520636081695557
INFO:root:current mean train loss 3831.043153705019
INFO:root:current train perplexity4.519252300262451
INFO:root:current mean train loss 3828.649369156541
INFO:root:current train perplexity4.521104335784912
INFO:root:current mean train loss 3827.755649857029
INFO:root:current train perplexity4.521059513092041


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.15s/it]
INFO:root:final mean train loss: 3823.9632092752763
INFO:root:final train perplexity: 4.520687580108643
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.90s/it]
INFO:root:eval mean loss: 4006.052438289561
INFO:root:eval perplexity: 5.052736282348633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/46

 23%|â–ˆâ–ˆâ–Ž       | 46/200 [2:30:27<8:40:00, 202.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3831.7637046700092
INFO:root:current train perplexity4.503537654876709
INFO:root:current mean train loss 3820.3075499391844
INFO:root:current train perplexity4.482141017913818
INFO:root:current mean train loss 3813.7566210571745
INFO:root:current train perplexity4.4872589111328125
INFO:root:current mean train loss 3819.023392929368
INFO:root:current train perplexity4.49526834487915
INFO:root:current mean train loss 3824.1435797811832
INFO:root:current train perplexity4.4994797706604
INFO:root:current mean train loss 3821.749515163415
INFO:root:current train perplexity4.4990234375
INFO:root:current mean train loss 3822.926940460434
INFO:root:current train perplexity4.5054850578308105
INFO:root:current mean train loss 3818.990887857012
INFO:root:current train perplexity4.50235652923584
INFO:root:current mean train loss 3818.444551637291
INFO:root:current train perplexity4.502753734588623
INFO:root:current mean train loss 3817.091745623142
INFO:root:current train perplexity4.501967430114746


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:38<00:00, 158.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:38<00:00, 158.54s/it]
INFO:root:final mean train loss: 3813.2550909596107
INFO:root:final train perplexity: 4.501629829406738
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.51s/it]
INFO:root:eval mean loss: 4007.132642813608
INFO:root:eval perplexity: 5.054944038391113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/47

 24%|â–ˆâ–ˆâ–Ž       | 47/200 [2:33:19<8:13:16, 193.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3801.5304361979165
INFO:root:current train perplexity4.4278998374938965
INFO:root:current mean train loss 3794.488819754464
INFO:root:current train perplexity4.465213298797607
INFO:root:current mean train loss 3795.4272008167613
INFO:root:current train perplexity4.465165615081787
INFO:root:current mean train loss 3803.261896484375
INFO:root:current train perplexity4.476481914520264
INFO:root:current mean train loss 3803.4451706414475
INFO:root:current train perplexity4.479158401489258
INFO:root:current mean train loss 3805.735532863451
INFO:root:current train perplexity4.481377124786377
INFO:root:current mean train loss 3804.958428096065
INFO:root:current train perplexity4.4828290939331055
INFO:root:current mean train loss 3804.835810546875
INFO:root:current train perplexity4.4861741065979
INFO:root:current mean train loss 3805.922751953125
INFO:root:current train perplexity4.487556457519531
INFO:root:current mean train loss 3806.6839793669874
INFO:root:current train perplexity4.485811233520508


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.80s/it]
INFO:root:final mean train loss: 3804.089932657057
INFO:root:final train perplexity: 4.485381603240967
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.66s/it]
INFO:root:eval mean loss: 4002.0854734596633
INFO:root:eval perplexity: 5.044638156890869
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/48

 24%|â–ˆâ–ˆâ–       | 48/200 [2:36:05<7:49:33, 185.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3800.8150325913025
INFO:root:current train perplexity4.447844505310059
INFO:root:current mean train loss 3802.2106079768614
INFO:root:current train perplexity4.44520902633667
INFO:root:current mean train loss 3789.0701296102034
INFO:root:current train perplexity4.439798831939697
INFO:root:current mean train loss 3787.8502710407147
INFO:root:current train perplexity4.452035427093506
INFO:root:current mean train loss 3788.2125833009836
INFO:root:current train perplexity4.456076622009277
INFO:root:current mean train loss 3792.925148494452
INFO:root:current train perplexity4.451989650726318
INFO:root:current mean train loss 3794.2591565245243
INFO:root:current train perplexity4.455904483795166
INFO:root:current mean train loss 3793.2467700475936
INFO:root:current train perplexity4.4592437744140625
INFO:root:current mean train loss 3793.697076229385
INFO:root:current train perplexity4.46079158782959
INFO:root:current mean train loss 3796.928832883631
INFO:root:current train perplexity4.4685959815979


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.71s/it]
INFO:root:final mean train loss: 3794.376752115065
INFO:root:final train perplexity: 4.468225479125977
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.96s/it]
INFO:root:eval mean loss: 4002.1007746703235
INFO:root:eval perplexity: 5.0446696281433105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/49

 24%|â–ˆâ–ˆâ–       | 49/200 [2:39:31<8:01:59, 191.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3786.861596411401
INFO:root:current train perplexity4.401897430419922
INFO:root:current mean train loss 3781.921933798266
INFO:root:current train perplexity4.418540954589844
INFO:root:current mean train loss 3772.3253043787586
INFO:root:current train perplexity4.4247145652771
INFO:root:current mean train loss 3776.5616576836237
INFO:root:current train perplexity4.430972099304199
INFO:root:current mean train loss 3777.486250556899
INFO:root:current train perplexity4.434392929077148
INFO:root:current mean train loss 3780.4671504864637
INFO:root:current train perplexity4.438095569610596
INFO:root:current mean train loss 3778.305280715788
INFO:root:current train perplexity4.435910224914551
INFO:root:current mean train loss 3781.2626647563407
INFO:root:current train perplexity4.439278602600098
INFO:root:current mean train loss 3780.5253840488217
INFO:root:current train perplexity4.440448760986328
INFO:root:current mean train loss 3785.4217316197337
INFO:root:current train perplexity4.44731330871582


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.27s/it]
INFO:root:final mean train loss: 3782.5435474764918
INFO:root:final train perplexity: 4.447414398193359
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.41s/it]
INFO:root:eval mean loss: 4001.3065367353724
INFO:root:eval perplexity: 5.04304838180542
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/50

 25%|â–ˆâ–ˆâ–Œ       | 50/200 [2:42:35<7:53:05, 189.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3760.3648570667615
INFO:root:current train perplexity4.382350444793701
INFO:root:current mean train loss 3767.3902373194096
INFO:root:current train perplexity4.4017744064331055
INFO:root:current mean train loss 3770.5904218488713
INFO:root:current train perplexity4.411068916320801
INFO:root:current mean train loss 3772.674192194353
INFO:root:current train perplexity4.413775444030762
INFO:root:current mean train loss 3776.739758814504
INFO:root:current train perplexity4.425436496734619
INFO:root:current mean train loss 3775.4289346991077
INFO:root:current train perplexity4.429948329925537
INFO:root:current mean train loss 3770.7274028467004
INFO:root:current train perplexity4.429240703582764
INFO:root:current mean train loss 3770.713265238775
INFO:root:current train perplexity4.429216384887695
INFO:root:current mean train loss 3772.306012485661
INFO:root:current train perplexity4.430343151092529


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.19s/it]
INFO:root:final mean train loss: 3774.4702049378425
INFO:root:final train perplexity: 4.433271408081055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.68s/it]
INFO:root:eval mean loss: 4000.788702349291
INFO:root:eval perplexity: 5.041994094848633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/51

 26%|â–ˆâ–ˆâ–Œ       | 51/200 [2:45:56<7:58:49, 192.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3719.8763602120534
INFO:root:current train perplexity4.395537853240967
INFO:root:current mean train loss 3763.4946768216996
INFO:root:current train perplexity4.396042823791504
INFO:root:current mean train loss 3761.6562724090427
INFO:root:current train perplexity4.4028778076171875
INFO:root:current mean train loss 3770.8824299865128
INFO:root:current train perplexity4.403316974639893
INFO:root:current mean train loss 3771.94352553459
INFO:root:current train perplexity4.409550189971924
INFO:root:current mean train loss 3768.590325771234
INFO:root:current train perplexity4.407698631286621
INFO:root:current mean train loss 3764.9848025477504
INFO:root:current train perplexity4.407577037811279
INFO:root:current mean train loss 3761.8328420593175
INFO:root:current train perplexity4.409289360046387
INFO:root:current mean train loss 3765.3224404865628
INFO:root:current train perplexity4.413459300994873
INFO:root:current mean train loss 3765.7187583443874
INFO:root:current train perplexity4.412459850311279


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:38<00:00, 158.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:38<00:00, 158.42s/it]
INFO:root:final mean train loss: 3763.790973478748
INFO:root:final train perplexity: 4.4146318435668945
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.65s/it]
INFO:root:eval mean loss: 3997.27232414949
INFO:root:eval perplexity: 5.0348286628723145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/52

 26%|â–ˆâ–ˆâ–Œ       | 52/200 [2:50:09<8:39:58, 210.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3772.047021484375
INFO:root:current train perplexity4.470399856567383
INFO:root:current mean train loss 3735.6274796195653
INFO:root:current train perplexity4.371530055999756
INFO:root:current mean train loss 3738.813124545785
INFO:root:current train perplexity4.375910758972168
INFO:root:current mean train loss 3739.529968843006
INFO:root:current train perplexity4.382344722747803
INFO:root:current mean train loss 3745.648646931476
INFO:root:current train perplexity4.382674694061279
INFO:root:current mean train loss 3748.6806640625
INFO:root:current train perplexity4.3864593505859375
INFO:root:current mean train loss 3746.8811023246953
INFO:root:current train perplexity4.391739368438721
INFO:root:current mean train loss 3750.8539571268575
INFO:root:current train perplexity4.395247459411621
INFO:root:current mean train loss 3756.460706839532
INFO:root:current train perplexity4.397220134735107
INFO:root:current mean train loss 3757.638466956967
INFO:root:current train perplexity4.39858865737915


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.09s/it]
INFO:root:final mean train loss: 3755.572613439252
INFO:root:final train perplexity: 4.400341033935547
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 3993.469610552416
INFO:root:eval perplexity: 5.027093410491943
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/53

 26%|â–ˆâ–ˆâ–‹       | 53/200 [2:54:02<8:52:57, 217.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3744.03125
INFO:root:current train perplexity4.429648399353027
INFO:root:current mean train loss 3747.581540983867
INFO:root:current train perplexity4.389159202575684
INFO:root:current mean train loss 3737.874765712584
INFO:root:current train perplexity4.377596378326416
INFO:root:current mean train loss 3748.1020281056503
INFO:root:current train perplexity4.384001731872559
INFO:root:current mean train loss 3743.148614112367
INFO:root:current train perplexity4.3821797370910645
INFO:root:current mean train loss 3749.457239446403
INFO:root:current train perplexity4.388765335083008
INFO:root:current mean train loss 3751.7033330877557
INFO:root:current train perplexity4.388247966766357
INFO:root:current mean train loss 3747.4973158038338
INFO:root:current train perplexity4.382689952850342
INFO:root:current mean train loss 3750.2573615962942
INFO:root:current train perplexity4.386373996734619
INFO:root:current mean train loss 3752.150438500897
INFO:root:current train perplexity4.387413501739502


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.77s/it]
INFO:root:final mean train loss: 3746.9050192063855
INFO:root:final train perplexity: 4.385319232940674
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.24s/it]
INFO:root:eval mean loss: 3995.161141469969
INFO:root:eval perplexity: 5.030532360076904
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/54

 27%|â–ˆâ–ˆâ–‹       | 54/200 [2:56:50<8:13:13, 202.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3717.539487777218
INFO:root:current train perplexity4.371311187744141
INFO:root:current mean train loss 3725.1178062380727
INFO:root:current train perplexity4.347546577453613
INFO:root:current mean train loss 3735.8060783617425
INFO:root:current train perplexity4.3607635498046875
INFO:root:current mean train loss 3727.2068269389633
INFO:root:current train perplexity4.352608680725098
INFO:root:current mean train loss 3731.00190610952
INFO:root:current train perplexity4.360070705413818
INFO:root:current mean train loss 3734.142619504767
INFO:root:current train perplexity4.366706848144531
INFO:root:current mean train loss 3732.6630062339045
INFO:root:current train perplexity4.3684234619140625
INFO:root:current mean train loss 3733.762129547495
INFO:root:current train perplexity4.367523670196533
INFO:root:current mean train loss 3735.3561814878535
INFO:root:current train perplexity4.36784553527832
INFO:root:current mean train loss 3737.0778958067604
INFO:root:current train perplexity4.366372585296631


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.03s/it]
INFO:root:final mean train loss: 3735.824281692505
INFO:root:final train perplexity: 4.366189956665039
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.12s/it]
INFO:root:eval mean loss: 3995.574511372451
INFO:root:eval perplexity: 5.031373500823975
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/55

 28%|â–ˆâ–ˆâ–Š       | 55/200 [2:59:35<7:41:57, 191.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3689.0877216045674
INFO:root:current train perplexity4.306669235229492
INFO:root:current mean train loss 3725.3784144559354
INFO:root:current train perplexity4.331294536590576
INFO:root:current mean train loss 3726.9291471217966
INFO:root:current train perplexity4.334762096405029
INFO:root:current mean train loss 3722.6078071706766
INFO:root:current train perplexity4.329508304595947
INFO:root:current mean train loss 3719.405565961347
INFO:root:current train perplexity4.330185413360596
INFO:root:current mean train loss 3717.6106070269016
INFO:root:current train perplexity4.336470127105713
INFO:root:current mean train loss 3719.6439868049442
INFO:root:current train perplexity4.340106010437012
INFO:root:current mean train loss 3723.5078686622546
INFO:root:current train perplexity4.347268581390381
INFO:root:current mean train loss 3726.0640841496574
INFO:root:current train perplexity4.349132537841797
INFO:root:current mean train loss 3729.792172887963
INFO:root:current train perplexity4.351665496826172


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.12s/it]
INFO:root:final mean train loss: 3727.61230585652
INFO:root:final train perplexity: 4.352066993713379
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.08s/it]
INFO:root:eval mean loss: 3991.2205317071143
INFO:root:eval perplexity: 5.022523403167725
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/56

 28%|â–ˆâ–ˆâ–Š       | 56/200 [3:02:18<7:18:37, 182.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3723.106798537234
INFO:root:current train perplexity4.336289882659912
INFO:root:current mean train loss 3706.9435985331634
INFO:root:current train perplexity4.3159990310668945
INFO:root:current mean train loss 3712.9227537085653
INFO:root:current train perplexity4.318615436553955
INFO:root:current mean train loss 3714.2826226753873
INFO:root:current train perplexity4.3197503089904785
INFO:root:current mean train loss 3713.203871076272
INFO:root:current train perplexity4.32614278793335
INFO:root:current mean train loss 3715.823443034449
INFO:root:current train perplexity4.327821254730225
INFO:root:current mean train loss 3721.344230734399
INFO:root:current train perplexity4.332784652709961
INFO:root:current mean train loss 3721.7438108554006
INFO:root:current train perplexity4.334955215454102
INFO:root:current mean train loss 3723.2452667848843
INFO:root:current train perplexity4.336864948272705
INFO:root:current mean train loss 3723.2503774254224
INFO:root:current train perplexity4.337204933166504


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.53s/it]
INFO:root:final mean train loss: 3718.784496799592
INFO:root:final train perplexity: 4.3369364738464355
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.29s/it]
INFO:root:eval mean loss: 3992.5758567431294
INFO:root:eval perplexity: 5.025277137756348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/57

 28%|â–ˆâ–ˆâ–Š       | 57/200 [3:05:03<7:03:26, 177.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3671.2976917613637
INFO:root:current train perplexity4.251042366027832
INFO:root:current mean train loss 3686.4797473538306
INFO:root:current train perplexity4.286624431610107
INFO:root:current mean train loss 3695.8549383425243
INFO:root:current train perplexity4.29125452041626
INFO:root:current mean train loss 3694.583117159991
INFO:root:current train perplexity4.29235315322876
INFO:root:current mean train loss 3705.2739687070743
INFO:root:current train perplexity4.3042168617248535
INFO:root:current mean train loss 3706.5421501090937
INFO:root:current train perplexity4.310390472412109
INFO:root:current mean train loss 3707.61520082896
INFO:root:current train perplexity4.315345764160156
INFO:root:current mean train loss 3708.8763455220405
INFO:root:current train perplexity4.32124662399292
INFO:root:current mean train loss 3710.2366836280153
INFO:root:current train perplexity4.320459842681885
INFO:root:current mean train loss 3712.861497617392
INFO:root:current train perplexity4.322344779968262


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.70s/it]
INFO:root:final mean train loss: 3710.6724360066078
INFO:root:final train perplexity: 4.32307767868042
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.98s/it]
INFO:root:eval mean loss: 3991.6935325243794
INFO:root:eval perplexity: 5.023483753204346
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/58

 29%|â–ˆâ–ˆâ–‰       | 58/200 [3:07:54<6:55:34, 175.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3698.9189491877482
INFO:root:current train perplexity4.307610511779785
INFO:root:current mean train loss 3680.8362774995207
INFO:root:current train perplexity4.267688751220703
INFO:root:current mean train loss 3689.8270351859555
INFO:root:current train perplexity4.275862693786621
INFO:root:current mean train loss 3682.4070846515583
INFO:root:current train perplexity4.2774248123168945
INFO:root:current mean train loss 3689.690033684024
INFO:root:current train perplexity4.287600517272949
INFO:root:current mean train loss 3692.9580971428177
INFO:root:current train perplexity4.290719985961914
INFO:root:current mean train loss 3695.2719052690186
INFO:root:current train perplexity4.293997287750244
INFO:root:current mean train loss 3696.9625437725263
INFO:root:current train perplexity4.300062656402588
INFO:root:current mean train loss 3699.324432337685
INFO:root:current train perplexity4.304903507232666
INFO:root:current mean train loss 3704.1284681658876
INFO:root:current train perplexity4.3088555335998535


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.99s/it]
INFO:root:final mean train loss: 3703.079633282077
INFO:root:final train perplexity: 4.310147285461426
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.63s/it]
INFO:root:eval mean loss: 3989.6766972102173
INFO:root:eval perplexity: 5.019388675689697
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/59

 30%|â–ˆâ–ˆâ–‰       | 59/200 [3:10:43<6:47:44, 173.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3690.0228563765404
INFO:root:current train perplexity4.273058891296387
INFO:root:current mean train loss 3675.9529536732457
INFO:root:current train perplexity4.255529880523682
INFO:root:current mean train loss 3690.04700472786
INFO:root:current train perplexity4.271109580993652
INFO:root:current mean train loss 3693.6594554150524
INFO:root:current train perplexity4.281683444976807
INFO:root:current mean train loss 3691.1716147906714
INFO:root:current train perplexity4.287402629852295
INFO:root:current mean train loss 3692.5145141815347
INFO:root:current train perplexity4.290757179260254
INFO:root:current mean train loss 3693.02714036012
INFO:root:current train perplexity4.291853904724121
INFO:root:current mean train loss 3695.5589696189
INFO:root:current train perplexity4.291958332061768
INFO:root:current mean train loss 3695.604768562536
INFO:root:current train perplexity4.292753219604492
INFO:root:current mean train loss 3695.3593885773366
INFO:root:current train perplexity4.293295860290527


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.52s/it]
INFO:root:final mean train loss: 3693.688660467825
INFO:root:final train perplexity: 4.29420804977417
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.45s/it]
INFO:root:eval mean loss: 3989.756659325133
INFO:root:eval perplexity: 5.0195512771606445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/60

 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [3:13:26<6:37:25, 170.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3679.5566746192644
INFO:root:current train perplexity4.275503158569336
INFO:root:current mean train loss 3690.9321261784216
INFO:root:current train perplexity4.281225204467773
INFO:root:current mean train loss 3687.310576626904
INFO:root:current train perplexity4.282969951629639
INFO:root:current mean train loss 3677.7133582927936
INFO:root:current train perplexity4.276340484619141
INFO:root:current mean train loss 3678.5567425626305
INFO:root:current train perplexity4.2729644775390625
INFO:root:current mean train loss 3682.2877899328046
INFO:root:current train perplexity4.278078079223633
INFO:root:current mean train loss 3680.340720355072
INFO:root:current train perplexity4.273967742919922
INFO:root:current mean train loss 3683.3831713459763
INFO:root:current train perplexity4.277210712432861
INFO:root:current mean train loss 3685.2325140873863
INFO:root:current train perplexity4.2773356437683105
INFO:root:current mean train loss 3689.627861607428
INFO:root:current train perplexity4.281653881072998


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.11s/it]
INFO:root:final mean train loss: 3686.3986031932213
INFO:root:final train perplexity: 4.281875133514404
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.73s/it]
INFO:root:eval mean loss: 3988.513048537234
INFO:root:eval perplexity: 5.017027854919434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/61

 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [3:16:09<6:29:20, 168.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3665.841589215158
INFO:root:current train perplexity4.226631164550781
INFO:root:current mean train loss 3673.3964791527405
INFO:root:current train perplexity4.252816200256348
INFO:root:current mean train loss 3677.380331963197
INFO:root:current train perplexity4.2576680183410645
INFO:root:current mean train loss 3680.0503863351905
INFO:root:current train perplexity4.261470794677734
INFO:root:current mean train loss 3681.258652704697
INFO:root:current train perplexity4.265096187591553
INFO:root:current mean train loss 3681.9625113128195
INFO:root:current train perplexity4.264416694641113
INFO:root:current mean train loss 3681.151528526428
INFO:root:current train perplexity4.264625549316406
INFO:root:current mean train loss 3680.3285760552335
INFO:root:current train perplexity4.267640590667725
INFO:root:current mean train loss 3679.3102033716177
INFO:root:current train perplexity4.266506195068359
INFO:root:current mean train loss 3680.874190402973
INFO:root:current train perplexity4.267702102661133


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.30s/it]
INFO:root:final mean train loss: 3678.0340421738165
INFO:root:final train perplexity: 4.267766952514648
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.14s/it]
INFO:root:eval mean loss: 3990.3792802526596
INFO:root:eval perplexity: 5.020814895629883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/62

 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [3:18:56<6:26:08, 167.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3645.955152652138
INFO:root:current train perplexity4.220336437225342
INFO:root:current mean train loss 3659.800415665064
INFO:root:current train perplexity4.238778591156006
INFO:root:current mean train loss 3664.314098914195
INFO:root:current train perplexity4.241474628448486
INFO:root:current mean train loss 3666.1643152937104
INFO:root:current train perplexity4.2430419921875
INFO:root:current mean train loss 3669.3052260890154
INFO:root:current train perplexity4.2418437004089355
INFO:root:current mean train loss 3671.3893895253414
INFO:root:current train perplexity4.249309539794922
INFO:root:current mean train loss 3671.096502290355
INFO:root:current train perplexity4.248823165893555
INFO:root:current mean train loss 3673.2270375761595
INFO:root:current train perplexity4.255385875701904
INFO:root:current mean train loss 3673.102446316341
INFO:root:current train perplexity4.254711627960205


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.87s/it]
INFO:root:final mean train loss: 3669.9169313984535
INFO:root:final train perplexity: 4.254122734069824
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.70s/it]
INFO:root:eval mean loss: 3990.6842638380986
INFO:root:eval perplexity: 5.021433353424072
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/63

 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [3:21:44<6:23:08, 167.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3691.9783528645835
INFO:root:current train perplexity4.315312385559082
INFO:root:current mean train loss 3669.0981966777913
INFO:root:current train perplexity4.236361026763916
INFO:root:current mean train loss 3655.766336976601
INFO:root:current train perplexity4.225662708282471
INFO:root:current mean train loss 3655.1623527098805
INFO:root:current train perplexity4.2334418296813965
INFO:root:current mean train loss 3662.584235785321
INFO:root:current train perplexity4.237501621246338
INFO:root:current mean train loss 3666.9861601873135
INFO:root:current train perplexity4.235297203063965
INFO:root:current mean train loss 3667.5142759509745
INFO:root:current train perplexity4.2354254722595215
INFO:root:current mean train loss 3664.680257045697
INFO:root:current train perplexity4.233907699584961
INFO:root:current mean train loss 3665.1108745038136
INFO:root:current train perplexity4.235490322113037
INFO:root:current mean train loss 3664.9333931383235
INFO:root:current train perplexity4.236209869384766


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.12s/it]
INFO:root:final mean train loss: 3661.2946504162205
INFO:root:final train perplexity: 4.239675521850586
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.86s/it]
INFO:root:eval mean loss: 3988.7749300476507
INFO:root:eval perplexity: 5.0175580978393555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/64

 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [3:24:27<6:17:03, 166.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3634.8147416548295
INFO:root:current train perplexity4.203908443450928
INFO:root:current mean train loss 3663.8242561409065
INFO:root:current train perplexity4.216176986694336
INFO:root:current mean train loss 3643.757463066499
INFO:root:current train perplexity4.211926460266113
INFO:root:current mean train loss 3633.0089444960813
INFO:root:current train perplexity4.205831527709961
INFO:root:current mean train loss 3639.2534007422823
INFO:root:current train perplexity4.206362724304199
INFO:root:current mean train loss 3645.678038236913
INFO:root:current train perplexity4.211956977844238
INFO:root:current mean train loss 3650.0463255837
INFO:root:current train perplexity4.217782020568848
INFO:root:current mean train loss 3652.682724664315
INFO:root:current train perplexity4.222280025482178
INFO:root:current mean train loss 3656.7534188718596
INFO:root:current train perplexity4.225699424743652
INFO:root:current mean train loss 3655.1000569214807
INFO:root:current train perplexity4.224933624267578


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.42s/it]
INFO:root:final mean train loss: 3653.2376571163054
INFO:root:final train perplexity: 4.226219654083252
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.15s/it]
INFO:root:eval mean loss: 3986.1737069204346
INFO:root:eval perplexity: 5.012284755706787
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/65
######################best############
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [3:27:16<6:16:31, 167.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3586.8047388980262
INFO:root:current train perplexity4.186344623565674
INFO:root:current mean train loss 3642.920578387605
INFO:root:current train perplexity4.200500011444092
INFO:root:current mean train loss 3644.8485625802655
INFO:root:current train perplexity4.202324390411377
INFO:root:current mean train loss 3646.159435308092
INFO:root:current train perplexity4.201914310455322
INFO:root:current mean train loss 3648.3965473038484
INFO:root:current train perplexity4.2078046798706055
INFO:root:current mean train loss 3644.6278944070627
INFO:root:current train perplexity4.202099800109863
INFO:root:current mean train loss 3650.063722675182
INFO:root:current train perplexity4.209792613983154
INFO:root:current mean train loss 3648.354694223205
INFO:root:current train perplexity4.212250709533691
INFO:root:current mean train loss 3646.682445484203
INFO:root:current train perplexity4.208528518676758
INFO:root:current mean train loss 3647.8193003391934
INFO:root:current train perplexity4.214261054992676


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.30s/it]
INFO:root:final mean train loss: 3647.6928107353947
INFO:root:final train perplexity: 4.216984272003174
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.08s/it]
INFO:root:eval mean loss: 3986.5949828235816
INFO:root:eval perplexity: 5.013137340545654
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/66

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [3:30:02<6:12:23, 166.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3609.2476218894676
INFO:root:current train perplexity4.115728378295898
INFO:root:current mean train loss 3625.035242756521
INFO:root:current train perplexity4.1712846755981445
INFO:root:current mean train loss 3638.947110751652
INFO:root:current train perplexity4.198737621307373
INFO:root:current mean train loss 3640.110918984136
INFO:root:current train perplexity4.195549964904785
INFO:root:current mean train loss 3642.252906245426
INFO:root:current train perplexity4.193552017211914
INFO:root:current mean train loss 3636.483730135199
INFO:root:current train perplexity4.189145088195801
INFO:root:current mean train loss 3636.559359269089
INFO:root:current train perplexity4.192716121673584
INFO:root:current mean train loss 3637.050151253009
INFO:root:current train perplexity4.197262763977051
INFO:root:current mean train loss 3637.711632725117
INFO:root:current train perplexity4.199117183685303
INFO:root:current mean train loss 3640.9349600947276
INFO:root:current train perplexity4.201746940612793


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.94s/it]
INFO:root:final mean train loss: 3639.3724682100355
INFO:root:final train perplexity: 4.203164577484131
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.97s/it]
INFO:root:eval mean loss: 3989.6054497035684
INFO:root:eval perplexity: 5.019244194030762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/67

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [3:32:47<6:08:23, 166.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3610.4027901785716
INFO:root:current train perplexity4.155958652496338
INFO:root:current mean train loss 3605.465456814236
INFO:root:current train perplexity4.158663272857666
INFO:root:current mean train loss 3614.514138339428
INFO:root:current train perplexity4.167004585266113
INFO:root:current mean train loss 3623.969580806903
INFO:root:current train perplexity4.173658847808838
INFO:root:current mean train loss 3623.527099048132
INFO:root:current train perplexity4.173663139343262
INFO:root:current mean train loss 3631.346728515625
INFO:root:current train perplexity4.180259704589844
INFO:root:current mean train loss 3631.4605880136564
INFO:root:current train perplexity4.177530765533447
INFO:root:current mean train loss 3633.3496588674534
INFO:root:current train perplexity4.183790683746338
INFO:root:current mean train loss 3635.2342527834953
INFO:root:current train perplexity4.188202857971191
INFO:root:current mean train loss 3636.978930272393
INFO:root:current train perplexity4.1904120445251465


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.58s/it]
INFO:root:final mean train loss: 3632.538471037342
INFO:root:final train perplexity: 4.191847801208496
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.86s/it]
INFO:root:eval mean loss: 3989.3783521719856
INFO:root:eval perplexity: 5.018782615661621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/68

 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [3:35:35<6:07:06, 166.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3617.463747956032
INFO:root:current train perplexity4.157128810882568
INFO:root:current mean train loss 3631.5384120274257
INFO:root:current train perplexity4.176871299743652
INFO:root:current mean train loss 3630.306695883166
INFO:root:current train perplexity4.176765441894531
INFO:root:current mean train loss 3628.2411127118257
INFO:root:current train perplexity4.171766757965088
INFO:root:current mean train loss 3622.559475522009
INFO:root:current train perplexity4.16771936416626
INFO:root:current mean train loss 3625.092338660365
INFO:root:current train perplexity4.170825958251953
INFO:root:current mean train loss 3628.7603602194304
INFO:root:current train perplexity4.173990249633789
INFO:root:current mean train loss 3629.617264718098
INFO:root:current train perplexity4.177103042602539
INFO:root:current mean train loss 3631.493379821415
INFO:root:current train perplexity4.1807146072387695
INFO:root:current mean train loss 3628.498212051796
INFO:root:current train perplexity4.178479194641113


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.61s/it]
INFO:root:final mean train loss: 3625.104615672942
INFO:root:final train perplexity: 4.179571628570557
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.13s/it]
INFO:root:eval mean loss: 3988.7473213791
INFO:root:eval perplexity: 5.017502784729004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/69

 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [3:38:19<6:02:15, 165.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3603.5000861672793
INFO:root:current train perplexity4.146792411804199
INFO:root:current mean train loss 3600.1314381984685
INFO:root:current train perplexity4.15219259262085
INFO:root:current mean train loss 3604.330182200884
INFO:root:current train perplexity4.148875713348389
INFO:root:current mean train loss 3613.6726018574163
INFO:root:current train perplexity4.160586357116699
INFO:root:current mean train loss 3606.2074724353865
INFO:root:current train perplexity4.157479286193848
INFO:root:current mean train loss 3607.991318164417
INFO:root:current train perplexity4.161790370941162
INFO:root:current mean train loss 3612.2659981488814
INFO:root:current train perplexity4.163633823394775
INFO:root:current mean train loss 3614.3601012452145
INFO:root:current train perplexity4.165955543518066
INFO:root:current mean train loss 3617.959839871291
INFO:root:current train perplexity4.1666035652160645
INFO:root:current mean train loss 3621.243947314915
INFO:root:current train perplexity4.168898582458496


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.04s/it]
INFO:root:final mean train loss: 3619.251803613478
INFO:root:final train perplexity: 4.169931411743164
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.81s/it]
INFO:root:eval mean loss: 3989.1009599401596
INFO:root:eval perplexity: 5.0182204246521
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/70

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [3:41:03<5:58:09, 165.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3570.4415593551375
INFO:root:current train perplexity4.136223316192627
INFO:root:current mean train loss 3581.523764556309
INFO:root:current train perplexity4.133416175842285
INFO:root:current mean train loss 3597.5015600491674
INFO:root:current train perplexity4.142195224761963
INFO:root:current mean train loss 3598.038092058017
INFO:root:current train perplexity4.1450300216674805
INFO:root:current mean train loss 3600.195759293301
INFO:root:current train perplexity4.141190528869629
INFO:root:current mean train loss 3600.9042903238205
INFO:root:current train perplexity4.142429351806641
INFO:root:current mean train loss 3603.050157005762
INFO:root:current train perplexity4.144562721252441
INFO:root:current mean train loss 3604.2601210602975
INFO:root:current train perplexity4.148300647735596
INFO:root:current mean train loss 3607.12611895418
INFO:root:current train perplexity4.1509013175964355
INFO:root:current mean train loss 3612.7551575025254
INFO:root:current train perplexity4.154065132141113


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.44s/it]
INFO:root:final mean train loss: 3611.0486345598774
INFO:root:final train perplexity: 4.156458377838135
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.70s/it]
INFO:root:eval mean loss: 3988.318411319814
INFO:root:eval perplexity: 5.016632556915283
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/71

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [3:43:48<5:55:18, 165.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3576.5790323285914
INFO:root:current train perplexity4.085484504699707
INFO:root:current mean train loss 3581.5202549003557
INFO:root:current train perplexity4.101891994476318
INFO:root:current mean train loss 3582.700053582924
INFO:root:current train perplexity4.113790512084961
INFO:root:current mean train loss 3597.4844488408976
INFO:root:current train perplexity4.129161357879639
INFO:root:current mean train loss 3597.282193627041
INFO:root:current train perplexity4.12825870513916
INFO:root:current mean train loss 3593.355625482253
INFO:root:current train perplexity4.13041353225708
INFO:root:current mean train loss 3599.5589616080633
INFO:root:current train perplexity4.134275913238525
INFO:root:current mean train loss 3601.5014642071383
INFO:root:current train perplexity4.1379876136779785
INFO:root:current mean train loss 3601.1668620918035
INFO:root:current train perplexity4.139256000518799
INFO:root:current mean train loss 3607.5386792471886
INFO:root:current train perplexity4.146693706512451


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.64s/it]
INFO:root:final mean train loss: 3604.925244423651
INFO:root:final train perplexity: 4.146428108215332
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.34s/it]
INFO:root:eval mean loss: 3990.7851112311614
INFO:root:eval perplexity: 5.0216383934021
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/72

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [3:46:37<5:54:56, 166.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3613.4013671875
INFO:root:current train perplexity4.117673873901367
INFO:root:current mean train loss 3595.0520577566963
INFO:root:current train perplexity4.114322662353516
INFO:root:current mean train loss 3596.7880495383524
INFO:root:current train perplexity4.117032051086426
INFO:root:current mean train loss 3594.220169921875
INFO:root:current train perplexity4.124680519104004
INFO:root:current mean train loss 3597.7707026110197
INFO:root:current train perplexity4.130721092224121
INFO:root:current mean train loss 3598.228099949049
INFO:root:current train perplexity4.129344463348389
INFO:root:current mean train loss 3597.87041015625
INFO:root:current train perplexity4.1295647621154785
INFO:root:current mean train loss 3599.4486734501006
INFO:root:current train perplexity4.1335296630859375
INFO:root:current mean train loss 3600.92801953125
INFO:root:current train perplexity4.134064197540283
INFO:root:current mean train loss 3601.2669598858174
INFO:root:current train perplexity4.13561487197876


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.66s/it]
INFO:root:final mean train loss: 3597.9518097908267
INFO:root:final train perplexity: 4.135035991668701
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.23s/it]
INFO:root:eval mean loss: 3988.853622977615
INFO:root:eval perplexity: 5.01771879196167
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/73

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [3:49:22<5:51:15, 165.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3558.35152720256
INFO:root:current train perplexity4.087930679321289
INFO:root:current mean train loss 3576.5665463306864
INFO:root:current train perplexity4.104733467102051
INFO:root:current mean train loss 3587.967687168728
INFO:root:current train perplexity4.118066310882568
INFO:root:current mean train loss 3586.6171613648416
INFO:root:current train perplexity4.113031387329102
INFO:root:current mean train loss 3587.9881538722825
INFO:root:current train perplexity4.118469715118408
INFO:root:current mean train loss 3588.3580521179515
INFO:root:current train perplexity4.121641159057617
INFO:root:current mean train loss 3590.609001461269
INFO:root:current train perplexity4.122546672821045
INFO:root:current mean train loss 3590.5306575770273
INFO:root:current train perplexity4.121071815490723
INFO:root:current mean train loss 3591.864209150269
INFO:root:current train perplexity4.120964050292969
INFO:root:current mean train loss 3592.907329633059
INFO:root:current train perplexity4.123147010803223


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:37<00:00, 157.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:37<00:00, 157.51s/it]
INFO:root:final mean train loss: 3590.872645285822
INFO:root:final train perplexity: 4.1235032081604
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.23s/it]
INFO:root:eval mean loss: 3992.9343053939497
INFO:root:eval perplexity: 5.026005268096924
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/74

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [3:52:13<5:52:08, 167.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3591.2127537989354
INFO:root:current train perplexity4.107364177703857
INFO:root:current mean train loss 3573.116963810946
INFO:root:current train perplexity4.0868988037109375
INFO:root:current mean train loss 3580.6746931043276
INFO:root:current train perplexity4.09610652923584
INFO:root:current mean train loss 3577.286179018143
INFO:root:current train perplexity4.097219944000244
INFO:root:current mean train loss 3577.0458800399374
INFO:root:current train perplexity4.097053527832031
INFO:root:current mean train loss 3578.553713416085
INFO:root:current train perplexity4.095081329345703
INFO:root:current mean train loss 3580.12280308769
INFO:root:current train perplexity4.101402282714844
INFO:root:current mean train loss 3581.6347279699353
INFO:root:current train perplexity4.105700492858887
INFO:root:current mean train loss 3583.113838033109
INFO:root:current train perplexity4.108251094818115
INFO:root:current mean train loss 3586.9041170337728
INFO:root:current train perplexity4.112531661987305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.41s/it]
INFO:root:final mean train loss: 3584.1250320557624
INFO:root:final train perplexity: 4.112540245056152
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.24s/it]
INFO:root:eval mean loss: 3988.524976797983
INFO:root:eval perplexity: 5.0170512199401855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/75

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [3:54:57<5:46:48, 166.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3565.1871202256943
INFO:root:current train perplexity4.084061622619629
INFO:root:current mean train loss 3577.14226773516
INFO:root:current train perplexity4.087409973144531
INFO:root:current mean train loss 3576.4102738294314
INFO:root:current train perplexity4.093832015991211
INFO:root:current mean train loss 3574.6606885867013
INFO:root:current train perplexity4.093843936920166
INFO:root:current mean train loss 3578.8802057239477
INFO:root:current train perplexity4.096627235412598
INFO:root:current mean train loss 3578.739250883634
INFO:root:current train perplexity4.093611717224121
INFO:root:current mean train loss 3581.269248340263
INFO:root:current train perplexity4.100010395050049
INFO:root:current mean train loss 3578.8398553611937
INFO:root:current train perplexity4.099194526672363
INFO:root:current mean train loss 3579.4571572580644
INFO:root:current train perplexity4.101605415344238


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.28s/it]
INFO:root:final mean train loss: 3577.7441272735596
INFO:root:final train perplexity: 4.102200508117676
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.58s/it]
INFO:root:eval mean loss: 3991.8150608793217
INFO:root:eval perplexity: 5.023730754852295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/76

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [3:58:22<6:07:56, 178.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3572.8761858258927
INFO:root:current train perplexity4.096829414367676
INFO:root:current mean train loss 3569.9581447137853
INFO:root:current train perplexity4.09171199798584
INFO:root:current mean train loss 3564.0340865130584
INFO:root:current train perplexity4.081103801727295
INFO:root:current mean train loss 3563.761531867111
INFO:root:current train perplexity4.075784206390381
INFO:root:current mean train loss 3567.996421270347
INFO:root:current train perplexity4.0809102058410645
INFO:root:current mean train loss 3566.888900124815
INFO:root:current train perplexity4.079710960388184
INFO:root:current mean train loss 3571.792250807635
INFO:root:current train perplexity4.085194110870361
INFO:root:current mean train loss 3572.570853960396
INFO:root:current train perplexity4.087769508361816
INFO:root:current mean train loss 3572.5457550389174
INFO:root:current train perplexity4.087770938873291
INFO:root:current mean train loss 3571.725046782404
INFO:root:current train perplexity4.087737083435059


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:38<00:00, 158.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:38<00:00, 158.84s/it]
INFO:root:final mean train loss: 3570.404794508411
INFO:root:final train perplexity: 4.0903401374816895
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.26s/it]
INFO:root:eval mean loss: 3991.4565464317375
INFO:root:eval perplexity: 5.023002624511719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/77

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [4:01:14<6:01:19, 176.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3526.9466959635415
INFO:root:current train perplexity4.016548156738281
INFO:root:current mean train loss 3555.147494904891
INFO:root:current train perplexity4.049686908721924
INFO:root:current mean train loss 3560.808826535247
INFO:root:current train perplexity4.057377338409424
INFO:root:current mean train loss 3557.024914744544
INFO:root:current train perplexity4.058434963226318
INFO:root:current mean train loss 3561.9226209525605
INFO:root:current train perplexity4.068570613861084
INFO:root:current mean train loss 3563.4353207486347
INFO:root:current train perplexity4.072202682495117
INFO:root:current mean train loss 3559.3956531059453
INFO:root:current train perplexity4.068185806274414
INFO:root:current mean train loss 3563.06719945094
INFO:root:current train perplexity4.073663234710693
INFO:root:current mean train loss 3564.1721164445935
INFO:root:current train perplexity4.076290130615234
INFO:root:current mean train loss 3565.2840689570526
INFO:root:current train perplexity4.077336311340332


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.64s/it]
INFO:root:final mean train loss: 3564.2527146493235
INFO:root:final train perplexity: 4.080423831939697
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.21s/it]
INFO:root:eval mean loss: 3991.594096298759
INFO:root:eval perplexity: 5.023281574249268
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/78

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [4:04:56<6:26:04, 189.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3555.809771993886
INFO:root:current train perplexity4.067086219787598
INFO:root:current mean train loss 3552.50628413999
INFO:root:current train perplexity4.068697452545166
INFO:root:current mean train loss 3549.3309736722254
INFO:root:current train perplexity4.0678277015686035
INFO:root:current mean train loss 3551.611186024574
INFO:root:current train perplexity4.061853885650635
INFO:root:current mean train loss 3551.1867225592864
INFO:root:current train perplexity4.061299800872803
INFO:root:current mean train loss 3550.2243334914256
INFO:root:current train perplexity4.062932968139648
INFO:root:current mean train loss 3555.4174013091892
INFO:root:current train perplexity4.065735340118408
INFO:root:current mean train loss 3555.1297031682225
INFO:root:current train perplexity4.063723564147949
INFO:root:current mean train loss 3557.3307862218066
INFO:root:current train perplexity4.064470291137695
INFO:root:current mean train loss 3558.426391204801
INFO:root:current train perplexity4.068994522094727


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:41<00:00, 161.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:41<00:00, 161.26s/it]
INFO:root:final mean train loss: 3558.1589439145982
INFO:root:final train perplexity: 4.0706257820129395
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.65s/it]
INFO:root:eval mean loss: 3994.4683863863033
INFO:root:eval perplexity: 5.0291242599487305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/79

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [4:08:40<6:43:50, 200.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3541.415346207157
INFO:root:current train perplexity4.028843402862549
INFO:root:current mean train loss 3549.3294575232585
INFO:root:current train perplexity4.048986434936523
INFO:root:current mean train loss 3554.533137598079
INFO:root:current train perplexity4.050637245178223
INFO:root:current mean train loss 3557.789520540266
INFO:root:current train perplexity4.051997661590576
INFO:root:current mean train loss 3555.538927684527
INFO:root:current train perplexity4.056643009185791
INFO:root:current mean train loss 3554.8829596280602
INFO:root:current train perplexity4.059505939483643
INFO:root:current mean train loss 3554.949428068666
INFO:root:current train perplexity4.059544086456299
INFO:root:current mean train loss 3553.722607488671
INFO:root:current train perplexity4.058166980743408
INFO:root:current mean train loss 3556.767675369942
INFO:root:current train perplexity4.062277793884277
INFO:root:current mean train loss 3553.790905748607
INFO:root:current train perplexity4.061192512512207


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.28s/it]
INFO:root:final mean train loss: 3551.32154058641
INFO:root:final train perplexity: 4.059659481048584
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.81s/it]
INFO:root:eval mean loss: 3993.126475232713
INFO:root:eval perplexity: 5.02639627456665
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/80

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [4:11:41<6:28:41, 194.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3503.1717497996797
INFO:root:current train perplexity4.0435099601745605
INFO:root:current mean train loss 3527.4146842682103
INFO:root:current train perplexity4.026494979858398
INFO:root:current mean train loss 3530.010215088912
INFO:root:current train perplexity4.02657413482666
INFO:root:current mean train loss 3534.7070751809088
INFO:root:current train perplexity4.025707244873047
INFO:root:current mean train loss 3536.1615715982703
INFO:root:current train perplexity4.035635471343994
INFO:root:current mean train loss 3537.0308387204313
INFO:root:current train perplexity4.038647174835205
INFO:root:current mean train loss 3543.9905961921704
INFO:root:current train perplexity4.0451979637146
INFO:root:current mean train loss 3546.022252806791
INFO:root:current train perplexity4.049580097198486
INFO:root:current mean train loss 3547.6080317900773
INFO:root:current train perplexity4.051222324371338
INFO:root:current mean train loss 3547.6588981067794
INFO:root:current train perplexity4.050931453704834


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.22s/it]
INFO:root:final mean train loss: 3546.9424557224397
INFO:root:final train perplexity: 4.0526509284973145
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.85s/it]
INFO:root:eval mean loss: 3993.2088614389404
INFO:root:eval perplexity: 5.0265631675720215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/81

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [4:14:26<6:08:01, 185.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3548.6070322888963
INFO:root:current train perplexity4.079189777374268
INFO:root:current mean train loss 3554.7072571215986
INFO:root:current train perplexity4.051694393157959
INFO:root:current mean train loss 3539.0848650604125
INFO:root:current train perplexity4.036283493041992
INFO:root:current mean train loss 3536.391665587851
INFO:root:current train perplexity4.031973838806152
INFO:root:current mean train loss 3542.4269730058027
INFO:root:current train perplexity4.032815456390381
INFO:root:current mean train loss 3536.8490885119118
INFO:root:current train perplexity4.032924652099609
INFO:root:current mean train loss 3539.629356419653
INFO:root:current train perplexity4.036208152770996
INFO:root:current mean train loss 3542.9948155251213
INFO:root:current train perplexity4.036843299865723
INFO:root:current mean train loss 3545.5598793074823
INFO:root:current train perplexity4.040178298950195
INFO:root:current mean train loss 3543.088539776102
INFO:root:current train perplexity4.042603492736816


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.62s/it]
INFO:root:final mean train loss: 3540.1304398813554
INFO:root:final train perplexity: 4.041774272918701
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.30s/it]
INFO:root:eval mean loss: 3996.76572542664
INFO:root:eval perplexity: 5.033797740936279
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/82

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [4:17:10<5:52:08, 179.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3538.455508700284
INFO:root:current train perplexity4.02780818939209
INFO:root:current mean train loss 3532.5739509828627
INFO:root:current train perplexity4.026437759399414
INFO:root:current mean train loss 3526.442666207108
INFO:root:current train perplexity4.020650386810303
INFO:root:current mean train loss 3531.1079521071742
INFO:root:current train perplexity4.029336929321289
INFO:root:current mean train loss 3528.8444759830013
INFO:root:current train perplexity4.033626079559326
INFO:root:current mean train loss 3531.5094370249153
INFO:root:current train perplexity4.033720970153809
INFO:root:current mean train loss 3532.2782152015743
INFO:root:current train perplexity4.032573699951172
INFO:root:current mean train loss 3534.728161216887
INFO:root:current train perplexity4.0326247215271
INFO:root:current mean train loss 3535.8231942160087
INFO:root:current train perplexity4.0319108963012695
INFO:root:current mean train loss 3538.9250380910503
INFO:root:current train perplexity4.034323692321777


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.24s/it]
INFO:root:final mean train loss: 3534.5536853421117
INFO:root:final train perplexity: 4.032892227172852
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.66s/it]
INFO:root:eval mean loss: 3995.09672990082
INFO:root:eval perplexity: 5.030402183532715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/83

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [4:19:53<5:39:41, 174.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3526.9021964905755
INFO:root:current train perplexity3.988165855407715
INFO:root:current mean train loss 3527.803724417657
INFO:root:current train perplexity4.008402347564697
INFO:root:current mean train loss 3518.992888359969
INFO:root:current train perplexity4.015117168426514
INFO:root:current mean train loss 3519.13996790526
INFO:root:current train perplexity4.016758441925049
INFO:root:current mean train loss 3522.2067697084235
INFO:root:current train perplexity4.014637470245361
INFO:root:current mean train loss 3523.750279265653
INFO:root:current train perplexity4.016961097717285
INFO:root:current mean train loss 3528.301453281132
INFO:root:current train perplexity4.021138668060303
INFO:root:current mean train loss 3531.528313593033
INFO:root:current train perplexity4.024796009063721
INFO:root:current mean train loss 3531.01429311812
INFO:root:current train perplexity4.023413181304932
INFO:root:current mean train loss 3530.9796846098616
INFO:root:current train perplexity4.023629188537598


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.64s/it]
INFO:root:final mean train loss: 3528.9764313851633
INFO:root:final train perplexity: 4.024027347564697
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.69s/it]
INFO:root:eval mean loss: 3996.8287327543217
INFO:root:eval perplexity: 5.033925533294678
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/84

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [4:22:36<5:30:38, 171.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3496.148028306558
INFO:root:current train perplexity3.990753412246704
INFO:root:current mean train loss 3508.9776804070725
INFO:root:current train perplexity3.993337869644165
INFO:root:current mean train loss 3505.4285866149676
INFO:root:current train perplexity3.992591142654419
INFO:root:current mean train loss 3508.221592165389
INFO:root:current train perplexity3.9986774921417236
INFO:root:current mean train loss 3511.7565840216957
INFO:root:current train perplexity3.999812602996826
INFO:root:current mean train loss 3517.1047581340304
INFO:root:current train perplexity4.003415584564209
INFO:root:current mean train loss 3521.222632600014
INFO:root:current train perplexity4.00758171081543
INFO:root:current mean train loss 3525.026181627959
INFO:root:current train perplexity4.009363174438477
INFO:root:current mean train loss 3525.6533009718537
INFO:root:current train perplexity4.011850357055664
INFO:root:current mean train loss 3524.299742332325
INFO:root:current train perplexity4.012333393096924


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.03s/it]
INFO:root:final mean train loss: 3521.362909378544
INFO:root:final train perplexity: 4.011958599090576
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.46s/it]
INFO:root:eval mean loss: 3996.2251374806074
INFO:root:eval perplexity: 5.032697677612305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/85

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [4:26:07<5:50:40, 182.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3477.5561832476264
INFO:root:current train perplexity4.005425930023193
INFO:root:current mean train loss 3502.8753832598636
INFO:root:current train perplexity4.000202178955078
INFO:root:current mean train loss 3515.471932578685
INFO:root:current train perplexity4.001683712005615
INFO:root:current mean train loss 3518.119029183501
INFO:root:current train perplexity3.998289108276367
INFO:root:current mean train loss 3518.071182027988
INFO:root:current train perplexity3.999950408935547
INFO:root:current mean train loss 3517.278809437068
INFO:root:current train perplexity4.002619743347168
INFO:root:current mean train loss 3516.017800692079
INFO:root:current train perplexity4.003674507141113
INFO:root:current mean train loss 3518.5357818015887
INFO:root:current train perplexity4.004726409912109
INFO:root:current mean train loss 3520.2274035214023
INFO:root:current train perplexity4.005068778991699
INFO:root:current mean train loss 3520.857421376245
INFO:root:current train perplexity4.005407810211182


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.92s/it]
INFO:root:final mean train loss: 3517.6012720292615
INFO:root:final train perplexity: 4.006008625030518
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.77s/it]
INFO:root:eval mean loss: 3996.7908338181514
INFO:root:eval perplexity: 5.033848762512207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/86

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [4:30:09<6:21:04, 200.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3477.5668412131827
INFO:root:current train perplexity3.9615931510925293
INFO:root:current mean train loss 3485.849910960478
INFO:root:current train perplexity3.96659517288208
INFO:root:current mean train loss 3490.878281011814
INFO:root:current train perplexity3.983466148376465
INFO:root:current mean train loss 3495.833549716368
INFO:root:current train perplexity3.983689785003662
INFO:root:current mean train loss 3499.2838357851
INFO:root:current train perplexity3.983525037765503
INFO:root:current mean train loss 3505.667444284364
INFO:root:current train perplexity3.987745523452759
INFO:root:current mean train loss 3506.4804843863717
INFO:root:current train perplexity3.9879138469696045
INFO:root:current mean train loss 3510.486963449015
INFO:root:current train perplexity3.99359130859375
INFO:root:current mean train loss 3511.6041910715544
INFO:root:current train perplexity3.9938244819641113
INFO:root:current mean train loss 3513.3306111777324
INFO:root:current train perplexity3.99481201171875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.41s/it]
INFO:root:final mean train loss: 3510.7408697682044
INFO:root:final train perplexity: 3.995181083679199
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.05s/it]
INFO:root:eval mean loss: 3997.2543321974736
INFO:root:eval perplexity: 5.034792900085449
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/87

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [4:34:03<6:36:56, 210.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3498.7853875411183
INFO:root:current train perplexity3.9594757556915283
INFO:root:current mean train loss 3514.501727764423
INFO:root:current train perplexity3.977360248565674
INFO:root:current mean train loss 3512.450051310911
INFO:root:current train perplexity3.9830515384674072
INFO:root:current mean train loss 3503.9593978688686
INFO:root:current train perplexity3.97895884513855
INFO:root:current mean train loss 3503.622315932765
INFO:root:current train perplexity3.978681802749634
INFO:root:current mean train loss 3505.558783728335
INFO:root:current train perplexity3.9771814346313477
INFO:root:current mean train loss 3504.5767757278554
INFO:root:current train perplexity3.978950262069702
INFO:root:current mean train loss 3506.151665683962
INFO:root:current train perplexity3.9831960201263428
INFO:root:current mean train loss 3508.1571010824023
INFO:root:current train perplexity3.986888885498047


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.18s/it]
INFO:root:final mean train loss: 3506.2604604536486
INFO:root:final train perplexity: 3.9881248474121094
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.32s/it]
INFO:root:eval mean loss: 3999.1067240830007
INFO:root:eval perplexity: 5.038565635681152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/88

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [4:37:14<6:22:29, 204.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3699.2521158854165
INFO:root:current train perplexity4.08480167388916
INFO:root:current mean train loss 3512.515041906857
INFO:root:current train perplexity3.9773507118225098
INFO:root:current mean train loss 3498.720268963593
INFO:root:current train perplexity3.9650487899780273
INFO:root:current mean train loss 3493.722202615769
INFO:root:current train perplexity3.9593374729156494
INFO:root:current mean train loss 3499.026170299899
INFO:root:current train perplexity3.969783067703247
INFO:root:current mean train loss 3499.3189209469742
INFO:root:current train perplexity3.972952127456665
INFO:root:current mean train loss 3500.2565998944083
INFO:root:current train perplexity3.972113609313965
INFO:root:current mean train loss 3496.263130806588
INFO:root:current train perplexity3.970264434814453
INFO:root:current mean train loss 3498.7305140513113
INFO:root:current train perplexity3.970968723297119
INFO:root:current mean train loss 3499.790029870051
INFO:root:current train perplexity3.975862741470337


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.04s/it]
INFO:root:final mean train loss: 3499.1262863528345
INFO:root:final train perplexity: 3.9769155979156494
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.85s/it]
INFO:root:eval mean loss: 4000.085045780696
INFO:root:eval perplexity: 5.040558815002441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/89

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [4:39:56<5:55:12, 192.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3490.255925958807
INFO:root:current train perplexity3.9118521213531494
INFO:root:current mean train loss 3486.4710484410193
INFO:root:current train perplexity3.9568612575531006
INFO:root:current mean train loss 3484.3726823996594
INFO:root:current train perplexity3.956580638885498
INFO:root:current mean train loss 3481.5524658988143
INFO:root:current train perplexity3.955662727355957
INFO:root:current mean train loss 3481.0824333989126
INFO:root:current train perplexity3.951042890548706
INFO:root:current mean train loss 3483.5820818936522
INFO:root:current train perplexity3.9530904293060303
INFO:root:current mean train loss 3486.0904331238494
INFO:root:current train perplexity3.9600725173950195
INFO:root:current mean train loss 3492.1732687648337
INFO:root:current train perplexity3.961751937866211
INFO:root:current mean train loss 3491.7728869041885
INFO:root:current train perplexity3.9628119468688965
INFO:root:current mean train loss 3494.511449686128
INFO:root:current train perplexity3.9665839672088623


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.93s/it]
INFO:root:final mean train loss: 3494.2578852253578
INFO:root:final train perplexity: 3.969284772872925
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.80s/it]
INFO:root:eval mean loss: 4002.650013159353
INFO:root:eval perplexity: 5.0457892417907715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/90

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [4:42:43<5:38:05, 184.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3448.2368935032896
INFO:root:current train perplexity3.9911258220672607
INFO:root:current mean train loss 3485.977237477022
INFO:root:current train perplexity3.939889907836914
INFO:root:current mean train loss 3500.7999819402826
INFO:root:current train perplexity3.9494686126708984
INFO:root:current mean train loss 3496.293693518564
INFO:root:current train perplexity3.9541330337524414
INFO:root:current mean train loss 3496.572540647375
INFO:root:current train perplexity3.9526846408843994
INFO:root:current mean train loss 3494.757898113861
INFO:root:current train perplexity3.953705310821533
INFO:root:current mean train loss 3491.325373980841
INFO:root:current train perplexity3.954388380050659
INFO:root:current mean train loss 3488.49339971423
INFO:root:current train perplexity3.9582245349884033
INFO:root:current mean train loss 3490.006640684619
INFO:root:current train perplexity3.9599497318267822
INFO:root:current mean train loss 3493.5595936904924
INFO:root:current train perplexity3.9628679752349854


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:40<00:00, 160.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:40<00:00, 160.66s/it]
INFO:root:final mean train loss: 3489.7492534268285
INFO:root:final train perplexity: 3.9622304439544678
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.54s/it]
INFO:root:eval mean loss: 4002.550452266179
INFO:root:eval perplexity: 5.045586585998535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/91

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [4:45:37<5:29:24, 181.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3475.966462311921
INFO:root:current train perplexity3.9754698276519775
INFO:root:current mean train loss 3477.7666380874753
INFO:root:current train perplexity3.943305253982544
INFO:root:current mean train loss 3477.250193591685
INFO:root:current train perplexity3.946822166442871
INFO:root:current mean train loss 3479.019611883601
INFO:root:current train perplexity3.946143388748169
INFO:root:current mean train loss 3473.9424514234483
INFO:root:current train perplexity3.9444761276245117
INFO:root:current mean train loss 3480.1136009028105
INFO:root:current train perplexity3.9496536254882812
INFO:root:current mean train loss 3482.37392726089
INFO:root:current train perplexity3.948857545852661
INFO:root:current mean train loss 3484.9703021567657
INFO:root:current train perplexity3.9513180255889893
INFO:root:current mean train loss 3485.6013933433155
INFO:root:current train perplexity3.953160047531128
INFO:root:current mean train loss 3485.68585448692
INFO:root:current train perplexity3.95296311378479


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:37<00:00, 157.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:37<00:00, 157.47s/it]
INFO:root:final mean train loss: 3484.012129629812
INFO:root:final train perplexity: 3.9532718658447266
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it]
INFO:root:eval mean loss: 4006.0481770833335
INFO:root:eval perplexity: 5.052728176116943
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/92

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [4:48:28<5:20:37, 178.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3464.4717215401784
INFO:root:current train perplexity3.9275362491607666
INFO:root:current mean train loss 3473.2500560619214
INFO:root:current train perplexity3.932558059692383
INFO:root:current mean train loss 3480.5307710688166
INFO:root:current train perplexity3.9435384273529053
INFO:root:current mean train loss 3482.805599201259
INFO:root:current train perplexity3.9441041946411133
INFO:root:current mean train loss 3485.883339507004
INFO:root:current train perplexity3.947793483734131
INFO:root:current mean train loss 3486.173450733791
INFO:root:current train perplexity3.9487318992614746
INFO:root:current mean train loss 3481.7423382135826
INFO:root:current train perplexity3.943046808242798
INFO:root:current mean train loss 3478.6989789275085
INFO:root:current train perplexity3.941699504852295
INFO:root:current mean train loss 3480.6481954060628
INFO:root:current train perplexity3.94400954246521
INFO:root:current mean train loss 3479.9269766251673
INFO:root:current train perplexity3.9429049491882324


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:38<00:00, 158.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:38<00:00, 158.76s/it]
INFO:root:final mean train loss: 3479.69967983615
INFO:root:final train perplexity: 3.946552038192749
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.24s/it]
INFO:root:eval mean loss: 4003.1179216533687
INFO:root:eval perplexity: 5.0467448234558105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/93

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [4:51:24<5:16:26, 177.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3433.0261684683865
INFO:root:current train perplexity3.9134318828582764
INFO:root:current mean train loss 3474.2419297011584
INFO:root:current train perplexity3.9134368896484375
INFO:root:current mean train loss 3466.4065996334875
INFO:root:current train perplexity3.926121473312378
INFO:root:current mean train loss 3467.445301823296
INFO:root:current train perplexity3.9265120029449463
INFO:root:current mean train loss 3466.382479079959
INFO:root:current train perplexity3.9261200428009033
INFO:root:current mean train loss 3467.007350746
INFO:root:current train perplexity3.9268696308135986
INFO:root:current mean train loss 3469.0901733208593
INFO:root:current train perplexity3.9315154552459717
INFO:root:current mean train loss 3474.7819232760976
INFO:root:current train perplexity3.9342713356018066
INFO:root:current mean train loss 3475.1789319093823
INFO:root:current train perplexity3.935317039489746
INFO:root:current mean train loss 3475.985838808159
INFO:root:current train perplexity3.9365086555480957


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:40<00:00, 160.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:40<00:00, 160.12s/it]
INFO:root:final mean train loss: 3473.445046886321
INFO:root:final train perplexity: 3.9368250370025635
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.54s/it]
INFO:root:eval mean loss: 4003.4304995705897
INFO:root:eval perplexity: 5.047382354736328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/94

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [4:54:18<5:12:01, 176.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3455.90935680913
INFO:root:current train perplexity3.930565118789673
INFO:root:current mean train loss 3468.7113934447434
INFO:root:current train perplexity3.9218530654907227
INFO:root:current mean train loss 3470.1067740755725
INFO:root:current train perplexity3.925274610519409
INFO:root:current mean train loss 3469.471971821581
INFO:root:current train perplexity3.915435552597046
INFO:root:current mean train loss 3467.0886030176
INFO:root:current train perplexity3.9167604446411133
INFO:root:current mean train loss 3470.3063060947425
INFO:root:current train perplexity3.9239566326141357
INFO:root:current mean train loss 3470.1136911512335
INFO:root:current train perplexity3.927318572998047
INFO:root:current mean train loss 3470.2082769848535
INFO:root:current train perplexity3.92620587348938
INFO:root:current mean train loss 3470.0641404184416
INFO:root:current train perplexity3.9276087284088135
INFO:root:current mean train loss 3471.422737578864
INFO:root:current train perplexity3.9307100772857666


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.84s/it]
INFO:root:final mean train loss: 3467.7684096059493
INFO:root:final train perplexity: 3.928018093109131
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.71s/it]
INFO:root:eval mean loss: 4007.7991692292776
INFO:root:eval perplexity: 5.056306838989258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/95

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [4:57:07<5:04:49, 174.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3433.16650390625
INFO:root:current train perplexity3.8727049827575684
INFO:root:current mean train loss 3444.5007723442413
INFO:root:current train perplexity3.8799705505371094
INFO:root:current mean train loss 3447.921883483651
INFO:root:current train perplexity3.8886606693267822
INFO:root:current mean train loss 3455.6603963102802
INFO:root:current train perplexity3.8979172706604004
INFO:root:current mean train loss 3456.765157462725
INFO:root:current train perplexity3.9015448093414307
INFO:root:current mean train loss 3461.555394153902
INFO:root:current train perplexity3.9063186645507812
INFO:root:current mean train loss 3460.9367875835783
INFO:root:current train perplexity3.9089417457580566
INFO:root:current mean train loss 3463.8220533288045
INFO:root:current train perplexity3.91294002532959
INFO:root:current mean train loss 3466.5520937545475
INFO:root:current train perplexity3.917464256286621
INFO:root:current mean train loss 3467.218678718066
INFO:root:current train perplexity3.919754981994629


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.35s/it]
INFO:root:final mean train loss: 3462.8218303803474
INFO:root:final train perplexity: 3.9203600883483887
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.18s/it]
INFO:root:eval mean loss: 4005.9983516179077
INFO:root:eval perplexity: 5.052626132965088
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/96

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [4:59:56<4:59:30, 172.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3466.7286468050374
INFO:root:current train perplexity3.944559335708618
INFO:root:current mean train loss 3461.2225495298467
INFO:root:current train perplexity3.9157347679138184
INFO:root:current mean train loss 3468.249836325199
INFO:root:current train perplexity3.9195876121520996
INFO:root:current mean train loss 3465.330624281548
INFO:root:current train perplexity3.9131109714508057
INFO:root:current mean train loss 3462.1696970774224
INFO:root:current train perplexity3.911442995071411
INFO:root:current mean train loss 3459.388791146522
INFO:root:current train perplexity3.910750150680542
INFO:root:current mean train loss 3460.2232327439797
INFO:root:current train perplexity3.910461187362671
INFO:root:current mean train loss 3458.431793093526
INFO:root:current train perplexity3.9128715991973877
INFO:root:current mean train loss 3462.380628750811
INFO:root:current train perplexity3.9154374599456787
INFO:root:current mean train loss 3462.0265805265158
INFO:root:current train perplexity3.9157397747039795


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.42s/it]
INFO:root:final mean train loss: 3459.5944474127987
INFO:root:final train perplexity: 3.9153716564178467
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.52s/it]
INFO:root:eval mean loss: 4009.300436682735
INFO:root:eval perplexity: 5.059377670288086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/97

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [5:02:42<4:53:07, 170.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3445.605927734375
INFO:root:current train perplexity3.914763927459717
INFO:root:current mean train loss 3444.67275390625
INFO:root:current train perplexity3.8990330696105957
INFO:root:current mean train loss 3455.7588449928976
INFO:root:current train perplexity3.8967223167419434
INFO:root:current mean train loss 3459.8216276041667
INFO:root:current train perplexity3.898466110229492
INFO:root:current mean train loss 3457.1602081620067
INFO:root:current train perplexity3.901428461074829
INFO:root:current mean train loss 3453.3050199558425
INFO:root:current train perplexity3.9033591747283936
INFO:root:current mean train loss 3457.877808159722
INFO:root:current train perplexity3.905313014984131
INFO:root:current mean train loss 3456.2580185231855
INFO:root:current train perplexity3.9048986434936523
INFO:root:current mean train loss 3457.8670580357143
INFO:root:current train perplexity3.9063756465911865
INFO:root:current mean train loss 3456.5381059695515
INFO:root:current train perplexity3.9077649116516113


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:38<00:00, 158.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:38<00:00, 158.89s/it]
INFO:root:final mean train loss: 3454.893418096727
INFO:root:final train perplexity: 3.908116102218628
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.46s/it]
INFO:root:eval mean loss: 4007.6754159048096
INFO:root:eval perplexity: 5.05605411529541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/98

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [5:05:36<4:51:37, 171.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3431.8032844267696
INFO:root:current train perplexity3.8742587566375732
INFO:root:current mean train loss 3435.7719286308916
INFO:root:current train perplexity3.887237787246704
INFO:root:current mean train loss 3450.1639123923364
INFO:root:current train perplexity3.8892016410827637
INFO:root:current mean train loss 3451.0844178361617
INFO:root:current train perplexity3.8871052265167236
INFO:root:current mean train loss 3450.856112715127
INFO:root:current train perplexity3.8898608684539795
INFO:root:current mean train loss 3450.5491413620284
INFO:root:current train perplexity3.8918654918670654
INFO:root:current mean train loss 3452.0858602900807
INFO:root:current train perplexity3.895556688308716
INFO:root:current mean train loss 3449.6540761194924
INFO:root:current train perplexity3.894885540008545
INFO:root:current mean train loss 3450.739316981349
INFO:root:current train perplexity3.8954014778137207
INFO:root:current mean train loss 3451.186704245613
INFO:root:current train perplexity3.8978095054626465


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.46s/it]
INFO:root:final mean train loss: 3448.389488712434
INFO:root:final train perplexity: 3.8981008529663086
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.01s/it]
INFO:root:eval mean loss: 4011.784837655142
INFO:root:eval perplexity: 5.064462661743164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/99

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [5:08:34<4:52:16, 173.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3414.5582986349586
INFO:root:current train perplexity3.8442580699920654
INFO:root:current mean train loss 3427.837302642343
INFO:root:current train perplexity3.853677988052368
INFO:root:current mean train loss 3432.713394007732
INFO:root:current train perplexity3.8665263652801514
INFO:root:current mean train loss 3438.278686211237
INFO:root:current train perplexity3.874643087387085
INFO:root:current mean train loss 3439.607376626941
INFO:root:current train perplexity3.8776488304138184
INFO:root:current mean train loss 3439.966970375952
INFO:root:current train perplexity3.877535104751587
INFO:root:current mean train loss 3441.995635147205
INFO:root:current train perplexity3.8810036182403564
INFO:root:current mean train loss 3443.1828418832965
INFO:root:current train perplexity3.8838272094726562
INFO:root:current mean train loss 3442.3058695680766
INFO:root:current train perplexity3.8857452869415283
INFO:root:current mean train loss 3446.3047700298785
INFO:root:current train perplexity3.890782356262207


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.31s/it]
INFO:root:final mean train loss: 3443.57500168585
INFO:root:final train perplexity: 3.8907036781311035
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.35s/it]
INFO:root:eval mean loss: 4011.2557883837544
INFO:root:eval perplexity: 5.063380241394043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/100

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [5:11:24<4:47:25, 172.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3421.498510495581
INFO:root:current train perplexity3.853609085083008
INFO:root:current mean train loss 3425.533286549937
INFO:root:current train perplexity3.871441602706909
INFO:root:current mean train loss 3428.38653748171
INFO:root:current train perplexity3.872490406036377
INFO:root:current mean train loss 3425.9942428091713
INFO:root:current train perplexity3.8687169551849365
INFO:root:current mean train loss 3432.0965407377253
INFO:root:current train perplexity3.87214732170105
INFO:root:current mean train loss 3434.1411638212126
INFO:root:current train perplexity3.875462055206299
INFO:root:current mean train loss 3439.113482080986
INFO:root:current train perplexity3.879560708999634
INFO:root:current mean train loss 3442.442109643891
INFO:root:current train perplexity3.881946086883545
INFO:root:current mean train loss 3442.1832738415947
INFO:root:current train perplexity3.8835229873657227


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:41<00:00, 161.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:41<00:00, 161.09s/it]
INFO:root:final mean train loss: 3439.3142241201094
INFO:root:final train perplexity: 3.8841683864593506
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.79s/it]
INFO:root:eval mean loss: 4012.0367336408467
INFO:root:eval perplexity: 5.064977645874023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/101

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [5:14:45<4:58:37, 180.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3390.7582659040177
INFO:root:current train perplexity3.8508377075195312
INFO:root:current mean train loss 3454.6511116384345
INFO:root:current train perplexity3.8728902339935303
INFO:root:current mean train loss 3441.670883104997
INFO:root:current train perplexity3.865764617919922
INFO:root:current mean train loss 3433.7427672345784
INFO:root:current train perplexity3.8719959259033203
INFO:root:current mean train loss 3439.8421010010366
INFO:root:current train perplexity3.875652551651001
INFO:root:current mean train loss 3438.9821372850406
INFO:root:current train perplexity3.8775577545166016
INFO:root:current mean train loss 3437.4503533804827
INFO:root:current train perplexity3.874467611312866
INFO:root:current mean train loss 3436.3607821754554
INFO:root:current train perplexity3.8749840259552
INFO:root:current mean train loss 3437.3268431860865
INFO:root:current train perplexity3.8767263889312744
INFO:root:current mean train loss 3436.6706058455934
INFO:root:current train perplexity3.877805709838867


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.53s/it]
INFO:root:final mean train loss: 3435.1118772568243
INFO:root:final train perplexity: 3.877734422683716
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.89s/it]
INFO:root:eval mean loss: 4015.709600786791
INFO:root:eval perplexity: 5.072505950927734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/102

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [5:18:24<5:14:24, 192.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3418.974576822917
INFO:root:current train perplexity3.8288497924804688
INFO:root:current mean train loss 3409.3627547554347
INFO:root:current train perplexity3.8207685947418213
INFO:root:current mean train loss 3410.722115734012
INFO:root:current train perplexity3.8349924087524414
INFO:root:current mean train loss 3427.288971044147
INFO:root:current train perplexity3.852203607559204
INFO:root:current mean train loss 3432.806265883848
INFO:root:current train perplexity3.857421398162842
INFO:root:current mean train loss 3428.5469854558555
INFO:root:current train perplexity3.855146884918213
INFO:root:current mean train loss 3430.742174002795
INFO:root:current train perplexity3.859241485595703
INFO:root:current mean train loss 3429.1509011008525
INFO:root:current train perplexity3.861971139907837
INFO:root:current mean train loss 3429.1320905626917
INFO:root:current train perplexity3.8643906116485596
INFO:root:current mean train loss 3429.9802438204406
INFO:root:current train perplexity3.8664915561676025


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:37<00:00, 157.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:37<00:00, 157.94s/it]
INFO:root:final mean train loss: 3429.797102589761
INFO:root:final train perplexity: 3.8696117401123047
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.76s/it]
INFO:root:eval mean loss: 4013.1539297983154
INFO:root:eval perplexity: 5.067266464233398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/103

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [5:21:18<5:02:09, 186.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3370.2720575747285
INFO:root:current train perplexity3.819481611251831
INFO:root:current mean train loss 3413.982773199314
INFO:root:current train perplexity3.82944917678833
INFO:root:current mean train loss 3418.375707241452
INFO:root:current train perplexity3.8414342403411865
INFO:root:current mean train loss 3416.6177014802633
INFO:root:current train perplexity3.844177007675171
INFO:root:current mean train loss 3415.670070783466
INFO:root:current train perplexity3.8464739322662354
INFO:root:current mean train loss 3419.902492661777
INFO:root:current train perplexity3.854459047317505
INFO:root:current mean train loss 3423.269477170696
INFO:root:current train perplexity3.8587234020233154
INFO:root:current mean train loss 3425.477584986601
INFO:root:current train perplexity3.862729787826538
INFO:root:current mean train loss 3426.1629785512227
INFO:root:current train perplexity3.862631320953369
INFO:root:current mean train loss 3426.7325364068424
INFO:root:current train perplexity3.861125946044922


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.29s/it]
INFO:root:final mean train loss: 3425.7209058577014
INFO:root:final train perplexity: 3.863393545150757
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.02s/it]
INFO:root:eval mean loss: 4013.933465619459
INFO:root:eval perplexity: 5.068864822387695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/104

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [5:24:07<4:50:12, 181.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3373.478696761593
INFO:root:current train perplexity3.811140775680542
INFO:root:current mean train loss 3393.908290717438
INFO:root:current train perplexity3.8234851360321045
INFO:root:current mean train loss 3390.875138452043
INFO:root:current train perplexity3.8309295177459717
INFO:root:current mean train loss 3401.2128124409933
INFO:root:current train perplexity3.8411381244659424
INFO:root:current mean train loss 3403.0219330046402
INFO:root:current train perplexity3.8414902687072754
INFO:root:current mean train loss 3408.3474033736466
INFO:root:current train perplexity3.8447086811065674
INFO:root:current mean train loss 3413.6301439771937
INFO:root:current train perplexity3.8476035594940186
INFO:root:current mean train loss 3416.1517582800743
INFO:root:current train perplexity3.849997043609619
INFO:root:current mean train loss 3422.324975262767
INFO:root:current train perplexity3.856051445007324
INFO:root:current mean train loss 3422.021275636077
INFO:root:current train perplexity3.854069232940674


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.72s/it]
INFO:root:final mean train loss: 3420.7896095398933
INFO:root:final train perplexity: 3.8558850288391113
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.18s/it]
INFO:root:eval mean loss: 4014.5354540669327
INFO:root:eval perplexity: 5.070098400115967
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/105

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [5:27:57<5:10:39, 196.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3401.9837802984775
INFO:root:current train perplexity3.844841480255127
INFO:root:current mean train loss 3417.229130367581
INFO:root:current train perplexity3.8409228324890137
INFO:root:current mean train loss 3413.4855783374737
INFO:root:current train perplexity3.844325542449951
INFO:root:current mean train loss 3424.000082820566
INFO:root:current train perplexity3.8478522300720215
INFO:root:current mean train loss 3419.826467179492
INFO:root:current train perplexity3.844085216522217
INFO:root:current mean train loss 3418.6749514436456
INFO:root:current train perplexity3.8438973426818848
INFO:root:current mean train loss 3421.140114558881
INFO:root:current train perplexity3.844961643218994
INFO:root:current mean train loss 3422.0390793486763
INFO:root:current train perplexity3.8466391563415527
INFO:root:current mean train loss 3419.5579820889825
INFO:root:current train perplexity3.8459513187408447
INFO:root:current mean train loss 3419.0363041529386
INFO:root:current train perplexity3.847545623779297


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:39<00:00, 159.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:39<00:00, 159.64s/it]
INFO:root:final mean train loss: 3415.7731601961195
INFO:root:final train perplexity: 3.8482604026794434
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.56s/it]
INFO:root:eval mean loss: 4017.5128182485596
INFO:root:eval perplexity: 5.076207637786865
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/106

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [5:31:30<5:15:10, 201.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3345.696029338431
INFO:root:current train perplexity3.797222852706909
INFO:root:current mean train loss 3392.6711542038693
INFO:root:current train perplexity3.827925205230713
INFO:root:current mean train loss 3393.2907774149166
INFO:root:current train perplexity3.8225882053375244
INFO:root:current mean train loss 3396.9692523527556
INFO:root:current train perplexity3.828244686126709
INFO:root:current mean train loss 3402.758850780376
INFO:root:current train perplexity3.8270187377929688
INFO:root:current mean train loss 3409.824581167162
INFO:root:current train perplexity3.8330705165863037
INFO:root:current mean train loss 3412.0038854961604
INFO:root:current train perplexity3.8353092670440674
INFO:root:current mean train loss 3410.8104857581366
INFO:root:current train perplexity3.8359270095825195
INFO:root:current mean train loss 3413.534865990721
INFO:root:current train perplexity3.840700387954712
INFO:root:current mean train loss 3412.884078318869
INFO:root:current train perplexity3.8407726287841797


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:37<00:00, 157.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:37<00:00, 157.20s/it]
INFO:root:final mean train loss: 3411.5462758464196
INFO:root:final train perplexity: 3.841848850250244
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.30s/it]
INFO:root:eval mean loss: 4019.454717974291
INFO:root:eval perplexity: 5.080194473266602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/107

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [5:34:29<5:01:30, 194.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3391.0196732954546
INFO:root:current train perplexity3.81378173828125
INFO:root:current mean train loss 3398.664012096774
INFO:root:current train perplexity3.815260887145996
INFO:root:current mean train loss 3393.0361031326593
INFO:root:current train perplexity3.8187241554260254
INFO:root:current mean train loss 3402.95019393706
INFO:root:current train perplexity3.8251571655273438
INFO:root:current mean train loss 3406.527945784684
INFO:root:current train perplexity3.8241140842437744
INFO:root:current mean train loss 3404.8581380208334
INFO:root:current train perplexity3.8273983001708984
INFO:root:current mean train loss 3405.2158296308444
INFO:root:current train perplexity3.830263137817383
INFO:root:current mean train loss 3408.1742847164737
INFO:root:current train perplexity3.829805850982666
INFO:root:current mean train loss 3407.349954027321
INFO:root:current train perplexity3.8296008110046387
INFO:root:current mean train loss 3410.1691884305465
INFO:root:current train perplexity3.834515333175659


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.81s/it]
INFO:root:final mean train loss: 3406.3545660818777
INFO:root:final train perplexity: 3.8339881896972656
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.27s/it]
INFO:root:eval mean loss: 4020.9683656083776
INFO:root:eval perplexity: 5.083303928375244
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/108

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [5:38:24<5:16:59, 206.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3353.8807586185517
INFO:root:current train perplexity3.8122901916503906
INFO:root:current mean train loss 3377.28851430694
INFO:root:current train perplexity3.823302745819092
INFO:root:current mean train loss 3384.116545122386
INFO:root:current train perplexity3.817249298095703
INFO:root:current mean train loss 3392.6402288599775
INFO:root:current train perplexity3.824431896209717
INFO:root:current mean train loss 3396.9201349048326
INFO:root:current train perplexity3.819169759750366
INFO:root:current mean train loss 3401.1500120552564
INFO:root:current train perplexity3.8235361576080322
INFO:root:current mean train loss 3403.874372893689
INFO:root:current train perplexity3.8245489597320557
INFO:root:current mean train loss 3404.288867955439
INFO:root:current train perplexity3.824765682220459
INFO:root:current mean train loss 3404.1316413039544
INFO:root:current train perplexity3.8268604278564453
INFO:root:current mean train loss 3406.159066617179
INFO:root:current train perplexity3.830214738845825


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.20s/it]
INFO:root:final mean train loss: 3403.7052571081344
INFO:root:final train perplexity: 3.829982042312622
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.19s/it]
INFO:root:eval mean loss: 4019.3193220855496
INFO:root:eval perplexity: 5.079916000366211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/109

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [5:41:14<4:56:34, 195.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3379.7075126540494
INFO:root:current train perplexity3.790114164352417
INFO:root:current mean train loss 3379.6697262769553
INFO:root:current train perplexity3.8056137561798096
INFO:root:current mean train loss 3382.0340535631917
INFO:root:current train perplexity3.807612180709839
INFO:root:current mean train loss 3386.920705625632
INFO:root:current train perplexity3.8038058280944824
INFO:root:current mean train loss 3391.096000136843
INFO:root:current train perplexity3.812650680541992
INFO:root:current mean train loss 3394.9771495491736
INFO:root:current train perplexity3.8190066814422607
INFO:root:current mean train loss 3396.2426492204963
INFO:root:current train perplexity3.8200812339782715
INFO:root:current mean train loss 3398.0255400859273
INFO:root:current train perplexity3.8207716941833496
INFO:root:current mean train loss 3399.4188561773462
INFO:root:current train perplexity3.8218586444854736
INFO:root:current mean train loss 3401.514043743161
INFO:root:current train perplexity3.8243520259857178


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.11s/it]
INFO:root:final mean train loss: 3399.725641988939
INFO:root:final train perplexity: 3.8239736557006836
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.47s/it]
INFO:root:eval mean loss: 4023.144250748005
INFO:root:eval perplexity: 5.087778568267822
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/110

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [5:44:03<4:41:39, 187.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3387.641545935522
INFO:root:current train perplexity3.7933595180511475
INFO:root:current mean train loss 3392.424073629539
INFO:root:current train perplexity3.796968936920166
INFO:root:current mean train loss 3399.1721147653448
INFO:root:current train perplexity3.8100109100341797
INFO:root:current mean train loss 3401.0224873484913
INFO:root:current train perplexity3.814671039581299
INFO:root:current mean train loss 3402.5606207797823
INFO:root:current train perplexity3.8120644092559814
INFO:root:current mean train loss 3398.586983214594
INFO:root:current train perplexity3.8082473278045654
INFO:root:current mean train loss 3399.3224845964883
INFO:root:current train perplexity3.8097856044769287
INFO:root:current mean train loss 3396.209241051729
INFO:root:current train perplexity3.8112523555755615
INFO:root:current mean train loss 3396.086379952805
INFO:root:current train perplexity3.814995288848877
INFO:root:current mean train loss 3397.8634094300623
INFO:root:current train perplexity3.8177289962768555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.37s/it]
INFO:root:final mean train loss: 3395.314278448782
INFO:root:final train perplexity: 3.817323923110962
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.95s/it]
INFO:root:eval mean loss: 4022.4870363059617
INFO:root:eval perplexity: 5.086427688598633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/111

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [5:47:16<4:40:41, 189.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3398.998925220007
INFO:root:current train perplexity3.7971315383911133
INFO:root:current mean train loss 3393.5268528576203
INFO:root:current train perplexity3.798288583755493
INFO:root:current mean train loss 3393.4040382730836
INFO:root:current train perplexity3.80568265914917
INFO:root:current mean train loss 3390.2134079255493
INFO:root:current train perplexity3.801142692565918
INFO:root:current mean train loss 3389.052254616113
INFO:root:current train perplexity3.8041088581085205
INFO:root:current mean train loss 3389.718316619197
INFO:root:current train perplexity3.8078560829162598
INFO:root:current mean train loss 3393.4477951294125
INFO:root:current train perplexity3.8111634254455566
INFO:root:current mean train loss 3391.1231805784428
INFO:root:current train perplexity3.8109683990478516
INFO:root:current mean train loss 3393.0336454406533
INFO:root:current train perplexity3.81166410446167
INFO:root:current mean train loss 3393.7146683744145
INFO:root:current train perplexity3.8106541633605957


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.52s/it]
INFO:root:final mean train loss: 3390.7981392645065
INFO:root:final train perplexity: 3.8105287551879883
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.94s/it]
INFO:root:eval mean loss: 4026.915735123005
INFO:root:eval perplexity: 5.095544338226318
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/112

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [5:50:14<4:32:31, 185.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3373.1612767269735
INFO:root:current train perplexity3.7845559120178223
INFO:root:current mean train loss 3361.833707682292
INFO:root:current train perplexity3.7897965908050537
INFO:root:current mean train loss 3369.411611162606
INFO:root:current train perplexity3.7897870540618896
INFO:root:current mean train loss 3379.36494387856
INFO:root:current train perplexity3.7985305786132812
INFO:root:current mean train loss 3380.894162819602
INFO:root:current train perplexity3.799842119216919
INFO:root:current mean train loss 3379.555107668067
INFO:root:current train perplexity3.798264741897583
INFO:root:current mean train loss 3383.747428268323
INFO:root:current train perplexity3.8021814823150635
INFO:root:current mean train loss 3387.0640397749607
INFO:root:current train perplexity3.8047714233398438
INFO:root:current mean train loss 3388.0524618649615
INFO:root:current train perplexity3.8060696125030518


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:38<00:00, 158.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:38<00:00, 158.19s/it]
INFO:root:final mean train loss: 3387.883588544784
INFO:root:final train perplexity: 3.806149959564209
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.98s/it]
INFO:root:eval mean loss: 4027.125462308843
INFO:root:eval perplexity: 5.095976829528809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/113

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [5:53:07<4:23:56, 182.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3324.55078125
INFO:root:current train perplexity3.8405239582061768
INFO:root:current mean train loss 3361.062744140625
INFO:root:current train perplexity3.7708935737609863
INFO:root:current mean train loss 3377.368314395397
INFO:root:current train perplexity3.7889175415039062
INFO:root:current mean train loss 3375.7397686545996
INFO:root:current train perplexity3.7887494564056396
INFO:root:current mean train loss 3375.9448732891983
INFO:root:current train perplexity3.7907769680023193
INFO:root:current mean train loss 3380.2926619967693
INFO:root:current train perplexity3.7942850589752197
INFO:root:current mean train loss 3381.128553197554
INFO:root:current train perplexity3.794238328933716
INFO:root:current mean train loss 3382.0320504895317
INFO:root:current train perplexity3.795323610305786
INFO:root:current mean train loss 3386.0105035195165
INFO:root:current train perplexity3.799405813217163
INFO:root:current mean train loss 3384.869123051201
INFO:root:current train perplexity3.7968897819519043


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:40<00:00, 160.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:40<00:00, 160.89s/it]
INFO:root:final mean train loss: 3382.4042909068444
INFO:root:final train perplexity: 3.7979300022125244
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.31s/it]
INFO:root:eval mean loss: 4024.7076909491357
INFO:root:eval perplexity: 5.090996742248535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/114

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [5:56:05<4:19:12, 180.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3349.2549272017045
INFO:root:current train perplexity3.7827882766723633
INFO:root:current mean train loss 3374.0602895375846
INFO:root:current train perplexity3.803741455078125
INFO:root:current mean train loss 3369.7463888014663
INFO:root:current train perplexity3.796434164047241
INFO:root:current mean train loss 3376.9334108407857
INFO:root:current train perplexity3.793255090713501
INFO:root:current mean train loss 3377.484042944989
INFO:root:current train perplexity3.791534185409546
INFO:root:current mean train loss 3375.076151330877
INFO:root:current train perplexity3.7892472743988037
INFO:root:current mean train loss 3380.6760721409573
INFO:root:current train perplexity3.788569211959839
INFO:root:current mean train loss 3379.4601127098717
INFO:root:current train perplexity3.7889745235443115
INFO:root:current mean train loss 3376.85963690178
INFO:root:current train perplexity3.7866945266723633
INFO:root:current mean train loss 3378.4896965152475
INFO:root:current train perplexity3.788160562515259


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:37<00:00, 157.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:37<00:00, 157.33s/it]
INFO:root:final mean train loss: 3378.219181860647
INFO:root:final train perplexity: 3.7916650772094727
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.56s/it]
INFO:root:eval mean loss: 4027.7039110981827
INFO:root:eval perplexity: 5.097168922424316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/115

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [5:59:07<4:16:22, 180.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3330.952880859375
INFO:root:current train perplexity3.7470879554748535
INFO:root:current mean train loss 3345.298227005646
INFO:root:current train perplexity3.769981622695923
INFO:root:current mean train loss 3360.9523190014984
INFO:root:current train perplexity3.7730586528778076
INFO:root:current mean train loss 3368.280748708121
INFO:root:current train perplexity3.777833938598633
INFO:root:current mean train loss 3368.4571576903713
INFO:root:current train perplexity3.7749032974243164
INFO:root:current mean train loss 3370.6892814268726
INFO:root:current train perplexity3.7744369506835938
INFO:root:current mean train loss 3373.2548966168974
INFO:root:current train perplexity3.7794668674468994
INFO:root:current mean train loss 3376.943171600639
INFO:root:current train perplexity3.781825304031372
INFO:root:current mean train loss 3377.402792980674
INFO:root:current train perplexity3.7828242778778076
INFO:root:current mean train loss 3375.5834440245853
INFO:root:current train perplexity3.784771680831909


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.68s/it]
INFO:root:final mean train loss: 3374.817600434826
INFO:root:final train perplexity: 3.7865798473358154
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.30s/it]
INFO:root:eval mean loss: 4028.41005582336
INFO:root:eval perplexity: 5.098624229431152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/116

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [6:02:41<4:27:13, 190.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3384.156548394097
INFO:root:current train perplexity3.792942762374878
INFO:root:current mean train loss 3380.299435593012
INFO:root:current train perplexity3.7789645195007324
INFO:root:current mean train loss 3376.9479915938186
INFO:root:current train perplexity3.773127555847168
INFO:root:current mean train loss 3370.36394871703
INFO:root:current train perplexity3.771408796310425
INFO:root:current mean train loss 3373.377203554962
INFO:root:current train perplexity3.775669574737549
INFO:root:current mean train loss 3372.5657164484996
INFO:root:current train perplexity3.7740848064422607
INFO:root:current mean train loss 3372.9173212127444
INFO:root:current train perplexity3.7743146419525146
INFO:root:current mean train loss 3372.9409361029916
INFO:root:current train perplexity3.7761404514312744
INFO:root:current mean train loss 3372.1414079031892
INFO:root:current train perplexity3.7759644985198975
INFO:root:current mean train loss 3372.6607664698795
INFO:root:current train perplexity3.779282569885254


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.69s/it]
INFO:root:final mean train loss: 3369.859801138601
INFO:root:final train perplexity: 3.7791807651519775
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.12s/it]
INFO:root:eval mean loss: 4029.2655124529033
INFO:root:eval perplexity: 5.100388526916504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/117

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [6:06:12<4:32:25, 196.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3365.7046107700894
INFO:root:current train perplexity3.7523720264434814
INFO:root:current mean train loss 3365.4327021846066
INFO:root:current train perplexity3.7555296421051025
INFO:root:current mean train loss 3361.787022107713
INFO:root:current train perplexity3.761763095855713
INFO:root:current mean train loss 3367.55146484375
INFO:root:current train perplexity3.7665281295776367
INFO:root:current mean train loss 3371.0626150547773
INFO:root:current train perplexity3.76955509185791
INFO:root:current mean train loss 3370.8518632264895
INFO:root:current train perplexity3.770658493041992
INFO:root:current mean train loss 3370.1453674797
INFO:root:current train perplexity3.7736399173736572
INFO:root:current mean train loss 3371.602599184205
INFO:root:current train perplexity3.773811101913452
INFO:root:current mean train loss 3370.9554734281437
INFO:root:current train perplexity3.7746741771698
INFO:root:current mean train loss 3370.79487879136
INFO:root:current train perplexity3.7765371799468994


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.35s/it]
INFO:root:final mean train loss: 3367.763502674718
INFO:root:final train perplexity: 3.7760567665100098
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.71s/it]
INFO:root:eval mean loss: 4031.47191690215
INFO:root:eval perplexity: 5.104939937591553
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/118

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [6:09:03<4:18:50, 189.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3360.7555130359738
INFO:root:current train perplexity3.755892276763916
INFO:root:current mean train loss 3348.7298336429194
INFO:root:current train perplexity3.7418839931488037
INFO:root:current mean train loss 3348.787514266654
INFO:root:current train perplexity3.747903347015381
INFO:root:current mean train loss 3353.105601141126
INFO:root:current train perplexity3.7505862712860107
INFO:root:current mean train loss 3360.512484238325
INFO:root:current train perplexity3.7543106079101562
INFO:root:current mean train loss 3361.655819719009
INFO:root:current train perplexity3.7564926147460938
INFO:root:current mean train loss 3363.901225563156
INFO:root:current train perplexity3.7613272666931152
INFO:root:current mean train loss 3365.092271026981
INFO:root:current train perplexity3.764237403869629
INFO:root:current mean train loss 3364.0060681832924
INFO:root:current train perplexity3.768434524536133
INFO:root:current mean train loss 3364.8251590668083
INFO:root:current train perplexity3.7681663036346436


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:37<00:00, 157.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:37<00:00, 157.92s/it]
INFO:root:final mean train loss: 3362.574211858934
INFO:root:final train perplexity: 3.7683334350585938
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.22s/it]
INFO:root:eval mean loss: 4031.4936558067375
INFO:root:eval perplexity: 5.104986190795898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/119

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [6:12:31<4:23:02, 194.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3363.2640069699755
INFO:root:current train perplexity3.758913516998291
INFO:root:current mean train loss 3350.459267319433
INFO:root:current train perplexity3.747685194015503
INFO:root:current mean train loss 3349.0843569083045
INFO:root:current train perplexity3.7531871795654297
INFO:root:current mean train loss 3343.6805019976405
INFO:root:current train perplexity3.751473903656006
INFO:root:current mean train loss 3345.0744044267944
INFO:root:current train perplexity3.750739097595215
INFO:root:current mean train loss 3351.1721173682795
INFO:root:current train perplexity3.7544212341308594
INFO:root:current mean train loss 3356.0121129002255
INFO:root:current train perplexity3.7582974433898926
INFO:root:current mean train loss 3360.036576231691
INFO:root:current train perplexity3.761794090270996
INFO:root:current mean train loss 3359.536296051061
INFO:root:current train perplexity3.7623260021209717
INFO:root:current mean train loss 3361.2922016709385
INFO:root:current train perplexity3.763145923614502


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:37<00:00, 157.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:37<00:00, 157.70s/it]
INFO:root:final mean train loss: 3359.3557577440815
INFO:root:final train perplexity: 3.7635514736175537
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.15s/it]
INFO:root:eval mean loss: 4033.213836020612
INFO:root:eval perplexity: 5.1085381507873535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/120

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [6:15:23<4:10:38, 187.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3341.7250521385063
INFO:root:current train perplexity3.730278968811035
INFO:root:current mean train loss 3337.534182758451
INFO:root:current train perplexity3.7308895587921143
INFO:root:current mean train loss 3338.5354267842063
INFO:root:current train perplexity3.728001117706299
INFO:root:current mean train loss 3345.618570736856
INFO:root:current train perplexity3.739851474761963
INFO:root:current mean train loss 3348.476674730222
INFO:root:current train perplexity3.745436906814575
INFO:root:current mean train loss 3346.9193091213383
INFO:root:current train perplexity3.748791217803955
INFO:root:current mean train loss 3352.557871330852
INFO:root:current train perplexity3.7529048919677734
INFO:root:current mean train loss 3354.7498308063655
INFO:root:current train perplexity3.7551069259643555
INFO:root:current mean train loss 3356.3910129533797
INFO:root:current train perplexity3.7554714679718018
INFO:root:current mean train loss 3356.327054752672
INFO:root:current train perplexity3.7555429935455322


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.57s/it]
INFO:root:final mean train loss: 3354.1346097761584
INFO:root:final train perplexity: 3.755807638168335
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.46s/it]
INFO:root:eval mean loss: 4034.1401124778367
INFO:root:eval perplexity: 5.110451698303223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/121

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [6:18:11<3:59:39, 182.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3341.0960310750934
INFO:root:current train perplexity3.7478840351104736
INFO:root:current mean train loss 3348.600688271894
INFO:root:current train perplexity3.7463018894195557
INFO:root:current mean train loss 3343.8324198633545
INFO:root:current train perplexity3.7384700775146484
INFO:root:current mean train loss 3344.073494976158
INFO:root:current train perplexity3.7423150539398193
INFO:root:current mean train loss 3347.6923049175252
INFO:root:current train perplexity3.7410285472869873
INFO:root:current mean train loss 3347.547573836392
INFO:root:current train perplexity3.74224591255188
INFO:root:current mean train loss 3350.5048429154563
INFO:root:current train perplexity3.744251251220703
INFO:root:current mean train loss 3350.238693137834
INFO:root:current train perplexity3.745152473449707
INFO:root:current mean train loss 3352.0037356049957
INFO:root:current train perplexity3.746692180633545
INFO:root:current mean train loss 3354.838295337949
INFO:root:current train perplexity3.751924753189087


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:39<00:00, 159.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:39<00:00, 159.94s/it]
INFO:root:final mean train loss: 3352.6231189235564
INFO:root:final train perplexity: 3.753567934036255
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.09s/it]
INFO:root:eval mean loss: 4035.077493004765
INFO:root:eval perplexity: 5.11238956451416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/122

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [6:21:28<4:02:27, 186.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3348.6124576822917
INFO:root:current train perplexity3.739661931991577
INFO:root:current mean train loss 3336.9491364397322
INFO:root:current train perplexity3.747420310974121
INFO:root:current mean train loss 3344.2541752485795
INFO:root:current train perplexity3.747537851333618
INFO:root:current mean train loss 3345.632423177083
INFO:root:current train perplexity3.7448506355285645
INFO:root:current mean train loss 3350.1966246916118
INFO:root:current train perplexity3.748718738555908
INFO:root:current mean train loss 3350.4016155740487
INFO:root:current train perplexity3.745326280593872
INFO:root:current mean train loss 3351.4396513310185
INFO:root:current train perplexity3.7462332248687744
INFO:root:current mean train loss 3351.632332409274
INFO:root:current train perplexity3.7464895248413086
INFO:root:current mean train loss 3350.286383091518
INFO:root:current train perplexity3.7458078861236572
INFO:root:current mean train loss 3349.833731971154
INFO:root:current train perplexity3.7457897663116455


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.91s/it]
INFO:root:final mean train loss: 3347.668825457173
INFO:root:final train perplexity: 3.7462384700775146
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.21s/it]
INFO:root:eval mean loss: 4035.5364808427526
INFO:root:eval perplexity: 5.113338947296143
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/123

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [6:24:17<3:52:40, 181.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3328.4800069418297
INFO:root:current train perplexity3.732618808746338
INFO:root:current mean train loss 3321.5578533235143
INFO:root:current train perplexity3.7285983562469482
INFO:root:current mean train loss 3327.480203042182
INFO:root:current train perplexity3.7269763946533203
INFO:root:current mean train loss 3338.420289042102
INFO:root:current train perplexity3.7378900051116943
INFO:root:current mean train loss 3340.2339726481623
INFO:root:current train perplexity3.7416913509368896
INFO:root:current mean train loss 3349.451627492496
INFO:root:current train perplexity3.743936061859131
INFO:root:current mean train loss 3351.351624339426
INFO:root:current train perplexity3.744865894317627
INFO:root:current mean train loss 3349.1344460283963
INFO:root:current train perplexity3.7412686347961426
INFO:root:current mean train loss 3348.711117494957
INFO:root:current train perplexity3.7425763607025146
INFO:root:current mean train loss 3348.717216856482
INFO:root:current train perplexity3.7437615394592285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:38<00:00, 158.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:38<00:00, 158.36s/it]
INFO:root:final mean train loss: 3345.945471732847
INFO:root:final train perplexity: 3.743691921234131
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.66s/it]
INFO:root:eval mean loss: 4036.7131364971187
INFO:root:eval perplexity: 5.115771770477295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/124

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [6:27:10<3:46:31, 178.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3308.8843041723903
INFO:root:current train perplexity3.6774730682373047
INFO:root:current mean train loss 3335.5440245623363
INFO:root:current train perplexity3.7189619541168213
INFO:root:current mean train loss 3336.990700842998
INFO:root:current train perplexity3.7203001976013184
INFO:root:current mean train loss 3338.211500709319
INFO:root:current train perplexity3.719639539718628
INFO:root:current mean train loss 3337.5808189998093
INFO:root:current train perplexity3.7214629650115967
INFO:root:current mean train loss 3340.7924143731493
INFO:root:current train perplexity3.7283051013946533
INFO:root:current mean train loss 3342.4840238049474
INFO:root:current train perplexity3.730133533477783
INFO:root:current mean train loss 3345.5524482582373
INFO:root:current train perplexity3.731886863708496
INFO:root:current mean train loss 3343.7078212134365
INFO:root:current train perplexity3.7344956398010254
INFO:root:current mean train loss 3343.3681919009364
INFO:root:current train perplexity3.735961437225342


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.55s/it]
INFO:root:final mean train loss: 3340.6650604124993
INFO:root:final train perplexity: 3.73590087890625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.51s/it]
INFO:root:eval mean loss: 4037.5701497395835
INFO:root:eval perplexity: 5.117545127868652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/125

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [6:30:11<3:44:20, 179.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3342.0079801925503
INFO:root:current train perplexity3.7266530990600586
INFO:root:current mean train loss 3330.297066386621
INFO:root:current train perplexity3.724591016769409
INFO:root:current mean train loss 3333.980362601902
INFO:root:current train perplexity3.7263383865356445
INFO:root:current mean train loss 3334.761142357848
INFO:root:current train perplexity3.726776123046875
INFO:root:current mean train loss 3333.9815734985596
INFO:root:current train perplexity3.7237110137939453
INFO:root:current mean train loss 3336.4940057159065
INFO:root:current train perplexity3.724339723587036
INFO:root:current mean train loss 3336.148864658776
INFO:root:current train perplexity3.726126194000244
INFO:root:current mean train loss 3339.2091744319073
INFO:root:current train perplexity3.728468179702759
INFO:root:current mean train loss 3340.720687645561
INFO:root:current train perplexity3.732071876525879


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.29s/it]
INFO:root:final mean train loss: 3338.36145259488
INFO:root:final train perplexity: 3.7325069904327393
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.65s/it]
INFO:root:eval mean loss: 4038.5289228723404
INFO:root:eval perplexity: 5.119530200958252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/126

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [6:33:08<3:40:31, 178.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3344.2215750558034
INFO:root:current train perplexity3.7825205326080322
INFO:root:current mean train loss 3325.094213182681
INFO:root:current train perplexity3.712905168533325
INFO:root:current mean train loss 3332.4256562311293
INFO:root:current train perplexity3.7178289890289307
INFO:root:current mean train loss 3330.593747614261
INFO:root:current train perplexity3.716996431350708
INFO:root:current mean train loss 3324.1643984183047
INFO:root:current train perplexity3.7176504135131836
INFO:root:current mean train loss 3329.2796127650395
INFO:root:current train perplexity3.721717119216919
INFO:root:current mean train loss 3331.126169220423
INFO:root:current train perplexity3.7207579612731934
INFO:root:current mean train loss 3335.279731977104
INFO:root:current train perplexity3.7252089977264404
INFO:root:current mean train loss 3336.2963988198962
INFO:root:current train perplexity3.725961446762085
INFO:root:current mean train loss 3336.114074235977
INFO:root:current train perplexity3.7241756916046143


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:39<00:00, 159.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:39<00:00, 159.43s/it]
INFO:root:final mean train loss: 3333.962762586532
INFO:root:final train perplexity: 3.7260355949401855
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.52s/it]
INFO:root:eval mean loss: 4040.7949686253323
INFO:root:eval perplexity: 5.124222755432129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/127

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [6:36:09<3:38:05, 179.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3300.4126139322916
INFO:root:current train perplexity3.7400903701782227
INFO:root:current mean train loss 3314.26349779212
INFO:root:current train perplexity3.730550765991211
INFO:root:current mean train loss 3319.239632539971
INFO:root:current train perplexity3.726407289505005
INFO:root:current mean train loss 3325.2764299665178
INFO:root:current train perplexity3.719834566116333
INFO:root:current mean train loss 3327.801119517131
INFO:root:current train perplexity3.7183175086975098
INFO:root:current mean train loss 3326.6843294902915
INFO:root:current train perplexity3.7185568809509277
INFO:root:current mean train loss 3328.404156742251
INFO:root:current train perplexity3.716968059539795
INFO:root:current mean train loss 3330.0052061707825
INFO:root:current train perplexity3.7187983989715576
INFO:root:current mean train loss 3329.29254337615
INFO:root:current train perplexity3.7170677185058594
INFO:root:current mean train loss 3331.874513319672
INFO:root:current train perplexity3.720604181289673


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.46s/it]
INFO:root:final mean train loss: 3331.238640631399
INFO:root:final train perplexity: 3.7220335006713867
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.46s/it]
INFO:root:eval mean loss: 4041.0003411042776
INFO:root:eval perplexity: 5.124648571014404
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/128

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [6:39:06<3:34:14, 178.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3288.6033033288045
INFO:root:current train perplexity3.705235242843628
INFO:root:current mean train loss 3331.3750952743903
INFO:root:current train perplexity3.7115418910980225
INFO:root:current mean train loss 3328.3888109147283
INFO:root:current train perplexity3.709831714630127
INFO:root:current mean train loss 3328.8899371734715
INFO:root:current train perplexity3.7171900272369385
INFO:root:current mean train loss 3326.5672541047948
INFO:root:current train perplexity3.710782289505005
INFO:root:current mean train loss 3325.5396436760575
INFO:root:current train perplexity3.7131757736206055
INFO:root:current mean train loss 3326.765862086803
INFO:root:current train perplexity3.7142281532287598
INFO:root:current mean train loss 3327.9522433247967
INFO:root:current train perplexity3.7151429653167725
INFO:root:current mean train loss 3326.292219122589
INFO:root:current train perplexity3.713197946548462
INFO:root:current mean train loss 3327.2506649724064
INFO:root:current train perplexity3.7131402492523193


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.73s/it]
INFO:root:final mean train loss: 3326.1942713952835
INFO:root:final train perplexity: 3.7146332263946533
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.57s/it]
INFO:root:eval mean loss: 4042.5703125
INFO:root:eval perplexity: 5.127902030944824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/129

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [6:42:27<3:39:18, 185.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3327.2249637726813
INFO:root:current train perplexity3.682676076889038
INFO:root:current mean train loss 3318.8444544668414
INFO:root:current train perplexity3.7029800415039062
INFO:root:current mean train loss 3329.659423828125
INFO:root:current train perplexity3.7126662731170654
INFO:root:current mean train loss 3329.7847808192505
INFO:root:current train perplexity3.7134604454040527
INFO:root:current mean train loss 3326.727913486985
INFO:root:current train perplexity3.7143893241882324
INFO:root:current mean train loss 3329.008515496263
INFO:root:current train perplexity3.718007802963257
INFO:root:current mean train loss 3327.803744598727
INFO:root:current train perplexity3.7136759757995605
INFO:root:current mean train loss 3328.557803883272
INFO:root:current train perplexity3.7128920555114746
INFO:root:current mean train loss 3325.2986450929793
INFO:root:current train perplexity3.710361957550049
INFO:root:current mean train loss 3325.285031426222
INFO:root:current train perplexity3.710001230239868


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.37s/it]
INFO:root:final mean train loss: 3324.201775089387
INFO:root:final train perplexity: 3.711714029312134
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.96s/it]
INFO:root:eval mean loss: 4042.686119999446
INFO:root:eval perplexity: 5.128142833709717
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/130

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [6:45:17<3:30:58, 180.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3323.068152794471
INFO:root:current train perplexity3.7042627334594727
INFO:root:current mean train loss 3325.2126728304856
INFO:root:current train perplexity3.709988832473755
INFO:root:current mean train loss 3321.462862022751
INFO:root:current train perplexity3.7009336948394775
INFO:root:current mean train loss 3324.7164713541665
INFO:root:current train perplexity3.7056357860565186
INFO:root:current mean train loss 3324.790450041821
INFO:root:current train perplexity3.708369493484497
INFO:root:current mean train loss 3318.1935586734694
INFO:root:current train perplexity3.7050364017486572
INFO:root:current mean train loss 3317.9784373013254
INFO:root:current train perplexity3.7051641941070557
INFO:root:current mean train loss 3318.558761576032
INFO:root:current train perplexity3.7034857273101807
INFO:root:current mean train loss 3322.60042327408
INFO:root:current train perplexity3.706244707107544
INFO:root:current mean train loss 3323.2554134738584
INFO:root:current train perplexity3.7078192234039307


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.67s/it]
INFO:root:final mean train loss: 3321.2255976277015
INFO:root:final train perplexity: 3.7073585987091064
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.52s/it]
INFO:root:eval mean loss: 4046.6484582779253
INFO:root:eval perplexity: 5.136366367340088
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/131

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [6:48:06<3:23:57, 177.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3279.864585064827
INFO:root:current train perplexity3.6904375553131104
INFO:root:current mean train loss 3313.4767302428786
INFO:root:current train perplexity3.688981056213379
INFO:root:current mean train loss 3315.1498993784794
INFO:root:current train perplexity3.700841188430786
INFO:root:current mean train loss 3313.7452009129593
INFO:root:current train perplexity3.693551778793335
INFO:root:current mean train loss 3316.0503322934146
INFO:root:current train perplexity3.6946606636047363
INFO:root:current mean train loss 3317.3239290840665
INFO:root:current train perplexity3.696401596069336
INFO:root:current mean train loss 3317.852869614567
INFO:root:current train perplexity3.699359655380249
INFO:root:current mean train loss 3318.7611128106173
INFO:root:current train perplexity3.7009003162384033
INFO:root:current mean train loss 3318.01619312417
INFO:root:current train perplexity3.7002151012420654
INFO:root:current mean train loss 3319.6327642906053
INFO:root:current train perplexity3.701381206512451


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.95s/it]
INFO:root:final mean train loss: 3318.0391602669993
INFO:root:final train perplexity: 3.70270037651062
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.94s/it]
INFO:root:eval mean loss: 4045.238961727061
INFO:root:eval perplexity: 5.133440017700195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/132

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [6:51:48<3:35:54, 190.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3283.5371271306817
INFO:root:current train perplexity3.672558069229126
INFO:root:current mean train loss 3287.266519657258
INFO:root:current train perplexity3.6790454387664795
INFO:root:current mean train loss 3292.126802810968
INFO:root:current train perplexity3.6860978603363037
INFO:root:current mean train loss 3294.3229629731513
INFO:root:current train perplexity3.681183099746704
INFO:root:current mean train loss 3299.6391478150754
INFO:root:current train perplexity3.682098150253296
INFO:root:current mean train loss 3303.951391381616
INFO:root:current train perplexity3.6853816509246826
INFO:root:current mean train loss 3306.2900058891937
INFO:root:current train perplexity3.6892616748809814
INFO:root:current mean train loss 3308.7340642461713
INFO:root:current train perplexity3.6909613609313965
INFO:root:current mean train loss 3311.979560718202
INFO:root:current train perplexity3.6924819946289062
INFO:root:current mean train loss 3314.056150809882
INFO:root:current train perplexity3.695045232772827


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:39<00:00, 159.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:39<00:00, 159.18s/it]
INFO:root:final mean train loss: 3314.1060306179907
INFO:root:final train perplexity: 3.6969590187072754
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 13.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 13.00s/it]
INFO:root:eval mean loss: 4047.2945305574026
INFO:root:eval perplexity: 5.13770866394043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/133

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [6:54:53<3:31:12, 189.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3299.1790132068454
INFO:root:current train perplexity3.6887383460998535
INFO:root:current mean train loss 3301.0906031321892
INFO:root:current train perplexity3.6874918937683105
INFO:root:current mean train loss 3307.6885229770674
INFO:root:current train perplexity3.6945271492004395
INFO:root:current mean train loss 3311.5574275245353
INFO:root:current train perplexity3.6976325511932373
INFO:root:current mean train loss 3313.3187464143493
INFO:root:current train perplexity3.6959452629089355
INFO:root:current mean train loss 3319.3683245101574
INFO:root:current train perplexity3.6972270011901855
INFO:root:current mean train loss 3316.8679298642533
INFO:root:current train perplexity3.6946117877960205
INFO:root:current mean train loss 3314.7201063723583
INFO:root:current train perplexity3.6930322647094727
INFO:root:current mean train loss 3314.523240320376
INFO:root:current train perplexity3.693701982498169
INFO:root:current mean train loss 3316.0799498434253
INFO:root:current train perplexity3.6955833435058594


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:38<00:00, 158.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:38<00:00, 158.97s/it]
INFO:root:final mean train loss: 3313.506375712733
INFO:root:final train perplexity: 3.69608473777771
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.18s/it]
INFO:root:eval mean loss: 4050.46597095246
INFO:root:eval perplexity: 5.144300937652588
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/134

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [6:57:47<3:22:47, 184.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3310.5571151518484
INFO:root:current train perplexity3.6894960403442383
INFO:root:current mean train loss 3296.8466382835345
INFO:root:current train perplexity3.672149658203125
INFO:root:current mean train loss 3297.321331404232
INFO:root:current train perplexity3.674006938934326
INFO:root:current mean train loss 3300.3361092539167
INFO:root:current train perplexity3.67729115486145
INFO:root:current mean train loss 3304.580690290771
INFO:root:current train perplexity3.6817164421081543
INFO:root:current mean train loss 3310.5633363206
INFO:root:current train perplexity3.6844828128814697
INFO:root:current mean train loss 3314.602468840234
INFO:root:current train perplexity3.691117763519287
INFO:root:current mean train loss 3312.8419282866203
INFO:root:current train perplexity3.6902341842651367
INFO:root:current mean train loss 3313.605133792426
INFO:root:current train perplexity3.6917381286621094
INFO:root:current mean train loss 3311.72688181884
INFO:root:current train perplexity3.6897270679473877


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.44s/it]
INFO:root:final mean train loss: 3309.649903143606
INFO:root:final train perplexity: 3.690465211868286
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.15s/it]
INFO:root:eval mean loss: 4048.196482989805
INFO:root:eval perplexity: 5.139582633972168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/135

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [7:00:36<3:14:56, 179.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3313.3831678945808
INFO:root:current train perplexity3.6819491386413574
INFO:root:current mean train loss 3305.5933831071056
INFO:root:current train perplexity3.6938352584838867
INFO:root:current mean train loss 3304.3092237903224
INFO:root:current train perplexity3.686922788619995
INFO:root:current mean train loss 3307.0831025055654
INFO:root:current train perplexity3.685945749282837
INFO:root:current mean train loss 3309.790660882046
INFO:root:current train perplexity3.687269449234009
INFO:root:current mean train loss 3311.355381044905
INFO:root:current train perplexity3.6873421669006348
INFO:root:current mean train loss 3314.241295433887
INFO:root:current train perplexity3.6878714561462402
INFO:root:current mean train loss 3313.344292186497
INFO:root:current train perplexity3.6855125427246094
INFO:root:current mean train loss 3311.9047546039533
INFO:root:current train perplexity3.6855077743530273
INFO:root:current mean train loss 3308.6670857040826
INFO:root:current train perplexity3.684727907180786


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.43s/it]
INFO:root:final mean train loss: 3306.1654167175293
INFO:root:final train perplexity: 3.6853957176208496
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.20s/it]
INFO:root:eval mean loss: 4050.6676622755986
INFO:root:eval perplexity: 5.144720554351807
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/136

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [7:03:26<3:08:38, 176.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3282.863140939296
INFO:root:current train perplexity3.666916847229004
INFO:root:current mean train loss 3298.479319852941
INFO:root:current train perplexity3.674812078475952
INFO:root:current mean train loss 3297.073437840266
INFO:root:current train perplexity3.671778678894043
INFO:root:current mean train loss 3305.3216726219316
INFO:root:current train perplexity3.6781117916107178
INFO:root:current mean train loss 3308.6576742371985
INFO:root:current train perplexity3.6800472736358643
INFO:root:current mean train loss 3307.8072312207196
INFO:root:current train perplexity3.6780967712402344
INFO:root:current mean train loss 3307.3406639487807
INFO:root:current train perplexity3.6784613132476807
INFO:root:current mean train loss 3304.591159379467
INFO:root:current train perplexity3.677034616470337
INFO:root:current mean train loss 3304.859141593856
INFO:root:current train perplexity3.6783318519592285
INFO:root:current mean train loss 3306.068598321144
INFO:root:current train perplexity3.6817331314086914


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.38s/it]
INFO:root:final mean train loss: 3303.765899473621
INFO:root:final train perplexity: 3.681908130645752
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.95s/it]
INFO:root:eval mean loss: 4050.4784619486923
INFO:root:eval perplexity: 5.1443281173706055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/137

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [7:06:15<3:03:19, 174.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3281.381265419408
INFO:root:current train perplexity3.655916452407837
INFO:root:current mean train loss 3294.0956192407853
INFO:root:current train perplexity3.6616361141204834
INFO:root:current mean train loss 3297.1534850039725
INFO:root:current train perplexity3.66831636428833
INFO:root:current mean train loss 3297.207628930973
INFO:root:current train perplexity3.6716549396514893
INFO:root:current mean train loss 3296.552166686395
INFO:root:current train perplexity3.673123598098755
INFO:root:current mean train loss 3299.468688041623
INFO:root:current train perplexity3.6760449409484863
INFO:root:current mean train loss 3297.7040095267535
INFO:root:current train perplexity3.674412488937378
INFO:root:current mean train loss 3301.6910601537934
INFO:root:current train perplexity3.678083658218384
INFO:root:current mean train loss 3302.3759651056216
INFO:root:current train perplexity3.6777172088623047


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.15s/it]
INFO:root:final mean train loss: 3300.9995155949746
INFO:root:final train perplexity: 3.6778924465179443
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.41s/it]
INFO:root:eval mean loss: 4051.6430906471633
INFO:root:eval perplexity: 5.146750450134277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/138

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [7:09:37<3:08:55, 182.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3356.9715169270835
INFO:root:current train perplexity3.5359036922454834
INFO:root:current mean train loss 3275.0932522375606
INFO:root:current train perplexity3.6400392055511475
INFO:root:current mean train loss 3279.5161024572812
INFO:root:current train perplexity3.6480040550231934
INFO:root:current mean train loss 3285.242558142533
INFO:root:current train perplexity3.657170534133911
INFO:root:current mean train loss 3290.4351349255585
INFO:root:current train perplexity3.655913829803467
INFO:root:current mean train loss 3291.930964505933
INFO:root:current train perplexity3.656987428665161
INFO:root:current mean train loss 3293.949038984764
INFO:root:current train perplexity3.659618377685547
INFO:root:current mean train loss 3294.9315447746267
INFO:root:current train perplexity3.6631693840026855
INFO:root:current mean train loss 3297.5122292258525
INFO:root:current train perplexity3.666346549987793
INFO:root:current mean train loss 3297.806083400384
INFO:root:current train perplexity3.6685948371887207


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.91s/it]
INFO:root:final mean train loss: 3296.8834013785086
INFO:root:final train perplexity: 3.671924114227295
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.64s/it]
INFO:root:eval mean loss: 4054.281629197141
INFO:root:eval perplexity: 5.152245044708252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/139

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [7:12:28<3:02:13, 179.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3349.8331187855115
INFO:root:current train perplexity3.613633871078491
INFO:root:current mean train loss 3295.7646858284065
INFO:root:current train perplexity3.669680118560791
INFO:root:current mean train loss 3289.0744015662026
INFO:root:current train perplexity3.655592918395996
INFO:root:current mean train loss 3279.971135669966
INFO:root:current train perplexity3.6462831497192383
INFO:root:current mean train loss 3284.452308227836
INFO:root:current train perplexity3.6510345935821533
INFO:root:current mean train loss 3286.1212146258868
INFO:root:current train perplexity3.6584672927856445
INFO:root:current mean train loss 3289.0557759436374
INFO:root:current train perplexity3.659714460372925
INFO:root:current mean train loss 3291.6258938087863
INFO:root:current train perplexity3.660184621810913
INFO:root:current mean train loss 3293.832853079724
INFO:root:current train perplexity3.6649043560028076
INFO:root:current mean train loss 3296.1873531404362
INFO:root:current train perplexity3.6661930084228516


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.55s/it]
INFO:root:final mean train loss: 3293.961432549261
INFO:root:final train perplexity: 3.667693614959717
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.18s/it]
INFO:root:eval mean loss: 4055.894600509752
INFO:root:eval perplexity: 5.155605792999268
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/140

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [7:15:23<2:57:49, 177.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3286.616634971217
INFO:root:current train perplexity3.662477493286133
INFO:root:current mean train loss 3271.6451241629466
INFO:root:current train perplexity3.6462647914886475
INFO:root:current mean train loss 3272.2669226241437
INFO:root:current train perplexity3.6571054458618164
INFO:root:current mean train loss 3279.8527870297808
INFO:root:current train perplexity3.6574699878692627
INFO:root:current mean train loss 3284.318130966587
INFO:root:current train perplexity3.65970778465271
INFO:root:current mean train loss 3287.433778149085
INFO:root:current train perplexity3.6613543033599854
INFO:root:current mean train loss 3286.198436632295
INFO:root:current train perplexity3.6603896617889404
INFO:root:current mean train loss 3289.0784842500434
INFO:root:current train perplexity3.66153883934021
INFO:root:current mean train loss 3290.4296299674716
INFO:root:current train perplexity3.661862373352051
INFO:root:current mean train loss 3292.19318589967
INFO:root:current train perplexity3.6621246337890625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.88s/it]
INFO:root:final mean train loss: 3292.290587332941
INFO:root:final train perplexity: 3.6652770042419434
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.25s/it]
INFO:root:eval mean loss: 4053.9398167386967
INFO:root:eval perplexity: 5.1515326499938965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/141

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [7:18:13<2:52:35, 175.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3238.538158275463
INFO:root:current train perplexity3.6574277877807617
INFO:root:current mean train loss 3284.9469272883857
INFO:root:current train perplexity3.6620469093322754
INFO:root:current mean train loss 3285.7305182234304
INFO:root:current train perplexity3.6617352962493896
INFO:root:current mean train loss 3285.14335534332
INFO:root:current train perplexity3.6625866889953613
INFO:root:current mean train loss 3290.37739509386
INFO:root:current train perplexity3.663370370864868
INFO:root:current mean train loss 3290.3120492432104
INFO:root:current train perplexity3.660980224609375
INFO:root:current mean train loss 3291.828491405627
INFO:root:current train perplexity3.6637258529663086
INFO:root:current mean train loss 3291.729636253976
INFO:root:current train perplexity3.663649797439575
INFO:root:current mean train loss 3292.4217820081053
INFO:root:current train perplexity3.664830207824707
INFO:root:current mean train loss 3291.6707398909452
INFO:root:current train perplexity3.661905527114868


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.31s/it]
INFO:root:final mean train loss: 3289.7382585463984
INFO:root:final train perplexity: 3.661588191986084
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.47s/it]
INFO:root:eval mean loss: 4056.3572019752883
INFO:root:eval perplexity: 5.156570911407471
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/142

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [7:21:00<2:47:09, 172.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3343.686474609375
INFO:root:current train perplexity3.653923988342285
INFO:root:current mean train loss 3307.908009620949
INFO:root:current train perplexity3.6388564109802246
INFO:root:current mean train loss 3296.801787940492
INFO:root:current train perplexity3.6407926082611084
INFO:root:current mean train loss 3294.775923361707
INFO:root:current train perplexity3.642879009246826
INFO:root:current mean train loss 3288.694520025144
INFO:root:current train perplexity3.6459953784942627
INFO:root:current mean train loss 3293.349727110105
INFO:root:current train perplexity3.650846481323242
INFO:root:current mean train loss 3289.5307002030017
INFO:root:current train perplexity3.6473946571350098
INFO:root:current mean train loss 3287.226263552296
INFO:root:current train perplexity3.648894786834717
INFO:root:current mean train loss 3285.797413571295
INFO:root:current train perplexity3.651407480239868
INFO:root:current mean train loss 3286.5031735670123
INFO:root:current train perplexity3.654017210006714


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.29s/it]
INFO:root:final mean train loss: 3285.373166853382
INFO:root:final train perplexity: 3.655287027359009
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.56s/it]
INFO:root:eval mean loss: 4057.3955199329566
INFO:root:eval perplexity: 5.158736228942871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/143

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [7:23:49<2:43:07, 171.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3279.7234397710754
INFO:root:current train perplexity3.631591796875
INFO:root:current mean train loss 3272.6810721017264
INFO:root:current train perplexity3.630638599395752
INFO:root:current mean train loss 3271.192424004951
INFO:root:current train perplexity3.6337175369262695
INFO:root:current mean train loss 3276.177823347531
INFO:root:current train perplexity3.635019540786743
INFO:root:current mean train loss 3277.892478925649
INFO:root:current train perplexity3.6392452716827393
INFO:root:current mean train loss 3280.5719230188192
INFO:root:current train perplexity3.6434171199798584
INFO:root:current mean train loss 3282.8720190543595
INFO:root:current train perplexity3.6457102298736572
INFO:root:current mean train loss 3280.4034481330964
INFO:root:current train perplexity3.6466431617736816
INFO:root:current mean train loss 3282.8213183130374
INFO:root:current train perplexity3.649535894393921
INFO:root:current mean train loss 3284.337869913176
INFO:root:current train perplexity3.6529641151428223


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:39<00:00, 159.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:39<00:00, 159.31s/it]
INFO:root:final mean train loss: 3283.9528819053403
INFO:root:final train perplexity: 3.653240203857422
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.73s/it]
INFO:root:eval mean loss: 4059.000083111702
INFO:root:eval perplexity: 5.162084579467773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/144

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [7:26:43<2:40:55, 172.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3282.147566253064
INFO:root:current train perplexity3.6234028339385986
INFO:root:current mean train loss 3276.7904076986756
INFO:root:current train perplexity3.637293577194214
INFO:root:current mean train loss 3276.843178068974
INFO:root:current train perplexity3.6354446411132812
INFO:root:current mean train loss 3271.9767530827103
INFO:root:current train perplexity3.6351096630096436
INFO:root:current mean train loss 3275.7663552565477
INFO:root:current train perplexity3.6370632648468018
INFO:root:current mean train loss 3277.608189300703
INFO:root:current train perplexity3.6419429779052734
INFO:root:current mean train loss 3282.0111595892135
INFO:root:current train perplexity3.6452443599700928
INFO:root:current mean train loss 3284.021852373918
INFO:root:current train perplexity3.648007392883301
INFO:root:current mean train loss 3283.5004690598375
INFO:root:current train perplexity3.648178815841675
INFO:root:current mean train loss 3281.940758545692
INFO:root:current train perplexity3.648092746734619


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.95s/it]
INFO:root:final mean train loss: 3280.714180546422
INFO:root:final train perplexity: 3.6485755443573
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.20s/it]
INFO:root:eval mean loss: 4059.7213558981603
INFO:root:eval perplexity: 5.163589954376221
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/145

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [7:29:29<2:36:20, 170.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3280.451606362553
INFO:root:current train perplexity3.6269936561584473
INFO:root:current mean train loss 3272.2839908239976
INFO:root:current train perplexity3.6266655921936035
INFO:root:current mean train loss 3268.1272029213924
INFO:root:current train perplexity3.6302244663238525
INFO:root:current mean train loss 3271.919845028508
INFO:root:current train perplexity3.637026309967041
INFO:root:current mean train loss 3274.529368681066
INFO:root:current train perplexity3.6380298137664795
INFO:root:current mean train loss 3276.298665655747
INFO:root:current train perplexity3.640357255935669
INFO:root:current mean train loss 3280.807982472259
INFO:root:current train perplexity3.642346143722534
INFO:root:current mean train loss 3280.727790279665
INFO:root:current train perplexity3.6443514823913574
INFO:root:current mean train loss 3281.3689573063702
INFO:root:current train perplexity3.6451973915100098
INFO:root:current mean train loss 3280.6838465462884
INFO:root:current train perplexity3.6453857421875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.22s/it]
INFO:root:final mean train loss: 3278.817967014928
INFO:root:final train perplexity: 3.6458468437194824
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.62s/it]
INFO:root:eval mean loss: 4060.401839885306
INFO:root:eval perplexity: 5.165011405944824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/146

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [7:32:15<2:32:13, 169.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3271.2720528218283
INFO:root:current train perplexity3.6315810680389404
INFO:root:current mean train loss 3283.4299228691057
INFO:root:current train perplexity3.6255087852478027
INFO:root:current mean train loss 3280.0691201427903
INFO:root:current train perplexity3.6317312717437744
INFO:root:current mean train loss 3281.4678951751957
INFO:root:current train perplexity3.630063056945801
INFO:root:current mean train loss 3278.0383755604257
INFO:root:current train perplexity3.6313135623931885
INFO:root:current mean train loss 3275.179287918871
INFO:root:current train perplexity3.63293194770813
INFO:root:current mean train loss 3276.3406080163045
INFO:root:current train perplexity3.6341564655303955
INFO:root:current mean train loss 3276.6078710046245
INFO:root:current train perplexity3.6346893310546875
INFO:root:current mean train loss 3277.841857135777
INFO:root:current train perplexity3.6385200023651123
INFO:root:current mean train loss 3278.613253225585
INFO:root:current train perplexity3.640503168106079


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:40<00:00, 160.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:40<00:00, 160.44s/it]
INFO:root:final mean train loss: 3275.4262668240453
INFO:root:final train perplexity: 3.6409714221954346
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.43s/it]
INFO:root:eval mean loss: 4061.5053936031695
INFO:root:eval perplexity: 5.167316436767578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/147

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [7:35:10<2:30:56, 170.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3250.6029036458335
INFO:root:current train perplexity3.61055850982666
INFO:root:current mean train loss 3271.0640262276784
INFO:root:current train perplexity3.6345298290252686
INFO:root:current mean train loss 3276.018736683239
INFO:root:current train perplexity3.639331102371216
INFO:root:current mean train loss 3270.6975787760416
INFO:root:current train perplexity3.6340646743774414
INFO:root:current mean train loss 3269.6353294613486
INFO:root:current train perplexity3.6304469108581543
INFO:root:current mean train loss 3271.043757218071
INFO:root:current train perplexity3.630574941635132
INFO:root:current mean train loss 3274.081813874421
INFO:root:current train perplexity3.6327548027038574
INFO:root:current mean train loss 3274.7755553805446
INFO:root:current train perplexity3.6324121952056885
INFO:root:current mean train loss 3278.6326411830355
INFO:root:current train perplexity3.6375255584716797
INFO:root:current mean train loss 3277.0788321314103
INFO:root:current train perplexity3.6386184692382812


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.66s/it]
INFO:root:final mean train loss: 3274.4533800309705
INFO:root:final train perplexity: 3.639573574066162
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.30s/it]
INFO:root:eval mean loss: 4061.230326767509
INFO:root:eval perplexity: 5.166741371154785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/148

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [7:37:59<2:27:36, 170.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3276.047163262425
INFO:root:current train perplexity3.637650728225708
INFO:root:current mean train loss 3269.00496552681
INFO:root:current train perplexity3.6352198123931885
INFO:root:current mean train loss 3269.8880766204725
INFO:root:current train perplexity3.631556272506714
INFO:root:current mean train loss 3272.2479142868797
INFO:root:current train perplexity3.6310696601867676
INFO:root:current mean train loss 3272.3673189214546
INFO:root:current train perplexity3.630039691925049
INFO:root:current mean train loss 3270.9319132417186
INFO:root:current train perplexity3.6322014331817627
INFO:root:current mean train loss 3270.995832094162
INFO:root:current train perplexity3.6315765380859375
INFO:root:current mean train loss 3270.963663269277
INFO:root:current train perplexity3.6317317485809326
INFO:root:current mean train loss 3271.9470496863496
INFO:root:current train perplexity3.6333186626434326
INFO:root:current mean train loss 3273.9320968674497
INFO:root:current train perplexity3.6350650787353516


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:39<00:00, 159.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:39<00:00, 159.83s/it]
INFO:root:final mean train loss: 3271.6441769753733
INFO:root:final train perplexity: 3.635542154312134
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.97s/it]
INFO:root:eval mean loss: 4062.822442237367
INFO:root:eval perplexity: 5.170069217681885
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/149

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [7:40:54<2:25:55, 171.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3260.88091303228
INFO:root:current train perplexity3.6106746196746826
INFO:root:current mean train loss 3256.743821069208
INFO:root:current train perplexity3.610053300857544
INFO:root:current mean train loss 3260.6582777934386
INFO:root:current train perplexity3.6171982288360596
INFO:root:current mean train loss 3262.3452685421994
INFO:root:current train perplexity3.6179091930389404
INFO:root:current mean train loss 3263.715213690173
INFO:root:current train perplexity3.620985269546509
INFO:root:current mean train loss 3262.7765522551817
INFO:root:current train perplexity3.6213831901550293
INFO:root:current mean train loss 3266.853862933588
INFO:root:current train perplexity3.6246509552001953
INFO:root:current mean train loss 3267.077941045749
INFO:root:current train perplexity3.6280837059020996
INFO:root:current mean train loss 3268.759513812167
INFO:root:current train perplexity3.6288390159606934
INFO:root:current mean train loss 3270.071168100798
INFO:root:current train perplexity3.629671812057495


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.75s/it]
INFO:root:final mean train loss: 3267.534350364439
INFO:root:final train perplexity: 3.629652500152588
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.25s/it]
INFO:root:eval mean loss: 4065.293160945811
INFO:root:eval perplexity: 5.175238132476807
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/150

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [7:43:41<2:21:55, 170.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3265.2665251144253
INFO:root:current train perplexity3.6404597759246826
INFO:root:current mean train loss 3266.402488516803
INFO:root:current train perplexity3.6248557567596436
INFO:root:current mean train loss 3265.645533124739
INFO:root:current train perplexity3.623424768447876
INFO:root:current mean train loss 3263.309542777843
INFO:root:current train perplexity3.621227264404297
INFO:root:current mean train loss 3264.7548182302103
INFO:root:current train perplexity3.6216349601745605
INFO:root:current mean train loss 3266.394130190943
INFO:root:current train perplexity3.626297950744629
INFO:root:current mean train loss 3265.3549874541754
INFO:root:current train perplexity3.6276803016662598
INFO:root:current mean train loss 3262.6197541849187
INFO:root:current train perplexity3.6258511543273926
INFO:root:current mean train loss 3266.714122190889
INFO:root:current train perplexity3.627148389816284


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.08s/it]
INFO:root:final mean train loss: 3266.8593214711836
INFO:root:final train perplexity: 3.62868595123291
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.62s/it]
INFO:root:eval mean loss: 4065.8125883061834
INFO:root:eval perplexity: 5.176324367523193
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/151

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [7:46:28<2:18:28, 169.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3254.534737723214
INFO:root:current train perplexity3.619387626647949
INFO:root:current mean train loss 3267.945588584258
INFO:root:current train perplexity3.6265270709991455
INFO:root:current mean train loss 3263.5197895437045
INFO:root:current train perplexity3.6249611377716064
INFO:root:current mean train loss 3261.245944243689
INFO:root:current train perplexity3.6274285316467285
INFO:root:current mean train loss 3262.1129243368014
INFO:root:current train perplexity3.627044200897217
INFO:root:current mean train loss 3263.281001043978
INFO:root:current train perplexity3.6232213973999023
INFO:root:current mean train loss 3262.9456085255356
INFO:root:current train perplexity3.623586416244507
INFO:root:current mean train loss 3267.721847167278
INFO:root:current train perplexity3.6241648197174072
INFO:root:current mean train loss 3268.505685421023
INFO:root:current train perplexity3.6252667903900146
INFO:root:current mean train loss 3271.27157535574
INFO:root:current train perplexity3.6276097297668457


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.69s/it]
INFO:root:final mean train loss: 3265.4435323899793
INFO:root:final train perplexity: 3.626659393310547
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.59s/it]
INFO:root:eval mean loss: 4064.6200894835993
INFO:root:eval perplexity: 5.173828125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/152

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [7:49:17<2:15:20, 169.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3285.3943359375
INFO:root:current train perplexity3.626575469970703
INFO:root:current mean train loss 3260.5294200067933
INFO:root:current train perplexity3.613750457763672
INFO:root:current mean train loss 3260.057058502907
INFO:root:current train perplexity3.6167984008789062
INFO:root:current mean train loss 3254.610773189484
INFO:root:current train perplexity3.6138405799865723
INFO:root:current mean train loss 3259.4958954960466
INFO:root:current train perplexity3.615032434463501
INFO:root:current mean train loss 3262.1037460179004
INFO:root:current train perplexity3.618574857711792
INFO:root:current mean train loss 3263.1811150279473
INFO:root:current train perplexity3.6160125732421875
INFO:root:current mean train loss 3265.8621954217656
INFO:root:current train perplexity3.620137929916382
INFO:root:current mean train loss 3264.5782370350844
INFO:root:current train perplexity3.621563673019409
INFO:root:current mean train loss 3264.992667242999
INFO:root:current train perplexity3.622762680053711


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.40s/it]
INFO:root:final mean train loss: 3262.64158562691
INFO:root:final train perplexity: 3.622653007507324
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.97s/it]
INFO:root:eval mean loss: 4065.964523423648
INFO:root:eval perplexity: 5.176642417907715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/153

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [7:52:16<2:14:51, 172.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3216.783203125
INFO:root:current train perplexity3.5755789279937744
INFO:root:current mean train loss 3248.673538332063
INFO:root:current train perplexity3.603339433670044
INFO:root:current mean train loss 3249.1852819331557
INFO:root:current train perplexity3.5993258953094482
INFO:root:current mean train loss 3251.1365932783474
INFO:root:current train perplexity3.6013050079345703
INFO:root:current mean train loss 3252.676031162271
INFO:root:current train perplexity3.6054983139038086
INFO:root:current mean train loss 3255.259516349486
INFO:root:current train perplexity3.6068763732910156
INFO:root:current mean train loss 3255.4861913592244
INFO:root:current train perplexity3.6103360652923584
INFO:root:current mean train loss 3258.967010962353
INFO:root:current train perplexity3.614010810852051
INFO:root:current mean train loss 3261.620944536471
INFO:root:current train perplexity3.614804983139038
INFO:root:current mean train loss 3262.066692976368
INFO:root:current train perplexity3.6166703701019287


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.53s/it]
INFO:root:final mean train loss: 3259.5639610290527
INFO:root:final train perplexity: 3.6182563304901123
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.30s/it]
INFO:root:eval mean loss: 4066.9327037621897
INFO:root:eval perplexity: 5.178669452667236
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/154

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [7:55:07<2:11:41, 171.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3283.373078377016
INFO:root:current train perplexity3.644700765609741
INFO:root:current mean train loss 3260.3426932997377
INFO:root:current train perplexity3.6238555908203125
INFO:root:current mean train loss 3255.9374450419373
INFO:root:current train perplexity3.610686779022217
INFO:root:current mean train loss 3256.4038956287764
INFO:root:current train perplexity3.612544059753418
INFO:root:current mean train loss 3252.858732643924
INFO:root:current train perplexity3.614611864089966
INFO:root:current mean train loss 3252.213237295492
INFO:root:current train perplexity3.613851308822632
INFO:root:current mean train loss 3256.5656041842067
INFO:root:current train perplexity3.6175296306610107
INFO:root:current mean train loss 3259.5854892965544
INFO:root:current train perplexity3.6203370094299316
INFO:root:current mean train loss 3262.0386832153467
INFO:root:current train perplexity3.617595672607422
INFO:root:current mean train loss 3260.446376124463
INFO:root:current train perplexity3.616961717605591


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.21s/it]
INFO:root:final mean train loss: 3258.3285360028667
INFO:root:final train perplexity: 3.6164937019348145
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.29s/it]
INFO:root:eval mean loss: 4068.274178579344
INFO:root:eval perplexity: 5.1814799308776855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/155

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [7:57:53<2:07:38, 170.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3297.634765625
INFO:root:current train perplexity3.6179134845733643
INFO:root:current mean train loss 3254.136450019672
INFO:root:current train perplexity3.597289562225342
INFO:root:current mean train loss 3257.4940589042885
INFO:root:current train perplexity3.605090856552124
INFO:root:current mean train loss 3255.5277196833517
INFO:root:current train perplexity3.6094977855682373
INFO:root:current mean train loss 3250.6409225290076
INFO:root:current train perplexity3.610530138015747
INFO:root:current mean train loss 3252.933639498058
INFO:root:current train perplexity3.6093337535858154
INFO:root:current mean train loss 3252.982402007531
INFO:root:current train perplexity3.60772442817688
INFO:root:current mean train loss 3255.0862311955557
INFO:root:current train perplexity3.6081700325012207
INFO:root:current mean train loss 3256.049349579112
INFO:root:current train perplexity3.6075658798217773
INFO:root:current mean train loss 3257.5566005848973
INFO:root:current train perplexity3.611694574356079


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.27s/it]
INFO:root:final mean train loss: 3255.271552793441
INFO:root:final train perplexity: 3.6121346950531006
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.21s/it]
INFO:root:eval mean loss: 4068.5110313469636
INFO:root:eval perplexity: 5.181975364685059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/156

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [8:00:41<2:04:12, 169.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3241.965155418883
INFO:root:current train perplexity3.5554070472717285
INFO:root:current mean train loss 3255.3058965773807
INFO:root:current train perplexity3.587771415710449
INFO:root:current mean train loss 3246.847696775367
INFO:root:current train perplexity3.5905191898345947
INFO:root:current mean train loss 3249.052956001216
INFO:root:current train perplexity3.5942840576171875
INFO:root:current mean train loss 3252.4501341408
INFO:root:current train perplexity3.6008477210998535
INFO:root:current mean train loss 3247.9124584023652
INFO:root:current train perplexity3.599980354309082
INFO:root:current mean train loss 3248.5292387642485
INFO:root:current train perplexity3.6021993160247803
INFO:root:current mean train loss 3251.4907056611864
INFO:root:current train perplexity3.604187250137329
INFO:root:current mean train loss 3254.835495337404
INFO:root:current train perplexity3.6064677238464355
INFO:root:current mean train loss 3256.3370300744127
INFO:root:current train perplexity3.6087701320648193


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.94s/it]
INFO:root:final mean train loss: 3253.521185290429
INFO:root:final train perplexity: 3.6096410751342773
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.97s/it]
INFO:root:eval mean loss: 4069.0565107629654
INFO:root:eval perplexity: 5.183119297027588
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/157

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [8:03:27<2:00:38, 168.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3231.369961825284
INFO:root:current train perplexity3.622739553451538
INFO:root:current mean train loss 3223.8595403855848
INFO:root:current train perplexity3.5952279567718506
INFO:root:current mean train loss 3238.52094152114
INFO:root:current train perplexity3.60007643699646
INFO:root:current mean train loss 3243.9548284826146
INFO:root:current train perplexity3.603701591491699
INFO:root:current mean train loss 3245.3879743303573
INFO:root:current train perplexity3.603367805480957
INFO:root:current mean train loss 3248.9615683065877
INFO:root:current train perplexity3.6031789779663086
INFO:root:current mean train loss 3252.665441242247
INFO:root:current train perplexity3.6060776710510254
INFO:root:current mean train loss 3252.609349777525
INFO:root:current train perplexity3.6054506301879883
INFO:root:current mean train loss 3254.378705512153
INFO:root:current train perplexity3.607309579849243
INFO:root:current mean train loss 3253.355062786322
INFO:root:current train perplexity3.6054534912109375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.39s/it]
INFO:root:final mean train loss: 3250.8050451586323
INFO:root:final train perplexity: 3.6057751178741455
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.50s/it]
INFO:root:eval mean loss: 4070.4098082197474
INFO:root:eval perplexity: 5.185956954956055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/158

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [8:06:13<1:57:20, 167.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3265.3741086929563
INFO:root:current train perplexity3.6005876064300537
INFO:root:current mean train loss 3258.499000970571
INFO:root:current train perplexity3.594693660736084
INFO:root:current mean train loss 3253.2847171681915
INFO:root:current train perplexity3.5930514335632324
INFO:root:current mean train loss 3245.8899692503874
INFO:root:current train perplexity3.5958800315856934
INFO:root:current mean train loss 3249.011504138263
INFO:root:current train perplexity3.6025607585906982
INFO:root:current mean train loss 3250.83551469874
INFO:root:current train perplexity3.6027309894561768
INFO:root:current mean train loss 3249.7868192048454
INFO:root:current train perplexity3.6058292388916016
INFO:root:current mean train loss 3253.683650385505
INFO:root:current train perplexity3.605414867401123
INFO:root:current mean train loss 3251.9498909146873
INFO:root:current train perplexity3.6044461727142334
INFO:root:current mean train loss 3251.969280365719
INFO:root:current train perplexity3.6036622524261475


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.23s/it]
INFO:root:final mean train loss: 3249.5946715570267
INFO:root:final train perplexity: 3.604053497314453
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.64s/it]
INFO:root:eval mean loss: 4070.7331006205673
INFO:root:eval perplexity: 5.186634540557861
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/159

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [8:08:59<1:54:23, 167.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3252.436014524648
INFO:root:current train perplexity3.606333017349243
INFO:root:current mean train loss 3240.9554950201023
INFO:root:current train perplexity3.5886497497558594
INFO:root:current mean train loss 3241.9470349976937
INFO:root:current train perplexity3.58925461769104
INFO:root:current mean train loss 3238.559404481132
INFO:root:current train perplexity3.594376564025879
INFO:root:current mean train loss 3242.996944872943
INFO:root:current train perplexity3.595978021621704
INFO:root:current mean train loss 3242.5074819908878
INFO:root:current train perplexity3.596949577331543
INFO:root:current mean train loss 3244.7513669691925
INFO:root:current train perplexity3.595085620880127
INFO:root:current mean train loss 3246.872209007174
INFO:root:current train perplexity3.596301317214966
INFO:root:current mean train loss 3248.0487473988233
INFO:root:current train perplexity3.599656343460083
INFO:root:current mean train loss 3248.2057841464984
INFO:root:current train perplexity3.599483013153076


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:39<00:00, 159.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:39<00:00, 159.20s/it]
INFO:root:final mean train loss: 3246.493241771575
INFO:root:final train perplexity: 3.5996456146240234
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.70s/it]
INFO:root:eval mean loss: 4071.167911610705
INFO:root:eval perplexity: 5.187546730041504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/160

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [8:11:53<1:52:54, 169.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3242.543314873418
INFO:root:current train perplexity3.5829896926879883
INFO:root:current mean train loss 3237.860819385038
INFO:root:current train perplexity3.5960564613342285
INFO:root:current mean train loss 3244.321313564068
INFO:root:current train perplexity3.5990350246429443
INFO:root:current mean train loss 3250.095343033682
INFO:root:current train perplexity3.597606658935547
INFO:root:current mean train loss 3247.8212350355557
INFO:root:current train perplexity3.5960288047790527
INFO:root:current mean train loss 3249.349667985616
INFO:root:current train perplexity3.5961949825286865
INFO:root:current mean train loss 3245.8098396222617
INFO:root:current train perplexity3.5974385738372803
INFO:root:current mean train loss 3247.085516286906
INFO:root:current train perplexity3.597959041595459
INFO:root:current mean train loss 3245.664187486668
INFO:root:current train perplexity3.5983996391296387
INFO:root:current mean train loss 3247.453785351762
INFO:root:current train perplexity3.5985794067382812


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.12s/it]
INFO:root:final mean train loss: 3245.4394602621755
INFO:root:final train perplexity: 3.5981500148773193
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.35s/it]
INFO:root:eval mean loss: 4072.55987159242
INFO:root:eval perplexity: 5.19046688079834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/161

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [8:14:40<1:49:31, 168.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3234.5315867456898
INFO:root:current train perplexity3.567586660385132
INFO:root:current mean train loss 3230.935392818349
INFO:root:current train perplexity3.5711874961853027
INFO:root:current mean train loss 3236.836464911803
INFO:root:current train perplexity3.5746772289276123
INFO:root:current mean train loss 3243.367783026486
INFO:root:current train perplexity3.5850489139556885
INFO:root:current mean train loss 3241.074119990856
INFO:root:current train perplexity3.5856785774230957
INFO:root:current mean train loss 3241.9565878872977
INFO:root:current train perplexity3.584867000579834
INFO:root:current mean train loss 3240.942863275564
INFO:root:current train perplexity3.5854413509368896
INFO:root:current mean train loss 3242.2997609469307
INFO:root:current train perplexity3.587994337081909
INFO:root:current mean train loss 3242.731967723894
INFO:root:current train perplexity3.5902554988861084
INFO:root:current mean train loss 3245.276042903448
INFO:root:current train perplexity3.5944321155548096


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.61s/it]
INFO:root:final mean train loss: 3242.455186167071
INFO:root:final train perplexity: 3.5939159393310547
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.13s/it]
INFO:root:eval mean loss: 4073.322837017952
INFO:root:eval perplexity: 5.192069053649902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/162

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [8:18:19<1:56:15, 183.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3238.80478515625
INFO:root:current train perplexity3.592127799987793
INFO:root:current mean train loss 3247.329432091346
INFO:root:current train perplexity3.599679946899414
INFO:root:current mean train loss 3244.0307410288665
INFO:root:current train perplexity3.5906169414520264
INFO:root:current mean train loss 3247.728473595728
INFO:root:current train perplexity3.5886735916137695
INFO:root:current mean train loss 3250.096048867582
INFO:root:current train perplexity3.592912197113037
INFO:root:current mean train loss 3248.2833668428307
INFO:root:current train perplexity3.5912632942199707
INFO:root:current mean train loss 3246.999350480553
INFO:root:current train perplexity3.5896332263946533
INFO:root:current mean train loss 3244.8720036728578
INFO:root:current train perplexity3.5908145904541016
INFO:root:current mean train loss 3245.2368327732192
INFO:root:current train perplexity3.5922231674194336


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.55s/it]
INFO:root:final mean train loss: 3241.4576000705842
INFO:root:final train perplexity: 3.592501640319824
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.04s/it]
INFO:root:eval mean loss: 4073.7923246343084
INFO:root:eval perplexity: 5.193053722381592
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/163

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [8:21:19<1:52:36, 182.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3248.5123697916665
INFO:root:current train perplexity3.580827236175537
INFO:root:current mean train loss 3212.788868135619
INFO:root:current train perplexity3.584867477416992
INFO:root:current mean train loss 3237.094834802186
INFO:root:current train perplexity3.597805976867676
INFO:root:current mean train loss 3234.2089448935126
INFO:root:current train perplexity3.592886209487915
INFO:root:current mean train loss 3234.1908307323974
INFO:root:current train perplexity3.5949268341064453
INFO:root:current mean train loss 3236.6676867505903
INFO:root:current train perplexity3.5943222045898438
INFO:root:current mean train loss 3239.1683157292964
INFO:root:current train perplexity3.591989040374756
INFO:root:current mean train loss 3238.502268458837
INFO:root:current train perplexity3.5888545513153076
INFO:root:current mean train loss 3238.8207977408933
INFO:root:current train perplexity3.589475393295288
INFO:root:current mean train loss 3243.1400961638287
INFO:root:current train perplexity3.591301441192627


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.34s/it]
INFO:root:final mean train loss: 3240.6220329653834
INFO:root:final train perplexity: 3.591318130493164
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 12.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.28s/it]
INFO:root:eval mean loss: 4075.4210023271276
INFO:root:eval perplexity: 5.196475982666016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/164

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [8:24:13<1:48:02, 180.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3255.8099476207385
INFO:root:current train perplexity3.575349807739258
INFO:root:current mean train loss 3239.6362414660753
INFO:root:current train perplexity3.572211503982544
INFO:root:current mean train loss 3241.88108963085
INFO:root:current train perplexity3.5788934230804443
INFO:root:current mean train loss 3242.15491232918
INFO:root:current train perplexity3.586869239807129
INFO:root:current mean train loss 3246.432452645035
INFO:root:current train perplexity3.59258770942688
INFO:root:current mean train loss 3242.9539615758013
INFO:root:current train perplexity3.5927088260650635
INFO:root:current mean train loss 3240.1488674432285
INFO:root:current train perplexity3.5891079902648926
INFO:root:current mean train loss 3238.5548293144557
INFO:root:current train perplexity3.587329626083374
INFO:root:current mean train loss 3239.9087504094095
INFO:root:current train perplexity3.587165117263794
INFO:root:current mean train loss 3239.852238643575
INFO:root:current train perplexity3.5868563652038574


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:41<00:00, 161.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:41<00:00, 161.56s/it]
INFO:root:final mean train loss: 3236.827058976696
INFO:root:final train perplexity: 3.585944890975952
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.57s/it]
INFO:root:eval mean loss: 4075.183340951906
INFO:root:eval perplexity: 5.195976734161377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/165

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [8:27:08<1:44:11, 178.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3249.655453330592
INFO:root:current train perplexity3.5920732021331787
INFO:root:current mean train loss 3233.5718429950107
INFO:root:current train perplexity3.578883409500122
INFO:root:current mean train loss 3241.2959151594605
INFO:root:current train perplexity3.591216564178467
INFO:root:current mean train loss 3241.0466821365594
INFO:root:current train perplexity3.586517333984375
INFO:root:current mean train loss 3238.380833737321
INFO:root:current train perplexity3.5866289138793945
INFO:root:current mean train loss 3236.6360018515174
INFO:root:current train perplexity3.5864953994750977
INFO:root:current mean train loss 3238.6391743550585
INFO:root:current train perplexity3.5863561630249023
INFO:root:current mean train loss 3241.2699292094053
INFO:root:current train perplexity3.5869534015655518
INFO:root:current mean train loss 3241.516894888965
INFO:root:current train perplexity3.588716745376587
INFO:root:current mean train loss 3240.149282029975
INFO:root:current train perplexity3.5863587856292725


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.64s/it]
INFO:root:final mean train loss: 3236.8442581545924
INFO:root:final train perplexity: 3.5859692096710205
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.78s/it]
INFO:root:eval mean loss: 4075.7022731050533
INFO:root:eval perplexity: 5.197066783905029
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/166

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [8:30:49<1:48:21, 191.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3231.422697844329
INFO:root:current train perplexity3.590024471282959
INFO:root:current mean train loss 3232.5540165938733
INFO:root:current train perplexity3.5720677375793457
INFO:root:current mean train loss 3237.6338170257436
INFO:root:current train perplexity3.5812666416168213
INFO:root:current mean train loss 3233.047758236573
INFO:root:current train perplexity3.578561782836914
INFO:root:current mean train loss 3233.8606648858313
INFO:root:current train perplexity3.575356960296631
INFO:root:current mean train loss 3237.5124697024726
INFO:root:current train perplexity3.575928211212158
INFO:root:current mean train loss 3238.555569443406
INFO:root:current train perplexity3.5793843269348145
INFO:root:current mean train loss 3239.310431688983
INFO:root:current train perplexity3.5808372497558594
INFO:root:current mean train loss 3236.662941283442
INFO:root:current train perplexity3.581606864929199
INFO:root:current mean train loss 3237.2111513534924
INFO:root:current train perplexity3.5827410221099854


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 148.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 148.00s/it]
INFO:root:final mean train loss: 3234.7787137185373
INFO:root:final train perplexity: 3.58304762840271
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.58s/it]
INFO:root:eval mean loss: 4075.3746848681294
INFO:root:eval perplexity: 5.196378231048584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/167

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [8:33:31<1:40:17, 182.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3264.6263881138393
INFO:root:current train perplexity3.576524019241333
INFO:root:current mean train loss 3235.4511592158565
INFO:root:current train perplexity3.5804364681243896
INFO:root:current mean train loss 3223.9726811835108
INFO:root:current train perplexity3.572131872177124
INFO:root:current mean train loss 3229.835101591651
INFO:root:current train perplexity3.5728976726531982
INFO:root:current mean train loss 3232.25656485722
INFO:root:current train perplexity3.575204849243164
INFO:root:current mean train loss 3236.2484429760516
INFO:root:current train perplexity3.5770699977874756
INFO:root:current mean train loss 3235.440596164493
INFO:root:current train perplexity3.5788211822509766
INFO:root:current mean train loss 3236.2643873565053
INFO:root:current train perplexity3.5776853561401367
INFO:root:current mean train loss 3236.7239509262727
INFO:root:current train perplexity3.5785934925079346
INFO:root:current mean train loss 3236.242707375919
INFO:root:current train perplexity3.580312967300415


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.86s/it]
INFO:root:final mean train loss: 3233.5074006972773
INFO:root:final train perplexity: 3.5812509059906006
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.27s/it]
INFO:root:eval mean loss: 4075.3880520002217
INFO:root:eval perplexity: 5.196406364440918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/168

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [8:36:54<1:40:38, 188.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3235.266351744186
INFO:root:current train perplexity3.550427198410034
INFO:root:current mean train loss 3246.5555821131993
INFO:root:current train perplexity3.581479549407959
INFO:root:current mean train loss 3231.444203317901
INFO:root:current train perplexity3.577385425567627
INFO:root:current mean train loss 3226.844083113156
INFO:root:current train perplexity3.571593761444092
INFO:root:current mean train loss 3228.4550208098194
INFO:root:current train perplexity3.5729973316192627
INFO:root:current mean train loss 3227.0562944219037
INFO:root:current train perplexity3.569453716278076
INFO:root:current mean train loss 3231.4058410739453
INFO:root:current train perplexity3.570225238800049
INFO:root:current mean train loss 3232.9452300244993
INFO:root:current train perplexity3.5749478340148926
INFO:root:current mean train loss 3234.7491696901875
INFO:root:current train perplexity3.576659679412842
INFO:root:current mean train loss 3233.250189772087
INFO:root:current train perplexity3.576535940170288


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.57s/it]
INFO:root:final mean train loss: 3229.844752773162
INFO:root:final train perplexity: 3.576079845428467
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.31s/it]
INFO:root:eval mean loss: 4077.57807478668
INFO:root:eval perplexity: 5.201009750366211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/169

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [8:39:45<1:34:39, 183.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3234.07097790288
INFO:root:current train perplexity3.5562689304351807
INFO:root:current mean train loss 3222.982232706436
INFO:root:current train perplexity3.5596487522125244
INFO:root:current mean train loss 3226.2857982133964
INFO:root:current train perplexity3.5718393325805664
INFO:root:current mean train loss 3226.1822930577814
INFO:root:current train perplexity3.5707151889801025
INFO:root:current mean train loss 3221.1474706814715
INFO:root:current train perplexity3.566429615020752
INFO:root:current mean train loss 3221.8565755799114
INFO:root:current train perplexity3.5680832862854004
INFO:root:current mean train loss 3225.4052745625722
INFO:root:current train perplexity3.56972336769104
INFO:root:current mean train loss 3228.3754005076567
INFO:root:current train perplexity3.5728743076324463
INFO:root:current mean train loss 3229.701798722551
INFO:root:current train perplexity3.572108030319214
INFO:root:current mean train loss 3230.8955678849566
INFO:root:current train perplexity3.5738914012908936


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.84s/it]
INFO:root:final mean train loss: 3229.5244376890123
INFO:root:final train perplexity: 3.5756285190582275
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.39s/it]
INFO:root:eval mean loss: 4079.0052931765294
INFO:root:eval perplexity: 5.204012870788574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/170

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [8:43:39<1:39:18, 198.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3217.4113272974046
INFO:root:current train perplexity3.5661356449127197
INFO:root:current mean train loss 3211.6186953370675
INFO:root:current train perplexity3.552147626876831
INFO:root:current mean train loss 3211.2889427862574
INFO:root:current train perplexity3.5604841709136963
INFO:root:current mean train loss 3220.7594072347233
INFO:root:current train perplexity3.5700480937957764
INFO:root:current mean train loss 3221.1443030662786
INFO:root:current train perplexity3.5692856311798096
INFO:root:current mean train loss 3223.5197587943035
INFO:root:current train perplexity3.5720770359039307
INFO:root:current mean train loss 3227.3660294065344
INFO:root:current train perplexity3.5741114616394043
INFO:root:current mean train loss 3229.677295629529
INFO:root:current train perplexity3.5749733448028564
INFO:root:current mean train loss 3230.160095996435
INFO:root:current train perplexity3.5751171112060547
INFO:root:current mean train loss 3230.216763779816
INFO:root:current train perplexity3.574352979660034


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.86s/it]
INFO:root:final mean train loss: 3228.5952840005198
INFO:root:final train perplexity: 3.574317455291748
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.58s/it]
INFO:root:eval mean loss: 4077.853723404255
INFO:root:eval perplexity: 5.201589107513428
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/171

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [8:47:07<1:37:19, 201.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3254.121840747435
INFO:root:current train perplexity3.5623321533203125
INFO:root:current mean train loss 3242.884916202751
INFO:root:current train perplexity3.5781466960906982
INFO:root:current mean train loss 3234.898933096325
INFO:root:current train perplexity3.582275152206421
INFO:root:current mean train loss 3235.116086538871
INFO:root:current train perplexity3.58373761177063
INFO:root:current mean train loss 3225.570963367405
INFO:root:current train perplexity3.5758326053619385
INFO:root:current mean train loss 3223.5330029038523
INFO:root:current train perplexity3.5710866451263428
INFO:root:current mean train loss 3223.4412755780313
INFO:root:current train perplexity3.5707695484161377
INFO:root:current mean train loss 3226.16900197095
INFO:root:current train perplexity3.5717759132385254
INFO:root:current mean train loss 3229.1608740290694
INFO:root:current train perplexity3.572420358657837
INFO:root:current mean train loss 3229.374531411582
INFO:root:current train perplexity3.5724709033966064


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.09s/it]
INFO:root:final mean train loss: 3227.091697200652
INFO:root:final train perplexity: 3.572197914123535
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.81s/it]
INFO:root:eval mean loss: 4078.966611605164
INFO:root:eval perplexity: 5.20393180847168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/172

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [8:49:48<1:28:19, 189.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3218.6537141927083
INFO:root:current train perplexity3.5772459506988525
INFO:root:current mean train loss 3219.682466517857
INFO:root:current train perplexity3.5667574405670166
INFO:root:current mean train loss 3229.3204270241476
INFO:root:current train perplexity3.570152759552002
INFO:root:current mean train loss 3225.1847643229166
INFO:root:current train perplexity3.566707134246826
INFO:root:current mean train loss 3225.074701377467
INFO:root:current train perplexity3.5666446685791016
INFO:root:current mean train loss 3226.107376443614
INFO:root:current train perplexity3.5662381649017334
INFO:root:current mean train loss 3223.8989818431714
INFO:root:current train perplexity3.5666353702545166
INFO:root:current mean train loss 3225.6677312247984
INFO:root:current train perplexity3.5676910877227783
INFO:root:current mean train loss 3227.745429966518
INFO:root:current train perplexity3.568467378616333
INFO:root:current mean train loss 3226.9555591446315
INFO:root:current train perplexity3.5677735805511475


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.16s/it]
INFO:root:final mean train loss: 3224.0161556736116
INFO:root:final train perplexity: 3.567866325378418
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.35s/it]
INFO:root:eval mean loss: 4079.39672158965
INFO:root:eval perplexity: 5.204836368560791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/173

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [8:53:36<1:30:26, 200.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3226.681440606175
INFO:root:current train perplexity3.5860986709594727
INFO:root:current mean train loss 3229.681396484375
INFO:root:current train perplexity3.5670201778411865
INFO:root:current mean train loss 3226.4787011028598
INFO:root:current train perplexity3.568213939666748
INFO:root:current mean train loss 3226.861172588936
INFO:root:current train perplexity3.5632762908935547
INFO:root:current mean train loss 3234.052200096241
INFO:root:current train perplexity3.5679352283477783
INFO:root:current mean train loss 3228.301274137677
INFO:root:current train perplexity3.5668411254882812
INFO:root:current mean train loss 3226.7799485124224
INFO:root:current train perplexity3.566265106201172
INFO:root:current mean train loss 3227.8183780830936
INFO:root:current train perplexity3.5675601959228516
INFO:root:current mean train loss 3229.195504384025
INFO:root:current train perplexity3.569352388381958
INFO:root:current mean train loss 3227.0535671354432
INFO:root:current train perplexity3.568512439727783


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.28s/it]
INFO:root:final mean train loss: 3224.6436984154484
INFO:root:final train perplexity: 3.56874942779541
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.86s/it]
INFO:root:eval mean loss: 4080.601344331782
INFO:root:eval perplexity: 5.207372665405273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/174

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [8:57:38<1:32:26, 213.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3208.119945484203
INFO:root:current train perplexity3.5593810081481934
INFO:root:current mean train loss 3207.5785429789757
INFO:root:current train perplexity3.551460027694702
INFO:root:current mean train loss 3216.9986668747315
INFO:root:current train perplexity3.5583043098449707
INFO:root:current mean train loss 3221.9630898087835
INFO:root:current train perplexity3.561795473098755
INFO:root:current mean train loss 3218.231586526222
INFO:root:current train perplexity3.5569539070129395
INFO:root:current mean train loss 3219.3976030430413
INFO:root:current train perplexity3.5566771030426025
INFO:root:current mean train loss 3222.201464066457
INFO:root:current train perplexity3.5599396228790283
INFO:root:current mean train loss 3222.448698986647
INFO:root:current train perplexity3.560800313949585
INFO:root:current mean train loss 3225.202441077441
INFO:root:current train perplexity3.564284086227417
INFO:root:current mean train loss 3225.8036082062786
INFO:root:current train perplexity3.566845655441284


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.28s/it]
INFO:root:final mean train loss: 3223.275764772969
INFO:root:final train perplexity: 3.566824197769165
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.99s/it]
INFO:root:eval mean loss: 4081.902328166556
INFO:root:eval perplexity: 5.210112571716309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/175

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [9:01:29<1:31:02, 218.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3216.82601158065
INFO:root:current train perplexity3.56526780128479
INFO:root:current mean train loss 3217.532593386856
INFO:root:current train perplexity3.557363986968994
INFO:root:current mean train loss 3219.4660530217916
INFO:root:current train perplexity3.5596349239349365
INFO:root:current mean train loss 3220.2506467584976
INFO:root:current train perplexity3.5600459575653076
INFO:root:current mean train loss 3221.4568732190946
INFO:root:current train perplexity3.5614264011383057
INFO:root:current mean train loss 3222.9455525648214
INFO:root:current train perplexity3.564971923828125
INFO:root:current mean train loss 3223.536211049267
INFO:root:current train perplexity3.5628859996795654
INFO:root:current mean train loss 3221.716528900872
INFO:root:current train perplexity3.5616960525512695
INFO:root:current mean train loss 3222.0637467737592
INFO:root:current train perplexity3.5624120235443115


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.01s/it]
INFO:root:final mean train loss: 3221.5604172983476
INFO:root:final train perplexity: 3.564411163330078
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.93s/it]
INFO:root:eval mean loss: 4081.229047193595
INFO:root:eval perplexity: 5.2086944580078125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/176

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [9:04:37<1:23:41, 209.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3181.806954520089
INFO:root:current train perplexity3.441096305847168
INFO:root:current mean train loss 3228.323666581484
INFO:root:current train perplexity3.5512855052948
INFO:root:current mean train loss 3221.7633062537743
INFO:root:current train perplexity3.5494208335876465
INFO:root:current mean train loss 3219.1024674903297
INFO:root:current train perplexity3.552006959915161
INFO:root:current mean train loss 3220.6886559188806
INFO:root:current train perplexity3.550955057144165
INFO:root:current mean train loss 3218.639886318109
INFO:root:current train perplexity3.552398204803467
INFO:root:current mean train loss 3217.505740723461
INFO:root:current train perplexity3.5542361736297607
INFO:root:current mean train loss 3219.595203448219
INFO:root:current train perplexity3.559046745300293
INFO:root:current mean train loss 3220.8967209524085
INFO:root:current train perplexity3.56052827835083
INFO:root:current mean train loss 3224.0319563120174
INFO:root:current train perplexity3.5649425983428955


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.84s/it]
INFO:root:final mean train loss: 3220.6891723755866
INFO:root:final train perplexity: 3.5631861686706543
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.68s/it]
INFO:root:eval mean loss: 4082.065724041445
INFO:root:eval perplexity: 5.210456848144531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/177

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [9:07:19<1:14:50, 195.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3224.232373046875
INFO:root:current train perplexity3.523076295852661
INFO:root:current mean train loss 3212.934659476902
INFO:root:current train perplexity3.534602165222168
INFO:root:current mean train loss 3215.672803869913
INFO:root:current train perplexity3.557861566543579
INFO:root:current mean train loss 3213.313777281746
INFO:root:current train perplexity3.558681011199951
INFO:root:current mean train loss 3216.446266707455
INFO:root:current train perplexity3.5561039447784424
INFO:root:current mean train loss 3216.230376308404
INFO:root:current train perplexity3.5546886920928955
INFO:root:current mean train loss 3220.1945074314026
INFO:root:current train perplexity3.55731201171875
INFO:root:current mean train loss 3222.264917162915
INFO:root:current train perplexity3.5592305660247803
INFO:root:current mean train loss 3222.256951567293
INFO:root:current train perplexity3.559194326400757
INFO:root:current mean train loss 3220.5073965270662
INFO:root:current train perplexity3.55981183052063


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.31s/it]
INFO:root:final mean train loss: 3218.7846339441116
INFO:root:final train perplexity: 3.5605099201202393
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.68s/it]
INFO:root:eval mean loss: 4082.745700700909
INFO:root:eval perplexity: 5.211889266967773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/178

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [9:10:43<1:12:29, 197.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3235.9483271059785
INFO:root:current train perplexity3.5549840927124023
INFO:root:current mean train loss 3228.161374968242
INFO:root:current train perplexity3.546745538711548
INFO:root:current mean train loss 3222.055529401976
INFO:root:current train perplexity3.5425150394439697
INFO:root:current mean train loss 3224.9671370089977
INFO:root:current train perplexity3.549355983734131
INFO:root:current mean train loss 3228.7822635010343
INFO:root:current train perplexity3.5551507472991943
INFO:root:current mean train loss 3224.1188157265774
INFO:root:current train perplexity3.556644916534424
INFO:root:current mean train loss 3223.119024236933
INFO:root:current train perplexity3.556602954864502
INFO:root:current mean train loss 3220.244024801716
INFO:root:current train perplexity3.5576791763305664
INFO:root:current mean train loss 3218.8870468417754
INFO:root:current train perplexity3.5565240383148193
INFO:root:current mean train loss 3219.282390821794
INFO:root:current train perplexity3.5593597888946533


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.89s/it]
INFO:root:final mean train loss: 3218.126980873846
INFO:root:final train perplexity: 3.5595855712890625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.75s/it]
INFO:root:eval mean loss: 4082.3296677609706
INFO:root:eval perplexity: 5.211013317108154
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/179

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [9:14:35<1:12:51, 208.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3199.5784636466733
INFO:root:current train perplexity3.5529966354370117
INFO:root:current mean train loss 3210.925140147901
INFO:root:current train perplexity3.552896738052368
INFO:root:current mean train loss 3210.373558407738
INFO:root:current train perplexity3.560427188873291
INFO:root:current mean train loss 3210.4519205237443
INFO:root:current train perplexity3.55904221534729
INFO:root:current mean train loss 3213.0425053926188
INFO:root:current train perplexity3.5577597618103027
INFO:root:current mean train loss 3214.751017942267
INFO:root:current train perplexity3.554734230041504
INFO:root:current mean train loss 3216.556885926357
INFO:root:current train perplexity3.55743145942688
INFO:root:current mean train loss 3218.5920794235208
INFO:root:current train perplexity3.5587480068206787
INFO:root:current mean train loss 3219.226027505923
INFO:root:current train perplexity3.5576202869415283
INFO:root:current mean train loss 3217.563746926608
INFO:root:current train perplexity3.555830955505371


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.87s/it]
INFO:root:final mean train loss: 3216.9153057221442
INFO:root:final train perplexity: 3.557884931564331
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.78s/it]
INFO:root:eval mean loss: 4082.541211283799
INFO:root:eval perplexity: 5.211458683013916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/180

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [9:18:31<1:12:08, 216.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3226.2455115685098
INFO:root:current train perplexity3.5763988494873047
INFO:root:current mean train loss 3210.700955836893
INFO:root:current train perplexity3.5556046962738037
INFO:root:current mean train loss 3210.690515494247
INFO:root:current train perplexity3.554591655731201
INFO:root:current mean train loss 3215.3269763147587
INFO:root:current train perplexity3.5523605346679688
INFO:root:current mean train loss 3215.3547886042497
INFO:root:current train perplexity3.5550642013549805
INFO:root:current mean train loss 3215.1166480352795
INFO:root:current train perplexity3.5538406372070312
INFO:root:current mean train loss 3214.0719412503668
INFO:root:current train perplexity3.552274703979492
INFO:root:current mean train loss 3216.801618728328
INFO:root:current train perplexity3.554152250289917
INFO:root:current mean train loss 3218.578746554678
INFO:root:current train perplexity3.5571346282958984
INFO:root:current mean train loss 3218.596542667149
INFO:root:current train perplexity3.5561699867248535


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:35<00:00, 155.56s/it]
INFO:root:final mean train loss: 3216.14676918522
INFO:root:final train perplexity: 3.5568060874938965
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.17s/it]
INFO:root:eval mean loss: 4083.979145888741
INFO:root:eval perplexity: 5.2144904136657715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/181

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [9:22:41<1:11:45, 226.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3222.044911486037
INFO:root:current train perplexity3.534186363220215
INFO:root:current mean train loss 3214.4640432344813
INFO:root:current train perplexity3.5580101013183594
INFO:root:current mean train loss 3216.8501579500885
INFO:root:current train perplexity3.554213762283325
INFO:root:current mean train loss 3224.347585188896
INFO:root:current train perplexity3.560622453689575
INFO:root:current mean train loss 3219.36935745683
INFO:root:current train perplexity3.554830312728882
INFO:root:current mean train loss 3216.6936450239946
INFO:root:current train perplexity3.5544722080230713
INFO:root:current mean train loss 3219.158466887437
INFO:root:current train perplexity3.5549490451812744
INFO:root:current mean train loss 3217.5062907881525
INFO:root:current train perplexity3.5546154975891113
INFO:root:current mean train loss 3217.373538615149
INFO:root:current train perplexity3.554504871368408
INFO:root:current mean train loss 3217.350762017803
INFO:root:current train perplexity3.5547163486480713


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.55s/it]
INFO:root:final mean train loss: 3214.1074256896973
INFO:root:final train perplexity: 3.553945541381836
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.27s/it]
INFO:root:eval mean loss: 4083.7897395140735
INFO:root:eval perplexity: 5.2140913009643555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/182

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [9:26:28<1:07:57, 226.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3211.2378062855114
INFO:root:current train perplexity3.571571111679077
INFO:root:current mean train loss 3205.457867628528
INFO:root:current train perplexity3.561307191848755
INFO:root:current mean train loss 3204.2399002374386
INFO:root:current train perplexity3.546657085418701
INFO:root:current mean train loss 3210.4664791483274
INFO:root:current train perplexity3.548205852508545
INFO:root:current mean train loss 3212.64341303228
INFO:root:current train perplexity3.5466690063476562
INFO:root:current mean train loss 3211.0510385874154
INFO:root:current train perplexity3.5502662658691406
INFO:root:current mean train loss 3212.5998173604485
INFO:root:current train perplexity3.548884391784668
INFO:root:current mean train loss 3214.0326492006416
INFO:root:current train perplexity3.551975727081299
INFO:root:current mean train loss 3215.6347522044043
INFO:root:current train perplexity3.552321195602417
INFO:root:current mean train loss 3216.5128320823787
INFO:root:current train perplexity3.5527100563049316


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.45s/it]
INFO:root:final mean train loss: 3212.929152827109
INFO:root:final train perplexity: 3.5522940158843994
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.84s/it]
INFO:root:eval mean loss: 4083.605394295767
INFO:root:eval perplexity: 5.213702201843262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/183

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [9:29:47<1:01:51, 218.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3202.8305702814982
INFO:root:current train perplexity3.555896282196045
INFO:root:current mean train loss 3222.0305026001724
INFO:root:current train perplexity3.553406000137329
INFO:root:current mean train loss 3215.2396384119534
INFO:root:current train perplexity3.5527679920196533
INFO:root:current mean train loss 3215.80727956052
INFO:root:current train perplexity3.5555334091186523
INFO:root:current mean train loss 3215.3395199868387
INFO:root:current train perplexity3.5544111728668213
INFO:root:current mean train loss 3213.7419581032136
INFO:root:current train perplexity3.553250789642334
INFO:root:current mean train loss 3215.5580704863073
INFO:root:current train perplexity3.5532801151275635
INFO:root:current mean train loss 3216.6431694380735
INFO:root:current train perplexity3.5517969131469727
INFO:root:current mean train loss 3213.8920488235985
INFO:root:current train perplexity3.5510027408599854
INFO:root:current mean train loss 3214.0784842391126
INFO:root:current train perplexity3.5519468784332275


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.31s/it]
INFO:root:final mean train loss: 3212.8708947704686
INFO:root:final train perplexity: 3.5522119998931885
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.15s/it]
INFO:root:eval mean loss: 4083.8783625609485
INFO:root:eval perplexity: 5.214277267456055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/184

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [9:32:28<53:40, 201.30s/it]  

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3214.42343956316
INFO:root:current train perplexity3.5465822219848633
INFO:root:current mean train loss 3217.8444067525584
INFO:root:current train perplexity3.5425403118133545
INFO:root:current mean train loss 3214.814845912131
INFO:root:current train perplexity3.540968894958496
INFO:root:current mean train loss 3212.244347256149
INFO:root:current train perplexity3.5408923625946045
INFO:root:current mean train loss 3211.856432872213
INFO:root:current train perplexity3.5415525436401367
INFO:root:current mean train loss 3212.2795568355955
INFO:root:current train perplexity3.54327392578125
INFO:root:current mean train loss 3212.4126489585274
INFO:root:current train perplexity3.5457241535186768
INFO:root:current mean train loss 3210.7254348933
INFO:root:current train perplexity3.5458433628082275
INFO:root:current mean train loss 3214.383761593176
INFO:root:current train perplexity3.5473904609680176
INFO:root:current mean train loss 3213.133094858313
INFO:root:current train perplexity3.5482337474823


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.14s/it]
INFO:root:final mean train loss: 3209.7519885032407
INFO:root:final train perplexity: 3.5478432178497314
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.69s/it]
INFO:root:eval mean loss: 4084.660509474734
INFO:root:eval perplexity: 5.215927600860596
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/185

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [9:35:09<47:17, 189.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3201.5201184236553
INFO:root:current train perplexity3.5321483612060547
INFO:root:current mean train loss 3197.665602359026
INFO:root:current train perplexity3.5417962074279785
INFO:root:current mean train loss 3201.869173877128
INFO:root:current train perplexity3.5507876873016357
INFO:root:current mean train loss 3206.3522440324045
INFO:root:current train perplexity3.547369956970215
INFO:root:current mean train loss 3209.269891599524
INFO:root:current train perplexity3.5479393005371094
INFO:root:current mean train loss 3211.529976167827
INFO:root:current train perplexity3.5470237731933594
INFO:root:current mean train loss 3213.4088729835926
INFO:root:current train perplexity3.5491340160369873
INFO:root:current mean train loss 3213.578189874338
INFO:root:current train perplexity3.5501809120178223
INFO:root:current mean train loss 3214.7228498404615
INFO:root:current train perplexity3.550182819366455
INFO:root:current mean train loss 3214.016451187835
INFO:root:current train perplexity3.5497004985809326


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.57s/it]
INFO:root:final mean train loss: 3211.0842085807553
INFO:root:final train perplexity: 3.5497093200683594
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.05s/it]
INFO:root:eval mean loss: 4085.1753743489585
INFO:root:eval perplexity: 5.217013359069824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/186

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [9:37:50<42:08, 180.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3213.4880679777298
INFO:root:current train perplexity3.558708667755127
INFO:root:current mean train loss 3211.7551870091074
INFO:root:current train perplexity3.5538418292999268
INFO:root:current mean train loss 3214.2104194455032
INFO:root:current train perplexity3.546661853790283
INFO:root:current mean train loss 3214.889388525517
INFO:root:current train perplexity3.545306921005249
INFO:root:current mean train loss 3214.9762206028618
INFO:root:current train perplexity3.544097661972046
INFO:root:current mean train loss 3213.4722673718325
INFO:root:current train perplexity3.54582142829895
INFO:root:current mean train loss 3215.2536240845616
INFO:root:current train perplexity3.547485113143921
INFO:root:current mean train loss 3213.6633688552256
INFO:root:current train perplexity3.5476818084716797
INFO:root:current mean train loss 3212.1658628650825
INFO:root:current train perplexity3.547008514404297
INFO:root:current mean train loss 3211.897981127707
INFO:root:current train perplexity3.547341823577881


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:32<00:00, 152.67s/it]
INFO:root:final mean train loss: 3208.9770651171284
INFO:root:final train perplexity: 3.5467591285705566
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.75s/it]
INFO:root:eval mean loss: 4086.269707862367
INFO:root:eval perplexity: 5.219322204589844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/187

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [9:40:36<38:12, 176.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3216.5628931949013
INFO:root:current train perplexity3.536836624145508
INFO:root:current mean train loss 3214.049278846154
INFO:root:current train perplexity3.5471720695495605
INFO:root:current mean train loss 3211.879483083951
INFO:root:current train perplexity3.546480417251587
INFO:root:current mean train loss 3210.173467785799
INFO:root:current train perplexity3.546133041381836
INFO:root:current mean train loss 3207.6060941445708
INFO:root:current train perplexity3.543175458908081
INFO:root:current mean train loss 3210.8706858915443
INFO:root:current train perplexity3.5474634170532227
INFO:root:current mean train loss 3214.215145500787
INFO:root:current train perplexity3.5498011112213135
INFO:root:current mean train loss 3212.768959131781
INFO:root:current train perplexity3.5477781295776367
INFO:root:current mean train loss 3211.876887929906
INFO:root:current train perplexity3.547905445098877


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.13s/it]
INFO:root:final mean train loss: 3208.9022892367457
INFO:root:final train perplexity: 3.54665470123291
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.36s/it]
INFO:root:eval mean loss: 4085.567458998227
INFO:root:eval perplexity: 5.217840194702148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/188

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [9:43:17<34:19, 171.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3168.0298665364585
INFO:root:current train perplexity3.4745256900787354
INFO:root:current mean train loss 3208.145057456007
INFO:root:current train perplexity3.527695417404175
INFO:root:current mean train loss 3207.147678619535
INFO:root:current train perplexity3.537884473800659
INFO:root:current mean train loss 3211.126821788624
INFO:root:current train perplexity3.544966697692871
INFO:root:current mean train loss 3208.2039816125157
INFO:root:current train perplexity3.5447306632995605
INFO:root:current mean train loss 3208.306965822254
INFO:root:current train perplexity3.546276569366455
INFO:root:current mean train loss 3204.579942896196
INFO:root:current train perplexity3.544753313064575
INFO:root:current mean train loss 3206.178611614287
INFO:root:current train perplexity3.541630744934082
INFO:root:current mean train loss 3206.2368693084527
INFO:root:current train perplexity3.541659116744995
INFO:root:current mean train loss 3210.6488300716364
INFO:root:current train perplexity3.5437724590301514


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.53s/it]
INFO:root:final mean train loss: 3207.6863731876497
INFO:root:final train perplexity: 3.5449538230895996
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.84s/it]
INFO:root:eval mean loss: 4086.011457294437
INFO:root:eval perplexity: 5.218776226043701
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/189

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [9:45:58<30:53, 168.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3191.4755415482955
INFO:root:current train perplexity3.5528106689453125
INFO:root:current mean train loss 3191.6390699781814
INFO:root:current train perplexity3.530965805053711
INFO:root:current mean train loss 3207.5444405361372
INFO:root:current train perplexity3.5395901203155518
INFO:root:current mean train loss 3209.5311824884448
INFO:root:current train perplexity3.5422780513763428
INFO:root:current mean train loss 3204.965408065313
INFO:root:current train perplexity3.542649745941162
INFO:root:current mean train loss 3204.3645611966426
INFO:root:current train perplexity3.5424461364746094
INFO:root:current mean train loss 3202.497286882416
INFO:root:current train perplexity3.5398857593536377
INFO:root:current mean train loss 3204.3675944010415
INFO:root:current train perplexity3.5415358543395996
INFO:root:current mean train loss 3204.3779841751116
INFO:root:current train perplexity3.5401055812835693
INFO:root:current mean train loss 3207.782423000566
INFO:root:current train perplexity3.5423333644866943


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.58s/it]
INFO:root:final mean train loss: 3206.7146188674433
INFO:root:final train perplexity: 3.5435945987701416
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.91s/it]
INFO:root:eval mean loss: 4085.729062777039
INFO:root:eval perplexity: 5.218180179595947
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/190

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [9:48:44<27:56, 167.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3189.217220908717
INFO:root:current train perplexity3.548088312149048
INFO:root:current mean train loss 3226.104773256959
INFO:root:current train perplexity3.551438331604004
INFO:root:current mean train loss 3221.2186173391124
INFO:root:current train perplexity3.5466456413269043
INFO:root:current mean train loss 3220.669658601097
INFO:root:current train perplexity3.5475189685821533
INFO:root:current mean train loss 3213.6534927841585
INFO:root:current train perplexity3.54659366607666
INFO:root:current mean train loss 3213.843802215047
INFO:root:current train perplexity3.5460708141326904
INFO:root:current mean train loss 3210.329161513025
INFO:root:current train perplexity3.5444517135620117
INFO:root:current mean train loss 3210.0208249576235
INFO:root:current train perplexity3.5444436073303223
INFO:root:current mean train loss 3207.7023398151327
INFO:root:current train perplexity3.5437002182006836
INFO:root:current mean train loss 3208.441332662456
INFO:root:current train perplexity3.543424606323242


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.21s/it]
INFO:root:final mean train loss: 3207.1317427235267
INFO:root:final train perplexity: 3.544178009033203
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.34s/it]
INFO:root:eval mean loss: 4086.433308053524
INFO:root:eval perplexity: 5.219667911529541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/191

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [9:51:26<24:54, 166.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3259.196967230903
INFO:root:current train perplexity3.556032419204712
INFO:root:current mean train loss 3222.719972625492
INFO:root:current train perplexity3.5374083518981934
INFO:root:current mean train loss 3216.471391450991
INFO:root:current train perplexity3.542370557785034
INFO:root:current mean train loss 3215.58900307005
INFO:root:current train perplexity3.5423996448516846
INFO:root:current mean train loss 3211.925463924363
INFO:root:current train perplexity3.541834592819214
INFO:root:current mean train loss 3215.298540900735
INFO:root:current train perplexity3.543346643447876
INFO:root:current mean train loss 3210.081171111817
INFO:root:current train perplexity3.5409672260284424
INFO:root:current mean train loss 3208.1247071655775
INFO:root:current train perplexity3.540163516998291
INFO:root:current mean train loss 3206.4545871868386
INFO:root:current train perplexity3.540092945098877
INFO:root:current mean train loss 3206.9697576397316
INFO:root:current train perplexity3.5408780574798584


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.32s/it]
INFO:root:final mean train loss: 3205.6147599374094
INFO:root:final train perplexity: 3.542057514190674
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.70s/it]
INFO:root:eval mean loss: 4086.175812416888
INFO:root:eval perplexity: 5.219123840332031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/192

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [9:54:09<22:01, 165.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3191.78193359375
INFO:root:current train perplexity3.5428476333618164
INFO:root:current mean train loss 3204.575424985532
INFO:root:current train perplexity3.5369765758514404
INFO:root:current mean train loss 3201.3240036984707
INFO:root:current train perplexity3.5387091636657715
INFO:root:current mean train loss 3204.6947870510726
INFO:root:current train perplexity3.5414254665374756
INFO:root:current mean train loss 3209.243240391523
INFO:root:current train perplexity3.5418899059295654
INFO:root:current mean train loss 3204.0601804358935
INFO:root:current train perplexity3.5374643802642822
INFO:root:current mean train loss 3206.8598129152315
INFO:root:current train perplexity3.5414719581604004
INFO:root:current mean train loss 3204.725000332164
INFO:root:current train perplexity3.5405356884002686
INFO:root:current mean train loss 3204.789109573821
INFO:root:current train perplexity3.539462089538574
INFO:root:current mean train loss 3206.0813434784427
INFO:root:current train perplexity3.5404419898986816


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.44s/it]
INFO:root:final mean train loss: 3205.060899057696
INFO:root:final train perplexity: 3.54128360748291
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.40s/it]
INFO:root:eval mean loss: 4086.8688618544993
INFO:root:eval perplexity: 5.220586776733398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/193

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [9:56:49<19:04, 163.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3204.1675429233287
INFO:root:current train perplexity3.556713104248047
INFO:root:current mean train loss 3205.66845703125
INFO:root:current train perplexity3.551528215408325
INFO:root:current mean train loss 3206.2146789801955
INFO:root:current train perplexity3.5428476333618164
INFO:root:current mean train loss 3201.2042496127915
INFO:root:current train perplexity3.5419955253601074
INFO:root:current mean train loss 3206.6115342392072
INFO:root:current train perplexity3.540937900543213
INFO:root:current mean train loss 3206.499281066557
INFO:root:current train perplexity3.5388906002044678
INFO:root:current mean train loss 3205.9469212462336
INFO:root:current train perplexity3.5396950244903564
INFO:root:current mean train loss 3204.9296099533144
INFO:root:current train perplexity3.53792667388916
INFO:root:current mean train loss 3208.0131775119553
INFO:root:current train perplexity3.539905548095703
INFO:root:current mean train loss 3207.840488664419
INFO:root:current train perplexity3.5397140979766846


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.36s/it]
INFO:root:final mean train loss: 3204.3286521050236
INFO:root:final train perplexity: 3.5402605533599854
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.10s/it]
INFO:root:eval mean loss: 4086.836922719969
INFO:root:eval perplexity: 5.220519065856934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/194

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [9:59:31<16:19, 163.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3172.992254518995
INFO:root:current train perplexity3.5035197734832764
INFO:root:current mean train loss 3190.7648020359065
INFO:root:current train perplexity3.522639513015747
INFO:root:current mean train loss 3196.809119965451
INFO:root:current train perplexity3.5342929363250732
INFO:root:current mean train loss 3197.847942124065
INFO:root:current train perplexity3.534919023513794
INFO:root:current mean train loss 3201.177111302141
INFO:root:current train perplexity3.536445379257202
INFO:root:current mean train loss 3203.6948042798604
INFO:root:current train perplexity3.5394887924194336
INFO:root:current mean train loss 3207.6642860143047
INFO:root:current train perplexity3.542738676071167
INFO:root:current mean train loss 3205.395186626165
INFO:root:current train perplexity3.5409793853759766
INFO:root:current mean train loss 3206.443921099258
INFO:root:current train perplexity3.541652202606201
INFO:root:current mean train loss 3207.1611102211486
INFO:root:current train perplexity3.541933536529541


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.41s/it]
INFO:root:final mean train loss: 3204.7944715561407
INFO:root:final train perplexity: 3.540911912918091
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.77s/it]
INFO:root:eval mean loss: 4086.426073872451
INFO:root:eval perplexity: 5.219651699066162
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/195

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [10:02:11<13:30, 162.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3217.6599617650954
INFO:root:current train perplexity3.5564682483673096
INFO:root:current mean train loss 3213.5147206048546
INFO:root:current train perplexity3.5437381267547607
INFO:root:current mean train loss 3215.337808616373
INFO:root:current train perplexity3.5420119762420654
INFO:root:current mean train loss 3211.54132505114
INFO:root:current train perplexity3.538926839828491
INFO:root:current mean train loss 3208.737339260791
INFO:root:current train perplexity3.538641929626465
INFO:root:current mean train loss 3203.780279551934
INFO:root:current train perplexity3.537294387817383
INFO:root:current mean train loss 3202.6577859742506
INFO:root:current train perplexity3.537586212158203
INFO:root:current mean train loss 3203.4783152302575
INFO:root:current train perplexity3.5381393432617188
INFO:root:current mean train loss 3205.459354422839
INFO:root:current train perplexity3.538076877593994
INFO:root:current mean train loss 3205.2207708428377
INFO:root:current train perplexity3.538097381591797


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.52s/it]
INFO:root:final mean train loss: 3202.9234804338025
INFO:root:final train perplexity: 3.5382986068725586
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.13s/it]
INFO:root:eval mean loss: 4086.446905474291
INFO:root:eval perplexity: 5.219696998596191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/196

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [10:04:48<10:42, 160.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3216.350833722015
INFO:root:current train perplexity3.5452828407287598
INFO:root:current mean train loss 3207.2493348264406
INFO:root:current train perplexity3.543565034866333
INFO:root:current mean train loss 3211.383428795061
INFO:root:current train perplexity3.5430643558502197
INFO:root:current mean train loss 3211.173007892328
INFO:root:current train perplexity3.54164981842041
INFO:root:current mean train loss 3211.8497839852116
INFO:root:current train perplexity3.5425238609313965
INFO:root:current mean train loss 3210.9665897645227
INFO:root:current train perplexity3.5425753593444824
INFO:root:current mean train loss 3207.48393430238
INFO:root:current train perplexity3.540034770965576
INFO:root:current mean train loss 3207.681747575782
INFO:root:current train perplexity3.5411713123321533
INFO:root:current mean train loss 3206.2802357041164
INFO:root:current train perplexity3.5399816036224365
INFO:root:current mean train loss 3205.2541337274592
INFO:root:current train perplexity3.5389087200164795


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.23s/it]
INFO:root:final mean train loss: 3202.630855129611
INFO:root:final train perplexity: 3.5378894805908203
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.74s/it]
INFO:root:eval mean loss: 4086.8972825936394
INFO:root:eval perplexity: 5.22064733505249
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/197

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [10:07:28<08:01, 160.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3199.3500227864583
INFO:root:current train perplexity3.5296850204467773
INFO:root:current mean train loss 3203.809115513393
INFO:root:current train perplexity3.5329437255859375
INFO:root:current mean train loss 3202.7655992542614
INFO:root:current train perplexity3.5362884998321533
INFO:root:current mean train loss 3199.7516575520835
INFO:root:current train perplexity3.534937620162964
INFO:root:current mean train loss 3202.441440172697
INFO:root:current train perplexity3.5329320430755615
INFO:root:current mean train loss 3203.358336871603
INFO:root:current train perplexity3.5321903228759766
INFO:root:current mean train loss 3205.1646375868054
INFO:root:current train perplexity3.53498911857605
INFO:root:current mean train loss 3203.0026398689515
INFO:root:current train perplexity3.534191131591797
INFO:root:current mean train loss 3204.8547907366074
INFO:root:current train perplexity3.5349082946777344
INFO:root:current mean train loss 3204.3390752704327
INFO:root:current train perplexity3.5370595455169678


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.85s/it]
INFO:root:final mean train loss: 3202.0774082676057
INFO:root:final train perplexity: 3.5371177196502686
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 13.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.00s/it]
INFO:root:eval mean loss: 4087.2255062887853
INFO:root:eval perplexity: 5.221340656280518
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/198

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [10:10:10<05:21, 160.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3200.629109210279
INFO:root:current train perplexity3.5439412593841553
INFO:root:current mean train loss 3211.691922547387
INFO:root:current train perplexity3.543240547180176
INFO:root:current mean train loss 3213.7497618981893
INFO:root:current train perplexity3.549086093902588
INFO:root:current mean train loss 3208.724043325718
INFO:root:current train perplexity3.5440571308135986
INFO:root:current mean train loss 3201.906562884155
INFO:root:current train perplexity3.542184829711914
INFO:root:current mean train loss 3206.0782673804674
INFO:root:current train perplexity3.545748710632324
INFO:root:current mean train loss 3206.7946709427615
INFO:root:current train perplexity3.542017936706543
INFO:root:current mean train loss 3206.1911331118295
INFO:root:current train perplexity3.5391790866851807
INFO:root:current mean train loss 3205.97070257202
INFO:root:current train perplexity3.5370030403137207
INFO:root:current mean train loss 3205.741728028834
INFO:root:current train perplexity3.538137435913086


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.41s/it]
INFO:root:final mean train loss: 3202.5691861798687
INFO:root:final train perplexity: 3.537803888320923
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.55s/it]
INFO:root:eval mean loss: 4087.2324599678636
INFO:root:eval perplexity: 5.221353530883789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [10:12:51<02:40, 160.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3199.522160456731
INFO:root:current train perplexity3.5428054332733154
INFO:root:current mean train loss 3199.894993966787
INFO:root:current train perplexity3.5309770107269287
INFO:root:current mean train loss 3197.5680405659364
INFO:root:current train perplexity3.5335655212402344
INFO:root:current mean train loss 3201.189027908208
INFO:root:current train perplexity3.534168243408203
INFO:root:current mean train loss 3203.9455790160387
INFO:root:current train perplexity3.537057638168335
INFO:root:current mean train loss 3203.411175361543
INFO:root:current train perplexity3.539161443710327
INFO:root:current mean train loss 3202.4526462582535
INFO:root:current train perplexity3.537593126296997
INFO:root:current mean train loss 3203.9406469757428
INFO:root:current train perplexity3.537147283554077
INFO:root:current mean train loss 3205.254398915369
INFO:root:current train perplexity3.5383715629577637
INFO:root:current mean train loss 3205.1439257024153
INFO:root:current train perplexity3.537851572036743


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.44s/it]
INFO:root:final mean train loss: 3202.5816405511673
INFO:root:final train perplexity: 3.5378215312957764
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:12<00:00, 12.16s/it]
INFO:root:eval mean loss: 4087.196406804078
INFO:root:eval perplexity: 5.221279144287109
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1320/200

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [10:15:38<00:00, 162.62s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [10:15:38<00:00, 184.69s/it]
INFO:root:evaluating final model
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.21s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.21s/it]
INFO:root:eval mean loss: 4087.196406804078
INFO:root:eval perplexity: 5.221279144287109
INFO:root:evalaution complete
INFO:root:save model final: small_val_1320/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x154cb1977f06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x154cb196f8e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x154cb1894e09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x154cb1978a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x154cb1892948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x154cb1978a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x154cb184db46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x154cb12b246a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x154dadacea27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x154dadacebe0]
python(+0x24a989) [0x5641fe1c6989]
python(+0x24a9bd) [0x5641fe1c69bd]
python(+0x24aa14) [0x5641fe1c6a14]
python(+0x108f75) [0x5641fe084f75]
python(Py_RunMain+0x313) [0x5641fe1c9983]
python(Py_BytesMain+0x39) [0x5641fe1c9bc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x154dadaac0b3]
python(+0x1d6e13) [0x5641fe152e13]
/opt/slurm/data/slurmd/job26146345/slurm_script: line 137: 580834 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path sentence-transformers/multi-qa-MiniLM-L6-cos-v1 --data_config data_config.json --data_folder fast_processed_data_1320_final  --output small_val_1320 --batch_size 128 --epochs 200 --save_head  --save_epochs 1 --external_embedding
"
