INFO:root:Output: allminil6_minilml6_not_concat
INFO:root:Steps per epochs:1983
INFO:root:Total steps:396600
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at nreimers/MiniLM-L6-H384-uncased and are newly initialized: ['encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.value.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.key.bias', 'cls.predictions.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.query.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.4.crossattention.self.value.bias', 'cls.predictions.decoder.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.value.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11895.674863873106
INFO:root:current train perplexity12721.9990234375
INFO:root:current mean train loss 10130.078689345164
INFO:root:current train perplexity2965.8369140625
INFO:root:current mean train loss 8844.563659463838
INFO:root:current train perplexity1067.8138427734375
INFO:root:current mean train loss 7964.816353628211
INFO:root:current train perplexity533.0267333984375
INFO:root:current mean train loss 7323.6211960052915
INFO:root:current train perplexity322.0989990234375
INFO:root:current mean train loss 6835.472582885538
INFO:root:current train perplexity219.13783264160156
INFO:root:current mean train loss 6454.237143324169
INFO:root:current train perplexity161.732421875
INFO:root:current mean train loss 6149.277957004361
INFO:root:current train perplexity126.75626373291016
INFO:root:current mean train loss 5889.018006389478
INFO:root:current train perplexity103.74429321289062
INFO:root:current mean train loss 5678.458000236565
INFO:root:current train perplexity87.42362976074219
INFO:root:current mean train loss 5489.743655453822
INFO:root:current train perplexity75.50743865966797
INFO:root:current mean train loss 5329.113072742911
INFO:root:current train perplexity66.56292724609375
INFO:root:current mean train loss 5190.287861719051
INFO:root:current train perplexity59.499420166015625
INFO:root:current mean train loss 5061.173326580928
INFO:root:current train perplexity53.875946044921875
INFO:root:current mean train loss 4947.943184779437
INFO:root:current train perplexity49.34327697753906
INFO:root:current mean train loss 4846.050723077656
INFO:root:current train perplexity45.55854034423828
INFO:root:current mean train loss 4754.579638700614
INFO:root:current train perplexity42.35844802856445
INFO:root:current mean train loss 4669.670670717673
INFO:root:current train perplexity39.660152435302734
INFO:root:current mean train loss 4590.300757208769
INFO:root:current train perplexity37.3109130859375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.64s/it]
INFO:root:final mean train loss: 4528.531730340216
INFO:root:final train perplexity: 35.56894302368164
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it]
INFO:root:eval mean loss: 2942.017588513963
INFO:root:eval perplexity: 10.797677993774414
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.32s/it]
INFO:root:eval mean loss: 3224.6074599678636
INFO:root:eval perplexity: 13.973640441894531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/1
  0%|          | 1/200 [06:42<22:16:27, 402.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3129.2928009033203
INFO:root:current train perplexity11.884281158447266
INFO:root:current mean train loss 3145.411231731546
INFO:root:current train perplexity11.628622055053711
INFO:root:current mean train loss 3127.217532687717
INFO:root:current train perplexity11.529583930969238
INFO:root:current mean train loss 3098.915256162233
INFO:root:current train perplexity11.44373893737793
INFO:root:current mean train loss 3087.4977334829478
INFO:root:current train perplexity11.327122688293457
INFO:root:current mean train loss 3066.2357887445496
INFO:root:current train perplexity11.191133499145508
INFO:root:current mean train loss 3051.5347020533177
INFO:root:current train perplexity11.075902938842773
INFO:root:current mean train loss 3038.218638159043
INFO:root:current train perplexity10.979869842529297
INFO:root:current mean train loss 3024.2811892640357
INFO:root:current train perplexity10.875320434570312
INFO:root:current mean train loss 3013.8868170992255
INFO:root:current train perplexity10.765938758850098
INFO:root:current mean train loss 3003.5092802273007
INFO:root:current train perplexity10.66766357421875
INFO:root:current mean train loss 2992.4864484452005
INFO:root:current train perplexity10.567684173583984
INFO:root:current mean train loss 2980.9914765608937
INFO:root:current train perplexity10.47813892364502
INFO:root:current mean train loss 2972.4740791668646
INFO:root:current train perplexity10.400629043579102
INFO:root:current mean train loss 2963.569992324053
INFO:root:current train perplexity10.328827857971191
INFO:root:current mean train loss 2954.748340455712
INFO:root:current train perplexity10.256791114807129
INFO:root:current mean train loss 2943.6528882319385
INFO:root:current train perplexity10.1817626953125
INFO:root:current mean train loss 2934.839012021507
INFO:root:current train perplexity10.111520767211914
INFO:root:current mean train loss 2924.8754151466132
INFO:root:current train perplexity10.042430877685547
INFO:root:current mean train loss 2918.3203949420586
INFO:root:current train perplexity9.984031677246094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.05s/it]
INFO:root:final mean train loss: 2912.4037145325105
INFO:root:final train perplexity: 9.943280220031738
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.91s/it]
INFO:root:eval mean loss: 2579.396072279477
INFO:root:eval perplexity: 8.053155899047852
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 2907.33834124626
INFO:root:eval perplexity: 10.780094146728516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/2
  1%|          | 2/200 [13:39<22:36:36, 411.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2757.6916060014205
INFO:root:current train perplexity8.831487655639648
INFO:root:current mean train loss 2716.340737708529
INFO:root:current train perplexity8.601927757263184
INFO:root:current mean train loss 2700.357995029171
INFO:root:current train perplexity8.5408296585083
INFO:root:current mean train loss 2703.7721816054336
INFO:root:current train perplexity8.530289649963379
INFO:root:current mean train loss 2704.5355526261187
INFO:root:current train perplexity8.494956970214844
INFO:root:current mean train loss 2699.9522143966933
INFO:root:current train perplexity8.458724021911621
INFO:root:current mean train loss 2698.135310602414
INFO:root:current train perplexity8.435056686401367
INFO:root:current mean train loss 2697.4224225677863
INFO:root:current train perplexity8.409692764282227
INFO:root:current mean train loss 2692.5154948698228
INFO:root:current train perplexity8.37674331665039
INFO:root:current mean train loss 2690.414183654458
INFO:root:current train perplexity8.349418640136719
INFO:root:current mean train loss 2688.677548138008
INFO:root:current train perplexity8.32697582244873
INFO:root:current mean train loss 2682.9422059021267
INFO:root:current train perplexity8.29071044921875
INFO:root:current mean train loss 2676.651532125976
INFO:root:current train perplexity8.252957344055176
INFO:root:current mean train loss 2672.439870709865
INFO:root:current train perplexity8.222234725952148
INFO:root:current mean train loss 2665.319130811671
INFO:root:current train perplexity8.189285278320312
INFO:root:current mean train loss 2662.8969525898974
INFO:root:current train perplexity8.169830322265625
INFO:root:current mean train loss 2659.9341232944544
INFO:root:current train perplexity8.1448974609375
INFO:root:current mean train loss 2656.4572963109267
INFO:root:current train perplexity8.117413520812988
INFO:root:current mean train loss 2651.22154909291
INFO:root:current train perplexity8.083819389343262
INFO:root:current mean train loss 2647.2677068261364
INFO:root:current train perplexity8.060803413391113

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.79s/it]
INFO:root:final mean train loss: 2643.4943175438493
INFO:root:final train perplexity: 8.043132781982422
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.52s/it]
INFO:root:eval mean loss: 2411.6737194737643
INFO:root:eval perplexity: 7.031641006469727
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it]
INFO:root:eval mean loss: 2765.0255949412676
INFO:root:eval perplexity: 9.595688819885254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/3
  2%|â–         | 3/200 [20:31<22:31:24, 411.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2587.469775390625
INFO:root:current train perplexity7.505250453948975
INFO:root:current mean train loss 2549.300625
INFO:root:current train perplexity7.425370693206787
INFO:root:current mean train loss 2544.593703125
INFO:root:current train perplexity7.428159236907959
INFO:root:current mean train loss 2542.4681176757813
INFO:root:current train perplexity7.415853977203369
INFO:root:current mean train loss 2540.744462619358
INFO:root:current train perplexity7.415870189666748
INFO:root:current mean train loss 2533.1976706764913
INFO:root:current train perplexity7.37551212310791
INFO:root:current mean train loss 2531.556741098257
INFO:root:current train perplexity7.356739044189453
INFO:root:current mean train loss 2528.421680175781
INFO:root:current train perplexity7.3336310386657715
INFO:root:current mean train loss 2527.3209056181067
INFO:root:current train perplexity7.315101146697998
INFO:root:current mean train loss 2522.717556023849
INFO:root:current train perplexity7.287266254425049
INFO:root:current mean train loss 2518.5553138950895
INFO:root:current train perplexity7.27220344543457
INFO:root:current mean train loss 2517.2515137780233
INFO:root:current train perplexity7.2598395347595215
INFO:root:current mean train loss 2513.289219042969
INFO:root:current train perplexity7.237878799438477
INFO:root:current mean train loss 2509.865719310619
INFO:root:current train perplexity7.222052574157715
INFO:root:current mean train loss 2507.504431657462
INFO:root:current train perplexity7.21052360534668
INFO:root:current mean train loss 2504.238321021295
INFO:root:current train perplexity7.200798988342285
INFO:root:current mean train loss 2499.5952422170926
INFO:root:current train perplexity7.182745456695557
INFO:root:current mean train loss 2496.4598982282364
INFO:root:current train perplexity7.161786079406738
INFO:root:current mean train loss 2493.6978803315033
INFO:root:current train perplexity7.144853115081787
INFO:root:current mean train loss 2490.6781216821914
INFO:root:current train perplexity7.125844955444336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.64s/it]
INFO:root:final mean train loss: 2489.1401037850046
INFO:root:final train perplexity: 7.121266841888428
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.62s/it]
INFO:root:eval mean loss: 2307.946460913259
INFO:root:eval perplexity: 6.4658308029174805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.53s/it]
INFO:root:eval mean loss: 2677.182471309148
INFO:root:eval perplexity: 8.930508613586426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/4
  2%|â–         | 4/200 [27:12<22:10:51, 407.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2399.969755713619
INFO:root:current train perplexity6.7053937911987305
INFO:root:current mean train loss 2424.7784752760103
INFO:root:current train perplexity6.747218608856201
INFO:root:current mean train loss 2407.7800430126404
INFO:root:current train perplexity6.701417446136475
INFO:root:current mean train loss 2406.875051222965
INFO:root:current train perplexity6.706477165222168
INFO:root:current mean train loss 2407.5111457775697
INFO:root:current train perplexity6.7000908851623535
INFO:root:current mean train loss 2408.2706443073466
INFO:root:current train perplexity6.69566011428833
INFO:root:current mean train loss 2407.6700626127367
INFO:root:current train perplexity6.683640003204346
INFO:root:current mean train loss 2408.268843231798
INFO:root:current train perplexity6.681769371032715
INFO:root:current mean train loss 2408.231536548443
INFO:root:current train perplexity6.6728129386901855
INFO:root:current mean train loss 2402.4147470783914
INFO:root:current train perplexity6.6486921310424805
INFO:root:current mean train loss 2400.028600948373
INFO:root:current train perplexity6.641629695892334
INFO:root:current mean train loss 2398.9606779829087
INFO:root:current train perplexity6.635625839233398
INFO:root:current mean train loss 2396.9809853569577
INFO:root:current train perplexity6.62591552734375
INFO:root:current mean train loss 2398.2442301015567
INFO:root:current train perplexity6.623388767242432
INFO:root:current mean train loss 2396.8174471344846
INFO:root:current train perplexity6.616342544555664
INFO:root:current mean train loss 2393.3004965231385
INFO:root:current train perplexity6.601531028747559
INFO:root:current mean train loss 2391.3123010407685
INFO:root:current train perplexity6.591950416564941
INFO:root:current mean train loss 2389.122754997767
INFO:root:current train perplexity6.5803399085998535
INFO:root:current mean train loss 2388.3152694334367
INFO:root:current train perplexity6.577535152435303
INFO:root:current mean train loss 2388.152041211732
INFO:root:current train perplexity6.573789119720459

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.88s/it]
INFO:root:final mean train loss: 2388.075586116019
INFO:root:final train perplexity: 6.575693607330322
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.69s/it]
INFO:root:eval mean loss: 2231.7527292670934
INFO:root:eval perplexity: 6.079427719116211
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.63s/it]
INFO:root:eval mean loss: 2609.0373405294217
INFO:root:eval perplexity: 8.446420669555664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/5
  2%|â–Ž         | 5/200 [34:01<22:05:06, 407.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2376.9098074776784
INFO:root:current train perplexity6.450488567352295
INFO:root:current mean train loss 2355.8125590448794
INFO:root:current train perplexity6.370627403259277
INFO:root:current mean train loss 2348.1832408636387
INFO:root:current train perplexity6.360794544219971
INFO:root:current mean train loss 2352.597573598226
INFO:root:current train perplexity6.369447708129883
INFO:root:current mean train loss 2350.901215608455
INFO:root:current train perplexity6.358798503875732
INFO:root:current mean train loss 2348.0637798570606
INFO:root:current train perplexity6.360019683837891
INFO:root:current mean train loss 2346.3006588227568
INFO:root:current train perplexity6.354576110839844
INFO:root:current mean train loss 2346.039302592375
INFO:root:current train perplexity6.358617305755615
INFO:root:current mean train loss 2346.3281586936155
INFO:root:current train perplexity6.362783908843994
INFO:root:current mean train loss 2347.4830517032283
INFO:root:current train perplexity6.361046314239502
INFO:root:current mean train loss 2346.4692639565556
INFO:root:current train perplexity6.356357574462891
INFO:root:current mean train loss 2345.6920975350045
INFO:root:current train perplexity6.357954978942871
INFO:root:current mean train loss 2343.943857068213
INFO:root:current train perplexity6.350249767303467
INFO:root:current mean train loss 2342.3059610355795
INFO:root:current train perplexity6.342118263244629
INFO:root:current mean train loss 2341.102107045464
INFO:root:current train perplexity6.338811874389648
INFO:root:current mean train loss 2339.3518075654
INFO:root:current train perplexity6.330874919891357
INFO:root:current mean train loss 2339.3042287214917
INFO:root:current train perplexity6.32990837097168
INFO:root:current mean train loss 2339.0038732006947
INFO:root:current train perplexity6.326211929321289
INFO:root:current mean train loss 2336.0822197980942
INFO:root:current train perplexity6.3136515617370605

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.17s/it]
INFO:root:final mean train loss: 2336.8757416556355
INFO:root:final train perplexity: 6.315461158752441
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.67s/it]
INFO:root:eval mean loss: 2186.325855444509
INFO:root:eval perplexity: 5.860130786895752
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.18s/it]
INFO:root:eval mean loss: 2573.1192994895555
INFO:root:eval perplexity: 8.20191764831543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/6
  3%|â–Ž         | 6/200 [40:35<21:43:21, 403.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2367.749755859375
INFO:root:current train perplexity6.6472272872924805
INFO:root:current mean train loss 2314.5230724976795
INFO:root:current train perplexity6.14940881729126
INFO:root:current mean train loss 2300.4203172370567
INFO:root:current train perplexity6.113957405090332
INFO:root:current mean train loss 2288.1327281457643
INFO:root:current train perplexity6.089240074157715
INFO:root:current mean train loss 2295.280194898496
INFO:root:current train perplexity6.120323657989502
INFO:root:current mean train loss 2290.6141067474427
INFO:root:current train perplexity6.099111080169678
INFO:root:current mean train loss 2293.797871061252
INFO:root:current train perplexity6.100724697113037
INFO:root:current mean train loss 2295.8259209430166
INFO:root:current train perplexity6.098826885223389
INFO:root:current mean train loss 2295.6333388805983
INFO:root:current train perplexity6.097855567932129
INFO:root:current mean train loss 2297.0273686788983
INFO:root:current train perplexity6.103988170623779
INFO:root:current mean train loss 2293.5253516015237
INFO:root:current train perplexity6.092082977294922
INFO:root:current mean train loss 2291.3882751742026
INFO:root:current train perplexity6.084578037261963
INFO:root:current mean train loss 2290.1097111253316
INFO:root:current train perplexity6.077864646911621
INFO:root:current mean train loss 2286.7975445570714
INFO:root:current train perplexity6.0753278732299805
INFO:root:current mean train loss 2286.7288438468895
INFO:root:current train perplexity6.070755958557129
INFO:root:current mean train loss 2286.5643658622116
INFO:root:current train perplexity6.065446376800537
INFO:root:current mean train loss 2285.5119076120636
INFO:root:current train perplexity6.063704967498779
INFO:root:current mean train loss 2284.5459801047637
INFO:root:current train perplexity6.056252956390381
INFO:root:current mean train loss 2281.7738273658733
INFO:root:current train perplexity6.0457987785339355
INFO:root:current mean train loss 2280.983297943003
INFO:root:current train perplexity6.041242599487305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.79s/it]
INFO:root:final mean train loss: 2280.8097936156055
INFO:root:final train perplexity: 6.042294979095459
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.47s/it]
INFO:root:eval mean loss: 2141.3668039741247
INFO:root:eval perplexity: 5.650882720947266
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.92s/it]
INFO:root:eval mean loss: 2537.260209320285
INFO:root:eval perplexity: 7.964873313903809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/7
  4%|â–Ž         | 7/200 [47:09<21:27:29, 400.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2266.657958984375
INFO:root:current train perplexity5.904762268066406
INFO:root:current mean train loss 2236.900622351695
INFO:root:current train perplexity5.827828884124756
INFO:root:current mean train loss 2237.4107727610735
INFO:root:current train perplexity5.857390880584717
INFO:root:current mean train loss 2235.5162276741844
INFO:root:current train perplexity5.851853370666504
INFO:root:current mean train loss 2236.8800124757026
INFO:root:current train perplexity5.85761833190918
INFO:root:current mean train loss 2234.5041850322
INFO:root:current train perplexity5.847525119781494
INFO:root:current mean train loss 2233.551503598111
INFO:root:current train perplexity5.8484015464782715
INFO:root:current mean train loss 2235.0843650371585
INFO:root:current train perplexity5.850406646728516
INFO:root:current mean train loss 2236.419067233582
INFO:root:current train perplexity5.854215145111084
INFO:root:current mean train loss 2234.179747870285
INFO:root:current train perplexity5.839395999908447
INFO:root:current mean train loss 2234.611085063582
INFO:root:current train perplexity5.836401462554932
INFO:root:current mean train loss 2232.8258782729695
INFO:root:current train perplexity5.8328962326049805
INFO:root:current mean train loss 2233.96330885112
INFO:root:current train perplexity5.830410480499268
INFO:root:current mean train loss 2232.170608821516
INFO:root:current train perplexity5.829185962677002
INFO:root:current mean train loss 2232.413192081855
INFO:root:current train perplexity5.822772979736328
INFO:root:current mean train loss 2231.4168633623085
INFO:root:current train perplexity5.819681167602539
INFO:root:current mean train loss 2233.0754017305317
INFO:root:current train perplexity5.821042060852051
INFO:root:current mean train loss 2232.8915663198486
INFO:root:current train perplexity5.819828510284424
INFO:root:current mean train loss 2231.7610317855515
INFO:root:current train perplexity5.814154624938965
INFO:root:current mean train loss 2231.087656094707
INFO:root:current train perplexity5.80981969833374

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.48s/it]
INFO:root:final mean train loss: 2231.176198585191
INFO:root:final train perplexity: 5.810343265533447
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.81s/it]
INFO:root:eval mean loss: 2110.5359531700187
INFO:root:eval perplexity: 5.51172399520874
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.12s/it]
INFO:root:eval mean loss: 2508.9231956968915
INFO:root:eval perplexity: 7.782413482666016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/8
  4%|â–         | 8/200 [53:55<21:26:15, 401.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2182.8287632533484
INFO:root:current train perplexity5.599063873291016
INFO:root:current mean train loss 2189.902650282118
INFO:root:current train perplexity5.607255458831787
INFO:root:current mean train loss 2196.8663704080786
INFO:root:current train perplexity5.631783962249756
INFO:root:current mean train loss 2202.8354415665813
INFO:root:current train perplexity5.648618221282959
INFO:root:current mean train loss 2202.7913012975932
INFO:root:current train perplexity5.655690670013428
INFO:root:current mean train loss 2202.280299905082
INFO:root:current train perplexity5.648402214050293
INFO:root:current mean train loss 2203.86545775406
INFO:root:current train perplexity5.6631178855896
INFO:root:current mean train loss 2202.3414881284543
INFO:root:current train perplexity5.65540885925293
INFO:root:current mean train loss 2202.827051366018
INFO:root:current train perplexity5.657524108886719
INFO:root:current mean train loss 2200.7991186131767
INFO:root:current train perplexity5.647933483123779
INFO:root:current mean train loss 2196.6873611818764
INFO:root:current train perplexity5.636545181274414
INFO:root:current mean train loss 2196.2364398704226
INFO:root:current train perplexity5.640880107879639
INFO:root:current mean train loss 2195.2672640039855
INFO:root:current train perplexity5.641162395477295
INFO:root:current mean train loss 2195.675798623303
INFO:root:current train perplexity5.644699573516846
INFO:root:current mean train loss 2194.03305842702
INFO:root:current train perplexity5.638349533081055
INFO:root:current mean train loss 2194.1145098260636
INFO:root:current train perplexity5.639296531677246
INFO:root:current mean train loss 2193.779292470016
INFO:root:current train perplexity5.636908531188965
INFO:root:current mean train loss 2192.351470683425
INFO:root:current train perplexity5.6342878341674805
INFO:root:current mean train loss 2191.1830062824633
INFO:root:current train perplexity5.630617141723633
INFO:root:current mean train loss 2191.4597189417796
INFO:root:current train perplexity5.629321575164795

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.29s/it]
INFO:root:final mean train loss: 2190.853841699859
INFO:root:final train perplexity: 5.628478050231934
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.14s/it]
INFO:root:eval mean loss: 2085.503308884641
INFO:root:eval perplexity: 5.401261806488037
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.31s/it]
INFO:root:eval mean loss: 2489.444190924895
INFO:root:eval perplexity: 7.659417152404785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/9
  4%|â–         | 9/200 [1:00:30<21:12:30, 399.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2144.7408001239482
INFO:root:current train perplexity5.481595039367676
INFO:root:current mean train loss 2165.399080778423
INFO:root:current train perplexity5.507630348205566
INFO:root:current mean train loss 2163.352981809586
INFO:root:current train perplexity5.510226249694824
INFO:root:current mean train loss 2160.853449041193
INFO:root:current train perplexity5.502177715301514
INFO:root:current mean train loss 2157.547315749447
INFO:root:current train perplexity5.505102157592773
INFO:root:current mean train loss 2159.928082452304
INFO:root:current train perplexity5.51116418838501
INFO:root:current mean train loss 2157.554788601179
INFO:root:current train perplexity5.5056071281433105
INFO:root:current mean train loss 2156.1971080049557
INFO:root:current train perplexity5.497276782989502
INFO:root:current mean train loss 2158.125264772227
INFO:root:current train perplexity5.495467185974121
INFO:root:current mean train loss 2159.769956444492
INFO:root:current train perplexity5.495754718780518
INFO:root:current mean train loss 2158.7504699474957
INFO:root:current train perplexity5.493517875671387
INFO:root:current mean train loss 2154.855587747362
INFO:root:current train perplexity5.487240314483643
INFO:root:current mean train loss 2155.298129340711
INFO:root:current train perplexity5.4870285987854
INFO:root:current mean train loss 2154.508549797464
INFO:root:current train perplexity5.486059665679932
INFO:root:current mean train loss 2154.818624869523
INFO:root:current train perplexity5.482027530670166
INFO:root:current mean train loss 2154.746368093589
INFO:root:current train perplexity5.4749298095703125
INFO:root:current mean train loss 2155.3306529342985
INFO:root:current train perplexity5.476753234863281
INFO:root:current mean train loss 2155.097400264653
INFO:root:current train perplexity5.47767448425293
INFO:root:current mean train loss 2155.723062733595
INFO:root:current train perplexity5.478694915771484
INFO:root:current mean train loss 2156.8747064559184
INFO:root:current train perplexity5.478567123413086

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.45s/it]
INFO:root:final mean train loss: 2156.9789310826595
INFO:root:final train perplexity: 5.480099201202393
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.96s/it]
INFO:root:eval mean loss: 2069.95233543883
INFO:root:eval perplexity: 5.333757400512695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.13s/it]
INFO:root:eval mean loss: 2476.3409289637357
INFO:root:eval perplexity: 7.577775478363037
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/10
  5%|â–Œ         | 10/200 [1:07:00<20:56:57, 396.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2142.91967242697
INFO:root:current train perplexity5.355210304260254
INFO:root:current mean train loss 2131.018606693787
INFO:root:current train perplexity5.337515354156494
INFO:root:current mean train loss 2128.5415951186396
INFO:root:current train perplexity5.327765464782715
INFO:root:current mean train loss 2130.8266369992803
INFO:root:current train perplexity5.351876735687256
INFO:root:current mean train loss 2130.6807426664113
INFO:root:current train perplexity5.355832099914551
INFO:root:current mean train loss 2128.7523658899936
INFO:root:current train perplexity5.358979225158691
INFO:root:current mean train loss 2129.500221149804
INFO:root:current train perplexity5.3548150062561035
INFO:root:current mean train loss 2129.5347173365876
INFO:root:current train perplexity5.352038383483887
INFO:root:current mean train loss 2131.356014484366
INFO:root:current train perplexity5.35886287689209
INFO:root:current mean train loss 2130.301790062242
INFO:root:current train perplexity5.356772422790527
INFO:root:current mean train loss 2129.813917454433
INFO:root:current train perplexity5.357679843902588
INFO:root:current mean train loss 2130.6790573080957
INFO:root:current train perplexity5.3573713302612305
INFO:root:current mean train loss 2130.191077458567
INFO:root:current train perplexity5.3579277992248535
INFO:root:current mean train loss 2130.7074689732754
INFO:root:current train perplexity5.361514568328857
INFO:root:current mean train loss 2131.212738639567
INFO:root:current train perplexity5.361917972564697
INFO:root:current mean train loss 2130.179026733165
INFO:root:current train perplexity5.361241817474365
INFO:root:current mean train loss 2130.0988982368044
INFO:root:current train perplexity5.359620571136475
INFO:root:current mean train loss 2129.8414223834307
INFO:root:current train perplexity5.361396789550781
INFO:root:current mean train loss 2129.307909725183
INFO:root:current train perplexity5.359426498413086
INFO:root:current mean train loss 2129.4579755745303
INFO:root:current train perplexity5.359097957611084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.13s/it]
INFO:root:final mean train loss: 2128.981225610561
INFO:root:final train perplexity: 5.360422611236572
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it]
INFO:root:eval mean loss: 2042.4781290690105
INFO:root:eval perplexity: 5.216550827026367
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.48s/it]
INFO:root:eval mean loss: 2451.928334770473
INFO:root:eval perplexity: 7.427982330322266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/11
  6%|â–Œ         | 11/200 [1:13:35<20:48:16, 396.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2107.475550451944
INFO:root:current train perplexity5.297797679901123
INFO:root:current mean train loss 2107.548406785534
INFO:root:current train perplexity5.297282695770264
INFO:root:current mean train loss 2109.1574139361614
INFO:root:current train perplexity5.280594348907471
INFO:root:current mean train loss 2106.6708108378198
INFO:root:current train perplexity5.28137731552124
INFO:root:current mean train loss 2109.348193510079
INFO:root:current train perplexity5.289372444152832
INFO:root:current mean train loss 2105.199077306754
INFO:root:current train perplexity5.272169589996338
INFO:root:current mean train loss 2102.828746384156
INFO:root:current train perplexity5.263637065887451
INFO:root:current mean train loss 2101.9047332841324
INFO:root:current train perplexity5.2627716064453125
INFO:root:current mean train loss 2104.846009402996
INFO:root:current train perplexity5.264186859130859
INFO:root:current mean train loss 2102.9332448715613
INFO:root:current train perplexity5.260384559631348
INFO:root:current mean train loss 2104.920193217297
INFO:root:current train perplexity5.2592692375183105
INFO:root:current mean train loss 2105.4204235366383
INFO:root:current train perplexity5.260554313659668
INFO:root:current mean train loss 2104.8196285835133
INFO:root:current train perplexity5.260591506958008
INFO:root:current mean train loss 2105.8004970357874
INFO:root:current train perplexity5.2642598152160645
INFO:root:current mean train loss 2106.6749021137384
INFO:root:current train perplexity5.265186786651611
INFO:root:current mean train loss 2106.651302765778
INFO:root:current train perplexity5.26702356338501
INFO:root:current mean train loss 2105.6768564244608
INFO:root:current train perplexity5.263712406158447
INFO:root:current mean train loss 2105.2716454722713
INFO:root:current train perplexity5.259890079498291
INFO:root:current mean train loss 2104.828766742921
INFO:root:current train perplexity5.258737087249756

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.97s/it]
INFO:root:final mean train loss: 2103.8784606902814
INFO:root:final train perplexity: 5.255342483520508
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2030.0139445852726
INFO:root:eval perplexity: 5.1642303466796875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.31s/it]
INFO:root:eval mean loss: 2444.1044259578625
INFO:root:eval perplexity: 7.380607604980469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/12
  6%|â–Œ         | 12/200 [1:20:10<20:40:05, 395.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2092.1280110677085
INFO:root:current train perplexity5.181972980499268
INFO:root:current mean train loss 2088.7942119709496
INFO:root:current train perplexity5.2377119064331055
INFO:root:current mean train loss 2076.3265014047106
INFO:root:current train perplexity5.171302318572998
INFO:root:current mean train loss 2080.537411529239
INFO:root:current train perplexity5.191476345062256
INFO:root:current mean train loss 2075.783705945642
INFO:root:current train perplexity5.163702011108398
INFO:root:current mean train loss 2077.172300183275
INFO:root:current train perplexity5.163118362426758
INFO:root:current mean train loss 2078.4785099567266
INFO:root:current train perplexity5.162495136260986
INFO:root:current mean train loss 2075.7751628067213
INFO:root:current train perplexity5.155148506164551
INFO:root:current mean train loss 2081.7303533684717
INFO:root:current train perplexity5.166629791259766
INFO:root:current mean train loss 2078.5419317606675
INFO:root:current train perplexity5.156022071838379
INFO:root:current mean train loss 2078.6193060223627
INFO:root:current train perplexity5.156906604766846
INFO:root:current mean train loss 2079.6448178883584
INFO:root:current train perplexity5.154110908508301
INFO:root:current mean train loss 2081.4364636707387
INFO:root:current train perplexity5.1600518226623535
INFO:root:current mean train loss 2078.3001669637074
INFO:root:current train perplexity5.155686378479004
INFO:root:current mean train loss 2079.1889864213963
INFO:root:current train perplexity5.158746242523193
INFO:root:current mean train loss 2079.5569117299256
INFO:root:current train perplexity5.159738063812256
INFO:root:current mean train loss 2079.1868647470073
INFO:root:current train perplexity5.157714366912842
INFO:root:current mean train loss 2080.0817949224484
INFO:root:current train perplexity5.159512519836426
INFO:root:current mean train loss 2080.332572408074
INFO:root:current train perplexity5.161159992218018
INFO:root:current mean train loss 2080.851122841607
INFO:root:current train perplexity5.162452220916748

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.94s/it]
INFO:root:final mean train loss: 2081.887907165743
INFO:root:final train perplexity: 5.164984226226807
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.69s/it]
INFO:root:eval mean loss: 2025.9298173620346
INFO:root:eval perplexity: 5.147200584411621
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.24s/it]
INFO:root:eval mean loss: 2442.0403048467974
INFO:root:eval perplexity: 7.368157863616943
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/13
  6%|â–‹         | 13/200 [1:26:42<20:29:54, 394.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2114.225128173828
INFO:root:current train perplexity5.210660457611084
INFO:root:current mean train loss 2069.341514078776
INFO:root:current train perplexity5.120490074157715
INFO:root:current mean train loss 2077.801705655185
INFO:root:current train perplexity5.1189494132995605
INFO:root:current mean train loss 2072.417287826538
INFO:root:current train perplexity5.100215911865234
INFO:root:current mean train loss 2067.003855096726
INFO:root:current train perplexity5.095240592956543
INFO:root:current mean train loss 2065.958267916166
INFO:root:current train perplexity5.103555202484131
INFO:root:current mean train loss 2062.4227117723035
INFO:root:current train perplexity5.091645240783691
INFO:root:current mean train loss 2062.0934144761827
INFO:root:current train perplexity5.089292526245117
INFO:root:current mean train loss 2065.2785869319264
INFO:root:current train perplexity5.096531867980957
INFO:root:current mean train loss 2065.9076492972995
INFO:root:current train perplexity5.100038051605225
INFO:root:current mean train loss 2066.59002087163
INFO:root:current train perplexity5.104824066162109
INFO:root:current mean train loss 2066.5708768572126
INFO:root:current train perplexity5.1063666343688965
INFO:root:current mean train loss 2066.0567256739882
INFO:root:current train perplexity5.104449272155762
INFO:root:current mean train loss 2064.865760479551
INFO:root:current train perplexity5.103631973266602
INFO:root:current mean train loss 2064.3363497881824
INFO:root:current train perplexity5.100841999053955
INFO:root:current mean train loss 2063.6560258564195
INFO:root:current train perplexity5.100125312805176
INFO:root:current mean train loss 2064.467148467641
INFO:root:current train perplexity5.097092151641846
INFO:root:current mean train loss 2063.8385016862735
INFO:root:current train perplexity5.093380928039551
INFO:root:current mean train loss 2064.1557279146637
INFO:root:current train perplexity5.092258930206299
INFO:root:current mean train loss 2063.8191356658936
INFO:root:current train perplexity5.088868141174316

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.71s/it]
INFO:root:final mean train loss: 2063.3899169860315
INFO:root:final train perplexity: 5.09018087387085
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.48s/it]
INFO:root:eval mean loss: 2006.2605305123836
INFO:root:eval perplexity: 5.0659708976745605
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it]
INFO:root:eval mean loss: 2427.9954820998173
INFO:root:eval perplexity: 7.284008502960205
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/14
  7%|â–‹         | 14/200 [1:33:27<20:33:28, 397.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2048.076287346917
INFO:root:current train perplexity4.976036071777344
INFO:root:current mean train loss 2047.494603957573
INFO:root:current train perplexity5.009329795837402
INFO:root:current mean train loss 2043.6074867731409
INFO:root:current train perplexity5.013174533843994
INFO:root:current mean train loss 2042.0337508113873
INFO:root:current train perplexity5.013254642486572
INFO:root:current mean train loss 2050.1357391147917
INFO:root:current train perplexity5.0353312492370605
INFO:root:current mean train loss 2047.5546124847242
INFO:root:current train perplexity5.027967929840088
INFO:root:current mean train loss 2049.63062040847
INFO:root:current train perplexity5.031729221343994
INFO:root:current mean train loss 2045.3112518020691
INFO:root:current train perplexity5.025402545928955
INFO:root:current mean train loss 2041.848693337207
INFO:root:current train perplexity5.012633800506592
INFO:root:current mean train loss 2043.2018495801929
INFO:root:current train perplexity5.013539791107178
INFO:root:current mean train loss 2044.7744159459378
INFO:root:current train perplexity5.015954971313477
INFO:root:current mean train loss 2045.596908690118
INFO:root:current train perplexity5.016469955444336
INFO:root:current mean train loss 2045.0785778542152
INFO:root:current train perplexity5.0177507400512695
INFO:root:current mean train loss 2045.3238823947036
INFO:root:current train perplexity5.015317440032959
INFO:root:current mean train loss 2046.9235348844163
INFO:root:current train perplexity5.020638465881348
INFO:root:current mean train loss 2048.3303521279786
INFO:root:current train perplexity5.022702693939209
INFO:root:current mean train loss 2046.565583673569
INFO:root:current train perplexity5.018584728240967
INFO:root:current mean train loss 2048.3629924135093
INFO:root:current train perplexity5.026848793029785
INFO:root:current mean train loss 2048.456196825986
INFO:root:current train perplexity5.02662992477417
INFO:root:current mean train loss 2048.3177965407403
INFO:root:current train perplexity5.027663707733154

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.93s/it]
INFO:root:final mean train loss: 2047.054846320679
INFO:root:final train perplexity: 5.025025367736816
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.84s/it]
INFO:root:eval mean loss: 1994.8785486965314
INFO:root:eval perplexity: 5.019551753997803
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.52s/it]
INFO:root:eval mean loss: 2416.255908722573
INFO:root:eval perplexity: 7.214409828186035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/15
  8%|â–Š         | 15/200 [1:40:02<20:23:35, 396.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2017.8064303927952
INFO:root:current train perplexity4.90526008605957
INFO:root:current mean train loss 2041.924593046114
INFO:root:current train perplexity4.944149494171143
INFO:root:current mean train loss 2042.717984417292
INFO:root:current train perplexity4.96190881729126
INFO:root:current mean train loss 2042.946320786988
INFO:root:current train perplexity4.973320960998535
INFO:root:current mean train loss 2040.3421036640452
INFO:root:current train perplexity4.9727091789245605
INFO:root:current mean train loss 2038.1215569120882
INFO:root:current train perplexity4.967777252197266
INFO:root:current mean train loss 2036.211727410646
INFO:root:current train perplexity4.973748683929443
INFO:root:current mean train loss 2037.8403229650198
INFO:root:current train perplexity4.976680278778076
INFO:root:current mean train loss 2036.9816953136435
INFO:root:current train perplexity4.974478244781494
INFO:root:current mean train loss 2035.5313322759025
INFO:root:current train perplexity4.969256401062012
INFO:root:current mean train loss 2033.1148971181215
INFO:root:current train perplexity4.964443683624268
INFO:root:current mean train loss 2034.463522873057
INFO:root:current train perplexity4.966660976409912
INFO:root:current mean train loss 2033.9372972308925
INFO:root:current train perplexity4.96647834777832
INFO:root:current mean train loss 2034.7601169603086
INFO:root:current train perplexity4.967646598815918
INFO:root:current mean train loss 2036.2471438569248
INFO:root:current train perplexity4.974795818328857
INFO:root:current mean train loss 2037.3423864101965
INFO:root:current train perplexity4.979133129119873
INFO:root:current mean train loss 2035.5984171598682
INFO:root:current train perplexity4.976151943206787
INFO:root:current mean train loss 2035.8299044149087
INFO:root:current train perplexity4.977180480957031
INFO:root:current mean train loss 2035.8869678287444
INFO:root:current train perplexity4.976208686828613
INFO:root:current mean train loss 2034.631641212237
INFO:root:current train perplexity4.973564147949219

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.89s/it]
INFO:root:final mean train loss: 2033.6999139290415
INFO:root:final train perplexity: 4.972377300262451
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it]
INFO:root:eval mean loss: 1989.4088658542498
INFO:root:eval perplexity: 4.997396469116211
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.04s/it]
INFO:root:eval mean loss: 2413.566334825881
INFO:root:eval perplexity: 7.198557376861572
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/16
  8%|â–Š         | 16/200 [1:46:47<20:24:58, 399.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2011.2441612566022
INFO:root:current train perplexity4.846797943115234
INFO:root:current mean train loss 2033.2910934359008
INFO:root:current train perplexity4.9335713386535645
INFO:root:current mean train loss 2023.092933345105
INFO:root:current train perplexity4.90070915222168
INFO:root:current mean train loss 2032.9400822313005
INFO:root:current train perplexity4.941412448883057
INFO:root:current mean train loss 2031.2235975650212
INFO:root:current train perplexity4.933444499969482
INFO:root:current mean train loss 2025.7306314391556
INFO:root:current train perplexity4.924038887023926
INFO:root:current mean train loss 2023.524390958283
INFO:root:current train perplexity4.92149543762207
INFO:root:current mean train loss 2022.5601733810088
INFO:root:current train perplexity4.921075820922852
INFO:root:current mean train loss 2018.6916306295295
INFO:root:current train perplexity4.91903018951416
INFO:root:current mean train loss 2018.2806842776454
INFO:root:current train perplexity4.914431095123291
INFO:root:current mean train loss 2017.582922329088
INFO:root:current train perplexity4.9152512550354
INFO:root:current mean train loss 2018.5603495401567
INFO:root:current train perplexity4.916638374328613
INFO:root:current mean train loss 2017.7986344068092
INFO:root:current train perplexity4.914880752563477
INFO:root:current mean train loss 2018.0532701131986
INFO:root:current train perplexity4.9161376953125
INFO:root:current mean train loss 2016.6957763837845
INFO:root:current train perplexity4.914031505584717
INFO:root:current mean train loss 2017.578414829577
INFO:root:current train perplexity4.917836666107178
INFO:root:current mean train loss 2020.7023723426512
INFO:root:current train perplexity4.92442512512207
INFO:root:current mean train loss 2021.3783645500644
INFO:root:current train perplexity4.925374984741211
INFO:root:current mean train loss 2021.883586547134
INFO:root:current train perplexity4.926344394683838
INFO:root:current mean train loss 2023.5648808355927
INFO:root:current train perplexity4.931136131286621

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.13s/it]
INFO:root:final mean train loss: 2023.2841581112798
INFO:root:final train perplexity: 4.931699752807617
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.63s/it]
INFO:root:eval mean loss: 1988.1309554729055
INFO:root:eval perplexity: 4.992233753204346
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.54s/it]
INFO:root:eval mean loss: 2411.5164431308176
INFO:root:eval perplexity: 7.18649959564209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/17
  8%|â–Š         | 17/200 [1:53:19<20:11:51, 397.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2009.1344507390802
INFO:root:current train perplexity4.911925315856934
INFO:root:current mean train loss 2000.429916057181
INFO:root:current train perplexity4.855306148529053
INFO:root:current mean train loss 2005.7888509962295
INFO:root:current train perplexity4.855252265930176
INFO:root:current mean train loss 2007.7684272687459
INFO:root:current train perplexity4.857445240020752
INFO:root:current mean train loss 2011.8737515308817
INFO:root:current train perplexity4.873738765716553
INFO:root:current mean train loss 2009.4868475466358
INFO:root:current train perplexity4.871094226837158
INFO:root:current mean train loss 2010.8126522330351
INFO:root:current train perplexity4.876204490661621
INFO:root:current mean train loss 2014.086636925712
INFO:root:current train perplexity4.884016990661621
INFO:root:current mean train loss 2014.847719897021
INFO:root:current train perplexity4.8930182456970215
INFO:root:current mean train loss 2012.0101577820565
INFO:root:current train perplexity4.888066291809082
INFO:root:current mean train loss 2013.2889400930965
INFO:root:current train perplexity4.8957319259643555
INFO:root:current mean train loss 2014.2318633108428
INFO:root:current train perplexity4.894052982330322
INFO:root:current mean train loss 2016.6984900243533
INFO:root:current train perplexity4.895434856414795
INFO:root:current mean train loss 2015.0856170214563
INFO:root:current train perplexity4.89462423324585
INFO:root:current mean train loss 2014.560774608325
INFO:root:current train perplexity4.893770694732666
INFO:root:current mean train loss 2012.8383691436998
INFO:root:current train perplexity4.889798641204834
INFO:root:current mean train loss 2014.2268783786285
INFO:root:current train perplexity4.8929762840271
INFO:root:current mean train loss 2013.8500595604814
INFO:root:current train perplexity4.894059658050537
INFO:root:current mean train loss 2012.8557704990194
INFO:root:current train perplexity4.890787601470947

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.43s/it]
INFO:root:final mean train loss: 2013.1755030675783
INFO:root:final train perplexity: 4.8925395011901855
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it]
INFO:root:eval mean loss: 1981.0810975419713
INFO:root:eval perplexity: 4.963852405548096
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.88s/it]
INFO:root:eval mean loss: 2408.516029303801
INFO:root:eval perplexity: 7.168887138366699
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/18
  9%|â–‰         | 18/200 [2:00:03<20:11:05, 399.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1952.345068359375
INFO:root:current train perplexity4.861555576324463
INFO:root:current mean train loss 1974.4038934616815
INFO:root:current train perplexity4.779569149017334
INFO:root:current mean train loss 1986.04389707984
INFO:root:current train perplexity4.813241481781006
INFO:root:current mean train loss 1994.3476702580685
INFO:root:current train perplexity4.836086750030518
INFO:root:current mean train loss 1994.6580050998264
INFO:root:current train perplexity4.835316181182861
INFO:root:current mean train loss 1994.420684512299
INFO:root:current train perplexity4.830788612365723
INFO:root:current mean train loss 1995.8319251194473
INFO:root:current train perplexity4.837449550628662
INFO:root:current mean train loss 1999.8763476216202
INFO:root:current train perplexity4.850430011749268
INFO:root:current mean train loss 1998.3931178122573
INFO:root:current train perplexity4.845788478851318
INFO:root:current mean train loss 1999.0423455844268
INFO:root:current train perplexity4.846058368682861
INFO:root:current mean train loss 1999.7503554007308
INFO:root:current train perplexity4.850589752197266
INFO:root:current mean train loss 2000.4919766111072
INFO:root:current train perplexity4.8497114181518555
INFO:root:current mean train loss 2003.2173312491896
INFO:root:current train perplexity4.8581929206848145
INFO:root:current mean train loss 2072.193787603269
INFO:root:current train perplexity5.129202842712402
INFO:root:current mean train loss 2094.2604768474757
INFO:root:current train perplexity5.218911647796631
INFO:root:current mean train loss 2101.4819056108545
INFO:root:current train perplexity5.245158672332764
INFO:root:current mean train loss 2106.581976185261
INFO:root:current train perplexity5.261175155639648
INFO:root:current mean train loss 2107.7048383517
INFO:root:current train perplexity5.269707679748535
INFO:root:current mean train loss 2109.3495551365563
INFO:root:current train perplexity5.276060581207275
INFO:root:current mean train loss 2109.702945963542
INFO:root:current train perplexity5.278883457183838

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.61s/it]
INFO:root:final mean train loss: 2109.2887170650233
INFO:root:final train perplexity: 5.277813911437988
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.05s/it]
INFO:root:eval mean loss: 2026.3363972116024
INFO:root:eval perplexity: 5.1488938331604
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.53s/it]
INFO:root:eval mean loss: 2452.986787403729
INFO:root:eval perplexity: 7.434415340423584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/19
 10%|â–‰         | 19/200 [2:06:36<19:58:09, 397.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2151.7298306551847
INFO:root:current train perplexity5.418396949768066
INFO:root:current mean train loss 2105.877067190702
INFO:root:current train perplexity5.2635040283203125
INFO:root:current mean train loss 2101.6377266548775
INFO:root:current train perplexity5.246158599853516
INFO:root:current mean train loss 2103.740085388563
INFO:root:current train perplexity5.248443603515625
INFO:root:current mean train loss 2108.3591647035137
INFO:root:current train perplexity5.255932331085205
INFO:root:current mean train loss 2106.0383052899006
INFO:root:current train perplexity5.25010347366333
INFO:root:current mean train loss 2102.0376090390123
INFO:root:current train perplexity5.23856258392334
INFO:root:current mean train loss 2097.8996740959356
INFO:root:current train perplexity5.225121974945068
INFO:root:current mean train loss 2097.525584868271
INFO:root:current train perplexity5.221620082855225
INFO:root:current mean train loss 2098.2305201201534
INFO:root:current train perplexity5.223272323608398
INFO:root:current mean train loss 2097.398914314763
INFO:root:current train perplexity5.2237324714660645
INFO:root:current mean train loss 2097.676233845811
INFO:root:current train perplexity5.228824615478516
INFO:root:current mean train loss 2096.6783214512902
INFO:root:current train perplexity5.224757194519043
INFO:root:current mean train loss 2095.468421001117
INFO:root:current train perplexity5.221690654754639
INFO:root:current mean train loss 2096.19283048949
INFO:root:current train perplexity5.226310729980469
INFO:root:current mean train loss 2096.3550259443527
INFO:root:current train perplexity5.2284417152404785
INFO:root:current mean train loss 2097.287533761247
INFO:root:current train perplexity5.2267537117004395
INFO:root:current mean train loss 2097.671437262381
INFO:root:current train perplexity5.224580764770508
INFO:root:current mean train loss 2095.8999168153127
INFO:root:current train perplexity5.221340656280518
INFO:root:current mean train loss 2094.548794527084
INFO:root:current train perplexity5.217209815979004

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.62s/it]
INFO:root:final mean train loss: 2094.8308057760987
INFO:root:final train perplexity: 5.217976093292236
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 2028.623609610483
INFO:root:eval perplexity: 5.158426761627197
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.30s/it]
INFO:root:eval mean loss: 2455.199085857851
INFO:root:eval perplexity: 7.447879314422607
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/20
 10%|â–ˆ         | 20/200 [2:13:10<19:48:56, 396.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2051.7147373297275
INFO:root:current train perplexity5.116298198699951
INFO:root:current mean train loss 2065.1008660844764
INFO:root:current train perplexity5.109630107879639
INFO:root:current mean train loss 2068.15373044832
INFO:root:current train perplexity5.132546424865723
INFO:root:current mean train loss 2073.260346089141
INFO:root:current train perplexity5.128768444061279
INFO:root:current mean train loss 2078.1509306262456
INFO:root:current train perplexity5.142778396606445
INFO:root:current mean train loss 2076.732035960691
INFO:root:current train perplexity5.132288455963135
INFO:root:current mean train loss 2071.5879786913756
INFO:root:current train perplexity5.125491619110107
INFO:root:current mean train loss 2074.7062757024905
INFO:root:current train perplexity5.128902912139893
INFO:root:current mean train loss 2076.111745550181
INFO:root:current train perplexity5.134568214416504
INFO:root:current mean train loss 2076.4819276137346
INFO:root:current train perplexity5.134796619415283
INFO:root:current mean train loss 2076.7733645397843
INFO:root:current train perplexity5.136175155639648
INFO:root:current mean train loss 2076.57198418809
INFO:root:current train perplexity5.1347222328186035
INFO:root:current mean train loss 2076.2931564368
INFO:root:current train perplexity5.134673595428467
INFO:root:current mean train loss 2074.591619011535
INFO:root:current train perplexity5.129423141479492
INFO:root:current mean train loss 2073.972779592762
INFO:root:current train perplexity5.129856586456299
INFO:root:current mean train loss 2072.615613911352
INFO:root:current train perplexity5.126655578613281
INFO:root:current mean train loss 2072.1203210352396
INFO:root:current train perplexity5.12648344039917
INFO:root:current mean train loss 2072.472825491819
INFO:root:current train perplexity5.129591464996338
INFO:root:current mean train loss 2073.102498704289
INFO:root:current train perplexity5.128716945648193
INFO:root:current mean train loss 2074.0405581918435
INFO:root:current train perplexity5.129105567932129

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.68s/it]
INFO:root:final mean train loss: 2073.075981290185
INFO:root:final train perplexity: 5.129213333129883
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.40s/it]
INFO:root:eval mean loss: 2020.3162439224568
INFO:root:eval perplexity: 5.123887538909912
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.97s/it]
INFO:root:eval mean loss: 2450.3368023811504
INFO:root:eval perplexity: 7.418321132659912
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/21
 10%|â–ˆ         | 21/200 [2:19:54<19:49:25, 398.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2079.2079097202845
INFO:root:current train perplexity5.118585586547852
INFO:root:current mean train loss 2077.5155467498
INFO:root:current train perplexity5.104825019836426
INFO:root:current mean train loss 2062.792456150055
INFO:root:current train perplexity5.07226037979126
INFO:root:current mean train loss 2067.4861604497673
INFO:root:current train perplexity5.094940662384033
INFO:root:current mean train loss 2066.7692445453845
INFO:root:current train perplexity5.09503173828125
INFO:root:current mean train loss 2063.0537904149337
INFO:root:current train perplexity5.083694934844971
INFO:root:current mean train loss 2061.5019933188833
INFO:root:current train perplexity5.078512668609619
INFO:root:current mean train loss 2062.6589392606543
INFO:root:current train perplexity5.078370571136475
INFO:root:current mean train loss 2065.93278945495
INFO:root:current train perplexity5.085260391235352
INFO:root:current mean train loss 2064.246127587482
INFO:root:current train perplexity5.080832004547119
INFO:root:current mean train loss 2066.068636345141
INFO:root:current train perplexity5.084455490112305
INFO:root:current mean train loss 2063.6214793908143
INFO:root:current train perplexity5.081736087799072
INFO:root:current mean train loss 2062.3266823155104
INFO:root:current train perplexity5.078408241271973
INFO:root:current mean train loss 2061.2639237575477
INFO:root:current train perplexity5.080125331878662
INFO:root:current mean train loss 2061.2986065372006
INFO:root:current train perplexity5.079606533050537
INFO:root:current mean train loss 2061.8396385212486
INFO:root:current train perplexity5.078271865844727
INFO:root:current mean train loss 2062.795488809042
INFO:root:current train perplexity5.082664489746094
INFO:root:current mean train loss 2061.531631156904
INFO:root:current train perplexity5.07886266708374
INFO:root:current mean train loss 2061.8575268449454
INFO:root:current train perplexity5.081162929534912
INFO:root:current mean train loss 2061.150442236528
INFO:root:current train perplexity5.078056812286377

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.85s/it]
INFO:root:final mean train loss: 2060.3815817936347
INFO:root:final train perplexity: 5.078118324279785
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.33s/it]
INFO:root:eval mean loss: 2013.231328436669
INFO:root:eval perplexity: 5.094610214233398
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it]
INFO:root:eval mean loss: 2445.8236096970577
INFO:root:eval perplexity: 7.390990734100342
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/22
 11%|â–ˆ         | 22/200 [2:26:39<19:48:35, 400.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2062.1124234134204
INFO:root:current train perplexity5.0524163246154785
INFO:root:current mean train loss 2055.4807135962337
INFO:root:current train perplexity5.027099132537842
INFO:root:current mean train loss 2053.936831072573
INFO:root:current train perplexity5.017201900482178
INFO:root:current mean train loss 2052.5593615166304
INFO:root:current train perplexity5.017917156219482
INFO:root:current mean train loss 2057.6430904073895
INFO:root:current train perplexity5.028264999389648
INFO:root:current mean train loss 2058.3351658792812
INFO:root:current train perplexity5.047103404998779
INFO:root:current mean train loss 2052.4284501097
INFO:root:current train perplexity5.03447151184082
INFO:root:current mean train loss 2049.4669197349003
INFO:root:current train perplexity5.02885103225708
INFO:root:current mean train loss 2050.346616205344
INFO:root:current train perplexity5.030510425567627
INFO:root:current mean train loss 2053.6746088480777
INFO:root:current train perplexity5.034790992736816
INFO:root:current mean train loss 2055.2752494420943
INFO:root:current train perplexity5.0384931564331055
INFO:root:current mean train loss 2055.5693804780744
INFO:root:current train perplexity5.040834426879883
INFO:root:current mean train loss 2055.4420485335454
INFO:root:current train perplexity5.043554306030273
INFO:root:current mean train loss 2056.4696822864507
INFO:root:current train perplexity5.050028324127197
INFO:root:current mean train loss 2055.782503769014
INFO:root:current train perplexity5.051585674285889
INFO:root:current mean train loss 2055.6898048240823
INFO:root:current train perplexity5.05082893371582
INFO:root:current mean train loss 2055.9991846899748
INFO:root:current train perplexity5.052713394165039
INFO:root:current mean train loss 2054.4627593288433
INFO:root:current train perplexity5.049829006195068
INFO:root:current mean train loss 2054.946683558817
INFO:root:current train perplexity5.051483631134033
INFO:root:current mean train loss 2054.5798699310812
INFO:root:current train perplexity5.052780628204346

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.51s/it]
INFO:root:final mean train loss: 2054.141378721082
INFO:root:final train perplexity: 5.053188323974609
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.49s/it]
INFO:root:eval mean loss: 2012.6125457980108
INFO:root:eval perplexity: 5.092062473297119
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it]
INFO:root:eval mean loss: 2443.6606259176915
INFO:root:eval perplexity: 7.377927780151367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/23
 12%|â–ˆâ–        | 23/200 [2:33:15<19:37:39, 399.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2041.6635796440971
INFO:root:current train perplexity5.0291666984558105
INFO:root:current mean train loss 2052.145736533717
INFO:root:current train perplexity5.0356340408325195
INFO:root:current mean train loss 2047.1242528455011
INFO:root:current train perplexity5.020479679107666
INFO:root:current mean train loss 2047.1416823167067
INFO:root:current train perplexity5.029665946960449
INFO:root:current mean train loss 2056.0880988919007
INFO:root:current train perplexity5.0465474128723145
INFO:root:current mean train loss 2053.6286213503045
INFO:root:current train perplexity5.040402412414551
INFO:root:current mean train loss 2057.3862281688744
INFO:root:current train perplexity5.0455002784729
INFO:root:current mean train loss 2057.682736630983
INFO:root:current train perplexity5.049160957336426
INFO:root:current mean train loss 2055.5220295766767
INFO:root:current train perplexity5.0462517738342285
INFO:root:current mean train loss 2053.7773304332386
INFO:root:current train perplexity5.040531158447266
INFO:root:current mean train loss 2052.524343060135
INFO:root:current train perplexity5.036297798156738
INFO:root:current mean train loss 2052.5741618180477
INFO:root:current train perplexity5.035379886627197
INFO:root:current mean train loss 2052.8873062961784
INFO:root:current train perplexity5.035658836364746
INFO:root:current mean train loss 2053.4138817656813
INFO:root:current train perplexity5.036332607269287
INFO:root:current mean train loss 2052.867648008206
INFO:root:current train perplexity5.036280632019043
INFO:root:current mean train loss 2052.287356279481
INFO:root:current train perplexity5.036973476409912
INFO:root:current mean train loss 2052.584524229151
INFO:root:current train perplexity5.040024757385254
INFO:root:current mean train loss 2051.7059886058614
INFO:root:current train perplexity5.040380954742432
INFO:root:current mean train loss 2052.0718365058697
INFO:root:current train perplexity5.0422797203063965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 339.00s/it]
INFO:root:final mean train loss: 2051.1315949671325
INFO:root:final train perplexity: 5.041208744049072
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.27s/it]
INFO:root:eval mean loss: 2009.1141322792
INFO:root:eval perplexity: 5.077675819396973
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.89s/it]
INFO:root:eval mean loss: 2444.929956747285
INFO:root:eval perplexity: 7.38559103012085
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/24
 12%|â–ˆâ–        | 24/200 [2:39:47<19:24:56, 397.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1985.5013776506696
INFO:root:current train perplexity4.916452884674072
INFO:root:current mean train loss 2055.1247547185308
INFO:root:current train perplexity4.991682529449463
INFO:root:current mean train loss 2062.999456875566
INFO:root:current train perplexity5.039945602416992
INFO:root:current mean train loss 2059.727047997888
INFO:root:current train perplexity5.034190654754639
INFO:root:current mean train loss 2052.067429901048
INFO:root:current train perplexity5.0267486572265625
INFO:root:current mean train loss 2045.9725515151165
INFO:root:current train perplexity5.0109357833862305
INFO:root:current mean train loss 2042.819990330905
INFO:root:current train perplexity5.01702880859375
INFO:root:current mean train loss 2043.3377575044753
INFO:root:current train perplexity5.02003812789917
INFO:root:current mean train loss 2043.5349027309867
INFO:root:current train perplexity5.023731231689453
INFO:root:current mean train loss 2047.3592970741886
INFO:root:current train perplexity5.030080318450928
INFO:root:current mean train loss 2048.671772931278
INFO:root:current train perplexity5.033909320831299
INFO:root:current mean train loss 2048.203777254651
INFO:root:current train perplexity5.0324907302856445
INFO:root:current mean train loss 2049.182528188432
INFO:root:current train perplexity5.033979892730713
INFO:root:current mean train loss 2050.21424591368
INFO:root:current train perplexity5.033266067504883
INFO:root:current mean train loss 2049.978135619336
INFO:root:current train perplexity5.031355381011963
INFO:root:current mean train loss 2050.7618149806112
INFO:root:current train perplexity5.0329976081848145
INFO:root:current mean train loss 2051.33756854776
INFO:root:current train perplexity5.032129287719727
INFO:root:current mean train loss 2051.2291935550306
INFO:root:current train perplexity5.033496379852295
INFO:root:current mean train loss 2050.923789011159
INFO:root:current train perplexity5.035544395446777
INFO:root:current mean train loss 2051.1091574242305
INFO:root:current train perplexity5.039342403411865

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.20s/it]
INFO:root:final mean train loss: 2050.2338797626503
INFO:root:final train perplexity: 5.03764009475708
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it]
INFO:root:eval mean loss: 2018.774763391373
INFO:root:eval perplexity: 5.117502689361572
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it]
INFO:root:eval mean loss: 2458.0957741162456
INFO:root:eval perplexity: 7.465545654296875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/25
 12%|â–ˆâ–Ž        | 25/200 [2:46:31<19:24:06, 399.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2054.3124796549478
INFO:root:current train perplexity5.062593936920166
INFO:root:current mean train loss 2052.0475011025705
INFO:root:current train perplexity5.047120571136475
INFO:root:current mean train loss 2050.8407423836843
INFO:root:current train perplexity5.02492094039917
INFO:root:current mean train loss 2048.1415872456114
INFO:root:current train perplexity5.023829936981201
INFO:root:current mean train loss 2049.955601530255
INFO:root:current train perplexity5.026103496551514
INFO:root:current mean train loss 2054.3158713770276
INFO:root:current train perplexity5.03060245513916
INFO:root:current mean train loss 2054.824079660269
INFO:root:current train perplexity5.032313346862793
INFO:root:current mean train loss 2053.526919370198
INFO:root:current train perplexity5.02991247177124
INFO:root:current mean train loss 2050.3613349396046
INFO:root:current train perplexity5.029539108276367
INFO:root:current mean train loss 2049.6946127094748
INFO:root:current train perplexity5.032153606414795
INFO:root:current mean train loss 2048.241710424423
INFO:root:current train perplexity5.0268025398254395
INFO:root:current mean train loss 2048.8811392461703
INFO:root:current train perplexity5.026803016662598
INFO:root:current mean train loss 2049.8623452778734
INFO:root:current train perplexity5.027385711669922
INFO:root:current mean train loss 2047.8268461198604
INFO:root:current train perplexity5.023952484130859
INFO:root:current mean train loss 2047.8974242478275
INFO:root:current train perplexity5.025803565979004
INFO:root:current mean train loss 2047.8664803091935
INFO:root:current train perplexity5.024057865142822
INFO:root:current mean train loss 2047.990501817224
INFO:root:current train perplexity5.023706912994385
INFO:root:current mean train loss 2047.6048281640851
INFO:root:current train perplexity5.024770259857178
INFO:root:current mean train loss 2047.5395269561232
INFO:root:current train perplexity5.027702331542969
INFO:root:current mean train loss 2049.428522946681
INFO:root:current train perplexity5.032736301422119

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.93s/it]
INFO:root:final mean train loss: 2048.7448199219734
INFO:root:final train perplexity: 5.0317277908325195
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it]
INFO:root:eval mean loss: 2010.734960677776
INFO:root:eval perplexity: 5.084336757659912
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.26s/it]
INFO:root:eval mean loss: 2448.4664865047375
INFO:root:eval perplexity: 7.406983852386475
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/26
 13%|â–ˆâ–Ž        | 26/200 [2:53:08<19:15:04, 398.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2031.133994497904
INFO:root:current train perplexity4.993880271911621
INFO:root:current mean train loss 2053.0745157011856
INFO:root:current train perplexity5.023035049438477
INFO:root:current mean train loss 2046.2042003330848
INFO:root:current train perplexity5.004183292388916
INFO:root:current mean train loss 2045.2329577672517
INFO:root:current train perplexity5.016294002532959
INFO:root:current mean train loss 2041.5537524580145
INFO:root:current train perplexity5.01280403137207
INFO:root:current mean train loss 2045.108867088219
INFO:root:current train perplexity5.014686107635498
INFO:root:current mean train loss 2045.51155268867
INFO:root:current train perplexity5.004929542541504
INFO:root:current mean train loss 2045.503354874378
INFO:root:current train perplexity5.004127025604248
INFO:root:current mean train loss 2045.1485627635907
INFO:root:current train perplexity5.005152225494385
INFO:root:current mean train loss 2045.3176169643746
INFO:root:current train perplexity5.0105390548706055
INFO:root:current mean train loss 2044.463582825821
INFO:root:current train perplexity5.007404327392578
INFO:root:current mean train loss 2045.3703137196333
INFO:root:current train perplexity5.009784698486328
INFO:root:current mean train loss 2043.6520680343788
INFO:root:current train perplexity5.009079456329346
INFO:root:current mean train loss 2045.6628925912332
INFO:root:current train perplexity5.015054702758789
INFO:root:current mean train loss 2046.1720040167147
INFO:root:current train perplexity5.0170464515686035
INFO:root:current mean train loss 2047.1616099244352
INFO:root:current train perplexity5.021892547607422
INFO:root:current mean train loss 2047.051062361341
INFO:root:current train perplexity5.022400856018066
INFO:root:current mean train loss 2046.8794975302674
INFO:root:current train perplexity5.024557113647461
INFO:root:current mean train loss 2047.6702115019011
INFO:root:current train perplexity5.029496192932129
INFO:root:current mean train loss 2048.2267492216683
INFO:root:current train perplexity5.029108047485352

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.98s/it]
INFO:root:final mean train loss: 2048.2992914135384
INFO:root:final train perplexity: 5.029960632324219
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.95s/it]
INFO:root:eval mean loss: 2017.1662099851785
INFO:root:eval perplexity: 5.110849857330322
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it]
INFO:root:eval mean loss: 2452.240507518146
INFO:root:eval perplexity: 7.429879188537598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/27
 14%|â–ˆâ–Ž        | 27/200 [2:59:43<19:05:32, 397.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2058.948648386988
INFO:root:current train perplexity5.062821388244629
INFO:root:current mean train loss 2026.0464129870452
INFO:root:current train perplexity4.9970011711120605
INFO:root:current mean train loss 2022.2253801212755
INFO:root:current train perplexity4.963234901428223
INFO:root:current mean train loss 2029.184434262068
INFO:root:current train perplexity4.974677085876465
INFO:root:current mean train loss 2031.8656200425594
INFO:root:current train perplexity4.979495525360107
INFO:root:current mean train loss 2035.8848623186884
INFO:root:current train perplexity4.983668327331543
INFO:root:current mean train loss 2038.2417418877042
INFO:root:current train perplexity4.990771770477295
INFO:root:current mean train loss 2039.6961138481201
INFO:root:current train perplexity4.997292518615723
INFO:root:current mean train loss 2036.3256399159109
INFO:root:current train perplexity4.994654655456543
INFO:root:current mean train loss 2037.384296839322
INFO:root:current train perplexity4.99923849105835
INFO:root:current mean train loss 2037.8211425319737
INFO:root:current train perplexity5.000825881958008
INFO:root:current mean train loss 2038.8188217242148
INFO:root:current train perplexity5.005476474761963
INFO:root:current mean train loss 2038.7719909959073
INFO:root:current train perplexity5.003387451171875
INFO:root:current mean train loss 2040.806109466328
INFO:root:current train perplexity5.007282733917236
INFO:root:current mean train loss 2042.365802613142
INFO:root:current train perplexity5.0082011222839355
INFO:root:current mean train loss 2042.300229661425
INFO:root:current train perplexity5.009671211242676
INFO:root:current mean train loss 2043.9734558179093
INFO:root:current train perplexity5.010537624359131
INFO:root:current mean train loss 2043.5098210357562
INFO:root:current train perplexity5.009145736694336
INFO:root:current mean train loss 2043.126742885495
INFO:root:current train perplexity5.008209705352783
INFO:root:current mean train loss 2043.8527767193086
INFO:root:current train perplexity5.010493278503418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.30s/it]
INFO:root:final mean train loss: 2043.3132907484614
INFO:root:final train perplexity: 5.010220050811768
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.54s/it]
INFO:root:eval mean loss: 2021.1851681107325
INFO:root:eval perplexity: 5.127487659454346
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.18s/it]
INFO:root:eval mean loss: 2457.6476366841202
INFO:root:eval perplexity: 7.462810039520264
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/28
 14%|â–ˆâ–        | 28/200 [3:06:16<18:55:21, 396.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2041.5558219401041
INFO:root:current train perplexity4.99069356918335
INFO:root:current mean train loss 2027.4442857142858
INFO:root:current train perplexity4.960289001464844
INFO:root:current mean train loss 2027.007256303267
INFO:root:current train perplexity4.9631524085998535
INFO:root:current mean train loss 2027.5805875651042
INFO:root:current train perplexity4.952269077301025
INFO:root:current mean train loss 2032.8881648334705
INFO:root:current train perplexity4.9649176597595215
INFO:root:current mean train loss 2040.1225689962637
INFO:root:current train perplexity4.973491668701172
INFO:root:current mean train loss 2039.8038505497684
INFO:root:current train perplexity4.981405258178711
INFO:root:current mean train loss 2041.5271448147682
INFO:root:current train perplexity4.988649845123291
INFO:root:current mean train loss 2041.1300728236606
INFO:root:current train perplexity4.983175754547119
INFO:root:current mean train loss 2038.682571864984
INFO:root:current train perplexity4.978943347930908
INFO:root:current mean train loss 2037.9303475881177
INFO:root:current train perplexity4.976109504699707
INFO:root:current mean train loss 2036.493904899435
INFO:root:current train perplexity4.976848602294922
INFO:root:current mean train loss 2037.6225058402267
INFO:root:current train perplexity4.97929573059082
INFO:root:current mean train loss 2036.5386065340908
INFO:root:current train perplexity4.974825859069824
INFO:root:current mean train loss 2035.5223255429025
INFO:root:current train perplexity4.972128391265869
INFO:root:current mean train loss 2035.2197278025794
INFO:root:current train perplexity4.970180988311768
INFO:root:current mean train loss 2035.4560160622668
INFO:root:current train perplexity4.973031044006348
INFO:root:current mean train loss 2035.0861990399428
INFO:root:current train perplexity4.974154472351074
INFO:root:current mean train loss 2034.6932881510418
INFO:root:current train perplexity4.972481727600098
INFO:root:current mean train loss 2035.7277472310127
INFO:root:current train perplexity4.977288722991943

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.85s/it]
INFO:root:final mean train loss: 2034.8680755415169
INFO:root:final train perplexity: 4.9769606590271
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it]
INFO:root:eval mean loss: 2008.7766204184675
INFO:root:eval perplexity: 5.076289653778076
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.47s/it]
INFO:root:eval mean loss: 2446.653280055269
INFO:root:eval perplexity: 7.396005630493164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/29
 14%|â–ˆâ–        | 29/200 [3:13:07<19:01:29, 400.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2004.0875907566237
INFO:root:current train perplexity4.919186592102051
INFO:root:current mean train loss 2020.0677038828533
INFO:root:current train perplexity4.938698768615723
INFO:root:current mean train loss 2028.1070552460135
INFO:root:current train perplexity4.957608699798584
INFO:root:current mean train loss 2025.9345690668845
INFO:root:current train perplexity4.950223922729492
INFO:root:current mean train loss 2029.5494670092576
INFO:root:current train perplexity4.955846309661865
INFO:root:current mean train loss 2029.3585159714157
INFO:root:current train perplexity4.957857608795166
INFO:root:current mean train loss 2028.745780283316
INFO:root:current train perplexity4.954754829406738
INFO:root:current mean train loss 2026.606484307183
INFO:root:current train perplexity4.9424967765808105
INFO:root:current mean train loss 2026.0039623585517
INFO:root:current train perplexity4.941243648529053
INFO:root:current mean train loss 2028.9110149260491
INFO:root:current train perplexity4.946533203125
INFO:root:current mean train loss 2029.1027079711466
INFO:root:current train perplexity4.944052219390869
INFO:root:current mean train loss 2029.3767409356649
INFO:root:current train perplexity4.943735599517822
INFO:root:current mean train loss 2028.4647800693572
INFO:root:current train perplexity4.942689895629883
INFO:root:current mean train loss 2028.0633793973375
INFO:root:current train perplexity4.943495273590088
INFO:root:current mean train loss 2027.0401185881997
INFO:root:current train perplexity4.940952777862549
INFO:root:current mean train loss 2027.2745731679638
INFO:root:current train perplexity4.939497470855713
INFO:root:current mean train loss 2024.9522953980359
INFO:root:current train perplexity4.937437534332275
INFO:root:current mean train loss 2026.3432220731463
INFO:root:current train perplexity4.938177585601807
INFO:root:current mean train loss 2025.7949860715967
INFO:root:current train perplexity4.938088893890381

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.77s/it]
INFO:root:final mean train loss: 2024.635942621659
INFO:root:final train perplexity: 4.936959743499756
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.94s/it]
INFO:root:eval mean loss: 2005.3317936024766
INFO:root:eval perplexity: 5.062166213989258
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.64s/it]
INFO:root:eval mean loss: 2446.411799870484
INFO:root:eval perplexity: 7.394546031951904
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/30
 15%|â–ˆâ–Œ        | 30/200 [3:19:48<18:55:38, 400.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2024.673122829861
INFO:root:current train perplexity5.009974002838135
INFO:root:current mean train loss 2034.7958782790997
INFO:root:current train perplexity4.934953689575195
INFO:root:current mean train loss 2021.2754157399447
INFO:root:current train perplexity4.915745735168457
INFO:root:current mean train loss 2017.992305619817
INFO:root:current train perplexity4.914168834686279
INFO:root:current mean train loss 2018.8987619264785
INFO:root:current train perplexity4.915774822235107
INFO:root:current mean train loss 2018.85339307504
INFO:root:current train perplexity4.916562557220459
INFO:root:current mean train loss 2020.6003277658046
INFO:root:current train perplexity4.913381576538086
INFO:root:current mean train loss 2019.5634478096902
INFO:root:current train perplexity4.908771514892578
INFO:root:current mean train loss 2021.0371134490401
INFO:root:current train perplexity4.916080474853516
INFO:root:current mean train loss 2018.9139907887272
INFO:root:current train perplexity4.909785747528076
INFO:root:current mean train loss 2021.4868035822133
INFO:root:current train perplexity4.915815353393555
INFO:root:current mean train loss 2019.987615862228
INFO:root:current train perplexity4.908905029296875
INFO:root:current mean train loss 2019.8974786069
INFO:root:current train perplexity4.910308837890625
INFO:root:current mean train loss 2020.9084724443755
INFO:root:current train perplexity4.912233829498291
INFO:root:current mean train loss 2021.8715093435337
INFO:root:current train perplexity4.916338920593262
INFO:root:current mean train loss 2021.3484089764797
INFO:root:current train perplexity4.91420316696167
INFO:root:current mean train loss 2019.4436304484782
INFO:root:current train perplexity4.910697937011719
INFO:root:current mean train loss 2017.2994733333867
INFO:root:current train perplexity4.903732776641846
INFO:root:current mean train loss 2016.6468984288626
INFO:root:current train perplexity4.903992176055908
INFO:root:current mean train loss 2015.8920381125386
INFO:root:current train perplexity4.902451515197754

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.75s/it]
INFO:root:final mean train loss: 2015.1712420565036
INFO:root:final train perplexity: 4.900245189666748
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.12s/it]
INFO:root:eval mean loss: 2004.6881164117908
INFO:root:eval perplexity: 5.059532642364502
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.51s/it]
INFO:root:eval mean loss: 2440.393991023936
INFO:root:eval perplexity: 7.358242511749268
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/31
 16%|â–ˆâ–Œ        | 31/200 [3:26:26<18:46:10, 399.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2016.554419884315
INFO:root:current train perplexity4.942659854888916
INFO:root:current mean train loss 1998.6762249658977
INFO:root:current train perplexity4.844303131103516
INFO:root:current mean train loss 2002.8016092756154
INFO:root:current train perplexity4.866088390350342
INFO:root:current mean train loss 2006.2207158562596
INFO:root:current train perplexity4.868447780609131
INFO:root:current mean train loss 2006.9054823324714
INFO:root:current train perplexity4.871411323547363
INFO:root:current mean train loss 2006.6324091574086
INFO:root:current train perplexity4.869540691375732
INFO:root:current mean train loss 2007.3303158306085
INFO:root:current train perplexity4.86668062210083
INFO:root:current mean train loss 2009.817273520898
INFO:root:current train perplexity4.872974872589111
INFO:root:current mean train loss 2011.5663879246747
INFO:root:current train perplexity4.871720790863037
INFO:root:current mean train loss 2012.7303333653228
INFO:root:current train perplexity4.873023509979248
INFO:root:current mean train loss 2010.3511514347663
INFO:root:current train perplexity4.865970611572266
INFO:root:current mean train loss 2008.7228735048013
INFO:root:current train perplexity4.8663177490234375
INFO:root:current mean train loss 2009.0996321760617
INFO:root:current train perplexity4.867364406585693
INFO:root:current mean train loss 2009.5436432667268
INFO:root:current train perplexity4.865910530090332
INFO:root:current mean train loss 2007.343701120513
INFO:root:current train perplexity4.86187744140625
INFO:root:current mean train loss 2005.5991010953371
INFO:root:current train perplexity4.857892990112305
INFO:root:current mean train loss 2004.7549103646554
INFO:root:current train perplexity4.856820106506348
INFO:root:current mean train loss 2005.4254994132705
INFO:root:current train perplexity4.858341217041016
INFO:root:current mean train loss 2005.0141455826858
INFO:root:current train perplexity4.858123779296875
INFO:root:current mean train loss 2005.8459840261553
INFO:root:current train perplexity4.860317707061768

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.04s/it]
INFO:root:final mean train loss: 2004.612218782749
INFO:root:final train perplexity: 4.859608173370361
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.18s/it]
INFO:root:eval mean loss: 2007.9325513907359
INFO:root:eval perplexity: 5.072825908660889
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.10s/it]
INFO:root:eval mean loss: 2446.341376554881
INFO:root:eval perplexity: 7.394120693206787
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/32
 16%|â–ˆâ–Œ        | 32/200 [3:33:17<18:49:22, 403.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2002.9737123001453
INFO:root:current train perplexity4.805481433868408
INFO:root:current mean train loss 1984.2920613322224
INFO:root:current train perplexity4.809903144836426
INFO:root:current mean train loss 1989.807185671457
INFO:root:current train perplexity4.813066482543945
INFO:root:current mean train loss 1990.0081680342337
INFO:root:current train perplexity4.812501907348633
INFO:root:current mean train loss 1992.1417826013155
INFO:root:current train perplexity4.8115386962890625
INFO:root:current mean train loss 1996.132195179414
INFO:root:current train perplexity4.820356369018555
INFO:root:current mean train loss 1995.2820813311018
INFO:root:current train perplexity4.820165157318115
INFO:root:current mean train loss 1996.3308616422548
INFO:root:current train perplexity4.823065280914307
INFO:root:current mean train loss 1994.750612958046
INFO:root:current train perplexity4.82015323638916
INFO:root:current mean train loss 1992.139359119209
INFO:root:current train perplexity4.807572364807129
INFO:root:current mean train loss 1991.9044053689402
INFO:root:current train perplexity4.811519622802734
INFO:root:current mean train loss 1993.1018209515803
INFO:root:current train perplexity4.8150787353515625
INFO:root:current mean train loss 1994.6149114729988
INFO:root:current train perplexity4.81624698638916
INFO:root:current mean train loss 1995.3905752811163
INFO:root:current train perplexity4.819361686706543
INFO:root:current mean train loss 1994.0170816380532
INFO:root:current train perplexity4.8163042068481445
INFO:root:current mean train loss 1995.794127508177
INFO:root:current train perplexity4.82277774810791
INFO:root:current mean train loss 1995.8794647421114
INFO:root:current train perplexity4.821911334991455
INFO:root:current mean train loss 1994.5232593319708
INFO:root:current train perplexity4.818990230560303
INFO:root:current mean train loss 1995.3199807972735
INFO:root:current train perplexity4.820353031158447
INFO:root:current mean train loss 1994.4414902479452
INFO:root:current train perplexity4.820322513580322

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.65s/it]
INFO:root:final mean train loss: 1994.9605860015208
INFO:root:final train perplexity: 4.822758197784424
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it]
INFO:root:eval mean loss: 1991.5629861168827
INFO:root:eval perplexity: 5.006109714508057
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.12s/it]
INFO:root:eval mean loss: 2432.189954825327
INFO:root:eval perplexity: 7.3090386390686035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/33
 16%|â–ˆâ–‹        | 33/200 [3:40:26<19:03:31, 410.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1959.5425821940105
INFO:root:current train perplexity4.740973472595215
INFO:root:current mean train loss 1966.7656936645508
INFO:root:current train perplexity4.75274133682251
INFO:root:current mean train loss 1977.8084162785456
INFO:root:current train perplexity4.756767272949219
INFO:root:current mean train loss 1982.2856455485025
INFO:root:current train perplexity4.779689788818359
INFO:root:current mean train loss 1983.7714835788893
INFO:root:current train perplexity4.778857707977295
INFO:root:current mean train loss 1986.12300894601
INFO:root:current train perplexity4.787169933319092
INFO:root:current mean train loss 1984.4410104462595
INFO:root:current train perplexity4.781806468963623
INFO:root:current mean train loss 1985.4711747018914
INFO:root:current train perplexity4.777213096618652
INFO:root:current mean train loss 1987.6241974586665
INFO:root:current train perplexity4.784997463226318
INFO:root:current mean train loss 1987.6727280934651
INFO:root:current train perplexity4.781160354614258
INFO:root:current mean train loss 1987.1180380767246
INFO:root:current train perplexity4.7857441902160645
INFO:root:current mean train loss 1988.4119169037917
INFO:root:current train perplexity4.788786888122559
INFO:root:current mean train loss 1987.4060260106646
INFO:root:current train perplexity4.789210796356201
INFO:root:current mean train loss 1985.7994892793542
INFO:root:current train perplexity4.784826278686523
INFO:root:current mean train loss 1986.0352697085027
INFO:root:current train perplexity4.786645412445068
INFO:root:current mean train loss 1987.8127652681792
INFO:root:current train perplexity4.794121265411377
INFO:root:current mean train loss 1997.91303380024
INFO:root:current train perplexity4.835453987121582
INFO:root:current mean train loss 2449.6903397300025
INFO:root:current train perplexity6.900722026824951
INFO:root:current mean train loss 2862.267394822644
INFO:root:current train perplexity9.556079864501953
INFO:root:current mean train loss 3171.2232020164024
INFO:root:current train perplexity12.18674373626709

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.22s/it]
INFO:root:final mean train loss: 3224.0466961728403
INFO:root:final train perplexity: 12.713659286499023
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.30s/it]
INFO:root:eval mean loss: 7520.378269060284
INFO:root:eval perplexity: 437.9219970703125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.36s/it]
INFO:root:eval mean loss: 7569.907920891512
INFO:root:eval perplexity: 488.2748107910156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/34
 17%|â–ˆâ–‹        | 34/200 [3:47:27<19:05:14, 413.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7712.050882711039
INFO:root:current train perplexity448.7433166503906
INFO:root:current mean train loss 7547.2545159119
INFO:root:current train perplexity397.31610107421875
INFO:root:current mean train loss 7478.146387423849
INFO:root:current train perplexity373.53271484375
INFO:root:current mean train loss 7500.732969734334
INFO:root:current train perplexity372.9148254394531
INFO:root:current mean train loss 7462.346228257665
INFO:root:current train perplexity358.685791015625
INFO:root:current mean train loss 7395.07061714688
INFO:root:current train perplexity339.54473876953125
INFO:root:current mean train loss 7322.066808703379
INFO:root:current train perplexity319.16082763671875
INFO:root:current mean train loss 7263.257522799026
INFO:root:current train perplexity306.40313720703125
INFO:root:current mean train loss 7225.161592142068
INFO:root:current train perplexity296.5865173339844
INFO:root:current mean train loss 7195.653440258764
INFO:root:current train perplexity290.01202392578125
INFO:root:current mean train loss 7166.150744254875
INFO:root:current train perplexity285.0841369628906
INFO:root:current mean train loss 7153.2627214482
INFO:root:current train perplexity281.35491943359375
INFO:root:current mean train loss 7140.48488660557
INFO:root:current train perplexity278.67596435546875
INFO:root:current mean train loss 7125.694385226602
INFO:root:current train perplexity276.52008056640625
INFO:root:current mean train loss 7126.176862278901
INFO:root:current train perplexity275.45648193359375
INFO:root:current mean train loss 7119.271047491777
INFO:root:current train perplexity274.57733154296875
INFO:root:current mean train loss 7113.425845305978
INFO:root:current train perplexity273.4938049316406
INFO:root:current mean train loss 7112.163340382315
INFO:root:current train perplexity272.675537109375
INFO:root:current mean train loss 7112.724869254046
INFO:root:current train perplexity271.99066162109375
INFO:root:current mean train loss 7106.18362931525
INFO:root:current train perplexity271.1312255859375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.86s/it]
INFO:root:final mean train loss: 7103.59807632454
INFO:root:final train perplexity: 271.0558776855469
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.29s/it]
INFO:root:eval mean loss: 6667.190334455341
INFO:root:eval perplexity: 219.6492919921875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.24s/it]
INFO:root:eval mean loss: 6748.916214746786
INFO:root:eval perplexity: 249.49769592285156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/35
 18%|â–ˆâ–Š        | 35/200 [3:54:27<19:03:52, 415.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7018.845484956782
INFO:root:current train perplexity255.7987823486328
INFO:root:current mean train loss 7000.719832272874
INFO:root:current train perplexity253.50503540039062
INFO:root:current mean train loss 6989.475675621811
INFO:root:current train perplexity250.892578125
INFO:root:current mean train loss 6995.244685913705
INFO:root:current train perplexity249.12049865722656
INFO:root:current mean train loss 6980.198770005693
INFO:root:current train perplexity248.11968994140625
INFO:root:current mean train loss 6989.002622251158
INFO:root:current train perplexity248.9318084716797
INFO:root:current mean train loss 6994.325752544129
INFO:root:current train perplexity250.23294067382812
INFO:root:current mean train loss 7005.373778681911
INFO:root:current train perplexity251.68678283691406
INFO:root:current mean train loss 7018.073631610913
INFO:root:current train perplexity252.69088745117188
INFO:root:current mean train loss 7020.3091738910025
INFO:root:current train perplexity253.4270782470703
INFO:root:current mean train loss 7020.083688460495
INFO:root:current train perplexity254.0312957763672
INFO:root:current mean train loss 7023.525122356575
INFO:root:current train perplexity254.15438842773438
INFO:root:current mean train loss 7021.997704247971
INFO:root:current train perplexity254.00404357910156
INFO:root:current mean train loss 7019.408644469602
INFO:root:current train perplexity253.74618530273438
INFO:root:current mean train loss 7020.236905957162
INFO:root:current train perplexity252.9643096923828
INFO:root:current mean train loss 7012.058235350337
INFO:root:current train perplexity251.1855010986328
INFO:root:current mean train loss 6992.411297110205
INFO:root:current train perplexity247.68409729003906
INFO:root:current mean train loss 6948.254916834327
INFO:root:current train perplexity239.34002685546875
INFO:root:current mean train loss 6850.539534281778
INFO:root:current train perplexity221.50559997558594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:10<00:00, 370.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:10<00:00, 370.25s/it]
INFO:root:final mean train loss: 6729.540345561787
INFO:root:final train perplexity: 201.80868530273438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.90s/it]
INFO:root:eval mean loss: 3114.5947897620235
INFO:root:eval perplexity: 12.414949417114258
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.30s/it]
INFO:root:eval mean loss: 3441.308000280502
INFO:root:eval perplexity: 16.683101654052734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/36
 18%|â–ˆâ–Š        | 36/200 [4:01:38<19:09:04, 420.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3915.0364213423295
INFO:root:current train perplexity22.257850646972656
INFO:root:current mean train loss 3764.994554124437
INFO:root:current train perplexity19.543018341064453
INFO:root:current mean train loss 3595.945849377962
INFO:root:current train perplexity16.82256317138672
INFO:root:current mean train loss 3469.3668546523313
INFO:root:current train perplexity15.250368118286133
INFO:root:current mean train loss 3375.978510278855
INFO:root:current train perplexity14.182682037353516
INFO:root:current mean train loss 3295.761822426156
INFO:root:current train perplexity13.329392433166504
INFO:root:current mean train loss 3230.153172869144
INFO:root:current train perplexity12.720247268676758
INFO:root:current mean train loss 3182.143610314478
INFO:root:current train perplexity12.261894226074219
INFO:root:current mean train loss 3139.308189156905
INFO:root:current train perplexity11.88111686706543
INFO:root:current mean train loss 3099.7549447186298
INFO:root:current train perplexity11.535965919494629
INFO:root:current mean train loss 3068.915904542223
INFO:root:current train perplexity11.246235847473145
INFO:root:current mean train loss 3041.9410909108487
INFO:root:current train perplexity10.983519554138184
INFO:root:current mean train loss 3015.495196820487
INFO:root:current train perplexity10.74407958984375
INFO:root:current mean train loss 2991.4204200261606
INFO:root:current train perplexity10.545623779296875
INFO:root:current mean train loss 2968.8650257048416
INFO:root:current train perplexity10.374324798583984
INFO:root:current mean train loss 2947.233477771085
INFO:root:current train perplexity10.217065811157227
INFO:root:current mean train loss 2930.663457528321
INFO:root:current train perplexity10.077287673950195
INFO:root:current mean train loss 2912.4791794135376
INFO:root:current train perplexity9.941082954406738
INFO:root:current mean train loss 2897.2022352550384
INFO:root:current train perplexity9.815468788146973
INFO:root:current mean train loss 2887.248009059393
INFO:root:current train perplexity9.74625015258789

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.83s/it]
INFO:root:final mean train loss: 2883.9388968832736
INFO:root:final train perplexity: 9.722545623779297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.75s/it]
INFO:root:eval mean loss: 2406.912040115248
INFO:root:eval perplexity: 7.004613876342773
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it]
INFO:root:eval mean loss: 2813.378172529505
INFO:root:eval perplexity: 9.982744216918945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/37
 18%|â–ˆâ–Š        | 37/200 [4:08:39<19:02:21, 420.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2952.542410714286
INFO:root:current train perplexity10.065584182739258
INFO:root:current mean train loss 2849.1707286834717
INFO:root:current train perplexity9.54178237915039
INFO:root:current mean train loss 2858.6949473598547
INFO:root:current train perplexity9.536911010742188
INFO:root:current mean train loss 2831.5029557390912
INFO:root:current train perplexity9.284758567810059
INFO:root:current mean train loss 2826.668941319546
INFO:root:current train perplexity9.259270668029785
INFO:root:current mean train loss 2813.7681718306108
INFO:root:current train perplexity9.175505638122559
INFO:root:current mean train loss 2804.9179364830065
INFO:root:current train perplexity9.122889518737793
INFO:root:current mean train loss 2810.433010562436
INFO:root:current train perplexity9.173263549804688
INFO:root:current mean train loss 2815.359439868282
INFO:root:current train perplexity9.207934379577637
INFO:root:current mean train loss 2874.8017714927937
INFO:root:current train perplexity9.632193565368652
INFO:root:current mean train loss 3004.450838675295
INFO:root:current train perplexity10.669703483581543
INFO:root:current mean train loss 3005.5237612893397
INFO:root:current train perplexity10.672298431396484
INFO:root:current mean train loss 2999.535160623855
INFO:root:current train perplexity10.629324913024902
INFO:root:current mean train loss 2994.6815229668673
INFO:root:current train perplexity10.57802963256836
INFO:root:current mean train loss 2983.770342145647
INFO:root:current train perplexity10.48764419555664
INFO:root:current mean train loss 2972.9832718934063
INFO:root:current train perplexity10.413935661315918
INFO:root:current mean train loss 2966.8864926049982
INFO:root:current train perplexity10.369802474975586
INFO:root:current mean train loss 2957.4463033322936
INFO:root:current train perplexity10.304542541503906
INFO:root:current mean train loss 2950.193756170294
INFO:root:current train perplexity10.237578392028809
INFO:root:current mean train loss 2943.8892983084397
INFO:root:current train perplexity10.185540199279785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.89s/it]
INFO:root:final mean train loss: 2942.72476930373
INFO:root:final train perplexity: 10.183917999267578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.47s/it]
INFO:root:eval mean loss: 2427.4002936613474
INFO:root:eval perplexity: 7.121645450592041
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.58s/it]
INFO:root:eval mean loss: 2833.3685475883753
INFO:root:eval perplexity: 10.147292137145996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/38
 19%|â–ˆâ–‰        | 38/200 [4:15:19<18:38:49, 414.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2836.239328342014
INFO:root:current train perplexity9.263956069946289
INFO:root:current mean train loss 2841.723876953125
INFO:root:current train perplexity9.314452171325684
INFO:root:current mean train loss 2844.4399663185586
INFO:root:current train perplexity9.385939598083496
INFO:root:current mean train loss 2851.480718551857
INFO:root:current train perplexity9.47442626953125
INFO:root:current mean train loss 2849.5300655064957
INFO:root:current train perplexity9.464485168457031
INFO:root:current mean train loss 2848.1124027917144
INFO:root:current train perplexity9.452432632446289
INFO:root:current mean train loss 2850.0044369246607
INFO:root:current train perplexity9.448624610900879
INFO:root:current mean train loss 2847.311101680474
INFO:root:current train perplexity9.435079574584961
INFO:root:current mean train loss 2844.5695873012205
INFO:root:current train perplexity9.419305801391602
INFO:root:current mean train loss 2843.507585410466
INFO:root:current train perplexity9.391539573669434
INFO:root:current mean train loss 2841.358155698639
INFO:root:current train perplexity9.376729011535645
INFO:root:current mean train loss 2841.2708670936818
INFO:root:current train perplexity9.37034797668457
INFO:root:current mean train loss 2838.157545808233
INFO:root:current train perplexity9.343088150024414
INFO:root:current mean train loss 2833.634570494017
INFO:root:current train perplexity9.31466293334961
INFO:root:current mean train loss 2830.3094267003676
INFO:root:current train perplexity9.2919340133667
INFO:root:current mean train loss 2825.9675803372775
INFO:root:current train perplexity9.267813682556152
INFO:root:current mean train loss 2819.44740795379
INFO:root:current train perplexity9.222017288208008
INFO:root:current mean train loss 2812.756319114882
INFO:root:current train perplexity9.183184623718262
INFO:root:current mean train loss 2808.391795154768
INFO:root:current train perplexity9.14933967590332
INFO:root:current mean train loss 2802.2754483651993
INFO:root:current train perplexity9.111838340759277

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.23s/it]
INFO:root:final mean train loss: 2799.3618835664674
INFO:root:final train perplexity: 9.095186233520508
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.63s/it]
INFO:root:eval mean loss: 2348.7260902350677
INFO:root:eval perplexity: 6.68263053894043
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.71s/it]
INFO:root:eval mean loss: 2758.4901239922706
INFO:root:eval perplexity: 9.544537544250488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/39
 20%|â–ˆâ–‰        | 39/200 [4:21:59<18:20:07, 409.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2700.267755323841
INFO:root:current train perplexity8.415172576904297
INFO:root:current mean train loss 2714.737981348862
INFO:root:current train perplexity8.521281242370605
INFO:root:current mean train loss 2699.0149997390863
INFO:root:current train perplexity8.457754135131836
INFO:root:current mean train loss 2697.097242155128
INFO:root:current train perplexity8.43945026397705
INFO:root:current mean train loss 2694.5022226308847
INFO:root:current train perplexity8.387850761413574
INFO:root:current mean train loss 2685.990870791398
INFO:root:current train perplexity8.357958793640137
INFO:root:current mean train loss 2680.05682465245
INFO:root:current train perplexity8.310330390930176
INFO:root:current mean train loss 2678.3430758899276
INFO:root:current train perplexity8.284162521362305
INFO:root:current mean train loss 2676.7578640470924
INFO:root:current train perplexity8.25809097290039
INFO:root:current mean train loss 2673.338535237461
INFO:root:current train perplexity8.23957633972168
INFO:root:current mean train loss 2671.4470835540255
INFO:root:current train perplexity8.227108001708984
INFO:root:current mean train loss 2671.754996898868
INFO:root:current train perplexity8.239338874816895
INFO:root:current mean train loss 2669.501969568703
INFO:root:current train perplexity8.238849639892578
INFO:root:current mean train loss 2670.2009381309654
INFO:root:current train perplexity8.23569393157959
INFO:root:current mean train loss 2672.7907619658963
INFO:root:current train perplexity8.242959976196289
INFO:root:current mean train loss 2673.830351493728
INFO:root:current train perplexity8.236159324645996
INFO:root:current mean train loss 2674.0319380593787
INFO:root:current train perplexity8.237631797790527
INFO:root:current mean train loss 2676.0016754531425
INFO:root:current train perplexity8.24588680267334
INFO:root:current mean train loss 2675.7345986863083
INFO:root:current train perplexity8.245393753051758
INFO:root:current mean train loss 2676.30488385775
INFO:root:current train perplexity8.244634628295898

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.44s/it]
INFO:root:final mean train loss: 2674.993904856318
INFO:root:final train perplexity: 8.24544620513916
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it]
INFO:root:eval mean loss: 2314.390550545767
INFO:root:eval perplexity: 6.499616622924805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.47s/it]
INFO:root:eval mean loss: 2729.4580355164007
INFO:root:eval perplexity: 9.320590019226074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/40
 20%|â–ˆâ–ˆ        | 40/200 [4:28:32<17:59:54, 404.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2665.8230598546284
INFO:root:current train perplexity8.23334789276123
INFO:root:current mean train loss 2673.426946032647
INFO:root:current train perplexity8.24377727508545
INFO:root:current mean train loss 2660.178192904346
INFO:root:current train perplexity8.157865524291992
INFO:root:current mean train loss 2669.845219352944
INFO:root:current train perplexity8.178662300109863
INFO:root:current mean train loss 2668.0329080155598
INFO:root:current train perplexity8.176427841186523
INFO:root:current mean train loss 2667.8056880970694
INFO:root:current train perplexity8.175463676452637
INFO:root:current mean train loss 2672.5416362239966
INFO:root:current train perplexity8.186837196350098
INFO:root:current mean train loss 2668.9207931342266
INFO:root:current train perplexity8.167738914489746
INFO:root:current mean train loss 2664.637271191073
INFO:root:current train perplexity8.143844604492188
INFO:root:current mean train loss 2667.354681963818
INFO:root:current train perplexity8.15727424621582
INFO:root:current mean train loss 2668.4470124337495
INFO:root:current train perplexity8.168441772460938
INFO:root:current mean train loss 2667.9081254721295
INFO:root:current train perplexity8.16920280456543
INFO:root:current mean train loss 2669.331298446357
INFO:root:current train perplexity8.187689781188965
INFO:root:current mean train loss 2670.5349333543895
INFO:root:current train perplexity8.200392723083496
INFO:root:current mean train loss 2672.447955953664
INFO:root:current train perplexity8.213752746582031
INFO:root:current mean train loss 2671.5622192150886
INFO:root:current train perplexity8.221611022949219
INFO:root:current mean train loss 2675.2857172354265
INFO:root:current train perplexity8.238495826721191
INFO:root:current mean train loss 2676.684046624684
INFO:root:current train perplexity8.248197555541992
INFO:root:current mean train loss 2675.7362975911806
INFO:root:current train perplexity8.250675201416016
INFO:root:current mean train loss 2676.371069200235
INFO:root:current train perplexity8.2500638961792

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.56s/it]
INFO:root:final mean train loss: 2675.8289639794702
INFO:root:final train perplexity: 8.250880241394043
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.89s/it]
INFO:root:eval mean loss: 2291.4999813864415
INFO:root:eval perplexity: 6.38040018081665
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.33s/it]
INFO:root:eval mean loss: 2708.7562286160514
INFO:root:eval perplexity: 9.164114952087402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/41
 20%|â–ˆâ–ˆ        | 41/200 [4:35:15<17:51:31, 404.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2687.4541956583657
INFO:root:current train perplexity8.38077449798584
INFO:root:current mean train loss 2692.8529463787468
INFO:root:current train perplexity8.386539459228516
INFO:root:current mean train loss 2687.021283123944
INFO:root:current train perplexity8.363414764404297
INFO:root:current mean train loss 2689.5336353032276
INFO:root:current train perplexity8.343727111816406
INFO:root:current mean train loss 2690.909980035597
INFO:root:current train perplexity8.35452651977539
INFO:root:current mean train loss 2700.261983372221
INFO:root:current train perplexity8.393221855163574
INFO:root:current mean train loss 2700.676306012033
INFO:root:current train perplexity8.4225435256958
INFO:root:current mean train loss 2704.1796270782625
INFO:root:current train perplexity8.43982219696045
INFO:root:current mean train loss 2708.538538524083
INFO:root:current train perplexity8.472707748413086
INFO:root:current mean train loss 2715.3002787517257
INFO:root:current train perplexity8.511754035949707
INFO:root:current mean train loss 2715.1607997922133
INFO:root:current train perplexity8.515783309936523
INFO:root:current mean train loss 2716.2157643806177
INFO:root:current train perplexity8.513389587402344
INFO:root:current mean train loss 2714.2569205201703
INFO:root:current train perplexity8.50833511352539
INFO:root:current mean train loss 2711.9824043864164
INFO:root:current train perplexity8.488553047180176
INFO:root:current mean train loss 2709.6730784043907
INFO:root:current train perplexity8.459662437438965
INFO:root:current mean train loss 2705.7650135776453
INFO:root:current train perplexity8.445450782775879
INFO:root:current mean train loss 2704.252097363742
INFO:root:current train perplexity8.430625915527344
INFO:root:current mean train loss 2702.5075725733836
INFO:root:current train perplexity8.423133850097656
INFO:root:current mean train loss 2703.410997350508
INFO:root:current train perplexity8.431640625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.56s/it]
INFO:root:final mean train loss: 2702.8442880204393
INFO:root:final train perplexity: 8.428555488586426
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.59s/it]
INFO:root:eval mean loss: 2315.0450179729055
INFO:root:eval perplexity: 6.503057956695557
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.37s/it]
INFO:root:eval mean loss: 2729.8514040683176
INFO:root:eval perplexity: 9.323587417602539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/42
 21%|â–ˆâ–ˆ        | 42/200 [4:41:50<17:37:11, 401.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2718.8170635516826
INFO:root:current train perplexity8.644036293029785
INFO:root:current mean train loss 2705.5852504493914
INFO:root:current train perplexity8.46810531616211
INFO:root:current mean train loss 2710.36044555091
INFO:root:current train perplexity8.449528694152832
INFO:root:current mean train loss 2699.955085145018
INFO:root:current train perplexity8.40182876586914
INFO:root:current mean train loss 2697.651841872541
INFO:root:current train perplexity8.387092590332031
INFO:root:current mean train loss 2699.6700660750184
INFO:root:current train perplexity8.384875297546387
INFO:root:current mean train loss 2695.90958911093
INFO:root:current train perplexity8.363358497619629
INFO:root:current mean train loss 2694.541213197427
INFO:root:current train perplexity8.355982780456543
INFO:root:current mean train loss 2691.4533550267142
INFO:root:current train perplexity8.356450080871582
INFO:root:current mean train loss 2687.6857271058666
INFO:root:current train perplexity8.336004257202148
INFO:root:current mean train loss 2687.3862229975166
INFO:root:current train perplexity8.334238052368164
INFO:root:current mean train loss 2685.901460412806
INFO:root:current train perplexity8.311820030212402
INFO:root:current mean train loss 2683.1747378658283
INFO:root:current train perplexity8.288423538208008
INFO:root:current mean train loss 2682.8846259832562
INFO:root:current train perplexity8.28453540802002
INFO:root:current mean train loss 2683.4324380128164
INFO:root:current train perplexity8.282954216003418
INFO:root:current mean train loss 2682.5150445810787
INFO:root:current train perplexity8.286786079406738
INFO:root:current mean train loss 2682.2578476150807
INFO:root:current train perplexity8.281160354614258
INFO:root:current mean train loss 2681.2509112873067
INFO:root:current train perplexity8.279265403747559
INFO:root:current mean train loss 2681.138894739167
INFO:root:current train perplexity8.276860237121582
INFO:root:current mean train loss 2679.315445895477
INFO:root:current train perplexity8.262462615966797

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.50s/it]
INFO:root:final mean train loss: 2676.702092788704
INFO:root:final train perplexity: 8.256561279296875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.02s/it]
INFO:root:eval mean loss: 2292.0340576171875
INFO:root:eval perplexity: 6.383155822753906
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it]
INFO:root:eval mean loss: 2707.6738670836103
INFO:root:eval perplexity: 9.156005859375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/43
 22%|â–ˆâ–ˆâ–       | 43/200 [4:48:34<17:32:54, 402.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2729.210310872396
INFO:root:current train perplexity8.35447883605957
INFO:root:current mean train loss 2690.6736853966345
INFO:root:current train perplexity8.339616775512695
INFO:root:current mean train loss 2670.852098547894
INFO:root:current train perplexity8.295522689819336
INFO:root:current mean train loss 2669.9730646306816
INFO:root:current train perplexity8.265477180480957
INFO:root:current mean train loss 2668.9670529387718
INFO:root:current train perplexity8.249544143676758
INFO:root:current mean train loss 2670.2925403522995
INFO:root:current train perplexity8.251977920532227
INFO:root:current mean train loss 2673.5852395678326
INFO:root:current train perplexity8.246979713439941
INFO:root:current mean train loss 2672.786252876177
INFO:root:current train perplexity8.242918968200684
INFO:root:current mean train loss 2676.227891448607
INFO:root:current train perplexity8.247518539428711
INFO:root:current mean train loss 2675.2740412886424
INFO:root:current train perplexity8.243022918701172
INFO:root:current mean train loss 2678.243069250607
INFO:root:current train perplexity8.253941535949707
INFO:root:current mean train loss 2680.128341269704
INFO:root:current train perplexity8.265582084655762
INFO:root:current mean train loss 2681.6927932863314
INFO:root:current train perplexity8.26965618133545
INFO:root:current mean train loss 2680.897315003818
INFO:root:current train perplexity8.269847869873047
INFO:root:current mean train loss 2680.1468789267374
INFO:root:current train perplexity8.27073860168457
INFO:root:current mean train loss 2679.712602124183
INFO:root:current train perplexity8.274673461914062
INFO:root:current mean train loss 2680.6729850160564
INFO:root:current train perplexity8.28477668762207
INFO:root:current mean train loss 2682.273505944048
INFO:root:current train perplexity8.296399116516113
INFO:root:current mean train loss 2684.9251072617826
INFO:root:current train perplexity8.309331893920898
INFO:root:current mean train loss 2686.241690616904
INFO:root:current train perplexity8.318838119506836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.41s/it]
INFO:root:final mean train loss: 2686.8801428967513
INFO:root:final train perplexity: 8.323103904724121
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.44s/it]
INFO:root:eval mean loss: 2299.95149696296
INFO:root:eval perplexity: 6.424160480499268
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it]
INFO:root:eval mean loss: 2717.3304850260415
INFO:root:eval perplexity: 9.22860336303711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/44
 22%|â–ˆâ–ˆâ–       | 44/200 [4:55:10<17:21:05, 400.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2704.98873316988
INFO:root:current train perplexity8.618165969848633
INFO:root:current mean train loss 2739.4477206898387
INFO:root:current train perplexity8.674116134643555
INFO:root:current mean train loss 2725.617833929023
INFO:root:current train perplexity8.579446792602539
INFO:root:current mean train loss 2727.3183460070695
INFO:root:current train perplexity8.549339294433594
INFO:root:current mean train loss 2726.5651882777543
INFO:root:current train perplexity8.562868118286133
INFO:root:current mean train loss 2728.3743131034335
INFO:root:current train perplexity8.575990676879883
INFO:root:current mean train loss 2724.1781441690014
INFO:root:current train perplexity8.55104923248291
INFO:root:current mean train loss 2721.6478828726363
INFO:root:current train perplexity8.545495986938477
INFO:root:current mean train loss 2721.4356195118803
INFO:root:current train perplexity8.564593315124512
INFO:root:current mean train loss 2725.99376577762
INFO:root:current train perplexity8.581893920898438
INFO:root:current mean train loss 2727.5879659424995
INFO:root:current train perplexity8.594386100769043
INFO:root:current mean train loss 2725.443354905119
INFO:root:current train perplexity8.58489990234375
INFO:root:current mean train loss 2726.158737610891
INFO:root:current train perplexity8.586542129516602
INFO:root:current mean train loss 2725.2807082506843
INFO:root:current train perplexity8.581400871276855
INFO:root:current mean train loss 2725.1420933869103
INFO:root:current train perplexity8.57939624786377
INFO:root:current mean train loss 2728.136812018978
INFO:root:current train perplexity8.597662925720215
INFO:root:current mean train loss 2733.9024528498785
INFO:root:current train perplexity8.63398551940918
INFO:root:current mean train loss 2739.904561558654
INFO:root:current train perplexity8.673805236816406
INFO:root:current mean train loss 2741.761352076425
INFO:root:current train perplexity8.685203552246094
INFO:root:current mean train loss 2742.8992540607346
INFO:root:current train perplexity8.692588806152344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.28s/it]
INFO:root:final mean train loss: 2741.5394442852134
INFO:root:final train perplexity: 8.689740180969238
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it]
INFO:root:eval mean loss: 2324.18584815492
INFO:root:eval perplexity: 6.551310062408447
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it]
INFO:root:eval mean loss: 2738.5726482851287
INFO:root:eval perplexity: 9.390326499938965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [5:01:56<17:18:27, 401.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2697.2930335998535
INFO:root:current train perplexity8.58382797241211
INFO:root:current mean train loss 2748.9754504692264
INFO:root:current train perplexity8.744826316833496
INFO:root:current mean train loss 2768.438089081735
INFO:root:current train perplexity8.852083206176758
INFO:root:current mean train loss 2783.063531561212
INFO:root:current train perplexity8.960454940795898
INFO:root:current mean train loss 2806.6794444117054
INFO:root:current train perplexity9.145609855651855
INFO:root:current mean train loss 2812.9999939397717
INFO:root:current train perplexity9.208505630493164
INFO:root:current mean train loss 2821.4275277379047
INFO:root:current train perplexity9.292223930358887
INFO:root:current mean train loss 2821.506067086265
INFO:root:current train perplexity9.301786422729492
INFO:root:current mean train loss 2824.2300906711152
INFO:root:current train perplexity9.327345848083496
INFO:root:current mean train loss 2835.347251797118
INFO:root:current train perplexity9.379364967346191
INFO:root:current mean train loss 2843.9919247734815
INFO:root:current train perplexity9.4442777633667
INFO:root:current mean train loss 2850.2551651263157
INFO:root:current train perplexity9.487360000610352
INFO:root:current mean train loss 2855.984601564045
INFO:root:current train perplexity9.528047561645508
INFO:root:current mean train loss 2861.448703978418
INFO:root:current train perplexity9.567028999328613
INFO:root:current mean train loss 2868.2538035241632
INFO:root:current train perplexity9.617960929870605
INFO:root:current mean train loss 2871.5698443556685
INFO:root:current train perplexity9.641940116882324
INFO:root:current mean train loss 2876.7039093604453
INFO:root:current train perplexity9.673393249511719
INFO:root:current mean train loss 2880.017059810578
INFO:root:current train perplexity9.690946578979492
INFO:root:current mean train loss 2883.437572954039
INFO:root:current train perplexity9.710660934448242
INFO:root:current mean train loss 2886.5807379510884
INFO:root:current train perplexity9.736152648925781

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.28s/it]
INFO:root:final mean train loss: 2886.681645980581
INFO:root:final train perplexity: 9.74360179901123
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.63s/it]
INFO:root:eval mean loss: 2402.105609433871
INFO:root:eval perplexity: 6.9774394035339355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.03s/it]
INFO:root:eval mean loss: 2806.7723427630485
INFO:root:eval perplexity: 9.928959846496582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [5:08:29<17:04:54, 399.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2969.327733169367
INFO:root:current train perplexity10.503183364868164
INFO:root:current mean train loss 2995.659783969268
INFO:root:current train perplexity10.558067321777344
INFO:root:current mean train loss 3005.8334995690616
INFO:root:current train perplexity10.694960594177246
INFO:root:current mean train loss 3014.690032398294
INFO:root:current train perplexity10.797595977783203
INFO:root:current mean train loss 3017.8785453685355
INFO:root:current train perplexity10.800298690795898
INFO:root:current mean train loss 3012.041149251022
INFO:root:current train perplexity10.774739265441895
INFO:root:current mean train loss 3004.457472567341
INFO:root:current train perplexity10.73315715789795
INFO:root:current mean train loss 3007.9694399082705
INFO:root:current train perplexity10.724331855773926
INFO:root:current mean train loss 3009.6010043851093
INFO:root:current train perplexity10.754366874694824
INFO:root:current mean train loss 3015.1865799307943
INFO:root:current train perplexity10.791622161865234
INFO:root:current mean train loss 3020.3060233851033
INFO:root:current train perplexity10.832447052001953
INFO:root:current mean train loss 3022.367463269343
INFO:root:current train perplexity10.86531925201416
INFO:root:current mean train loss 3031.1275155441917
INFO:root:current train perplexity10.940764427185059
INFO:root:current mean train loss 3044.854989838376
INFO:root:current train perplexity11.04755687713623
INFO:root:current mean train loss 3053.277325616665
INFO:root:current train perplexity11.11927318572998
INFO:root:current mean train loss 3065.858176224749
INFO:root:current train perplexity11.216769218444824
INFO:root:current mean train loss 3077.8775371163465
INFO:root:current train perplexity11.326441764831543
INFO:root:current mean train loss 3088.053447605585
INFO:root:current train perplexity11.416424751281738
INFO:root:current mean train loss 3097.885224313447
INFO:root:current train perplexity11.503507614135742
INFO:root:current mean train loss 3104.8188007013896
INFO:root:current train perplexity11.565473556518555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.39s/it]
INFO:root:final mean train loss: 3104.0104019542086
INFO:root:final train perplexity: 11.565299987792969
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.86s/it]
INFO:root:eval mean loss: 2516.3017227497508
INFO:root:eval perplexity: 7.652535438537598
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.98s/it]
INFO:root:eval mean loss: 2915.0573462087214
INFO:root:eval perplexity: 10.84836196899414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [5:15:01<16:52:56, 397.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3237.109880719866
INFO:root:current train perplexity12.510334968566895
INFO:root:current mean train loss 3232.6357976740055
INFO:root:current train perplexity12.683232307434082
INFO:root:current mean train loss 3217.784310769715
INFO:root:current train perplexity12.700140953063965
INFO:root:current mean train loss 3243.898768746074
INFO:root:current train perplexity12.850814819335938
INFO:root:current mean train loss 3247.444656555911
INFO:root:current train perplexity12.90096378326416
INFO:root:current mean train loss 3242.6859522790814
INFO:root:current train perplexity12.874873161315918
INFO:root:current mean train loss 3243.5595105015445
INFO:root:current train perplexity12.909459114074707
INFO:root:current mean train loss 3248.5773313899986
INFO:root:current train perplexity12.964929580688477
INFO:root:current mean train loss 3249.87983632247
INFO:root:current train perplexity12.976099014282227
INFO:root:current mean train loss 3249.0326522184996
INFO:root:current train perplexity12.990641593933105
INFO:root:current mean train loss 3255.6821151205318
INFO:root:current train perplexity13.034964561462402
INFO:root:current mean train loss 3258.1968032251016
INFO:root:current train perplexity13.056665420532227
INFO:root:current mean train loss 3260.5886822951775
INFO:root:current train perplexity13.075752258300781
INFO:root:current mean train loss 3265.664948251967
INFO:root:current train perplexity13.120377540588379
INFO:root:current mean train loss 3269.9086288228054
INFO:root:current train perplexity13.168246269226074
INFO:root:current mean train loss 3274.363830337238
INFO:root:current train perplexity13.208425521850586
INFO:root:current mean train loss 3280.0667106349842
INFO:root:current train perplexity13.2641019821167
INFO:root:current mean train loss 3281.252903073728
INFO:root:current train perplexity13.280635833740234
INFO:root:current mean train loss 3285.430342486334
INFO:root:current train perplexity13.327765464782715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:46<00:00, 346.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:46<00:00, 346.49s/it]
INFO:root:final mean train loss: 3286.751773805373
INFO:root:final train perplexity: 13.358197212219238
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.43s/it]
INFO:root:eval mean loss: 2573.109231286015
INFO:root:eval perplexity: 8.012313842773438
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.82s/it]
INFO:root:eval mean loss: 2961.864239631815
INFO:root:eval perplexity: 11.271685600280762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/48
 24%|â–ˆâ–ˆâ–       | 48/200 [5:21:43<16:49:53, 398.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3292.4731608072916
INFO:root:current train perplexity13.697708129882812
INFO:root:current mean train loss 3410.862260105299
INFO:root:current train perplexity14.376388549804688
INFO:root:current mean train loss 3377.84698287609
INFO:root:current train perplexity14.195719718933105
INFO:root:current mean train loss 3375.8901235429066
INFO:root:current train perplexity14.286541938781738
INFO:root:current mean train loss 3378.3141019154746
INFO:root:current train perplexity14.380324363708496
INFO:root:current mean train loss 3373.4879318681737
INFO:root:current train perplexity14.375312805175781
INFO:root:current mean train loss 3366.215126397358
INFO:root:current train perplexity14.326347351074219
INFO:root:current mean train loss 3371.418911849869
INFO:root:current train perplexity14.329391479492188
INFO:root:current mean train loss 3365.444586368865
INFO:root:current train perplexity14.25328540802002
INFO:root:current mean train loss 3369.4584872886785
INFO:root:current train perplexity14.26733684539795
INFO:root:current mean train loss 3371.0202550127
INFO:root:current train perplexity14.281232833862305
INFO:root:current mean train loss 3367.509281503994
INFO:root:current train perplexity14.251681327819824
INFO:root:current mean train loss 3369.0841171955376
INFO:root:current train perplexity14.249054908752441
INFO:root:current mean train loss 3367.8352501930844
INFO:root:current train perplexity14.25512409210205
INFO:root:current mean train loss 3370.56788938273
INFO:root:current train perplexity14.266840934753418
INFO:root:current mean train loss 3369.6283728470503
INFO:root:current train perplexity14.248912811279297
INFO:root:current mean train loss 3371.863510424729
INFO:root:current train perplexity14.264969825744629
INFO:root:current mean train loss 3368.398785275829
INFO:root:current train perplexity14.244928359985352
INFO:root:current mean train loss 3370.1586733815425
INFO:root:current train perplexity14.260661125183105
INFO:root:current mean train loss 3372.047254788471
INFO:root:current train perplexity14.275568008422852

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.73s/it]
INFO:root:final mean train loss: 3372.909849566038
INFO:root:final train perplexity: 14.297429084777832
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it]
INFO:root:eval mean loss: 2641.8130272398603
INFO:root:eval perplexity: 8.470108032226562
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.51s/it]
INFO:root:eval mean loss: 3016.910295202377
INFO:root:eval perplexity: 11.790712356567383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/49
 24%|â–ˆâ–ˆâ–       | 49/200 [5:28:17<16:39:22, 397.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3525.946792602539
INFO:root:current train perplexity15.58743953704834
INFO:root:current mean train loss 3431.518895004735
INFO:root:current train perplexity14.831768035888672
INFO:root:current mean train loss 3429.5963050579203
INFO:root:current train perplexity14.745054244995117
INFO:root:current mean train loss 3422.2927863798946
INFO:root:current train perplexity14.762377738952637
INFO:root:current mean train loss 3420.406520702221
INFO:root:current train perplexity14.85217571258545
INFO:root:current mean train loss 3438.392071028401
INFO:root:current train perplexity15.013400077819824
INFO:root:current mean train loss 3438.2622081901454
INFO:root:current train perplexity15.011327743530273
INFO:root:current mean train loss 3448.5293672488688
INFO:root:current train perplexity15.09672737121582
INFO:root:current mean train loss 3465.831951434796
INFO:root:current train perplexity15.254321098327637
INFO:root:current mean train loss 3473.1986806975924
INFO:root:current train perplexity15.3756742477417
INFO:root:current mean train loss 3483.2578446735706
INFO:root:current train perplexity15.484408378601074
INFO:root:current mean train loss 3481.2002990506985
INFO:root:current train perplexity15.519960403442383
INFO:root:current mean train loss 3484.266567874264
INFO:root:current train perplexity15.563431739807129
INFO:root:current mean train loss 3489.6594027499177
INFO:root:current train perplexity15.631547927856445
INFO:root:current mean train loss 3496.113346376899
INFO:root:current train perplexity15.705791473388672
INFO:root:current mean train loss 3497.2960947699084
INFO:root:current train perplexity15.737622261047363
INFO:root:current mean train loss 3500.7335574580175
INFO:root:current train perplexity15.7927885055542
INFO:root:current mean train loss 3505.208270841603
INFO:root:current train perplexity15.8502197265625
INFO:root:current mean train loss 3509.6303257838085
INFO:root:current train perplexity15.90405559539795
INFO:root:current mean train loss 3512.178397547878
INFO:root:current train perplexity15.94677448272705

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.48s/it]
INFO:root:final mean train loss: 3514.027590476078
INFO:root:final train perplexity: 15.980571746826172
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.65s/it]
INFO:root:eval mean loss: 2723.8557241453345
INFO:root:eval perplexity: 9.051176071166992
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.22s/it]
INFO:root:eval mean loss: 3080.921791455424
INFO:root:eval perplexity: 12.42440414428711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [5:34:49<16:29:18, 395.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3619.2811453683034
INFO:root:current train perplexity17.495946884155273
INFO:root:current mean train loss 3587.0449349832215
INFO:root:current train perplexity16.868200302124023
INFO:root:current mean train loss 3581.13705015374
INFO:root:current train perplexity16.836545944213867
INFO:root:current mean train loss 3558.4027683728063
INFO:root:current train perplexity16.604333877563477
INFO:root:current mean train loss 3550.1882231782433
INFO:root:current train perplexity16.45622444152832
INFO:root:current mean train loss 3545.758152695953
INFO:root:current train perplexity16.385343551635742
INFO:root:current mean train loss 3546.5233991296705
INFO:root:current train perplexity16.39216423034668
INFO:root:current mean train loss 3541.4513609291557
INFO:root:current train perplexity16.339231491088867
INFO:root:current mean train loss 3543.5099413257326
INFO:root:current train perplexity16.35824966430664
INFO:root:current mean train loss 3541.6492715399436
INFO:root:current train perplexity16.31859016418457
INFO:root:current mean train loss 3545.0912068878843
INFO:root:current train perplexity16.352256774902344
INFO:root:current mean train loss 3545.934392678416
INFO:root:current train perplexity16.36797523498535
INFO:root:current mean train loss 3546.7992372413555
INFO:root:current train perplexity16.379148483276367
INFO:root:current mean train loss 3543.5186430052354
INFO:root:current train perplexity16.354251861572266
INFO:root:current mean train loss 3548.7006554560794
INFO:root:current train perplexity16.40277862548828
INFO:root:current mean train loss 3549.2468621073576
INFO:root:current train perplexity16.419795989990234
INFO:root:current mean train loss 3550.940238846223
INFO:root:current train perplexity16.435230255126953
INFO:root:current mean train loss 3549.623614721805
INFO:root:current train perplexity16.42063331604004
INFO:root:current mean train loss 3551.197063076748
INFO:root:current train perplexity16.44932746887207
INFO:root:current mean train loss 3553.5781833732844
INFO:root:current train perplexity16.472219467163086

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.40s/it]
INFO:root:final mean train loss: 3553.4288543070197
INFO:root:final train perplexity: 16.484949111938477
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.90s/it]
INFO:root:eval mean loss: 2752.5522036721522
INFO:root:eval perplexity: 9.263690948486328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it]
INFO:root:eval mean loss: 3113.40051485968
INFO:root:eval perplexity: 12.75883960723877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [5:41:34<16:29:27, 398.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3594.1966256806345
INFO:root:current train perplexity16.960491180419922
INFO:root:current mean train loss 3626.696459666792
INFO:root:current train perplexity17.254985809326172
INFO:root:current mean train loss 3632.3574246284657
INFO:root:current train perplexity17.444931030273438
INFO:root:current mean train loss 3635.842569986979
INFO:root:current train perplexity17.47174835205078
INFO:root:current mean train loss 3629.1889344571487
INFO:root:current train perplexity17.450334548950195
INFO:root:current mean train loss 3632.932064204671
INFO:root:current train perplexity17.500213623046875
INFO:root:current mean train loss 3636.8266007706925
INFO:root:current train perplexity17.538850784301758
INFO:root:current mean train loss 3645.0926943945824
INFO:root:current train perplexity17.645263671875
INFO:root:current mean train loss 3647.1127498353603
INFO:root:current train perplexity17.687349319458008
INFO:root:current mean train loss 3648.9389913807745
INFO:root:current train perplexity17.71074104309082
INFO:root:current mean train loss 3652.1005715089264
INFO:root:current train perplexity17.773794174194336
INFO:root:current mean train loss 3657.249360544195
INFO:root:current train perplexity17.829214096069336
INFO:root:current mean train loss 3662.817090268007
INFO:root:current train perplexity17.890390396118164
INFO:root:current mean train loss 3660.966011907485
INFO:root:current train perplexity17.893888473510742
INFO:root:current mean train loss 3662.361489997229
INFO:root:current train perplexity17.908695220947266
INFO:root:current mean train loss 3660.4337028805476
INFO:root:current train perplexity17.869340896606445
INFO:root:current mean train loss 3662.0418336279827
INFO:root:current train perplexity17.893415451049805
INFO:root:current mean train loss 3660.479216250531
INFO:root:current train perplexity17.88991355895996
INFO:root:current mean train loss 3657.3496882693175
INFO:root:current train perplexity17.86322784423828
INFO:root:current mean train loss 3656.1065106319143
INFO:root:current train perplexity17.860307693481445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.41s/it]
INFO:root:final mean train loss: 3655.482400945143
INFO:root:final train perplexity: 17.866601943969727
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.52s/it]
INFO:root:eval mean loss: 2801.7864912317154
INFO:root:eval perplexity: 9.639992713928223
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.21s/it]
INFO:root:eval mean loss: 3153.795414052111
INFO:root:eval perplexity: 13.187383651733398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [5:48:05<16:17:27, 396.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3714.474232868976
INFO:root:current train perplexity18.621910095214844
INFO:root:current mean train loss 3736.633455537056
INFO:root:current train perplexity18.856077194213867
INFO:root:current mean train loss 3754.9211296378094
INFO:root:current train perplexity19.11281967163086
INFO:root:current mean train loss 3752.6980331062337
INFO:root:current train perplexity19.129085540771484
INFO:root:current mean train loss 3752.220504981884
INFO:root:current train perplexity19.163862228393555
INFO:root:current mean train loss 3757.3233732612835
INFO:root:current train perplexity19.29352378845215
INFO:root:current mean train loss 3762.524897696857
INFO:root:current train perplexity19.339048385620117
INFO:root:current mean train loss 3761.231171862528
INFO:root:current train perplexity19.328630447387695
INFO:root:current mean train loss 3756.966226752725
INFO:root:current train perplexity19.259794235229492
INFO:root:current mean train loss 3763.5023872631614
INFO:root:current train perplexity19.327796936035156
INFO:root:current mean train loss 3766.843698827404
INFO:root:current train perplexity19.385154724121094
INFO:root:current mean train loss 3770.7747508651205
INFO:root:current train perplexity19.442527770996094
INFO:root:current mean train loss 3770.4294376507087
INFO:root:current train perplexity19.484485626220703
INFO:root:current mean train loss 3778.4593941005173
INFO:root:current train perplexity19.612916946411133
INFO:root:current mean train loss 3783.4518419035526
INFO:root:current train perplexity19.70682716369629
INFO:root:current mean train loss 3792.590949554347
INFO:root:current train perplexity19.87611198425293
INFO:root:current mean train loss 3799.5242900338403
INFO:root:current train perplexity19.999624252319336
INFO:root:current mean train loss 3806.327833345748
INFO:root:current train perplexity20.10426902770996
INFO:root:current mean train loss 3816.6574686286426
INFO:root:current train perplexity20.25340461730957
INFO:root:current mean train loss 3821.4748392340757
INFO:root:current train perplexity20.365558624267578

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.55s/it]
INFO:root:final mean train loss: 3821.4748392340757
INFO:root:final train perplexity: 20.365558624267578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.02s/it]
INFO:root:eval mean loss: 2948.337559043938
INFO:root:eval perplexity: 10.853011131286621
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.72s/it]
INFO:root:eval mean loss: 3276.531486348903
INFO:root:eval perplexity: 14.579806327819824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [5:54:38<16:08:46, 395.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4038.6748364257815
INFO:root:current train perplexity23.540416717529297
INFO:root:current mean train loss 3983.6914050292967
INFO:root:current train perplexity22.985227584838867
INFO:root:current mean train loss 3971.064522298177
INFO:root:current train perplexity22.998157501220703
INFO:root:current mean train loss 3987.1020458984376
INFO:root:current train perplexity23.05924415588379
INFO:root:current mean train loss 3983.5573896484375
INFO:root:current train perplexity23.073753356933594
INFO:root:current mean train loss 3989.727451171875
INFO:root:current train perplexity23.2043514251709
INFO:root:current mean train loss 3995.084750279018
INFO:root:current train perplexity23.29362678527832
INFO:root:current mean train loss 3993.48119140625
INFO:root:current train perplexity23.276138305664062
INFO:root:current mean train loss 3987.2686309136284
INFO:root:current train perplexity23.22273063659668
INFO:root:current mean train loss 3994.4843334960938
INFO:root:current train perplexity23.31684684753418
INFO:root:current mean train loss 3997.8033152077414
INFO:root:current train perplexity23.364381790161133
INFO:root:current mean train loss 4000.6315588378907
INFO:root:current train perplexity23.45332145690918
INFO:root:current mean train loss 3995.883640136719
INFO:root:current train perplexity23.40683364868164
INFO:root:current mean train loss 4002.55710710798
INFO:root:current train perplexity23.48348617553711
INFO:root:current mean train loss 3996.540311360677
INFO:root:current train perplexity23.407169342041016
INFO:root:current mean train loss 3996.215459289551
INFO:root:current train perplexity23.442163467407227
INFO:root:current mean train loss 3998.429637379366
INFO:root:current train perplexity23.456050872802734
INFO:root:current mean train loss 3999.681264512804
INFO:root:current train perplexity23.451705932617188
INFO:root:current mean train loss 4001.3343058696546
INFO:root:current train perplexity23.470651626586914

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.57s/it]
INFO:root:final mean train loss: 4002.311976507344
INFO:root:final train perplexity: 23.487394332885742
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.86s/it]
INFO:root:eval mean loss: 3046.7263633782136
INFO:root:eval perplexity: 11.75188159942627
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.62s/it]
INFO:root:eval mean loss: 3362.159926394199
INFO:root:eval perplexity: 15.637418746948242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [6:01:13<16:01:16, 395.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4109.03759765625
INFO:root:current train perplexity24.871692657470703
INFO:root:current mean train loss 4096.531318860177
INFO:root:current train perplexity24.856428146362305
INFO:root:current mean train loss 4060.9626341085827
INFO:root:current train perplexity24.36048698425293
INFO:root:current mean train loss 4063.8002174930994
INFO:root:current train perplexity24.491680145263672
INFO:root:current mean train loss 4063.863653608363
INFO:root:current train perplexity24.528419494628906
INFO:root:current mean train loss 4065.8837205897908
INFO:root:current train perplexity24.52802276611328
INFO:root:current mean train loss 4062.313302854665
INFO:root:current train perplexity24.48157501220703
INFO:root:current mean train loss 4053.5112161676257
INFO:root:current train perplexity24.41421127319336
INFO:root:current mean train loss 4047.1390182140262
INFO:root:current train perplexity24.354900360107422
INFO:root:current mean train loss 4049.092969921449
INFO:root:current train perplexity24.358325958251953
INFO:root:current mean train loss 4045.9164839813025
INFO:root:current train perplexity24.255767822265625
INFO:root:current mean train loss 4042.1096906124103
INFO:root:current train perplexity24.191896438598633
INFO:root:current mean train loss 4038.9053356261556
INFO:root:current train perplexity24.150802612304688
INFO:root:current mean train loss 4035.7091323053105
INFO:root:current train perplexity24.097387313842773
INFO:root:current mean train loss 4035.6235368791904
INFO:root:current train perplexity24.108304977416992
INFO:root:current mean train loss 4036.612060225002
INFO:root:current train perplexity24.130802154541016
INFO:root:current mean train loss 4040.5932567362884
INFO:root:current train perplexity24.172168731689453
INFO:root:current mean train loss 4040.9515169706883
INFO:root:current train perplexity24.182249069213867
INFO:root:current mean train loss 4041.9101645806104
INFO:root:current train perplexity24.1827449798584
INFO:root:current mean train loss 4040.8333055698195
INFO:root:current train perplexity24.18436050415039

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.74s/it]
INFO:root:final mean train loss: 4039.7853388322224
INFO:root:final train perplexity: 24.191890716552734
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.78s/it]
INFO:root:eval mean loss: 3099.114264738475
INFO:root:eval perplexity: 12.260488510131836
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.21s/it]
INFO:root:eval mean loss: 3406.7853276678857
INFO:root:eval perplexity: 16.21866226196289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [6:07:46<15:53:06, 394.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4198.049460018382
INFO:root:current train perplexity25.767555236816406
INFO:root:current mean train loss 4196.931870190066
INFO:root:current train perplexity26.503738403320312
INFO:root:current mean train loss 4165.869377462273
INFO:root:current train perplexity26.36020851135254
INFO:root:current mean train loss 4179.467339978247
INFO:root:current train perplexity26.512826919555664
INFO:root:current mean train loss 4187.10981827837
INFO:root:current train perplexity26.640422821044922
INFO:root:current mean train loss 4167.902486851153
INFO:root:current train perplexity26.392820358276367
INFO:root:current mean train loss 4164.004729935799
INFO:root:current train perplexity26.390291213989258
INFO:root:current mean train loss 4147.227297582808
INFO:root:current train perplexity26.089447021484375
INFO:root:current mean train loss 4133.626271346205
INFO:root:current train perplexity25.783159255981445
INFO:root:current mean train loss 4115.855102016278
INFO:root:current train perplexity25.443485260009766
INFO:root:current mean train loss 4094.772054587388
INFO:root:current train perplexity25.0640869140625
INFO:root:current mean train loss 4076.0774554432596
INFO:root:current train perplexity24.70530891418457
INFO:root:current mean train loss 4062.7569849147208
INFO:root:current train perplexity24.466264724731445
INFO:root:current mean train loss 4047.1683722957855
INFO:root:current train perplexity24.20676040649414
INFO:root:current mean train loss 4029.611582480714
INFO:root:current train perplexity23.91073226928711
INFO:root:current mean train loss 4017.9612468933346
INFO:root:current train perplexity23.72632598876953
INFO:root:current mean train loss 4012.3231314725654
INFO:root:current train perplexity23.6500244140625
INFO:root:current mean train loss 4010.447267032962
INFO:root:current train perplexity23.585203170776367
INFO:root:current mean train loss 4007.8603745921228
INFO:root:current train perplexity23.56867027282715
INFO:root:current mean train loss 4009.319284685642
INFO:root:current train perplexity23.591737747192383

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.91s/it]
INFO:root:final mean train loss: 4007.5864023274985
INFO:root:final train perplexity: 23.585298538208008
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it]
INFO:root:eval mean loss: 2997.9517069065823
INFO:root:eval perplexity: 11.29733943939209
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it]
INFO:root:eval mean loss: 3321.1986516857824
INFO:root:eval perplexity: 15.122254371643066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [6:14:18<15:45:26, 393.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4084.6706255744484
INFO:root:current train perplexity24.80316734313965
INFO:root:current mean train loss 4012.1639460885763
INFO:root:current train perplexity23.540523529052734
INFO:root:current mean train loss 4011.740498941733
INFO:root:current train perplexity23.523473739624023
INFO:root:current mean train loss 3995.2512791299414
INFO:root:current train perplexity23.372961044311523
INFO:root:current mean train loss 3994.396206671806
INFO:root:current train perplexity23.468435287475586
INFO:root:current mean train loss 3993.221401872306
INFO:root:current train perplexity23.42133140563965
INFO:root:current mean train loss 3999.4793691796276
INFO:root:current train perplexity23.508386611938477
INFO:root:current mean train loss 4004.9077161440996
INFO:root:current train perplexity23.661762237548828
INFO:root:current mean train loss 4012.0277669079574
INFO:root:current train perplexity23.78864288330078
INFO:root:current mean train loss 4017.4263971210403
INFO:root:current train perplexity23.8704833984375
INFO:root:current mean train loss 4022.117934324081
INFO:root:current train perplexity23.947324752807617
INFO:root:current mean train loss 4024.3137686403807
INFO:root:current train perplexity24.01487159729004
INFO:root:current mean train loss 4024.9026079917317
INFO:root:current train perplexity24.011476516723633
INFO:root:current mean train loss 4027.74725319208
INFO:root:current train perplexity24.033676147460938
INFO:root:current mean train loss 4028.223680429176
INFO:root:current train perplexity24.05126190185547
INFO:root:current mean train loss 4031.335436626068
INFO:root:current train perplexity24.074342727661133
INFO:root:current mean train loss 4033.3455335130698
INFO:root:current train perplexity24.10240936279297
INFO:root:current mean train loss 4030.3964509119787
INFO:root:current train perplexity24.05263900756836
INFO:root:current mean train loss 4031.5985981236918
INFO:root:current train perplexity24.072734832763672
INFO:root:current mean train loss 4038.565826744498
INFO:root:current train perplexity24.158058166503906

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.82s/it]
INFO:root:final mean train loss: 4039.6381613711665
INFO:root:final train perplexity: 24.189088821411133
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it]
INFO:root:eval mean loss: 3105.920486341977
INFO:root:eval perplexity: 12.328163146972656
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.99s/it]
INFO:root:eval mean loss: 3414.981048367548
INFO:root:eval perplexity: 16.327735900878906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [6:20:51<15:38:06, 393.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4135.1439208984375
INFO:root:current train perplexity26.14386749267578
INFO:root:current mean train loss 4089.052898588635
INFO:root:current train perplexity25.361801147460938
INFO:root:current mean train loss 4069.740789157241
INFO:root:current train perplexity24.864761352539062
INFO:root:current mean train loss 4078.651389080545
INFO:root:current train perplexity24.97092628479004
INFO:root:current mean train loss 4068.0671590169272
INFO:root:current train perplexity24.777250289916992
INFO:root:current mean train loss 4061.5304823324714
INFO:root:current train perplexity24.60956573486328
INFO:root:current mean train loss 4055.5025960042803
INFO:root:current train perplexity24.474700927734375
INFO:root:current mean train loss 4058.398378054301
INFO:root:current train perplexity24.459083557128906
INFO:root:current mean train loss 4054.595470516363
INFO:root:current train perplexity24.475749969482422
INFO:root:current mean train loss 4054.0739567023666
INFO:root:current train perplexity24.452302932739258
INFO:root:current mean train loss 4059.202571111672
INFO:root:current train perplexity24.50664520263672
INFO:root:current mean train loss 4065.760029413929
INFO:root:current train perplexity24.620576858520508
INFO:root:current mean train loss 4062.994522624211
INFO:root:current train perplexity24.599212646484375
INFO:root:current mean train loss 4058.81446044208
INFO:root:current train perplexity24.527151107788086
INFO:root:current mean train loss 4060.992630711693
INFO:root:current train perplexity24.546667098999023
INFO:root:current mean train loss 4058.0169629466777
INFO:root:current train perplexity24.49543571472168
INFO:root:current mean train loss 4057.1274370152314
INFO:root:current train perplexity24.485334396362305
INFO:root:current mean train loss 4060.554506051594
INFO:root:current train perplexity24.54801368713379
INFO:root:current mean train loss 4062.9715919903056
INFO:root:current train perplexity24.612764358520508
INFO:root:current mean train loss 4068.7413966481276
INFO:root:current train perplexity24.736759185791016

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.39s/it]
INFO:root:final mean train loss: 4068.8247312852604
INFO:root:final train perplexity: 24.75233268737793
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 3241.3370283410904
INFO:root:eval perplexity: 13.75500774383545
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it]
INFO:root:eval mean loss: 3541.1490430899544
INFO:root:eval perplexity: 18.10248565673828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [6:27:35<15:38:41, 396.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4179.450221162684
INFO:root:current train perplexity27.130523681640625
INFO:root:current mean train loss 4159.165180268159
INFO:root:current train perplexity26.513124465942383
INFO:root:current mean train loss 4157.741097005209
INFO:root:current train perplexity26.307764053344727
INFO:root:current mean train loss 4130.2598398183845
INFO:root:current train perplexity25.811752319335938
INFO:root:current mean train loss 4109.613499214723
INFO:root:current train perplexity25.397357940673828
INFO:root:current mean train loss 4078.6027477297007
INFO:root:current train perplexity24.887413024902344
INFO:root:current mean train loss 4059.3815814609943
INFO:root:current train perplexity24.505577087402344
INFO:root:current mean train loss 4040.8980328796774
INFO:root:current train perplexity24.13735580444336
INFO:root:current mean train loss 4019.1845821746997
INFO:root:current train perplexity23.738117218017578
INFO:root:current mean train loss 3999.849004848112
INFO:root:current train perplexity23.4178466796875
INFO:root:current mean train loss 3977.429620670723
INFO:root:current train perplexity22.99212646484375
INFO:root:current mean train loss 3958.2488827218485
INFO:root:current train perplexity22.66813087463379
INFO:root:current mean train loss 3937.3100004559824
INFO:root:current train perplexity22.316762924194336
INFO:root:current mean train loss 3923.3206629343413
INFO:root:current train perplexity22.050344467163086
INFO:root:current mean train loss 3906.192835089173
INFO:root:current train perplexity21.751964569091797
INFO:root:current mean train loss 3896.0451031705934
INFO:root:current train perplexity21.55812644958496
INFO:root:current mean train loss 3882.805323279859
INFO:root:current train perplexity21.325191497802734
INFO:root:current mean train loss 3869.0976130295867
INFO:root:current train perplexity21.07716178894043
INFO:root:current mean train loss 3855.196904011936
INFO:root:current train perplexity20.8658504486084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.23s/it]
INFO:root:final mean train loss: 3840.6320240599784
INFO:root:final train perplexity: 20.675580978393555
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2885.8588001440603
INFO:root:eval perplexity: 10.318239212036133
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.32s/it]
INFO:root:eval mean loss: 3232.372981511109
INFO:root:eval perplexity: 14.062665939331055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [6:34:10<15:30:53, 396.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3917.9215087890625
INFO:root:current train perplexity18.632612228393555
INFO:root:current mean train loss 3623.852014878217
INFO:root:current train perplexity17.31317138671875
INFO:root:current mean train loss 3594.3075918065438
INFO:root:current train perplexity17.19526481628418
INFO:root:current mean train loss 3599.5004793887106
INFO:root:current train perplexity17.209135055541992
INFO:root:current mean train loss 3610.23338993509
INFO:root:current train perplexity17.20480728149414
INFO:root:current mean train loss 3609.996343726656
INFO:root:current train perplexity17.18854331970215
INFO:root:current mean train loss 3610.086798886524
INFO:root:current train perplexity17.198856353759766
INFO:root:current mean train loss 3607.513562672498
INFO:root:current train perplexity17.177682876586914
INFO:root:current mean train loss 3607.362033149548
INFO:root:current train perplexity17.15433692932129
INFO:root:current mean train loss 3606.0775124831102
INFO:root:current train perplexity17.144182205200195
INFO:root:current mean train loss 3603.688337436455
INFO:root:current train perplexity17.121620178222656
INFO:root:current mean train loss 3603.6350483141446
INFO:root:current train perplexity17.09885025024414
INFO:root:current mean train loss 3602.6256324907704
INFO:root:current train perplexity17.117311477661133
INFO:root:current mean train loss 3603.402043918311
INFO:root:current train perplexity17.109661102294922
INFO:root:current mean train loss 3610.8881057543354
INFO:root:current train perplexity17.21072769165039
INFO:root:current mean train loss 3623.6171497898636
INFO:root:current train perplexity17.389705657958984
INFO:root:current mean train loss 3632.4715728569267
INFO:root:current train perplexity17.509328842163086
INFO:root:current mean train loss 3636.3889131467577
INFO:root:current train perplexity17.588069915771484
INFO:root:current mean train loss 3640.703504081836
INFO:root:current train perplexity17.660655975341797
INFO:root:current mean train loss 3641.51796333321
INFO:root:current train perplexity17.66953468322754

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.43s/it]
INFO:root:final mean train loss: 3642.504649875504
INFO:root:final train perplexity: 17.684673309326172
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.02s/it]
INFO:root:eval mean loss: 2876.707940284242
INFO:root:eval perplexity: 10.242157936096191
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.13s/it]
INFO:root:eval mean loss: 3214.478506967531
INFO:root:eval perplexity: 13.858362197875977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [6:40:55<15:30:17, 398.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3578.2547928659537
INFO:root:current train perplexity17.61949348449707
INFO:root:current mean train loss 3712.1946703486083
INFO:root:current train perplexity19.0074520111084
INFO:root:current mean train loss 3761.823393799943
INFO:root:current train perplexity19.56602668762207
INFO:root:current mean train loss 3767.877534776646
INFO:root:current train perplexity19.630779266357422
INFO:root:current mean train loss 3768.292599917027
INFO:root:current train perplexity19.636228561401367
INFO:root:current mean train loss 3781.6120690141797
INFO:root:current train perplexity19.765989303588867
INFO:root:current mean train loss 3789.392673966958
INFO:root:current train perplexity19.821435928344727
INFO:root:current mean train loss 3788.5545184012085
INFO:root:current train perplexity19.819942474365234
INFO:root:current mean train loss 3788.1734826317347
INFO:root:current train perplexity19.79891014099121
INFO:root:current mean train loss 3778.7660226915295
INFO:root:current train perplexity19.739526748657227
INFO:root:current mean train loss 3777.307241752407
INFO:root:current train perplexity19.7071475982666
INFO:root:current mean train loss 3779.1425855430352
INFO:root:current train perplexity19.722959518432617
INFO:root:current mean train loss 3779.7436315146892
INFO:root:current train perplexity19.700668334960938
INFO:root:current mean train loss 3781.295713157162
INFO:root:current train perplexity19.718713760375977
INFO:root:current mean train loss 3778.4910340688866
INFO:root:current train perplexity19.69577980041504
INFO:root:current mean train loss 3776.8526571950606
INFO:root:current train perplexity19.663494110107422
INFO:root:current mean train loss 3775.766533854569
INFO:root:current train perplexity19.6597900390625
INFO:root:current mean train loss 3779.4563224042413
INFO:root:current train perplexity19.698230743408203
INFO:root:current mean train loss 3779.973099837007
INFO:root:current train perplexity19.71196746826172
INFO:root:current mean train loss 3782.3608421337613
INFO:root:current train perplexity19.752601623535156

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.30s/it]
INFO:root:final mean train loss: 3784.9792496473933
INFO:root:final train perplexity: 19.78774070739746
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it]
INFO:root:eval mean loss: 2915.6113151387967
INFO:root:eval perplexity: 10.569528579711914
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.76s/it]
INFO:root:eval mean loss: 3253.951870532746
INFO:root:eval perplexity: 14.313042640686035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [6:47:30<15:21:12, 397.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3738.902981228299
INFO:root:current train perplexity19.666996002197266
INFO:root:current mean train loss 3764.310401467716
INFO:root:current train perplexity19.72784996032715
INFO:root:current mean train loss 3775.319872839976
INFO:root:current train perplexity19.84347915649414
INFO:root:current mean train loss 3786.052276611328
INFO:root:current train perplexity19.992095947265625
INFO:root:current mean train loss 3790.058044993549
INFO:root:current train perplexity20.049467086791992
INFO:root:current mean train loss 3788.5489410855876
INFO:root:current train perplexity20.10989761352539
INFO:root:current mean train loss 3781.777169857385
INFO:root:current train perplexity19.99566650390625
INFO:root:current mean train loss 3778.5241675998855
INFO:root:current train perplexity19.957002639770508
INFO:root:current mean train loss 3782.8081256191126
INFO:root:current train perplexity20.018409729003906
INFO:root:current mean train loss 3795.114203559028
INFO:root:current train perplexity20.094833374023438
INFO:root:current mean train loss 3798.5742057888665
INFO:root:current train perplexity20.12470817565918
INFO:root:current mean train loss 3800.2072882853763
INFO:root:current train perplexity20.098936080932617
INFO:root:current mean train loss 3802.710871724249
INFO:root:current train perplexity20.095457077026367
INFO:root:current mean train loss 3799.051877872673
INFO:root:current train perplexity20.040151596069336
INFO:root:current mean train loss 3799.105341749271
INFO:root:current train perplexity20.03056526184082
INFO:root:current mean train loss 3801.8809332847595
INFO:root:current train perplexity20.04024314880371
INFO:root:current mean train loss 3803.2404859771354
INFO:root:current train perplexity20.043386459350586
INFO:root:current mean train loss 3805.150610576577
INFO:root:current train perplexity20.057819366455078
INFO:root:current mean train loss 3800.537355377264
INFO:root:current train perplexity20.03620719909668
INFO:root:current mean train loss 3803.77703239504
INFO:root:current train perplexity20.060747146606445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.44s/it]
INFO:root:final mean train loss: 3803.6384847990143
INFO:root:final train perplexity: 20.081079483032227
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.06s/it]
INFO:root:eval mean loss: 2932.1972941946474
INFO:root:eval perplexity: 10.712260246276855
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.52s/it]
INFO:root:eval mean loss: 3270.6712096735096
INFO:root:eval perplexity: 14.510100364685059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [6:54:12<15:17:42, 399.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3872.009120725236
INFO:root:current train perplexity20.555641174316406
INFO:root:current mean train loss 3819.2843982970794
INFO:root:current train perplexity19.97698211669922
INFO:root:current mean train loss 3815.8634636317315
INFO:root:current train perplexity19.989580154418945
INFO:root:current mean train loss 3815.8614574572857
INFO:root:current train perplexity19.99485206604004
INFO:root:current mean train loss 3812.4481257760763
INFO:root:current train perplexity20.0152645111084
INFO:root:current mean train loss 3814.741870956007
INFO:root:current train perplexity20.047216415405273
INFO:root:current mean train loss 3815.9993958173814
INFO:root:current train perplexity20.098445892333984
INFO:root:current mean train loss 3805.6353284777556
INFO:root:current train perplexity20.036909103393555
INFO:root:current mean train loss 3808.2052212320486
INFO:root:current train perplexity20.080455780029297
INFO:root:current mean train loss 3809.0256232374736
INFO:root:current train perplexity20.065061569213867
INFO:root:current mean train loss 3809.317121051089
INFO:root:current train perplexity20.089153289794922
INFO:root:current mean train loss 3804.928952748943
INFO:root:current train perplexity20.079030990600586
INFO:root:current mean train loss 3802.6242925182687
INFO:root:current train perplexity20.054941177368164
INFO:root:current mean train loss 3805.845993098381
INFO:root:current train perplexity20.086997985839844
INFO:root:current mean train loss 3803.9082792404183
INFO:root:current train perplexity20.06376075744629
INFO:root:current mean train loss 3806.5844956082983
INFO:root:current train perplexity20.07505226135254
INFO:root:current mean train loss 3807.917999027573
INFO:root:current train perplexity20.083641052246094
INFO:root:current mean train loss 3807.2389665985543
INFO:root:current train perplexity20.091873168945312
INFO:root:current mean train loss 3804.283329213817
INFO:root:current train perplexity20.068002700805664
INFO:root:current mean train loss 3805.466326344886
INFO:root:current train perplexity20.090656280517578

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.46s/it]
INFO:root:final mean train loss: 3804.1485443038287
INFO:root:final train perplexity: 20.089157104492188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it]
INFO:root:eval mean loss: 2918.7673400446033
INFO:root:eval perplexity: 10.596539497375488
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.38s/it]
INFO:root:eval mean loss: 3257.8244325894834
INFO:root:eval perplexity: 14.35844612121582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [7:00:46<15:07:35, 397.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3815.487862723214
INFO:root:current train perplexity20.672771453857422
INFO:root:current mean train loss 3815.0863611557907
INFO:root:current train perplexity20.533296585083008
INFO:root:current mean train loss 3830.865687391493
INFO:root:current train perplexity20.67342185974121
INFO:root:current mean train loss 3842.4057564400337
INFO:root:current train perplexity20.685298919677734
INFO:root:current mean train loss 3827.1569102185836
INFO:root:current train perplexity20.561220169067383
INFO:root:current mean train loss 3828.3768083538926
INFO:root:current train perplexity20.564945220947266
INFO:root:current mean train loss 3828.159951098997
INFO:root:current train perplexity20.597164154052734
INFO:root:current mean train loss 3829.519567078429
INFO:root:current train perplexity20.614330291748047
INFO:root:current mean train loss 3831.1222198837104
INFO:root:current train perplexity20.597026824951172
INFO:root:current mean train loss 3832.5316444003706
INFO:root:current train perplexity20.638647079467773
INFO:root:current mean train loss 3832.8205790011684
INFO:root:current train perplexity20.593196868896484
INFO:root:current mean train loss 3835.4557233239852
INFO:root:current train perplexity20.61701774597168
INFO:root:current mean train loss 3836.6652722456324
INFO:root:current train perplexity20.618871688842773
INFO:root:current mean train loss 3837.633387923415
INFO:root:current train perplexity20.62010955810547
INFO:root:current mean train loss 3842.5288326756486
INFO:root:current train perplexity20.661901473999023
INFO:root:current mean train loss 3842.408680520999
INFO:root:current train perplexity20.643579483032227
INFO:root:current mean train loss 3840.7505966095155
INFO:root:current train perplexity20.624048233032227
INFO:root:current mean train loss 3839.5048048806057
INFO:root:current train perplexity20.61712646484375
INFO:root:current mean train loss 3839.246187358999
INFO:root:current train perplexity20.635129928588867
INFO:root:current mean train loss 3843.8679833736514
INFO:root:current train perplexity20.700735092163086

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.66s/it]
INFO:root:final mean train loss: 3842.465857616892
INFO:root:final train perplexity: 20.705509185791016
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.65s/it]
INFO:root:eval mean loss: 2981.1823020556294
INFO:root:eval perplexity: 11.145159721374512
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it]
INFO:root:eval mean loss: 3314.697526214816
INFO:root:eval perplexity: 15.042070388793945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [7:07:30<15:05:35, 399.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3852.730959837464
INFO:root:current train perplexity20.498693466186523
INFO:root:current mean train loss 3894.1361926073696
INFO:root:current train perplexity21.532657623291016
INFO:root:current mean train loss 3923.257927339667
INFO:root:current train perplexity22.02472496032715
INFO:root:current mean train loss 3946.9368760850693
INFO:root:current train perplexity22.355073928833008
INFO:root:current mean train loss 3944.9640997978695
INFO:root:current train perplexity22.41714096069336
INFO:root:current mean train loss 3943.223662342286
INFO:root:current train perplexity22.46013069152832
INFO:root:current mean train loss 3939.239156886827
INFO:root:current train perplexity22.401363372802734
INFO:root:current mean train loss 3934.907212292527
INFO:root:current train perplexity22.31178855895996
INFO:root:current mean train loss 3933.573596700606
INFO:root:current train perplexity22.27617073059082
INFO:root:current mean train loss 3935.557845744681
INFO:root:current train perplexity22.292783737182617
INFO:root:current mean train loss 3937.045062025644
INFO:root:current train perplexity22.316699981689453
INFO:root:current mean train loss 3937.11916921434
INFO:root:current train perplexity22.357770919799805
INFO:root:current mean train loss 3936.2954562527316
INFO:root:current train perplexity22.330116271972656
INFO:root:current mean train loss 3937.5548705614638
INFO:root:current train perplexity22.325868606567383
INFO:root:current mean train loss 3941.8919187647107
INFO:root:current train perplexity22.402873992919922
INFO:root:current mean train loss 3947.0734763286664
INFO:root:current train perplexity22.45115852355957
INFO:root:current mean train loss 3949.8769386531194
INFO:root:current train perplexity22.49580192565918
INFO:root:current mean train loss 3950.202891925626
INFO:root:current train perplexity22.53406524658203
INFO:root:current mean train loss 3952.568793704665
INFO:root:current train perplexity22.567625045776367

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.28s/it]
INFO:root:final mean train loss: 3953.9783056492884
INFO:root:final train perplexity: 22.608930587768555
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.77s/it]
INFO:root:eval mean loss: 3046.2158480164007
INFO:root:eval perplexity: 11.747032165527344
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.33s/it]
INFO:root:eval mean loss: 3369.9896569218195
INFO:root:eval perplexity: 15.737876892089844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [7:14:05<14:55:35, 398.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4083.5025634765625
INFO:root:current train perplexity23.44135856628418
INFO:root:current mean train loss 4002.502432016226
INFO:root:current train perplexity23.471384048461914
INFO:root:current mean train loss 4000.8118932387406
INFO:root:current train perplexity23.7042293548584
INFO:root:current mean train loss 4004.6061682450145
INFO:root:current train perplexity23.70778465270996
INFO:root:current mean train loss 4008.32199972927
INFO:root:current train perplexity23.785757064819336
INFO:root:current mean train loss 4024.0562632727247
INFO:root:current train perplexity23.988359451293945
INFO:root:current mean train loss 4030.5534288014796
INFO:root:current train perplexity24.066709518432617
INFO:root:current mean train loss 4034.737347689542
INFO:root:current train perplexity24.174766540527344
INFO:root:current mean train loss 4033.7673673866993
INFO:root:current train perplexity24.237834930419922
INFO:root:current mean train loss 4049.707207063658
INFO:root:current train perplexity24.4528865814209
INFO:root:current mean train loss 4062.8526679415154
INFO:root:current train perplexity24.687284469604492
INFO:root:current mean train loss 4072.47432918825
INFO:root:current train perplexity24.84623146057129
INFO:root:current mean train loss 4077.9735271669306
INFO:root:current train perplexity24.925636291503906
INFO:root:current mean train loss 4078.3864789155364
INFO:root:current train perplexity24.908687591552734
INFO:root:current mean train loss 4082.0437790742967
INFO:root:current train perplexity24.936193466186523
INFO:root:current mean train loss 4083.6730086955617
INFO:root:current train perplexity24.951244354248047
INFO:root:current mean train loss 4084.0499066664393
INFO:root:current train perplexity24.97355079650879
INFO:root:current mean train loss 4085.7783574207288
INFO:root:current train perplexity25.004638671875
INFO:root:current mean train loss 4082.000588833625
INFO:root:current train perplexity24.98291778564453
INFO:root:current mean train loss 4080.4722002814797
INFO:root:current train perplexity24.96502113342285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.91s/it]
INFO:root:final mean train loss: 4081.276162382694
INFO:root:final train perplexity: 24.996599197387695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.40s/it]
INFO:root:eval mean loss: 3105.0552805366247
INFO:root:eval perplexity: 12.319540023803711
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.03s/it]
INFO:root:eval mean loss: 3427.6899227926915
INFO:root:eval perplexity: 16.498329162597656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [7:20:36<14:44:33, 396.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4265.154331752232
INFO:root:current train perplexity26.77290153503418
INFO:root:current mean train loss 4161.214587503228
INFO:root:current train perplexity26.28044319152832
INFO:root:current mean train loss 4121.690922387585
INFO:root:current train perplexity25.660476684570312
INFO:root:current mean train loss 4112.0808037018105
INFO:root:current train perplexity25.402807235717773
INFO:root:current mean train loss 4101.850562741241
INFO:root:current train perplexity25.304645538330078
INFO:root:current mean train loss 4102.306497233385
INFO:root:current train perplexity25.254789352416992
INFO:root:current mean train loss 4100.542959314614
INFO:root:current train perplexity25.257572174072266
INFO:root:current mean train loss 4096.90613724157
INFO:root:current train perplexity25.25152015686035
INFO:root:current mean train loss 4095.0981421522915
INFO:root:current train perplexity25.21915626525879
INFO:root:current mean train loss 4093.126756699155
INFO:root:current train perplexity25.192331314086914
INFO:root:current mean train loss 4086.392694576013
INFO:root:current train perplexity25.060585021972656
INFO:root:current mean train loss 4084.3215072863236
INFO:root:current train perplexity24.998279571533203
INFO:root:current mean train loss 4080.178495389921
INFO:root:current train perplexity24.92724609375
INFO:root:current mean train loss 4079.788497335707
INFO:root:current train perplexity24.914989471435547
INFO:root:current mean train loss 4075.035887125594
INFO:root:current train perplexity24.871135711669922
INFO:root:current mean train loss 4080.522875061637
INFO:root:current train perplexity24.937440872192383
INFO:root:current mean train loss 4084.1296769270994
INFO:root:current train perplexity25.002105712890625
INFO:root:current mean train loss 4086.538732817947
INFO:root:current train perplexity25.08074188232422
INFO:root:current mean train loss 4086.1102908290004
INFO:root:current train perplexity25.120410919189453
INFO:root:current mean train loss 4092.502526048445
INFO:root:current train perplexity25.2133731842041

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.09s/it]
INFO:root:final mean train loss: 4094.8584512546095
INFO:root:final train perplexity: 25.265804290771484
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 3097.7368042857934
INFO:root:eval perplexity: 12.246838569641113
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it]
INFO:root:eval mean loss: 3423.8486518589316
INFO:root:eval perplexity: 16.446582794189453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [7:27:22<14:44:10, 398.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4153.043238589638
INFO:root:current train perplexity26.262680053710938
INFO:root:current mean train loss 4143.523228742074
INFO:root:current train perplexity26.146011352539062
INFO:root:current mean train loss 4158.606623801865
INFO:root:current train perplexity26.091779708862305
INFO:root:current mean train loss 4143.598142364322
INFO:root:current train perplexity25.943012237548828
INFO:root:current mean train loss 4154.895322756136
INFO:root:current train perplexity26.1777286529541
INFO:root:current mean train loss 4165.882482592501
INFO:root:current train perplexity26.455707550048828
INFO:root:current mean train loss 4169.803572795234
INFO:root:current train perplexity26.564781188964844
INFO:root:current mean train loss 4166.644331438431
INFO:root:current train perplexity26.489429473876953
INFO:root:current mean train loss 4160.513375585006
INFO:root:current train perplexity26.435443878173828
INFO:root:current mean train loss 4160.223623442497
INFO:root:current train perplexity26.458192825317383
INFO:root:current mean train loss 4162.4558691124
INFO:root:current train perplexity26.511442184448242
INFO:root:current mean train loss 4165.890718966251
INFO:root:current train perplexity26.597665786743164
INFO:root:current mean train loss 4165.537778099442
INFO:root:current train perplexity26.586341857910156
INFO:root:current mean train loss 4163.445478909754
INFO:root:current train perplexity26.57203483581543
INFO:root:current mean train loss 4160.719547107256
INFO:root:current train perplexity26.565610885620117
INFO:root:current mean train loss 4161.8107962540125
INFO:root:current train perplexity26.614646911621094
INFO:root:current mean train loss 4162.135035401881
INFO:root:current train perplexity26.593164443969727
INFO:root:current mean train loss 4160.498750781026
INFO:root:current train perplexity26.562297821044922
INFO:root:current mean train loss 4160.27805080144
INFO:root:current train perplexity26.567840576171875
INFO:root:current mean train loss 4161.391503931445
INFO:root:current train perplexity26.590862274169922

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.91s/it]
INFO:root:final mean train loss: 4160.440216449193
INFO:root:final train perplexity: 26.606977462768555
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it]
INFO:root:eval mean loss: 3118.950171937334
INFO:root:eval perplexity: 12.458760261535645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.42s/it]
INFO:root:eval mean loss: 3443.8249273638353
INFO:root:eval perplexity: 16.717479705810547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [7:33:54<14:33:27, 397.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4138.263640802556
INFO:root:current train perplexity26.218673706054688
INFO:root:current mean train loss 4127.67828093498
INFO:root:current train perplexity26.10139274597168
INFO:root:current mean train loss 4114.492730353861
INFO:root:current train perplexity26.106395721435547
INFO:root:current mean train loss 4123.402773575044
INFO:root:current train perplexity26.247600555419922
INFO:root:current mean train loss 4147.893153331044
INFO:root:current train perplexity26.58846092224121
INFO:root:current mean train loss 4157.548490727055
INFO:root:current train perplexity26.69935417175293
INFO:root:current mean train loss 4160.703392995587
INFO:root:current train perplexity26.704912185668945
INFO:root:current mean train loss 4157.365726213266
INFO:root:current train perplexity26.586938858032227
INFO:root:current mean train loss 4159.946850443165
INFO:root:current train perplexity26.61016082763672
INFO:root:current mean train loss 4166.773253180219
INFO:root:current train perplexity26.70486068725586
INFO:root:current mean train loss 4171.263242141217
INFO:root:current train perplexity26.787790298461914
INFO:root:current mean train loss 4174.745187576096
INFO:root:current train perplexity26.88587760925293
INFO:root:current mean train loss 4179.063943250436
INFO:root:current train perplexity26.941781997680664
INFO:root:current mean train loss 4182.573837674412
INFO:root:current train perplexity27.019752502441406
INFO:root:current mean train loss 4184.481288928265
INFO:root:current train perplexity27.06924057006836
INFO:root:current mean train loss 4187.361231881782
INFO:root:current train perplexity27.108217239379883
INFO:root:current mean train loss 4188.222209273508
INFO:root:current train perplexity27.135828018188477
INFO:root:current mean train loss 4191.846834935897
INFO:root:current train perplexity27.20848274230957
INFO:root:current mean train loss 4194.951672264572
INFO:root:current train perplexity27.323596954345703
INFO:root:current mean train loss 4196.270500444573
INFO:root:current train perplexity27.365100860595703

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.60s/it]
INFO:root:final mean train loss: 4196.917694445758
INFO:root:final train perplexity: 27.38353157043457
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.74s/it]
INFO:root:eval mean loss: 3158.763209566157
INFO:root:eval perplexity: 12.866437911987305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.59s/it]
INFO:root:eval mean loss: 3485.52907221368
INFO:root:eval perplexity: 17.29749298095703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [7:40:28<14:24:54, 396.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4227.982449001736
INFO:root:current train perplexity27.85695457458496
INFO:root:current mean train loss 4207.663825456486
INFO:root:current train perplexity27.29786491394043
INFO:root:current mean train loss 4199.388290405273
INFO:root:current train perplexity27.40580940246582
INFO:root:current mean train loss 4196.082300329721
INFO:root:current train perplexity27.470272064208984
INFO:root:current mean train loss 4205.1694879046945
INFO:root:current train perplexity27.52775001525879
INFO:root:current mean train loss 4203.053170157479
INFO:root:current train perplexity27.434398651123047
INFO:root:current mean train loss 4201.760126023066
INFO:root:current train perplexity27.418540954589844
INFO:root:current mean train loss 4211.207393349761
INFO:root:current train perplexity27.536869049072266
INFO:root:current mean train loss 4215.939791338159
INFO:root:current train perplexity27.703702926635742
INFO:root:current mean train loss 4213.782815313143
INFO:root:current train perplexity27.638389587402344
INFO:root:current mean train loss 4207.079495785842
INFO:root:current train perplexity27.518260955810547
INFO:root:current mean train loss 4207.0818783496425
INFO:root:current train perplexity27.531084060668945
INFO:root:current mean train loss 4208.840088274494
INFO:root:current train perplexity27.572284698486328
INFO:root:current mean train loss 4211.443037828273
INFO:root:current train perplexity27.62674331665039
INFO:root:current mean train loss 4206.4133201267405
INFO:root:current train perplexity27.58498191833496
INFO:root:current mean train loss 4207.5761482685275
INFO:root:current train perplexity27.588401794433594
INFO:root:current mean train loss 4208.14313182192
INFO:root:current train perplexity27.605350494384766
INFO:root:current mean train loss 4208.072710644311
INFO:root:current train perplexity27.592914581298828
INFO:root:current mean train loss 4208.602523151626
INFO:root:current train perplexity27.613828659057617
INFO:root:current mean train loss 4211.9434826833485
INFO:root:current train perplexity27.66640281677246

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.95s/it]
INFO:root:final mean train loss: 4210.142916142189
INFO:root:final train perplexity: 27.670644760131836
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 3173.0553662455673
INFO:root:eval perplexity: 13.016020774841309
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.67s/it]
INFO:root:eval mean loss: 3493.7791302187225
INFO:root:eval perplexity: 17.414594650268555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [7:47:11<14:22:46, 398.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4237.893104810393
INFO:root:current train perplexity28.358129501342773
INFO:root:current mean train loss 4251.605367993551
INFO:root:current train perplexity28.522920608520508
INFO:root:current mean train loss 4279.646538440744
INFO:root:current train perplexity28.89211082458496
INFO:root:current mean train loss 4277.886276284343
INFO:root:current train perplexity29.010889053344727
INFO:root:current mean train loss 4267.208980380879
INFO:root:current train perplexity28.890766143798828
INFO:root:current mean train loss 4261.74763527629
INFO:root:current train perplexity28.795310974121094
INFO:root:current mean train loss 4258.6037831521
INFO:root:current train perplexity28.752811431884766
INFO:root:current mean train loss 4268.8428226369415
INFO:root:current train perplexity28.88990592956543
INFO:root:current mean train loss 4257.1674683853
INFO:root:current train perplexity28.816064834594727
INFO:root:current mean train loss 4252.610700370086
INFO:root:current train perplexity28.688369750976562
INFO:root:current mean train loss 4245.186918680771
INFO:root:current train perplexity28.535259246826172
INFO:root:current mean train loss 4237.989673405961
INFO:root:current train perplexity28.37610626220703
INFO:root:current mean train loss 4235.937504735078
INFO:root:current train perplexity28.334320068359375
INFO:root:current mean train loss 4240.902319142594
INFO:root:current train perplexity28.391115188598633
INFO:root:current mean train loss 4244.365309961856
INFO:root:current train perplexity28.383955001831055
INFO:root:current mean train loss 4242.200629510993
INFO:root:current train perplexity28.299152374267578
INFO:root:current mean train loss 4237.551757523405
INFO:root:current train perplexity28.243940353393555
INFO:root:current mean train loss 4242.289170718846
INFO:root:current train perplexity28.30982208251953
INFO:root:current mean train loss 4241.178379557637
INFO:root:current train perplexity28.291786193847656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:45<00:00, 345.26s/it]
INFO:root:final mean train loss: 4238.908116204536
INFO:root:final train perplexity: 28.30555534362793
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.75s/it]
INFO:root:eval mean loss: 3198.863476908799
INFO:root:eval perplexity: 13.290547370910645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.75s/it]
INFO:root:eval mean loss: 3524.6211011088485
INFO:root:eval perplexity: 17.859437942504883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [7:53:52<14:17:51, 399.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4340.00439453125
INFO:root:current train perplexity30.256755828857422
INFO:root:current mean train loss 4276.296395931604
INFO:root:current train perplexity29.156387329101562
INFO:root:current mean train loss 4278.2977140852545
INFO:root:current train perplexity29.111175537109375
INFO:root:current mean train loss 4264.128891090942
INFO:root:current train perplexity28.847396850585938
INFO:root:current mean train loss 4254.472795157597
INFO:root:current train perplexity28.63949966430664
INFO:root:current mean train loss 4265.8572766451025
INFO:root:current train perplexity28.695894241333008
INFO:root:current mean train loss 4254.415007235587
INFO:root:current train perplexity28.523792266845703
INFO:root:current mean train loss 4258.398058148349
INFO:root:current train perplexity28.685544967651367
INFO:root:current mean train loss 4259.185366344215
INFO:root:current train perplexity28.705829620361328
INFO:root:current mean train loss 4260.047448972992
INFO:root:current train perplexity28.721561431884766
INFO:root:current mean train loss 4263.9335185178
INFO:root:current train perplexity28.811098098754883
INFO:root:current mean train loss 4262.077858564436
INFO:root:current train perplexity28.75935173034668
INFO:root:current mean train loss 4267.333656424907
INFO:root:current train perplexity28.86876106262207
INFO:root:current mean train loss 4271.251582614495
INFO:root:current train perplexity28.969467163085938
INFO:root:current mean train loss 4273.429653639813
INFO:root:current train perplexity29.024221420288086
INFO:root:current mean train loss 4272.317703794198
INFO:root:current train perplexity28.998615264892578
INFO:root:current mean train loss 4266.699133315983
INFO:root:current train perplexity28.90624237060547
INFO:root:current mean train loss 4267.473776778191
INFO:root:current train perplexity28.8856143951416
INFO:root:current mean train loss 4267.346932344659
INFO:root:current train perplexity28.857894897460938
INFO:root:current mean train loss 4264.262522774503
INFO:root:current train perplexity28.844852447509766

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.59s/it]
INFO:root:final mean train loss: 4263.412096386177
INFO:root:final train perplexity: 28.857881546020508
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.14s/it]
INFO:root:eval mean loss: 3186.9599799839316
INFO:root:eval perplexity: 13.163214683532715
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it]
INFO:root:eval mean loss: 3517.4727774545654
INFO:root:eval perplexity: 17.75533103942871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [8:00:25<14:06:58, 397.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4284.832837975543
INFO:root:current train perplexity29.531993865966797
INFO:root:current mean train loss 4271.81253175813
INFO:root:current train perplexity29.41266632080078
INFO:root:current mean train loss 4274.900569077565
INFO:root:current train perplexity29.442813873291016
INFO:root:current mean train loss 4284.998447477264
INFO:root:current train perplexity29.354917526245117
INFO:root:current mean train loss 4277.354025838505
INFO:root:current train perplexity29.09430694580078
INFO:root:current mean train loss 4269.875392118786
INFO:root:current train perplexity28.88250160217285
INFO:root:current mean train loss 4266.14262985303
INFO:root:current train perplexity28.801057815551758
INFO:root:current mean train loss 4263.77705300992
INFO:root:current train perplexity28.717891693115234
INFO:root:current mean train loss 4266.787167517847
INFO:root:current train perplexity28.79555892944336
INFO:root:current mean train loss 4265.902929634599
INFO:root:current train perplexity28.85051918029785
INFO:root:current mean train loss 4267.454293677068
INFO:root:current train perplexity28.92636489868164
INFO:root:current mean train loss 4273.446929741415
INFO:root:current train perplexity29.033336639404297
INFO:root:current mean train loss 4273.525071225981
INFO:root:current train perplexity29.044973373413086
INFO:root:current mean train loss 4278.496413550229
INFO:root:current train perplexity29.136791229248047
INFO:root:current mean train loss 4274.174721305671
INFO:root:current train perplexity29.11490249633789
INFO:root:current mean train loss 4273.331437650043
INFO:root:current train perplexity29.116701126098633
INFO:root:current mean train loss 4276.771844343279
INFO:root:current train perplexity29.171274185180664
INFO:root:current mean train loss 4278.21745108119
INFO:root:current train perplexity29.167261123657227
INFO:root:current mean train loss 4275.964756700408
INFO:root:current train perplexity29.138534545898438
INFO:root:current mean train loss 4275.781194646223
INFO:root:current train perplexity29.11840057373047

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.68s/it]
INFO:root:final mean train loss: 4273.948187892989
INFO:root:final train perplexity: 29.098670959472656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it]
INFO:root:eval mean loss: 3209.5235682277817
INFO:root:eval perplexity: 13.405623435974121
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.32s/it]
INFO:root:eval mean loss: 3529.3775098002548
INFO:root:eval perplexity: 17.92904281616211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [8:07:00<13:59:00, 396.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4147.436193847656
INFO:root:current train perplexity27.556110382080078
INFO:root:current mean train loss 4218.576077706473
INFO:root:current train perplexity28.16619110107422
INFO:root:current mean train loss 4239.237594604492
INFO:root:current train perplexity28.37946891784668
INFO:root:current mean train loss 4249.689453843061
INFO:root:current train perplexity28.464204788208008
INFO:root:current mean train loss 4275.746914950284
INFO:root:current train perplexity28.928834915161133
INFO:root:current mean train loss 4273.001222963686
INFO:root:current train perplexity29.005895614624023
INFO:root:current mean train loss 4276.396869659424
INFO:root:current train perplexity28.982938766479492
INFO:root:current mean train loss 4273.270542783995
INFO:root:current train perplexity28.871803283691406
INFO:root:current mean train loss 4272.929623558408
INFO:root:current train perplexity28.859539031982422
INFO:root:current mean train loss 4273.288905107214
INFO:root:current train perplexity28.82389259338379
INFO:root:current mean train loss 4272.685388887846
INFO:root:current train perplexity28.857633590698242
INFO:root:current mean train loss 4276.030544776248
INFO:root:current train perplexity28.899887084960938
INFO:root:current mean train loss 4275.177179151966
INFO:root:current train perplexity28.8886661529541
INFO:root:current mean train loss 4275.019116575327
INFO:root:current train perplexity28.893335342407227
INFO:root:current mean train loss 4271.699100748698
INFO:root:current train perplexity28.87287712097168
INFO:root:current mean train loss 4273.563806469409
INFO:root:current train perplexity28.876602172851562
INFO:root:current mean train loss 4268.952835752906
INFO:root:current train perplexity28.800968170166016
INFO:root:current mean train loss 4263.593163220636
INFO:root:current train perplexity28.74225616455078
INFO:root:current mean train loss 4261.48600225034
INFO:root:current train perplexity28.727855682373047
INFO:root:current mean train loss 4259.785288136276
INFO:root:current train perplexity28.730993270874023

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:44<00:00, 344.82s/it]
INFO:root:final mean train loss: 4257.3007667837755
INFO:root:final train perplexity: 28.71913719177246
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.38s/it]
INFO:root:eval mean loss: 3212.6154750526375
INFO:root:eval perplexity: 13.439187049865723
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.04s/it]
INFO:root:eval mean loss: 3537.997526128241
INFO:root:eval perplexity: 18.05588150024414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [8:13:40<13:54:57, 397.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4316.728074458608
INFO:root:current train perplexity28.99271011352539
INFO:root:current mean train loss 4316.862667010848
INFO:root:current train perplexity29.545867919921875
INFO:root:current mean train loss 4321.924111214129
INFO:root:current train perplexity29.71060562133789
INFO:root:current mean train loss 4330.8278959044555
INFO:root:current train perplexity29.834590911865234
INFO:root:current mean train loss 4311.1226878760945
INFO:root:current train perplexity29.69070053100586
INFO:root:current mean train loss 4321.703279286356
INFO:root:current train perplexity29.86932373046875
INFO:root:current mean train loss 4324.216688739654
INFO:root:current train perplexity29.955238342285156
INFO:root:current mean train loss 4321.259235417355
INFO:root:current train perplexity29.90613555908203
INFO:root:current mean train loss 4321.875588273501
INFO:root:current train perplexity29.920934677124023
INFO:root:current mean train loss 4320.972928707876
INFO:root:current train perplexity29.94056510925293
INFO:root:current mean train loss 4321.825208940028
INFO:root:current train perplexity29.948204040527344
INFO:root:current mean train loss 4320.713439255618
INFO:root:current train perplexity29.942113876342773
INFO:root:current mean train loss 4316.746067723871
INFO:root:current train perplexity29.886463165283203
INFO:root:current mean train loss 4315.394409269644
INFO:root:current train perplexity29.913358688354492
INFO:root:current mean train loss 4316.380539160357
INFO:root:current train perplexity29.964366912841797
INFO:root:current mean train loss 4317.566078220336
INFO:root:current train perplexity29.9903621673584
INFO:root:current mean train loss 4315.174664420828
INFO:root:current train perplexity29.97039794921875
INFO:root:current mean train loss 4316.268340004935
INFO:root:current train perplexity29.989803314208984
INFO:root:current mean train loss 4312.274602328184
INFO:root:current train perplexity29.897687911987305
INFO:root:current mean train loss 4306.434788255102
INFO:root:current train perplexity29.81679344177246

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.35s/it]
INFO:root:final mean train loss: 4304.809269538145
INFO:root:final train perplexity: 29.815597534179688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.84s/it]
INFO:root:eval mean loss: 3240.066146525931
INFO:root:eval perplexity: 13.740880966186523
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it]
INFO:root:eval mean loss: 3562.0421008387357
INFO:root:eval perplexity: 18.414451599121094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [8:20:13<13:45:14, 396.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4270.074921479097
INFO:root:current train perplexity29.750377655029297
INFO:root:current mean train loss 4300.052906957166
INFO:root:current train perplexity29.568538665771484
INFO:root:current mean train loss 4279.548180350422
INFO:root:current train perplexity29.331314086914062
INFO:root:current mean train loss 4268.4698545078545
INFO:root:current train perplexity29.078628540039062
INFO:root:current mean train loss 4256.945786874506
INFO:root:current train perplexity28.92750358581543
INFO:root:current mean train loss 4270.025708348078
INFO:root:current train perplexity29.139005661010742
INFO:root:current mean train loss 4272.732833364244
INFO:root:current train perplexity29.2641658782959
INFO:root:current mean train loss 4275.462496971899
INFO:root:current train perplexity29.29161262512207
INFO:root:current mean train loss 4282.960444749357
INFO:root:current train perplexity29.400592803955078
INFO:root:current mean train loss 4295.003708230396
INFO:root:current train perplexity29.595571517944336
INFO:root:current mean train loss 4300.024500898365
INFO:root:current train perplexity29.73506736755371
INFO:root:current mean train loss 4304.639811059279
INFO:root:current train perplexity29.84928321838379
INFO:root:current mean train loss 4311.850200179982
INFO:root:current train perplexity29.966089248657227
INFO:root:current mean train loss 4312.9929997029085
INFO:root:current train perplexity29.97226333618164
INFO:root:current mean train loss 4315.414553596983
INFO:root:current train perplexity29.99970054626465
INFO:root:current mean train loss 4320.476220641081
INFO:root:current train perplexity30.11496925354004
INFO:root:current mean train loss 4321.540068231034
INFO:root:current train perplexity30.153608322143555
INFO:root:current mean train loss 4322.2835090577
INFO:root:current train perplexity30.203672409057617
INFO:root:current mean train loss 4321.77181645315
INFO:root:current train perplexity30.225505828857422
INFO:root:current mean train loss 4322.691355170933
INFO:root:current train perplexity30.214202880859375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.95s/it]
INFO:root:final mean train loss: 4321.715679405316
INFO:root:final train perplexity: 30.21579360961914
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.37s/it]
INFO:root:eval mean loss: 3220.2560836034463
INFO:root:eval perplexity: 13.522488594055176
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it]
INFO:root:eval mean loss: 3544.5530070852724
INFO:root:eval perplexity: 18.152944564819336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [8:26:44<13:35:31, 394.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4392.569829584478
INFO:root:current train perplexity30.80006980895996
INFO:root:current mean train loss 4362.362759734948
INFO:root:current train perplexity30.5896053314209
INFO:root:current mean train loss 4350.940349146263
INFO:root:current train perplexity30.504453659057617
INFO:root:current mean train loss 4349.20231140605
INFO:root:current train perplexity30.678293228149414
INFO:root:current mean train loss 4344.679779487812
INFO:root:current train perplexity30.6727352142334
INFO:root:current mean train loss 4340.731695649588
INFO:root:current train perplexity30.610565185546875
INFO:root:current mean train loss 4331.916239273359
INFO:root:current train perplexity30.582530975341797
INFO:root:current mean train loss 4329.897615570184
INFO:root:current train perplexity30.545841217041016
INFO:root:current mean train loss 4332.526064135276
INFO:root:current train perplexity30.582021713256836
INFO:root:current mean train loss 4332.4875815937185
INFO:root:current train perplexity30.572900772094727
INFO:root:current mean train loss 4331.505062057817
INFO:root:current train perplexity30.476240158081055
INFO:root:current mean train loss 4326.238458359572
INFO:root:current train perplexity30.344825744628906
INFO:root:current mean train loss 4324.949318789032
INFO:root:current train perplexity30.276086807250977
INFO:root:current mean train loss 4323.124409042786
INFO:root:current train perplexity30.218013763427734
INFO:root:current mean train loss 4324.576593021672
INFO:root:current train perplexity30.23086929321289
INFO:root:current mean train loss 4330.237119165177
INFO:root:current train perplexity30.304157257080078
INFO:root:current mean train loss 4331.667687071491
INFO:root:current train perplexity30.342937469482422
INFO:root:current mean train loss 4334.93674644926
INFO:root:current train perplexity30.428401947021484
INFO:root:current mean train loss 4333.68782121728
INFO:root:current train perplexity30.42804527282715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.55s/it]
INFO:root:final mean train loss: 4329.440709901349
INFO:root:final train perplexity: 30.400447845458984
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.03s/it]
INFO:root:eval mean loss: 3251.024079884198
INFO:root:eval perplexity: 13.863190650939941
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.05s/it]
INFO:root:eval mean loss: 3566.1905604152817
INFO:root:eval perplexity: 18.477031707763672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [8:33:30<13:35:48, 397.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4197.702056884766
INFO:root:current train perplexity28.288414001464844
INFO:root:current mean train loss 4274.047880949797
INFO:root:current train perplexity29.30561065673828
INFO:root:current mean train loss 4299.584196824294
INFO:root:current train perplexity29.667207717895508
INFO:root:current mean train loss 4308.486080021054
INFO:root:current train perplexity29.995481491088867
INFO:root:current mean train loss 4303.392814486634
INFO:root:current train perplexity29.821449279785156
INFO:root:current mean train loss 4297.6449171652
INFO:root:current train perplexity29.658740997314453
INFO:root:current mean train loss 4302.459499158357
INFO:root:current train perplexity29.581371307373047
INFO:root:current mean train loss 4306.539174915034
INFO:root:current train perplexity29.694345474243164
INFO:root:current mean train loss 4301.723393204188
INFO:root:current train perplexity29.664831161499023
INFO:root:current mean train loss 4301.902138058835
INFO:root:current train perplexity29.665771484375
INFO:root:current mean train loss 4314.622366284567
INFO:root:current train perplexity29.917695999145508
INFO:root:current mean train loss 4321.080875768558
INFO:root:current train perplexity30.067476272583008
INFO:root:current mean train loss 4324.375934929248
INFO:root:current train perplexity30.1179141998291
INFO:root:current mean train loss 4332.910932161757
INFO:root:current train perplexity30.268169403076172
INFO:root:current mean train loss 4334.943164478649
INFO:root:current train perplexity30.4019832611084
INFO:root:current mean train loss 4334.221419842869
INFO:root:current train perplexity30.417165756225586
INFO:root:current mean train loss 4336.356774021737
INFO:root:current train perplexity30.529176712036133
INFO:root:current mean train loss 4339.248123776438
INFO:root:current train perplexity30.61614990234375
INFO:root:current mean train loss 4342.284393175513
INFO:root:current train perplexity30.671894073486328
INFO:root:current mean train loss 4344.205125724745
INFO:root:current train perplexity30.727075576782227

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.71s/it]
INFO:root:final mean train loss: 4346.860361658078
INFO:root:final train perplexity: 30.82097625732422
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.78s/it]
INFO:root:eval mean loss: 3303.09954530973
INFO:root:eval perplexity: 14.459517478942871
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.31s/it]
INFO:root:eval mean loss: 3622.9589445506426
INFO:root:eval perplexity: 19.355085372924805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [8:40:02<13:26:07, 396.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4356.090458984375
INFO:root:current train perplexity32.37239074707031
INFO:root:current mean train loss 4458.034892578125
INFO:root:current train perplexity33.91848373413086
INFO:root:current mean train loss 4438.208974609375
INFO:root:current train perplexity33.24275588989258
INFO:root:current mean train loss 4434.079172926683
INFO:root:current train perplexity33.30629348754883
INFO:root:current mean train loss 4425.337813648897
INFO:root:current train perplexity33.25426483154297
INFO:root:current mean train loss 4424.568786272322
INFO:root:current train perplexity33.21615982055664
INFO:root:current mean train loss 4424.58977265625
INFO:root:current train perplexity33.19236373901367
INFO:root:current mean train loss 4432.354066204202
INFO:root:current train perplexity33.300758361816406
INFO:root:current mean train loss 4429.39677438447
INFO:root:current train perplexity33.24295425415039
INFO:root:current mean train loss 4431.881563027871
INFO:root:current train perplexity33.17649841308594
INFO:root:current mean train loss 4430.548051876905
INFO:root:current train perplexity33.141334533691406
INFO:root:current mean train loss 4432.708013454861
INFO:root:current train perplexity33.188453674316406
INFO:root:current mean train loss 4437.606443120217
INFO:root:current train perplexity33.25804138183594
INFO:root:current mean train loss 4442.015216317806
INFO:root:current train perplexity33.321083068847656
INFO:root:current mean train loss 4444.328034025493
INFO:root:current train perplexity33.369178771972656
INFO:root:current mean train loss 4446.706103515625
INFO:root:current train perplexity33.41053009033203
INFO:root:current mean train loss 4450.941711237981
INFO:root:current train perplexity33.4932746887207
INFO:root:current mean train loss 4454.754913100091
INFO:root:current train perplexity33.57803726196289
INFO:root:current mean train loss 4461.576265785531
INFO:root:current train perplexity33.68646240234375
INFO:root:current mean train loss 4463.3190821580765
INFO:root:current train perplexity33.75846862792969

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.87s/it]
INFO:root:final mean train loss: 4461.770418552816
INFO:root:final train perplexity: 33.74461364746094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.55s/it]
INFO:root:eval mean loss: 3345.7172124335107
INFO:root:eval perplexity: 14.966578483581543
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.78s/it]
INFO:root:eval mean loss: 3665.072640060533
INFO:root:eval perplexity: 20.0333251953125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [8:46:36<13:17:41, 395.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4443.5270589192705
INFO:root:current train perplexity34.75066375732422
INFO:root:current mean train loss 4525.391231912962
INFO:root:current train perplexity35.66114044189453
INFO:root:current mean train loss 4543.518837164256
INFO:root:current train perplexity36.086822509765625
INFO:root:current mean train loss 4538.68491367987
INFO:root:current train perplexity35.75914764404297
INFO:root:current mean train loss 4552.134432002969
INFO:root:current train perplexity35.8183708190918
INFO:root:current mean train loss 4548.7068938645925
INFO:root:current train perplexity35.79013442993164
INFO:root:current mean train loss 4535.786216094115
INFO:root:current train perplexity35.56547546386719
INFO:root:current mean train loss 4521.991223440658
INFO:root:current train perplexity35.278507232666016
INFO:root:current mean train loss 4517.329302790046
INFO:root:current train perplexity35.17557144165039
INFO:root:current mean train loss 4518.914703174762
INFO:root:current train perplexity35.243255615234375
INFO:root:current mean train loss 4518.934320782974
INFO:root:current train perplexity35.25222396850586
INFO:root:current mean train loss 4517.761614851275
INFO:root:current train perplexity35.268558502197266
INFO:root:current mean train loss 4519.270369623402
INFO:root:current train perplexity35.26863479614258
INFO:root:current mean train loss 4518.25454152501
INFO:root:current train perplexity35.226463317871094
INFO:root:current mean train loss 4520.632851779213
INFO:root:current train perplexity35.25756072998047
INFO:root:current mean train loss 4521.990113254651
INFO:root:current train perplexity35.30020523071289
INFO:root:current mean train loss 4525.346741094369
INFO:root:current train perplexity35.409027099609375
INFO:root:current mean train loss 4524.37327854231
INFO:root:current train perplexity35.44695281982422
INFO:root:current mean train loss 4529.8540654053
INFO:root:current train perplexity35.570003509521484
INFO:root:current mean train loss 4533.955387386553
INFO:root:current train perplexity35.70912551879883

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.51s/it]
INFO:root:final mean train loss: 4535.663827223785
INFO:root:final train perplexity: 35.76957321166992
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it]
INFO:root:eval mean loss: 3485.065470377604
INFO:root:eval perplexity: 16.75197982788086
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it]
INFO:root:eval mean loss: 3789.786728013492
INFO:root:eval perplexity: 22.184463500976562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [8:53:21<13:16:37, 398.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4705.094916909428
INFO:root:current train perplexity40.0085563659668
INFO:root:current mean train loss 4672.79399444772
INFO:root:current train perplexity39.41058349609375
INFO:root:current mean train loss 4658.312305818654
INFO:root:current train perplexity39.08002471923828
INFO:root:current mean train loss 4644.395312636011
INFO:root:current train perplexity38.9758186340332
INFO:root:current mean train loss 4656.210501344635
INFO:root:current train perplexity39.1954345703125
INFO:root:current mean train loss 4666.098409198904
INFO:root:current train perplexity39.38985824584961
INFO:root:current mean train loss 4680.894080756829
INFO:root:current train perplexity39.577945709228516
INFO:root:current mean train loss 4692.667255627779
INFO:root:current train perplexity39.92155456542969
INFO:root:current mean train loss 4684.192330232738
INFO:root:current train perplexity39.82776641845703
INFO:root:current mean train loss 4686.580827858202
INFO:root:current train perplexity39.95352554321289
INFO:root:current mean train loss 4689.431503454394
INFO:root:current train perplexity40.10163879394531
INFO:root:current mean train loss 4690.714265732851
INFO:root:current train perplexity40.16654586791992
INFO:root:current mean train loss 4687.302377956836
INFO:root:current train perplexity40.17832565307617
INFO:root:current mean train loss 4688.923991065064
INFO:root:current train perplexity40.2916145324707
INFO:root:current mean train loss 4689.381692532074
INFO:root:current train perplexity40.363525390625
INFO:root:current mean train loss 4686.80398389267
INFO:root:current train perplexity40.32867431640625
INFO:root:current mean train loss 4687.7056183541945
INFO:root:current train perplexity40.3427734375
INFO:root:current mean train loss 4692.309955746562
INFO:root:current train perplexity40.40739440917969
INFO:root:current mean train loss 4692.1600976772625
INFO:root:current train perplexity40.44623565673828
INFO:root:current mean train loss 4695.774663811256
INFO:root:current train perplexity40.527069091796875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.57s/it]
INFO:root:final mean train loss: 4694.725914166903
INFO:root:final train perplexity: 40.55029296875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.12s/it]
INFO:root:eval mean loss: 3639.4514844096298
INFO:root:eval perplexity: 18.979787826538086
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.21s/it]
INFO:root:eval mean loss: 3915.4270837662066
INFO:root:eval perplexity: 24.585176467895508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [8:59:53<13:06:15, 396.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4693.828317742598
INFO:root:current train perplexity42.05773162841797
INFO:root:current mean train loss 4715.574634898792
INFO:root:current train perplexity42.70296859741211
INFO:root:current mean train loss 4722.0974987969885
INFO:root:current train perplexity42.510704040527344
INFO:root:current mean train loss 4734.0868660135475
INFO:root:current train perplexity42.63390350341797
INFO:root:current mean train loss 4729.789536932937
INFO:root:current train perplexity42.39043426513672
INFO:root:current mean train loss 4727.519169277615
INFO:root:current train perplexity42.12990951538086
INFO:root:current mean train loss 4716.571605072924
INFO:root:current train perplexity41.809356689453125
INFO:root:current mean train loss 4728.187641576394
INFO:root:current train perplexity41.836631774902344
INFO:root:current mean train loss 4733.760403289099
INFO:root:current train perplexity41.935916900634766
INFO:root:current mean train loss 4738.050042324378
INFO:root:current train perplexity42.02635955810547
INFO:root:current mean train loss 4737.859851028839
INFO:root:current train perplexity41.960968017578125
INFO:root:current mean train loss 4736.199595963873
INFO:root:current train perplexity41.85479736328125
INFO:root:current mean train loss 4734.220436407107
INFO:root:current train perplexity41.80214309692383
INFO:root:current mean train loss 4735.585882319961
INFO:root:current train perplexity41.811092376708984
INFO:root:current mean train loss 4740.475135534436
INFO:root:current train perplexity41.91924285888672
INFO:root:current mean train loss 4745.811577811459
INFO:root:current train perplexity42.12030792236328
INFO:root:current mean train loss 4753.720147690511
INFO:root:current train perplexity42.430484771728516
INFO:root:current mean train loss 4756.10272051837
INFO:root:current train perplexity42.53765869140625
INFO:root:current mean train loss 4754.705543892216
INFO:root:current train perplexity42.49393081665039
INFO:root:current mean train loss 4756.406529476768
INFO:root:current train perplexity42.532344818115234

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.85s/it]
INFO:root:final mean train loss: 4755.5416552168035
INFO:root:final train perplexity: 42.54261016845703
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.35s/it]
INFO:root:eval mean loss: 3768.57289069426
INFO:root:eval perplexity: 21.068958282470703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.97s/it]
INFO:root:eval mean loss: 4049.9353408272386
INFO:root:eval perplexity: 27.444021224975586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [9:06:26<12:57:49, 395.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4684.648663264449
INFO:root:current train perplexity41.27254104614258
INFO:root:current mean train loss 4675.794761222879
INFO:root:current train perplexity40.690528869628906
INFO:root:current mean train loss 4653.990353528957
INFO:root:current train perplexity39.880435943603516
INFO:root:current mean train loss 4646.535475558604
INFO:root:current train perplexity39.30400466918945
INFO:root:current mean train loss 4631.010272229178
INFO:root:current train perplexity39.12137222290039
INFO:root:current mean train loss 4614.089987434786
INFO:root:current train perplexity38.45586013793945
INFO:root:current mean train loss 4603.974865845959
INFO:root:current train perplexity38.01334762573242
INFO:root:current mean train loss 4606.461858645965
INFO:root:current train perplexity37.93547439575195
INFO:root:current mean train loss 4584.883566793375
INFO:root:current train perplexity37.25326919555664
INFO:root:current mean train loss 4562.306499254548
INFO:root:current train perplexity36.51413345336914
INFO:root:current mean train loss 4539.273702637165
INFO:root:current train perplexity35.82329177856445
INFO:root:current mean train loss 4513.691732248337
INFO:root:current train perplexity35.16633224487305
INFO:root:current mean train loss 4494.66952026084
INFO:root:current train perplexity34.67982482910156
INFO:root:current mean train loss 4473.923342823212
INFO:root:current train perplexity34.12196350097656
INFO:root:current mean train loss 4457.969210318727
INFO:root:current train perplexity33.67730712890625
INFO:root:current mean train loss 4446.0371204096045
INFO:root:current train perplexity33.30549240112305
INFO:root:current mean train loss 4430.038836096704
INFO:root:current train perplexity32.87864685058594
INFO:root:current mean train loss 4416.656110568879
INFO:root:current train perplexity32.5047492980957
INFO:root:current mean train loss 4401.088409601162
INFO:root:current train perplexity32.14373016357422

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.83s/it]
INFO:root:final mean train loss: 4388.311402659914
INFO:root:final train perplexity: 31.84519386291504
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.67s/it]
INFO:root:eval mean loss: 3291.1332211325353
INFO:root:eval perplexity: 14.320258140563965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.90s/it]
INFO:root:eval mean loss: 3611.6839616924312
INFO:root:eval perplexity: 19.177440643310547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [9:12:58<12:48:55, 394.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4323.6017578125
INFO:root:current train perplexity29.500993728637695
INFO:root:current mean train loss 4133.01327903054
INFO:root:current train perplexity26.316923141479492
INFO:root:current mean train loss 4123.681240699405
INFO:root:current train perplexity26.13541603088379
INFO:root:current mean train loss 4127.088530115928
INFO:root:current train perplexity26.175357818603516
INFO:root:current mean train loss 4133.5047059594135
INFO:root:current train perplexity26.183053970336914
INFO:root:current mean train loss 4130.4480947457105
INFO:root:current train perplexity26.164339065551758
INFO:root:current mean train loss 4138.811497022285
INFO:root:current train perplexity26.193849563598633
INFO:root:current mean train loss 4141.0647907955545
INFO:root:current train perplexity26.212915420532227
INFO:root:current mean train loss 4142.395129846644
INFO:root:current train perplexity26.21735382080078
INFO:root:current mean train loss 4136.755027955443
INFO:root:current train perplexity26.152034759521484
INFO:root:current mean train loss 4137.674171855662
INFO:root:current train perplexity26.17626190185547
INFO:root:current mean train loss 4140.469051546664
INFO:root:current train perplexity26.199045181274414
INFO:root:current mean train loss 4137.3812136815595
INFO:root:current train perplexity26.15715980529785
INFO:root:current mean train loss 4137.639063990935
INFO:root:current train perplexity26.1420841217041
INFO:root:current mean train loss 4134.08451715564
INFO:root:current train perplexity26.070966720581055
INFO:root:current mean train loss 4134.115652162665
INFO:root:current train perplexity26.074522018432617
INFO:root:current mean train loss 4135.674975434297
INFO:root:current train perplexity26.127696990966797
INFO:root:current mean train loss 4139.816028902824
INFO:root:current train perplexity26.19095802307129
INFO:root:current mean train loss 4145.973708482606
INFO:root:current train perplexity26.294958114624023
INFO:root:current mean train loss 4149.487138390666
INFO:root:current train perplexity26.333454132080078

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:36<00:00, 336.82s/it]
INFO:root:final mean train loss: 4148.241473668762
INFO:root:final train perplexity: 26.35222816467285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.05s/it]
INFO:root:eval mean loss: 3255.963497513575
INFO:root:eval perplexity: 13.918684005737305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.28s/it]
INFO:root:eval mean loss: 3579.6061128656916
INFO:root:eval perplexity: 18.680879592895508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [9:19:29<12:40:36, 393.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4115.885570384838
INFO:root:current train perplexity26.330020904541016
INFO:root:current mean train loss 4127.308414969857
INFO:root:current train perplexity26.384000778198242
INFO:root:current mean train loss 4173.456566629956
INFO:root:current train perplexity26.91411018371582
INFO:root:current mean train loss 4162.143724913991
INFO:root:current train perplexity26.959014892578125
INFO:root:current mean train loss 4172.6750974275465
INFO:root:current train perplexity27.180370330810547
INFO:root:current mean train loss 4217.885421608159
INFO:root:current train perplexity28.14361572265625
INFO:root:current mean train loss 4243.484357477945
INFO:root:current train perplexity28.685354232788086
INFO:root:current mean train loss 4283.516320481753
INFO:root:current train perplexity29.43825912475586
INFO:root:current mean train loss 4297.761604502815
INFO:root:current train perplexity29.74814224243164
INFO:root:current mean train loss 4297.271624749275
INFO:root:current train perplexity29.789052963256836
INFO:root:current mean train loss 4296.665943119751
INFO:root:current train perplexity29.720359802246094
INFO:root:current mean train loss 4293.370645328444
INFO:root:current train perplexity29.678512573242188
INFO:root:current mean train loss 4291.986724878388
INFO:root:current train perplexity29.6503849029541
INFO:root:current mean train loss 4290.164486756429
INFO:root:current train perplexity29.593067169189453
INFO:root:current mean train loss 4283.706877956377
INFO:root:current train perplexity29.42681312561035
INFO:root:current mean train loss 4279.734559344558
INFO:root:current train perplexity29.267940521240234
INFO:root:current mean train loss 4272.968408623281
INFO:root:current train perplexity29.136978149414062
INFO:root:current mean train loss 4271.700181317177
INFO:root:current train perplexity29.079639434814453
INFO:root:current mean train loss 4268.796553621673
INFO:root:current train perplexity29.015655517578125
INFO:root:current mean train loss 4264.106806518998
INFO:root:current train perplexity28.920310974121094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.42s/it]
INFO:root:final mean train loss: 4264.0790040539905
INFO:root:final train perplexity: 28.873056411743164
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 27.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 27.00s/it]
INFO:root:eval mean loss: 3239.8189030640515
INFO:root:eval perplexity: 13.73813247680664
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.74s/it]
INFO:root:eval mean loss: 3558.7710186031695
INFO:root:eval perplexity: 18.365253448486328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [9:26:11<12:39:08, 396.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4125.452281605114
INFO:root:current train perplexity26.46498680114746
INFO:root:current mean train loss 4114.963172064887
INFO:root:current train perplexity26.345260620117188
INFO:root:current mean train loss 4129.280237416752
INFO:root:current train perplexity26.48159408569336
INFO:root:current mean train loss 4144.751882153888
INFO:root:current train perplexity26.63895606994629
INFO:root:current mean train loss 4160.361658044763
INFO:root:current train perplexity26.822608947753906
INFO:root:current mean train loss 4172.896549449248
INFO:root:current train perplexity26.986248016357422
INFO:root:current mean train loss 4168.095523431434
INFO:root:current train perplexity26.866533279418945
INFO:root:current mean train loss 4169.120081747732
INFO:root:current train perplexity26.894943237304688
INFO:root:current mean train loss 4166.695086583142
INFO:root:current train perplexity26.785619735717773
INFO:root:current mean train loss 4167.942601349394
INFO:root:current train perplexity26.829208374023438
INFO:root:current mean train loss 4173.9729883186665
INFO:root:current train perplexity26.859128952026367
INFO:root:current mean train loss 4167.650912838382
INFO:root:current train perplexity26.765108108520508
INFO:root:current mean train loss 4165.811768755652
INFO:root:current train perplexity26.74576187133789
INFO:root:current mean train loss 4164.027967543829
INFO:root:current train perplexity26.73099136352539
INFO:root:current mean train loss 4165.596137810282
INFO:root:current train perplexity26.773361206054688
INFO:root:current mean train loss 4167.036795028133
INFO:root:current train perplexity26.78367805480957
INFO:root:current mean train loss 4171.230067046599
INFO:root:current train perplexity26.869884490966797
INFO:root:current mean train loss 4175.559922664537
INFO:root:current train perplexity26.92563819885254
INFO:root:current mean train loss 4179.855118956328
INFO:root:current train perplexity26.995147705078125
INFO:root:current mean train loss 4183.549857559518
INFO:root:current train perplexity27.07373809814453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.01s/it]
INFO:root:final mean train loss: 4182.568585663688
INFO:root:final train perplexity: 27.07539176940918
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it]
INFO:root:eval mean loss: 3263.7362934951243
INFO:root:eval perplexity: 14.006454467773438
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.67s/it]
INFO:root:eval mean loss: 3575.366973227643
INFO:root:eval perplexity: 18.616228103637695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [9:32:45<12:31:18, 395.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4276.1946040919565
INFO:root:current train perplexity28.656719207763672
INFO:root:current mean train loss 4237.032646605687
INFO:root:current train perplexity27.972225189208984
INFO:root:current mean train loss 4214.752287064475
INFO:root:current train perplexity27.714611053466797
INFO:root:current mean train loss 4200.473797827216
INFO:root:current train perplexity27.488950729370117
INFO:root:current mean train loss 4186.56278068228
INFO:root:current train perplexity27.18378448486328
INFO:root:current mean train loss 4182.673154453542
INFO:root:current train perplexity27.056297302246094
INFO:root:current mean train loss 4192.764199676744
INFO:root:current train perplexity27.25400733947754
INFO:root:current mean train loss 4203.2828511903535
INFO:root:current train perplexity27.45026969909668
INFO:root:current mean train loss 4203.956145708569
INFO:root:current train perplexity27.472936630249023
INFO:root:current mean train loss 4209.117574415892
INFO:root:current train perplexity27.556427001953125
INFO:root:current mean train loss 4215.829022866841
INFO:root:current train perplexity27.697092056274414
INFO:root:current mean train loss 4220.411298516903
INFO:root:current train perplexity27.861284255981445
INFO:root:current mean train loss 4227.675446887701
INFO:root:current train perplexity27.986726760864258
INFO:root:current mean train loss 4233.570495470932
INFO:root:current train perplexity28.175996780395508
INFO:root:current mean train loss 4243.417765215927
INFO:root:current train perplexity28.376815795898438
INFO:root:current mean train loss 4252.22284033297
INFO:root:current train perplexity28.563072204589844
INFO:root:current mean train loss 4259.31249323873
INFO:root:current train perplexity28.742202758789062
INFO:root:current mean train loss 4265.160432970436
INFO:root:current train perplexity28.869895935058594
INFO:root:current mean train loss 4268.938844019723
INFO:root:current train perplexity28.965723037719727
INFO:root:current mean train loss 4273.180866994279
INFO:root:current train perplexity29.075023651123047

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.14s/it]
INFO:root:final mean train loss: 4274.433035107496
INFO:root:final train perplexity: 29.10979461669922
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.30s/it]
INFO:root:eval mean loss: 3346.5766991148603
INFO:root:eval perplexity: 14.9769868850708
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.19s/it]
INFO:root:eval mean loss: 3654.166597406915
INFO:root:eval perplexity: 19.855438232421875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [9:39:29<12:29:26, 397.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4396.433362129407
INFO:root:current train perplexity31.85849952697754
INFO:root:current mean train loss 4407.298655306356
INFO:root:current train perplexity31.922548294067383
INFO:root:current mean train loss 4400.194488744942
INFO:root:current train perplexity31.82806968688965
INFO:root:current mean train loss 4403.25447203621
INFO:root:current train perplexity31.855499267578125
INFO:root:current mean train loss 4417.921457202863
INFO:root:current train perplexity32.3661994934082
INFO:root:current mean train loss 4433.54169102441
INFO:root:current train perplexity32.7994499206543
INFO:root:current mean train loss 4447.036422684481
INFO:root:current train perplexity33.25279998779297
INFO:root:current mean train loss 4462.352503602487
INFO:root:current train perplexity33.62864685058594
INFO:root:current mean train loss 4471.680807821843
INFO:root:current train perplexity33.88997268676758
INFO:root:current mean train loss 4484.330992029732
INFO:root:current train perplexity34.15561294555664
INFO:root:current mean train loss 4488.324351917614
INFO:root:current train perplexity34.306949615478516
INFO:root:current mean train loss 4495.582926984958
INFO:root:current train perplexity34.54902648925781
INFO:root:current mean train loss 4517.476701381248
INFO:root:current train perplexity35.08624267578125
INFO:root:current mean train loss 4534.016045425038
INFO:root:current train perplexity35.59117889404297
INFO:root:current mean train loss 4545.7759909003935
INFO:root:current train perplexity35.90598678588867
INFO:root:current mean train loss 4550.682504245386
INFO:root:current train perplexity36.08686447143555
INFO:root:current mean train loss 4553.966875733295
INFO:root:current train perplexity36.210445404052734
INFO:root:current mean train loss 4559.563645044247
INFO:root:current train perplexity36.38298416137695
INFO:root:current mean train loss 4564.211987122687
INFO:root:current train perplexity36.528682708740234
INFO:root:current mean train loss 4567.292522681133
INFO:root:current train perplexity36.63991928100586

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:37<00:00, 337.28s/it]
INFO:root:final mean train loss: 4566.245203492381
INFO:root:final train perplexity: 36.64274978637695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.51s/it]
INFO:root:eval mean loss: 3647.747892772052
INFO:root:eval perplexity: 19.107572555541992
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.34s/it]
INFO:root:eval mean loss: 3934.825555463209
INFO:root:eval perplexity: 24.97833251953125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [9:46:00<12:19:04, 395.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4662.007884457237
INFO:root:current train perplexity39.375972747802734
INFO:root:current mean train loss 4651.469595102163
INFO:root:current train perplexity39.36927795410156
INFO:root:current mean train loss 4659.225143173993
INFO:root:current train perplexity39.64627456665039
INFO:root:current mean train loss 4660.443968181368
INFO:root:current train perplexity39.71761703491211
INFO:root:current mean train loss 4653.947144787721
INFO:root:current train perplexity39.58365249633789
INFO:root:current mean train loss 4657.541971671481
INFO:root:current train perplexity39.65602111816406
INFO:root:current mean train loss 4659.176612030688
INFO:root:current train perplexity39.67493438720703
INFO:root:current mean train loss 4658.1956205164115
INFO:root:current train perplexity39.7438850402832
INFO:root:current mean train loss 4665.932924886522
INFO:root:current train perplexity39.95751953125
INFO:root:current mean train loss 4683.831800604586
INFO:root:current train perplexity40.3450813293457
INFO:root:current mean train loss 4695.182627666595
INFO:root:current train perplexity40.63725280761719
INFO:root:current mean train loss 4711.765850753465
INFO:root:current train perplexity41.1807975769043
INFO:root:current mean train loss 4726.090423466156
INFO:root:current train perplexity41.57343292236328
INFO:root:current mean train loss 4735.751290007561
INFO:root:current train perplexity41.85685348510742
INFO:root:current mean train loss 4744.155299402958
INFO:root:current train perplexity42.13628005981445
INFO:root:current mean train loss 4748.8873022384405
INFO:root:current train perplexity42.2916145324707
INFO:root:current mean train loss 4751.884927233131
INFO:root:current train perplexity42.374549865722656
INFO:root:current mean train loss 4753.3087813098455
INFO:root:current train perplexity42.482452392578125
INFO:root:current mean train loss 4758.609824502185
INFO:root:current train perplexity42.63710403442383

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.21s/it]
INFO:root:final mean train loss: 4762.76382872581
INFO:root:final train perplexity: 42.78562545776367
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.60s/it]
INFO:root:eval mean loss: 3725.9252392924423
INFO:root:eval perplexity: 20.354652404785156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.15s/it]
INFO:root:eval mean loss: 3997.2505185823916
INFO:root:eval perplexity: 26.286653518676758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [9:52:33<12:10:53, 395.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4955.823811848958
INFO:root:current train perplexity49.58856201171875
INFO:root:current mean train loss 4887.569662911551
INFO:root:current train perplexity46.62102127075195
INFO:root:current mean train loss 4878.0738260521075
INFO:root:current train perplexity46.29174041748047
INFO:root:current mean train loss 4890.7987060546875
INFO:root:current train perplexity46.86017608642578
INFO:root:current mean train loss 4881.207191837644
INFO:root:current train perplexity46.71809005737305
INFO:root:current mean train loss 4872.266486644745
INFO:root:current train perplexity46.70795440673828
INFO:root:current mean train loss 4882.324821920956
INFO:root:current train perplexity46.98082733154297
INFO:root:current mean train loss 4893.317743537132
INFO:root:current train perplexity47.28371047973633
INFO:root:current mean train loss 4902.264640620189
INFO:root:current train perplexity47.59702682495117
INFO:root:current mean train loss 4911.283945184005
INFO:root:current train perplexity47.90262985229492
INFO:root:current mean train loss 4923.97134266729
INFO:root:current train perplexity48.349212646484375
INFO:root:current mean train loss 4940.633326468708
INFO:root:current train perplexity48.9390869140625
INFO:root:current mean train loss 4950.314624547172
INFO:root:current train perplexity49.32170867919922
INFO:root:current mean train loss 4961.218132019043
INFO:root:current train perplexity49.7606201171875
INFO:root:current mean train loss 4971.8576748337355
INFO:root:current train perplexity50.18496322631836
INFO:root:current mean train loss 4981.3011472994685
INFO:root:current train perplexity50.56568145751953
INFO:root:current mean train loss 4994.037398799773
INFO:root:current train perplexity51.15624237060547
INFO:root:current mean train loss 5008.429000569281
INFO:root:current train perplexity51.80480194091797
INFO:root:current mean train loss 5027.180601410519
INFO:root:current train perplexity52.526023864746094
INFO:root:current mean train loss 5042.208388452251
INFO:root:current train perplexity53.2405891418457

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:46<00:00, 346.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:46<00:00, 346.13s/it]
INFO:root:final mean train loss: 5050.428639406636
INFO:root:final train perplexity: 53.68168258666992
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.10s/it]
INFO:root:eval mean loss: 4024.6896011677195
INFO:root:eval perplexity: 25.917861938476562
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.72s/it]
INFO:root:eval mean loss: 4256.303454676418
INFO:root:eval perplexity: 32.489654541015625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [9:59:15<12:08:11, 397.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5380.360082165948
INFO:root:current train perplexity72.7923583984375
INFO:root:current mean train loss 5522.5409702034885
INFO:root:current train perplexity77.8189468383789
INFO:root:current mean train loss 5590.015181495633
INFO:root:current train perplexity81.806640625
INFO:root:current mean train loss 5602.087694718845
INFO:root:current train perplexity83.26387023925781
INFO:root:current mean train loss 5607.365043159965
INFO:root:current train perplexity83.00544738769531
INFO:root:current mean train loss 5621.803901081049
INFO:root:current train perplexity84.14502716064453
INFO:root:current mean train loss 5622.881355419068
INFO:root:current train perplexity84.06758880615234
INFO:root:current mean train loss 5620.911493832519
INFO:root:current train perplexity84.2624740600586
INFO:root:current mean train loss 5623.7246629740275
INFO:root:current train perplexity84.48503875732422
INFO:root:current mean train loss 5617.694551432993
INFO:root:current train perplexity84.1645736694336
INFO:root:current mean train loss 5604.54104409621
INFO:root:current train perplexity83.30937957763672
INFO:root:current mean train loss 5594.195893766608
INFO:root:current train perplexity82.96239471435547
INFO:root:current mean train loss 5592.440790832868
INFO:root:current train perplexity82.54722595214844
INFO:root:current mean train loss 5585.81542380902
INFO:root:current train perplexity81.99092864990234
INFO:root:current mean train loss 5583.864218517648
INFO:root:current train perplexity81.76771545410156
INFO:root:current mean train loss 5578.9114748329175
INFO:root:current train perplexity81.55223083496094
INFO:root:current mean train loss 5578.275033631158
INFO:root:current train perplexity81.44869995117188
INFO:root:current mean train loss 5576.373467096226
INFO:root:current train perplexity81.21232604980469
INFO:root:current mean train loss 5579.500451172943
INFO:root:current train perplexity81.40711975097656
INFO:root:current mean train loss 5583.250817345856
INFO:root:current train perplexity81.64195251464844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:38<00:00, 338.66s/it]
INFO:root:final mean train loss: 5581.791721207412
INFO:root:final train perplexity: 81.62513732910156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it]
INFO:root:eval mean loss: 4475.273931841478
INFO:root:eval perplexity: 37.31288528442383
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.50s/it]
INFO:root:eval mean loss: 4672.996058254377
INFO:root:eval perplexity: 45.68201446533203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [10:05:49<11:59:24, 396.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5515.65870202106
INFO:root:current train perplexity79.57313537597656
INFO:root:current mean train loss 5563.736953526327
INFO:root:current train perplexity80.85787963867188
INFO:root:current mean train loss 5613.742292698806
INFO:root:current train perplexity82.58959197998047
INFO:root:current mean train loss 5627.06829728143
INFO:root:current train perplexity84.13873291015625
INFO:root:current mean train loss 5671.260073264083
INFO:root:current train perplexity86.86278533935547
INFO:root:current mean train loss 5694.355449075664
INFO:root:current train perplexity88.46098327636719
INFO:root:current mean train loss 5719.488926748742
INFO:root:current train perplexity89.69505310058594
INFO:root:current mean train loss 5725.765214608118
INFO:root:current train perplexity90.2401351928711
INFO:root:current mean train loss 5732.053733446919
INFO:root:current train perplexity90.7712631225586
INFO:root:current mean train loss 5742.882425384844
INFO:root:current train perplexity91.48755645751953
INFO:root:current mean train loss 5748.852503585086
INFO:root:current train perplexity92.14083862304688
INFO:root:current mean train loss 5754.287798337287
INFO:root:current train perplexity92.67564392089844
INFO:root:current mean train loss 5771.011446785965
INFO:root:current train perplexity93.83037567138672
INFO:root:current mean train loss 5784.794646536613
INFO:root:current train perplexity95.08311462402344
INFO:root:current mean train loss 5800.711383233921
INFO:root:current train perplexity96.30995178222656
INFO:root:current mean train loss 5811.038354713272
INFO:root:current train perplexity97.2588882446289
INFO:root:current mean train loss 5816.7448739368165
INFO:root:current train perplexity97.91938781738281
INFO:root:current mean train loss 5824.7922696073165
INFO:root:current train perplexity98.58658599853516
INFO:root:current mean train loss 5831.4712477463945
INFO:root:current train perplexity99.0962142944336
INFO:root:current mean train loss 5834.940826635567
INFO:root:current train perplexity99.52359008789062

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.81s/it]
INFO:root:final mean train loss: 5834.881895033566
INFO:root:final train perplexity: 99.65741729736328
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it]
INFO:root:eval mean loss: 5029.776876246676
INFO:root:eval perplexity: 58.42758560180664
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.11s/it]
INFO:root:eval mean loss: 5214.287906727893
INFO:root:eval perplexity: 71.12138366699219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [10:12:22<11:51:33, 395.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5991.056198846726
INFO:root:current train perplexity110.24150085449219
INFO:root:current mean train loss 6018.135502540261
INFO:root:current train perplexity111.46246337890625
INFO:root:current mean train loss 6018.692969492633
INFO:root:current train perplexity112.64741516113281
INFO:root:current mean train loss 6022.111911910296
INFO:root:current train perplexity113.84712982177734
INFO:root:current mean train loss 6032.049539982114
INFO:root:current train perplexity115.22005462646484
INFO:root:current mean train loss 6040.333784032249
INFO:root:current train perplexity116.11864471435547
INFO:root:current mean train loss 6064.682190033465
INFO:root:current train perplexity118.5257568359375
INFO:root:current mean train loss 6096.456223634093
INFO:root:current train perplexity121.07845306396484
INFO:root:current mean train loss 6123.6588973557
INFO:root:current train perplexity123.71886444091797
INFO:root:current mean train loss 6138.601506218361
INFO:root:current train perplexity126.03483581542969
INFO:root:current mean train loss 6161.8524922095485
INFO:root:current train perplexity128.483154296875
INFO:root:current mean train loss 6181.597864493766
INFO:root:current train perplexity130.96304321289062
INFO:root:current mean train loss 6199.3313817547505
INFO:root:current train perplexity132.86831665039062
INFO:root:current mean train loss 6210.8279132801035
INFO:root:current train perplexity134.1114501953125
INFO:root:current mean train loss 6226.133266738401
INFO:root:current train perplexity135.50970458984375
INFO:root:current mean train loss 6239.246012838392
INFO:root:current train perplexity136.9985809326172
INFO:root:current mean train loss 6249.857642966871
INFO:root:current train perplexity138.3140411376953
INFO:root:current mean train loss 6266.327654167258
INFO:root:current train perplexity139.9593963623047
INFO:root:current mean train loss 6279.805170015181
INFO:root:current train perplexity141.4898681640625
INFO:root:current mean train loss 6291.471508304015
INFO:root:current train perplexity142.77920532226562

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.82s/it]
INFO:root:final mean train loss: 6293.012243227591
INFO:root:final train perplexity: 143.0290069580078
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.88s/it]
INFO:root:eval mean loss: 6076.606150958555
INFO:root:eval perplexity: 136.23788452148438
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it]
INFO:root:eval mean loss: 6183.959680435505
INFO:root:eval perplexity: 157.1831512451172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [10:19:08<11:50:34, 398.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6465.769671630859
INFO:root:current train perplexity162.55343627929688
INFO:root:current mean train loss 6416.962475585938
INFO:root:current train perplexity156.0858917236328
INFO:root:current mean train loss 6392.45649937221
INFO:root:current train perplexity154.64002990722656
INFO:root:current mean train loss 6391.76675704153
INFO:root:current train perplexity153.61692810058594
INFO:root:current mean train loss 6405.441910807292
INFO:root:current train perplexity155.02024841308594
INFO:root:current mean train loss 6419.5749705347525
INFO:root:current train perplexity156.7716064453125
INFO:root:current mean train loss 6423.646295525046
INFO:root:current train perplexity156.7281036376953
INFO:root:current mean train loss 6418.994120592949
INFO:root:current train perplexity156.25120544433594
INFO:root:current mean train loss 6420.503968394886
INFO:root:current train perplexity156.62440490722656
INFO:root:current mean train loss 6420.861837830836
INFO:root:current train perplexity156.9486541748047
INFO:root:current mean train loss 6427.526269983362
INFO:root:current train perplexity157.96961975097656
INFO:root:current mean train loss 6436.024269233316
INFO:root:current train perplexity159.31057739257812
INFO:root:current mean train loss 6449.406509017945
INFO:root:current train perplexity160.73049926757812
INFO:root:current mean train loss 6454.884506623642
INFO:root:current train perplexity161.59921264648438
INFO:root:current mean train loss 6468.205136520798
INFO:root:current train perplexity162.66943359375
INFO:root:current mean train loss 6475.633334157436
INFO:root:current train perplexity163.7093505859375
INFO:root:current mean train loss 6478.627042933873
INFO:root:current train perplexity164.48971557617188
INFO:root:current mean train loss 6477.579784881935
INFO:root:current train perplexity164.8213653564453
INFO:root:current mean train loss 6480.996548007397
INFO:root:current train perplexity165.17225646972656
INFO:root:current mean train loss 6481.842431394019
INFO:root:current train perplexity165.7163543701172

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.73s/it]
INFO:root:final mean train loss: 6479.680060667037
INFO:root:final train perplexity: 165.71438598632812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.88s/it]
INFO:root:eval mean loss: 6270.394048163232
INFO:root:eval perplexity: 159.35372924804688
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it]
INFO:root:eval mean loss: 6376.683681190437
INFO:root:eval perplexity: 184.0167694091797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [10:25:42<11:41:46, 397.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6580.333657176224
INFO:root:current train perplexity180.27420043945312
INFO:root:current mean train loss 6596.205985287119
INFO:root:current train perplexity180.3203582763672
INFO:root:current mean train loss 6556.840190643414
INFO:root:current train perplexity178.4104461669922
INFO:root:current mean train loss 6560.207232958123
INFO:root:current train perplexity178.517333984375
INFO:root:current mean train loss 6568.004760987802
INFO:root:current train perplexity178.7158660888672
INFO:root:current mean train loss 6574.078630456972
INFO:root:current train perplexity178.8467254638672
INFO:root:current mean train loss 6576.8828328158625
INFO:root:current train perplexity178.88442993164062
INFO:root:current mean train loss 6580.860915199576
INFO:root:current train perplexity179.5294189453125
INFO:root:current mean train loss 6587.664183345527
INFO:root:current train perplexity180.23130798339844
INFO:root:current mean train loss 6583.8798318784475
INFO:root:current train perplexity180.27273559570312
INFO:root:current mean train loss 6588.556654868391
INFO:root:current train perplexity180.64170837402344
INFO:root:current mean train loss 6590.925673966818
INFO:root:current train perplexity180.8866729736328
INFO:root:current mean train loss 6594.960842629626
INFO:root:current train perplexity181.27420043945312
INFO:root:current mean train loss 6597.341020588203
INFO:root:current train perplexity181.6013946533203
INFO:root:current mean train loss 6599.375980802752
INFO:root:current train perplexity181.73037719726562
INFO:root:current mean train loss 6599.498947611733
INFO:root:current train perplexity181.97622680664062
INFO:root:current mean train loss 6597.768304072904
INFO:root:current train perplexity182.07342529296875
INFO:root:current mean train loss 6601.5808636681795
INFO:root:current train perplexity182.3238983154297
INFO:root:current mean train loss 6603.994352204962
INFO:root:current train perplexity182.4346923828125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.18s/it]
INFO:root:final mean train loss: 6601.991110966654
INFO:root:final train perplexity: 182.4957733154297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it]
INFO:root:eval mean loss: 6350.930272744902
INFO:root:eval perplexity: 170.0784149169922
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it]
INFO:root:eval mean loss: 6460.68905141844
INFO:root:eval perplexity: 197.103515625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [10:32:31<11:41:13, 400.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6426.23388671875
INFO:root:current train perplexity176.27037048339844
INFO:root:current mean train loss 6578.1625762404055
INFO:root:current train perplexity183.28475952148438
INFO:root:current mean train loss 6592.627160758616
INFO:root:current train perplexity183.5394287109375
INFO:root:current mean train loss 6601.790269207802
INFO:root:current train perplexity183.79928588867188
INFO:root:current mean train loss 6592.198012199955
INFO:root:current train perplexity183.55194091796875
INFO:root:current mean train loss 6599.492572235226
INFO:root:current train perplexity184.1241912841797
INFO:root:current mean train loss 6607.191014193557
INFO:root:current train perplexity184.31788635253906
INFO:root:current mean train loss 6610.867733226103
INFO:root:current train perplexity184.430419921875
INFO:root:current mean train loss 6614.959474455813
INFO:root:current train perplexity184.8482666015625
INFO:root:current mean train loss 6615.0646726912955
INFO:root:current train perplexity185.1060028076172
INFO:root:current mean train loss 6626.248039651905
INFO:root:current train perplexity185.47586059570312
INFO:root:current mean train loss 6629.611602509257
INFO:root:current train perplexity185.86070251464844
INFO:root:current mean train loss 6626.399243123841
INFO:root:current train perplexity185.8488311767578
INFO:root:current mean train loss 6627.1717066655965
INFO:root:current train perplexity185.79115295410156
INFO:root:current mean train loss 6624.38499215435
INFO:root:current train perplexity185.85646057128906
INFO:root:current mean train loss 6624.059650295162
INFO:root:current train perplexity185.9972381591797
INFO:root:current mean train loss 6627.05290318599
INFO:root:current train perplexity186.079833984375
INFO:root:current mean train loss 6624.640936941639
INFO:root:current train perplexity186.04576110839844
INFO:root:current mean train loss 6627.4771727169755
INFO:root:current train perplexity186.12181091308594
INFO:root:current mean train loss 6626.647224195076
INFO:root:current train perplexity186.11434936523438

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.45s/it]
INFO:root:final mean train loss: 6627.4742381778315
INFO:root:final train perplexity: 186.20071411132812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.69s/it]
INFO:root:eval mean loss: 6402.223319412124
INFO:root:eval perplexity: 177.2820587158203
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.10s/it]
INFO:root:eval mean loss: 6513.447113253546
INFO:root:eval perplexity: 205.79409790039062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [10:39:09<11:32:51, 399.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6584.8071446572585
INFO:root:current train perplexity184.79046630859375
INFO:root:current mean train loss 6597.116456941794
INFO:root:current train perplexity184.84571838378906
INFO:root:current mean train loss 6624.472671046402
INFO:root:current train perplexity185.20436096191406
INFO:root:current mean train loss 6627.313792248867
INFO:root:current train perplexity184.87841796875
INFO:root:current mean train loss 6617.238548615139
INFO:root:current train perplexity184.42251586914062
INFO:root:current mean train loss 6614.914309859051
INFO:root:current train perplexity184.1980438232422
INFO:root:current mean train loss 6614.011188682399
INFO:root:current train perplexity184.5493621826172
INFO:root:current mean train loss 6616.706520257994
INFO:root:current train perplexity184.46243286132812
INFO:root:current mean train loss 6618.365324862741
INFO:root:current train perplexity184.4406280517578
INFO:root:current mean train loss 6609.659319196428
INFO:root:current train perplexity183.9634246826172
INFO:root:current mean train loss 6610.519968856086
INFO:root:current train perplexity183.89202880859375
INFO:root:current mean train loss 6608.11824393167
INFO:root:current train perplexity183.6939697265625
INFO:root:current mean train loss 6608.496618126777
INFO:root:current train perplexity183.57260131835938
INFO:root:current mean train loss 6609.407820497394
INFO:root:current train perplexity183.48849487304688
INFO:root:current mean train loss 6607.440252595978
INFO:root:current train perplexity183.39437866210938
INFO:root:current mean train loss 6607.093338580788
INFO:root:current train perplexity183.27452087402344
INFO:root:current mean train loss 6605.909382364634
INFO:root:current train perplexity183.14942932128906
INFO:root:current mean train loss 6603.229269061868
INFO:root:current train perplexity182.99517822265625
INFO:root:current mean train loss 6603.501880056151
INFO:root:current train perplexity182.84332275390625
INFO:root:current mean train loss 6604.394291028774
INFO:root:current train perplexity182.83670043945312

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.61s/it]
INFO:root:final mean train loss: 6604.576348793849
INFO:root:final train perplexity: 182.86834716796875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.69s/it]
INFO:root:eval mean loss: 6367.766255263741
INFO:root:eval perplexity: 172.40997314453125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.29s/it]
INFO:root:eval mean loss: 6482.024204551751
INFO:root:eval perplexity: 200.57284545898438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [10:45:58<11:30:52, 402.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6644.831604003906
INFO:root:current train perplexity181.50149536132812
INFO:root:current mean train loss 6590.1909839527025
INFO:root:current train perplexity182.20509338378906
INFO:root:current mean train loss 6593.707560877646
INFO:root:current train perplexity181.1048583984375
INFO:root:current mean train loss 6587.088746520295
INFO:root:current train perplexity180.43080139160156
INFO:root:current mean train loss 6599.390240260533
INFO:root:current train perplexity180.76234436035156
INFO:root:current mean train loss 6598.9004993299495
INFO:root:current train perplexity180.51754760742188
INFO:root:current mean train loss 6603.0238850911455
INFO:root:current train perplexity180.6543731689453
INFO:root:current mean train loss 6596.96559640813
INFO:root:current train perplexity180.3793487548828
INFO:root:current mean train loss 6600.19810860112
INFO:root:current train perplexity180.3845977783203
INFO:root:current mean train loss 6595.08831400811
INFO:root:current train perplexity180.3156280517578
INFO:root:current mean train loss 6602.755512266669
INFO:root:current train perplexity180.56446838378906
INFO:root:current mean train loss 6594.542306507921
INFO:root:current train perplexity180.23336791992188
INFO:root:current mean train loss 6595.721713335086
INFO:root:current train perplexity180.01597595214844
INFO:root:current mean train loss 6595.736523727282
INFO:root:current train perplexity180.07032775878906
INFO:root:current mean train loss 6591.868606820291
INFO:root:current train perplexity180.0037841796875
INFO:root:current mean train loss 6590.457875648518
INFO:root:current train perplexity179.9193572998047
INFO:root:current mean train loss 6584.458166029847
INFO:root:current train perplexity179.7515411376953
INFO:root:current mean train loss 6583.7775334198905
INFO:root:current train perplexity179.64186096191406
INFO:root:current mean train loss 6584.029854646493
INFO:root:current train perplexity179.57000732421875
INFO:root:current mean train loss 6581.863772288485
INFO:root:current train perplexity179.4468231201172

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.67s/it]
INFO:root:final mean train loss: 6580.448883133588
INFO:root:final train perplexity: 179.4215087890625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.75s/it]
INFO:root:eval mean loss: 6348.543341021165
INFO:root:eval perplexity: 169.75042724609375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.64s/it]
INFO:root:eval mean loss: 6465.4187124265845
INFO:root:eval perplexity: 197.86741638183594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [10:52:33<11:20:28, 400.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6502.846251502404
INFO:root:current train perplexity176.48634338378906
INFO:root:current mean train loss 6573.312813683712
INFO:root:current train perplexity177.053955078125
INFO:root:current mean train loss 6557.308258402122
INFO:root:current train perplexity177.5423583984375
INFO:root:current mean train loss 6567.34055276113
INFO:root:current train perplexity177.78761291503906
INFO:root:current mean train loss 6564.391990087365
INFO:root:current train perplexity177.70252990722656
INFO:root:current mean train loss 6572.012265797843
INFO:root:current train perplexity177.5422821044922
INFO:root:current mean train loss 6564.5132680333645
INFO:root:current train perplexity177.05361938476562
INFO:root:current mean train loss 6564.861713643791
INFO:root:current train perplexity176.91065979003906
INFO:root:current mean train loss 6567.370387012284
INFO:root:current train perplexity176.88612365722656
INFO:root:current mean train loss 6569.1789669689115
INFO:root:current train perplexity176.85736083984375
INFO:root:current mean train loss 6568.128873697917
INFO:root:current train perplexity176.81764221191406
INFO:root:current mean train loss 6562.25296070279
INFO:root:current train perplexity176.6006622314453
INFO:root:current mean train loss 6566.199170114872
INFO:root:current train perplexity176.67529296875
INFO:root:current mean train loss 6566.5078597184065
INFO:root:current train perplexity176.69871520996094
INFO:root:current mean train loss 6568.194465590337
INFO:root:current train perplexity176.7611541748047
INFO:root:current mean train loss 6568.614290884585
INFO:root:current train perplexity176.71127319335938
INFO:root:current mean train loss 6565.556961453641
INFO:root:current train perplexity176.52725219726562
INFO:root:current mean train loss 6562.546795049132
INFO:root:current train perplexity176.44781494140625
INFO:root:current mean train loss 6565.355129702161
INFO:root:current train perplexity176.4881134033203
INFO:root:current mean train loss 6561.6478493260975
INFO:root:current train perplexity176.3711700439453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.79s/it]
INFO:root:final mean train loss: 6558.643824436421
INFO:root:final train perplexity: 176.3624267578125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 6324.697622312721
INFO:root:eval perplexity: 166.5081329345703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.43s/it]
INFO:root:eval mean loss: 6443.007513817321
INFO:root:eval perplexity: 194.2738037109375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [10:59:10<11:12:27, 399.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6480.328899104421
INFO:root:current train perplexity173.41603088378906
INFO:root:current mean train loss 6521.411521827781
INFO:root:current train perplexity174.89637756347656
INFO:root:current mean train loss 6522.462049119016
INFO:root:current train perplexity175.59487915039062
INFO:root:current mean train loss 6518.574024460078
INFO:root:current train perplexity175.1714630126953
INFO:root:current mean train loss 6519.462104512448
INFO:root:current train perplexity174.8977813720703
INFO:root:current mean train loss 6526.443747818675
INFO:root:current train perplexity175.04788208007812
INFO:root:current mean train loss 6531.491354128482
INFO:root:current train perplexity175.212646484375
INFO:root:current mean train loss 6535.203911744725
INFO:root:current train perplexity175.25149536132812
INFO:root:current mean train loss 6531.285891439909
INFO:root:current train perplexity175.02317810058594
INFO:root:current mean train loss 6536.001374347632
INFO:root:current train perplexity175.1712188720703
INFO:root:current mean train loss 6540.930584637824
INFO:root:current train perplexity175.24456787109375
INFO:root:current mean train loss 6539.850168709021
INFO:root:current train perplexity174.96844482421875
INFO:root:current mean train loss 6541.300704694203
INFO:root:current train perplexity175.0838623046875
INFO:root:current mean train loss 6543.348751173005
INFO:root:current train perplexity175.22401428222656
INFO:root:current mean train loss 6543.465944524397
INFO:root:current train perplexity175.10531616210938
INFO:root:current mean train loss 6545.900825818781
INFO:root:current train perplexity175.0997314453125
INFO:root:current mean train loss 6545.045249621451
INFO:root:current train perplexity174.93040466308594
INFO:root:current mean train loss 6544.751077123229
INFO:root:current train perplexity174.83383178710938
INFO:root:current mean train loss 6546.975594758734
INFO:root:current train perplexity174.89544677734375
INFO:root:current mean train loss 6549.893725659845
INFO:root:current train perplexity174.92189025878906

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.38s/it]
INFO:root:final mean train loss: 6548.239050360683
INFO:root:final train perplexity: 174.921142578125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it]
INFO:root:eval mean loss: 6323.229864458665
INFO:root:eval perplexity: 166.3106231689453
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.33s/it]
INFO:root:eval mean loss: 6442.991775404477
INFO:root:eval perplexity: 194.27120971679688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [11:05:59<11:10:15, 402.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6587.049405184659
INFO:root:current train perplexity176.2323760986328
INFO:root:current mean train loss 6582.785323099874
INFO:root:current train perplexity176.25961303710938
INFO:root:current mean train loss 6577.404159698996
INFO:root:current train perplexity174.86317443847656
INFO:root:current mean train loss 6575.91902730459
INFO:root:current train perplexity174.9244842529297
INFO:root:current mean train loss 6560.283824484907
INFO:root:current train perplexity174.691162109375
INFO:root:current mean train loss 6552.646653928422
INFO:root:current train perplexity174.83224487304688
INFO:root:current mean train loss 6555.497369987259
INFO:root:current train perplexity174.99722290039062
INFO:root:current mean train loss 6558.32617859727
INFO:root:current train perplexity174.80665588378906
INFO:root:current mean train loss 6552.235582396239
INFO:root:current train perplexity174.80133056640625
INFO:root:current mean train loss 6548.034031101414
INFO:root:current train perplexity174.7205810546875
INFO:root:current mean train loss 6551.4608717442
INFO:root:current train perplexity174.57583618164062
INFO:root:current mean train loss 6546.687718280859
INFO:root:current train perplexity174.41383361816406
INFO:root:current mean train loss 6541.58569542677
INFO:root:current train perplexity174.2720947265625
INFO:root:current mean train loss 6540.749431094755
INFO:root:current train perplexity174.0819854736328
INFO:root:current mean train loss 6542.266714267846
INFO:root:current train perplexity174.05368041992188
INFO:root:current mean train loss 6541.278583233173
INFO:root:current train perplexity174.00347900390625
INFO:root:current mean train loss 6542.784572266774
INFO:root:current train perplexity174.0780792236328
INFO:root:current mean train loss 6543.550814091596
INFO:root:current train perplexity173.99160766601562
INFO:root:current mean train loss 6542.693509279144
INFO:root:current train perplexity173.90817260742188

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.18s/it]
INFO:root:final mean train loss: 6540.5032873418195
INFO:root:final train perplexity: 173.857177734375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it]
INFO:root:eval mean loss: 6318.980425462655
INFO:root:eval perplexity: 165.739990234375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.86s/it]
INFO:root:eval mean loss: 6438.309360801751
INFO:root:eval perplexity: 193.5287628173828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [11:12:35<11:00:38, 400.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6721.909637451172
INFO:root:current train perplexity175.51400756835938
INFO:root:current mean train loss 6610.136996565194
INFO:root:current train perplexity174.60055541992188
INFO:root:current mean train loss 6561.127590603299
INFO:root:current train perplexity173.23817443847656
INFO:root:current mean train loss 6538.81854479826
INFO:root:current train perplexity172.69918823242188
INFO:root:current mean train loss 6528.087773249699
INFO:root:current train perplexity172.75247192382812
INFO:root:current mean train loss 6523.905610313711
INFO:root:current train perplexity172.69168090820312
INFO:root:current mean train loss 6533.106603845374
INFO:root:current train perplexity173.0531463623047
INFO:root:current mean train loss 6538.731917908738
INFO:root:current train perplexity173.1370086669922
INFO:root:current mean train loss 6539.883503035003
INFO:root:current train perplexity173.15286254882812
INFO:root:current mean train loss 6533.633302913482
INFO:root:current train perplexity173.09243774414062
INFO:root:current mean train loss 6536.129111943283
INFO:root:current train perplexity173.18142700195312
INFO:root:current mean train loss 6532.698959295895
INFO:root:current train perplexity173.29229736328125
INFO:root:current mean train loss 6535.198952122739
INFO:root:current train perplexity173.4115753173828
INFO:root:current mean train loss 6532.428611871319
INFO:root:current train perplexity173.27088928222656
INFO:root:current mean train loss 6531.034525553386
INFO:root:current train perplexity173.1846466064453
INFO:root:current mean train loss 6531.077293375865
INFO:root:current train perplexity173.17515563964844
INFO:root:current mean train loss 6528.129937502417
INFO:root:current train perplexity173.022216796875
INFO:root:current mean train loss 6531.741731941561
INFO:root:current train perplexity173.0933380126953
INFO:root:current mean train loss 6535.225895146441
INFO:root:current train perplexity173.13296508789062
INFO:root:current mean train loss 6536.6055311867985
INFO:root:current train perplexity173.2201690673828

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:42<00:00, 342.15s/it]
INFO:root:final mean train loss: 6536.1714646516875
INFO:root:final train perplexity: 173.2642822265625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.25s/it]
INFO:root:eval mean loss: 6314.980967420212
INFO:root:eval perplexity: 165.2047882080078
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it]
INFO:root:eval mean loss: 6433.31057198166
INFO:root:eval perplexity: 192.73915100097656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [11:19:12<10:52:19, 399.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6552.584591027462
INFO:root:current train perplexity175.676025390625
INFO:root:current mean train loss 6530.585548343515
INFO:root:current train perplexity172.7476043701172
INFO:root:current mean train loss 6514.3294955405045
INFO:root:current train perplexity172.10342407226562
INFO:root:current mean train loss 6532.009346260323
INFO:root:current train perplexity172.5766143798828
INFO:root:current mean train loss 6526.685576194428
INFO:root:current train perplexity172.1527557373047
INFO:root:current mean train loss 6527.997615391944
INFO:root:current train perplexity172.19651794433594
INFO:root:current mean train loss 6520.583247710555
INFO:root:current train perplexity172.22665405273438
INFO:root:current mean train loss 6534.225445381779
INFO:root:current train perplexity172.48291015625
INFO:root:current mean train loss 6535.042402507878
INFO:root:current train perplexity172.55101013183594
INFO:root:current mean train loss 6542.709979777934
INFO:root:current train perplexity172.76112365722656
INFO:root:current mean train loss 6544.109736129598
INFO:root:current train perplexity172.87887573242188
INFO:root:current mean train loss 6546.207713895631
INFO:root:current train perplexity172.99424743652344
INFO:root:current mean train loss 6546.362372405338
INFO:root:current train perplexity173.08970642089844
INFO:root:current mean train loss 6544.427644997187
INFO:root:current train perplexity173.0735321044922
INFO:root:current mean train loss 6539.180526744047
INFO:root:current train perplexity173.00967407226562
INFO:root:current mean train loss 6539.625145560686
INFO:root:current train perplexity172.90988159179688
INFO:root:current mean train loss 6539.01238793153
INFO:root:current train perplexity172.93923950195312
INFO:root:current mean train loss 6538.58201800752
INFO:root:current train perplexity173.00587463378906
INFO:root:current mean train loss 6536.160903722552
INFO:root:current train perplexity172.925537109375
INFO:root:current mean train loss 6533.253530882211
INFO:root:current train perplexity172.82728576660156

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.57s/it]
INFO:root:final mean train loss: 6533.189327915209
INFO:root:final train perplexity: 172.85719299316406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 6297.289535197806
INFO:root:eval perplexity: 162.8578643798828
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.27s/it]
INFO:root:eval mean loss: 6416.884583818151
INFO:root:eval perplexity: 190.1673126220703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [11:25:46<10:43:09, 397.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6598.59830078125
INFO:root:current train perplexity173.58819580078125
INFO:root:current mean train loss 6531.687542317708
INFO:root:current train perplexity170.96665954589844
INFO:root:current mean train loss 6550.010189453125
INFO:root:current train perplexity171.7093048095703
INFO:root:current mean train loss 6539.546418805804
INFO:root:current train perplexity171.7245330810547
INFO:root:current mean train loss 6544.7040386284725
INFO:root:current train perplexity172.23641967773438
INFO:root:current mean train loss 6535.510957919034
INFO:root:current train perplexity172.31602478027344
INFO:root:current mean train loss 6535.130837590144
INFO:root:current train perplexity172.43077087402344
INFO:root:current mean train loss 6532.599994791667
INFO:root:current train perplexity172.30230712890625
INFO:root:current mean train loss 6522.90341050092
INFO:root:current train perplexity171.95379638671875
INFO:root:current mean train loss 6524.8199671052635
INFO:root:current train perplexity172.0348358154297
INFO:root:current mean train loss 6526.206801525298
INFO:root:current train perplexity172.17935180664062
INFO:root:current mean train loss 6524.66700280231
INFO:root:current train perplexity172.1432342529297
INFO:root:current mean train loss 6527.241384765625
INFO:root:current train perplexity172.05313110351562
INFO:root:current mean train loss 6527.341234447338
INFO:root:current train perplexity172.14454650878906
INFO:root:current mean train loss 6527.816826508621
INFO:root:current train perplexity172.10391235351562
INFO:root:current mean train loss 6526.987027784779
INFO:root:current train perplexity172.0690460205078
INFO:root:current mean train loss 6526.037382220644
INFO:root:current train perplexity172.0935821533203
INFO:root:current mean train loss 6527.564744977679
INFO:root:current train perplexity172.0029296875
INFO:root:current mean train loss 6527.4486504962
INFO:root:current train perplexity171.9879150390625
INFO:root:current mean train loss 6527.1111848958335
INFO:root:current train perplexity171.99546813964844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.06s/it]
INFO:root:final mean train loss: 6526.731173101243
INFO:root:final train perplexity: 171.97906494140625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.07s/it]
INFO:root:eval mean loss: 6288.152362796432
INFO:root:eval perplexity: 161.6588592529297
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.13s/it]
INFO:root:eval mean loss: 6408.991509620179
INFO:root:eval perplexity: 188.94375610351562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [11:32:34<10:41:08, 400.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6422.191646746735
INFO:root:current train perplexity169.7696990966797
INFO:root:current mean train loss 6512.958984375
INFO:root:current train perplexity171.5261688232422
INFO:root:current mean train loss 6526.4152201106035
INFO:root:current train perplexity172.03524780273438
INFO:root:current mean train loss 6508.758747818035
INFO:root:current train perplexity171.6967010498047
INFO:root:current mean train loss 6513.200966943255
INFO:root:current train perplexity171.70816040039062
INFO:root:current mean train loss 6513.777311025683
INFO:root:current train perplexity171.4914093017578
INFO:root:current mean train loss 6513.385017452211
INFO:root:current train perplexity171.47840881347656
INFO:root:current mean train loss 6508.596608386979
INFO:root:current train perplexity171.19866943359375
INFO:root:current mean train loss 6515.181375928129
INFO:root:current train perplexity171.21621704101562
INFO:root:current mean train loss 6521.495723120799
INFO:root:current train perplexity171.46531677246094
INFO:root:current mean train loss 6520.818723183429
INFO:root:current train perplexity171.47317504882812
INFO:root:current mean train loss 6519.367129341394
INFO:root:current train perplexity171.46646118164062
INFO:root:current mean train loss 6519.93953983635
INFO:root:current train perplexity171.3356170654297
INFO:root:current mean train loss 6516.288309182402
INFO:root:current train perplexity171.16943359375
INFO:root:current mean train loss 6527.157440580799
INFO:root:current train perplexity171.3573455810547
INFO:root:current mean train loss 6532.701490021239
INFO:root:current train perplexity171.45518493652344
INFO:root:current mean train loss 6531.290845151282
INFO:root:current train perplexity171.36708068847656
INFO:root:current mean train loss 6529.295281937518
INFO:root:current train perplexity171.36911010742188
INFO:root:current mean train loss 6522.782610492267
INFO:root:current train perplexity171.33668518066406
INFO:root:current mean train loss 6522.981607659189
INFO:root:current train perplexity171.2799072265625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.29s/it]
INFO:root:final mean train loss: 6521.232114452337
INFO:root:final train perplexity: 171.23483276367188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.69s/it]
INFO:root:eval mean loss: 6292.760629640404
INFO:root:eval perplexity: 162.26255798339844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.06s/it]
INFO:root:eval mean loss: 6411.891972967919
INFO:root:eval perplexity: 189.3924102783203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [11:39:19<10:36:35, 402.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6527.727818080357
INFO:root:current train perplexity171.5892333984375
INFO:root:current mean train loss 6508.3190758746605
INFO:root:current train perplexity170.7218475341797
INFO:root:current mean train loss 6499.167805416483
INFO:root:current train perplexity171.001953125
INFO:root:current mean train loss 6482.863169352214
INFO:root:current train perplexity170.4042510986328
INFO:root:current mean train loss 6486.253668162449
INFO:root:current train perplexity170.5533447265625
INFO:root:current mean train loss 6493.396209298748
INFO:root:current train perplexity170.52926635742188
INFO:root:current mean train loss 6492.7936797560305
INFO:root:current train perplexity170.30572509765625
INFO:root:current mean train loss 6502.649465132733
INFO:root:current train perplexity170.24847412109375
INFO:root:current mean train loss 6506.338564497313
INFO:root:current train perplexity170.47528076171875
INFO:root:current mean train loss 6507.570069848038
INFO:root:current train perplexity170.55398559570312
INFO:root:current mean train loss 6508.540457524937
INFO:root:current train perplexity170.51292419433594
INFO:root:current mean train loss 6505.418863244959
INFO:root:current train perplexity170.3990478515625
INFO:root:current mean train loss 6511.357800635222
INFO:root:current train perplexity170.5512237548828
INFO:root:current mean train loss 6513.296789621342
INFO:root:current train perplexity170.52325439453125
INFO:root:current mean train loss 6513.28492888993
INFO:root:current train perplexity170.62255859375
INFO:root:current mean train loss 6510.896875863124
INFO:root:current train perplexity170.53529357910156
INFO:root:current mean train loss 6513.654296295093
INFO:root:current train perplexity170.58653259277344
INFO:root:current mean train loss 6517.9931016588425
INFO:root:current train perplexity170.6581268310547
INFO:root:current mean train loss 6518.241023037337
INFO:root:current train perplexity170.75189208984375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:40<00:00, 340.22s/it]
INFO:root:final mean train loss: 6518.705589305976
INFO:root:final train perplexity: 170.89402770996094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.12s/it]
INFO:root:eval mean loss: 6289.370503310616
INFO:root:eval perplexity: 161.8181915283203
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.67s/it]
INFO:root:eval mean loss: 6409.4263396567485
INFO:root:eval perplexity: 189.01097106933594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [11:45:54<10:26:38, 399.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6191.77197265625
INFO:root:current train perplexity162.70155334472656
INFO:root:current mean train loss 6478.271271658416
INFO:root:current train perplexity170.29443359375
INFO:root:current mean train loss 6471.932211501088
INFO:root:current train perplexity169.30001831054688
INFO:root:current mean train loss 6491.398426144622
INFO:root:current train perplexity170.51812744140625
INFO:root:current mean train loss 6489.761113573488
INFO:root:current train perplexity170.23199462890625
INFO:root:current mean train loss 6502.731604174463
INFO:root:current train perplexity170.4938201904297
INFO:root:current mean train loss 6511.564522995528
INFO:root:current train perplexity170.6484375
INFO:root:current mean train loss 6515.120657709968
INFO:root:current train perplexity170.60597229003906
INFO:root:current mean train loss 6514.572935563943
INFO:root:current train perplexity170.6714630126953
INFO:root:current mean train loss 6522.124808155869
INFO:root:current train perplexity170.89019775390625
INFO:root:current mean train loss 6522.424960781406
INFO:root:current train perplexity170.9483184814453
INFO:root:current mean train loss 6521.574294143108
INFO:root:current train perplexity170.9329833984375
INFO:root:current mean train loss 6523.613111713546
INFO:root:current train perplexity171.02682495117188
INFO:root:current mean train loss 6523.105353153824
INFO:root:current train perplexity170.94546508789062
INFO:root:current mean train loss 6521.868724488088
INFO:root:current train perplexity170.93380737304688
INFO:root:current mean train loss 6524.580547213316
INFO:root:current train perplexity170.94212341308594
INFO:root:current mean train loss 6524.149712947962
INFO:root:current train perplexity170.9326629638672
INFO:root:current mean train loss 6521.356012432944
INFO:root:current train perplexity170.9038848876953
INFO:root:current mean train loss 6519.517783902606
INFO:root:current train perplexity170.88719177246094
INFO:root:current mean train loss 6518.278754911066
INFO:root:current train perplexity170.92361450195312

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:39<00:00, 339.11s/it]
INFO:root:final mean train loss: 6519.563824244358
INFO:root:final train perplexity: 171.00970458984375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it]
INFO:root:eval mean loss: 6286.737831061613
INFO:root:eval perplexity: 161.4740447998047
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.02s/it]
INFO:root:eval mean loss: 6407.539291057181
INFO:root:eval perplexity: 188.71945190429688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [11:52:27<10:16:41, 397.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6501.659044053819
INFO:root:current train perplexity171.97299194335938
INFO:root:current mean train loss 6468.960130594544
INFO:root:current train perplexity169.82215881347656
INFO:root:current mean train loss 6538.331585525373
INFO:root:current train perplexity172.05091857910156
INFO:root:current mean train loss 6539.784336306014
INFO:root:current train perplexity172.07740783691406
INFO:root:current mean train loss 6533.589809874028
INFO:root:current train perplexity171.50408935546875
INFO:root:current mean train loss 6543.059944535775
INFO:root:current train perplexity171.57156372070312
INFO:root:current mean train loss 6544.892259715059
INFO:root:current train perplexity171.58981323242188
INFO:root:current mean train loss 6541.972856866948
INFO:root:current train perplexity171.76376342773438
INFO:root:current mean train loss 6543.010237789387
INFO:root:current train perplexity171.61444091796875
INFO:root:current mean train loss 6540.223293994247
INFO:root:current train perplexity171.45175170898438
INFO:root:current mean train loss 6536.007634071096
INFO:root:current train perplexity171.24806213378906
INFO:root:current mean train loss 6535.156167891882
INFO:root:current train perplexity171.17279052734375
INFO:root:current mean train loss 6536.565324254028
INFO:root:current train perplexity171.3439483642578
INFO:root:current mean train loss 6530.33052009733
INFO:root:current train perplexity171.15025329589844
INFO:root:current mean train loss 6527.29186546853
INFO:root:current train perplexity171.11737060546875
INFO:root:current mean train loss 6527.835761229825
INFO:root:current train perplexity171.05056762695312
INFO:root:current mean train loss 6525.670899342842
INFO:root:current train perplexity171.0040740966797
INFO:root:current mean train loss 6524.527338918346
INFO:root:current train perplexity170.9789581298828
INFO:root:current mean train loss 6523.1041766041835
INFO:root:current train perplexity170.9579315185547
INFO:root:current mean train loss 6521.334347658287
INFO:root:current train perplexity170.9032440185547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.19s/it]
INFO:root:final mean train loss: 6519.296763825525
INFO:root:final train perplexity: 170.97373962402344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it]
INFO:root:eval mean loss: 6289.530439660904
INFO:root:eval perplexity: 161.839111328125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it]
INFO:root:eval mean loss: 6410.903562721631
INFO:root:eval perplexity: 189.23941040039062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [11:59:13<10:13:44, 400.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6560.237360491072
INFO:root:current train perplexity169.81309509277344
INFO:root:current mean train loss 6546.163266782408
INFO:root:current train perplexity171.14169311523438
INFO:root:current mean train loss 6502.210137549867
INFO:root:current train perplexity170.7838134765625
INFO:root:current mean train loss 6520.646007754198
INFO:root:current train perplexity170.72145080566406
INFO:root:current mean train loss 6520.971021910919
INFO:root:current train perplexity170.2380828857422
INFO:root:current mean train loss 6526.346479811624
INFO:root:current train perplexity170.45602416992188
INFO:root:current mean train loss 6514.846221395177
INFO:root:current train perplexity170.05764770507812
INFO:root:current mean train loss 6512.229895434736
INFO:root:current train perplexity170.1812744140625
INFO:root:current mean train loss 6513.745423021145
INFO:root:current train perplexity170.33633422851562
INFO:root:current mean train loss 6517.981759170288
INFO:root:current train perplexity170.48358154296875
INFO:root:current mean train loss 6513.504280363074
INFO:root:current train perplexity170.43936157226562
INFO:root:current mean train loss 6514.377162204019
INFO:root:current train perplexity170.51951599121094
INFO:root:current mean train loss 6515.96167723621
INFO:root:current train perplexity170.61134338378906
INFO:root:current mean train loss 6522.205420104752
INFO:root:current train perplexity170.7721710205078
INFO:root:current mean train loss 6522.08269987206
INFO:root:current train perplexity170.6400604248047
INFO:root:current mean train loss 6521.173307079601
INFO:root:current train perplexity170.632568359375
INFO:root:current mean train loss 6517.416947689698
INFO:root:current train perplexity170.44097900390625
INFO:root:current mean train loss 6516.1222273505045
INFO:root:current train perplexity170.4074249267578
INFO:root:current mean train loss 6514.040348262943
INFO:root:current train perplexity170.39158630371094
INFO:root:current mean train loss 6514.660110071463
INFO:root:current train perplexity170.38890075683594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:41<00:00, 341.86s/it]
INFO:root:final mean train loss: 6515.383870319592
INFO:root:final train perplexity: 170.44691467285156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.83s/it]
INFO:root:eval mean loss: 6290.658833388741
INFO:root:eval perplexity: 161.98695373535156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.58s/it]
INFO:root:eval mean loss: 6410.695260555186
INFO:root:eval perplexity: 189.2071990966797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil6_minilml6_not_concat/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [12:05:50<10:05:47, 399.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6469.198843149038
INFO:root:current train perplexity170.50341796875
INFO:root:current mean train loss 6441.535840486225
INFO:root:current train perplexity170.09544372558594
INFO:root:current mean train loss 6454.165690104167
INFO:root:current train perplexity170.2892303466797
INFO:root:current mean train loss 6477.023021351208
INFO:root:current train perplexity170.65576171875
INFO:root:current mean train loss 6479.1470990476355
INFO:root:current train perplexity170.34901428222656
INFO:root:current mean train loss 6486.842188738395
INFO:root:current train perplexity170.32398986816406
INFO:root:current mean train loss 6502.888661390433
INFO:root:current train perplexity170.4056396484375
slurmstepd: error: *** JOB 29837594 ON gr007 CANCELLED AT 2023-02-05T02:42:32 ***
