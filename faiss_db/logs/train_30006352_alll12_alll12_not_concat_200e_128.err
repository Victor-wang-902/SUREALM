INFO:root:Output: alll12_alll12_not_concat_200e_128
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L12-v1 and are newly initialized: ['encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.6.crossattention.output.dense.bias', 'cls.predictions.decoder.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.query.bias', 'cls.predictions.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.value.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.key.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.value.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.6.crossattention.self.query.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 23240.31581439394
INFO:root:current train perplexity9917.17578125
INFO:root:current mean train loss 19253.190650518216
INFO:root:current train perplexity2011.2200927734375
INFO:root:current mean train loss 16801.361141957568
INFO:root:current train perplexity762.2174682617188
INFO:root:current mean train loss 15084.72265135495
INFO:root:current train perplexity383.700927734375
INFO:root:current mean train loss 13808.026225302166
INFO:root:current train perplexity232.34095764160156
INFO:root:current mean train loss 12839.492694529945
INFO:root:current train perplexity158.15646362304688
INFO:root:current mean train loss 12077.362255789521
INFO:root:current train perplexity117.10400390625
INFO:root:current mean train loss 11462.699815809801
INFO:root:current train perplexity91.87466430664062
INFO:root:current mean train loss 10958.48294057199
INFO:root:current train perplexity75.264404296875

100%|██████████| 1/1 [08:35<00:00, 515.55s/it][A100%|██████████| 1/1 [08:35<00:00, 515.55s/it]
INFO:root:final mean train loss: 10556.47331237793
INFO:root:final train perplexity: 64.38202667236328
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.82s/it][A100%|██████████| 1/1 [00:38<00:00, 38.82s/it]
INFO:root:eval mean loss: 6181.440266927083
INFO:root:eval perplexity: 12.177536964416504
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.38s/it][A100%|██████████| 1/1 [00:37<00:00, 37.38s/it]
INFO:root:eval mean loss: 6717.457637272828
INFO:root:eval perplexity: 15.593602180480957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/1
  0%|          | 1/200 [09:52<32:46:35, 592.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6497.320731026785
INFO:root:current train perplexity13.138251304626465
INFO:root:current mean train loss 6566.545921254381
INFO:root:current train perplexity13.187078475952148
INFO:root:current mean train loss 6473.171325388738
INFO:root:current train perplexity12.71805191040039
INFO:root:current mean train loss 6400.260517928034
INFO:root:current train perplexity12.416526794433594
INFO:root:current mean train loss 6327.172419667537
INFO:root:current train perplexity12.097978591918945
INFO:root:current mean train loss 6273.725732325567
INFO:root:current train perplexity11.835220336914062
INFO:root:current mean train loss 6218.483453137871
INFO:root:current train perplexity11.598491668701172
INFO:root:current mean train loss 6177.667816809582
INFO:root:current train perplexity11.3930025100708
INFO:root:current mean train loss 6128.552201924566
INFO:root:current train perplexity11.198681831359863
INFO:root:current mean train loss 6082.49162815687
INFO:root:current train perplexity10.99263858795166

100%|██████████| 1/1 [08:30<00:00, 510.53s/it][A100%|██████████| 1/1 [08:30<00:00, 510.53s/it]
INFO:root:final mean train loss: 6045.9238003146265
INFO:root:final train perplexity: 10.862232208251953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.16s/it][A100%|██████████| 1/1 [00:38<00:00, 38.16s/it]
INFO:root:eval mean loss: 5318.359922152039
INFO:root:eval perplexity: 8.589914321899414
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.27s/it][A100%|██████████| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 5958.926660848848
INFO:root:eval perplexity: 11.43509292602539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/2
  1%|          | 2/200 [19:52<32:49:06, 596.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5613.292024739583
INFO:root:current train perplexity9.217930793762207
INFO:root:current mean train loss 5606.594081182066
INFO:root:current train perplexity9.164287567138672
INFO:root:current mean train loss 5596.413001907704
INFO:root:current train perplexity9.084088325500488
INFO:root:current mean train loss 5571.979964967758
INFO:root:current train perplexity8.998760223388672
INFO:root:current mean train loss 5556.9552840267315
INFO:root:current train perplexity8.932209968566895
INFO:root:current mean train loss 5529.21005859375
INFO:root:current train perplexity8.846549034118652
INFO:root:current mean train loss 5504.6628445757115
INFO:root:current train perplexity8.769509315490723
INFO:root:current mean train loss 5484.123425890516
INFO:root:current train perplexity8.692560195922852
INFO:root:current mean train loss 5463.69518968079
INFO:root:current train perplexity8.617107391357422
INFO:root:current mean train loss 5448.6462613131835
INFO:root:current train perplexity8.565679550170898

100%|██████████| 1/1 [08:40<00:00, 520.84s/it][A100%|██████████| 1/1 [08:40<00:00, 520.84s/it]
INFO:root:final mean train loss: 5432.105302379978
INFO:root:final train perplexity: 8.526021957397461
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.11s/it][A100%|██████████| 1/1 [00:38<00:00, 38.11s/it]
INFO:root:eval mean loss: 4953.583343722296
INFO:root:eval perplexity: 7.411877155303955
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.50s/it][A100%|██████████| 1/1 [00:36<00:00, 36.50s/it]
INFO:root:eval mean loss: 5639.210355718085
INFO:root:eval perplexity: 10.033712387084961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/3
  2%|▏         | 3/200 [29:49<32:39:36, 596.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5178.809612771739
INFO:root:current train perplexity7.761798858642578
INFO:root:current mean train loss 5217.003445757114
INFO:root:current train perplexity7.82866096496582
INFO:root:current mean train loss 5218.050115610987
INFO:root:current train perplexity7.785674571990967
INFO:root:current mean train loss 5191.255256204044
INFO:root:current train perplexity7.741653919219971
INFO:root:current mean train loss 5171.818178145316
INFO:root:current train perplexity7.688571929931641
INFO:root:current mean train loss 5149.490543401948
INFO:root:current train perplexity7.637450695037842
INFO:root:current mean train loss 5147.645775857744
INFO:root:current train perplexity7.6197428703308105
INFO:root:current mean train loss 5136.527399804418
INFO:root:current train perplexity7.577813625335693
INFO:root:current mean train loss 5126.938045237507
INFO:root:current train perplexity7.547298431396484
INFO:root:current mean train loss 5113.004425743161
INFO:root:current train perplexity7.509028911590576

100%|██████████| 1/1 [08:35<00:00, 515.24s/it][A100%|██████████| 1/1 [08:35<00:00, 515.24s/it]
INFO:root:final mean train loss: 5100.4325497534965
INFO:root:final train perplexity: 7.4802656173706055
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.73s/it][A100%|██████████| 1/1 [00:38<00:00, 38.74s/it]
INFO:root:eval mean loss: 4716.364105441046
INFO:root:eval perplexity: 6.7339324951171875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.36s/it][A100%|██████████| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 5428.981767370346
INFO:root:eval perplexity: 9.207195281982422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/4
  2%|▏         | 4/200 [39:42<32:24:38, 595.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5002.804277973791
INFO:root:current train perplexity7.101083755493164
INFO:root:current mean train loss 4951.940347686069
INFO:root:current train perplexity7.025057315826416
INFO:root:current mean train loss 4940.942427201705
INFO:root:current train perplexity7.018298149108887
INFO:root:current mean train loss 4933.139495019826
INFO:root:current train perplexity6.992715358734131
INFO:root:current mean train loss 4931.175263513269
INFO:root:current train perplexity6.9830546379089355
INFO:root:current mean train loss 4924.368350731226
INFO:root:current train perplexity6.962182521820068
INFO:root:current mean train loss 4916.288349810568
INFO:root:current train perplexity6.932702541351318
INFO:root:current mean train loss 4903.342116829472
INFO:root:current train perplexity6.903109073638916
INFO:root:current mean train loss 4894.178203853603
INFO:root:current train perplexity6.882967472076416
INFO:root:current mean train loss 4889.934563494395
INFO:root:current train perplexity6.869452953338623

100%|██████████| 1/1 [08:35<00:00, 515.02s/it][A100%|██████████| 1/1 [08:35<00:00, 515.02s/it]
INFO:root:final mean train loss: 4880.292165325534
INFO:root:final train perplexity: 6.858005046844482
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.14s/it][A100%|██████████| 1/1 [00:38<00:00, 38.14s/it]
INFO:root:eval mean loss: 4558.022886884974
INFO:root:eval perplexity: 6.316280841827393
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.01s/it][A100%|██████████| 1/1 [00:37<00:00, 37.01s/it]
INFO:root:eval mean loss: 5289.654201642841
INFO:root:eval perplexity: 8.697297096252441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/5
  2%|▎         | 5/200 [49:33<32:10:25, 593.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4788.10705879407
INFO:root:current train perplexity6.6723761558532715
INFO:root:current mean train loss 4789.021020683454
INFO:root:current train perplexity6.59852933883667
INFO:root:current mean train loss 4772.422718766345
INFO:root:current train perplexity6.583885669708252
INFO:root:current mean train loss 4767.672701765302
INFO:root:current train perplexity6.563230514526367
INFO:root:current mean train loss 4759.608470734268
INFO:root:current train perplexity6.537639141082764
INFO:root:current mean train loss 4751.5078813485625
INFO:root:current train perplexity6.520604610443115
INFO:root:current mean train loss 4749.176188533108
INFO:root:current train perplexity6.50269889831543
INFO:root:current mean train loss 4740.9786738704115
INFO:root:current train perplexity6.489572048187256
INFO:root:current mean train loss 4733.791607207706
INFO:root:current train perplexity6.47110652923584
INFO:root:current mean train loss 4731.829561503678
INFO:root:current train perplexity6.460991382598877

100%|██████████| 1/1 [08:34<00:00, 514.63s/it][A100%|██████████| 1/1 [08:34<00:00, 514.63s/it]
INFO:root:final mean train loss: 4727.949041181995
INFO:root:final train perplexity: 6.4579548835754395
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.89s/it][A100%|██████████| 1/1 [00:37<00:00, 37.89s/it]
INFO:root:eval mean loss: 4455.768940810616
INFO:root:eval perplexity: 6.060439586639404
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.70s/it][A100%|██████████| 1/1 [00:36<00:00, 36.70s/it]
INFO:root:eval mean loss: 5200.760717946587
INFO:root:eval perplexity: 8.386829376220703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/6
  3%|▎         | 6/200 [59:24<31:56:54, 592.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4602.922768450798
INFO:root:current train perplexity6.163524150848389
INFO:root:current mean train loss 4614.118747010523
INFO:root:current train perplexity6.18681001663208
INFO:root:current mean train loss 4635.709507251076
INFO:root:current train perplexity6.203055381774902
INFO:root:current mean train loss 4641.358173996983
INFO:root:current train perplexity6.21740198135376
INFO:root:current mean train loss 4638.367032932222
INFO:root:current train perplexity6.210849761962891
INFO:root:current mean train loss 4633.89128690228
INFO:root:current train perplexity6.2051825523376465
INFO:root:current mean train loss 4625.498346107636
INFO:root:current train perplexity6.190768241882324
INFO:root:current mean train loss 4624.776733235023
INFO:root:current train perplexity6.189507007598877
INFO:root:current mean train loss 4616.17103650522
INFO:root:current train perplexity6.176055431365967
INFO:root:current mean train loss 4614.752688382721
INFO:root:current train perplexity6.1654462814331055

100%|██████████| 1/1 [08:34<00:00, 514.07s/it][A100%|██████████| 1/1 [08:34<00:00, 514.07s/it]
INFO:root:final mean train loss: 4608.793297798403
INFO:root:final train perplexity: 6.161389350891113
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.63s/it][A100%|██████████| 1/1 [00:37<00:00, 37.63s/it]
INFO:root:eval mean loss: 4368.235432942708
INFO:root:eval perplexity: 5.849675178527832
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.80s/it][A100%|██████████| 1/1 [00:36<00:00, 36.80s/it]
INFO:root:eval mean loss: 5127.04757798648
INFO:root:eval perplexity: 8.137802124023438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/7
  4%|▎         | 7/200 [1:09:14<31:43:58, 591.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4567.136736505682
INFO:root:current train perplexity6.0226521492004395
INFO:root:current mean train loss 4526.139541330645
INFO:root:current train perplexity5.942986965179443
INFO:root:current mean train loss 4545.06585669424
INFO:root:current train perplexity5.9714202880859375
INFO:root:current mean train loss 4546.348302706866
INFO:root:current train perplexity5.974096775054932
INFO:root:current mean train loss 4536.950195849073
INFO:root:current train perplexity5.966048717498779
INFO:root:current mean train loss 4531.337706749719
INFO:root:current train perplexity5.9615159034729
INFO:root:current mean train loss 4528.668903566317
INFO:root:current train perplexity5.9585981369018555
INFO:root:current mean train loss 4527.141291778767
INFO:root:current train perplexity5.956571578979492
INFO:root:current mean train loss 4523.64888723273
INFO:root:current train perplexity5.948080539703369
INFO:root:current mean train loss 4521.087170985356
INFO:root:current train perplexity5.944967746734619

100%|██████████| 1/1 [08:34<00:00, 514.38s/it][A100%|██████████| 1/1 [08:34<00:00, 514.38s/it]
INFO:root:final mean train loss: 4516.468425627678
INFO:root:final train perplexity: 5.940999507904053
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.31s/it][A100%|██████████| 1/1 [00:38<00:00, 38.31s/it]
INFO:root:eval mean loss: 4307.189375207779
INFO:root:eval perplexity: 5.707043647766113
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.83s/it][A100%|██████████| 1/1 [00:36<00:00, 36.83s/it]
INFO:root:eval mean loss: 5078.91824232602
INFO:root:eval perplexity: 7.979210376739502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/8
  4%|▍         | 8/200 [1:19:05<31:33:10, 591.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4461.462235708085
INFO:root:current train perplexity5.838768005371094
INFO:root:current mean train loss 4461.807328113017
INFO:root:current train perplexity5.825096607208252
INFO:root:current mean train loss 4478.005890936906
INFO:root:current train perplexity5.844028949737549
INFO:root:current mean train loss 4480.779044663611
INFO:root:current train perplexity5.84800910949707
INFO:root:current mean train loss 4486.30678879674
INFO:root:current train perplexity5.853928565979004
INFO:root:current mean train loss 4487.803300278225
INFO:root:current train perplexity5.860263347625732
INFO:root:current mean train loss 4481.050834276018
INFO:root:current train perplexity5.856049060821533
INFO:root:current mean train loss 4481.439248661226
INFO:root:current train perplexity5.852914810180664
INFO:root:current mean train loss 4482.840071482565
INFO:root:current train perplexity5.853730201721191
INFO:root:current mean train loss 4479.328089253553
INFO:root:current train perplexity5.846355438232422

100%|██████████| 1/1 [08:34<00:00, 514.87s/it][A100%|██████████| 1/1 [08:34<00:00, 514.87s/it]
INFO:root:final mean train loss: 4475.039605232977
INFO:root:final train perplexity: 5.844685077667236
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.09s/it][A100%|██████████| 1/1 [00:38<00:00, 38.09s/it]
INFO:root:eval mean loss: 4253.437848030253
INFO:root:eval perplexity: 5.584335803985596
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.81s/it][A100%|██████████| 1/1 [00:36<00:00, 36.81s/it]
INFO:root:eval mean loss: 5039.076017772052
INFO:root:eval perplexity: 7.85026741027832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/9
  4%|▍         | 9/200 [1:28:56<31:22:55, 591.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4406.719743755501
INFO:root:current train perplexity5.723127365112305
INFO:root:current mean train loss 4425.19632761102
INFO:root:current train perplexity5.7300262451171875
INFO:root:current mean train loss 4409.111292089483
INFO:root:current train perplexity5.703519344329834
INFO:root:current mean train loss 4409.111332073366
INFO:root:current train perplexity5.700926780700684
INFO:root:current mean train loss 4413.659586070196
INFO:root:current train perplexity5.699891567230225
INFO:root:current mean train loss 4413.4922524901485
INFO:root:current train perplexity5.694085121154785
INFO:root:current mean train loss 4409.045668123021
INFO:root:current train perplexity5.685835838317871
INFO:root:current mean train loss 4408.404116698585
INFO:root:current train perplexity5.683424472808838
INFO:root:current mean train loss 4412.358353589624
INFO:root:current train perplexity5.689004421234131
INFO:root:current mean train loss 4407.317626450261
INFO:root:current train perplexity5.679333686828613

100%|██████████| 1/1 [08:34<00:00, 514.68s/it][A100%|██████████| 1/1 [08:34<00:00, 514.68s/it]
INFO:root:final mean train loss: 4401.399753385975
INFO:root:final train perplexity: 5.6773200035095215
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.09s/it][A100%|██████████| 1/1 [00:38<00:00, 38.10s/it]
INFO:root:eval mean loss: 4195.720663300643
INFO:root:eval perplexity: 5.455511093139648
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.85s/it][A100%|██████████| 1/1 [00:36<00:00, 36.85s/it]
INFO:root:eval mean loss: 4991.77596548094
INFO:root:eval perplexity: 7.699888706207275
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/10
  5%|▌         | 10/200 [1:38:47<31:12:47, 591.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4381.981624554985
INFO:root:current train perplexity5.578447341918945
INFO:root:current mean train loss 4370.8178820050625
INFO:root:current train perplexity5.563665866851807
INFO:root:current mean train loss 4353.166119756665
INFO:root:current train perplexity5.549093723297119
INFO:root:current mean train loss 4351.210433114487
INFO:root:current train perplexity5.549396514892578
INFO:root:current mean train loss 4347.0653374339445
INFO:root:current train perplexity5.550260066986084
INFO:root:current mean train loss 4348.676465181077
INFO:root:current train perplexity5.546445846557617
INFO:root:current mean train loss 4345.70175939456
INFO:root:current train perplexity5.540680408477783
INFO:root:current mean train loss 4341.952254054176
INFO:root:current train perplexity5.535151481628418
INFO:root:current mean train loss 4339.74390176159
INFO:root:current train perplexity5.530566215515137
INFO:root:current mean train loss 4336.894841475677
INFO:root:current train perplexity5.5272626876831055

100%|██████████| 1/1 [08:35<00:00, 515.10s/it][A100%|██████████| 1/1 [08:35<00:00, 515.10s/it]
INFO:root:final mean train loss: 4333.098898856871
INFO:root:final train perplexity: 5.52638053894043
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.10s/it][A100%|██████████| 1/1 [00:38<00:00, 38.10s/it]
INFO:root:eval mean loss: 4165.100904532358
INFO:root:eval perplexity: 5.388379096984863
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.87s/it][A100%|██████████| 1/1 [00:36<00:00, 36.87s/it]
INFO:root:eval mean loss: 4968.9190821005095
INFO:root:eval perplexity: 7.6282572746276855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/11
  6%|▌         | 11/200 [1:48:39<31:03:04, 591.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4279.130505792026
INFO:root:current train perplexity5.390570640563965
INFO:root:current mean train loss 4282.216774680398
INFO:root:current train perplexity5.410586357116699
INFO:root:current mean train loss 4274.548972737914
INFO:root:current train perplexity5.411877632141113
INFO:root:current mean train loss 4274.285461583495
INFO:root:current train perplexity5.3884596824646
INFO:root:current mean train loss 4275.509029192602
INFO:root:current train perplexity5.386868476867676
INFO:root:current mean train loss 4279.806089956878
INFO:root:current train perplexity5.394226551055908
INFO:root:current mean train loss 4276.665052566639
INFO:root:current train perplexity5.392836570739746
INFO:root:current mean train loss 4275.831685978696
INFO:root:current train perplexity5.393792152404785
INFO:root:current mean train loss 4275.409664941076
INFO:root:current train perplexity5.397297382354736
INFO:root:current mean train loss 4274.7696371184775
INFO:root:current train perplexity5.394032955169678

100%|██████████| 1/1 [08:30<00:00, 510.82s/it][A100%|██████████| 1/1 [08:30<00:00, 510.82s/it]
INFO:root:final mean train loss: 4271.37663269043
INFO:root:final train perplexity: 5.393430233001709
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.20s/it][A100%|██████████| 1/1 [00:38<00:00, 38.20s/it]
INFO:root:eval mean loss: 4094.2702619403813
INFO:root:eval perplexity: 5.236235618591309
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.66s/it][A100%|██████████| 1/1 [00:36<00:00, 36.66s/it]
INFO:root:eval mean loss: 4905.5916375775705
INFO:root:eval perplexity: 7.433254718780518
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/12
  6%|▌         | 12/200 [1:58:26<30:49:08, 590.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4217.467439350329
INFO:root:current train perplexity5.275247097015381
INFO:root:current mean train loss 4217.32542192508
INFO:root:current train perplexity5.266983985900879
INFO:root:current mean train loss 4223.752029263771
INFO:root:current train perplexity5.287760257720947
INFO:root:current mean train loss 4223.552387633505
INFO:root:current train perplexity5.286235809326172
INFO:root:current mean train loss 4220.47795878709
INFO:root:current train perplexity5.279688358306885
INFO:root:current mean train loss 4215.643951056985
INFO:root:current train perplexity5.279480934143066
INFO:root:current mean train loss 4216.698622274056
INFO:root:current train perplexity5.275233268737793
INFO:root:current mean train loss 4218.756670720322
INFO:root:current train perplexity5.277915954589844
INFO:root:current mean train loss 4219.984953845146
INFO:root:current train perplexity5.2781291007995605

100%|██████████| 1/1 [08:32<00:00, 512.36s/it][A100%|██████████| 1/1 [08:32<00:00, 512.36s/it]
INFO:root:final mean train loss: 4216.255413178475
INFO:root:final train perplexity: 5.277406215667725
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.16s/it][A100%|██████████| 1/1 [00:38<00:00, 38.16s/it]
INFO:root:eval mean loss: 4056.5221129072474
INFO:root:eval perplexity: 5.156913757324219
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.94s/it][A100%|██████████| 1/1 [00:36<00:00, 36.94s/it]
INFO:root:eval mean loss: 4876.625232020168
INFO:root:eval perplexity: 7.34572696685791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/13
  6%|▋         | 13/200 [2:08:15<30:38:07, 589.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4172.606038411458
INFO:root:current train perplexity5.1828203201293945
INFO:root:current mean train loss 4167.386851486651
INFO:root:current train perplexity5.194298267364502
INFO:root:current mean train loss 4169.864780970982
INFO:root:current train perplexity5.177981376647949
INFO:root:current mean train loss 4170.967286767739
INFO:root:current train perplexity5.169482231140137
INFO:root:current mean train loss 4163.411877956343
INFO:root:current train perplexity5.169496059417725
INFO:root:current mean train loss 4161.504871163643
INFO:root:current train perplexity5.167556285858154
INFO:root:current mean train loss 4162.949395276223
INFO:root:current train perplexity5.168798446655273
INFO:root:current mean train loss 4170.522878372822
INFO:root:current train perplexity5.1779866218566895
INFO:root:current mean train loss 4167.850119850852
INFO:root:current train perplexity5.17874813079834
INFO:root:current mean train loss 4168.617674970152
INFO:root:current train perplexity5.17691707611084

100%|██████████| 1/1 [08:30<00:00, 510.93s/it][A100%|██████████| 1/1 [08:30<00:00, 510.93s/it]
INFO:root:final mean train loss: 4168.656386160082
INFO:root:final train perplexity: 5.179224967956543
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.82s/it][A100%|██████████| 1/1 [00:37<00:00, 37.82s/it]
INFO:root:eval mean loss: 4027.114460397274
INFO:root:eval perplexity: 5.095953464508057
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.86s/it][A100%|██████████| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 4846.82971797429
INFO:root:eval perplexity: 7.256772994995117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/14
  7%|▋         | 14/200 [2:18:02<30:25:45, 588.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4170.071954900568
INFO:root:current train perplexity4.956143379211426
INFO:root:current mean train loss 4136.039843310107
INFO:root:current train perplexity5.080795764923096
INFO:root:current mean train loss 4133.892892846564
INFO:root:current train perplexity5.075608730316162
INFO:root:current mean train loss 4131.2711640876205
INFO:root:current train perplexity5.077665328979492
INFO:root:current mean train loss 4126.396295477874
INFO:root:current train perplexity5.075826168060303
INFO:root:current mean train loss 4120.529079967282
INFO:root:current train perplexity5.0747151374816895
INFO:root:current mean train loss 4123.9277907151445
INFO:root:current train perplexity5.08176851272583
INFO:root:current mean train loss 4122.210574207762
INFO:root:current train perplexity5.0796074867248535
INFO:root:current mean train loss 4128.45559681094
INFO:root:current train perplexity5.088587284088135
INFO:root:current mean train loss 4129.052554820424
INFO:root:current train perplexity5.091122627258301

100%|██████████| 1/1 [08:31<00:00, 511.06s/it][A100%|██████████| 1/1 [08:31<00:00, 511.06s/it]
INFO:root:final mean train loss: 4127.244492623114
INFO:root:final train perplexity: 5.095293998718262
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.77s/it][A100%|██████████| 1/1 [00:37<00:00, 37.77s/it]
INFO:root:eval mean loss: 3983.416386164672
INFO:root:eval perplexity: 5.0066986083984375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.77s/it][A100%|██████████| 1/1 [00:36<00:00, 36.77s/it]
INFO:root:eval mean loss: 4814.477407468971
INFO:root:eval perplexity: 7.161404609680176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/15
  8%|▊         | 15/200 [2:27:49<30:14:17, 588.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4066.288150185033
INFO:root:current train perplexity5.037530422210693
INFO:root:current mean train loss 4091.774924911371
INFO:root:current train perplexity5.042077541351318
INFO:root:current mean train loss 4088.653248965468
INFO:root:current train perplexity5.0191850662231445
INFO:root:current mean train loss 4101.572900849824
INFO:root:current train perplexity5.035024166107178
INFO:root:current mean train loss 4093.1279098765663
INFO:root:current train perplexity5.0193963050842285
INFO:root:current mean train loss 4094.604254162151
INFO:root:current train perplexity5.0166544914245605
INFO:root:current mean train loss 4090.163523339686
INFO:root:current train perplexity5.0123982429504395
INFO:root:current mean train loss 4094.038785082906
INFO:root:current train perplexity5.01108980178833
INFO:root:current mean train loss 4091.110116364755
INFO:root:current train perplexity5.012523174285889
INFO:root:current mean train loss 4090.483525156845
INFO:root:current train perplexity5.014211177825928

100%|██████████| 1/1 [08:30<00:00, 510.61s/it][A100%|██████████| 1/1 [08:30<00:00, 510.61s/it]
INFO:root:final mean train loss: 4083.1930031314973
INFO:root:final train perplexity: 5.007505893707275
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.01s/it][A100%|██████████| 1/1 [00:38<00:00, 38.02s/it]
INFO:root:eval mean loss: 3960.2528483072915
INFO:root:eval perplexity: 4.960020542144775
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.88s/it][A100%|██████████| 1/1 [00:36<00:00, 36.88s/it]
INFO:root:eval mean loss: 4789.15717634918
INFO:root:eval perplexity: 7.087637424468994
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/16
  8%|▊         | 16/200 [2:37:36<30:03:11, 588.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4104.212899667245
INFO:root:current train perplexity4.956076622009277
INFO:root:current mean train loss 4073.2120563176672
INFO:root:current train perplexity4.974862575531006
INFO:root:current mean train loss 4058.6890379783868
INFO:root:current train perplexity4.961174488067627
INFO:root:current mean train loss 4060.5730525492163
INFO:root:current train perplexity4.9540228843688965
INFO:root:current mean train loss 4059.1045785229435
INFO:root:current train perplexity4.950959205627441
INFO:root:current mean train loss 4052.8601852503853
INFO:root:current train perplexity4.945912837982178
INFO:root:current mean train loss 4047.37457324063
INFO:root:current train perplexity4.934573173522949
INFO:root:current mean train loss 4051.8744267564693
INFO:root:current train perplexity4.939760208129883
INFO:root:current mean train loss 4053.3628685431154
INFO:root:current train perplexity4.945616245269775
INFO:root:current mean train loss 4049.916739619151
INFO:root:current train perplexity4.938703536987305

100%|██████████| 1/1 [08:32<00:00, 512.37s/it][A100%|██████████| 1/1 [08:32<00:00, 512.37s/it]
INFO:root:final mean train loss: 4050.062879562378
INFO:root:final train perplexity: 4.942479133605957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.72s/it][A100%|██████████| 1/1 [00:37<00:00, 37.72s/it]
INFO:root:eval mean loss: 3960.333773132757
INFO:root:eval perplexity: 4.960183143615723
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.55s/it][A100%|██████████| 1/1 [00:36<00:00, 36.55s/it]
INFO:root:eval mean loss: 4788.9764032025705
INFO:root:eval perplexity: 7.0871148109436035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/17
  8%|▊         | 17/200 [2:47:24<29:53:33, 588.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4080.8481236049106
INFO:root:current train perplexity4.948115825653076
INFO:root:current mean train loss 4027.0153718171296
INFO:root:current train perplexity4.903575897216797
INFO:root:current mean train loss 4019.828989361702
INFO:root:current train perplexity4.880224704742432
INFO:root:current mean train loss 4021.1064139750465
INFO:root:current train perplexity4.881793975830078
INFO:root:current mean train loss 4017.523681640625
INFO:root:current train perplexity4.880758762359619
INFO:root:current mean train loss 4018.050056129527
INFO:root:current train perplexity4.880941867828369
INFO:root:current mean train loss 4023.5904027743604
INFO:root:current train perplexity4.887813091278076
INFO:root:current mean train loss 4020.415852200255
INFO:root:current train perplexity4.886275291442871
INFO:root:current mean train loss 4017.9853869409617
INFO:root:current train perplexity4.882279872894287
INFO:root:current mean train loss 4021.5873161764707
INFO:root:current train perplexity4.8835368156433105

100%|██████████| 1/1 [08:32<00:00, 512.70s/it][A100%|██████████| 1/1 [08:32<00:00, 512.70s/it]
INFO:root:final mean train loss: 4017.369676343856
INFO:root:final train perplexity: 4.8791375160217285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.61s/it][A100%|██████████| 1/1 [00:37<00:00, 37.61s/it]
INFO:root:eval mean loss: 3952.636999251995
INFO:root:eval perplexity: 4.944769859313965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.08s/it][A100%|██████████| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 4798.822270819482
INFO:root:eval perplexity: 7.115705490112305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/18
  9%|▉         | 18/200 [2:57:13<29:44:28, 588.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3931.9084188771803
INFO:root:current train perplexity4.7942962646484375
INFO:root:current mean train loss 3966.7375915100524
INFO:root:current train perplexity4.788318157196045
INFO:root:current mean train loss 3969.41811443062
INFO:root:current train perplexity4.800073146820068
INFO:root:current mean train loss 3971.44252588033
INFO:root:current train perplexity4.796205043792725
INFO:root:current mean train loss 3981.429100019399
INFO:root:current train perplexity4.81011962890625
INFO:root:current mean train loss 3983.8575207901704
INFO:root:current train perplexity4.811674118041992
INFO:root:current mean train loss 3982.922515157222
INFO:root:current train perplexity4.81072473526001
INFO:root:current mean train loss 3985.694334294562
INFO:root:current train perplexity4.810426712036133
INFO:root:current mean train loss 3989.0529382599348
INFO:root:current train perplexity4.818204402923584
INFO:root:current mean train loss 3990.802426804414
INFO:root:current train perplexity4.823068141937256

100%|██████████| 1/1 [08:31<00:00, 511.39s/it][A100%|██████████| 1/1 [08:31<00:00, 511.39s/it]
INFO:root:final mean train loss: 3988.968247136762
INFO:root:final train perplexity: 4.824771404266357
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.84s/it][A100%|██████████| 1/1 [00:37<00:00, 37.84s/it]
INFO:root:eval mean loss: 3904.492987450133
INFO:root:eval perplexity: 4.849435329437256
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.24s/it][A100%|██████████| 1/1 [00:37<00:00, 37.24s/it]
INFO:root:eval mean loss: 4744.035109499668
INFO:root:eval perplexity: 6.958063125610352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/19
 10%|▉         | 19/200 [3:07:01<29:34:20, 588.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3973.683277803309
INFO:root:current train perplexity4.81563663482666
INFO:root:current mean train loss 3963.0022764900664
INFO:root:current train perplexity4.791851043701172
INFO:root:current mean train loss 3951.3271289840636
INFO:root:current train perplexity4.7628350257873535
INFO:root:current mean train loss 3965.3247598936077
INFO:root:current train perplexity4.781064987182617
INFO:root:current mean train loss 3959.299695338484
INFO:root:current train perplexity4.7730255126953125
INFO:root:current mean train loss 3962.8030188364905
INFO:root:current train perplexity4.77198600769043
INFO:root:current mean train loss 3963.704901488695
INFO:root:current train perplexity4.769407272338867
INFO:root:current mean train loss 3960.5264390318116
INFO:root:current train perplexity4.763768672943115
INFO:root:current mean train loss 3962.845886158747
INFO:root:current train perplexity4.767314910888672
INFO:root:current mean train loss 3962.867721220672
INFO:root:current train perplexity4.768786907196045

100%|██████████| 1/1 [08:32<00:00, 512.02s/it][A100%|██████████| 1/1 [08:32<00:00, 512.02s/it]
INFO:root:final mean train loss: 3959.958901374571
INFO:root:final train perplexity: 4.769866466522217
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.60s/it][A100%|██████████| 1/1 [00:37<00:00, 37.60s/it]
INFO:root:eval mean loss: 3884.9141508061834
INFO:root:eval perplexity: 4.811193466186523
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.74s/it][A100%|██████████| 1/1 [00:36<00:00, 36.74s/it]
INFO:root:eval mean loss: 4730.737574800532
INFO:root:eval perplexity: 6.920331954956055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/20
 10%|█         | 20/200 [3:16:49<29:24:13, 588.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3936.2288342492056
INFO:root:current train perplexity4.729320526123047
INFO:root:current mean train loss 3939.5926137480346
INFO:root:current train perplexity4.700745582580566
INFO:root:current mean train loss 3931.5874051716337
INFO:root:current train perplexity4.713289737701416
INFO:root:current mean train loss 3938.102631550313
INFO:root:current train perplexity4.7125468254089355
INFO:root:current mean train loss 3942.520657275497
INFO:root:current train perplexity4.723394393920898
INFO:root:current mean train loss 3946.7625983550424
INFO:root:current train perplexity4.730338096618652
INFO:root:current mean train loss 3941.038346378865
INFO:root:current train perplexity4.722123622894287
INFO:root:current mean train loss 3942.404531687459
INFO:root:current train perplexity4.723556041717529
INFO:root:current mean train loss 3945.286693284342
INFO:root:current train perplexity4.728336811065674
INFO:root:current mean train loss 3940.0141945243254
INFO:root:current train perplexity4.724846839904785

100%|██████████| 1/1 [08:31<00:00, 511.19s/it][A100%|██████████| 1/1 [08:31<00:00, 511.19s/it]
INFO:root:final mean train loss: 3936.498784034483
INFO:root:final train perplexity: 4.725922107696533
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.59s/it][A100%|██████████| 1/1 [00:37<00:00, 37.59s/it]
INFO:root:eval mean loss: 3869.541547193595
INFO:root:eval perplexity: 4.781379222869873
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.95s/it][A100%|██████████| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 4724.318977518285
INFO:root:eval perplexity: 6.902190685272217
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/21
 10%|█         | 21/200 [3:26:36<29:13:38, 587.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3943.081601270989
INFO:root:current train perplexity4.709195613861084
INFO:root:current mean train loss 3932.1457095574474
INFO:root:current train perplexity4.701513290405273
INFO:root:current mean train loss 3917.6547385226477
INFO:root:current train perplexity4.69705867767334
INFO:root:current mean train loss 3920.5268913913487
INFO:root:current train perplexity4.691224098205566
INFO:root:current mean train loss 3913.0964350240897
INFO:root:current train perplexity4.674249649047852
INFO:root:current mean train loss 3909.6398826747136
INFO:root:current train perplexity4.674331188201904
INFO:root:current mean train loss 3911.5856183236506
INFO:root:current train perplexity4.673704624176025
INFO:root:current mean train loss 3912.667807368909
INFO:root:current train perplexity4.672478199005127
INFO:root:current mean train loss 3916.0817862645977
INFO:root:current train perplexity4.677420139312744
INFO:root:current mean train loss 3916.5911813477574
INFO:root:current train perplexity4.683034420013428

100%|██████████| 1/1 [08:31<00:00, 511.48s/it][A100%|██████████| 1/1 [08:31<00:00, 511.48s/it]
INFO:root:final mean train loss: 3913.4454988664197
INFO:root:final train perplexity: 4.683133125305176
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.20s/it][A100%|██████████| 1/1 [00:38<00:00, 38.20s/it]
INFO:root:eval mean loss: 3877.2940855634974
INFO:root:eval perplexity: 4.796392440795898
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.86s/it][A100%|██████████| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 4727.222588721742
INFO:root:eval perplexity: 6.910390853881836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/22
 11%|█         | 22/200 [3:36:24<29:04:02, 587.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3923.826461588542
INFO:root:current train perplexity4.660700798034668
INFO:root:current mean train loss 3917.657936662946
INFO:root:current train perplexity4.640711784362793
INFO:root:current mean train loss 3898.5251216264205
INFO:root:current train perplexity4.626162052154541
INFO:root:current mean train loss 3891.559494140625
INFO:root:current train perplexity4.619471549987793
INFO:root:current mean train loss 3885.30660104852
INFO:root:current train perplexity4.622191905975342
INFO:root:current mean train loss 3890.53483313519
INFO:root:current train perplexity4.6277008056640625
INFO:root:current mean train loss 3891.7706029369215
INFO:root:current train perplexity4.628912448883057
INFO:root:current mean train loss 3888.7784167086693
INFO:root:current train perplexity4.624475002288818
INFO:root:current mean train loss 3891.6928387276785
INFO:root:current train perplexity4.632125377655029
INFO:root:current mean train loss 3891.4396995192305
INFO:root:current train perplexity4.636303901672363

100%|██████████| 1/1 [08:36<00:00, 516.61s/it][A100%|██████████| 1/1 [08:36<00:00, 516.61s/it]
INFO:root:final mean train loss: 3887.583792225007
INFO:root:final train perplexity: 4.635593891143799
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.53s/it][A100%|██████████| 1/1 [00:37<00:00, 37.53s/it]
INFO:root:eval mean loss: 3843.6597978307846
INFO:root:eval perplexity: 4.731598377227783
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.82s/it][A100%|██████████| 1/1 [00:36<00:00, 36.82s/it]
INFO:root:eval mean loss: 4700.072727933843
INFO:root:eval perplexity: 6.834096908569336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/23
 12%|█▏        | 23/200 [3:46:17<28:58:16, 589.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3861.3631430016944
INFO:root:current train perplexity4.590196132659912
INFO:root:current mean train loss 3859.1544849833504
INFO:root:current train perplexity4.590526103973389
INFO:root:current mean train loss 3874.787542444236
INFO:root:current train perplexity4.602025508880615
INFO:root:current mean train loss 3870.6979017929993
INFO:root:current train perplexity4.60108757019043
INFO:root:current mean train loss 3866.313403269766
INFO:root:current train perplexity4.596139430999756
INFO:root:current mean train loss 3865.6049997319897
INFO:root:current train perplexity4.592162132263184
INFO:root:current mean train loss 3865.9892663913797
INFO:root:current train perplexity4.596183776855469
INFO:root:current mean train loss 3866.0343948305795
INFO:root:current train perplexity4.598170757293701
INFO:root:current mean train loss 3869.271925099979
INFO:root:current train perplexity4.601205348968506
INFO:root:current mean train loss 3871.3992198427964
INFO:root:current train perplexity4.601099967956543

100%|██████████| 1/1 [08:31<00:00, 511.54s/it][A100%|██████████| 1/1 [08:31<00:00, 511.54s/it]
INFO:root:final mean train loss: 3869.306254479193
INFO:root:final train perplexity: 4.602287292480469
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.95s/it][A100%|██████████| 1/1 [00:37<00:00, 37.95s/it]
INFO:root:eval mean loss: 3839.1291209552305
INFO:root:eval perplexity: 4.722938060760498
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.15s/it][A100%|██████████| 1/1 [00:37<00:00, 37.15s/it]
INFO:root:eval mean loss: 4703.13634474734
INFO:root:eval perplexity: 6.842663764953613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/24
 12%|█▏        | 24/200 [3:56:05<28:47:25, 588.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3855.5901388650414
INFO:root:current train perplexity4.56168794631958
INFO:root:current mean train loss 3820.5293748466133
INFO:root:current train perplexity4.513114929199219
INFO:root:current mean train loss 3832.7813993368773
INFO:root:current train perplexity4.537526607513428
INFO:root:current mean train loss 3841.506841557105
INFO:root:current train perplexity4.55238676071167
INFO:root:current mean train loss 3847.88112986889
INFO:root:current train perplexity4.562073707580566
INFO:root:current mean train loss 3845.389124216767
INFO:root:current train perplexity4.5540971755981445
INFO:root:current mean train loss 3844.6948842822903
INFO:root:current train perplexity4.557032585144043
INFO:root:current mean train loss 3850.63030226523
INFO:root:current train perplexity4.563138008117676
INFO:root:current mean train loss 3849.775395557134
INFO:root:current train perplexity4.566131591796875
INFO:root:current mean train loss 3851.5868941075146
INFO:root:current train perplexity4.565021514892578

100%|██████████| 1/1 [08:32<00:00, 512.82s/it][A100%|██████████| 1/1 [08:32<00:00, 512.82s/it]
INFO:root:final mean train loss: 3848.6750876518986
INFO:root:final train perplexity: 4.564977645874023
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.83s/it][A100%|██████████| 1/1 [00:37<00:00, 37.83s/it]
INFO:root:eval mean loss: 3826.1207838126106
INFO:root:eval perplexity: 4.698159694671631
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.19s/it][A100%|██████████| 1/1 [00:37<00:00, 37.19s/it]
INFO:root:eval mean loss: 4693.045694121232
INFO:root:eval perplexity: 6.814488887786865
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/25
 12%|█▎        | 25/200 [4:05:54<28:37:58, 589.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3844.3891700205177
INFO:root:current train perplexity4.515707015991211
INFO:root:current mean train loss 3846.1378192230686
INFO:root:current train perplexity4.536141395568848
INFO:root:current mean train loss 3829.3310848988817
INFO:root:current train perplexity4.520091533660889
INFO:root:current mean train loss 3822.8656186364346
INFO:root:current train perplexity4.517953395843506
INFO:root:current mean train loss 3823.8906367422346
INFO:root:current train perplexity4.518211364746094
INFO:root:current mean train loss 3826.612317730071
INFO:root:current train perplexity4.5135416984558105
INFO:root:current mean train loss 3829.4499427893643
INFO:root:current train perplexity4.520861625671387
INFO:root:current mean train loss 3830.1242425223913
INFO:root:current train perplexity4.521783828735352
INFO:root:current mean train loss 3828.0179403981856
INFO:root:current train perplexity4.520206928253174

100%|██████████| 1/1 [08:36<00:00, 516.63s/it][A100%|██████████| 1/1 [08:36<00:00, 516.63s/it]
INFO:root:final mean train loss: 3823.41527698886
INFO:root:final train perplexity: 4.519711017608643
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.92s/it][A100%|██████████| 1/1 [00:37<00:00, 37.92s/it]
INFO:root:eval mean loss: 3844.311772772606
INFO:root:eval perplexity: 4.732846260070801
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.11s/it][A100%|██████████| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 4717.384831421764
INFO:root:eval perplexity: 6.88264799118042
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/26
 13%|█▎        | 26/200 [4:15:47<28:31:44, 590.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3715.340645926339
INFO:root:current train perplexity4.471733093261719
INFO:root:current mean train loss 3760.6320116274824
INFO:root:current train perplexity4.433372974395752
INFO:root:current mean train loss 3780.623920827672
INFO:root:current train perplexity4.458687782287598
INFO:root:current mean train loss 3789.0624276325834
INFO:root:current train perplexity4.463096618652344
INFO:root:current mean train loss 3796.8219093116554
INFO:root:current train perplexity4.467803478240967
INFO:root:current mean train loss 3797.9140947631595
INFO:root:current train perplexity4.470972537994385
INFO:root:current mean train loss 3794.115795456008
INFO:root:current train perplexity4.465991973876953
INFO:root:current mean train loss 3793.9031704439976
INFO:root:current train perplexity4.465844631195068
INFO:root:current mean train loss 3796.9286918781945
INFO:root:current train perplexity4.467788219451904
INFO:root:current mean train loss 3798.1854190174513
INFO:root:current train perplexity4.469061851501465

100%|██████████| 1/1 [08:32<00:00, 512.40s/it][A100%|██████████| 1/1 [08:32<00:00, 512.40s/it]
INFO:root:final mean train loss: 3797.0592400335495
INFO:root:final train perplexity: 4.472957611083984
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.31s/it][A100%|██████████| 1/1 [00:38<00:00, 38.31s/it]
INFO:root:eval mean loss: 3791.9203045351287
INFO:root:eval perplexity: 4.633632659912109
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.07s/it][A100%|██████████| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 4668.165549853169
INFO:root:eval perplexity: 6.745510101318359
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/27
 14%|█▎        | 27/200 [4:25:37<28:21:03, 589.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3773.389208984375
INFO:root:current train perplexity4.409476280212402
INFO:root:current mean train loss 3771.2418775475544
INFO:root:current train perplexity4.421555042266846
INFO:root:current mean train loss 3754.384923464753
INFO:root:current train perplexity4.410184860229492
INFO:root:current mean train loss 3760.4395066034226
INFO:root:current train perplexity4.415335655212402
INFO:root:current mean train loss 3766.975645354857
INFO:root:current train perplexity4.419947147369385
INFO:root:current mean train loss 3770.3363703162927
INFO:root:current train perplexity4.4201860427856445
INFO:root:current mean train loss 3765.629654153963
INFO:root:current train perplexity4.4150166511535645
INFO:root:current mean train loss 3770.747957072225
INFO:root:current train perplexity4.427063465118408
INFO:root:current mean train loss 3773.302740965299
INFO:root:current train perplexity4.42977237701416
INFO:root:current mean train loss 3775.39761115736
INFO:root:current train perplexity4.433553695678711

100%|██████████| 1/1 [08:32<00:00, 512.23s/it][A100%|██████████| 1/1 [08:32<00:00, 512.23s/it]
INFO:root:final mean train loss: 3774.0185436741
INFO:root:final train perplexity: 4.432481288909912
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.07s/it][A100%|██████████| 1/1 [00:38<00:00, 38.07s/it]
INFO:root:eval mean loss: 3776.9993922456783
INFO:root:eval perplexity: 4.605760097503662
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.52s/it][A100%|██████████| 1/1 [00:36<00:00, 36.52s/it]
INFO:root:eval mean loss: 4655.242088804854
INFO:root:eval perplexity: 6.709956645965576
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/28
 14%|█▍        | 28/200 [4:35:25<28:09:52, 589.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3783.3642578125
INFO:root:current train perplexity4.422314643859863
INFO:root:current mean train loss 3751.343684498857
INFO:root:current train perplexity4.37416934967041
INFO:root:current mean train loss 3758.7963396423065
INFO:root:current train perplexity4.3898396492004395
INFO:root:current mean train loss 3751.158028522881
INFO:root:current train perplexity4.388304710388184
INFO:root:current mean train loss 3757.802294575576
INFO:root:current train perplexity4.393105983734131
INFO:root:current mean train loss 3761.571106540541
INFO:root:current train perplexity4.393757343292236
INFO:root:current mean train loss 3754.3998349405597
INFO:root:current train perplexity4.388095855712891
INFO:root:current mean train loss 3753.644001434453
INFO:root:current train perplexity4.390100002288818
INFO:root:current mean train loss 3754.557459074556
INFO:root:current train perplexity4.38969612121582
INFO:root:current mean train loss 3755.3691072970273
INFO:root:current train perplexity4.3917131423950195

100%|██████████| 1/1 [08:30<00:00, 510.75s/it][A100%|██████████| 1/1 [08:30<00:00, 510.75s/it]
INFO:root:final mean train loss: 3750.714411212552
INFO:root:final train perplexity: 4.391915321350098
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.03s/it][A100%|██████████| 1/1 [00:38<00:00, 38.03s/it]
INFO:root:eval mean loss: 3767.199043869127
INFO:root:eval perplexity: 4.5875444412231445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.93s/it][A100%|██████████| 1/1 [00:36<00:00, 36.93s/it]
INFO:root:eval mean loss: 4640.085807637965
INFO:root:eval perplexity: 6.66849946975708
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/29
 14%|█▍        | 29/200 [4:45:12<27:58:10, 588.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3767.466111706149
INFO:root:current train perplexity4.382112979888916
INFO:root:current mean train loss 3738.528199174022
INFO:root:current train perplexity4.351257801055908
INFO:root:current mean train loss 3724.9530985778542
INFO:root:current train perplexity4.353869438171387
INFO:root:current mean train loss 3725.176949584592
INFO:root:current train perplexity4.340926170349121
INFO:root:current mean train loss 3725.6149500163137
INFO:root:current train perplexity4.344968318939209
INFO:root:current mean train loss 3732.685078364083
INFO:root:current train perplexity4.35584831237793
INFO:root:current mean train loss 3734.0117017259313
INFO:root:current train perplexity4.356012344360352
INFO:root:current mean train loss 3732.0556533750855
INFO:root:current train perplexity4.352910041809082
INFO:root:current mean train loss 3733.5382921790388
INFO:root:current train perplexity4.358503818511963
INFO:root:current mean train loss 3733.6192725291185
INFO:root:current train perplexity4.356174945831299

100%|██████████| 1/1 [08:31<00:00, 511.59s/it][A100%|██████████| 1/1 [08:31<00:00, 511.59s/it]
INFO:root:final mean train loss: 3730.0430406755017
INFO:root:final train perplexity: 4.356242656707764
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.66s/it][A100%|██████████| 1/1 [00:37<00:00, 37.66s/it]
INFO:root:eval mean loss: 3769.717274767287
INFO:root:eval perplexity: 4.592216968536377
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.63s/it][A100%|██████████| 1/1 [00:38<00:00, 38.63s/it]
INFO:root:eval mean loss: 4646.304798315603
INFO:root:eval perplexity: 6.685479640960693
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/30
 15%|█▌        | 30/200 [4:55:02<27:48:49, 589.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3707.930188301282
INFO:root:current train perplexity4.290881156921387
INFO:root:current mean train loss 3695.1964945621626
INFO:root:current train perplexity4.296334743499756
INFO:root:current mean train loss 3699.3611636620685
INFO:root:current train perplexity4.289119720458984
INFO:root:current mean train loss 3701.316711605826
INFO:root:current train perplexity4.2971320152282715
INFO:root:current mean train loss 3700.368367605709
INFO:root:current train perplexity4.299816131591797
INFO:root:current mean train loss 3703.4471464988696
INFO:root:current train perplexity4.309947967529297
INFO:root:current mean train loss 3704.670935115904
INFO:root:current train perplexity4.311853885650635
INFO:root:current mean train loss 3704.6074839838466
INFO:root:current train perplexity4.313287734985352
INFO:root:current mean train loss 3709.382209277693
INFO:root:current train perplexity4.315944671630859
INFO:root:current mean train loss 3709.7261717189995
INFO:root:current train perplexity4.315653324127197

100%|██████████| 1/1 [08:32<00:00, 512.12s/it][A100%|██████████| 1/1 [08:32<00:00, 512.12s/it]
INFO:root:final mean train loss: 3706.9698768738776
INFO:root:final train perplexity: 4.316767692565918
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.15s/it][A100%|██████████| 1/1 [00:38<00:00, 38.16s/it]
INFO:root:eval mean loss: 3756.886372451241
INFO:root:eval perplexity: 4.568452835083008
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.49s/it][A100%|██████████| 1/1 [00:36<00:00, 36.49s/it]
INFO:root:eval mean loss: 4641.175689480829
INFO:root:eval perplexity: 6.671472549438477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/31
 16%|█▌        | 31/200 [5:04:50<27:38:23, 588.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3725.482437458444
INFO:root:current train perplexity4.322807312011719
INFO:root:current mean train loss 3697.627806786777
INFO:root:current train perplexity4.284395694732666
INFO:root:current mean train loss 3696.8139164109944
INFO:root:current train perplexity4.277168273925781
INFO:root:current mean train loss 3685.6687581614733
INFO:root:current train perplexity4.269741058349609
INFO:root:current mean train loss 3689.8358364574597
INFO:root:current train perplexity4.27763032913208
INFO:root:current mean train loss 3686.724387550703
INFO:root:current train perplexity4.277451992034912
INFO:root:current mean train loss 3688.8698368219907
INFO:root:current train perplexity4.282468795776367
INFO:root:current mean train loss 3690.451621917357
INFO:root:current train perplexity4.285998821258545
INFO:root:current mean train loss 3691.1567679701334
INFO:root:current train perplexity4.285606861114502
INFO:root:current mean train loss 3691.3374301866093
INFO:root:current train perplexity4.28765869140625

100%|██████████| 1/1 [08:31<00:00, 511.04s/it][A100%|██████████| 1/1 [08:31<00:00, 511.04s/it]
INFO:root:final mean train loss: 3691.152849258915
INFO:root:final train perplexity: 4.289913177490234
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.91s/it][A100%|██████████| 1/1 [00:37<00:00, 37.91s/it]
INFO:root:eval mean loss: 3749.1338081089316
INFO:root:eval perplexity: 4.554153919219971
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.06s/it][A100%|██████████| 1/1 [00:37<00:00, 37.06s/it]
INFO:root:eval mean loss: 4637.82167691711
INFO:root:eval perplexity: 6.662329196929932
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/32
 16%|█▌        | 32/200 [5:14:37<27:27:28, 588.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3705.602286044034
INFO:root:current train perplexity4.302163600921631
INFO:root:current mean train loss 3693.6554939516127
INFO:root:current train perplexity4.26805305480957
INFO:root:current mean train loss 3679.089798751532
INFO:root:current train perplexity4.269645690917969
INFO:root:current mean train loss 3674.2175739986797
INFO:root:current train perplexity4.26357364654541
INFO:root:current mean train loss 3677.9646253648693
INFO:root:current train perplexity4.263012409210205
INFO:root:current mean train loss 3672.3507187851915
INFO:root:current train perplexity4.257936954498291
INFO:root:current mean train loss 3674.205498941436
INFO:root:current train perplexity4.257815837860107
INFO:root:current mean train loss 3675.455375620861
INFO:root:current train perplexity4.261667251586914
INFO:root:current mean train loss 3675.078636981451
INFO:root:current train perplexity4.2585625648498535
INFO:root:current mean train loss 3673.9871075854876
INFO:root:current train perplexity4.255362510681152

100%|██████████| 1/1 [08:31<00:00, 511.44s/it][A100%|██████████| 1/1 [08:31<00:00, 511.44s/it]
INFO:root:final mean train loss: 3671.875775921729
INFO:root:final train perplexity: 4.257411003112793
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.60s/it][A100%|██████████| 1/1 [00:37<00:00, 37.60s/it]
INFO:root:eval mean loss: 3743.4918031083776
INFO:root:eval perplexity: 4.543774604797363
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.14s/it][A100%|██████████| 1/1 [00:37<00:00, 37.14s/it]
INFO:root:eval mean loss: 4634.527139433732
INFO:root:eval perplexity: 6.6533589363098145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/33
 16%|█▋        | 33/200 [5:24:25<27:17:07, 588.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3641.1580636160716
INFO:root:current train perplexity4.24213981628418
INFO:root:current mean train loss 3647.7342416962233
INFO:root:current train perplexity4.230515003204346
INFO:root:current mean train loss 3642.309650145556
INFO:root:current train perplexity4.225851058959961
INFO:root:current mean train loss 3641.72695460464
INFO:root:current train perplexity4.21607780456543
INFO:root:current mean train loss 3638.2155508614
INFO:root:current train perplexity4.205524444580078
INFO:root:current mean train loss 3645.3428250409356
INFO:root:current train perplexity4.211630344390869
INFO:root:current mean train loss 3651.9202941618355
INFO:root:current train perplexity4.219929218292236
INFO:root:current mean train loss 3655.8972196766463
INFO:root:current train perplexity4.223260402679443
INFO:root:current mean train loss 3656.214411482474
INFO:root:current train perplexity4.223095893859863
INFO:root:current mean train loss 3654.669638438636
INFO:root:current train perplexity4.22409200668335

100%|██████████| 1/1 [08:31<00:00, 511.15s/it][A100%|██████████| 1/1 [08:31<00:00, 511.15s/it]
INFO:root:final mean train loss: 3651.5619856311428
INFO:root:final train perplexity: 4.223426818847656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.72s/it][A100%|██████████| 1/1 [00:37<00:00, 37.72s/it]
INFO:root:eval mean loss: 3728.1737415503103
INFO:root:eval perplexity: 4.515717506408691
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.60s/it][A100%|██████████| 1/1 [00:36<00:00, 36.60s/it]
INFO:root:eval mean loss: 4619.310657690603
INFO:root:eval perplexity: 6.612087726593018
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/34
 17%|█▋        | 34/200 [5:34:12<27:06:13, 587.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3614.69511649978
INFO:root:current train perplexity4.173708438873291
INFO:root:current mean train loss 3617.9518857364765
INFO:root:current train perplexity4.178328990936279
INFO:root:current mean train loss 3627.0776295116466
INFO:root:current train perplexity4.182652950286865
INFO:root:current mean train loss 3626.0686680056015
INFO:root:current train perplexity4.1830830574035645
INFO:root:current mean train loss 3636.5124060758358
INFO:root:current train perplexity4.193742275238037
INFO:root:current mean train loss 3630.9872016439085
INFO:root:current train perplexity4.191882610321045
INFO:root:current mean train loss 3630.333816278176
INFO:root:current train perplexity4.189062595367432
INFO:root:current mean train loss 3634.3433032004905
INFO:root:current train perplexity4.191718578338623
INFO:root:current mean train loss 3633.8677884615386
INFO:root:current train perplexity4.190186023712158
INFO:root:current mean train loss 3635.389969516365
INFO:root:current train perplexity4.191649436950684

100%|██████████| 1/1 [08:30<00:00, 510.40s/it][A100%|██████████| 1/1 [08:30<00:00, 510.40s/it]
INFO:root:final mean train loss: 3631.979253030592
INFO:root:final train perplexity: 4.190922260284424
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.51s/it][A100%|██████████| 1/1 [00:37<00:00, 37.51s/it]
INFO:root:eval mean loss: 3725.112782579787
INFO:root:eval perplexity: 4.510130882263184
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.20s/it][A100%|██████████| 1/1 [00:37<00:00, 37.20s/it]
INFO:root:eval mean loss: 4625.98953138852
INFO:root:eval perplexity: 6.630171298980713
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/35
 18%|█▊        | 35/200 [5:43:59<26:55:24, 587.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3638.305843304984
INFO:root:current train perplexity4.146164894104004
INFO:root:current mean train loss 3606.9933700135302
INFO:root:current train perplexity4.135988712310791
INFO:root:current mean train loss 3604.7550298219085
INFO:root:current train perplexity4.142263889312744
INFO:root:current mean train loss 3624.3161286125082
INFO:root:current train perplexity4.169872283935547
INFO:root:current mean train loss 3623.5513108159903
INFO:root:current train perplexity4.159827709197998
INFO:root:current mean train loss 3617.238620263925
INFO:root:current train perplexity4.160250663757324
INFO:root:current mean train loss 3617.6321890245304
INFO:root:current train perplexity4.159038066864014
INFO:root:current mean train loss 3619.6419312620346
INFO:root:current train perplexity4.159934997558594
INFO:root:current mean train loss 3620.0584148801904
INFO:root:current train perplexity4.159578800201416
INFO:root:current mean train loss 3618.165915125846
INFO:root:current train perplexity4.161728858947754

100%|██████████| 1/1 [08:31<00:00, 511.72s/it][A100%|██████████| 1/1 [08:31<00:00, 511.72s/it]
INFO:root:final mean train loss: 3614.2328015604326
INFO:root:final train perplexity: 4.161682605743408
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.77s/it][A100%|██████████| 1/1 [00:37<00:00, 37.77s/it]
INFO:root:eval mean loss: 3717.485081449468
INFO:root:eval perplexity: 4.496242046356201
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.98s/it][A100%|██████████| 1/1 [00:36<00:00, 36.98s/it]
INFO:root:eval mean loss: 4619.753082058954
INFO:root:eval perplexity: 6.613285064697266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/36
 18%|█▊        | 36/200 [5:53:46<26:46:03, 587.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3596.434427195582
INFO:root:current train perplexity4.135706424713135
INFO:root:current mean train loss 3603.601836668616
INFO:root:current train perplexity4.130347728729248
INFO:root:current mean train loss 3603.3705952607797
INFO:root:current train perplexity4.12861442565918
INFO:root:current mean train loss 3597.46046814438
INFO:root:current train perplexity4.1258134841918945
INFO:root:current mean train loss 3605.760044356391
INFO:root:current train perplexity4.134706020355225
INFO:root:current mean train loss 3597.64462358257
INFO:root:current train perplexity4.129160404205322
INFO:root:current mean train loss 3600.7640659826466
INFO:root:current train perplexity4.13514518737793
INFO:root:current mean train loss 3598.38849815359
INFO:root:current train perplexity4.131776809692383
INFO:root:current mean train loss 3600.197338013934
INFO:root:current train perplexity4.132843017578125
INFO:root:current mean train loss 3601.3189752920784
INFO:root:current train perplexity4.135982990264893

100%|██████████| 1/1 [08:31<00:00, 511.46s/it][A100%|██████████| 1/1 [08:31<00:00, 511.46s/it]
INFO:root:final mean train loss: 3598.6971437392694
INFO:root:final train perplexity: 4.136252403259277
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.64s/it][A100%|██████████| 1/1 [00:37<00:00, 37.64s/it]
INFO:root:eval mean loss: 3706.334339331228
INFO:root:eval perplexity: 4.476014137268066
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.60s/it][A100%|██████████| 1/1 [00:36<00:00, 36.60s/it]
INFO:root:eval mean loss: 4607.662573415337
INFO:root:eval perplexity: 6.580668926239014
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/37
 18%|█▊        | 37/200 [6:03:34<26:36:00, 587.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3602.598918071546
INFO:root:current train perplexity4.118452072143555
INFO:root:current mean train loss 3574.133696414263
INFO:root:current train perplexity4.105565071105957
INFO:root:current mean train loss 3578.0747666181146
INFO:root:current train perplexity4.099603176116943
INFO:root:current mean train loss 3580.0035595085046
INFO:root:current train perplexity4.101161956787109
INFO:root:current mean train loss 3587.1972542810922
INFO:root:current train perplexity4.104190349578857
INFO:root:current mean train loss 3587.005421973477
INFO:root:current train perplexity4.109817981719971
INFO:root:current mean train loss 3586.023238323404
INFO:root:current train perplexity4.108574867248535
INFO:root:current mean train loss 3586.0956407846893
INFO:root:current train perplexity4.106308460235596
INFO:root:current mean train loss 3584.7928953714213
INFO:root:current train perplexity4.105353832244873

100%|██████████| 1/1 [08:32<00:00, 512.35s/it][A100%|██████████| 1/1 [08:32<00:00, 512.35s/it]
INFO:root:final mean train loss: 3580.8469491774035
INFO:root:final train perplexity: 4.10722541809082
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.42s/it][A100%|██████████| 1/1 [00:37<00:00, 37.42s/it]
INFO:root:eval mean loss: 3702.7775255568486
INFO:root:eval perplexity: 4.46958065032959
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.45s/it][A100%|██████████| 1/1 [00:37<00:00, 37.45s/it]
INFO:root:eval mean loss: 4605.702757923315
INFO:root:eval perplexity: 6.575398921966553
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/38
 19%|█▉        | 38/200 [6:13:22<26:27:13, 587.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3645.3324381510415
INFO:root:current train perplexity4.201151371002197
INFO:root:current mean train loss 3582.330580628034
INFO:root:current train perplexity4.092427730560303
INFO:root:current mean train loss 3568.380819687115
INFO:root:current train perplexity4.0778703689575195
INFO:root:current mean train loss 3566.1092678359632
INFO:root:current train perplexity4.0780768394470215
INFO:root:current mean train loss 3568.747495589718
INFO:root:current train perplexity4.084262847900391
INFO:root:current mean train loss 3560.5013318526344
INFO:root:current train perplexity4.074268817901611
INFO:root:current mean train loss 3560.4350144621944
INFO:root:current train perplexity4.074949264526367
INFO:root:current mean train loss 3567.330123966483
INFO:root:current train perplexity4.083074569702148
INFO:root:current mean train loss 3567.367039130604
INFO:root:current train perplexity4.080544471740723
INFO:root:current mean train loss 3570.063983499014
INFO:root:current train perplexity4.08494758605957

100%|██████████| 1/1 [08:31<00:00, 511.52s/it][A100%|██████████| 1/1 [08:31<00:00, 511.52s/it]
INFO:root:final mean train loss: 3568.4756147323114
INFO:root:final train perplexity: 4.087227821350098
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 38.00s/it][A100%|██████████| 1/1 [00:37<00:00, 38.00s/it]
INFO:root:eval mean loss: 3693.6630565021055
INFO:root:eval perplexity: 4.453137397766113
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.58s/it][A100%|██████████| 1/1 [00:36<00:00, 36.58s/it]
INFO:root:eval mean loss: 4600.117983987146
INFO:root:eval perplexity: 6.560399055480957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/39
 20%|█▉        | 39/200 [6:23:10<26:17:09, 587.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3508.9762739701705
INFO:root:current train perplexity4.075821399688721
INFO:root:current mean train loss 3545.433538763373
INFO:root:current train perplexity4.0265913009643555
INFO:root:current mean train loss 3541.0252043376036
INFO:root:current train perplexity4.029894828796387
INFO:root:current mean train loss 3545.546829468951
INFO:root:current train perplexity4.041781902313232
INFO:root:current mean train loss 3553.592647506083
INFO:root:current train perplexity4.046133041381836
INFO:root:current mean train loss 3562.207144481562
INFO:root:current train perplexity4.059771537780762
INFO:root:current mean train loss 3559.8031175678957
INFO:root:current train perplexity4.057315826416016
INFO:root:current mean train loss 3559.663141564478
INFO:root:current train perplexity4.058196067810059
INFO:root:current mean train loss 3558.228095076969
INFO:root:current train perplexity4.059509754180908
INFO:root:current mean train loss 3557.9502674023224
INFO:root:current train perplexity4.060766220092773

100%|██████████| 1/1 [08:33<00:00, 513.00s/it][A100%|██████████| 1/1 [08:33<00:00, 513.01s/it]
INFO:root:final mean train loss: 3551.286354311051
INFO:root:final train perplexity: 4.059602737426758
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.75s/it][A100%|██████████| 1/1 [00:37<00:00, 37.75s/it]
INFO:root:eval mean loss: 3713.226030931405
INFO:root:eval perplexity: 4.488504409790039
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.97s/it][A100%|██████████| 1/1 [00:36<00:00, 36.97s/it]
INFO:root:eval mean loss: 4621.645887009641
INFO:root:eval perplexity: 6.618406772613525
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/40
 20%|██        | 40/200 [6:32:59<26:08:33, 588.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3505.225701583059
INFO:root:current train perplexity4.049947738647461
INFO:root:current mean train loss 3525.28646927521
INFO:root:current train perplexity4.034400939941406
INFO:root:current mean train loss 3534.455236426227
INFO:root:current train perplexity4.043686389923096
INFO:root:current mean train loss 3529.7051470048
INFO:root:current train perplexity4.033254146575928
INFO:root:current mean train loss 3539.1206439252687
INFO:root:current train perplexity4.035084247589111
INFO:root:current mean train loss 3539.0744751211764
INFO:root:current train perplexity4.0392889976501465
INFO:root:current mean train loss 3540.3789938093196
INFO:root:current train perplexity4.034472465515137
INFO:root:current mean train loss 3539.16592088893
INFO:root:current train perplexity4.03366756439209
INFO:root:current mean train loss 3541.208702376183
INFO:root:current train perplexity4.036751747131348
INFO:root:current mean train loss 3540.1871110752177
INFO:root:current train perplexity4.037803649902344

100%|██████████| 1/1 [08:33<00:00, 513.66s/it][A100%|██████████| 1/1 [08:33<00:00, 513.66s/it]
INFO:root:final mean train loss: 3537.3340669447375
INFO:root:final train perplexity: 4.037317752838135
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.19s/it][A100%|██████████| 1/1 [00:38<00:00, 38.19s/it]
INFO:root:eval mean loss: 3670.8973622423537
INFO:root:eval perplexity: 4.412331581115723
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.83s/it][A100%|██████████| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 4584.601948623116
INFO:root:eval perplexity: 6.518907070159912
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/41
 20%|██        | 41/200 [6:42:50<26:00:24, 588.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3511.1107584635415
INFO:root:current train perplexity3.9880211353302
INFO:root:current mean train loss 3546.1618575449065
INFO:root:current train perplexity4.023534297943115
INFO:root:current mean train loss 3543.4207306580397
INFO:root:current train perplexity4.025228023529053
INFO:root:current mean train loss 3538.953582670346
INFO:root:current train perplexity4.018152236938477
INFO:root:current mean train loss 3536.6277947526346
INFO:root:current train perplexity4.017336845397949
INFO:root:current mean train loss 3534.596507816206
INFO:root:current train perplexity4.018807888031006
INFO:root:current mean train loss 3535.860330536035
INFO:root:current train perplexity4.020495414733887
INFO:root:current mean train loss 3532.70368917641
INFO:root:current train perplexity4.019411563873291
INFO:root:current mean train loss 3531.2252552996524
INFO:root:current train perplexity4.017269134521484
INFO:root:current mean train loss 3525.8697674369605
INFO:root:current train perplexity4.014112949371338

100%|██████████| 1/1 [08:34<00:00, 514.26s/it][A100%|██████████| 1/1 [08:34<00:00, 514.26s/it]
INFO:root:final mean train loss: 3522.1590264843358
INFO:root:final train perplexity: 4.013219356536865
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.03s/it][A100%|██████████| 1/1 [00:38<00:00, 38.06s/it]
INFO:root:eval mean loss: 3692.456669367797
INFO:root:eval perplexity: 4.450965404510498
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.47s/it][A100%|██████████| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 4610.679013948914
INFO:root:eval perplexity: 6.588791847229004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/42
 21%|██        | 42/200 [6:52:40<25:51:46, 589.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3526.4390415736607
INFO:root:current train perplexity3.965829849243164
INFO:root:current mean train loss 3479.3411223234953
INFO:root:current train perplexity3.960514783859253
INFO:root:current mean train loss 3495.3551975980718
INFO:root:current train perplexity3.971463918685913
INFO:root:current mean train loss 3503.115966796875
INFO:root:current train perplexity3.9868927001953125
INFO:root:current mean train loss 3501.4358847431754
INFO:root:current train perplexity3.9803502559661865
INFO:root:current mean train loss 3503.535147579585
INFO:root:current train perplexity3.981860876083374
INFO:root:current mean train loss 3508.4731068528545
INFO:root:current train perplexity3.9860126972198486
INFO:root:current mean train loss 3505.8914730149872
INFO:root:current train perplexity3.9822449684143066
INFO:root:current mean train loss 3506.6184011859095
INFO:root:current train perplexity3.9857945442199707
INFO:root:current mean train loss 3512.8697098512703
INFO:root:current train perplexity3.9928300380706787

100%|██████████| 1/1 [08:31<00:00, 511.53s/it][A100%|██████████| 1/1 [08:31<00:00, 511.53s/it]
INFO:root:final mean train loss: 3509.1868263982956
INFO:root:final train perplexity: 3.992732048034668
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.00s/it][A100%|██████████| 1/1 [00:38<00:00, 38.08s/it]
INFO:root:eval mean loss: 3668.1126786901596
INFO:root:eval perplexity: 4.407365322113037
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.07s/it][A100%|██████████| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 4581.476870705896
INFO:root:eval perplexity: 6.510581016540527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/43
 22%|██▏       | 43/200 [7:02:28<25:41:02, 588.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3461.4783452943316
INFO:root:current train perplexity3.9027328491210938
INFO:root:current mean train loss 3480.954203999126
INFO:root:current train perplexity3.931756019592285
INFO:root:current mean train loss 3488.2289084603267
INFO:root:current train perplexity3.947720527648926
INFO:root:current mean train loss 3491.718085909029
INFO:root:current train perplexity3.9557886123657227
INFO:root:current mean train loss 3496.289616363043
INFO:root:current train perplexity3.960705518722534
INFO:root:current mean train loss 3485.2432229619876
INFO:root:current train perplexity3.9555835723876953
INFO:root:current mean train loss 3489.293659405983
INFO:root:current train perplexity3.960299491882324
INFO:root:current mean train loss 3494.6970267417773
INFO:root:current train perplexity3.9653990268707275
INFO:root:current mean train loss 3497.0349596052974
INFO:root:current train perplexity3.9683315753936768
INFO:root:current mean train loss 3497.733603484557
INFO:root:current train perplexity3.967576503753662

100%|██████████| 1/1 [08:35<00:00, 515.58s/it][A100%|██████████| 1/1 [08:35<00:00, 515.58s/it]
INFO:root:final mean train loss: 3493.5764113395444
INFO:root:final train perplexity: 3.968217611312866
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.64s/it][A100%|██████████| 1/1 [00:37<00:00, 37.64s/it]
INFO:root:eval mean loss: 3722.474517605829
INFO:root:eval perplexity: 4.505322456359863
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.02s/it][A100%|██████████| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 4641.682572168661
INFO:root:eval perplexity: 6.672854900360107
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/44
 22%|██▏       | 44/200 [7:12:20<25:33:26, 589.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3470.323304419424
INFO:root:current train perplexity3.9421768188476562
INFO:root:current mean train loss 3488.286058438535
INFO:root:current train perplexity3.959429979324341
INFO:root:current mean train loss 3477.4379386749874
INFO:root:current train perplexity3.950657606124878
INFO:root:current mean train loss 3477.9602335959758
INFO:root:current train perplexity3.947758197784424
INFO:root:current mean train loss 3481.862338250069
INFO:root:current train perplexity3.954347848892212
INFO:root:current mean train loss 3485.0568116563636
INFO:root:current train perplexity3.955918788909912
INFO:root:current mean train loss 3483.6461378528224
INFO:root:current train perplexity3.951240301132202
INFO:root:current mean train loss 3484.0945295595457
INFO:root:current train perplexity3.950465440750122
INFO:root:current mean train loss 3487.147995407517
INFO:root:current train perplexity3.9529409408569336
INFO:root:current mean train loss 3486.868770948344
INFO:root:current train perplexity3.9514122009277344

100%|██████████| 1/1 [08:35<00:00, 515.15s/it][A100%|██████████| 1/1 [08:35<00:00, 515.15s/it]
INFO:root:final mean train loss: 3483.513681042579
INFO:root:final train perplexity: 3.9524943828582764
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.64s/it][A100%|██████████| 1/1 [00:37<00:00, 37.64s/it]
INFO:root:eval mean loss: 3658.9716987339316
INFO:root:eval perplexity: 4.391104221343994
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.10s/it][A100%|██████████| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 4582.548852365913
INFO:root:eval perplexity: 6.513436317443848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/45
 22%|██▎       | 45/200 [7:22:11<25:24:50, 590.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3513.1435753773835
INFO:root:current train perplexity3.9446773529052734
INFO:root:current mean train loss 3455.2208551370873
INFO:root:current train perplexity3.8938467502593994
INFO:root:current mean train loss 3443.103055622587
INFO:root:current train perplexity3.887101411819458
INFO:root:current mean train loss 3454.6018936879786
INFO:root:current train perplexity3.9022727012634277
INFO:root:current mean train loss 3465.086747046909
INFO:root:current train perplexity3.9120852947235107
INFO:root:current mean train loss 3469.130306455445
INFO:root:current train perplexity3.920747995376587
INFO:root:current mean train loss 3465.150934476954
INFO:root:current train perplexity3.921635150909424
INFO:root:current mean train loss 3466.8644405158925
INFO:root:current train perplexity3.926394462585449
INFO:root:current mean train loss 3468.2512411666
INFO:root:current train perplexity3.9275624752044678
INFO:root:current mean train loss 3472.2612482892337
INFO:root:current train perplexity3.930887222290039

100%|██████████| 1/1 [08:34<00:00, 514.39s/it][A100%|██████████| 1/1 [08:34<00:00, 514.39s/it]
INFO:root:final mean train loss: 3470.1815088333624
INFO:root:final train perplexity: 3.9317593574523926
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.89s/it][A100%|██████████| 1/1 [00:37<00:00, 37.89s/it]
INFO:root:eval mean loss: 3671.5997929133423
INFO:root:eval perplexity: 4.4135847091674805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.11s/it][A100%|██████████| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 4592.738830133533
INFO:root:eval perplexity: 6.540632724761963
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/46
 23%|██▎       | 46/200 [7:32:02<25:15:31, 590.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3455.355913304571
INFO:root:current train perplexity3.9013094902038574
INFO:root:current mean train loss 3433.3294670424775
INFO:root:current train perplexity3.8821372985839844
INFO:root:current mean train loss 3439.1298809837313
INFO:root:current train perplexity3.8952760696411133
INFO:root:current mean train loss 3441.551386612313
INFO:root:current train perplexity3.893416404724121
INFO:root:current mean train loss 3443.0609013232734
INFO:root:current train perplexity3.8987245559692383
INFO:root:current mean train loss 3450.886401840829
INFO:root:current train perplexity3.9069697856903076
INFO:root:current mean train loss 3455.5946010149223
INFO:root:current train perplexity3.909817934036255
INFO:root:current mean train loss 3458.8248833727184
INFO:root:current train perplexity3.907554864883423
INFO:root:current mean train loss 3461.8229504577566
INFO:root:current train perplexity3.910414218902588
INFO:root:current mean train loss 3459.629564445046
INFO:root:current train perplexity3.9111711978912354

100%|██████████| 1/1 [08:37<00:00, 517.35s/it][A100%|██████████| 1/1 [08:37<00:00, 517.35s/it]
INFO:root:final mean train loss: 3457.757942507344
INFO:root:final train perplexity: 3.912534713745117
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.80s/it][A100%|██████████| 1/1 [00:37<00:00, 37.80s/it]
INFO:root:eval mean loss: 3650.061118267952
INFO:root:eval perplexity: 4.375311374664307
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.47s/it][A100%|██████████| 1/1 [00:37<00:00, 37.47s/it]
INFO:root:eval mean loss: 4573.89997506649
INFO:root:eval perplexity: 6.490440845489502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/47
 24%|██▎       | 47/200 [7:41:56<25:08:24, 591.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3443.3900651041668
INFO:root:current train perplexity3.870861530303955
INFO:root:current mean train loss 3420.6355929129463
INFO:root:current train perplexity3.859102964401245
INFO:root:current mean train loss 3423.2045703125
INFO:root:current train perplexity3.8703646659851074
INFO:root:current mean train loss 3432.474119140625
INFO:root:current train perplexity3.8777270317077637
INFO:root:current mean train loss 3445.1169243421054
INFO:root:current train perplexity3.8909428119659424
INFO:root:current mean train loss 3450.5074834408965
INFO:root:current train perplexity3.8930554389953613
INFO:root:current mean train loss 3452.3959747540507
INFO:root:current train perplexity3.8936047554016113
INFO:root:current mean train loss 3452.9717329259074
INFO:root:current train perplexity3.897449493408203
INFO:root:current mean train loss 3452.478148995536
INFO:root:current train perplexity3.8988733291625977
INFO:root:current mean train loss 3451.092283653846
INFO:root:current train perplexity3.8976454734802246

100%|██████████| 1/1 [08:34<00:00, 514.73s/it][A100%|██████████| 1/1 [08:34<00:00, 514.73s/it]
INFO:root:final mean train loss: 3448.144930501138
INFO:root:final train perplexity: 3.8977251052856445
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.11s/it][A100%|██████████| 1/1 [00:38<00:00, 38.11s/it]
INFO:root:eval mean loss: 3658.077046279366
INFO:root:eval perplexity: 4.3895158767700195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.94s/it][A100%|██████████| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 4584.046028299535
INFO:root:eval perplexity: 6.517425537109375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/48
 24%|██▍       | 48/200 [7:51:47<24:58:24, 591.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3444.513868952372
INFO:root:current train perplexity3.8951010704040527
INFO:root:current mean train loss 3430.270454448429
INFO:root:current train perplexity3.873140811920166
INFO:root:current mean train loss 3429.258279214057
INFO:root:current train perplexity3.863800048828125
INFO:root:current mean train loss 3432.166472034106
INFO:root:current train perplexity3.8702728748321533
INFO:root:current mean train loss 3427.5013713323306
INFO:root:current train perplexity3.869840145111084
INFO:root:current mean train loss 3430.6008757236277
INFO:root:current train perplexity3.8716037273406982
INFO:root:current mean train loss 3431.8740220076866
INFO:root:current train perplexity3.87213134765625
INFO:root:current mean train loss 3435.193482536618
INFO:root:current train perplexity3.8777382373809814
INFO:root:current mean train loss 3435.596908068198
INFO:root:current train perplexity3.877356767654419
INFO:root:current mean train loss 3437.5189297153165
INFO:root:current train perplexity3.8774237632751465

100%|██████████| 1/1 [08:40<00:00, 520.91s/it][A100%|██████████| 1/1 [08:40<00:00, 520.91s/it]
INFO:root:final mean train loss: 3434.710147550029
INFO:root:final train perplexity: 3.877119302749634
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.21s/it][A100%|██████████| 1/1 [00:38<00:00, 38.21s/it]
INFO:root:eval mean loss: 3652.1110389655364
INFO:root:eval perplexity: 4.378939151763916
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.75s/it][A100%|██████████| 1/1 [00:37<00:00, 37.75s/it]
INFO:root:eval mean loss: 4585.309904490802
INFO:root:eval perplexity: 6.520793437957764
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/49
 24%|██▍       | 49/200 [8:01:46<24:53:50, 593.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3398.1602689302886
INFO:root:current train perplexity3.8171064853668213
INFO:root:current mean train loss 3413.3362174308736
INFO:root:current train perplexity3.826347589492798
INFO:root:current mean train loss 3418.171046935406
INFO:root:current train perplexity3.833376169204712
INFO:root:current mean train loss 3429.3270610214195
INFO:root:current train perplexity3.8508427143096924
INFO:root:current mean train loss 3431.5465408604887
INFO:root:current train perplexity3.8550829887390137
INFO:root:current mean train loss 3427.4249810801343
INFO:root:current train perplexity3.8528904914855957
INFO:root:current mean train loss 3423.184466791222
INFO:root:current train perplexity3.8526723384857178
INFO:root:current mean train loss 3424.8311411089603
INFO:root:current train perplexity3.8565547466278076
INFO:root:current mean train loss 3426.4634572723767
INFO:root:current train perplexity3.8599395751953125
INFO:root:current mean train loss 3426.1160648472974
INFO:root:current train perplexity3.859895706176758

100%|██████████| 1/1 [08:37<00:00, 517.68s/it][A100%|██████████| 1/1 [08:37<00:00, 517.68s/it]
INFO:root:final mean train loss: 3423.4591417004985
INFO:root:final train perplexity: 3.859947681427002
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.89s/it][A100%|██████████| 1/1 [00:37<00:00, 37.89s/it]
INFO:root:eval mean loss: 3644.1261652953235
INFO:root:eval perplexity: 4.364823341369629
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.05s/it][A100%|██████████| 1/1 [00:37<00:00, 37.05s/it]
INFO:root:eval mean loss: 4579.958565353501
INFO:root:eval perplexity: 6.506541728973389
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/50
 25%|██▌       | 50/200 [8:11:40<24:44:21, 593.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3409.582731613005
INFO:root:current train perplexity3.8272321224212646
INFO:root:current mean train loss 3402.065621074121
INFO:root:current train perplexity3.8241071701049805
INFO:root:current mean train loss 3399.7777683423915
INFO:root:current train perplexity3.8241665363311768
INFO:root:current mean train loss 3407.9378677406407
INFO:root:current train perplexity3.826361656188965
INFO:root:current mean train loss 3404.528462687093
INFO:root:current train perplexity3.8285577297210693
INFO:root:current mean train loss 3407.1397307687294
INFO:root:current train perplexity3.834165096282959
INFO:root:current mean train loss 3411.6126703745304
INFO:root:current train perplexity3.841214418411255
INFO:root:current mean train loss 3410.9626333453925
INFO:root:current train perplexity3.8406527042388916
INFO:root:current mean train loss 3412.890196463953
INFO:root:current train perplexity3.8419201374053955

100%|██████████| 1/1 [08:32<00:00, 512.58s/it][A100%|██████████| 1/1 [08:32<00:00, 512.58s/it]
INFO:root:final mean train loss: 3412.6775600064184
INFO:root:final train perplexity: 3.84356427192688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.96s/it][A100%|██████████| 1/1 [00:37<00:00, 37.96s/it]
INFO:root:eval mean loss: 3626.5135904947915
INFO:root:eval perplexity: 4.333847522735596
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.20s/it][A100%|██████████| 1/1 [00:37<00:00, 37.20s/it]
INFO:root:eval mean loss: 4563.67257798648
INFO:root:eval perplexity: 6.463353633880615
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/51
 26%|██▌       | 51/200 [8:21:29<24:31:03, 592.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3414.9266531808034
INFO:root:current train perplexity3.860377073287964
INFO:root:current mean train loss 3382.366888598861
INFO:root:current train perplexity3.7855634689331055
INFO:root:current mean train loss 3386.5716723750757
INFO:root:current train perplexity3.7995407581329346
INFO:root:current mean train loss 3394.563981543923
INFO:root:current train perplexity3.8091375827789307
INFO:root:current mean train loss 3397.369367369856
INFO:root:current train perplexity3.8145155906677246
INFO:root:current mean train loss 3406.914275340545
INFO:root:current train perplexity3.8208067417144775
INFO:root:current mean train loss 3411.1202471008805
INFO:root:current train perplexity3.8295769691467285
INFO:root:current mean train loss 3410.4130659089906
INFO:root:current train perplexity3.829587459564209
INFO:root:current mean train loss 3408.9178655877286
INFO:root:current train perplexity3.829071283340454
INFO:root:current mean train loss 3409.6212552542725
INFO:root:current train perplexity3.82955002784729

100%|██████████| 1/1 [08:35<00:00, 515.30s/it][A100%|██████████| 1/1 [08:35<00:00, 515.30s/it]
INFO:root:final mean train loss: 3402.5509892125283
INFO:root:final train perplexity: 3.8282382488250732
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.75s/it][A100%|██████████| 1/1 [00:38<00:00, 38.75s/it]
INFO:root:eval mean loss: 3634.216434992797
INFO:root:eval perplexity: 4.347367763519287
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.54s/it][A100%|██████████| 1/1 [00:37<00:00, 37.54s/it]
INFO:root:eval mean loss: 4568.225807568706
INFO:root:eval perplexity: 6.47539758682251
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/52
 26%|██▌       | 52/200 [8:31:22<24:21:43, 592.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3336.154085286458
INFO:root:current train perplexity3.8016040325164795
INFO:root:current mean train loss 3358.627679177989
INFO:root:current train perplexity3.786101818084717
INFO:root:current mean train loss 3369.819823083212
INFO:root:current train perplexity3.7888023853302
INFO:root:current mean train loss 3375.1311538938494
INFO:root:current train perplexity3.787949323654175
INFO:root:current mean train loss 3379.9077507294805
INFO:root:current train perplexity3.7891805171966553
INFO:root:current mean train loss 3387.582170623483
INFO:root:current train perplexity3.799332857131958
INFO:root:current mean train loss 3390.149714176829
INFO:root:current train perplexity3.8014564514160156
INFO:root:current mean train loss 3389.796274379917
INFO:root:current train perplexity3.8028876781463623
INFO:root:current mean train loss 3390.5952594780483
INFO:root:current train perplexity3.804563283920288
INFO:root:current mean train loss 3393.409101509136
INFO:root:current train perplexity3.8075437545776367

100%|██████████| 1/1 [08:33<00:00, 513.74s/it][A100%|██████████| 1/1 [08:33<00:00, 513.74s/it]
INFO:root:final mean train loss: 3390.4719169985865
INFO:root:final train perplexity: 3.8100385665893555
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.24s/it][A100%|██████████| 1/1 [00:38<00:00, 38.24s/it]
INFO:root:eval mean loss: 3731.0653829371677
INFO:root:eval perplexity: 4.521000385284424
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.25s/it][A100%|██████████| 1/1 [00:37<00:00, 37.26s/it]
INFO:root:eval mean loss: 4675.8453741411795
INFO:root:eval perplexity: 6.766727447509766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/53
 26%|██▋       | 53/200 [8:41:13<24:10:28, 592.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3310.6156908118205
INFO:root:current train perplexity3.7690792083740234
INFO:root:current mean train loss 3349.306749793572
INFO:root:current train perplexity3.7630481719970703
INFO:root:current mean train loss 3361.467934373248
INFO:root:current train perplexity3.7773947715759277
INFO:root:current mean train loss 3369.096832369872
INFO:root:current train perplexity3.780215263366699
INFO:root:current mean train loss 3372.5885497469712
INFO:root:current train perplexity3.7823486328125
INFO:root:current mean train loss 3373.7519395875656
INFO:root:current train perplexity3.7866594791412354
INFO:root:current mean train loss 3379.600678420947
INFO:root:current train perplexity3.790670871734619
INFO:root:current mean train loss 3379.5955579237984
INFO:root:current train perplexity3.7919399738311768
INFO:root:current mean train loss 3381.7734535189475
INFO:root:current train perplexity3.7936038970947266
INFO:root:current mean train loss 3384.7202672162784
INFO:root:current train perplexity3.7955055236816406

100%|██████████| 1/1 [08:39<00:00, 519.34s/it][A100%|██████████| 1/1 [08:39<00:00, 519.34s/it]
INFO:root:final mean train loss: 3381.6971562908543
INFO:root:final train perplexity: 3.7968711853027344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.31s/it][A100%|██████████| 1/1 [00:38<00:00, 38.31s/it]
INFO:root:eval mean loss: 3613.966367464539
INFO:root:eval perplexity: 4.311914443969727
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.01s/it][A100%|██████████| 1/1 [00:38<00:00, 38.01s/it]
INFO:root:eval mean loss: 4552.465022093861
INFO:root:eval perplexity: 6.43380069732666
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/54
 27%|██▋       | 54/200 [8:51:10<24:04:20, 593.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3412.0239021547377
INFO:root:current train perplexity3.837428092956543
INFO:root:current mean train loss 3392.2062690094226
INFO:root:current train perplexity3.7948710918426514
INFO:root:current mean train loss 3376.9737744352
INFO:root:current train perplexity3.783163070678711
INFO:root:current mean train loss 3383.6985224697887
INFO:root:current train perplexity3.7868499755859375
INFO:root:current mean train loss 3385.676427571237
INFO:root:current train perplexity3.7901999950408936
INFO:root:current mean train loss 3377.12542713115
INFO:root:current train perplexity3.7812671661376953
INFO:root:current mean train loss 3379.1370468502378
INFO:root:current train perplexity3.7859339714050293
INFO:root:current mean train loss 3377.7530970123335
INFO:root:current train perplexity3.7846295833587646
INFO:root:current mean train loss 3370.9818008000525
INFO:root:current train perplexity3.7793996334075928
INFO:root:current mean train loss 3374.200873451766
INFO:root:current train perplexity3.7832095623016357

100%|██████████| 1/1 [08:34<00:00, 514.66s/it][A100%|██████████| 1/1 [08:34<00:00, 514.66s/it]
INFO:root:final mean train loss: 3373.8232356040708
INFO:root:final train perplexity: 3.785094738006592
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.81s/it][A100%|██████████| 1/1 [00:38<00:00, 38.81s/it]
INFO:root:eval mean loss: 3628.832992229056
INFO:root:eval perplexity: 4.337913990020752
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.46s/it][A100%|██████████| 1/1 [00:37<00:00, 37.46s/it]
INFO:root:eval mean loss: 4572.722025986259
INFO:root:eval perplexity: 6.487315654754639
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/55
 28%|██▊       | 55/200 [9:01:03<23:53:40, 593.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3332.4431590544873
INFO:root:current train perplexity3.7456588745117188
INFO:root:current mean train loss 3356.580223906812
INFO:root:current train perplexity3.7469494342803955
INFO:root:current mean train loss 3353.4619957832115
INFO:root:current train perplexity3.751171112060547
INFO:root:current mean train loss 3349.0353514184644
INFO:root:current train perplexity3.7492477893829346
INFO:root:current mean train loss 3357.3772868023916
INFO:root:current train perplexity3.759019136428833
INFO:root:current mean train loss 3361.9250044389205
INFO:root:current train perplexity3.7646214962005615
INFO:root:current mean train loss 3362.678035443564
INFO:root:current train perplexity3.764822244644165
INFO:root:current mean train loss 3365.606448616162
INFO:root:current train perplexity3.7689435482025146
INFO:root:current mean train loss 3364.0851506629915
INFO:root:current train perplexity3.768202781677246
INFO:root:current mean train loss 3362.618890244359
INFO:root:current train perplexity3.766819953918457

100%|██████████| 1/1 [08:38<00:00, 518.77s/it][A100%|██████████| 1/1 [08:38<00:00, 518.77s/it]
INFO:root:final mean train loss: 3362.04406744434
INFO:root:final train perplexity: 3.767545223236084
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.05s/it][A100%|██████████| 1/1 [00:38<00:00, 38.05s/it]
INFO:root:eval mean loss: 3612.414869376108
INFO:root:eval perplexity: 4.309209823608398
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.78s/it][A100%|██████████| 1/1 [00:36<00:00, 36.80s/it]
INFO:root:eval mean loss: 4560.51730454898
INFO:root:eval perplexity: 6.455019474029541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/56
 28%|██▊       | 56/200 [9:10:58<23:45:03, 593.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3336.476531333112
INFO:root:current train perplexity3.738968849182129
INFO:root:current mean train loss 3348.004201876063
INFO:root:current train perplexity3.740190267562866
INFO:root:current mean train loss 3349.061136963879
INFO:root:current train perplexity3.7398884296417236
INFO:root:current mean train loss 3346.991768169128
INFO:root:current train perplexity3.7369048595428467
INFO:root:current mean train loss 3346.884105298343
INFO:root:current train perplexity3.7366256713867188
INFO:root:current mean train loss 3348.2153887147224
INFO:root:current train perplexity3.7385900020599365
INFO:root:current mean train loss 3348.8705994312695
INFO:root:current train perplexity3.7408082485198975
INFO:root:current mean train loss 3352.743475529723
INFO:root:current train perplexity3.744025945663452
INFO:root:current mean train loss 3355.5091845299585
INFO:root:current train perplexity3.7484519481658936
INFO:root:current mean train loss 3352.628595853683
INFO:root:current train perplexity3.7483971118927

100%|██████████| 1/1 [08:33<00:00, 513.80s/it][A100%|██████████| 1/1 [08:33<00:00, 513.80s/it]
INFO:root:final mean train loss: 3349.8434537456883
INFO:root:final train perplexity: 3.749453544616699
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.04s/it][A100%|██████████| 1/1 [00:38<00:00, 38.04s/it]
INFO:root:eval mean loss: 3639.4774923121677
INFO:root:eval perplexity: 4.356626033782959
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.95s/it][A100%|██████████| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 4589.026076296543
INFO:root:eval perplexity: 6.5307111740112305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/57
 28%|██▊       | 57/200 [9:20:48<23:32:40, 592.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3357.9266867897727
INFO:root:current train perplexity3.724562883377075
INFO:root:current mean train loss 3336.418579889113
INFO:root:current train perplexity3.727968692779541
INFO:root:current mean train loss 3339.604061351103
INFO:root:current train perplexity3.731861114501953
INFO:root:current mean train loss 3338.7059597821303
INFO:root:current train perplexity3.727795362472534
INFO:root:current mean train loss 3334.8188063401444
INFO:root:current train perplexity3.727762460708618
INFO:root:current mean train loss 3343.9381725964245
INFO:root:current train perplexity3.7396018505096436
INFO:root:current mean train loss 3343.738429970778
INFO:root:current train perplexity3.738469123840332
INFO:root:current mean train loss 3341.8921655111753
INFO:root:current train perplexity3.7383530139923096
INFO:root:current mean train loss 3345.517747738487
INFO:root:current train perplexity3.7391769886016846
INFO:root:current mean train loss 3346.9862135962044
INFO:root:current train perplexity3.7420401573181152

100%|██████████| 1/1 [08:33<00:00, 513.15s/it][A100%|██████████| 1/1 [08:33<00:00, 513.15s/it]
INFO:root:final mean train loss: 3345.9319131912725
INFO:root:final train perplexity: 3.7436718940734863
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.73s/it][A100%|██████████| 1/1 [00:37<00:00, 37.73s/it]
INFO:root:eval mean loss: 3610.3904102947695
INFO:root:eval perplexity: 4.305683612823486
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.80s/it][A100%|██████████| 1/1 [00:36<00:00, 36.82s/it]
INFO:root:eval mean loss: 4558.898868641955
INFO:root:eval perplexity: 6.45074987411499
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/58
 29%|██▉       | 58/200 [9:30:37<23:20:16, 591.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3309.005064949157
INFO:root:current train perplexity3.701371431350708
INFO:root:current mean train loss 3322.172327334164
INFO:root:current train perplexity3.7219207286834717
INFO:root:current mean train loss 3325.5979078169557
INFO:root:current train perplexity3.7208352088928223
INFO:root:current mean train loss 3330.3460353714704
INFO:root:current train perplexity3.7226076126098633
INFO:root:current mean train loss 3329.5015128281925
INFO:root:current train perplexity3.718951940536499
INFO:root:current mean train loss 3328.454971882632
INFO:root:current train perplexity3.718961238861084
INFO:root:current mean train loss 3332.993435820843
INFO:root:current train perplexity3.7212743759155273
INFO:root:current mean train loss 3332.468310674865
INFO:root:current train perplexity3.7198948860168457
INFO:root:current mean train loss 3337.5659714363956
INFO:root:current train perplexity3.7280993461608887
INFO:root:current mean train loss 3336.6609403901384
INFO:root:current train perplexity3.726789951324463

100%|██████████| 1/1 [08:34<00:00, 514.21s/it][A100%|██████████| 1/1 [08:34<00:00, 514.21s/it]
INFO:root:final mean train loss: 3334.0999023068334
INFO:root:final train perplexity: 3.7262372970581055
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.15s/it][A100%|██████████| 1/1 [00:38<00:00, 38.15s/it]
INFO:root:eval mean loss: 3613.039365511414
INFO:root:eval perplexity: 4.310298442840576
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.02s/it][A100%|██████████| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 4562.0537663453015
INFO:root:eval perplexity: 6.459078311920166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/59
 30%|██▉       | 59/200 [9:40:28<23:09:51, 591.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3297.9496932768484
INFO:root:current train perplexity3.6800832748413086
INFO:root:current mean train loss 3299.762930886787
INFO:root:current train perplexity3.6745119094848633
INFO:root:current mean train loss 3303.9170102052585
INFO:root:current train perplexity3.6834640502929688
INFO:root:current mean train loss 3313.6156627727005
INFO:root:current train perplexity3.6934924125671387
INFO:root:current mean train loss 3318.982396994427
INFO:root:current train perplexity3.701184034347534
INFO:root:current mean train loss 3326.8600770646344
INFO:root:current train perplexity3.7081122398376465
INFO:root:current mean train loss 3324.358659315038
INFO:root:current train perplexity3.708599805831909
INFO:root:current mean train loss 3326.5495396476776
INFO:root:current train perplexity3.71342134475708
INFO:root:current mean train loss 3323.866049204847
INFO:root:current train perplexity3.708749294281006
INFO:root:current mean train loss 3324.3648479237736
INFO:root:current train perplexity3.708880662918091

100%|██████████| 1/1 [08:33<00:00, 513.64s/it][A100%|██████████| 1/1 [08:33<00:00, 513.64s/it]
INFO:root:final mean train loss: 3322.0765380859375
INFO:root:final train perplexity: 3.7086029052734375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.59s/it][A100%|██████████| 1/1 [00:37<00:00, 37.59s/it]
INFO:root:eval mean loss: 3604.5788955147386
INFO:root:eval perplexity: 4.295577049255371
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.45s/it][A100%|██████████| 1/1 [00:37<00:00, 37.47s/it]
INFO:root:eval mean loss: 4556.678160322474
INFO:root:eval perplexity: 6.444894790649414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/60
 30%|███       | 60/200 [9:50:18<22:59:07, 591.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3324.9914210838606
INFO:root:current train perplexity3.71028995513916
INFO:root:current mean train loss 3315.305613597678
INFO:root:current train perplexity3.693394899368286
INFO:root:current mean train loss 3316.0916656165996
INFO:root:current train perplexity3.6973369121551514
INFO:root:current mean train loss 3316.321858509235
INFO:root:current train perplexity3.7027926445007324
INFO:root:current mean train loss 3315.027510927714
INFO:root:current train perplexity3.7004053592681885
INFO:root:current mean train loss 3313.6527000519486
INFO:root:current train perplexity3.6974377632141113
INFO:root:current mean train loss 3314.8220488108664
INFO:root:current train perplexity3.697629928588867
INFO:root:current mean train loss 3316.154786723263
INFO:root:current train perplexity3.698411464691162
INFO:root:current mean train loss 3317.8625916013402
INFO:root:current train perplexity3.699831485748291
INFO:root:current mean train loss 3317.62861572515
INFO:root:current train perplexity3.698793411254883

100%|██████████| 1/1 [08:35<00:00, 515.84s/it][A100%|██████████| 1/1 [08:35<00:00, 515.85s/it]
INFO:root:final mean train loss: 3315.2443209002095
INFO:root:final train perplexity: 3.698620557785034
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.17s/it][A100%|██████████| 1/1 [00:38<00:00, 38.17s/it]
INFO:root:eval mean loss: 3599.8272038453015
INFO:root:eval perplexity: 4.287331581115723
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.04s/it][A100%|██████████| 1/1 [00:37<00:00, 37.04s/it]
INFO:root:eval mean loss: 4549.691414907469
INFO:root:eval perplexity: 6.426507949829102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/61
 30%|███       | 61/200 [10:00:11<22:50:23, 591.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3296.602609217852
INFO:root:current train perplexity3.6855995655059814
INFO:root:current mean train loss 3313.8023322610293
INFO:root:current train perplexity3.696516275405884
INFO:root:current mean train loss 3305.5697357496733
INFO:root:current train perplexity3.686656951904297
INFO:root:current mean train loss 3308.218586608729
INFO:root:current train perplexity3.687727928161621
INFO:root:current mean train loss 3305.7253402929286
INFO:root:current train perplexity3.68426775932312
INFO:root:current mean train loss 3302.4506623822135
INFO:root:current train perplexity3.6783664226531982
INFO:root:current mean train loss 3305.4669191229987
INFO:root:current train perplexity3.6852810382843018
INFO:root:current mean train loss 3307.9734721201953
INFO:root:current train perplexity3.6888434886932373
INFO:root:current mean train loss 3308.853199095441
INFO:root:current train perplexity3.6886138916015625
INFO:root:current mean train loss 3311.424218947885
INFO:root:current train perplexity3.688697576522827

100%|██████████| 1/1 [08:32<00:00, 512.50s/it][A100%|██████████| 1/1 [08:32<00:00, 512.50s/it]
INFO:root:final mean train loss: 3307.819775058377
INFO:root:final train perplexity: 3.6878018379211426
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.81s/it][A100%|██████████| 1/1 [00:37<00:00, 37.82s/it]
INFO:root:eval mean loss: 3626.2302055629434
INFO:root:eval perplexity: 4.333350658416748
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.12s/it][A100%|██████████| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 4588.250167954898
INFO:root:eval perplexity: 6.528639793395996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/62
 31%|███       | 62/200 [10:10:00<22:38:44, 590.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3309.6370399876646
INFO:root:current train perplexity3.684903621673584
INFO:root:current mean train loss 3311.709997245593
INFO:root:current train perplexity3.682255744934082
INFO:root:current mean train loss 3306.4992932335804
INFO:root:current train perplexity3.6752212047576904
INFO:root:current mean train loss 3300.0517139289955
INFO:root:current train perplexity3.665121555328369
INFO:root:current mean train loss 3300.368025469539
INFO:root:current train perplexity3.6659815311431885
INFO:root:current mean train loss 3298.5753717502625
INFO:root:current train perplexity3.6668076515197754
INFO:root:current mean train loss 3298.8290428984938
INFO:root:current train perplexity3.670348644256592
INFO:root:current mean train loss 3298.101811247052
INFO:root:current train perplexity3.671848773956299
INFO:root:current mean train loss 3299.6857929251046
INFO:root:current train perplexity3.6726491451263428

100%|██████████| 1/1 [08:35<00:00, 515.52s/it][A100%|██████████| 1/1 [08:35<00:00, 515.54s/it]
INFO:root:final mean train loss: 3296.577455336048
INFO:root:final train perplexity: 3.6714816093444824
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.76s/it][A100%|██████████| 1/1 [00:37<00:00, 37.76s/it]
INFO:root:eval mean loss: 3610.0292587821364
INFO:root:eval perplexity: 4.305054664611816
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.92s/it][A100%|██████████| 1/1 [00:36<00:00, 36.92s/it]
INFO:root:eval mean loss: 4570.163778535018
INFO:root:eval perplexity: 6.480534076690674
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/63
 32%|███▏      | 63/200 [10:19:52<22:29:31, 591.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3292.202880859375
INFO:root:current train perplexity3.457770586013794
INFO:root:current mean train loss 3290.908985323119
INFO:root:current train perplexity3.64402174949646
INFO:root:current mean train loss 3282.4796377097446
INFO:root:current train perplexity3.6457576751708984
INFO:root:current mean train loss 3285.7942305461015
INFO:root:current train perplexity3.651566505432129
INFO:root:current mean train loss 3285.154055763415
INFO:root:current train perplexity3.654078483581543
INFO:root:current mean train loss 3282.8735303025596
INFO:root:current train perplexity3.6512069702148438
INFO:root:current mean train loss 3281.2306420372097
INFO:root:current train perplexity3.6526570320129395
INFO:root:current mean train loss 3284.1054024187633
INFO:root:current train perplexity3.654881000518799
INFO:root:current mean train loss 3285.266666322093
INFO:root:current train perplexity3.6558990478515625
INFO:root:current mean train loss 3287.965047065338
INFO:root:current train perplexity3.65590238571167

100%|██████████| 1/1 [08:35<00:00, 515.14s/it][A100%|██████████| 1/1 [08:35<00:00, 515.14s/it]
INFO:root:final mean train loss: 3287.898618882702
INFO:root:final train perplexity: 3.658931255340576
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.79s/it][A100%|██████████| 1/1 [00:37<00:00, 37.79s/it]
INFO:root:eval mean loss: 3602.566963791002
INFO:root:eval perplexity: 4.292083740234375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.66s/it][A100%|██████████| 1/1 [00:36<00:00, 36.66s/it]
INFO:root:eval mean loss: 4563.925800296432
INFO:root:eval perplexity: 6.464022636413574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/64
 32%|███▏      | 64/200 [10:29:43<22:19:42, 591.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3294.08154296875
INFO:root:current train perplexity3.6435153484344482
INFO:root:current mean train loss 3281.8830632390204
INFO:root:current train perplexity3.6458497047424316
INFO:root:current mean train loss 3275.4352228969196
INFO:root:current train perplexity3.636399507522583
INFO:root:current mean train loss 3275.8721024982415
INFO:root:current train perplexity3.6425304412841797
INFO:root:current mean train loss 3272.947737867815
INFO:root:current train perplexity3.6370468139648438
INFO:root:current mean train loss 3273.9808337665118
INFO:root:current train perplexity3.6408255100250244
INFO:root:current mean train loss 3277.9823623382517
INFO:root:current train perplexity3.647095203399658
INFO:root:current mean train loss 3277.3752341827094
INFO:root:current train perplexity3.647207021713257
INFO:root:current mean train loss 3280.625157141068
INFO:root:current train perplexity3.648449182510376
INFO:root:current mean train loss 3280.280463979744
INFO:root:current train perplexity3.6485435962677

100%|██████████| 1/1 [08:34<00:00, 514.48s/it][A100%|██████████| 1/1 [08:34<00:00, 514.54s/it]
INFO:root:final mean train loss: 3281.593305710823
INFO:root:final train perplexity: 3.6498401165008545
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.89s/it][A100%|██████████| 1/1 [00:37<00:00, 37.89s/it]
INFO:root:eval mean loss: 3637.752451795213
INFO:root:eval perplexity: 4.353588581085205
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.29s/it][A100%|██████████| 1/1 [00:37<00:00, 37.29s/it]
INFO:root:eval mean loss: 4604.949705299756
INFO:root:eval perplexity: 6.573372840881348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/65
 32%|███▎      | 65/200 [10:39:34<22:09:58, 591.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3253.4928428248354
INFO:root:current train perplexity3.6223278045654297
INFO:root:current mean train loss 3229.737737575499
INFO:root:current train perplexity3.6029653549194336
INFO:root:current mean train loss 3248.6735628032247
INFO:root:current train perplexity3.6136701107025146
INFO:root:current mean train loss 3267.256726495151
INFO:root:current train perplexity3.633741855621338
INFO:root:current mean train loss 3274.9949721015437
INFO:root:current train perplexity3.639594554901123
INFO:root:current mean train loss 3275.1190305500363
INFO:root:current train perplexity3.6394174098968506
INFO:root:current mean train loss 3278.1051031306797
INFO:root:current train perplexity3.6397788524627686
INFO:root:current mean train loss 3280.794793183349
INFO:root:current train perplexity3.642642021179199
INFO:root:current mean train loss 3276.6826908172125
INFO:root:current train perplexity3.637535333633423
INFO:root:current mean train loss 3273.8834508785876
INFO:root:current train perplexity3.6360106468200684

100%|██████████| 1/1 [08:35<00:00, 515.56s/it][A100%|██████████| 1/1 [08:35<00:00, 515.56s/it]
INFO:root:final mean train loss: 3272.6784832862118
INFO:root:final train perplexity: 3.637026071548462
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.85s/it][A100%|██████████| 1/1 [00:37<00:00, 37.85s/it]
INFO:root:eval mean loss: 3613.919418010306
INFO:root:eval perplexity: 4.311831951141357
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.92s/it][A100%|██████████| 1/1 [00:36<00:00, 36.92s/it]
INFO:root:eval mean loss: 4575.692157718307
INFO:root:eval perplexity: 6.495200157165527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/66
 33%|███▎      | 66/200 [10:49:26<22:00:32, 591.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3324.6428674768517
INFO:root:current train perplexity3.690681219100952
INFO:root:current mean train loss 3308.4375634381154
INFO:root:current train perplexity3.6716434955596924
INFO:root:current mean train loss 3272.37526887734
INFO:root:current train perplexity3.6344358921051025
INFO:root:current mean train loss 3265.152896986095
INFO:root:current train perplexity3.627758502960205
INFO:root:current mean train loss 3264.2368055428497
INFO:root:current train perplexity3.6234309673309326
INFO:root:current mean train loss 3262.8868456845944
INFO:root:current train perplexity3.625180244445801
INFO:root:current mean train loss 3259.3863636363635
INFO:root:current train perplexity3.621147871017456
INFO:root:current mean train loss 3263.5743349434747
INFO:root:current train perplexity3.6237778663635254
INFO:root:current mean train loss 3266.6398547909425
INFO:root:current train perplexity3.6247611045837402
INFO:root:current mean train loss 3267.0096152428027
INFO:root:current train perplexity3.62591290473938

100%|██████████| 1/1 [08:35<00:00, 515.21s/it][A100%|██████████| 1/1 [08:35<00:00, 515.21s/it]
INFO:root:final mean train loss: 3264.1019208354332
INFO:root:final train perplexity: 3.6247398853302
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.21s/it][A100%|██████████| 1/1 [00:38<00:00, 38.21s/it]
INFO:root:eval mean loss: 3595.7219792359265
INFO:root:eval perplexity: 4.280220031738281
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.62s/it][A100%|██████████| 1/1 [00:36<00:00, 36.64s/it]
INFO:root:eval mean loss: 4555.546156430075
INFO:root:eval perplexity: 6.4419121742248535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/67
 34%|███▎      | 67/200 [10:59:17<21:50:52, 591.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3224.4112374441966
INFO:root:current train perplexity3.5614492893218994
INFO:root:current mean train loss 3232.835328052662
INFO:root:current train perplexity3.5769853591918945
INFO:root:current mean train loss 3237.490823429189
INFO:root:current train perplexity3.585423469543457
INFO:root:current mean train loss 3243.4453256180036
INFO:root:current train perplexity3.595958709716797
INFO:root:current mean train loss 3253.8692281788794
INFO:root:current train perplexity3.6088836193084717
INFO:root:current mean train loss 3247.811799521758
INFO:root:current train perplexity3.6011908054351807
INFO:root:current mean train loss 3250.263535386934
INFO:root:current train perplexity3.6032090187072754
INFO:root:current mean train loss 3256.723307955995
INFO:root:current train perplexity3.6108503341674805
INFO:root:current mean train loss 3258.907662214633
INFO:root:current train perplexity3.612325429916382
INFO:root:current mean train loss 3257.6498670934993
INFO:root:current train perplexity3.6128671169281006

100%|██████████| 1/1 [08:36<00:00, 516.61s/it][A100%|██████████| 1/1 [08:36<00:00, 516.61s/it]
INFO:root:final mean train loss: 3256.949297628095
INFO:root:final train perplexity: 3.6145265102386475
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.14s/it][A100%|██████████| 1/1 [00:38<00:00, 38.15s/it]
INFO:root:eval mean loss: 3596.52949772828
INFO:root:eval perplexity: 4.281617641448975
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.38s/it][A100%|██████████| 1/1 [00:37<00:00, 37.38s/it]
INFO:root:eval mean loss: 4560.376502936613
INFO:root:eval perplexity: 6.454648494720459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/68
 34%|███▍      | 68/200 [11:09:11<21:42:34, 592.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3257.5350086300873
INFO:root:current train perplexity3.601647138595581
INFO:root:current mean train loss 3234.7294768220063
INFO:root:current train perplexity3.571276903152466
INFO:root:current mean train loss 3244.7626722045397
INFO:root:current train perplexity3.578794240951538
INFO:root:current mean train loss 3237.725100503371
INFO:root:current train perplexity3.5791757106781006
INFO:root:current mean train loss 3247.776685176531
INFO:root:current train perplexity3.590250015258789
INFO:root:current mean train loss 3247.226370964261
INFO:root:current train perplexity3.590069055557251
INFO:root:current mean train loss 3247.8450382879328
INFO:root:current train perplexity3.5946340560913086
INFO:root:current mean train loss 3247.594277711768
INFO:root:current train perplexity3.595038652420044
INFO:root:current mean train loss 3249.0140926772874
INFO:root:current train perplexity3.5967373847961426
INFO:root:current mean train loss 3249.477518350676
INFO:root:current train perplexity3.6003119945526123

100%|██████████| 1/1 [08:35<00:00, 515.87s/it][A100%|██████████| 1/1 [08:35<00:00, 515.87s/it]
INFO:root:final mean train loss: 3248.327306870491
INFO:root:final train perplexity: 3.6022520065307617
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.31s/it][A100%|██████████| 1/1 [00:38<00:00, 38.33s/it]
INFO:root:eval mean loss: 3589.7915489250886
INFO:root:eval perplexity: 4.269967555999756
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.12s/it][A100%|██████████| 1/1 [00:37<00:00, 37.13s/it]
INFO:root:eval mean loss: 4559.85430518617
INFO:root:eval perplexity: 6.453271389007568
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/69
 34%|███▍      | 69/200 [11:19:04<21:33:11, 592.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3291.132510914522
INFO:root:current train perplexity3.632446050643921
INFO:root:current mean train loss 3267.7252059835473
INFO:root:current train perplexity3.6113393306732178
INFO:root:current mean train loss 3241.9831834770293
INFO:root:current train perplexity3.5862843990325928
INFO:root:current mean train loss 3239.687895772124
INFO:root:current train perplexity3.5851268768310547
INFO:root:current mean train loss 3240.7578135826634
INFO:root:current train perplexity3.587315559387207
INFO:root:current mean train loss 3236.8302035184606
INFO:root:current train perplexity3.585832118988037
INFO:root:current mean train loss 3239.2943559637815
INFO:root:current train perplexity3.5902822017669678
INFO:root:current mean train loss 3239.1232789873916
INFO:root:current train perplexity3.5914134979248047
INFO:root:current mean train loss 3240.025018819771
INFO:root:current train perplexity3.5886170864105225
INFO:root:current mean train loss 3243.6508424520243
INFO:root:current train perplexity3.5922117233276367

100%|██████████| 1/1 [08:33<00:00, 513.29s/it][A100%|██████████| 1/1 [08:33<00:00, 513.30s/it]
INFO:root:final mean train loss: 3241.995745628111
INFO:root:final train perplexity: 3.5932648181915283
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.65s/it][A100%|██████████| 1/1 [00:38<00:00, 38.65s/it]
INFO:root:eval mean loss: 3611.8504803163787
INFO:root:eval perplexity: 4.308226108551025
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.67s/it][A100%|██████████| 1/1 [00:36<00:00, 36.68s/it]
INFO:root:eval mean loss: 4577.684836962544
INFO:root:eval perplexity: 6.500493049621582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/70
 35%|███▌      | 70/200 [11:28:54<21:21:55, 591.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3186.851305945445
INFO:root:current train perplexity3.5481300354003906
INFO:root:current mean train loss 3227.8328327682784
INFO:root:current train perplexity3.569502115249634
INFO:root:current mean train loss 3222.6540122013753
INFO:root:current train perplexity3.5707168579101562
INFO:root:current mean train loss 3231.4618820998
INFO:root:current train perplexity3.578145980834961
INFO:root:current mean train loss 3235.364537058313
INFO:root:current train perplexity3.581435203552246
INFO:root:current mean train loss 3231.4954207254864
INFO:root:current train perplexity3.5781826972961426
INFO:root:current mean train loss 3228.6328150932995
INFO:root:current train perplexity3.5751349925994873
INFO:root:current mean train loss 3234.17138318048
INFO:root:current train perplexity3.5795652866363525
INFO:root:current mean train loss 3235.175968831854
INFO:root:current train perplexity3.5822913646698
INFO:root:current mean train loss 3237.7171947809406
INFO:root:current train perplexity3.584136724472046

100%|██████████| 1/1 [08:35<00:00, 515.99s/it][A100%|██████████| 1/1 [08:35<00:00, 515.99s/it]
INFO:root:final mean train loss: 3235.6624736170616
INFO:root:final train perplexity: 3.5842974185943604
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.18s/it][A100%|██████████| 1/1 [00:38<00:00, 38.18s/it]
INFO:root:eval mean loss: 3589.801885943041
INFO:root:eval perplexity: 4.269985675811768
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.36s/it][A100%|██████████| 1/1 [00:37<00:00, 37.39s/it]
INFO:root:eval mean loss: 4562.660983904034
INFO:root:eval perplexity: 6.460680961608887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/71
 36%|███▌      | 71/200 [11:38:47<21:13:00, 592.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3191.785447761194
INFO:root:current train perplexity3.5279080867767334
INFO:root:current mean train loss 3221.416163278911
INFO:root:current train perplexity3.548307180404663
INFO:root:current mean train loss 3222.2093482999767
INFO:root:current train perplexity3.5557291507720947
INFO:root:current mean train loss 3218.8934269627043
INFO:root:current train perplexity3.5571537017822266
INFO:root:current mean train loss 3215.957643954095
INFO:root:current train perplexity3.5589449405670166
INFO:root:current mean train loss 3225.3096155237267
INFO:root:current train perplexity3.5666089057922363
INFO:root:current mean train loss 3228.1522357717627
INFO:root:current train perplexity3.5714378356933594
INFO:root:current mean train loss 3229.3587552584136
INFO:root:current train perplexity3.573126792907715
INFO:root:current mean train loss 3231.6617607635885
INFO:root:current train perplexity3.573294162750244
INFO:root:current mean train loss 3233.2094941163878
INFO:root:current train perplexity3.575904607772827

100%|██████████| 1/1 [08:39<00:00, 519.96s/it][A100%|██████████| 1/1 [08:39<00:00, 519.96s/it]
INFO:root:final mean train loss: 3230.265523356776
INFO:root:final train perplexity: 3.576673746109009
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.30s/it][A100%|██████████| 1/1 [00:38<00:00, 38.30s/it]
INFO:root:eval mean loss: 3584.906823124446
INFO:root:eval perplexity: 4.261541843414307
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.85s/it][A100%|██████████| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 4556.230678260749
INFO:root:eval perplexity: 6.443715572357178
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/72
 36%|███▌      | 72/200 [11:48:44<21:06:04, 593.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3233.491416015625
INFO:root:current train perplexity3.5643911361694336
INFO:root:current mean train loss 3215.0618833705357
INFO:root:current train perplexity3.5426433086395264
INFO:root:current mean train loss 3216.627432528409
INFO:root:current train perplexity3.542752265930176
INFO:root:current mean train loss 3214.3151328125
INFO:root:current train perplexity3.5491368770599365
INFO:root:current mean train loss 3219.0068277138157
INFO:root:current train perplexity3.5584027767181396
INFO:root:current mean train loss 3216.9219242527174
INFO:root:current train perplexity3.5574984550476074
INFO:root:current mean train loss 3216.2635579427083
INFO:root:current train perplexity3.5561187267303467
INFO:root:current mean train loss 3220.350441343246
INFO:root:current train perplexity3.5598304271698
INFO:root:current mean train loss 3220.538890625
INFO:root:current train perplexity3.5617129802703857
INFO:root:current mean train loss 3223.115112930689
INFO:root:current train perplexity3.5640244483947754

100%|██████████| 1/1 [08:37<00:00, 517.98s/it][A100%|██████████| 1/1 [08:37<00:00, 518.00s/it]
INFO:root:final mean train loss: 3221.729367225401
INFO:root:final train perplexity: 3.5646486282348633
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.08s/it][A100%|██████████| 1/1 [00:38<00:00, 38.08s/it]
INFO:root:eval mean loss: 3598.703898977726
INFO:root:eval perplexity: 4.285384654998779
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.41s/it][A100%|██████████| 1/1 [00:37<00:00, 37.43s/it]
INFO:root:eval mean loss: 4566.3684636109265
INFO:root:eval perplexity: 6.470484256744385
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/73
 36%|███▋      | 73/200 [11:58:39<20:57:09, 593.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3218.335363916604
INFO:root:current train perplexity3.544355869293213
INFO:root:current mean train loss 3227.200105927681
INFO:root:current train perplexity3.5565197467803955
INFO:root:current mean train loss 3223.4032832169282
INFO:root:current train perplexity3.5540943145751953
INFO:root:current mean train loss 3220.0396043264523
INFO:root:current train perplexity3.553424835205078
INFO:root:current mean train loss 3220.077402687468
INFO:root:current train perplexity3.552065134048462
INFO:root:current mean train loss 3216.7319884521066
INFO:root:current train perplexity3.550793170928955
INFO:root:current mean train loss 3218.294052191046
INFO:root:current train perplexity3.5537989139556885
INFO:root:current mean train loss 3217.0769105329064
INFO:root:current train perplexity3.5527591705322266
INFO:root:current mean train loss 3216.68288870063
INFO:root:current train perplexity3.5522937774658203
INFO:root:current mean train loss 3221.2562644547147
INFO:root:current train perplexity3.5599098205566406

100%|██████████| 1/1 [08:36<00:00, 516.08s/it][A100%|██████████| 1/1 [08:36<00:00, 516.08s/it]
INFO:root:final mean train loss: 3218.7249965667725
INFO:root:final train perplexity: 3.5604259967803955
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.02s/it][A100%|██████████| 1/1 [00:38<00:00, 38.02s/it]
INFO:root:eval mean loss: 3586.210582543772
INFO:root:eval perplexity: 4.263789653778076
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.28s/it][A100%|██████████| 1/1 [00:37<00:00, 37.30s/it]
INFO:root:eval mean loss: 4564.7315301556955
INFO:root:eval perplexity: 6.466152667999268
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/74
 37%|███▋      | 74/200 [12:08:32<20:46:34, 593.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3199.104462675996
INFO:root:current train perplexity3.5308427810668945
INFO:root:current mean train loss 3189.193611184964
INFO:root:current train perplexity3.518559455871582
INFO:root:current mean train loss 3193.208293062715
INFO:root:current train perplexity3.5307810306549072
INFO:root:current mean train loss 3202.1515732396897
INFO:root:current train perplexity3.5375609397888184
INFO:root:current mean train loss 3205.744009853138
INFO:root:current train perplexity3.5419325828552246
INFO:root:current mean train loss 3203.3768035837033
INFO:root:current train perplexity3.539567232131958
INFO:root:current mean train loss 3205.0550485878707
INFO:root:current train perplexity3.537940263748169
INFO:root:current mean train loss 3206.7909239565224
INFO:root:current train perplexity3.5414347648620605
INFO:root:current mean train loss 3209.6042074937745
INFO:root:current train perplexity3.543919324874878
INFO:root:current mean train loss 3209.2280404007156
INFO:root:current train perplexity3.543689489364624

100%|██████████| 1/1 [08:36<00:00, 516.75s/it][A100%|██████████| 1/1 [08:36<00:00, 516.76s/it]
INFO:root:final mean train loss: 3206.7539261233424
INFO:root:final train perplexity: 3.543649435043335
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.68s/it][A100%|██████████| 1/1 [00:38<00:00, 38.69s/it]
INFO:root:eval mean loss: 3596.857607144836
INFO:root:eval perplexity: 4.282186031341553
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.24s/it][A100%|██████████| 1/1 [00:37<00:00, 37.26s/it]
INFO:root:eval mean loss: 4572.551719719637
INFO:root:eval perplexity: 6.48686408996582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/75
 38%|███▊      | 75/200 [12:18:26<20:37:04, 593.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3176.656526199495
INFO:root:current train perplexity3.507730007171631
INFO:root:current mean train loss 3186.3604288532506
INFO:root:current train perplexity3.5206336975097656
INFO:root:current mean train loss 3192.6404037220423
INFO:root:current train perplexity3.5211691856384277
INFO:root:current mean train loss 3199.4720963786417
INFO:root:current train perplexity3.5265848636627197
INFO:root:current mean train loss 3202.2642443089303
INFO:root:current train perplexity3.529937982559204
INFO:root:current mean train loss 3200.9511091076274
INFO:root:current train perplexity3.530794382095337
INFO:root:current mean train loss 3203.7568279042607
INFO:root:current train perplexity3.535184144973755
INFO:root:current mean train loss 3204.9114405091327
INFO:root:current train perplexity3.53653883934021
INFO:root:current mean train loss 3205.2317820581898
INFO:root:current train perplexity3.536421775817871

100%|██████████| 1/1 [08:35<00:00, 515.13s/it][A100%|██████████| 1/1 [08:35<00:00, 515.13s/it]
INFO:root:final mean train loss: 3202.1655641986476
INFO:root:final train perplexity: 3.537240505218506
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.36s/it][A100%|██████████| 1/1 [00:38<00:00, 38.40s/it]
INFO:root:eval mean loss: 3593.0334264876997
INFO:root:eval perplexity: 4.275568962097168
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.54s/it][A100%|██████████| 1/1 [00:37<00:00, 37.54s/it]
INFO:root:eval mean loss: 4568.905162621897
INFO:root:eval perplexity: 6.477198123931885
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/76
 38%|███▊      | 76/200 [12:28:18<20:26:24, 593.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3141.309326171875
INFO:root:current train perplexity3.5591049194335938
INFO:root:current mean train loss 3190.2400906286507
INFO:root:current train perplexity3.5492756366729736
INFO:root:current mean train loss 3172.39649498981
INFO:root:current train perplexity3.5128016471862793
INFO:root:current mean train loss 3172.056487142457
INFO:root:current train perplexity3.5091850757598877
INFO:root:current mean train loss 3180.884943181818
INFO:root:current train perplexity3.51771879196167
INFO:root:current mean train loss 3183.922620423447
INFO:root:current train perplexity3.5160608291625977
INFO:root:current mean train loss 3187.4701199225187
INFO:root:current train perplexity3.5179214477539062
INFO:root:current mean train loss 3189.0221888260253
INFO:root:current train perplexity3.5176308155059814
INFO:root:current mean train loss 3192.8956454630384
INFO:root:current train perplexity3.52291202545166
INFO:root:current mean train loss 3194.978990178387
INFO:root:current train perplexity3.524257183074951

100%|██████████| 1/1 [08:41<00:00, 521.28s/it][A100%|██████████| 1/1 [08:41<00:00, 521.28s/it]
INFO:root:final mean train loss: 3192.4148497427664
INFO:root:final train perplexity: 3.5236592292785645
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.00s/it][A100%|██████████| 1/1 [00:38<00:00, 38.01s/it]
INFO:root:eval mean loss: 3595.302111037234
INFO:root:eval perplexity: 4.27949333190918
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.01s/it][A100%|██████████| 1/1 [00:38<00:00, 38.03s/it]
INFO:root:eval mean loss: 4573.316884142288
INFO:root:eval perplexity: 6.488894462585449
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/77
 38%|███▊      | 77/200 [12:38:17<20:19:48, 595.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3162.53974609375
INFO:root:current train perplexity3.475761890411377
INFO:root:current mean train loss 3178.457328464674
INFO:root:current train perplexity3.510214328765869
INFO:root:current mean train loss 3182.0278297601744
INFO:root:current train perplexity3.5145277976989746
INFO:root:current mean train loss 3174.260646081349
INFO:root:current train perplexity3.505209445953369
INFO:root:current mean train loss 3181.9591408603164
INFO:root:current train perplexity3.50966215133667
INFO:root:current mean train loss 3187.1279666641385
INFO:root:current train perplexity3.5155117511749268
INFO:root:current mean train loss 3188.1016172827744
INFO:root:current train perplexity3.515263557434082
INFO:root:current mean train loss 3190.2345969460225
INFO:root:current train perplexity3.515862464904785
INFO:root:current mean train loss 3194.3616741157016
INFO:root:current train perplexity3.520644187927246
INFO:root:current mean train loss 3192.1547763511785
INFO:root:current train perplexity3.5198612213134766

100%|██████████| 1/1 [08:39<00:00, 519.30s/it][A100%|██████████| 1/1 [08:39<00:00, 519.30s/it]
INFO:root:final mean train loss: 3191.130050228488
INFO:root:final train perplexity: 3.5218732357025146
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.63s/it][A100%|██████████| 1/1 [00:38<00:00, 38.63s/it]
INFO:root:eval mean loss: 3570.7652025155144
INFO:root:eval perplexity: 4.237241744995117
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.62s/it][A100%|██████████| 1/1 [00:37<00:00, 37.62s/it]
INFO:root:eval mean loss: 4548.982382050643
INFO:root:eval perplexity: 6.424644947052002
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/78
 39%|███▉      | 78/200 [12:48:14<20:11:07, 595.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3193.074165675951
INFO:root:current train perplexity3.52773118019104
INFO:root:current mean train loss 3163.6000003969766
INFO:root:current train perplexity3.4969921112060547
INFO:root:current mean train loss 3172.8179313078053
INFO:root:current train perplexity3.506110906600952
INFO:root:current mean train loss 3164.337310129644
INFO:root:current train perplexity3.4999964237213135
INFO:root:current mean train loss 3172.8183945820406
INFO:root:current train perplexity3.5014402866363525
INFO:root:current mean train loss 3168.8543031302283
INFO:root:current train perplexity3.4992823600769043
INFO:root:current mean train loss 3178.8278675354886
INFO:root:current train perplexity3.5056467056274414
INFO:root:current mean train loss 3180.684939731371
INFO:root:current train perplexity3.505725145339966
INFO:root:current mean train loss 3183.677291777415
INFO:root:current train perplexity3.509169578552246
INFO:root:current mean train loss 3185.9700392106242
INFO:root:current train perplexity3.510586738586426

100%|██████████| 1/1 [08:37<00:00, 517.42s/it][A100%|██████████| 1/1 [08:37<00:00, 517.42s/it]
INFO:root:final mean train loss: 3183.1157215487574
INFO:root:final train perplexity: 3.510755777359009
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.93s/it][A100%|██████████| 1/1 [00:38<00:00, 38.95s/it]
INFO:root:eval mean loss: 3577.2740140874334
INFO:root:eval perplexity: 4.248409271240234
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.11s/it][A100%|██████████| 1/1 [00:38<00:00, 38.11s/it]
INFO:root:eval mean loss: 4554.328571725399
INFO:root:eval perplexity: 6.438704967498779
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/79
 40%|███▉      | 79/200 [12:58:10<20:01:24, 595.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3175.0284541960687
INFO:root:current train perplexity3.472329616546631
INFO:root:current mean train loss 3183.0808776389554
INFO:root:current train perplexity3.492737054824829
INFO:root:current mean train loss 3172.2821420116343
INFO:root:current train perplexity3.4905943870544434
INFO:root:current mean train loss 3177.581686797819
INFO:root:current train perplexity3.4951303005218506
INFO:root:current mean train loss 3174.866073856221
INFO:root:current train perplexity3.49765944480896
INFO:root:current mean train loss 3180.6703471670494
INFO:root:current train perplexity3.503858804702759
INFO:root:current mean train loss 3175.200039387505
INFO:root:current train perplexity3.4997994899749756
INFO:root:current mean train loss 3174.4146546495595
INFO:root:current train perplexity3.49826717376709
INFO:root:current mean train loss 3176.9082107635754
INFO:root:current train perplexity3.499882459640503
INFO:root:current mean train loss 3178.680989495922
INFO:root:current train perplexity3.501084804534912

100%|██████████| 1/1 [08:37<00:00, 517.35s/it][A100%|██████████| 1/1 [08:37<00:00, 517.35s/it]
INFO:root:final mean train loss: 3176.616668393535
INFO:root:final train perplexity: 3.501765251159668
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.13s/it][A100%|██████████| 1/1 [00:38<00:00, 38.16s/it]
INFO:root:eval mean loss: 3583.510245248781
INFO:root:eval perplexity: 4.259136199951172
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.50s/it][A100%|██████████| 1/1 [00:37<00:00, 37.50s/it]
INFO:root:eval mean loss: 4566.286189951795
INFO:root:eval perplexity: 6.470265865325928
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/80
 40%|████      | 80/200 [13:08:05<19:50:42, 595.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3150.5215594951924
INFO:root:current train perplexity3.451209306716919
INFO:root:current mean train loss 3143.1196815984713
INFO:root:current train perplexity3.451625347137451
INFO:root:current mean train loss 3151.5519478131537
INFO:root:current train perplexity3.4636178016662598
INFO:root:current mean train loss 3163.481662806508
INFO:root:current train perplexity3.472843647003174
INFO:root:current mean train loss 3157.153441548619
INFO:root:current train perplexity3.4722678661346436
INFO:root:current mean train loss 3161.1884181318123
INFO:root:current train perplexity3.477022171020508
INFO:root:current mean train loss 3164.9369387440092
INFO:root:current train perplexity3.480313301086426
INFO:root:current mean train loss 3167.0567608782985
INFO:root:current train perplexity3.4823696613311768
INFO:root:current mean train loss 3170.805105070676
INFO:root:current train perplexity3.4881558418273926
INFO:root:current mean train loss 3168.6162392775727
INFO:root:current train perplexity3.4884257316589355

100%|██████████| 1/1 [08:36<00:00, 516.57s/it][A100%|██████████| 1/1 [08:36<00:00, 516.57s/it]
INFO:root:final mean train loss: 3168.3733418987645
INFO:root:final train perplexity: 3.4903950691223145
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.20s/it][A100%|██████████| 1/1 [00:38<00:00, 38.21s/it]
INFO:root:eval mean loss: 3597.3269320007757
INFO:root:eval perplexity: 4.282998085021973
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.34s/it][A100%|██████████| 1/1 [00:37<00:00, 37.34s/it]
INFO:root:eval mean loss: 4580.829345703125
INFO:root:eval perplexity: 6.508856773376465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/81
 40%|████      | 81/200 [13:17:58<19:39:45, 594.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3182.6055414727393
INFO:root:current train perplexity3.519009828567505
INFO:root:current mean train loss 3167.7540025775934
INFO:root:current train perplexity3.4897797107696533
INFO:root:current mean train loss 3162.909755938449
INFO:root:current train perplexity3.473679304122925
INFO:root:current mean train loss 3170.083999150081
INFO:root:current train perplexity3.481046438217163
INFO:root:current mean train loss 3165.6502699201274
INFO:root:current train perplexity3.4770455360412598
INFO:root:current mean train loss 3167.2507342071813
INFO:root:current train perplexity3.4795358180999756
INFO:root:current mean train loss 3169.5244457592735
INFO:root:current train perplexity3.4840729236602783
INFO:root:current mean train loss 3163.0310388690177
INFO:root:current train perplexity3.479340076446533
INFO:root:current mean train loss 3162.5734237797005
INFO:root:current train perplexity3.4797892570495605
INFO:root:current mean train loss 3163.3421255754192
INFO:root:current train perplexity3.481043577194214

100%|██████████| 1/1 [08:38<00:00, 518.51s/it][A100%|██████████| 1/1 [08:38<00:00, 518.51s/it]
INFO:root:final mean train loss: 3162.334537259994
INFO:root:final train perplexity: 3.4820892810821533
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.39s/it][A100%|██████████| 1/1 [00:38<00:00, 38.39s/it]
INFO:root:eval mean loss: 3568.836197224069
INFO:root:eval perplexity: 4.233938694000244
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.42s/it][A100%|██████████| 1/1 [00:37<00:00, 37.42s/it]
INFO:root:eval mean loss: 4551.654388644171
INFO:root:eval perplexity: 6.431668281555176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/82
 41%|████      | 82/200 [13:27:54<19:30:24, 595.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3177.730029296875
INFO:root:current train perplexity3.484710931777954
INFO:root:current mean train loss 3167.4158014112904
INFO:root:current train perplexity3.4895386695861816
INFO:root:current mean train loss 3171.934962852328
INFO:root:current train perplexity3.4873576164245605
INFO:root:current mean train loss 3172.678864986796
INFO:root:current train perplexity3.494828224182129
INFO:root:current mean train loss 3169.0950050437846
INFO:root:current train perplexity3.488062858581543
INFO:root:current mean train loss 3170.9413987718185
INFO:root:current train perplexity3.4891719818115234
INFO:root:current mean train loss 3166.43040165792
INFO:root:current train perplexity3.484941005706787
INFO:root:current mean train loss 3161.297725126759
INFO:root:current train perplexity3.477494478225708
INFO:root:current mean train loss 3161.455096114309
INFO:root:current train perplexity3.477966547012329
INFO:root:current mean train loss 3162.6864602932756
INFO:root:current train perplexity3.4792330265045166

100%|██████████| 1/1 [08:37<00:00, 517.63s/it][A100%|██████████| 1/1 [08:37<00:00, 517.63s/it]
INFO:root:final mean train loss: 3159.5081584069035
INFO:root:final train perplexity: 3.478208303451538
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.37s/it][A100%|██████████| 1/1 [00:38<00:00, 38.39s/it]
INFO:root:eval mean loss: 3571.43785149324
INFO:root:eval perplexity: 4.2383952140808105
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.09s/it][A100%|██████████| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 4558.15120269559
INFO:root:eval perplexity: 6.44877815246582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/83
 42%|████▏     | 83/200 [13:37:49<19:20:12, 594.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3126.789275638641
INFO:root:current train perplexity3.4344236850738525
INFO:root:current mean train loss 3143.5864737106976
INFO:root:current train perplexity3.450268507003784
INFO:root:current mean train loss 3143.3974674355395
INFO:root:current train perplexity3.4514644145965576
INFO:root:current mean train loss 3135.007445280217
INFO:root:current train perplexity3.44987416267395
INFO:root:current mean train loss 3136.914492250776
INFO:root:current train perplexity3.452939748764038
INFO:root:current mean train loss 3144.5851088095305
INFO:root:current train perplexity3.4574875831604004
INFO:root:current mean train loss 3144.581849341299
INFO:root:current train perplexity3.458728790283203
INFO:root:current mean train loss 3148.332898701159
INFO:root:current train perplexity3.4618749618530273
INFO:root:current mean train loss 3146.7107145766945
INFO:root:current train perplexity3.4612114429473877
INFO:root:current mean train loss 3150.870907158619
INFO:root:current train perplexity3.463864326477051

100%|██████████| 1/1 [08:35<00:00, 515.64s/it][A100%|██████████| 1/1 [08:35<00:00, 515.64s/it]
INFO:root:final mean train loss: 3150.2474172038415
INFO:root:final train perplexity: 3.4655237197875977
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.18s/it][A100%|██████████| 1/1 [00:38<00:00, 38.18s/it]
INFO:root:eval mean loss: 3588.671705313608
INFO:root:eval perplexity: 4.2680344581604
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.38s/it][A100%|██████████| 1/1 [00:37<00:00, 37.38s/it]
INFO:root:eval mean loss: 4575.489642204122
INFO:root:eval perplexity: 6.494661331176758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/84
 42%|████▏     | 84/200 [13:47:41<19:09:00, 594.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3135.1494484485033
INFO:root:current train perplexity3.4453554153442383
INFO:root:current mean train loss 3139.4903214661003
INFO:root:current train perplexity3.4491348266601562
INFO:root:current mean train loss 3134.3722874264877
INFO:root:current train perplexity3.437547445297241
INFO:root:current mean train loss 3147.4386470002946
INFO:root:current train perplexity3.4503607749938965
INFO:root:current mean train loss 3140.8441563826964
INFO:root:current train perplexity3.444188356399536
INFO:root:current mean train loss 3144.5511592190237
INFO:root:current train perplexity3.447094678878784
INFO:root:current mean train loss 3142.7445051986306
INFO:root:current train perplexity3.4461846351623535
INFO:root:current mean train loss 3142.256347022941
INFO:root:current train perplexity3.4481966495513916
INFO:root:current mean train loss 3144.050363604155
INFO:root:current train perplexity3.453110694885254
INFO:root:current mean train loss 3146.9139915961314
INFO:root:current train perplexity3.4572625160217285

100%|██████████| 1/1 [08:38<00:00, 518.22s/it][A100%|██████████| 1/1 [08:38<00:00, 518.22s/it]
INFO:root:final mean train loss: 3144.7195297364265
INFO:root:final train perplexity: 3.457974433898926
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.51s/it][A100%|██████████| 1/1 [00:38<00:00, 38.51s/it]
INFO:root:eval mean loss: 3575.445504695811
INFO:root:eval perplexity: 4.24526834487915
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.46s/it][A100%|██████████| 1/1 [00:37<00:00, 37.46s/it]
INFO:root:eval mean loss: 4564.983007119902
INFO:root:eval perplexity: 6.466818332672119
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/85
 42%|████▎     | 85/200 [13:57:37<18:59:53, 594.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3103.3613157634495
INFO:root:current train perplexity3.417447328567505
INFO:root:current mean train loss 3135.6834382637917
INFO:root:current train perplexity3.444978713989258
INFO:root:current mean train loss 3148.07866578461
INFO:root:current train perplexity3.4587368965148926
INFO:root:current mean train loss 3150.815778827919
INFO:root:current train perplexity3.456256628036499
INFO:root:current mean train loss 3152.068029097077
INFO:root:current train perplexity3.4559946060180664
INFO:root:current mean train loss 3145.5803998509014
INFO:root:current train perplexity3.452085494995117
INFO:root:current mean train loss 3145.873012716886
INFO:root:current train perplexity3.4518182277679443
INFO:root:current mean train loss 3148.2479174397263
INFO:root:current train perplexity3.454540491104126
INFO:root:current mean train loss 3144.361462277357
INFO:root:current train perplexity3.4524154663085938
INFO:root:current mean train loss 3142.99154635031
INFO:root:current train perplexity3.4532439708709717

100%|██████████| 1/1 [08:36<00:00, 516.23s/it][A100%|██████████| 1/1 [08:36<00:00, 516.23s/it]
INFO:root:final mean train loss: 3140.974655951223
INFO:root:final train perplexity: 3.452868700027466
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.86s/it][A100%|██████████| 1/1 [00:37<00:00, 37.86s/it]
INFO:root:eval mean loss: 3572.4331608765515
INFO:root:eval perplexity: 4.240100860595703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.00s/it][A100%|██████████| 1/1 [00:37<00:00, 37.01s/it]
INFO:root:eval mean loss: 4555.955729166667
INFO:root:eval perplexity: 6.442991256713867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/86
 43%|████▎     | 86/200 [14:07:30<18:48:46, 594.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3123.942343525503
INFO:root:current train perplexity3.435779571533203
INFO:root:current mean train loss 3122.4818069539606
INFO:root:current train perplexity3.434476137161255
INFO:root:current mean train loss 3116.7379307763504
INFO:root:current train perplexity3.430006504058838
INFO:root:current mean train loss 3121.3316167787066
INFO:root:current train perplexity3.4305202960968018
INFO:root:current mean train loss 3121.2675851434165
INFO:root:current train perplexity3.4304285049438477
INFO:root:current mean train loss 3125.2802006528163
INFO:root:current train perplexity3.431692361831665
INFO:root:current mean train loss 3129.024702269264
INFO:root:current train perplexity3.4352869987487793
INFO:root:current mean train loss 3129.704027110467
INFO:root:current train perplexity3.4332690238952637
INFO:root:current mean train loss 3128.6566532311335
INFO:root:current train perplexity3.4339046478271484
INFO:root:current mean train loss 3133.3437893296446
INFO:root:current train perplexity3.438934326171875

100%|██████████| 1/1 [08:36<00:00, 516.57s/it][A100%|██████████| 1/1 [08:36<00:00, 516.57s/it]
INFO:root:final mean train loss: 3130.6371944181383
INFO:root:final train perplexity: 3.438815116882324
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.84s/it][A100%|██████████| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 3608.0616879294103
INFO:root:eval perplexity: 4.301630973815918
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.58s/it][A100%|██████████| 1/1 [00:37<00:00, 37.58s/it]
INFO:root:eval mean loss: 4599.70275965481
INFO:root:eval perplexity: 6.559286117553711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/87
 44%|████▎     | 87/200 [14:17:23<18:38:33, 593.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3136.8005859375
INFO:root:current train perplexity3.4280247688293457
INFO:root:current mean train loss 3128.8586926582534
INFO:root:current train perplexity3.4204459190368652
INFO:root:current mean train loss 3127.24284626589
INFO:root:current train perplexity3.4226598739624023
INFO:root:current mean train loss 3129.967688760878
INFO:root:current train perplexity3.4272730350494385
INFO:root:current mean train loss 3127.4278596511995
INFO:root:current train perplexity3.4300453662872314
INFO:root:current mean train loss 3128.9213341977415
INFO:root:current train perplexity3.4324288368225098
INFO:root:current mean train loss 3131.3472399814523
INFO:root:current train perplexity3.435784101486206
INFO:root:current mean train loss 3131.5288875171973
INFO:root:current train perplexity3.4357259273529053
INFO:root:current mean train loss 3134.2077977697277
INFO:root:current train perplexity3.4380195140838623

100%|██████████| 1/1 [08:35<00:00, 515.08s/it][A100%|██████████| 1/1 [08:35<00:00, 515.10s/it]
INFO:root:final mean train loss: 3129.398710620019
INFO:root:final train perplexity: 3.4371352195739746
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.00s/it][A100%|██████████| 1/1 [00:38<00:00, 38.00s/it]
INFO:root:eval mean loss: 3576.265884724069
INFO:root:eval perplexity: 4.246677875518799
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.32s/it][A100%|██████████| 1/1 [00:37<00:00, 37.34s/it]
INFO:root:eval mean loss: 4563.43047706117
INFO:root:eval perplexity: 6.462715148925781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/88
 44%|████▍     | 88/200 [14:27:15<18:27:31, 593.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2969.66455078125
INFO:root:current train perplexity3.255389451980591
INFO:root:current mean train loss 3100.2295893696905
INFO:root:current train perplexity3.3988397121429443
INFO:root:current mean train loss 3102.344745805111
INFO:root:current train perplexity3.403808355331421
INFO:root:current mean train loss 3120.890230185128
INFO:root:current train perplexity3.424905776977539
INFO:root:current mean train loss 3123.4051522758996
INFO:root:current train perplexity3.4257547855377197
INFO:root:current mean train loss 3128.2044830625623
INFO:root:current train perplexity3.4310715198516846
INFO:root:current mean train loss 3128.7983479412833
INFO:root:current train perplexity3.4317803382873535
INFO:root:current mean train loss 3128.6265624305433
INFO:root:current train perplexity3.429464101791382
INFO:root:current mean train loss 3127.2159990854607
INFO:root:current train perplexity3.430938959121704
INFO:root:current mean train loss 3124.971641295508
INFO:root:current train perplexity3.427872896194458

100%|██████████| 1/1 [08:37<00:00, 517.12s/it][A100%|██████████| 1/1 [08:37<00:00, 517.14s/it]
INFO:root:final mean train loss: 3122.328001022339
INFO:root:final train perplexity: 3.427560567855835
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.03s/it][A100%|██████████| 1/1 [00:38<00:00, 38.05s/it]
INFO:root:eval mean loss: 3586.8151457225176
INFO:root:eval perplexity: 4.26483154296875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.09s/it][A100%|██████████| 1/1 [00:38<00:00, 38.09s/it]
INFO:root:eval mean loss: 4578.346918633643
INFO:root:eval perplexity: 6.502254009246826
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/89
 44%|████▍     | 89/200 [14:37:10<18:18:26, 593.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3147.789373224432
INFO:root:current train perplexity3.4167470932006836
INFO:root:current mean train loss 3088.0954413886543
INFO:root:current train perplexity3.3662984371185303
INFO:root:current mean train loss 3099.9168336696534
INFO:root:current train perplexity3.3958349227905273
INFO:root:current mean train loss 3115.950965415243
INFO:root:current train perplexity3.4104013442993164
INFO:root:current mean train loss 3119.2928107417124
INFO:root:current train perplexity3.42374849319458
INFO:root:current mean train loss 3122.3833772244984
INFO:root:current train perplexity3.425321102142334
INFO:root:current mean train loss 3121.871011437449
INFO:root:current train perplexity3.4220707416534424
INFO:root:current mean train loss 3119.4753321823355
INFO:root:current train perplexity3.4196295738220215
INFO:root:current mean train loss 3118.51045078414
INFO:root:current train perplexity3.419872522354126
INFO:root:current mean train loss 3117.8688533376785
INFO:root:current train perplexity3.418205976486206

100%|██████████| 1/1 [08:37<00:00, 517.33s/it][A100%|██████████| 1/1 [08:37<00:00, 517.33s/it]
INFO:root:final mean train loss: 3115.8517094888994
INFO:root:final train perplexity: 3.418813943862915
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.96s/it][A100%|██████████| 1/1 [00:37<00:00, 37.96s/it]
INFO:root:eval mean loss: 3578.0039858987147
INFO:root:eval perplexity: 4.249663352966309
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.67s/it][A100%|██████████| 1/1 [00:37<00:00, 37.67s/it]
INFO:root:eval mean loss: 4573.358815727504
INFO:root:eval perplexity: 6.489005088806152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/90
 45%|████▌     | 90/200 [14:47:04<18:08:54, 593.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3031.7790655838817
INFO:root:current train perplexity3.3552281856536865
INFO:root:current mean train loss 3102.32745207458
INFO:root:current train perplexity3.413148880004883
INFO:root:current mean train loss 3112.0353602579194
INFO:root:current train perplexity3.414957046508789
INFO:root:current mean train loss 3112.2540248763225
INFO:root:current train perplexity3.408306360244751
INFO:root:current mean train loss 3111.335057078796
INFO:root:current train perplexity3.408406972885132
INFO:root:current mean train loss 3110.559205747983
INFO:root:current train perplexity3.407078742980957
INFO:root:current mean train loss 3115.3151863356975
INFO:root:current train perplexity3.41564679145813
INFO:root:current mean train loss 3117.3409561348226
INFO:root:current train perplexity3.4181559085845947
INFO:root:current mean train loss 3118.600816663805
INFO:root:current train perplexity3.4175479412078857
INFO:root:current mean train loss 3115.6359042394924
INFO:root:current train perplexity3.4145710468292236

100%|██████████| 1/1 [08:37<00:00, 517.40s/it][A100%|██████████| 1/1 [08:37<00:00, 517.40s/it]
INFO:root:final mean train loss: 3112.2932762022942
INFO:root:final train perplexity: 3.414017677307129
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.50s/it][A100%|██████████| 1/1 [00:38<00:00, 38.53s/it]
INFO:root:eval mean loss: 3590.214339885306
INFO:root:eval perplexity: 4.270697593688965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.40s/it][A100%|██████████| 1/1 [00:37<00:00, 37.42s/it]
INFO:root:eval mean loss: 4589.53430781804
INFO:root:eval perplexity: 6.532067775726318
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/91
 46%|████▌     | 91/200 [14:56:59<17:59:30, 594.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3028.8889069733796
INFO:root:current train perplexity3.3273282051086426
INFO:root:current mean train loss 3082.1241695374015
INFO:root:current train perplexity3.3793046474456787
INFO:root:current mean train loss 3085.047224540542
INFO:root:current train perplexity3.3809192180633545
INFO:root:current mean train loss 3095.0355310469226
INFO:root:current train perplexity3.3913190364837646
INFO:root:current mean train loss 3099.1585061566893
INFO:root:current train perplexity3.3982737064361572
INFO:root:current mean train loss 3107.144233370642
INFO:root:current train perplexity3.405546188354492
INFO:root:current mean train loss 3110.4427313066935
INFO:root:current train perplexity3.409457206726074
INFO:root:current mean train loss 3125.3132435039115
INFO:root:current train perplexity3.4275548458099365
INFO:root:current mean train loss 3732.3863863408783
INFO:root:current train perplexity4.354948997497559
INFO:root:current mean train loss 4902.610726069478
INFO:root:current train perplexity6.91163969039917

100%|██████████| 1/1 [08:35<00:00, 515.54s/it][A100%|██████████| 1/1 [08:35<00:00, 515.54s/it]
INFO:root:final mean train loss: 5725.19704855642
INFO:root:final train perplexity: 9.571176528930664
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.49s/it][A100%|██████████| 1/1 [00:38<00:00, 38.49s/it]
INFO:root:eval mean loss: 18167.355517231827
INFO:root:eval perplexity: 1550.5189208984375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.36s/it][A100%|██████████| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 18322.185269835994
INFO:root:eval perplexity: 1793.9832763671875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/92
 46%|████▌     | 92/200 [15:06:52<17:48:53, 593.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17412.81939174107
INFO:root:current train perplexity1004.3760375976562
INFO:root:current mean train loss 17178.951475694445
INFO:root:current train perplexity898.3973388671875
INFO:root:current mean train loss 16940.437479222073
INFO:root:current train perplexity806.284912109375
INFO:root:current mean train loss 16412.301568330226
INFO:root:current train perplexity655.3206176757812
INFO:root:current mean train loss 15538.270767106682
INFO:root:current train perplexity459.4059753417969
INFO:root:current mean train loss 13777.707882775992
INFO:root:current train perplexity228.0845947265625
INFO:root:current mean train loss 12498.743949157235
INFO:root:current train perplexity137.72772216796875
INFO:root:current mean train loss 11443.906537654124
INFO:root:current train perplexity90.87828063964844
INFO:root:current mean train loss 10612.958181196202
INFO:root:current train perplexity65.64505767822266
INFO:root:current mean train loss 9955.749746720421
INFO:root:current train perplexity50.613067626953125

100%|██████████| 1/1 [08:39<00:00, 519.10s/it][A100%|██████████| 1/1 [08:39<00:00, 519.10s/it]
INFO:root:final mean train loss: 9663.357556866062
INFO:root:final train perplexity: 45.262290954589844
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.53s/it][A100%|██████████| 1/1 [00:38<00:00, 38.54s/it]
INFO:root:eval mean loss: 4496.889078776042
INFO:root:eval perplexity: 6.162052631378174
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.49s/it][A100%|██████████| 1/1 [00:37<00:00, 37.51s/it]
INFO:root:eval mean loss: 5416.65254460328
INFO:root:eval perplexity: 9.160892486572266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/93
 46%|████▋     | 93/200 [15:16:49<17:40:31, 594.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4472.151599972747
INFO:root:current train perplexity5.843680381774902
INFO:root:current mean train loss 4469.518249084899
INFO:root:current train perplexity5.802548885345459
INFO:root:current mean train loss 4465.597558794689
INFO:root:current train perplexity5.810842990875244
INFO:root:current mean train loss 4488.789740826576
INFO:root:current train perplexity5.859106540679932
INFO:root:current mean train loss 4484.574950620768
INFO:root:current train perplexity5.857319355010986
INFO:root:current mean train loss 4478.786249262633
INFO:root:current train perplexity5.8417887687683105
INFO:root:current mean train loss 4462.753125987194
INFO:root:current train perplexity5.806836128234863
INFO:root:current mean train loss 4444.524819868249
INFO:root:current train perplexity5.7678446769714355
INFO:root:current mean train loss 4429.988871184108
INFO:root:current train perplexity5.732194423675537
INFO:root:current mean train loss 4411.202212385257
INFO:root:current train perplexity5.690107822418213

100%|██████████| 1/1 [08:36<00:00, 516.20s/it][A100%|██████████| 1/1 [08:36<00:00, 516.20s/it]
INFO:root:final mean train loss: 4398.547540110926
INFO:root:final train perplexity: 5.670936107635498
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.39s/it][A100%|██████████| 1/1 [00:38<00:00, 38.39s/it]
INFO:root:eval mean loss: 4286.107132715536
INFO:root:eval perplexity: 5.658596992492676
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.29s/it][A100%|██████████| 1/1 [00:37<00:00, 37.29s/it]
INFO:root:eval mean loss: 5227.043015500332
INFO:root:eval perplexity: 8.477447509765625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/94
 47%|████▋     | 94/200 [15:26:42<17:29:53, 594.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4191.939170687806
INFO:root:current train perplexity5.246431827545166
INFO:root:current mean train loss 4193.483461493688
INFO:root:current train perplexity5.252213478088379
INFO:root:current mean train loss 4191.543137022223
INFO:root:current train perplexity5.24795389175415
INFO:root:current mean train loss 4195.508087245148
INFO:root:current train perplexity5.2533793449401855
INFO:root:current mean train loss 4208.715555059936
INFO:root:current train perplexity5.263630390167236
INFO:root:current mean train loss 4208.651193940705
INFO:root:current train perplexity5.258378982543945
INFO:root:current mean train loss 4207.466118831605
INFO:root:current train perplexity5.253632068634033
INFO:root:current mean train loss 4203.430391314185
INFO:root:current train perplexity5.239830017089844
INFO:root:current mean train loss 4198.3230806702595
INFO:root:current train perplexity5.234565734863281
INFO:root:current mean train loss 4197.507700826844
INFO:root:current train perplexity5.231359958648682

100%|██████████| 1/1 [08:38<00:00, 518.55s/it][A100%|██████████| 1/1 [08:38<00:00, 518.55s/it]
INFO:root:final mean train loss: 4193.848907655285
INFO:root:final train perplexity: 5.230959415435791
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.53s/it][A100%|██████████| 1/1 [00:38<00:00, 38.54s/it]
INFO:root:eval mean loss: 4269.163508421986
INFO:root:eval perplexity: 5.619959354400635
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.53s/it][A100%|██████████| 1/1 [00:37<00:00, 37.56s/it]
INFO:root:eval mean loss: 5201.829846104832
INFO:root:eval perplexity: 8.390497207641602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/95
 48%|████▊     | 95/200 [15:36:38<17:20:59, 594.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4221.912552138507
INFO:root:current train perplexity5.334177494049072
INFO:root:current mean train loss 4244.010109571541
INFO:root:current train perplexity5.333633899688721
INFO:root:current mean train loss 4228.796953238116
INFO:root:current train perplexity5.284186363220215
INFO:root:current mean train loss 4241.605010391278
INFO:root:current train perplexity5.320823669433594
INFO:root:current mean train loss 4237.855981498502
INFO:root:current train perplexity5.311718463897705
INFO:root:current mean train loss 4233.218529443621
INFO:root:current train perplexity5.300784111022949
INFO:root:current mean train loss 4232.9920600578525
INFO:root:current train perplexity5.3034749031066895
INFO:root:current mean train loss 4245.719236672945
INFO:root:current train perplexity5.32842493057251
INFO:root:current mean train loss 4251.467239113431
INFO:root:current train perplexity5.345607757568359
INFO:root:current mean train loss 4256.602989411578
INFO:root:current train perplexity5.354824542999268

100%|██████████| 1/1 [08:37<00:00, 517.46s/it][A100%|██████████| 1/1 [08:37<00:00, 517.46s/it]
INFO:root:final mean train loss: 4255.618751710461
INFO:root:final train perplexity: 5.360003471374512
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.45s/it][A100%|██████████| 1/1 [00:38<00:00, 38.45s/it]
INFO:root:eval mean loss: 4356.504853377105
INFO:root:eval perplexity: 5.821993350982666
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.34s/it][A100%|██████████| 1/1 [00:37<00:00, 37.34s/it]
INFO:root:eval mean loss: 5284.328758726729
INFO:root:eval perplexity: 8.678377151489258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/96
 48%|████▊     | 96/200 [15:46:33<17:11:01, 594.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4291.5846512068565
INFO:root:current train perplexity5.410923004150391
INFO:root:current mean train loss 4320.555531027788
INFO:root:current train perplexity5.472128868103027
INFO:root:current mean train loss 4337.451557745201
INFO:root:current train perplexity5.5136823654174805
INFO:root:current mean train loss 4351.682156180816
INFO:root:current train perplexity5.535799503326416
INFO:root:current mean train loss 4361.827654493442
INFO:root:current train perplexity5.569340229034424
INFO:root:current mean train loss 4369.370683404293
INFO:root:current train perplexity5.588981628417969
INFO:root:current mean train loss 4373.537683672812
INFO:root:current train perplexity5.609192371368408
INFO:root:current mean train loss 4371.570735846846
INFO:root:current train perplexity5.604320526123047
INFO:root:current mean train loss 4374.022468822088
INFO:root:current train perplexity5.603964328765869
INFO:root:current mean train loss 4371.76660383475
INFO:root:current train perplexity5.6042256355285645

100%|██████████| 1/1 [08:37<00:00, 517.15s/it][A100%|██████████| 1/1 [08:37<00:00, 517.15s/it]
INFO:root:final mean train loss: 4367.5679787051295
INFO:root:final train perplexity: 5.602046489715576
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.61s/it][A100%|██████████| 1/1 [00:38<00:00, 38.62s/it]
INFO:root:eval mean loss: 4345.627006801307
INFO:root:eval perplexity: 5.7964396476745605
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.18s/it][A100%|██████████| 1/1 [00:37<00:00, 37.23s/it]
INFO:root:eval mean loss: 5275.985109153369
INFO:root:eval perplexity: 8.648820877075195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/97
 48%|████▊     | 97/200 [15:56:28<17:00:57, 594.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4334.8683463541665
INFO:root:current train perplexity5.463806629180908
INFO:root:current mean train loss 4324.251044921875
INFO:root:current train perplexity5.502253532409668
INFO:root:current mean train loss 4319.719924538353
INFO:root:current train perplexity5.491363048553467
INFO:root:current mean train loss 4323.5503359375
INFO:root:current train perplexity5.508216381072998
INFO:root:current mean train loss 4332.811821546053
INFO:root:current train perplexity5.5170392990112305
INFO:root:current mean train loss 4337.722087720788
INFO:root:current train perplexity5.528992652893066
INFO:root:current mean train loss 4338.294441189236
INFO:root:current train perplexity5.523813247680664
INFO:root:current mean train loss 4331.9603125
INFO:root:current train perplexity5.521297454833984
INFO:root:current mean train loss 4333.383966238839
INFO:root:current train perplexity5.5223388671875
INFO:root:current mean train loss 4339.634449619391
INFO:root:current train perplexity5.531191349029541

100%|██████████| 1/1 [08:36<00:00, 517.00s/it][A100%|██████████| 1/1 [08:36<00:00, 517.00s/it]
INFO:root:final mean train loss: 4337.221810371645
INFO:root:final train perplexity: 5.535376071929932
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.17s/it][A100%|██████████| 1/1 [00:38<00:00, 38.19s/it]
INFO:root:eval mean loss: 4384.943987907247
INFO:root:eval perplexity: 5.8893327713012695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.39s/it][A100%|██████████| 1/1 [00:37<00:00, 37.44s/it]
INFO:root:eval mean loss: 5316.7358883255765
INFO:root:eval perplexity: 8.794148445129395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/98
 49%|████▉     | 98/200 [16:06:22<16:50:45, 594.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4428.279755741717
INFO:root:current train perplexity5.712217807769775
INFO:root:current mean train loss 5236.1657141179985
INFO:root:current train perplexity7.843313694000244
INFO:root:current mean train loss 5319.905511539311
INFO:root:current train perplexity8.157225608825684
INFO:root:current mean train loss 5398.494326758322
INFO:root:current train perplexity8.42216968536377
INFO:root:current mean train loss 5411.352952534615
INFO:root:current train perplexity8.4595365524292
INFO:root:current mean train loss 5394.808368453849
INFO:root:current train perplexity8.395151138305664
INFO:root:current mean train loss 5427.786581058977
INFO:root:current train perplexity8.513614654541016
INFO:root:current mean train loss 5426.984162351333
INFO:root:current train perplexity8.510485649108887
INFO:root:current mean train loss 5444.845272906639
INFO:root:current train perplexity8.56187629699707
INFO:root:current mean train loss 5462.286258980798
INFO:root:current train perplexity8.613545417785645

100%|██████████| 1/1 [08:38<00:00, 518.40s/it][A100%|██████████| 1/1 [08:38<00:00, 518.40s/it]
INFO:root:final mean train loss: 5455.23024792825
INFO:root:final train perplexity: 8.604164123535156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.97s/it][A100%|██████████| 1/1 [00:37<00:00, 37.99s/it]
INFO:root:eval mean loss: 5020.049953595966
INFO:root:eval perplexity: 7.613788604736328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.73s/it][A100%|██████████| 1/1 [00:37<00:00, 37.73s/it]
INFO:root:eval mean loss: 5840.072663868573
INFO:root:eval perplexity: 10.892626762390137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/99
 50%|████▉     | 99/200 [16:16:17<16:41:24, 594.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5748.590240813874
INFO:root:current train perplexity9.750164031982422
INFO:root:current mean train loss 5591.117757587533
INFO:root:current train perplexity9.036056518554688
INFO:root:current mean train loss 5439.2844934627365
INFO:root:current train perplexity8.538984298706055
INFO:root:current mean train loss 5256.10135644781
INFO:root:current train perplexity7.962109088897705
INFO:root:current mean train loss 5172.549748003119
INFO:root:current train perplexity7.67744779586792
INFO:root:current mean train loss 5100.363920724936
INFO:root:current train perplexity7.4586405754089355
INFO:root:current mean train loss 5048.550121964318
INFO:root:current train perplexity7.3055267333984375
INFO:root:current mean train loss 5012.63642429974
INFO:root:current train perplexity7.210014820098877
INFO:root:current mean train loss 4965.959308251789
INFO:root:current train perplexity7.076470851898193
INFO:root:current mean train loss 4940.601283130203
INFO:root:current train perplexity7.011984348297119

100%|██████████| 1/1 [08:37<00:00, 517.73s/it][A100%|██████████| 1/1 [08:37<00:00, 517.73s/it]
INFO:root:final mean train loss: 4936.5005695589125
INFO:root:final train perplexity: 7.011786460876465
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.04s/it][A100%|██████████| 1/1 [00:39<00:00, 39.05s/it]
INFO:root:eval mean loss: 4598.397595994016
INFO:root:eval perplexity: 6.420249938964844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.21s/it][A100%|██████████| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 5497.128674229832
INFO:root:eval perplexity: 9.46737003326416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/100
 50%|█████     | 100/200 [16:26:13<16:31:46, 595.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4830.726389875315
INFO:root:current train perplexity6.699057102203369
INFO:root:current mean train loss 4901.23824935223
INFO:root:current train perplexity6.903321266174316
INFO:root:current mean train loss 4954.942123157923
INFO:root:current train perplexity7.0474419593811035
INFO:root:current mean train loss 4993.475162515664
INFO:root:current train perplexity7.16408634185791
INFO:root:current mean train loss 5027.856473689567
INFO:root:current train perplexity7.269443035125732
INFO:root:current mean train loss 5040.582028804518
INFO:root:current train perplexity7.300697326660156
INFO:root:current mean train loss 5049.766888663493
INFO:root:current train perplexity7.334444999694824
INFO:root:current mean train loss 5070.040295730992
INFO:root:current train perplexity7.378579616546631
INFO:root:current mean train loss 5092.781743712632
INFO:root:current train perplexity7.442880630493164

100%|██████████| 1/1 [08:37<00:00, 517.67s/it][A100%|██████████| 1/1 [08:37<00:00, 517.71s/it]
INFO:root:final mean train loss: 5101.444215836063
INFO:root:final train perplexity: 7.483250141143799
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.95s/it][A100%|██████████| 1/1 [00:37<00:00, 37.95s/it]
INFO:root:eval mean loss: 5050.329416694371
INFO:root:eval perplexity: 7.707586288452148
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.50s/it][A100%|██████████| 1/1 [00:37<00:00, 37.54s/it]
INFO:root:eval mean loss: 5922.604177055629
INFO:root:eval perplexity: 11.266508102416992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/101
 50%|█████     | 101/200 [16:36:08<16:21:41, 594.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5239.20458984375
INFO:root:current train perplexity8.060505867004395
INFO:root:current mean train loss 5382.150582286799
INFO:root:current train perplexity8.255882263183594
INFO:root:current mean train loss 5300.342148343146
INFO:root:current train perplexity8.085820198059082
INFO:root:current mean train loss 5203.30059039088
INFO:root:current train perplexity7.775899887084961
INFO:root:current mean train loss 5107.539168074324
INFO:root:current train perplexity7.504214286804199
INFO:root:current mean train loss 5011.1085265270585
INFO:root:current train perplexity7.226523399353027
INFO:root:current mean train loss 4944.442233995315
INFO:root:current train perplexity7.033055305480957
INFO:root:current mean train loss 4896.5407759735235
INFO:root:current train perplexity6.897777080535889
INFO:root:current mean train loss 4865.205114428439
INFO:root:current train perplexity6.815892696380615
INFO:root:current mean train loss 4841.021263652495
INFO:root:current train perplexity6.747659206390381

100%|██████████| 1/1 [08:37<00:00, 517.55s/it][A100%|██████████| 1/1 [08:37<00:00, 517.55s/it]
INFO:root:final mean train loss: 4819.03336346534
INFO:root:final train perplexity: 6.694244384765625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.98s/it][A100%|██████████| 1/1 [00:37<00:00, 37.98s/it]
INFO:root:eval mean loss: 4466.428078942265
INFO:root:eval perplexity: 6.086617469787598
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.35s/it][A100%|██████████| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 5362.642881136414
INFO:root:eval perplexity: 8.96078872680664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/102
 51%|█████     | 102/200 [16:46:02<16:11:29, 594.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4641.43984375
INFO:root:current train perplexity6.148934364318848
INFO:root:current mean train loss 4595.957578974185
INFO:root:current train perplexity6.145938873291016
INFO:root:current mean train loss 4606.572672147529
INFO:root:current train perplexity6.139997482299805
INFO:root:current mean train loss 4595.891975136408
INFO:root:current train perplexity6.1359968185424805
INFO:root:current mean train loss 4611.914389589609
INFO:root:current train perplexity6.1645917892456055
INFO:root:current mean train loss 4647.789056811286
INFO:root:current train perplexity6.239625930786133
INFO:root:current mean train loss 4689.986717162094
INFO:root:current train perplexity6.348089694976807
INFO:root:current mean train loss 4739.636460609703
INFO:root:current train perplexity6.4724812507629395
INFO:root:current mean train loss 4753.393143093366
INFO:root:current train perplexity6.511475086212158
INFO:root:current mean train loss 4769.811090121243
INFO:root:current train perplexity6.5531768798828125

100%|██████████| 1/1 [08:36<00:00, 516.86s/it][A100%|██████████| 1/1 [08:36<00:00, 516.86s/it]
INFO:root:final mean train loss: 4777.686051276422
INFO:root:final train perplexity: 6.585928916931152
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.34s/it][A100%|██████████| 1/1 [00:38<00:00, 38.35s/it]
INFO:root:eval mean loss: 4624.1317510943045
INFO:root:eval perplexity: 6.487408638000488
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.02s/it][A100%|██████████| 1/1 [00:37<00:00, 37.03s/it]
INFO:root:eval mean loss: 5495.652045933068
INFO:root:eval perplexity: 9.461658477783203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/103
 52%|█████▏    | 103/200 [16:55:56<16:01:06, 594.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5001.860139266304
INFO:root:current train perplexity7.014843940734863
INFO:root:current mean train loss 5033.218646786077
INFO:root:current train perplexity7.251957893371582
INFO:root:current mean train loss 5277.7012419422645
INFO:root:current train perplexity7.999307632446289
INFO:root:current mean train loss 5204.454432626258
INFO:root:current train perplexity7.787993431091309
INFO:root:current mean train loss 5199.91185080526
INFO:root:current train perplexity7.748793125152588
INFO:root:current mean train loss 5186.018906660791
INFO:root:current train perplexity7.711063861846924
INFO:root:current mean train loss 5169.557845261085
INFO:root:current train perplexity7.660430431365967
INFO:root:current mean train loss 5211.4113408216635
INFO:root:current train perplexity7.795643329620361
INFO:root:current mean train loss 5172.790336896263
INFO:root:current train perplexity7.678494930267334
INFO:root:current mean train loss 5124.499400625507
INFO:root:current train perplexity7.536978721618652

100%|██████████| 1/1 [08:37<00:00, 517.49s/it][A100%|██████████| 1/1 [08:37<00:00, 517.50s/it]
INFO:root:final mean train loss: 5094.830333955826
INFO:root:final train perplexity: 7.463751316070557
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.92s/it][A100%|██████████| 1/1 [00:37<00:00, 37.93s/it]
INFO:root:eval mean loss: 4496.659044630984
INFO:root:eval perplexity: 6.161479473114014
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.26s/it][A100%|██████████| 1/1 [00:37<00:00, 37.26s/it]
INFO:root:eval mean loss: 5414.771359707447
INFO:root:eval perplexity: 9.153847694396973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/104
 52%|█████▏    | 104/200 [17:05:50<15:51:03, 594.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5069.265246975807
INFO:root:current train perplexity7.146350860595703
INFO:root:current mean train loss 5165.926586354962
INFO:root:current train perplexity7.593770503997803
INFO:root:current mean train loss 4849.27193460836
INFO:root:current train perplexity6.734307765960693
INFO:root:current mean train loss 4685.5777798102345
INFO:root:current train perplexity6.325259685516357
INFO:root:current mean train loss 4578.372579552458
INFO:root:current train perplexity6.067552089691162
INFO:root:current mean train loss 4570.6255190861875
INFO:root:current train perplexity6.0677361488342285
INFO:root:current mean train loss 4572.554441037911
INFO:root:current train perplexity6.071183681488037
INFO:root:current mean train loss 4577.744511678672
INFO:root:current train perplexity6.089916229248047
INFO:root:current mean train loss 4582.943189857382
INFO:root:current train perplexity6.100381374359131
INFO:root:current mean train loss 4583.979318063574
INFO:root:current train perplexity6.097567558288574

100%|██████████| 1/1 [08:35<00:00, 515.93s/it][A100%|██████████| 1/1 [08:35<00:00, 515.93s/it]
INFO:root:final mean train loss: 4582.360784961331
INFO:root:final train perplexity: 6.097470283508301
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.55s/it][A100%|██████████| 1/1 [00:38<00:00, 38.55s/it]
INFO:root:eval mean loss: 4436.291161070479
INFO:root:eval perplexity: 6.0128936767578125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.96s/it][A100%|██████████| 1/1 [00:36<00:00, 36.96s/it]
INFO:root:eval mean loss: 5362.249556737589
INFO:root:eval perplexity: 8.959348678588867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/105
 52%|█████▎    | 105/200 [17:15:43<15:40:25, 593.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4526.151623848157
INFO:root:current train perplexity5.938331604003906
INFO:root:current mean train loss 4536.918915453574
INFO:root:current train perplexity5.98465633392334
INFO:root:current mean train loss 4547.565948614017
INFO:root:current train perplexity6.009138107299805
INFO:root:current mean train loss 4574.955707561302
INFO:root:current train perplexity6.054943561553955
INFO:root:current mean train loss 4574.912232835635
INFO:root:current train perplexity6.068724632263184
INFO:root:current mean train loss 4594.363352816268
INFO:root:current train perplexity6.117350101470947
INFO:root:current mean train loss 4616.255296972809
INFO:root:current train perplexity6.170986175537109
INFO:root:current mean train loss 4638.163406392719
INFO:root:current train perplexity6.221499443054199
INFO:root:current mean train loss 4657.824494608537
INFO:root:current train perplexity6.273848056793213
INFO:root:current mean train loss 4682.671813119841
INFO:root:current train perplexity6.337393760681152

100%|██████████| 1/1 [08:37<00:00, 517.76s/it][A100%|██████████| 1/1 [08:37<00:00, 517.76s/it]
INFO:root:final mean train loss: 4684.893780616022
INFO:root:final train perplexity: 6.349184036254883
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.64s/it][A100%|██████████| 1/1 [00:37<00:00, 37.64s/it]
INFO:root:eval mean loss: 4574.29291853668
INFO:root:eval perplexity: 6.357973098754883
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.10s/it][A100%|██████████| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 5483.232297207447
INFO:root:eval perplexity: 9.413726806640625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/106
 53%|█████▎    | 106/200 [17:25:37<15:30:31, 593.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4894.372080701462
INFO:root:current train perplexity6.878748893737793
INFO:root:current mean train loss 4940.863174957483
INFO:root:current train perplexity7.001420021057129
INFO:root:current mean train loss 4967.928566627656
INFO:root:current train perplexity7.105207443237305
INFO:root:current mean train loss 5014.900352631935
INFO:root:current train perplexity7.223297119140625
INFO:root:current mean train loss 5016.750637933445
INFO:root:current train perplexity7.235424518585205
INFO:root:current mean train loss 4988.083056908421
INFO:root:current train perplexity7.166383266448975
INFO:root:current mean train loss 4971.384655440977
INFO:root:current train perplexity7.113287448883057
INFO:root:current mean train loss 4920.3621618636
INFO:root:current train perplexity6.974470615386963
INFO:root:current mean train loss 4950.315696887452
INFO:root:current train perplexity7.047018051147461
INFO:root:current mean train loss 4964.643188863269
INFO:root:current train perplexity7.083244800567627

100%|██████████| 1/1 [08:36<00:00, 516.83s/it][A100%|██████████| 1/1 [08:36<00:00, 516.83s/it]
INFO:root:final mean train loss: 4947.198075694422
INFO:root:final train perplexity: 7.041440486907959
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.76s/it][A100%|██████████| 1/1 [00:37<00:00, 37.76s/it]
INFO:root:eval mean loss: 4368.004737367021
INFO:root:eval perplexity: 5.849130153656006
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.03s/it][A100%|██████████| 1/1 [00:37<00:00, 37.05s/it]
INFO:root:eval mean loss: 5295.145362367021
INFO:root:eval perplexity: 8.71684741973877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/107
 54%|█████▎    | 107/200 [17:35:30<15:20:13, 593.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4480.217005504262
INFO:root:current train perplexity5.83996057510376
INFO:root:current mean train loss 4398.556457913306
INFO:root:current train perplexity5.654689311981201
INFO:root:current mean train loss 4417.384307981005
INFO:root:current train perplexity5.70964241027832
INFO:root:current mean train loss 4550.802518430898
INFO:root:current train perplexity6.02356481552124
INFO:root:current mean train loss 4617.353172218406
INFO:root:current train perplexity6.176575183868408
INFO:root:current mean train loss 4677.85213524071
INFO:root:current train perplexity6.325817584991455
INFO:root:current mean train loss 4709.116478560353
INFO:root:current train perplexity6.406515121459961
INFO:root:current mean train loss 4728.562681084437
INFO:root:current train perplexity6.451591968536377
INFO:root:current mean train loss 4734.80629854258
INFO:root:current train perplexity6.464041709899902
INFO:root:current mean train loss 4727.798985602094
INFO:root:current train perplexity6.445559978485107

100%|██████████| 1/1 [08:34<00:00, 514.21s/it][A100%|██████████| 1/1 [08:34<00:00, 514.22s/it]
INFO:root:final mean train loss: 4724.31503542008
INFO:root:final train perplexity: 6.448702812194824
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.24s/it][A100%|██████████| 1/1 [00:38<00:00, 38.24s/it]
INFO:root:eval mean loss: 4427.764681335882
INFO:root:eval perplexity: 5.992196559906006
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.92s/it][A100%|██████████| 1/1 [00:36<00:00, 36.93s/it]
INFO:root:eval mean loss: 5335.388952376995
INFO:root:eval perplexity: 8.861480712890625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/108
 54%|█████▍    | 108/200 [17:45:21<15:09:04, 592.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4614.819072420635
INFO:root:current train perplexity6.330188274383545
INFO:root:current mean train loss 4615.276656261983
INFO:root:current train perplexity6.203365325927734
INFO:root:current mean train loss 4595.485787859435
INFO:root:current train perplexity6.1409478187561035
INFO:root:current mean train loss 4562.478047520661
INFO:root:current train perplexity6.047266483306885
INFO:root:current mean train loss 4545.394862922685
INFO:root:current train perplexity6.012086391448975
INFO:root:current mean train loss 4540.200826262073
INFO:root:current train perplexity5.999917030334473
INFO:root:current mean train loss 4535.342714887938
INFO:root:current train perplexity5.985966682434082
INFO:root:current mean train loss 4534.104791683732
INFO:root:current train perplexity5.979909896850586
INFO:root:current mean train loss 4532.8014545462775
INFO:root:current train perplexity5.977274417877197
INFO:root:current mean train loss 4534.124565718701
INFO:root:current train perplexity5.975485801696777

100%|██████████| 1/1 [08:34<00:00, 514.48s/it][A100%|██████████| 1/1 [08:34<00:00, 514.48s/it]
INFO:root:final mean train loss: 4531.219816146358
INFO:root:final train perplexity: 5.975676536560059
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.07s/it][A100%|██████████| 1/1 [00:38<00:00, 38.10s/it]
INFO:root:eval mean loss: 4324.977610053746
INFO:root:eval perplexity: 5.748240947723389
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.01s/it][A100%|██████████| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 5257.537703277371
INFO:root:eval perplexity: 8.583821296691895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/109
 55%|█████▍    | 109/200 [17:55:12<14:58:23, 592.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4534.447348151409
INFO:root:current train perplexity5.979097366333008
INFO:root:current mean train loss 4552.412683319627
INFO:root:current train perplexity6.0121073722839355
INFO:root:current mean train loss 4650.542727312039
INFO:root:current train perplexity6.2480149269104
INFO:root:current mean train loss 4681.196064005643
INFO:root:current train perplexity6.301103115081787
INFO:root:current mean train loss 4706.824572261478
INFO:root:current train perplexity6.378523349761963
INFO:root:current mean train loss 4756.654125848292
INFO:root:current train perplexity6.504216194152832
INFO:root:current mean train loss 4781.147847341887
INFO:root:current train perplexity6.574765682220459
INFO:root:current mean train loss 4834.745556070647
INFO:root:current train perplexity6.715540409088135
INFO:root:current mean train loss 5391.560546875
INFO:root:current train perplexity8.377524375915527
INFO:root:current mean train loss 5527.523821185472
INFO:root:current train perplexity8.83881664276123

100%|██████████| 1/1 [08:37<00:00, 517.10s/it][A100%|██████████| 1/1 [08:37<00:00, 517.10s/it]
INFO:root:final mean train loss: 5535.854679230721
INFO:root:final train perplexity: 8.88224983215332
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.26s/it][A100%|██████████| 1/1 [00:38<00:00, 38.26s/it]
INFO:root:eval mean loss: 4972.2457647661795
INFO:root:eval perplexity: 7.468021869659424
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 36.99s/it][A100%|██████████| 1/1 [00:37<00:00, 37.00s/it]
INFO:root:eval mean loss: 5834.55019254211
INFO:root:eval perplexity: 10.86805534362793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/110
 55%|█████▌    | 110/200 [18:05:06<14:49:12, 592.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6180.564854875395
INFO:root:current train perplexity11.451878547668457
INFO:root:current mean train loss 6284.3893238259425
INFO:root:current train perplexity11.873649597167969
INFO:root:current mean train loss 6438.120808481743
INFO:root:current train perplexity12.602644920349121
INFO:root:current mean train loss 6629.869126453249
INFO:root:current train perplexity13.589550018310547
INFO:root:current mean train loss 6829.020571013831
INFO:root:current train perplexity14.727849006652832
INFO:root:current mean train loss 6998.303943693329
INFO:root:current train perplexity15.794212341308594
INFO:root:current mean train loss 7190.122305464148
INFO:root:current train perplexity17.055007934570312
INFO:root:current mean train loss 7465.051560368863
INFO:root:current train perplexity18.960037231445312
INFO:root:current mean train loss 7750.687247249182
INFO:root:current train perplexity21.211034774780273
INFO:root:current mean train loss 8057.203394826513
INFO:root:current train perplexity23.966230392456055

100%|██████████| 1/1 [08:34<00:00, 514.88s/it][A100%|██████████| 1/1 [08:34<00:00, 514.88s/it]
INFO:root:final mean train loss: 8089.46457229122
INFO:root:final train perplexity: 24.325559616088867
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.29s/it][A100%|██████████| 1/1 [00:38<00:00, 38.29s/it]
INFO:root:eval mean loss: 6518.126142785904
INFO:root:eval perplexity: 13.953615188598633
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.79s/it][A100%|██████████| 1/1 [00:36<00:00, 36.80s/it]
INFO:root:eval mean loss: 7317.758089539007
INFO:root:eval perplexity: 19.932104110717773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/111
 56%|█████▌    | 111/200 [18:14:57<14:38:42, 592.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 11279.675422054597
INFO:root:current train perplexity86.25226593017578
INFO:root:current mean train loss 11537.147727272728
INFO:root:current train perplexity94.79338836669922
INFO:root:current mean train loss 11815.297188044426
INFO:root:current train perplexity104.95418548583984
INFO:root:current mean train loss 11900.242003290536
INFO:root:current train perplexity108.89337158203125
INFO:root:current mean train loss 11957.558459397458
INFO:root:current train perplexity111.16437530517578
INFO:root:current mean train loss 12002.213181763735
INFO:root:current train perplexity113.19577026367188
INFO:root:current mean train loss 12088.560209982259
INFO:root:current train perplexity117.59222412109375
INFO:root:current mean train loss 12184.93795912087
INFO:root:current train perplexity122.06486511230469
INFO:root:current mean train loss 12235.008595291361
INFO:root:current train perplexity124.61555480957031
INFO:root:current mean train loss 12288.998106240502
INFO:root:current train perplexity127.08979797363281

100%|██████████| 1/1 [08:34<00:00, 514.93s/it][A100%|██████████| 1/1 [08:34<00:00, 514.93s/it]
INFO:root:final mean train loss: 12281.52681609123
INFO:root:final train perplexity: 127.15641784667969
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.38s/it][A100%|██████████| 1/1 [00:38<00:00, 38.42s/it]
INFO:root:eval mean loss: 9498.73071115913
INFO:root:eval perplexity: 46.57240295410156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.31s/it][A100%|██████████| 1/1 [00:37<00:00, 37.31s/it]
INFO:root:eval mean loss: 9976.817271996897
INFO:root:eval perplexity: 59.12521743774414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/112
 56%|█████▌    | 112/200 [18:24:49<14:28:44, 592.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12153.079091282894
INFO:root:current train perplexity120.9585952758789
INFO:root:current mean train loss 11902.138701923077
INFO:root:current train perplexity111.78448486328125
INFO:root:current mean train loss 11646.391154661016
INFO:root:current train perplexity100.0238037109375
INFO:root:current mean train loss 11310.86228738133
INFO:root:current train perplexity87.73985290527344
INFO:root:current mean train loss 11069.96904000947
INFO:root:current train perplexity79.64108276367188
INFO:root:current mean train loss 10874.066224067752
INFO:root:current train perplexity73.18836212158203
INFO:root:current mean train loss 10684.884597009892
INFO:root:current train perplexity67.63977813720703
INFO:root:current mean train loss 10517.86149579894
INFO:root:current train perplexity63.20499038696289
INFO:root:current mean train loss 10359.75916332053
INFO:root:current train perplexity59.25714111328125

100%|██████████| 1/1 [08:42<00:00, 522.65s/it][A100%|██████████| 1/1 [08:42<00:00, 522.66s/it]
INFO:root:final mean train loss: 10216.826536978444
INFO:root:final train perplexity: 56.307838439941406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.73s/it][A100%|██████████| 1/1 [00:37<00:00, 37.75s/it]
INFO:root:eval mean loss: 6503.098691683289
INFO:root:eval perplexity: 13.869085311889648
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.01s/it][A100%|██████████| 1/1 [00:37<00:00, 37.05s/it]
INFO:root:eval mean loss: 7185.236563608156
INFO:root:eval perplexity: 18.880739212036133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/113
 56%|█████▋    | 113/200 [18:34:48<14:21:43, 594.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8702.905598958334
INFO:root:current train perplexity33.94939041137695
INFO:root:current mean train loss 8850.016416679307
INFO:root:current train perplexity32.9635009765625
INFO:root:current mean train loss 8759.969659213362
INFO:root:current train perplexity31.899185180664062
INFO:root:current mean train loss 8745.04521033158
INFO:root:current train perplexity31.5257511138916
INFO:root:current mean train loss 8698.923305918503
INFO:root:current train perplexity31.05976676940918
INFO:root:current mean train loss 8665.041283548708
INFO:root:current train perplexity30.48876953125
INFO:root:current mean train loss 8613.202606757877
INFO:root:current train perplexity29.844615936279297
INFO:root:current mean train loss 8566.569771431588
INFO:root:current train perplexity29.256576538085938
INFO:root:current mean train loss 8519.089357292964
INFO:root:current train perplexity28.76420783996582
INFO:root:current mean train loss 8468.349459592158
INFO:root:current train perplexity28.207918167114258

100%|██████████| 1/1 [08:35<00:00, 515.56s/it][A100%|██████████| 1/1 [08:35<00:00, 515.58s/it]
INFO:root:final mean train loss: 8425.497073758033
INFO:root:final train perplexity: 27.774057388305664
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.25s/it][A100%|██████████| 1/1 [00:38<00:00, 38.26s/it]
INFO:root:eval mean loss: 6149.5386815713655
INFO:root:eval perplexity: 12.021456718444824
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.97s/it][A100%|██████████| 1/1 [00:36<00:00, 36.99s/it]
INFO:root:eval mean loss: 6868.741058566046
INFO:root:eval perplexity: 16.588716506958008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/114
 57%|█████▋    | 114/200 [18:44:41<14:11:00, 593.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8031.530495383523
INFO:root:current train perplexity24.05783462524414
INFO:root:current mean train loss 7943.759435705237
INFO:root:current train perplexity23.173120498657227
INFO:root:current mean train loss 7975.031150492447
INFO:root:current train perplexity23.44192886352539
INFO:root:current mean train loss 7946.5718040343645
INFO:root:current train perplexity23.126558303833008
INFO:root:current mean train loss 7912.199337553224
INFO:root:current train perplexity22.744489669799805
INFO:root:current mean train loss 7877.740329929061
INFO:root:current train perplexity22.395055770874023
INFO:root:current mean train loss 7844.871335892748
INFO:root:current train perplexity22.095308303833008
INFO:root:current mean train loss 7822.7606638976795
INFO:root:current train perplexity21.866039276123047
INFO:root:current mean train loss 7792.235644170006
INFO:root:current train perplexity21.625120162963867
INFO:root:current mean train loss 7769.163666943949
INFO:root:current train perplexity21.433216094970703

100%|██████████| 1/1 [08:40<00:00, 519.99s/it][A100%|██████████| 1/1 [08:40<00:00, 520.00s/it]
INFO:root:final mean train loss: 7748.700594502111
INFO:root:final train perplexity: 21.265514373779297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.96s/it][A100%|██████████| 1/1 [00:37<00:00, 37.98s/it]
INFO:root:eval mean loss: 5732.449966755319
INFO:root:eval perplexity: 10.155693054199219
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.43s/it][A100%|██████████| 1/1 [00:37<00:00, 37.43s/it]
INFO:root:eval mean loss: 6495.501859624335
INFO:root:eval perplexity: 14.240642547607422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/115
 57%|█████▊    | 115/200 [18:54:38<14:02:30, 594.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7672.980237458882
INFO:root:current train perplexity20.16832733154297
INFO:root:current mean train loss 7596.439818310137
INFO:root:current train perplexity19.643756866455078
INFO:root:current mean train loss 7490.820698219892
INFO:root:current train perplexity19.20665168762207
INFO:root:current mean train loss 7444.781657156152
INFO:root:current train perplexity18.837371826171875
INFO:root:current mean train loss 7410.574345773046
INFO:root:current train perplexity18.58141326904297
INFO:root:current mean train loss 7373.9726703621745
INFO:root:current train perplexity18.35094451904297
INFO:root:current mean train loss 7360.43581270825
INFO:root:current train perplexity18.24970245361328
INFO:root:current mean train loss 7340.641002586057
INFO:root:current train perplexity18.093984603881836
INFO:root:current mean train loss 7318.633412269154
INFO:root:current train perplexity17.91170883178711
INFO:root:current mean train loss 7297.238907142614
INFO:root:current train perplexity17.765600204467773

100%|██████████| 1/1 [08:37<00:00, 517.36s/it][A100%|██████████| 1/1 [08:37<00:00, 517.38s/it]
INFO:root:final mean train loss: 7282.152861687445
INFO:root:final train perplexity: 17.69036102294922
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.90s/it][A100%|██████████| 1/1 [00:37<00:00, 37.95s/it]
INFO:root:eval mean loss: 5518.619871315381
INFO:root:eval perplexity: 9.31445598602295
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.95s/it][A100%|██████████| 1/1 [00:36<00:00, 36.97s/it]
INFO:root:eval mean loss: 6307.040070229388
INFO:root:eval perplexity: 13.184412956237793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/116
 58%|█████▊    | 116/200 [19:04:32<13:52:13, 594.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7213.925112123842
INFO:root:current train perplexity16.554386138916016
INFO:root:current mean train loss 7127.303941621555
INFO:root:current train perplexity16.472055435180664
INFO:root:current mean train loss 7098.660265951955
INFO:root:current train perplexity16.3532772064209
INFO:root:current mean train loss 7061.639850021502
INFO:root:current train perplexity16.16177749633789
INFO:root:current mean train loss 7056.415829231923
INFO:root:current train perplexity16.079214096069336
INFO:root:current mean train loss 7033.72339006167
INFO:root:current train perplexity15.979798316955566
INFO:root:current mean train loss 7018.022156443132
INFO:root:current train perplexity15.920004844665527
INFO:root:current mean train loss 7016.261056514357
INFO:root:current train perplexity15.909171104431152
INFO:root:current mean train loss 7008.442442445397
INFO:root:current train perplexity15.875941276550293
INFO:root:current mean train loss 7000.221855616235
INFO:root:current train perplexity15.805154800415039

100%|██████████| 1/1 [08:39<00:00, 519.15s/it][A100%|██████████| 1/1 [08:39<00:00, 519.15s/it]
INFO:root:final mean train loss: 6989.820392854752
INFO:root:final train perplexity: 15.763330459594727
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.75s/it][A100%|██████████| 1/1 [00:37<00:00, 37.76s/it]
INFO:root:eval mean loss: 5429.617623836436
INFO:root:eval perplexity: 8.985191345214844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.21s/it][A100%|██████████| 1/1 [00:37<00:00, 37.23s/it]
INFO:root:eval mean loss: 6225.550542303857
INFO:root:eval perplexity: 12.7523193359375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/117
 58%|█████▊    | 117/200 [19:14:27<13:42:49, 594.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6845.0577427455355
INFO:root:current train perplexity14.67053508758545
INFO:root:current mean train loss 6890.9135706018515
INFO:root:current train perplexity14.914514541625977
INFO:root:current mean train loss 6862.884636801862
INFO:root:current train perplexity14.826839447021484
INFO:root:current mean train loss 6869.243019764459
INFO:root:current train perplexity14.820117950439453
INFO:root:current mean train loss 6856.232460039511
INFO:root:current train perplexity14.827094078063965
INFO:root:current mean train loss 6855.87988463785
INFO:root:current train perplexity14.844196319580078
INFO:root:current mean train loss 6844.397835414617
INFO:root:current train perplexity14.807113647460938
INFO:root:current mean train loss 6836.600406568878
INFO:root:current train perplexity14.740842819213867
INFO:root:current mean train loss 6825.076472445733
INFO:root:current train perplexity14.69750690460205
INFO:root:current mean train loss 6813.35118336397
INFO:root:current train perplexity14.641721725463867

100%|██████████| 1/1 [08:36<00:00, 516.66s/it][A100%|██████████| 1/1 [08:36<00:00, 516.66s/it]
INFO:root:final mean train loss: 6798.687844307192
INFO:root:final train perplexity: 14.618369102478027
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.11s/it][A100%|██████████| 1/1 [00:38<00:00, 38.12s/it]
INFO:root:eval mean loss: 5336.591246259974
INFO:root:eval perplexity: 8.653473854064941
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.16s/it][A100%|██████████| 1/1 [00:37<00:00, 37.17s/it]
INFO:root:eval mean loss: 6137.960979055851
INFO:root:eval perplexity: 12.303656578063965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/118
 59%|█████▉    | 118/200 [19:24:21<13:32:22, 594.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6695.925951580669
INFO:root:current train perplexity13.990995407104492
INFO:root:current mean train loss 6716.305619673295
INFO:root:current train perplexity14.052644729614258
INFO:root:current mean train loss 6833.212408371914
INFO:root:current train perplexity14.666912078857422
INFO:root:current mean train loss 6890.729022412536
INFO:root:current train perplexity15.126708030700684
INFO:root:current mean train loss 6880.520926654204
INFO:root:current train perplexity15.066161155700684
INFO:root:current mean train loss 6836.442755093232
INFO:root:current train perplexity14.824295043945312
INFO:root:current mean train loss 6805.162350098416
INFO:root:current train perplexity14.629166603088379
INFO:root:current mean train loss 6774.053039304341
INFO:root:current train perplexity14.445538520812988
INFO:root:current mean train loss 6745.161892747256
INFO:root:current train perplexity14.292691230773926
INFO:root:current mean train loss 6722.3401042011865
INFO:root:current train perplexity14.15015983581543

100%|██████████| 1/1 [08:44<00:00, 524.12s/it][A100%|██████████| 1/1 [08:44<00:00, 524.12s/it]
INFO:root:final mean train loss: 6704.546267109533
INFO:root:final train perplexity: 14.085382461547852
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.11s/it][A100%|██████████| 1/1 [00:38<00:00, 38.12s/it]
INFO:root:eval mean loss: 5270.809165142952
INFO:root:eval perplexity: 8.426322937011719
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.01s/it][A100%|██████████| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 6061.177474650931
INFO:root:eval perplexity: 11.92335033416748
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/119
 60%|█████▉    | 119/200 [19:34:22<13:25:02, 596.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6633.392463235294
INFO:root:current train perplexity13.769323348999023
INFO:root:current mean train loss 6714.268040537045
INFO:root:current train perplexity14.093639373779297
INFO:root:current mean train loss 6703.665696588645
INFO:root:current train perplexity14.037973403930664
INFO:root:current mean train loss 6646.161022914441
INFO:root:current train perplexity13.738011360168457
INFO:root:current mean train loss 6619.237115221383
INFO:root:current train perplexity13.56242561340332
INFO:root:current mean train loss 6599.758354837795
INFO:root:current train perplexity13.448760986328125
INFO:root:current mean train loss 6586.241351196477
INFO:root:current train perplexity13.43144416809082
INFO:root:current mean train loss 6599.060054042527
INFO:root:current train perplexity13.501052856445312
INFO:root:current mean train loss 6611.8339654404745
INFO:root:current train perplexity13.571039199829102
INFO:root:current mean train loss 6641.399532667094
INFO:root:current train perplexity13.719108581542969

100%|██████████| 1/1 [08:36<00:00, 516.20s/it][A100%|██████████| 1/1 [08:36<00:00, 516.20s/it]
INFO:root:final mean train loss: 6648.428761759112
INFO:root:final train perplexity: 13.776958465576172
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.77s/it][A100%|██████████| 1/1 [00:37<00:00, 37.77s/it]
INFO:root:eval mean loss: 5423.4204066932625
INFO:root:eval perplexity: 8.962702751159668
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.08s/it][A100%|██████████| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 6204.425081726507
INFO:root:eval perplexity: 12.642634391784668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/120
 60%|██████    | 120/200 [19:44:14<13:13:36, 595.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6971.335598185911
INFO:root:current train perplexity15.44122314453125
INFO:root:current mean train loss 6858.391193125983
INFO:root:current train perplexity15.053163528442383
INFO:root:current mean train loss 6933.447454150579
INFO:root:current train perplexity15.485231399536133
INFO:root:current mean train loss 6970.709059181319
INFO:root:current train perplexity15.6769437789917
INFO:root:current mean train loss 6969.3346822235835
INFO:root:current train perplexity15.581023216247559
INFO:root:current mean train loss 6926.6659876733
INFO:root:current train perplexity15.327997207641602
INFO:root:current mean train loss 6898.439556116037
INFO:root:current train perplexity15.157249450683594
INFO:root:current mean train loss 6867.280860146986
INFO:root:current train perplexity14.976673126220703
INFO:root:current mean train loss 6850.082003396937
INFO:root:current train perplexity14.871748924255371
INFO:root:current mean train loss 6832.1990318895005
INFO:root:current train perplexity14.774624824523926

100%|██████████| 1/1 [08:38<00:00, 518.08s/it][A100%|██████████| 1/1 [08:38<00:00, 518.08s/it]
INFO:root:final mean train loss: 6820.0645888543895
INFO:root:final train perplexity: 14.742178916931152
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.04s/it][A100%|██████████| 1/1 [00:38<00:00, 38.05s/it]
INFO:root:eval mean loss: 5314.26072833555
INFO:root:eval perplexity: 8.57568645477295
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.66s/it][A100%|██████████| 1/1 [00:37<00:00, 37.73s/it]
INFO:root:eval mean loss: 6109.468898908466
INFO:root:eval perplexity: 12.161141395568848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/121
 60%|██████    | 121/200 [19:54:09<13:03:44, 595.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6591.2348414179105
INFO:root:current train perplexity13.471375465393066
INFO:root:current mean train loss 6687.202777063061
INFO:root:current train perplexity13.939925193786621
INFO:root:current mean train loss 6709.527404099368
INFO:root:current train perplexity13.998342514038086
INFO:root:current mean train loss 6726.3221804751365
INFO:root:current train perplexity14.122701644897461
INFO:root:current mean train loss 6715.566358153774
INFO:root:current train perplexity14.106928825378418
INFO:root:current mean train loss 6694.467991312556
INFO:root:current train perplexity14.015654563903809
INFO:root:current mean train loss 6672.9748165468045
INFO:root:current train perplexity13.899291038513184
INFO:root:current mean train loss 6660.905399486636
INFO:root:current train perplexity13.83857536315918
INFO:root:current mean train loss 6645.261793653583
INFO:root:current train perplexity13.748735427856445
INFO:root:current mean train loss 6639.898047177967
INFO:root:current train perplexity13.697531700134277

100%|██████████| 1/1 [08:35<00:00, 515.19s/it][A100%|██████████| 1/1 [08:35<00:00, 515.19s/it]
INFO:root:final mean train loss: 6630.306581435665
INFO:root:final train perplexity: 13.67880916595459
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.80s/it][A100%|██████████| 1/1 [00:37<00:00, 37.81s/it]
INFO:root:eval mean loss: 5243.855015098626
INFO:root:eval perplexity: 8.334977149963379
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.00s/it][A100%|██████████| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 6056.803807901152
INFO:root:eval perplexity: 11.902046203613281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/122
 61%|██████    | 122/200 [20:04:01<12:52:20, 594.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6481.956901041666
INFO:root:current train perplexity12.992552757263184
INFO:root:current mean train loss 6500.458643973214
INFO:root:current train perplexity12.929733276367188
INFO:root:current mean train loss 6547.82755859375
INFO:root:current train perplexity13.292851448059082
INFO:root:current mean train loss 6615.121654947917
INFO:root:current train perplexity13.61054515838623
INFO:root:current mean train loss 6624.864214638158
INFO:root:current train perplexity13.583274841308594
INFO:root:current mean train loss 6619.052370923913
INFO:root:current train perplexity13.562128067016602
INFO:root:current mean train loss 6616.014027054398
INFO:root:current train perplexity13.532712936401367
INFO:root:current mean train loss 6602.046009954637
INFO:root:current train perplexity13.466362953186035
INFO:root:current mean train loss 6596.487120535714
INFO:root:current train perplexity13.434947967529297
INFO:root:current mean train loss 6593.090413661859
INFO:root:current train perplexity13.439308166503906

100%|██████████| 1/1 [08:36<00:00, 516.78s/it][A100%|██████████| 1/1 [08:36<00:00, 516.79s/it]
INFO:root:final mean train loss: 6587.173799576298
INFO:root:final train perplexity: 13.448003768920898
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.15s/it][A100%|██████████| 1/1 [00:38<00:00, 38.17s/it]
INFO:root:eval mean loss: 5349.72080355164
INFO:root:eval perplexity: 8.699541091918945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.23s/it][A100%|██████████| 1/1 [00:37<00:00, 37.24s/it]
INFO:root:eval mean loss: 6155.972372285018
INFO:root:eval perplexity: 12.394607543945312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/123
 62%|██████▏   | 123/200 [20:13:55<12:42:15, 593.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6620.52043721762
INFO:root:current train perplexity13.782537460327148
INFO:root:current mean train loss 6657.7427478227455
INFO:root:current train perplexity13.815258026123047
INFO:root:current mean train loss 6643.177318559518
INFO:root:current train perplexity13.734644889831543
INFO:root:current mean train loss 6629.995351766482
INFO:root:current train perplexity13.682252883911133
INFO:root:current mean train loss 6630.445176023874
INFO:root:current train perplexity13.685544967651367
INFO:root:current mean train loss 6630.417199057943
INFO:root:current train perplexity13.701343536376953
INFO:root:current mean train loss 6625.969939604685
INFO:root:current train perplexity13.672832489013672
INFO:root:current mean train loss 6634.276490037317
INFO:root:current train perplexity13.68222713470459
INFO:root:current mean train loss 6637.065073015466
INFO:root:current train perplexity13.69926929473877
INFO:root:current mean train loss 6642.847826626876
INFO:root:current train perplexity13.72039794921875

100%|██████████| 1/1 [08:38<00:00, 518.40s/it][A100%|██████████| 1/1 [08:38<00:00, 518.40s/it]
INFO:root:final mean train loss: 6638.047575058476
INFO:root:final train perplexity: 13.720645904541016
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.07s/it][A100%|██████████| 1/1 [00:38<00:00, 38.09s/it]
INFO:root:eval mean loss: 5332.880939023715
INFO:root:eval perplexity: 8.640501022338867
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.34s/it][A100%|██████████| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 6148.461869043661
INFO:root:eval perplexity: 12.35660171508789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/124
 62%|██████▏   | 124/200 [20:23:50<12:32:50, 594.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6701.424053485577
INFO:root:current train perplexity13.866595268249512
INFO:root:current mean train loss 6679.5519546588675
INFO:root:current train perplexity13.940011978149414
INFO:root:current mean train loss 6676.041814325601
INFO:root:current train perplexity13.944272994995117
INFO:root:current mean train loss 6689.419878166959
INFO:root:current train perplexity13.927769660949707
INFO:root:current mean train loss 6680.701012760947
INFO:root:current train perplexity13.930745124816895
INFO:root:current mean train loss 6685.815651107762
INFO:root:current train perplexity13.974343299865723
INFO:root:current mean train loss 6688.420178381648
INFO:root:current train perplexity13.966452598571777
INFO:root:current mean train loss 6693.9157693238385
INFO:root:current train perplexity14.002958297729492
INFO:root:current mean train loss 6690.394543854342
INFO:root:current train perplexity13.985565185546875
INFO:root:current mean train loss 6693.735202762361
INFO:root:current train perplexity13.996397018432617

100%|██████████| 1/1 [08:35<00:00, 515.95s/it][A100%|██████████| 1/1 [08:35<00:00, 515.95s/it]
INFO:root:final mean train loss: 6688.323700566446
INFO:root:final train perplexity: 13.995518684387207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.22s/it][A100%|██████████| 1/1 [00:38<00:00, 38.23s/it]
INFO:root:eval mean loss: 5307.909210854388
INFO:root:eval perplexity: 8.553688049316406
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.89s/it][A100%|██████████| 1/1 [00:36<00:00, 36.91s/it]
INFO:root:eval mean loss: 6101.840207363697
INFO:root:eval perplexity: 12.12326717376709
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/125
 62%|██████▎   | 125/200 [20:33:42<12:22:16, 593.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6658.957800662879
INFO:root:current train perplexity13.726591110229492
INFO:root:current mean train loss 6659.582296246859
INFO:root:current train perplexity13.726712226867676
INFO:root:current mean train loss 6646.882498954849
INFO:root:current train perplexity13.711159706115723
INFO:root:current mean train loss 6652.217540922619
INFO:root:current train perplexity13.776813507080078
INFO:root:current mean train loss 6648.729825862662
INFO:root:current train perplexity13.804224967956543
INFO:root:current mean train loss 6649.33723523581
INFO:root:current train perplexity13.786026954650879
INFO:root:current mean train loss 6651.5274059202875
INFO:root:current train perplexity13.79107666015625
INFO:root:current mean train loss 6657.548461455726
INFO:root:current train perplexity13.800674438476562
INFO:root:current mean train loss 6660.366600910734
INFO:root:current train perplexity13.814092636108398

100%|██████████| 1/1 [08:36<00:00, 516.58s/it][A100%|██████████| 1/1 [08:36<00:00, 516.60s/it]
INFO:root:final mean train loss: 6660.715155816847
INFO:root:final train perplexity: 13.843897819519043
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.75s/it][A100%|██████████| 1/1 [00:37<00:00, 37.75s/it]
INFO:root:eval mean loss: 5312.60645916445
INFO:root:eval perplexity: 8.569951057434082
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.96s/it][A100%|██████████| 1/1 [00:36<00:00, 36.99s/it]
INFO:root:eval mean loss: 6093.471991356383
INFO:root:eval perplexity: 12.081851959228516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/126
 63%|██████▎   | 126/200 [20:43:35<12:12:01, 593.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6637.465890066965
INFO:root:current train perplexity13.63829517364502
INFO:root:current mean train loss 6670.548974153037
INFO:root:current train perplexity13.832782745361328
INFO:root:current mean train loss 6707.143986356431
INFO:root:current train perplexity13.982808113098145
INFO:root:current mean train loss 6717.973775956841
INFO:root:current train perplexity13.98002815246582
INFO:root:current mean train loss 6721.60602541462
INFO:root:current train perplexity14.042767524719238
INFO:root:current mean train loss 6731.310595028969
INFO:root:current train perplexity14.12863540649414
INFO:root:current mean train loss 6762.9632067609655
INFO:root:current train perplexity14.320685386657715
INFO:root:current mean train loss 6770.859885381675
INFO:root:current train perplexity14.391000747680664
INFO:root:current mean train loss 6771.234528684557
INFO:root:current train perplexity14.406888961791992
INFO:root:current mean train loss 6766.313136326833
INFO:root:current train perplexity14.391371726989746

100%|██████████| 1/1 [08:36<00:00, 516.68s/it][A100%|██████████| 1/1 [08:36<00:00, 516.68s/it]
INFO:root:final mean train loss: 6757.998509191698
INFO:root:final train perplexity: 14.385570526123047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.79s/it][A100%|██████████| 1/1 [00:37<00:00, 37.81s/it]
INFO:root:eval mean loss: 5402.172661098182
INFO:root:eval perplexity: 8.886028289794922
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.28s/it][A100%|██████████| 1/1 [00:37<00:00, 37.33s/it]
INFO:root:eval mean loss: 6173.617821226729
INFO:root:eval perplexity: 12.484367370605469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/127
 64%|██████▎   | 127/200 [20:53:29<12:02:04, 593.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6726.130338541667
INFO:root:current train perplexity14.224727630615234
INFO:root:current mean train loss 6786.769887907609
INFO:root:current train perplexity14.697832107543945
INFO:root:current mean train loss 6778.246954487646
INFO:root:current train perplexity14.65426254272461
INFO:root:current mean train loss 6789.028160652282
INFO:root:current train perplexity14.556445121765137
INFO:root:current mean train loss 6787.109118505271
INFO:root:current train perplexity14.52708911895752
INFO:root:current mean train loss 6791.147481796116
INFO:root:current train perplexity14.532968521118164
INFO:root:current mean train loss 6795.869539189533
INFO:root:current train perplexity14.567488670349121
INFO:root:current mean train loss 6800.601841127623
INFO:root:current train perplexity14.589824676513672
INFO:root:current mean train loss 6810.786718150882
INFO:root:current train perplexity14.638667106628418
INFO:root:current mean train loss 6819.6342415898225
INFO:root:current train perplexity14.672903060913086

100%|██████████| 1/1 [08:35<00:00, 515.60s/it][A100%|██████████| 1/1 [08:35<00:00, 515.60s/it]
INFO:root:final mean train loss: 6810.821999088411
INFO:root:final train perplexity: 14.688517570495605
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.55s/it][A100%|██████████| 1/1 [00:37<00:00, 37.56s/it]
INFO:root:eval mean loss: 5398.714203097296
INFO:root:eval perplexity: 8.873607635498047
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.14s/it][A100%|██████████| 1/1 [00:37<00:00, 37.16s/it]
INFO:root:eval mean loss: 6172.952290419991
INFO:root:eval perplexity: 12.480971336364746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/128
 64%|██████▍   | 128/200 [21:03:20<11:51:33, 592.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6863.356169327446
INFO:root:current train perplexity14.939465522766113
INFO:root:current mean train loss 6846.117072376778
INFO:root:current train perplexity14.907557487487793
INFO:root:current mean train loss 6943.898236056614
INFO:root:current train perplexity15.512554168701172
INFO:root:current mean train loss 7899.661067809114
INFO:root:current train perplexity22.56732940673828
INFO:root:current mean train loss 8182.15062033651
INFO:root:current train perplexity25.155359268188477
INFO:root:current mean train loss 8149.080350740918
INFO:root:current train perplexity24.839786529541016
INFO:root:current mean train loss 8123.116707840089
INFO:root:current train perplexity24.599811553955078
INFO:root:current mean train loss 8070.348239756224
INFO:root:current train perplexity24.08238983154297
INFO:root:current mean train loss 8001.461715308893
INFO:root:current train perplexity23.48919105529785
INFO:root:current mean train loss 7929.766285740283
INFO:root:current train perplexity22.77495765686035

100%|██████████| 1/1 [08:34<00:00, 514.16s/it][A100%|██████████| 1/1 [08:34<00:00, 514.20s/it]
INFO:root:final mean train loss: 7872.341171633812
INFO:root:final train perplexity: 22.328561782836914
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.97s/it][A100%|██████████| 1/1 [00:37<00:00, 37.98s/it]
INFO:root:eval mean loss: 5658.146311225621
INFO:root:eval perplexity: 9.855091094970703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.08s/it][A100%|██████████| 1/1 [00:37<00:00, 37.10s/it]
INFO:root:eval mean loss: 6380.607685062057
INFO:root:eval perplexity: 13.587064743041992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/129
 64%|██████▍   | 129/200 [21:13:11<11:40:54, 592.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7175.139616935484
INFO:root:current train perplexity16.536693572998047
INFO:root:current mean train loss 7030.112796696088
INFO:root:current train perplexity16.153730392456055
INFO:root:current mean train loss 6980.278819162609
INFO:root:current train perplexity15.776952743530273
INFO:root:current mean train loss 6932.957152213935
INFO:root:current train perplexity15.484777450561523
INFO:root:current mean train loss 6896.749543440038
INFO:root:current train perplexity15.270120620727539
INFO:root:current mean train loss 6872.981440714748
INFO:root:current train perplexity15.106546401977539
INFO:root:current mean train loss 6841.171653687104
INFO:root:current train perplexity14.911755561828613
INFO:root:current mean train loss 6826.507159899752
INFO:root:current train perplexity14.779303550720215
INFO:root:current mean train loss 6810.39145114132
INFO:root:current train perplexity14.65103816986084
INFO:root:current mean train loss 6790.154463131881
INFO:root:current train perplexity14.545263290405273

100%|██████████| 1/1 [08:39<00:00, 519.71s/it][A100%|██████████| 1/1 [08:39<00:00, 519.71s/it]
INFO:root:final mean train loss: 6774.820822931105
INFO:root:final train perplexity: 14.481369972229004
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.70s/it][A100%|██████████| 1/1 [00:37<00:00, 37.71s/it]
INFO:root:eval mean loss: 5371.211408466312
INFO:root:eval perplexity: 8.775467872619629
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.69s/it][A100%|██████████| 1/1 [00:36<00:00, 36.71s/it]
INFO:root:eval mean loss: 6146.200184923538
INFO:root:eval perplexity: 12.345181465148926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/130
 65%|██████▌   | 130/200 [21:23:07<11:32:09, 593.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6560.604291866987
INFO:root:current train perplexity13.240153312683105
INFO:root:current mean train loss 6558.3173828125
INFO:root:current train perplexity13.405131340026855
INFO:root:current mean train loss 6558.716371927301
INFO:root:current train perplexity13.325506210327148
INFO:root:current mean train loss 6560.454418441187
INFO:root:current train perplexity13.353691101074219
INFO:root:current mean train loss 6553.04216792426
INFO:root:current train perplexity13.319363594055176
INFO:root:current mean train loss 6551.164013581285
INFO:root:current train perplexity13.291289329528809
INFO:root:current mean train loss 6543.15498459507
INFO:root:current train perplexity13.246994972229004
INFO:root:current mean train loss 6541.335619026979
INFO:root:current train perplexity13.212865829467773
INFO:root:current mean train loss 6534.981892855148
INFO:root:current train perplexity13.179978370666504
INFO:root:current mean train loss 6531.068384855065
INFO:root:current train perplexity13.137289047241211

100%|██████████| 1/1 [08:33<00:00, 513.80s/it][A100%|██████████| 1/1 [08:33<00:00, 513.80s/it]
INFO:root:final mean train loss: 6524.6817480517975
INFO:root:final train perplexity: 13.120495796203613
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.10s/it][A100%|██████████| 1/1 [00:38<00:00, 38.12s/it]
INFO:root:eval mean loss: 5291.057537538785
INFO:root:eval perplexity: 8.495599746704102
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.32s/it][A100%|██████████| 1/1 [00:37<00:00, 37.34s/it]
INFO:root:eval mean loss: 6090.581314411569
INFO:root:eval perplexity: 12.067578315734863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/131
 66%|██████▌   | 131/200 [21:32:58<11:21:25, 592.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6407.670004986702
INFO:root:current train perplexity12.515125274658203
INFO:root:current mean train loss 6428.355143229167
INFO:root:current train perplexity12.633052825927734
INFO:root:current mean train loss 6443.248017222292
INFO:root:current train perplexity12.675451278686523
INFO:root:current mean train loss 6439.112539681646
INFO:root:current train perplexity12.658285140991211
INFO:root:current mean train loss 6432.498207450713
INFO:root:current train perplexity12.604574203491211
INFO:root:current mean train loss 6433.146812871344
INFO:root:current train perplexity12.604540824890137
INFO:root:current mean train loss 6426.930324454212
INFO:root:current train perplexity12.576068878173828
INFO:root:current mean train loss 6421.760110755522
INFO:root:current train perplexity12.561772346496582
INFO:root:current mean train loss 6418.370033020957
INFO:root:current train perplexity12.561874389648438
INFO:root:current mean train loss 6417.880936716275
INFO:root:current train perplexity12.553706169128418

100%|██████████| 1/1 [08:34<00:00, 514.99s/it][A100%|██████████| 1/1 [08:34<00:00, 514.99s/it]
INFO:root:final mean train loss: 6413.607261042441
INFO:root:final train perplexity: 12.557948112487793
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.16s/it][A100%|██████████| 1/1 [00:38<00:00, 38.17s/it]
INFO:root:eval mean loss: 5235.929389683068
INFO:root:eval perplexity: 8.308309555053711
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.34s/it][A100%|██████████| 1/1 [00:37<00:00, 37.36s/it]
INFO:root:eval mean loss: 6042.744022883422
INFO:root:eval perplexity: 11.83381462097168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/132
 66%|██████▌   | 132/200 [21:42:50<11:11:21, 592.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6407.364098011363
INFO:root:current train perplexity12.379557609558105
INFO:root:current mean train loss 6407.850368573589
INFO:root:current train perplexity12.398756980895996
INFO:root:current mean train loss 6391.003410309436
INFO:root:current train perplexity12.371859550476074
INFO:root:current mean train loss 6386.702226837588
INFO:root:current train perplexity12.359601020812988
INFO:root:current mean train loss 6376.406280048077
INFO:root:current train perplexity12.328143119812012
INFO:root:current mean train loss 6370.4728709177925
INFO:root:current train perplexity12.325674057006836
INFO:root:current mean train loss 6366.044745944657
INFO:root:current train perplexity12.293538093566895
INFO:root:current mean train loss 6360.280998421978
INFO:root:current train perplexity12.277205467224121
INFO:root:current mean train loss 6354.514096765351
INFO:root:current train perplexity12.247464179992676
INFO:root:current mean train loss 6348.171643385962
INFO:root:current train perplexity12.21346664428711

100%|██████████| 1/1 [08:34<00:00, 514.32s/it][A100%|██████████| 1/1 [08:34<00:00, 514.32s/it]
INFO:root:final mean train loss: 6341.257750726515
INFO:root:final train perplexity: 12.204559326171875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.80s/it][A100%|██████████| 1/1 [00:37<00:00, 37.81s/it]
INFO:root:eval mean loss: 5186.636455562943
INFO:root:eval perplexity: 8.144341468811035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.74s/it][A100%|██████████| 1/1 [00:36<00:00, 36.74s/it]
INFO:root:eval mean loss: 6008.2197819703015
INFO:root:eval perplexity: 11.667924880981445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/133
 66%|██████▋   | 133/200 [21:52:40<11:00:47, 591.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6319.370016431051
INFO:root:current train perplexity11.92824649810791
INFO:root:current mean train loss 6315.450204299272
INFO:root:current train perplexity11.958484649658203
INFO:root:current mean train loss 6328.203527878446
INFO:root:current train perplexity11.979758262634277
INFO:root:current mean train loss 6319.038702005854
INFO:root:current train perplexity11.986557960510254
INFO:root:current mean train loss 6301.646205959773
INFO:root:current train perplexity11.95620059967041
INFO:root:current mean train loss 6293.419859430506
INFO:root:current train perplexity11.91653823852539
INFO:root:current mean train loss 6285.883595370239
INFO:root:current train perplexity11.883119583129883
INFO:root:current mean train loss 6284.849185088671
INFO:root:current train perplexity11.874775886535645
INFO:root:current mean train loss 6277.966340844076
INFO:root:current train perplexity11.868467330932617
INFO:root:current mean train loss 6276.402066905179
INFO:root:current train perplexity11.871441841125488

100%|██████████| 1/1 [08:34<00:00, 514.01s/it][A100%|██████████| 1/1 [08:34<00:00, 514.01s/it]
INFO:root:final mean train loss: 6271.469459533691
INFO:root:final train perplexity: 11.873111724853516
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.57s/it][A100%|██████████| 1/1 [00:37<00:00, 37.57s/it]
INFO:root:eval mean loss: 5151.867506094858
INFO:root:eval perplexity: 8.030638694763184
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.06s/it][A100%|██████████| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 5971.3237270057625
INFO:root:eval perplexity: 11.493207931518555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/134
 67%|██████▋   | 134/200 [22:02:30<10:50:22, 591.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6199.41513534331
INFO:root:current train perplexity11.554540634155273
INFO:root:current mean train loss 6214.940586737025
INFO:root:current train perplexity11.625465393066406
INFO:root:current mean train loss 6208.503763909709
INFO:root:current train perplexity11.57193660736084
INFO:root:current mean train loss 6217.220580725657
INFO:root:current train perplexity11.616781234741211
INFO:root:current mean train loss 6210.6136264679535
INFO:root:current train perplexity11.567004203796387
INFO:root:current mean train loss 6205.414423366353
INFO:root:current train perplexity11.579862594604492
INFO:root:current mean train loss 6209.034641771842
INFO:root:current train perplexity11.589151382446289
INFO:root:current mean train loss 6206.722314896441
INFO:root:current train perplexity11.579987525939941
INFO:root:current mean train loss 6215.06994362622
INFO:root:current train perplexity11.598795890808105
INFO:root:current mean train loss 6216.795770709964
INFO:root:current train perplexity11.599780082702637

100%|██████████| 1/1 [08:37<00:00, 517.94s/it][A100%|██████████| 1/1 [08:37<00:00, 517.94s/it]
INFO:root:final mean train loss: 6213.343073321927
INFO:root:final train perplexity: 11.603926658630371
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.78s/it][A100%|██████████| 1/1 [00:37<00:00, 37.80s/it]
INFO:root:eval mean loss: 5137.871554327349
INFO:root:eval perplexity: 7.985315322875977
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.83s/it][A100%|██████████| 1/1 [00:36<00:00, 36.83s/it]
INFO:root:eval mean loss: 5966.778874390514
INFO:root:eval perplexity: 11.471870422363281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/135
 68%|██████▊   | 135/200 [22:12:24<10:41:26, 592.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6200.691795638845
INFO:root:current train perplexity11.580066680908203
INFO:root:current mean train loss 6196.7185208624305
INFO:root:current train perplexity11.49966049194336
INFO:root:current mean train loss 6193.295018131161
INFO:root:current train perplexity11.470026969909668
INFO:root:current mean train loss 6190.622715771356
INFO:root:current train perplexity11.462198257446289
INFO:root:current mean train loss 6195.131539298995
INFO:root:current train perplexity11.472773551940918
INFO:root:current mean train loss 6184.899901500432
INFO:root:current train perplexity11.445223808288574
INFO:root:current mean train loss 6182.748110876519
INFO:root:current train perplexity11.429571151733398
INFO:root:current mean train loss 6178.6349348624035
INFO:root:current train perplexity11.420258522033691
INFO:root:current mean train loss 6175.2849390509455
INFO:root:current train perplexity11.405539512634277
INFO:root:current mean train loss 6174.2712734015895
INFO:root:current train perplexity11.406821250915527

100%|██████████| 1/1 [08:34<00:00, 514.63s/it][A100%|██████████| 1/1 [08:34<00:00, 514.63s/it]
INFO:root:final mean train loss: 6169.699550874771
INFO:root:final train perplexity: 11.40583324432373
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.01s/it][A100%|██████████| 1/1 [00:38<00:00, 38.01s/it]
INFO:root:eval mean loss: 5110.92345412234
INFO:root:eval perplexity: 7.89877462387085
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.24s/it][A100%|██████████| 1/1 [00:37<00:00, 37.26s/it]
INFO:root:eval mean loss: 5940.932485593971
INFO:root:eval perplexity: 11.351264953613281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/136
 68%|██████▊   | 136/200 [22:22:15<10:31:22, 591.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6141.866143588362
INFO:root:current train perplexity11.31559944152832
INFO:root:current mean train loss 6144.031790503844
INFO:root:current train perplexity11.253490447998047
INFO:root:current mean train loss 6155.754363907339
INFO:root:current train perplexity11.309520721435547
INFO:root:current mean train loss 6144.827683401971
INFO:root:current train perplexity11.289371490478516
INFO:root:current mean train loss 6139.507879676271
INFO:root:current train perplexity11.268426895141602
INFO:root:current mean train loss 6136.6910302651195
INFO:root:current train perplexity11.24638843536377
INFO:root:current mean train loss 6138.923973827556
INFO:root:current train perplexity11.24530029296875
INFO:root:current mean train loss 6129.068788094623
INFO:root:current train perplexity11.221747398376465
INFO:root:current mean train loss 6130.4721321871475
INFO:root:current train perplexity11.214563369750977
INFO:root:current mean train loss 6127.90781329154
INFO:root:current train perplexity11.199749946594238

100%|██████████| 1/1 [08:36<00:00, 516.22s/it][A100%|██████████| 1/1 [08:36<00:00, 516.22s/it]
INFO:root:final mean train loss: 6123.315626944265
INFO:root:final train perplexity: 11.199007034301758
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.80s/it][A100%|██████████| 1/1 [00:37<00:00, 37.81s/it]
INFO:root:eval mean loss: 5084.139295212766
INFO:root:eval perplexity: 7.813685417175293
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.30s/it][A100%|██████████| 1/1 [00:37<00:00, 37.30s/it]
INFO:root:eval mean loss: 5916.308011968085
INFO:root:eval perplexity: 11.23753833770752
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/137
 68%|██████▊   | 137/200 [22:32:08<10:21:48, 592.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6130.498530016447
INFO:root:current train perplexity11.06909465789795
INFO:root:current mean train loss 6104.831392728365
INFO:root:current train perplexity11.081459999084473
INFO:root:current mean train loss 6100.684775556144
INFO:root:current train perplexity11.085906982421875
INFO:root:current mean train loss 6090.455367385285
INFO:root:current train perplexity11.068143844604492
INFO:root:current mean train loss 6094.613737965594
INFO:root:current train perplexity11.057622909545898
INFO:root:current mean train loss 6087.096729746586
INFO:root:current train perplexity11.043277740478516
INFO:root:current mean train loss 6080.745327956385
INFO:root:current train perplexity11.025137901306152
INFO:root:current mean train loss 6079.477848000197
INFO:root:current train perplexity11.023347854614258
INFO:root:current mean train loss 6078.376904569658
INFO:root:current train perplexity10.991328239440918

100%|██████████| 1/1 [08:33<00:00, 513.37s/it][A100%|██████████| 1/1 [08:33<00:00, 513.38s/it]
INFO:root:final mean train loss: 6076.017484726444
INFO:root:final train perplexity: 10.991965293884277
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.14s/it][A100%|██████████| 1/1 [00:38<00:00, 38.18s/it]
INFO:root:eval mean loss: 5054.385970744681
INFO:root:eval perplexity: 7.720237731933594
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.98s/it][A100%|██████████| 1/1 [00:36<00:00, 36.98s/it]
INFO:root:eval mean loss: 5887.568321282137
INFO:root:eval perplexity: 11.106245994567871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/138
 69%|██████▉   | 138/200 [22:41:58<10:11:17, 591.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5946.118001302083
INFO:root:current train perplexity10.224851608276367
INFO:root:current mean train loss 6052.306673809163
INFO:root:current train perplexity10.8950834274292
INFO:root:current mean train loss 6034.57362463439
INFO:root:current train perplexity10.843079566955566
INFO:root:current mean train loss 6051.1213886525375
INFO:root:current train perplexity10.874876976013184
INFO:root:current mean train loss 6052.135243001706
INFO:root:current train perplexity10.865117073059082
INFO:root:current mean train loss 6046.569599978256
INFO:root:current train perplexity10.857120513916016
INFO:root:current mean train loss 6048.408045223103
INFO:root:current train perplexity10.849552154541016
INFO:root:current mean train loss 6044.283542074147
INFO:root:current train perplexity10.827261924743652
INFO:root:current mean train loss 6044.100606611924
INFO:root:current train perplexity10.817869186401367
INFO:root:current mean train loss 6042.872722976364
INFO:root:current train perplexity10.816410064697266

100%|██████████| 1/1 [08:33<00:00, 513.15s/it][A100%|██████████| 1/1 [08:33<00:00, 513.15s/it]
INFO:root:final mean train loss: 6034.894799017137
INFO:root:final train perplexity: 10.815069198608398
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.90s/it][A100%|██████████| 1/1 [00:37<00:00, 37.91s/it]
INFO:root:eval mean loss: 5043.779296875
INFO:root:eval perplexity: 7.687195301055908
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.17s/it][A100%|██████████| 1/1 [00:37<00:00, 37.17s/it]
INFO:root:eval mean loss: 5878.5441046099295
INFO:root:eval perplexity: 11.065339088439941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/139
 70%|██████▉   | 139/200 [22:51:48<10:00:50, 590.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5996.793545809659
INFO:root:current train perplexity10.647706985473633
INFO:root:current mean train loss 6014.8947160050675
INFO:root:current train perplexity10.671466827392578
INFO:root:current mean train loss 6026.5315415802725
INFO:root:current train perplexity10.679056167602539
INFO:root:current mean train loss 6029.808163560088
INFO:root:current train perplexity10.702401161193848
INFO:root:current mean train loss 6030.918093493385
INFO:root:current train perplexity10.737677574157715
INFO:root:current mean train loss 6039.40903731195
INFO:root:current train perplexity10.730565071105957
INFO:root:current mean train loss 6038.8299982099015
INFO:root:current train perplexity10.738115310668945
INFO:root:current mean train loss 6027.982195246572
INFO:root:current train perplexity10.722887992858887
INFO:root:current mean train loss 6026.079545892417
INFO:root:current train perplexity10.722746849060059
INFO:root:current mean train loss 6021.793543860627
INFO:root:current train perplexity10.72734260559082

100%|██████████| 1/1 [08:33<00:00, 513.46s/it][A100%|██████████| 1/1 [08:33<00:00, 513.48s/it]
INFO:root:final mean train loss: 6014.565620914583
INFO:root:final train perplexity: 10.728677749633789
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.47s/it][A100%|██████████| 1/1 [00:37<00:00, 37.47s/it]
INFO:root:eval mean loss: 5039.50597365359
INFO:root:eval perplexity: 7.673926830291748
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.12s/it][A100%|██████████| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 5871.937202183068
INFO:root:eval perplexity: 11.035481452941895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/140
 70%|███████   | 140/200 [23:01:38<9:50:33, 590.55s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6061.8401521381575
INFO:root:current train perplexity11.074980735778809
INFO:root:current mean train loss 6023.539608226103
INFO:root:current train perplexity10.812591552734375
INFO:root:current mean train loss 6014.6273767480025
INFO:root:current train perplexity10.76368522644043
INFO:root:current mean train loss 6024.323969252057
INFO:root:current train perplexity10.743438720703125
INFO:root:current mean train loss 6016.581483535949
INFO:root:current train perplexity10.737308502197266
INFO:root:current mean train loss 6016.403665590378
INFO:root:current train perplexity10.740311622619629
INFO:root:current mean train loss 6019.559422802656
INFO:root:current train perplexity10.731568336486816
INFO:root:current mean train loss 6022.000158233006
INFO:root:current train perplexity10.728551864624023
INFO:root:current mean train loss 6018.696690895909
INFO:root:current train perplexity10.715997695922852
INFO:root:current mean train loss 6010.390680788391
INFO:root:current train perplexity10.690211296081543

100%|██████████| 1/1 [08:34<00:00, 514.64s/it][A100%|██████████| 1/1 [08:34<00:00, 514.64s/it]
INFO:root:final mean train loss: 6001.758745870283
INFO:root:final train perplexity: 10.674604415893555
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.94s/it][A100%|██████████| 1/1 [00:37<00:00, 37.96s/it]
INFO:root:eval mean loss: 5022.689768256871
INFO:root:eval perplexity: 7.621917724609375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.92s/it][A100%|██████████| 1/1 [00:36<00:00, 36.94s/it]
INFO:root:eval mean loss: 5856.7166375775705
INFO:root:eval perplexity: 10.967013359069824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/141
 70%|███████   | 141/200 [23:11:29<9:40:50, 590.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6070.3232421875
INFO:root:current train perplexity10.681498527526855
INFO:root:current mean train loss 5979.843192513534
INFO:root:current train perplexity10.625357627868652
INFO:root:current mean train loss 5996.378282454571
INFO:root:current train perplexity10.660943984985352
INFO:root:current mean train loss 6009.119596055523
INFO:root:current train perplexity10.674029350280762
INFO:root:current mean train loss 6003.940159817769
INFO:root:current train perplexity10.65488052368164
INFO:root:current mean train loss 6003.723223286291
INFO:root:current train perplexity10.6591215133667
INFO:root:current mean train loss 6000.28015818132
INFO:root:current train perplexity10.648075103759766
INFO:root:current mean train loss 6005.634877117005
INFO:root:current train perplexity10.65256118774414
INFO:root:current mean train loss 6003.924074332112
INFO:root:current train perplexity10.64948844909668
INFO:root:current mean train loss 6004.599412376955
INFO:root:current train perplexity10.658312797546387

100%|██████████| 1/1 [08:34<00:00, 514.43s/it][A100%|██████████| 1/1 [08:34<00:00, 514.43s/it]
INFO:root:final mean train loss: 5994.669490814209
INFO:root:final train perplexity: 10.644787788391113
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.91s/it][A100%|██████████| 1/1 [00:37<00:00, 37.91s/it]
INFO:root:eval mean loss: 5026.554621703236
INFO:root:eval perplexity: 7.633842468261719
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.29s/it][A100%|██████████| 1/1 [00:37<00:00, 37.29s/it]
INFO:root:eval mean loss: 5860.16085923648
INFO:root:eval perplexity: 10.982466697692871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/142
 71%|███████   | 142/200 [23:21:20<9:31:07, 590.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6080.5314453125
INFO:root:current train perplexity10.627758979797363
INFO:root:current mean train loss 6026.4458224826385
INFO:root:current train perplexity10.592700004577637
INFO:root:current mean train loss 6016.820933759974
INFO:root:current train perplexity10.569365501403809
INFO:root:current mean train loss 5999.330764633862
INFO:root:current train perplexity10.583940505981445
INFO:root:current mean train loss 5999.241639727012
INFO:root:current train perplexity10.61038589477539
INFO:root:current mean train loss 5989.28666125146
INFO:root:current train perplexity10.582283020019531
INFO:root:current mean train loss 5994.086082830955
INFO:root:current train perplexity10.596075057983398
INFO:root:current mean train loss 5999.203799957483
INFO:root:current train perplexity10.615015983581543
INFO:root:current mean train loss 5997.515695756923
INFO:root:current train perplexity10.611924171447754
INFO:root:current mean train loss 5995.3615845379345
INFO:root:current train perplexity10.617023468017578

100%|██████████| 1/1 [08:36<00:00, 516.19s/it][A100%|██████████| 1/1 [08:36<00:00, 516.19s/it]
INFO:root:final mean train loss: 5989.501782571116
INFO:root:final train perplexity: 10.6231107711792
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.63s/it][A100%|██████████| 1/1 [00:37<00:00, 37.63s/it]
INFO:root:eval mean loss: 5013.89842364805
INFO:root:eval perplexity: 7.594873428344727
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.05s/it][A100%|██████████| 1/1 [00:37<00:00, 37.05s/it]
INFO:root:eval mean loss: 5846.206899656471
INFO:root:eval perplexity: 10.919978141784668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/143
 72%|███████▏  | 143/200 [23:31:12<9:21:43, 591.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6045.861793695494
INFO:root:current train perplexity10.723304748535156
INFO:root:current mean train loss 6031.932719624126
INFO:root:current train perplexity10.611795425415039
INFO:root:current mean train loss 6024.236557195216
INFO:root:current train perplexity10.643255233764648
INFO:root:current mean train loss 6019.228689299381
INFO:root:current train perplexity10.660442352294922
INFO:root:current mean train loss 6013.4346364454
INFO:root:current train perplexity10.679672241210938
INFO:root:current mean train loss 6015.66937964002
INFO:root:current train perplexity10.682064056396484
INFO:root:current mean train loss 6010.2585210014095
INFO:root:current train perplexity10.668179512023926
INFO:root:current mean train loss 6004.6596955701125
INFO:root:current train perplexity10.652790069580078
INFO:root:current mean train loss 6000.283198491252
INFO:root:current train perplexity10.652605056762695
INFO:root:current mean train loss 5998.79452886814
INFO:root:current train perplexity10.642620086669922

100%|██████████| 1/1 [08:34<00:00, 514.58s/it][A100%|██████████| 1/1 [08:34<00:00, 514.58s/it]
INFO:root:final mean train loss: 5992.282212780368
INFO:root:final train perplexity: 10.634770393371582
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.85s/it][A100%|██████████| 1/1 [00:37<00:00, 37.87s/it]
INFO:root:eval mean loss: 5016.932485593971
INFO:root:eval perplexity: 7.6041951179504395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.78s/it][A100%|██████████| 1/1 [00:36<00:00, 36.78s/it]
INFO:root:eval mean loss: 5849.789284131206
INFO:root:eval perplexity: 10.935989379882812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/144
 72%|███████▏  | 144/200 [23:41:03<9:11:42, 591.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5976.352902879902
INFO:root:current train perplexity10.557760238647461
INFO:root:current mean train loss 6001.744541597682
INFO:root:current train perplexity10.625154495239258
INFO:root:current mean train loss 6005.455404942729
INFO:root:current train perplexity10.639557838439941
INFO:root:current mean train loss 6008.062790742966
INFO:root:current train perplexity10.66266918182373
INFO:root:current mean train loss 6013.111425564717
INFO:root:current train perplexity10.674179077148438
INFO:root:current mean train loss 6007.543418039644
INFO:root:current train perplexity10.653511047363281
INFO:root:current mean train loss 6004.454535090245
INFO:root:current train perplexity10.642772674560547
INFO:root:current mean train loss 6010.2211465441915
INFO:root:current train perplexity10.658341407775879
INFO:root:current mean train loss 6006.119013247283
INFO:root:current train perplexity10.65720272064209
INFO:root:current mean train loss 6002.8429151468845
INFO:root:current train perplexity10.647513389587402

100%|██████████| 1/1 [08:36<00:00, 516.42s/it][A100%|██████████| 1/1 [08:36<00:00, 516.42s/it]
INFO:root:final mean train loss: 5996.4778454688285
INFO:root:final train perplexity: 10.652386665344238
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.84s/it][A100%|██████████| 1/1 [00:37<00:00, 37.85s/it]
INFO:root:eval mean loss: 5013.589345079788
INFO:root:eval perplexity: 7.593924522399902
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.24s/it][A100%|██████████| 1/1 [00:37<00:00, 37.24s/it]
INFO:root:eval mean loss: 5846.08536264406
INFO:root:eval perplexity: 10.919439315795898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/145
 72%|███████▎  | 145/200 [23:50:56<9:02:21, 591.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6001.698490466101
INFO:root:current train perplexity10.646097183227539
INFO:root:current mean train loss 5982.178182733884
INFO:root:current train perplexity10.581008911132812
INFO:root:current mean train loss 5989.093012864985
INFO:root:current train perplexity10.669464111328125
INFO:root:current mean train loss 5990.351134063806
INFO:root:current train perplexity10.645383834838867
INFO:root:current mean train loss 5990.508467796841
INFO:root:current train perplexity10.640228271484375
INFO:root:current mean train loss 5990.98105835616
INFO:root:current train perplexity10.648628234863281
INFO:root:current mean train loss 5992.877528096547
INFO:root:current train perplexity10.64470386505127
INFO:root:current mean train loss 5994.532353296896
INFO:root:current train perplexity10.648341178894043
INFO:root:current mean train loss 5991.742720687209
INFO:root:current train perplexity10.633715629577637
INFO:root:current mean train loss 5996.76806487878
INFO:root:current train perplexity10.638683319091797

100%|██████████| 1/1 [08:35<00:00, 515.13s/it][A100%|██████████| 1/1 [08:35<00:00, 515.13s/it]
INFO:root:final mean train loss: 5992.670196164039
INFO:root:final train perplexity: 10.636398315429688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.94s/it][A100%|██████████| 1/1 [00:37<00:00, 37.95s/it]
INFO:root:eval mean loss: 5010.472510804521
INFO:root:eval perplexity: 7.584358215332031
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.15s/it][A100%|██████████| 1/1 [00:37<00:00, 37.15s/it]
INFO:root:eval mean loss: 5842.712513159353
INFO:root:eval perplexity: 10.904389381408691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/146
 73%|███████▎  | 146/200 [24:00:48<8:52:31, 591.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6042.064985132929
INFO:root:current train perplexity10.671537399291992
INFO:root:current mean train loss 6019.7404039577095
INFO:root:current train perplexity10.676734924316406
INFO:root:current mean train loss 6007.751152124298
INFO:root:current train perplexity10.668754577636719
INFO:root:current mean train loss 6006.057831392626
INFO:root:current train perplexity10.691564559936523
INFO:root:current mean train loss 6012.944106957641
INFO:root:current train perplexity10.696796417236328
INFO:root:current mean train loss 6007.368296682099
INFO:root:current train perplexity10.694567680358887
INFO:root:current mean train loss 6007.82892879732
INFO:root:current train perplexity10.699732780456543
INFO:root:current mean train loss 6009.192968495356
INFO:root:current train perplexity10.696534156799316
INFO:root:current mean train loss 6010.413133245026
INFO:root:current train perplexity10.690096855163574
INFO:root:current mean train loss 6006.787062920113
INFO:root:current train perplexity10.673016548156738

100%|██████████| 1/1 [08:34<00:00, 514.41s/it][A100%|██████████| 1/1 [08:34<00:00, 514.41s/it]
INFO:root:final mean train loss: 5999.639583341537
INFO:root:final train perplexity: 10.665682792663574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.73s/it][A100%|██████████| 1/1 [00:37<00:00, 37.73s/it]
INFO:root:eval mean loss: 5012.683115857712
INFO:root:eval perplexity: 7.59113883972168
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.69s/it][A100%|██████████| 1/1 [00:36<00:00, 36.69s/it]
INFO:root:eval mean loss: 5848.598580867686
INFO:root:eval perplexity: 10.930665969848633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/147
 74%|███████▎  | 147/200 [24:10:38<8:42:17, 591.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6018.361165364583
INFO:root:current train perplexity10.770730018615723
INFO:root:current mean train loss 5996.844098772322
INFO:root:current train perplexity10.717750549316406
INFO:root:current mean train loss 6023.347693536932
INFO:root:current train perplexity10.73997688293457
INFO:root:current mean train loss 6019.297462239583
INFO:root:current train perplexity10.722376823425293
INFO:root:current mean train loss 6016.5122265625
INFO:root:current train perplexity10.727771759033203
INFO:root:current mean train loss 6015.185405061141
INFO:root:current train perplexity10.715999603271484
INFO:root:current mean train loss 6012.01126808449
INFO:root:current train perplexity10.709290504455566
INFO:root:current mean train loss 6016.930047253024
INFO:root:current train perplexity10.715361595153809
INFO:root:current mean train loss 6017.961370535714
INFO:root:current train perplexity10.72039794921875
INFO:root:current mean train loss 6016.345177283654
INFO:root:current train perplexity10.718023300170898

100%|██████████| 1/1 [08:37<00:00, 517.35s/it][A100%|██████████| 1/1 [08:37<00:00, 517.35s/it]
INFO:root:final mean train loss: 6012.225192654518
INFO:root:final train perplexity: 10.718772888183594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.79s/it][A100%|██████████| 1/1 [00:37<00:00, 37.81s/it]
INFO:root:eval mean loss: 5009.797339040337
INFO:root:eval perplexity: 7.582286357879639
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.93s/it][A100%|██████████| 1/1 [00:36<00:00, 36.93s/it]
INFO:root:eval mean loss: 5838.55567791445
INFO:root:eval perplexity: 10.885870933532715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/148
 74%|███████▍  | 148/200 [24:20:31<8:33:02, 591.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6055.972456231175
INFO:root:current train perplexity10.930264472961426
INFO:root:current mean train loss 6017.6927510245905
INFO:root:current train perplexity10.81146240234375
INFO:root:current mean train loss 6023.224752581162
INFO:root:current train perplexity10.804901123046875
INFO:root:current mean train loss 6040.241442966711
INFO:root:current train perplexity10.805512428283691
INFO:root:current mean train loss 6039.756652958398
INFO:root:current train perplexity10.776236534118652
INFO:root:current mean train loss 6031.828640082279
INFO:root:current train perplexity10.777649879455566
INFO:root:current mean train loss 6030.098644965913
INFO:root:current train perplexity10.765069007873535
INFO:root:current mean train loss 6026.847650637572
INFO:root:current train perplexity10.771615982055664
INFO:root:current mean train loss 6028.098643319118
INFO:root:current train perplexity10.77108383178711
INFO:root:current mean train loss 6033.231452266658
INFO:root:current train perplexity10.787416458129883

100%|██████████| 1/1 [08:36<00:00, 516.71s/it][A100%|██████████| 1/1 [08:36<00:00, 516.71s/it]
INFO:root:final mean train loss: 6028.316999620007
INFO:root:final train perplexity: 10.787040710449219
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.11s/it][A100%|██████████| 1/1 [00:38<00:00, 38.13s/it]
INFO:root:eval mean loss: 5021.344972434619
INFO:root:eval perplexity: 7.6177778244018555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.90s/it][A100%|██████████| 1/1 [00:36<00:00, 36.90s/it]
INFO:root:eval mean loss: 5850.6844110150705
INFO:root:eval perplexity: 10.939994812011719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/149
 74%|███████▍  | 149/200 [24:30:25<8:23:29, 592.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6019.204391311813
INFO:root:current train perplexity10.761822700500488
INFO:root:current mean train loss 6012.352656659032
INFO:root:current train perplexity10.774762153625488
INFO:root:current mean train loss 6040.986943929875
INFO:root:current train perplexity10.82215690612793
INFO:root:current mean train loss 6039.660087565937
INFO:root:current train perplexity10.82980728149414
INFO:root:current mean train loss 6047.534385541306
INFO:root:current train perplexity10.853950500488281
INFO:root:current mean train loss 6051.417235088832
INFO:root:current train perplexity10.85952091217041
INFO:root:current mean train loss 6051.545495658466
INFO:root:current train perplexity10.859122276306152
INFO:root:current mean train loss 6050.109164502015
INFO:root:current train perplexity10.854765892028809
INFO:root:current mean train loss 6051.331017970504
INFO:root:current train perplexity10.86206340789795
INFO:root:current mean train loss 6048.596803359139
INFO:root:current train perplexity10.853601455688477

100%|██████████| 1/1 [08:35<00:00, 515.03s/it][A100%|██████████| 1/1 [08:35<00:00, 515.03s/it]
INFO:root:final mean train loss: 6043.968918708063
INFO:root:final train perplexity: 10.853857040405273
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.87s/it][A100%|██████████| 1/1 [00:37<00:00, 37.89s/it]
INFO:root:eval mean loss: 5022.858187195257
INFO:root:eval perplexity: 7.622439384460449
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.02s/it][A100%|██████████| 1/1 [00:37<00:00, 37.04s/it]
INFO:root:eval mean loss: 5855.781783300089
INFO:root:eval perplexity: 10.962820053100586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/150
 75%|███████▌  | 150/200 [24:40:16<8:13:23, 592.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6055.47929983428
INFO:root:current train perplexity10.899123191833496
INFO:root:current mean train loss 6041.776921717965
INFO:root:current train perplexity10.854170799255371
INFO:root:current mean train loss 6052.961139997909
INFO:root:current train perplexity10.86424732208252
INFO:root:current mean train loss 6069.355336583647
INFO:root:current train perplexity10.899718284606934
INFO:root:current mean train loss 6064.959953109344
INFO:root:current train perplexity10.909795761108398
INFO:root:current mean train loss 6064.273578522799
INFO:root:current train perplexity10.905237197875977
INFO:root:current mean train loss 6064.164109302352
INFO:root:current train perplexity10.909356117248535
INFO:root:current mean train loss 6065.5818387486315
INFO:root:current train perplexity10.919650077819824
INFO:root:current mean train loss 6068.561678231889
INFO:root:current train perplexity10.931544303894043

100%|██████████| 1/1 [08:34<00:00, 514.66s/it][A100%|██████████| 1/1 [08:34<00:00, 514.69s/it]
INFO:root:final mean train loss: 6061.892684936523
INFO:root:final train perplexity: 10.930885314941406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.77s/it][A100%|██████████| 1/1 [00:37<00:00, 37.78s/it]
INFO:root:eval mean loss: 5030.2054071088205
INFO:root:eval perplexity: 7.645118713378906
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.02s/it][A100%|██████████| 1/1 [00:37<00:00, 37.05s/it]
INFO:root:eval mean loss: 5859.189009862589
INFO:root:eval perplexity: 10.978105545043945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/151
 76%|███████▌  | 151/200 [24:50:07<8:03:14, 591.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6020.467494419643
INFO:root:current train perplexity11.201597213745117
INFO:root:current mean train loss 6119.878025518399
INFO:root:current train perplexity11.114876747131348
INFO:root:current mean train loss 6113.393943897192
INFO:root:current train perplexity11.121930122375488
INFO:root:current mean train loss 6112.446543541328
INFO:root:current train perplexity11.180887222290039
INFO:root:current mean train loss 6118.381955908323
INFO:root:current train perplexity11.170905113220215
INFO:root:current mean train loss 6124.729143552761
INFO:root:current train perplexity11.202767372131348
INFO:root:current mean train loss 6128.710130669532
INFO:root:current train perplexity11.233452796936035
INFO:root:current mean train loss 6137.091605568202
INFO:root:current train perplexity11.262453079223633
INFO:root:current mean train loss 6145.923285388592
INFO:root:current train perplexity11.286368370056152
INFO:root:current mean train loss 6152.507748436638
INFO:root:current train perplexity11.322783470153809

100%|██████████| 1/1 [08:34<00:00, 514.89s/it][A100%|██████████| 1/1 [08:34<00:00, 514.90s/it]
INFO:root:final mean train loss: 6155.836660569714
INFO:root:final train perplexity: 11.343622207641602
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.54s/it][A100%|██████████| 1/1 [00:38<00:00, 38.55s/it]
INFO:root:eval mean loss: 5048.939068733378
INFO:root:eval perplexity: 7.703254699707031
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.85s/it][A100%|██████████| 1/1 [00:36<00:00, 36.88s/it]
INFO:root:eval mean loss: 5877.676809757314
INFO:root:eval perplexity: 11.06141471862793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/152
 76%|███████▌  | 152/200 [24:59:59<7:53:24, 591.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6197.1697265625
INFO:root:current train perplexity11.507197380065918
INFO:root:current mean train loss 6196.413090183424
INFO:root:current train perplexity11.495515823364258
INFO:root:current mean train loss 6204.420946130087
INFO:root:current train perplexity11.521927833557129
INFO:root:current mean train loss 6211.8958984375
INFO:root:current train perplexity11.531593322753906
INFO:root:current mean train loss 6217.947503294427
INFO:root:current train perplexity11.591179847717285
INFO:root:current mean train loss 6220.667064244539
INFO:root:current train perplexity11.602293968200684
INFO:root:current mean train loss 6223.380380621189
INFO:root:current train perplexity11.615690231323242
INFO:root:current mean train loss 6229.7806579163025
INFO:root:current train perplexity11.646716117858887
INFO:root:current mean train loss 6231.002415045054
INFO:root:current train perplexity11.654212951660156
INFO:root:current mean train loss 6230.107111829747
INFO:root:current train perplexity11.662899017333984

100%|██████████| 1/1 [08:35<00:00, 515.67s/it][A100%|██████████| 1/1 [08:35<00:00, 515.67s/it]
INFO:root:final mean train loss: 6230.263643203243
INFO:root:final train perplexity: 11.681653022766113
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.83s/it][A100%|██████████| 1/1 [00:37<00:00, 37.83s/it]
INFO:root:eval mean loss: 5056.6000838043
INFO:root:eval perplexity: 7.72715425491333
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.39s/it][A100%|██████████| 1/1 [00:37<00:00, 37.39s/it]
INFO:root:eval mean loss: 5880.923859291888
INFO:root:eval perplexity: 11.07611083984375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/153
 76%|███████▋  | 153/200 [25:09:51<7:43:41, 591.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6346.282820991848
INFO:root:current train perplexity12.308744430541992
INFO:root:current mean train loss 6305.611018483231
INFO:root:current train perplexity12.027997016906738
INFO:root:current mean train loss 6298.551429372197
INFO:root:current train perplexity11.944015502929688
INFO:root:current mean train loss 6283.348421173568
INFO:root:current train perplexity11.873921394348145
INFO:root:current mean train loss 6272.470319887707
INFO:root:current train perplexity11.822808265686035
INFO:root:current mean train loss 6274.325274669874
INFO:root:current train perplexity11.838936805725098
INFO:root:current mean train loss 6271.135150450191
INFO:root:current train perplexity11.831809043884277
INFO:root:current mean train loss 6273.346631737336
INFO:root:current train perplexity11.843205451965332
INFO:root:current mean train loss 6275.067608264353
INFO:root:current train perplexity11.846619606018066
INFO:root:current mean train loss 6270.879345861829
INFO:root:current train perplexity11.843111991882324

100%|██████████| 1/1 [08:34<00:00, 514.28s/it][A100%|██████████| 1/1 [08:34<00:00, 514.28s/it]
INFO:root:final mean train loss: 6267.015300750732
INFO:root:final train perplexity: 11.852264404296875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.85s/it][A100%|██████████| 1/1 [00:37<00:00, 37.85s/it]
INFO:root:eval mean loss: 5080.288051307624
INFO:root:eval perplexity: 7.801526069641113
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.26s/it][A100%|██████████| 1/1 [00:37<00:00, 37.28s/it]
INFO:root:eval mean loss: 5899.572431848404
INFO:root:eval perplexity: 11.160895347595215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/154
 77%|███████▋  | 154/200 [25:19:42<7:33:35, 591.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6248.999417212702
INFO:root:current train perplexity11.903268814086914
INFO:root:current mean train loss 6281.197000984017
INFO:root:current train perplexity11.943855285644531
INFO:root:current mean train loss 6273.895805854302
INFO:root:current train perplexity11.854174613952637
INFO:root:current mean train loss 6272.340846865559
INFO:root:current train perplexity11.823262214660645
INFO:root:current mean train loss 6279.4086415585125
INFO:root:current train perplexity11.852945327758789
INFO:root:current mean train loss 6277.887162892832
INFO:root:current train perplexity11.84936809539795
INFO:root:current mean train loss 6276.45130729373
INFO:root:current train perplexity11.839447975158691
INFO:root:current mean train loss 6276.552505263551
INFO:root:current train perplexity11.829834938049316
INFO:root:current mean train loss 6273.103493296856
INFO:root:current train perplexity11.841565132141113
INFO:root:current mean train loss 6272.742705676021
INFO:root:current train perplexity11.848687171936035

100%|██████████| 1/1 [08:33<00:00, 513.70s/it][A100%|██████████| 1/1 [08:33<00:00, 513.70s/it]
INFO:root:final mean train loss: 6266.462221699377
INFO:root:final train perplexity: 11.849676132202148
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.21s/it][A100%|██████████| 1/1 [00:38<00:00, 38.22s/it]
INFO:root:eval mean loss: 5075.163342198582
INFO:root:eval perplexity: 7.785375595092773
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.49s/it][A100%|██████████| 1/1 [00:37<00:00, 37.55s/it]
INFO:root:eval mean loss: 5893.466530224956
INFO:root:eval perplexity: 11.133062362670898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/155
 78%|███████▊  | 155/200 [25:29:33<7:23:34, 591.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6264.442983774038
INFO:root:current train perplexity11.90332317352295
INFO:root:current mean train loss 6271.153984234487
INFO:root:current train perplexity11.855969429016113
INFO:root:current mean train loss 6287.846945279812
INFO:root:current train perplexity11.918328285217285
INFO:root:current mean train loss 6282.950722483407
INFO:root:current train perplexity11.8846435546875
INFO:root:current mean train loss 6292.772261843323
INFO:root:current train perplexity11.905051231384277
INFO:root:current mean train loss 6290.805747405497
INFO:root:current train perplexity11.928897857666016
INFO:root:current mean train loss 6287.790991172731
INFO:root:current train perplexity11.92123031616211
INFO:root:current mean train loss 6288.720872933229
INFO:root:current train perplexity11.932538986206055
INFO:root:current mean train loss 6288.716279494748
INFO:root:current train perplexity11.934715270996094
INFO:root:current mean train loss 6289.610769123569
INFO:root:current train perplexity11.927885055541992

100%|██████████| 1/1 [08:35<00:00, 515.37s/it][A100%|██████████| 1/1 [08:35<00:00, 515.37s/it]
INFO:root:final mean train loss: 6282.060468981343
INFO:root:final train perplexity: 11.92282485961914
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.53s/it][A100%|██████████| 1/1 [00:37<00:00, 37.56s/it]
INFO:root:eval mean loss: 5109.36297997008
INFO:root:eval perplexity: 7.893789291381836
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.06s/it][A100%|██████████| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 5931.5442742963205
INFO:root:eval perplexity: 11.307767868041992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/156
 78%|███████▊  | 156/200 [25:39:25<7:13:43, 591.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6240.272866107048
INFO:root:current train perplexity11.933563232421875
INFO:root:current mean train loss 6286.339166135204
INFO:root:current train perplexity11.947598457336426
INFO:root:current mean train loss 6290.263598731655
INFO:root:current train perplexity11.89406681060791
INFO:root:current mean train loss 6283.176214652378
INFO:root:current train perplexity11.902270317077637
INFO:root:current mean train loss 6295.8361800020975
INFO:root:current train perplexity11.95926284790039
INFO:root:current mean train loss 6305.578802523709
INFO:root:current train perplexity11.973708152770996
INFO:root:current mean train loss 6302.133223803371
INFO:root:current train perplexity11.975691795349121
INFO:root:current mean train loss 6324.135297701221
INFO:root:current train perplexity12.07345199584961
INFO:root:current mean train loss 6360.664586523207
INFO:root:current train perplexity12.25291633605957
INFO:root:current mean train loss 6456.593784030161
INFO:root:current train perplexity12.74694538116455

100%|██████████| 1/1 [08:37<00:00, 517.89s/it][A100%|██████████| 1/1 [08:37<00:00, 517.89s/it]
INFO:root:final mean train loss: 6547.969492389309
INFO:root:final train perplexity: 13.241601943969727
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.53s/it][A100%|██████████| 1/1 [00:37<00:00, 37.53s/it]
INFO:root:eval mean loss: 6098.399891954788
INFO:root:eval perplexity: 11.775415420532227
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.97s/it][A100%|██████████| 1/1 [00:36<00:00, 36.98s/it]
INFO:root:eval mean loss: 6768.275075493129
INFO:root:eval perplexity: 15.921029090881348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/157
 78%|███████▊  | 157/200 [25:49:18<7:04:23, 592.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8970.664124644887
INFO:root:current train perplexity34.28099822998047
INFO:root:current mean train loss 10059.500721396169
INFO:root:current train perplexity53.09463882446289
INFO:root:current mean train loss 11422.203590303308
INFO:root:current train perplexity91.22161102294922
INFO:root:current mean train loss 12091.862050231073
INFO:root:current train perplexity119.41669464111328
INFO:root:current mean train loss 12471.151029146635
INFO:root:current train perplexity138.27560424804688
INFO:root:current mean train loss 12710.061587661881
INFO:root:current train perplexity151.23458862304688
INFO:root:current mean train loss 12863.77022080749
INFO:root:current train perplexity159.95668029785156
INFO:root:current mean train loss 12961.339386511796
INFO:root:current train perplexity166.113037109375
INFO:root:current mean train loss 13028.019467859101
INFO:root:current train perplexity170.7177734375
INFO:root:current mean train loss 13088.77857851358
INFO:root:current train perplexity174.36634826660156

100%|██████████| 1/1 [08:37<00:00, 517.55s/it][A100%|██████████| 1/1 [08:37<00:00, 517.55s/it]
INFO:root:final mean train loss: 13097.576661632907
INFO:root:final train perplexity: 175.45326232910156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.05s/it][A100%|██████████| 1/1 [00:38<00:00, 38.05s/it]
INFO:root:eval mean loss: 13035.024919658688
INFO:root:eval perplexity: 194.60693359375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.29s/it][A100%|██████████| 1/1 [00:37<00:00, 37.30s/it]
INFO:root:eval mean loss: 13240.335653535018
INFO:root:eval perplexity: 224.5628204345703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/158
 79%|███████▉  | 158/200 [25:59:13<6:55:00, 592.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13489.82533482143
INFO:root:current train perplexity207.0064239501953
INFO:root:current mean train loss 13483.330683234279
INFO:root:current train perplexity206.6463623046875
INFO:root:current mean train loss 13470.082985533507
INFO:root:current train perplexity206.36325073242188
INFO:root:current mean train loss 13489.03839262655
INFO:root:current train perplexity206.21649169921875
INFO:root:current mean train loss 13506.77193574514
INFO:root:current train perplexity206.3085479736328
INFO:root:current mean train loss 13499.060657887434
INFO:root:current train perplexity205.8010711669922
INFO:root:current mean train loss 13497.738820347851
INFO:root:current train perplexity205.47120666503906
INFO:root:current mean train loss 13505.250053755733
INFO:root:current train perplexity205.42047119140625
INFO:root:current mean train loss 13505.240195900928
INFO:root:current train perplexity205.2009735107422
INFO:root:current mean train loss 13507.306862709307
INFO:root:current train perplexity205.06344604492188

100%|██████████| 1/1 [08:35<00:00, 515.12s/it][A100%|██████████| 1/1 [08:35<00:00, 515.12s/it]
INFO:root:final mean train loss: 13490.71547009868
INFO:root:final train perplexity: 204.89083862304688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.14s/it][A100%|██████████| 1/1 [00:38<00:00, 38.17s/it]
INFO:root:eval mean loss: 13028.646747562057
INFO:root:eval perplexity: 194.10565185546875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.16s/it][A100%|██████████| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 13226.736591312057
INFO:root:eval perplexity: 223.31741333007812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/159
 80%|███████▉  | 159/200 [26:09:05<6:44:56, 592.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13411.430237676057
INFO:root:current train perplexity201.1460723876953
INFO:root:current mean train loss 13448.331477293494
INFO:root:current train perplexity201.6741943359375
INFO:root:current mean train loss 13469.587919453414
INFO:root:current train perplexity201.8679656982422
INFO:root:current mean train loss 13471.724925244273
INFO:root:current train perplexity201.8555450439453
INFO:root:current mean train loss 13452.082520567941
INFO:root:current train perplexity201.60409545898438
INFO:root:current mean train loss 13457.625636219353
INFO:root:current train perplexity201.669677734375
INFO:root:current mean train loss 13466.907165436382
INFO:root:current train perplexity201.53643798828125
INFO:root:current mean train loss 13457.395580009728
INFO:root:current train perplexity200.9946746826172
INFO:root:current mean train loss 13448.073887996914
INFO:root:current train perplexity200.7589569091797
INFO:root:current mean train loss 13445.218384920507
INFO:root:current train perplexity200.58633422851562

100%|██████████| 1/1 [08:37<00:00, 517.53s/it][A100%|██████████| 1/1 [08:37<00:00, 517.53s/it]
INFO:root:final mean train loss: 13437.352985259025
INFO:root:final train perplexity: 200.6223907470703
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.18s/it][A100%|██████████| 1/1 [00:38<00:00, 38.21s/it]
INFO:root:eval mean loss: 13026.651574966756
INFO:root:eval perplexity: 193.9490966796875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.12s/it][A100%|██████████| 1/1 [00:37<00:00, 37.13s/it]
INFO:root:eval mean loss: 13223.993157136525
INFO:root:eval perplexity: 223.0670928955078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/160
 80%|████████  | 160/200 [26:18:59<6:35:25, 593.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13513.154778975475
INFO:root:current train perplexity200.59274291992188
INFO:root:current mean train loss 13428.90734658694
INFO:root:current train perplexity198.33584594726562
INFO:root:current mean train loss 13393.829017557124
INFO:root:current train perplexity197.21041870117188
INFO:root:current mean train loss 13409.854958566952
INFO:root:current train perplexity197.5937957763672
INFO:root:current mean train loss 13395.089071062761
INFO:root:current train perplexity197.36093139648438
INFO:root:current mean train loss 13401.151402606865
INFO:root:current train perplexity197.44357299804688
INFO:root:current mean train loss 13415.100923923048
INFO:root:current train perplexity197.45750427246094
INFO:root:current mean train loss 13401.077420470956
INFO:root:current train perplexity197.23655700683594
INFO:root:current mean train loss 13401.661783854166
INFO:root:current train perplexity197.20420837402344
INFO:root:current mean train loss 13404.812279550242
INFO:root:current train perplexity197.1994171142578

100%|██████████| 1/1 [08:38<00:00, 518.10s/it][A100%|██████████| 1/1 [08:38<00:00, 518.10s/it]
INFO:root:final mean train loss: 13393.907237637428
INFO:root:final train perplexity: 197.21295166015625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.90s/it][A100%|██████████| 1/1 [00:37<00:00, 37.92s/it]
INFO:root:eval mean loss: 12975.99589289672
INFO:root:eval perplexity: 190.01666259765625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.26s/it][A100%|██████████| 1/1 [00:37<00:00, 37.29s/it]
INFO:root:eval mean loss: 13181.46989971188
INFO:root:eval perplexity: 219.2217559814453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/161
 80%|████████  | 161/200 [26:28:54<6:25:52, 593.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13463.144452676006
INFO:root:current train perplexity197.7123565673828
INFO:root:current mean train loss 13406.060990767046
INFO:root:current train perplexity197.91317749023438
INFO:root:current mean train loss 13430.120532311628
INFO:root:current train perplexity198.93426513671875
INFO:root:current mean train loss 13440.867894056848
INFO:root:current train perplexity199.49862670898438
INFO:root:current mean train loss 13430.544807575077
INFO:root:current train perplexity199.09426879882812
INFO:root:current mean train loss 13440.474388109562
INFO:root:current train perplexity199.35086059570312
INFO:root:current mean train loss 13429.798452852074
INFO:root:current train perplexity199.26968383789062
INFO:root:current mean train loss 13436.609002739835
INFO:root:current train perplexity199.3402099609375
INFO:root:current mean train loss 13424.366214240417
INFO:root:current train perplexity199.26123046875
INFO:root:current mean train loss 13430.184949262284
INFO:root:current train perplexity199.28024291992188

100%|██████████| 1/1 [08:37<00:00, 517.05s/it][A100%|██████████| 1/1 [08:37<00:00, 517.05s/it]
INFO:root:final mean train loss: 13420.655622420772
INFO:root:final train perplexity: 199.3051300048828
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.98s/it][A100%|██████████| 1/1 [00:37<00:00, 37.98s/it]
INFO:root:eval mean loss: 13021.476929576684
INFO:root:eval perplexity: 193.5436248779297
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.10s/it][A100%|██████████| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 13220.231556128103
INFO:root:eval perplexity: 222.72433471679688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/162
 81%|████████  | 162/200 [26:38:48<6:15:58, 593.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13523.567403371711
INFO:root:current train perplexity201.5753631591797
INFO:root:current mean train loss 13506.630473758012
INFO:root:current train perplexity200.96209716796875
INFO:root:current mean train loss 13469.058047537077
INFO:root:current train perplexity200.29978942871094
INFO:root:current mean train loss 13458.930928599684
INFO:root:current train perplexity200.30331420898438
INFO:root:current mean train loss 13460.25676886048
INFO:root:current train perplexity200.3927459716797
INFO:root:current mean train loss 13464.68214121586
INFO:root:current train perplexity200.287841796875
INFO:root:current mean train loss 13455.339981452338
INFO:root:current train perplexity200.17117309570312
INFO:root:current mean train loss 13446.960328223271
INFO:root:current train perplexity200.08653259277344
INFO:root:current mean train loss 13442.950655769902
INFO:root:current train perplexity199.97007751464844

100%|██████████| 1/1 [08:37<00:00, 517.67s/it][A100%|██████████| 1/1 [08:37<00:00, 517.68s/it]
INFO:root:final mean train loss: 13428.680653972011
INFO:root:final train perplexity: 199.9371795654297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.07s/it][A100%|██████████| 1/1 [00:38<00:00, 38.08s/it]
INFO:root:eval mean loss: 13020.920766843972
INFO:root:eval perplexity: 193.50015258789062
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.02s/it][A100%|██████████| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 13220.992326019503
INFO:root:eval perplexity: 222.7935791015625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/163
 82%|████████▏ | 163/200 [26:48:42<6:06:11, 593.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13257.127278645834
INFO:root:current train perplexity190.50048828125
INFO:root:current mean train loss 13393.018146996359
INFO:root:current train perplexity199.5086212158203
INFO:root:current mean train loss 13431.45916236915
INFO:root:current train perplexity199.83042907714844
INFO:root:current mean train loss 13468.251363319925
INFO:root:current train perplexity200.29730224609375
INFO:root:current mean train loss 13456.276798522798
INFO:root:current train perplexity200.16650390625
INFO:root:current mean train loss 13451.483870216203
INFO:root:current train perplexity199.73411560058594
INFO:root:current mean train loss 13438.250113365464
INFO:root:current train perplexity199.5362091064453
INFO:root:current mean train loss 13439.197630967728
INFO:root:current train perplexity199.55352783203125
INFO:root:current mean train loss 13432.899173266267
INFO:root:current train perplexity199.53192138671875
INFO:root:current mean train loss 13436.976594943937
INFO:root:current train perplexity199.60006713867188

100%|██████████| 1/1 [08:38<00:00, 518.04s/it][A100%|██████████| 1/1 [08:38<00:00, 518.08s/it]
INFO:root:final mean train loss: 13424.92118441674
INFO:root:final train perplexity: 199.6407012939453
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.66s/it][A100%|██████████| 1/1 [00:38<00:00, 38.68s/it]
INFO:root:eval mean loss: 13020.25469581117
INFO:root:eval perplexity: 193.44802856445312
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.05s/it][A100%|██████████| 1/1 [00:37<00:00, 37.06s/it]
INFO:root:eval mean loss: 13220.053987976507
INFO:root:eval perplexity: 222.70797729492188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/164
 82%|████████▏ | 164/200 [26:58:37<5:56:34, 594.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13604.4423828125
INFO:root:current train perplexity203.01747131347656
INFO:root:current mean train loss 13439.50146044482
INFO:root:current train perplexity200.42283630371094
INFO:root:current mean train loss 13466.15174670468
INFO:root:current train perplexity199.97340393066406
INFO:root:current mean train loss 13421.02901740856
INFO:root:current train perplexity199.1724090576172
INFO:root:current mean train loss 13425.329892791971
INFO:root:current train perplexity199.117431640625
INFO:root:current mean train loss 13416.119643239359
INFO:root:current train perplexity198.98995971679688
INFO:root:current mean train loss 13421.124996803395
INFO:root:current train perplexity199.11619567871094
INFO:root:current mean train loss 13411.796648371572
INFO:root:current train perplexity199.1620635986328
INFO:root:current mean train loss 13418.997562808261
INFO:root:current train perplexity199.20252990722656
INFO:root:current mean train loss 13425.722814901208
INFO:root:current train perplexity199.1958770751953

100%|██████████| 1/1 [08:38<00:00, 518.52s/it][A100%|██████████| 1/1 [08:38<00:00, 518.54s/it]
INFO:root:final mean train loss: 13418.003410831574
INFO:root:final train perplexity: 199.0966339111328
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.66s/it][A100%|██████████| 1/1 [00:39<00:00, 39.67s/it]
INFO:root:eval mean loss: 13013.018838652482
INFO:root:eval perplexity: 192.8827667236328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.63s/it][A100%|██████████| 1/1 [00:37<00:00, 37.65s/it]
INFO:root:eval mean loss: 13212.977303579344
INFO:root:eval perplexity: 222.0646209716797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/165
 82%|████████▎ | 165/200 [27:08:35<5:47:11, 595.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13150.439504523027
INFO:root:current train perplexity196.2530059814453
INFO:root:current mean train loss 13370.30044478729
INFO:root:current train perplexity199.4029541015625
INFO:root:current mean train loss 13437.657150756278
INFO:root:current train perplexity199.34800720214844
INFO:root:current mean train loss 13412.03792062598
INFO:root:current train perplexity198.7147979736328
INFO:root:current mean train loss 13424.386765363963
INFO:root:current train perplexity198.8551788330078
INFO:root:current mean train loss 13424.590477857057
INFO:root:current train perplexity198.65415954589844
INFO:root:current mean train loss 13430.854615243841
INFO:root:current train perplexity198.71554565429688
INFO:root:current mean train loss 13411.76901376695
INFO:root:current train perplexity198.38607788085938
INFO:root:current mean train loss 13412.728138831655
INFO:root:current train perplexity198.54458618164062
INFO:root:current mean train loss 13413.381712671722
INFO:root:current train perplexity198.4412384033203

100%|██████████| 1/1 [08:39<00:00, 519.68s/it][A100%|██████████| 1/1 [08:39<00:00, 519.69s/it]
INFO:root:final mean train loss: 13409.745777007072
INFO:root:final train perplexity: 198.44908142089844
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 37.99s/it][A100%|██████████| 1/1 [00:38<00:00, 38.05s/it]
INFO:root:eval mean loss: 13010.21111064938
INFO:root:eval perplexity: 192.6638946533203
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:36<00:00, 36.98s/it][A100%|██████████| 1/1 [00:36<00:00, 36.99s/it]
INFO:root:eval mean loss: 13210.54907053413
INFO:root:eval perplexity: 221.8441619873047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/166
 83%|████████▎ | 166/200 [27:18:31<5:37:28, 595.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13397.546766493055
INFO:root:current train perplexity199.10755920410156
INFO:root:current mean train loss 13501.821181409941
INFO:root:current train perplexity199.97360229492188
INFO:root:current mean train loss 13462.445613642622
INFO:root:current train perplexity199.2252197265625
INFO:root:current mean train loss 13430.23704486812
INFO:root:current train perplexity198.40130615234375
INFO:root:current mean train loss 13436.937838480679
INFO:root:current train perplexity198.657470703125
INFO:root:current mean train loss 13420.778210981973
INFO:root:current train perplexity198.19422912597656
INFO:root:current mean train loss 13422.932361754885
INFO:root:current train perplexity197.81874084472656
INFO:root:current mean train loss 13418.978519654831
INFO:root:current train perplexity197.78883361816406
INFO:root:current mean train loss 13423.641215424728
INFO:root:current train perplexity197.75621032714844
INFO:root:current mean train loss 13406.41055235302
INFO:root:current train perplexity197.39292907714844

100%|██████████| 1/1 [08:41<00:00, 520.99s/it][A100%|██████████| 1/1 [08:41<00:00, 521.03s/it]
INFO:root:final mean train loss: 13394.1421843498
INFO:root:final train perplexity: 197.23109436035156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.85s/it][A100%|██████████| 1/1 [00:38<00:00, 38.86s/it]
INFO:root:eval mean loss: 12991.982027094415
INFO:root:eval perplexity: 191.24900817871094
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.47s/it][A100%|██████████| 1/1 [00:37<00:00, 37.48s/it]
INFO:root:eval mean loss: 13190.392024046985
INFO:root:eval perplexity: 220.02310180664062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/167
 84%|████████▎ | 167/200 [27:28:30<5:28:05, 596.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13519.947600446429
INFO:root:current train perplexity198.48959350585938
INFO:root:current mean train loss 13474.800607638888
INFO:root:current train perplexity197.04901123046875
INFO:root:current mean train loss 13427.223300365691
INFO:root:current train perplexity196.0218963623047
INFO:root:current mean train loss 13418.335430270523
INFO:root:current train perplexity195.37791442871094
INFO:root:current mean train loss 13414.608407417385
INFO:root:current train perplexity195.2855224609375
INFO:root:current mean train loss 13391.803389675817
INFO:root:current train perplexity195.0652313232422
INFO:root:current mean train loss 13372.973051488681
INFO:root:current train perplexity194.83143615722656
INFO:root:current mean train loss 13374.005792942176
INFO:root:current train perplexity194.92056274414062
INFO:root:current mean train loss 13369.890770022455
INFO:root:current train perplexity194.94973754882812
INFO:root:current mean train loss 13376.268506642715
INFO:root:current train perplexity194.8990936279297

100%|██████████| 1/1 [08:40<00:00, 520.34s/it][A100%|██████████| 1/1 [08:40<00:00, 520.34s/it]
INFO:root:final mean train loss: 13363.255493410172
INFO:root:final train perplexity: 194.84231567382812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.89s/it][A100%|██████████| 1/1 [00:38<00:00, 38.92s/it]
INFO:root:eval mean loss: 12982.49177194149
INFO:root:eval perplexity: 190.51638793945312
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:39<00:00, 39.97s/it][A100%|██████████| 1/1 [00:39<00:00, 39.99s/it]
INFO:root:eval mean loss: 13186.519025653812
INFO:root:eval perplexity: 219.6748504638672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/168
 84%|████████▍ | 168/200 [27:38:31<5:18:49, 597.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13350.425599563954
INFO:root:current train perplexity193.435302734375
INFO:root:current mean train loss 13432.510134396853
INFO:root:current train perplexity194.72686767578125
INFO:root:current mean train loss 13393.242099086934
INFO:root:current train perplexity194.53726196289062
INFO:root:current mean train loss 13380.927008359147
INFO:root:current train perplexity194.82809448242188
INFO:root:current mean train loss 13378.332635263827
INFO:root:current train perplexity194.55747985839844
INFO:root:current mean train loss 13380.8630222721
INFO:root:current train perplexity194.52102661132812
INFO:root:current mean train loss 13397.163822535964
INFO:root:current train perplexity194.92556762695312
INFO:root:current mean train loss 13386.724960306612
INFO:root:current train perplexity194.90829467773438
INFO:root:current mean train loss 13369.969574807235
INFO:root:current train perplexity194.63783264160156
INFO:root:current mean train loss 13366.514747854255
INFO:root:current train perplexity194.57203674316406

100%|██████████| 1/1 [08:40<00:00, 520.96s/it][A100%|██████████| 1/1 [08:40<00:00, 520.96s/it]
INFO:root:final mean train loss: 13360.302431660313
INFO:root:final train perplexity: 194.61546325683594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.25s/it][A100%|██████████| 1/1 [00:38<00:00, 38.28s/it]
INFO:root:eval mean loss: 12982.979796930407
INFO:root:eval perplexity: 190.5540008544922
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.01s/it][A100%|██████████| 1/1 [00:37<00:00, 37.05s/it]
INFO:root:eval mean loss: 13186.770577072251
INFO:root:eval perplexity: 219.69747924804688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/169
 84%|████████▍ | 169/200 [27:48:29<5:08:53, 597.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13400.923100490196
INFO:root:current train perplexity192.75376892089844
INFO:root:current mean train loss 13452.349376552153
INFO:root:current train perplexity195.42115783691406
INFO:root:current mean train loss 13424.585634026394
INFO:root:current train perplexity195.49095153808594
INFO:root:current mean train loss 13397.098062455485
INFO:root:current train perplexity194.98487854003906
INFO:root:current mean train loss 13383.589815600748
INFO:root:current train perplexity194.65667724609375
INFO:root:current mean train loss 13371.093136768375
INFO:root:current train perplexity194.59588623046875
INFO:root:current mean train loss 13383.570076984926
INFO:root:current train perplexity194.85885620117188
INFO:root:current mean train loss 13375.8536599638
INFO:root:current train perplexity194.74830627441406
INFO:root:current mean train loss 13370.392795011383
INFO:root:current train perplexity194.630126953125
INFO:root:current mean train loss 13365.852475395965
INFO:root:current train perplexity194.5347442626953

100%|██████████| 1/1 [08:39<00:00, 519.49s/it][A100%|██████████| 1/1 [08:39<00:00, 519.49s/it]
INFO:root:final mean train loss: 13359.986376116352
INFO:root:final train perplexity: 194.59133911132812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.09s/it][A100%|██████████| 1/1 [00:38<00:00, 38.11s/it]
INFO:root:eval mean loss: 12983.22630623892
INFO:root:eval perplexity: 190.572998046875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.32s/it][A100%|██████████| 1/1 [00:37<00:00, 37.33s/it]
INFO:root:eval mean loss: 13187.576843694593
INFO:root:eval perplexity: 219.76998901367188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/170
 85%|████████▌ | 170/200 [27:58:25<4:58:43, 597.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13319.737337791314
INFO:root:current train perplexity194.02078247070312
INFO:root:current mean train loss 13387.132923054245
INFO:root:current train perplexity194.50033569335938
INFO:root:current mean train loss 13379.130840522443
INFO:root:current train perplexity194.1408233642578
INFO:root:current mean train loss 13364.328326297005
INFO:root:current train perplexity194.2521209716797
INFO:root:current mean train loss 13380.011133663535
INFO:root:current train perplexity194.73707580566406
INFO:root:current mean train loss 13377.375576503802
INFO:root:current train perplexity194.57667541503906
INFO:root:current mean train loss 13373.120841829477
INFO:root:current train perplexity194.6129608154297
INFO:root:current mean train loss 13368.92170001647
INFO:root:current train perplexity194.5432891845703
INFO:root:current mean train loss 13360.165414226209
INFO:root:current train perplexity194.3213348388672
INFO:root:current mean train loss 13362.728699939717
INFO:root:current train perplexity194.36599731445312

100%|██████████| 1/1 [08:38<00:00, 518.78s/it][A100%|██████████| 1/1 [08:38<00:00, 518.78s/it]
INFO:root:final mean train loss: 13359.336963776619
INFO:root:final train perplexity: 194.5413360595703
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.97s/it][A100%|██████████| 1/1 [00:38<00:00, 38.98s/it]
INFO:root:eval mean loss: 12984.63321420656
INFO:root:eval perplexity: 190.68161010742188
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.31s/it][A100%|██████████| 1/1 [00:37<00:00, 37.33s/it]
INFO:root:eval mean loss: 13188.21971271055
INFO:root:eval perplexity: 219.82772827148438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/171
 86%|████████▌ | 171/200 [28:08:22<4:48:39, 597.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13511.772213152984
INFO:root:current train perplexity196.63133239746094
INFO:root:current mean train loss 13440.184301319237
INFO:root:current train perplexity196.36439514160156
INFO:root:current mean train loss 13428.54907318001
INFO:root:current train perplexity195.7624053955078
INFO:root:current mean train loss 13403.405840216281
INFO:root:current train perplexity195.2725830078125
INFO:root:current mean train loss 13379.728411067987
INFO:root:current train perplexity195.04029846191406
INFO:root:current mean train loss 13378.224836722884
INFO:root:current train perplexity194.96368408203125
INFO:root:current mean train loss 13384.018014430285
INFO:root:current train perplexity194.86692810058594
INFO:root:current mean train loss 13377.895927976288
INFO:root:current train perplexity194.6238250732422
INFO:root:current mean train loss 13375.938990187067
INFO:root:current train perplexity194.589111328125
INFO:root:current mean train loss 13370.71486091811
INFO:root:current train perplexity194.57603454589844

100%|██████████| 1/1 [08:39<00:00, 519.59s/it][A100%|██████████| 1/1 [08:39<00:00, 519.59s/it]
INFO:root:final mean train loss: 13359.414794675766
INFO:root:final train perplexity: 194.54736328125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.68s/it][A100%|██████████| 1/1 [00:38<00:00, 38.70s/it]
INFO:root:eval mean loss: 12984.05287982048
INFO:root:eval perplexity: 190.63670349121094
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.70s/it][A100%|██████████| 1/1 [00:37<00:00, 37.71s/it]
INFO:root:eval mean loss: 13188.303094525709
INFO:root:eval perplexity: 219.8352813720703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/172
 86%|████████▌ | 172/200 [28:18:19<4:38:43, 597.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13317.528411458334
INFO:root:current train perplexity194.14813232421875
INFO:root:current mean train loss 13324.806640625
INFO:root:current train perplexity193.7612762451172
INFO:root:current mean train loss 13298.857549715909
INFO:root:current train perplexity193.288330078125
INFO:root:current mean train loss 13323.2071328125
INFO:root:current train perplexity193.30087280273438
INFO:root:current mean train loss 13350.764089226974
INFO:root:current train perplexity193.65782165527344
INFO:root:current mean train loss 13353.515383831522
INFO:root:current train perplexity193.9199676513672
INFO:root:current mean train loss 13362.841937210647
INFO:root:current train perplexity193.98582458496094
INFO:root:current mean train loss 13371.840241935484
INFO:root:current train perplexity194.1307373046875
INFO:root:current mean train loss 13367.8585
INFO:root:current train perplexity194.32151794433594
INFO:root:current mean train loss 13368.081036658654
INFO:root:current train perplexity194.4294891357422

100%|██████████| 1/1 [08:39<00:00, 519.64s/it][A100%|██████████| 1/1 [08:39<00:00, 519.64s/it]
INFO:root:final mean train loss: 13357.470237485824
INFO:root:final train perplexity: 194.39816284179688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.98s/it][A100%|██████████| 1/1 [00:38<00:00, 38.99s/it]
INFO:root:eval mean loss: 12983.434805795656
INFO:root:eval perplexity: 190.58917236328125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.44s/it][A100%|██████████| 1/1 [00:37<00:00, 37.46s/it]
INFO:root:eval mean loss: 13187.242208277925
INFO:root:eval perplexity: 219.7399139404297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/173
 86%|████████▋ | 173/200 [28:28:17<4:28:49, 597.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13369.798498682228
INFO:root:current train perplexity194.33319091796875
INFO:root:current mean train loss 13389.663598232582
INFO:root:current train perplexity194.4141082763672
INFO:root:current mean train loss 13377.465640873454
INFO:root:current train perplexity194.26119995117188
INFO:root:current mean train loss 13380.333099604275
INFO:root:current train perplexity194.11351013183594
INFO:root:current mean train loss 13372.107019523162
INFO:root:current train perplexity194.28399658203125
INFO:root:current mean train loss 13360.85634480864
INFO:root:current train perplexity194.33810424804688
INFO:root:current mean train loss 13348.837174288525
INFO:root:current train perplexity194.08380126953125
INFO:root:current mean train loss 13353.69480239264
INFO:root:current train perplexity194.2403564453125
INFO:root:current mean train loss 13360.132116851288
INFO:root:current train perplexity194.3607177734375
INFO:root:current mean train loss 13364.033674020855
INFO:root:current train perplexity194.29307556152344

100%|██████████| 1/1 [08:41<00:00, 521.21s/it][A100%|██████████| 1/1 [08:41<00:00, 521.21s/it]
INFO:root:final mean train loss: 13356.793759007607
INFO:root:final train perplexity: 194.34625244140625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.23s/it][A100%|██████████| 1/1 [00:38<00:00, 38.25s/it]
INFO:root:eval mean loss: 12982.490442154256
INFO:root:eval perplexity: 190.51629638671875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.39s/it][A100%|██████████| 1/1 [00:37<00:00, 37.42s/it]
INFO:root:eval mean loss: 13185.381725121897
INFO:root:eval perplexity: 219.57273864746094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/174
 87%|████████▋ | 174/200 [28:38:15<4:19:00, 597.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13308.918086796017
INFO:root:current train perplexity193.29441833496094
INFO:root:current mean train loss 13387.246466991164
INFO:root:current train perplexity193.89630126953125
INFO:root:current mean train loss 13337.231592971435
INFO:root:current train perplexity193.30612182617188
INFO:root:current mean train loss 13355.35431985294
INFO:root:current train perplexity193.90518188476562
INFO:root:current mean train loss 13359.84696410387
INFO:root:current train perplexity194.0509490966797
INFO:root:current mean train loss 13358.552222134094
INFO:root:current train perplexity193.9409637451172
INFO:root:current mean train loss 13361.643007755969
INFO:root:current train perplexity193.87985229492188
INFO:root:current mean train loss 13368.574748390092
INFO:root:current train perplexity194.08880615234375
INFO:root:current mean train loss 13365.22061982674
INFO:root:current train perplexity194.12054443359375
INFO:root:current mean train loss 13365.869183983981
INFO:root:current train perplexity194.24156188964844

100%|██████████| 1/1 [08:39<00:00, 519.89s/it][A100%|██████████| 1/1 [08:39<00:00, 519.89s/it]
INFO:root:final mean train loss: 13355.443281850507
INFO:root:final train perplexity: 194.24276733398438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.69s/it][A100%|██████████| 1/1 [00:38<00:00, 38.70s/it]
INFO:root:eval mean loss: 12981.219331781915
INFO:root:eval perplexity: 190.4185791015625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.02s/it][A100%|██████████| 1/1 [00:37<00:00, 37.05s/it]
INFO:root:eval mean loss: 13183.099173038563
INFO:root:eval perplexity: 219.36793518066406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/175
 88%|████████▊ | 175/200 [28:48:12<4:08:58, 597.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13437.064176925505
INFO:root:current train perplexity198.43820190429688
INFO:root:current mean train loss 13343.436052331972
INFO:root:current train perplexity196.29763793945312
INFO:root:current mean train loss 13368.629487614966
INFO:root:current train perplexity196.4784698486328
INFO:root:current mean train loss 13380.101697113878
INFO:root:current train perplexity196.09014892578125
INFO:root:current mean train loss 13376.330399079408
INFO:root:current train perplexity195.90023803710938
INFO:root:current mean train loss 13388.416990557178
INFO:root:current train perplexity195.97003173828125
INFO:root:current mean train loss 13380.327588519312
INFO:root:current train perplexity195.69064331054688
INFO:root:current mean train loss 13381.649823509855
INFO:root:current train perplexity195.53533935546875
INFO:root:current mean train loss 13376.723883742352
INFO:root:current train perplexity195.37680053710938

100%|██████████| 1/1 [08:40<00:00, 520.65s/it][A100%|██████████| 1/1 [08:40<00:00, 520.67s/it]
INFO:root:final mean train loss: 13370.587770277454
INFO:root:final train perplexity: 195.40679931640625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.81s/it][A100%|██████████| 1/1 [00:38<00:00, 38.81s/it]
INFO:root:eval mean loss: 12982.519122617465
INFO:root:eval perplexity: 190.51856994628906
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.88s/it][A100%|██████████| 1/1 [00:37<00:00, 37.90s/it]
INFO:root:eval mean loss: 13179.943643339982
INFO:root:eval perplexity: 219.08506774902344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/176
 88%|████████▊ | 176/200 [28:58:11<3:59:10, 597.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13376.908203125
INFO:root:current train perplexity191.51629638671875
INFO:root:current mean train loss 13351.970958674065
INFO:root:current train perplexity195.05276489257812
INFO:root:current mean train loss 13367.521158854166
INFO:root:current train perplexity194.56248474121094
INFO:root:current mean train loss 13369.117550132329
INFO:root:current train perplexity194.23739624023438
INFO:root:current mean train loss 13360.795670492937
INFO:root:current train perplexity194.47354125976562
INFO:root:current mean train loss 13368.200792421721
INFO:root:current train perplexity194.51156616210938
INFO:root:current mean train loss 13366.926329862541
INFO:root:current train perplexity194.32095336914062
INFO:root:current mean train loss 13359.419716064798
INFO:root:current train perplexity194.03115844726562
INFO:root:current mean train loss 13363.396807475605
INFO:root:current train perplexity194.1395263671875
INFO:root:current mean train loss 13360.851413916069
INFO:root:current train perplexity194.1907196044922

100%|██████████| 1/1 [08:37<00:00, 517.95s/it][A100%|██████████| 1/1 [08:37<00:00, 517.96s/it]
INFO:root:final mean train loss: 13356.523015914425
INFO:root:final train perplexity: 194.32550048828125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.19s/it][A100%|██████████| 1/1 [00:38<00:00, 38.20s/it]
INFO:root:eval mean loss: 12973.91462350399
INFO:root:eval perplexity: 189.8568115234375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.66s/it][A100%|██████████| 1/1 [00:37<00:00, 37.67s/it]
INFO:root:eval mean loss: 13175.475648271276
INFO:root:eval perplexity: 218.6851043701172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/177
 88%|████████▊ | 177/200 [29:08:07<3:48:54, 597.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13329.931966145834
INFO:root:current train perplexity191.10633850097656
INFO:root:current mean train loss 13341.3203125
INFO:root:current train perplexity193.32696533203125
INFO:root:current mean train loss 13350.719281431686
INFO:root:current train perplexity194.4889373779297
INFO:root:current mean train loss 13352.168706597222
INFO:root:current train perplexity194.734375
INFO:root:current mean train loss 13358.075510636296
INFO:root:current train perplexity194.2745361328125
INFO:root:current mean train loss 13357.571537469661
INFO:root:current train perplexity193.93125915527344
INFO:root:current mean train loss 13348.342322472054
INFO:root:current train perplexity193.6620635986328
INFO:root:current mean train loss 13353.966339324737
INFO:root:current train perplexity193.8240203857422
INFO:root:current mean train loss 13349.232605205138
INFO:root:current train perplexity193.7711639404297
INFO:root:current mean train loss 13358.47327207138
INFO:root:current train perplexity193.94337463378906

100%|██████████| 1/1 [08:41<00:00, 521.74s/it][A100%|██████████| 1/1 [08:41<00:00, 521.75s/it]
INFO:root:final mean train loss: 13352.883935005435
INFO:root:final train perplexity: 194.04678344726562
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.72s/it][A100%|██████████| 1/1 [00:38<00:00, 38.75s/it]
INFO:root:eval mean loss: 12967.123677138741
INFO:root:eval perplexity: 189.3362579345703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.36s/it][A100%|██████████| 1/1 [00:37<00:00, 37.37s/it]
INFO:root:eval mean loss: 13172.557721077128
INFO:root:eval perplexity: 218.42446899414062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/178
 89%|████████▉ | 178/200 [29:18:06<3:39:12, 597.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13178.490446671196
INFO:root:current train perplexity191.16256713867188
INFO:root:current mean train loss 13373.39957285315
INFO:root:current train perplexity194.4243927001953
INFO:root:current mean train loss 13342.538423136211
INFO:root:current train perplexity194.12841796875
INFO:root:current mean train loss 13349.212857367453
INFO:root:current train perplexity194.03273010253906
INFO:root:current mean train loss 13334.641102892287
INFO:root:current train perplexity193.9492950439453
INFO:root:current mean train loss 13352.227529726339
INFO:root:current train perplexity194.09713745117188
INFO:root:current mean train loss 13346.269238124498
INFO:root:current train perplexity193.9652862548828
INFO:root:current mean train loss 13360.558164224585
INFO:root:current train perplexity194.2194366455078
INFO:root:current mean train loss 13362.086845240356
INFO:root:current train perplexity193.97555541992188
INFO:root:current mean train loss 13354.254934656014
INFO:root:current train perplexity193.91802978515625

100%|██████████| 1/1 [08:40<00:00, 520.58s/it][A100%|██████████| 1/1 [08:40<00:00, 520.61s/it]
INFO:root:final mean train loss: 13350.892818573982
INFO:root:final train perplexity: 193.89427185058594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.07s/it][A100%|██████████| 1/1 [00:38<00:00, 38.09s/it]
INFO:root:eval mean loss: 12961.376371343085
INFO:root:eval perplexity: 188.896728515625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.88s/it][A100%|██████████| 1/1 [00:37<00:00, 37.91s/it]
INFO:root:eval mean loss: 13168.334628490691
INFO:root:eval perplexity: 218.04745483398438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/179
 90%|████████▉ | 179/200 [29:28:04<3:29:16, 597.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13351.39509828629
INFO:root:current train perplexity192.97035217285156
INFO:root:current mean train loss 13387.931223163168
INFO:root:current train perplexity193.48927307128906
INFO:root:current mean train loss 13350.177446902057
INFO:root:current train perplexity193.584228515625
INFO:root:current mean train loss 13351.983100453172
INFO:root:current train perplexity193.59605407714844
INFO:root:current mean train loss 13335.065119272042
INFO:root:current train perplexity193.5821075439453
INFO:root:current mean train loss 13344.17880840984
INFO:root:current train perplexity193.53660583496094
INFO:root:current mean train loss 13346.10993369899
INFO:root:current train perplexity193.6472930908203
INFO:root:current mean train loss 13358.927003623034
INFO:root:current train perplexity193.7912139892578
INFO:root:current mean train loss 13357.705167437574
INFO:root:current train perplexity193.8052520751953
INFO:root:current mean train loss 13358.479984140038
INFO:root:current train perplexity193.76089477539062

100%|██████████| 1/1 [08:40<00:00, 520.45s/it][A100%|██████████| 1/1 [08:40<00:00, 520.46s/it]
INFO:root:final mean train loss: 13349.761381826092
INFO:root:final train perplexity: 193.80784606933594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.81s/it][A100%|██████████| 1/1 [00:37<00:00, 37.85s/it]
INFO:root:eval mean loss: 12955.736328125
INFO:root:eval perplexity: 188.46640014648438
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.52s/it][A100%|██████████| 1/1 [00:37<00:00, 37.54s/it]
INFO:root:eval mean loss: 13163.49732657358
INFO:root:eval perplexity: 217.61669921875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/180
 90%|█████████ | 180/200 [29:38:02<3:19:14, 597.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13504.99456630609
INFO:root:current train perplexity194.53994750976562
INFO:root:current mean train loss 13432.414441883993
INFO:root:current train perplexity195.04049682617188
INFO:root:current mean train loss 13388.218692795503
INFO:root:current train perplexity193.99256896972656
INFO:root:current mean train loss 13392.78096480918
INFO:root:current train perplexity194.16062927246094
INFO:root:current mean train loss 13382.48235069049
INFO:root:current train perplexity194.22451782226562
INFO:root:current mean train loss 13351.74077791628
INFO:root:current train perplexity193.6374053955078
INFO:root:current mean train loss 13349.331036348298
INFO:root:current train perplexity193.6590118408203
INFO:root:current mean train loss 13351.86809006047
INFO:root:current train perplexity193.55055236816406
INFO:root:current mean train loss 13357.09911003613
INFO:root:current train perplexity193.66954040527344
INFO:root:current mean train loss 13356.466685594714
INFO:root:current train perplexity193.64036560058594

100%|██████████| 1/1 [08:36<00:00, 516.32s/it][A100%|██████████| 1/1 [08:36<00:00, 516.32s/it]
INFO:root:final mean train loss: 13347.546342911259
INFO:root:final train perplexity: 193.63851928710938
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.19s/it][A100%|██████████| 1/1 [00:38<00:00, 38.21s/it]
INFO:root:eval mean loss: 12955.28008643617
INFO:root:eval perplexity: 188.43162536621094
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.50s/it][A100%|██████████| 1/1 [00:37<00:00, 37.51s/it]
INFO:root:eval mean loss: 13164.502694204344
INFO:root:eval perplexity: 217.7060546875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/181
 90%|█████████ | 181/200 [29:47:55<3:08:53, 596.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13291.77948387633
INFO:root:current train perplexity192.8045196533203
INFO:root:current mean train loss 13347.937333917942
INFO:root:current train perplexity193.97601318359375
INFO:root:current mean train loss 13350.40260864752
INFO:root:current train perplexity193.97286987304688
INFO:root:current mean train loss 13351.47077911113
INFO:root:current train perplexity193.61358642578125
INFO:root:current mean train loss 13339.042479376398
INFO:root:current train perplexity193.41712951660156
INFO:root:current mean train loss 13336.147980461608
INFO:root:current train perplexity193.4646453857422
INFO:root:current mean train loss 13349.961388801681
INFO:root:current train perplexity193.64923095703125
INFO:root:current mean train loss 13352.78147224314
INFO:root:current train perplexity193.5696563720703
INFO:root:current mean train loss 13356.832836020514
INFO:root:current train perplexity193.6147003173828
INFO:root:current mean train loss 13362.489437244258
INFO:root:current train perplexity193.65846252441406

100%|██████████| 1/1 [08:37<00:00, 517.67s/it][A100%|██████████| 1/1 [08:37<00:00, 517.67s/it]
INFO:root:final mean train loss: 13346.8537565662
INFO:root:final train perplexity: 193.5856170654297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.02s/it][A100%|██████████| 1/1 [00:38<00:00, 38.04s/it]
INFO:root:eval mean loss: 12946.770867963209
INFO:root:eval perplexity: 187.7843780517578
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.27s/it][A100%|██████████| 1/1 [00:37<00:00, 37.29s/it]
INFO:root:eval mean loss: 13155.54661873892
INFO:root:eval perplexity: 216.91026306152344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/182
 91%|█████████ | 182/200 [29:57:50<2:58:46, 595.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13432.8994140625
INFO:root:current train perplexity195.91891479492188
INFO:root:current mean train loss 13426.489226310483
INFO:root:current train perplexity195.53533935546875
INFO:root:current mean train loss 13375.735064338236
INFO:root:current train perplexity194.35107421875
INFO:root:current mean train loss 13356.162948393487
INFO:root:current train perplexity193.58773803710938
INFO:root:current mean train loss 13354.396898609204
INFO:root:current train perplexity193.5485076904297
INFO:root:current mean train loss 13345.080259360924
INFO:root:current train perplexity193.5855255126953
INFO:root:current mean train loss 13345.94102755248
INFO:root:current train perplexity193.49859619140625
INFO:root:current mean train loss 13355.733820105546
INFO:root:current train perplexity193.4121551513672
INFO:root:current mean train loss 13356.413516538743
INFO:root:current train perplexity193.51731872558594
INFO:root:current mean train loss 13358.71430689627
INFO:root:current train perplexity193.59042358398438

100%|██████████| 1/1 [08:40<00:00, 520.16s/it][A100%|██████████| 1/1 [08:40<00:00, 520.18s/it]
INFO:root:final mean train loss: 13345.76611771122
INFO:root:final train perplexity: 193.50247192382812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.35s/it][A100%|██████████| 1/1 [00:38<00:00, 38.37s/it]
INFO:root:eval mean loss: 12943.143907912234
INFO:root:eval perplexity: 187.50914001464844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.42s/it][A100%|██████████| 1/1 [00:37<00:00, 37.44s/it]
INFO:root:eval mean loss: 13153.590723348847
INFO:root:eval perplexity: 216.73687744140625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/183
 92%|█████████▏| 183/200 [30:07:47<2:48:58, 596.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13420.666744171627
INFO:root:current train perplexity193.0482940673828
INFO:root:current mean train loss 13339.191088717407
INFO:root:current train perplexity192.6474609375
INFO:root:current mean train loss 13318.92521684886
INFO:root:current train perplexity192.88230895996094
INFO:root:current mean train loss 13335.628596870696
INFO:root:current train perplexity192.99684143066406
INFO:root:current mean train loss 13343.688044175216
INFO:root:current train perplexity193.3383026123047
INFO:root:current mean train loss 13340.478026476465
INFO:root:current train perplexity193.3732452392578
INFO:root:current mean train loss 13360.16726026348
INFO:root:current train perplexity193.5053253173828
INFO:root:current mean train loss 13363.725424670298
INFO:root:current train perplexity193.48696899414062
INFO:root:current mean train loss 13360.766148926346
INFO:root:current train perplexity193.4404754638672
INFO:root:current mean train loss 13352.543295284917
INFO:root:current train perplexity193.39878845214844

100%|██████████| 1/1 [08:38<00:00, 518.71s/it][A100%|██████████| 1/1 [08:38<00:00, 518.71s/it]
INFO:root:final mean train loss: 13344.50079370314
INFO:root:final train perplexity: 193.40606689453125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.36s/it][A100%|██████████| 1/1 [00:38<00:00, 38.37s/it]
INFO:root:eval mean loss: 12910.363565214982
INFO:root:eval perplexity: 185.0399932861328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.66s/it][A100%|██████████| 1/1 [00:37<00:00, 37.71s/it]
INFO:root:eval mean loss: 13121.488489029256
INFO:root:eval perplexity: 213.91029357910156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/184
 92%|█████████▏| 184/200 [30:17:44<2:39:02, 596.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13290.84306227993
INFO:root:current train perplexity190.98899841308594
INFO:root:current mean train loss 13355.078987344663
INFO:root:current train perplexity191.9369354248047
INFO:root:current mean train loss 13330.84958775369
INFO:root:current train perplexity192.1230926513672
INFO:root:current mean train loss 13354.001884686657
INFO:root:current train perplexity192.4285888671875
INFO:root:current mean train loss 13350.126393312103
INFO:root:current train perplexity192.66629028320312
INFO:root:current mean train loss 13339.584476931917
INFO:root:current train perplexity192.52578735351562
INFO:root:current mean train loss 13340.731215361866
INFO:root:current train perplexity192.6146697998047
INFO:root:current mean train loss 13347.64732540937
INFO:root:current train perplexity192.78179931640625
INFO:root:current mean train loss 13347.107720113376
INFO:root:current train perplexity192.9163360595703
INFO:root:current mean train loss 13355.471611297953
INFO:root:current train perplexity193.28538513183594

100%|██████████| 1/1 [08:39<00:00, 519.13s/it][A100%|██████████| 1/1 [08:39<00:00, 519.13s/it]
INFO:root:final mean train loss: 13342.378623224075
INFO:root:final train perplexity: 193.2441864013672
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.47s/it][A100%|██████████| 1/1 [00:38<00:00, 38.49s/it]
INFO:root:eval mean loss: 12895.491868905141
INFO:root:eval perplexity: 183.9306182861328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.08s/it][A100%|██████████| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 13105.54902897828
INFO:root:eval perplexity: 212.5206756591797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/185
 92%|█████████▎| 185/200 [30:27:40<2:29:05, 596.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13362.77089102057
INFO:root:current train perplexity192.98487854003906
INFO:root:current mean train loss 13359.343379015363
INFO:root:current train perplexity193.2789306640625
INFO:root:current mean train loss 13319.699862791218
INFO:root:current train perplexity192.76443481445312
INFO:root:current mean train loss 13338.364409836742
INFO:root:current train perplexity192.99786376953125
INFO:root:current mean train loss 13351.446478666492
INFO:root:current train perplexity193.23268127441406
INFO:root:current mean train loss 13370.070632960924
INFO:root:current train perplexity193.40191650390625
INFO:root:current mean train loss 13364.180968968612
INFO:root:current train perplexity193.1592559814453
INFO:root:current mean train loss 13358.24980945122
INFO:root:current train perplexity193.1023406982422
INFO:root:current mean train loss 13350.45179403086
INFO:root:current train perplexity193.03062438964844
INFO:root:current mean train loss 13347.448961392365
INFO:root:current train perplexity193.07839965820312

100%|██████████| 1/1 [08:38<00:00, 518.81s/it][A100%|██████████| 1/1 [08:38<00:00, 518.81s/it]
INFO:root:final mean train loss: 13340.849408057427
INFO:root:final train perplexity: 193.12757873535156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.69s/it][A100%|██████████| 1/1 [00:38<00:00, 38.70s/it]
INFO:root:eval mean loss: 12891.788972462322
INFO:root:eval perplexity: 183.65533447265625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.23s/it][A100%|██████████| 1/1 [00:37<00:00, 37.24s/it]
INFO:root:eval mean loss: 13104.730011635638
INFO:root:eval perplexity: 212.44955444335938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/186
 93%|█████████▎| 186/200 [30:37:36<2:19:09, 596.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13451.181337553879
INFO:root:current train perplexity193.77310180664062
INFO:root:current mean train loss 13410.697881851604
INFO:root:current train perplexity194.0127410888672
INFO:root:current mean train loss 13387.234477079704
INFO:root:current train perplexity193.58091735839844
INFO:root:current mean train loss 13348.22006470042
INFO:root:current train perplexity192.95948791503906
INFO:root:current mean train loss 13336.497162554542
INFO:root:current train perplexity192.53717041015625
INFO:root:current mean train loss 13336.741888043016
INFO:root:current train perplexity192.55075073242188
INFO:root:current mean train loss 13345.652238559862
INFO:root:current train perplexity192.71397399902344
INFO:root:current mean train loss 13355.808944915423
INFO:root:current train perplexity192.85296630859375
INFO:root:current mean train loss 13347.386956560034
INFO:root:current train perplexity192.94752502441406
INFO:root:current mean train loss 13350.057846734106
INFO:root:current train perplexity193.0465545654297

100%|██████████| 1/1 [08:42<00:00, 522.76s/it][A100%|██████████| 1/1 [08:42<00:00, 522.76s/it]
INFO:root:final mean train loss: 13339.77009804018
INFO:root:final train perplexity: 193.04534912109375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.39s/it][A100%|██████████| 1/1 [00:38<00:00, 38.40s/it]
INFO:root:eval mean loss: 12873.00333139406
INFO:root:eval perplexity: 182.2655792236328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.93s/it][A100%|██████████| 1/1 [00:37<00:00, 37.95s/it]
INFO:root:eval mean loss: 13089.053517010196
INFO:root:eval perplexity: 211.0918731689453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/187
 94%|█████████▎| 187/200 [30:47:37<2:09:29, 597.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13310.334868421052
INFO:root:current train perplexity193.5883026123047
INFO:root:current mean train loss 13353.071153846155
INFO:root:current train perplexity193.861083984375
INFO:root:current mean train loss 13348.015287341103
INFO:root:current train perplexity193.6609649658203
INFO:root:current mean train loss 13348.235000494462
INFO:root:current train perplexity193.35028076171875
INFO:root:current mean train loss 13342.446898674243
INFO:root:current train perplexity193.16505432128906
INFO:root:current mean train loss 13344.273585215336
INFO:root:current train perplexity193.231201171875
INFO:root:current mean train loss 13362.750390625
INFO:root:current train perplexity193.2430877685547
INFO:root:current mean train loss 13364.963078567216
INFO:root:current train perplexity193.26852416992188
INFO:root:current mean train loss 13360.53017087116
INFO:root:current train perplexity193.11090087890625

100%|██████████| 1/1 [08:41<00:00, 521.44s/it][A100%|██████████| 1/1 [08:41<00:00, 521.46s/it]
INFO:root:final mean train loss: 13337.938983548072
INFO:root:final train perplexity: 192.90603637695312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.55s/it][A100%|██████████| 1/1 [00:38<00:00, 38.56s/it]
INFO:root:eval mean loss: 12826.151685782359
INFO:root:eval perplexity: 178.8450164794922
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.85s/it][A100%|██████████| 1/1 [00:37<00:00, 37.86s/it]
INFO:root:eval mean loss: 13038.567230441045
INFO:root:eval perplexity: 206.77883911132812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/188
 94%|█████████▍| 188/200 [30:57:36<1:59:37, 598.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13678.202799479166
INFO:root:current train perplexity196.86521911621094
INFO:root:current mean train loss 13404.694554004855
INFO:root:current train perplexity194.4639892578125
INFO:root:current mean train loss 13411.258587015087
INFO:root:current train perplexity193.9046173095703
INFO:root:current mean train loss 13383.078234581271
INFO:root:current train perplexity193.34613037109375
INFO:root:current mean train loss 13367.562650240385
INFO:root:current train perplexity193.1293182373047
INFO:root:current mean train loss 13376.164569225273
INFO:root:current train perplexity193.39915466308594
INFO:root:current mean train loss 13362.63071038039
INFO:root:current train perplexity193.3205108642578
INFO:root:current mean train loss 13349.356138313478
INFO:root:current train perplexity193.1237030029297
INFO:root:current mean train loss 13344.040840500467
INFO:root:current train perplexity192.9541473388672
INFO:root:current mean train loss 13346.467404658084
INFO:root:current train perplexity192.86611938476562

100%|██████████| 1/1 [08:43<00:00, 523.40s/it][A100%|██████████| 1/1 [08:43<00:00, 523.41s/it]
INFO:root:final mean train loss: 13336.383141548404
INFO:root:final train perplexity: 192.78759765625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.58s/it][A100%|██████████| 1/1 [00:38<00:00, 38.60s/it]
INFO:root:eval mean loss: 12807.649407136525
INFO:root:eval perplexity: 177.5117950439453
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.26s/it][A100%|██████████| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 13022.29997783688
INFO:root:eval perplexity: 205.4078369140625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/189
 94%|█████████▍| 189/200 [31:07:37<1:49:48, 598.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13274.1201171875
INFO:root:current train perplexity192.53872680664062
INFO:root:current mean train loss 13345.290223817568
INFO:root:current train perplexity193.0367889404297
INFO:root:current mean train loss 13336.120149585307
INFO:root:current train perplexity193.20254516601562
INFO:root:current mean train loss 13359.707938730908
INFO:root:current train perplexity193.2953338623047
INFO:root:current mean train loss 13347.78020453163
INFO:root:current train perplexity193.23101806640625
INFO:root:current mean train loss 13342.881203369618
INFO:root:current train perplexity193.0552978515625
INFO:root:current mean train loss 13348.766614348915
INFO:root:current train perplexity192.9417266845703
INFO:root:current mean train loss 13347.468943664293
INFO:root:current train perplexity192.98690795898438
INFO:root:current mean train loss 13342.556013264873
INFO:root:current train perplexity192.71141052246094
INFO:root:current mean train loss 13343.128227694498
INFO:root:current train perplexity192.6593017578125

100%|██████████| 1/1 [08:40<00:00, 520.56s/it][A100%|██████████| 1/1 [08:40<00:00, 520.57s/it]
INFO:root:final mean train loss: 13333.47839724633
INFO:root:final train perplexity: 192.5668182373047
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.58s/it][A100%|██████████| 1/1 [00:38<00:00, 38.60s/it]
INFO:root:eval mean loss: 12767.58714261968
INFO:root:eval perplexity: 174.6593475341797
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.25s/it][A100%|██████████| 1/1 [00:37<00:00, 37.28s/it]
INFO:root:eval mean loss: 12980.81171043883
INFO:root:eval perplexity: 201.95249938964844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/190
 95%|█████████▌| 190/200 [31:17:35<1:39:46, 598.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13374.001696134868
INFO:root:current train perplexity192.0657501220703
INFO:root:current mean train loss 13325.793584230567
INFO:root:current train perplexity191.09832763671875
INFO:root:current mean train loss 13346.07288545234
INFO:root:current train perplexity192.20574951171875
INFO:root:current mean train loss 13330.129901180446
INFO:root:current train perplexity191.93556213378906
INFO:root:current mean train loss 13334.300844178848
INFO:root:current train perplexity191.95240783691406
INFO:root:current mean train loss 13328.808561762404
INFO:root:current train perplexity192.15011596679688
INFO:root:current mean train loss 13333.661017644386
INFO:root:current train perplexity192.28118896484375
INFO:root:current mean train loss 13336.531391255216
INFO:root:current train perplexity192.32070922851562
INFO:root:current mean train loss 13335.893725198413
INFO:root:current train perplexity192.433349609375
INFO:root:current mean train loss 13334.33221827394
INFO:root:current train perplexity192.2872314453125

100%|██████████| 1/1 [08:39<00:00, 519.91s/it][A100%|██████████| 1/1 [08:39<00:00, 519.92s/it]
INFO:root:final mean train loss: 13332.124392601752
INFO:root:final train perplexity: 192.4639129638672
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.90s/it][A100%|██████████| 1/1 [00:38<00:00, 38.91s/it]
INFO:root:eval mean loss: 12771.637910017731
INFO:root:eval perplexity: 174.94566345214844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.45s/it][A100%|██████████| 1/1 [00:37<00:00, 37.47s/it]
INFO:root:eval mean loss: 12985.040974069148
INFO:root:eval perplexity: 202.30197143554688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/191
 96%|█████████▌| 191/200 [31:27:33<1:29:46, 598.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13380.280598958334
INFO:root:current train perplexity192.7773895263672
INFO:root:current mean train loss 13295.557217335137
INFO:root:current train perplexity191.0924835205078
INFO:root:current mean train loss 13312.759714000551
INFO:root:current train perplexity192.27734375
INFO:root:current mean train loss 13325.57173105409
INFO:root:current train perplexity192.3445587158203
INFO:root:current mean train loss 13341.638472903249
INFO:root:current train perplexity192.28338623046875
INFO:root:current mean train loss 13352.260884873103
INFO:root:current train perplexity192.38812255859375
INFO:root:current mean train loss 13345.871202776116
INFO:root:current train perplexity192.25653076171875
INFO:root:current mean train loss 13341.027871657927
INFO:root:current train perplexity192.26229858398438
INFO:root:current mean train loss 13334.392912305397
INFO:root:current train perplexity192.16688537597656
INFO:root:current mean train loss 13340.931295088323
INFO:root:current train perplexity192.24002075195312

100%|██████████| 1/1 [08:40<00:00, 520.15s/it][A100%|██████████| 1/1 [08:40<00:00, 520.15s/it]
INFO:root:final mean train loss: 13329.780730462844
INFO:root:final train perplexity: 192.2861328125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.41s/it][A100%|██████████| 1/1 [00:38<00:00, 38.43s/it]
INFO:root:eval mean loss: 12762.845349900266
INFO:root:eval perplexity: 174.3247833251953
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.33s/it][A100%|██████████| 1/1 [00:38<00:00, 38.34s/it]
INFO:root:eval mean loss: 12975.53631981383
INFO:root:eval perplexity: 201.51731872558594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/192
 96%|█████████▌| 192/200 [31:37:31<1:19:47, 598.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13607.919363839286
INFO:root:current train perplexity195.91098022460938
INFO:root:current mean train loss 13341.548177083334
INFO:root:current train perplexity192.48199462890625
INFO:root:current mean train loss 13380.907878989361
INFO:root:current train perplexity192.76158142089844
INFO:root:current mean train loss 13351.302439948695
INFO:root:current train perplexity192.150390625
INFO:root:current mean train loss 13353.138332884339
INFO:root:current train perplexity192.3800506591797
INFO:root:current mean train loss 13342.791749415888
INFO:root:current train perplexity192.21536254882812
INFO:root:current mean train loss 13345.671104515255
INFO:root:current train perplexity192.37904357910156
INFO:root:current mean train loss 13334.68417570153
INFO:root:current train perplexity192.2510223388672
INFO:root:current mean train loss 13336.98971744012
INFO:root:current train perplexity192.1980438232422
INFO:root:current mean train loss 13344.54079837901
INFO:root:current train perplexity192.29722595214844

100%|██████████| 1/1 [08:40<00:00, 520.40s/it][A100%|██████████| 1/1 [08:40<00:00, 520.41s/it]
INFO:root:final mean train loss: 13328.733778922788
INFO:root:final train perplexity: 192.20657348632812
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.59s/it][A100%|██████████| 1/1 [00:38<00:00, 38.60s/it]
INFO:root:eval mean loss: 12726.256960605053
INFO:root:eval perplexity: 171.76458740234375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.14s/it][A100%|██████████| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 12937.9150390625
INFO:root:eval perplexity: 198.44094848632812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/193
 96%|█████████▋| 193/200 [31:47:29<1:09:47, 598.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13355.227993277616
INFO:root:current train perplexity193.12020874023438
INFO:root:current mean train loss 13299.171519886364
INFO:root:current train perplexity191.51702880859375
INFO:root:current mean train loss 13329.602494855968
INFO:root:current train perplexity191.7210693359375
INFO:root:current mean train loss 13331.808955334365
INFO:root:current train perplexity191.8871612548828
INFO:root:current mean train loss 13341.994887926778
INFO:root:current train perplexity192.32199096679688
INFO:root:current mean train loss 13340.434259179328
INFO:root:current train perplexity192.1664276123047
INFO:root:current mean train loss 13345.167352133554
INFO:root:current train perplexity192.3140106201172
INFO:root:current mean train loss 13339.519802006225
INFO:root:current train perplexity192.14691162109375
INFO:root:current mean train loss 13331.977324751631
INFO:root:current train perplexity192.01776123046875
INFO:root:current mean train loss 13333.713766735154
INFO:root:current train perplexity192.05128479003906

100%|██████████| 1/1 [08:40<00:00, 520.80s/it][A100%|██████████| 1/1 [08:40<00:00, 520.84s/it]
INFO:root:final mean train loss: 13327.440410983178
INFO:root:final train perplexity: 192.10861206054688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.14s/it][A100%|██████████| 1/1 [00:38<00:00, 38.17s/it]
INFO:root:eval mean loss: 12743.271782191932
INFO:root:eval perplexity: 172.95045471191406
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.76s/it][A100%|██████████| 1/1 [00:37<00:00, 37.77s/it]
INFO:root:eval mean loss: 12955.799943207003
INFO:root:eval perplexity: 199.89743041992188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/194
 97%|█████████▋| 194/200 [31:57:28<59:49, 598.27s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13223.441119025736
INFO:root:current train perplexity191.4358673095703
INFO:root:current mean train loss 13294.4672819226
INFO:root:current train perplexity192.06886291503906
INFO:root:current mean train loss 13356.894570156872
INFO:root:current train perplexity192.80386352539062
INFO:root:current mean train loss 13324.263977920227
INFO:root:current train perplexity192.5459747314453
INFO:root:current mean train loss 13337.504150931956
INFO:root:current train perplexity192.3150177001953
INFO:root:current mean train loss 13327.32027528074
INFO:root:current train perplexity192.17422485351562
INFO:root:current mean train loss 13335.598548807124
INFO:root:current train perplexity192.12693786621094
INFO:root:current mean train loss 13331.37173742302
INFO:root:current train perplexity192.0032958984375
INFO:root:current mean train loss 13338.629516745006
INFO:root:current train perplexity192.08966064453125
INFO:root:current mean train loss 13338.00223243625
INFO:root:current train perplexity191.9813232421875

100%|██████████| 1/1 [08:39<00:00, 519.74s/it][A100%|██████████| 1/1 [08:39<00:00, 519.75s/it]
INFO:root:final mean train loss: 13326.261998330394
INFO:root:final train perplexity: 192.01922607421875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.47s/it][A100%|██████████| 1/1 [00:38<00:00, 38.49s/it]
INFO:root:eval mean loss: 12731.930878767731
INFO:root:eval perplexity: 172.15916442871094
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.09s/it][A100%|██████████| 1/1 [00:38<00:00, 38.10s/it]
INFO:root:eval mean loss: 12944.791895223847
INFO:root:eval perplexity: 198.9996337890625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/195
 98%|█████████▊| 195/200 [32:07:25<49:50, 598.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13320.40517412606
INFO:root:current train perplexity192.3080596923828
INFO:root:current mean train loss 13361.59074660967
INFO:root:current train perplexity192.80018615722656
INFO:root:current mean train loss 13337.531710002413
INFO:root:current train perplexity192.5678253173828
INFO:root:current mean train loss 13329.33872573555
INFO:root:current train perplexity192.0592498779297
INFO:root:current mean train loss 13338.568384906046
INFO:root:current train perplexity192.140869140625
INFO:root:current mean train loss 13328.646058111583
INFO:root:current train perplexity191.97447204589844
INFO:root:current mean train loss 13331.649068783194
INFO:root:current train perplexity191.89337158203125
INFO:root:current mean train loss 13344.57688081563
INFO:root:current train perplexity192.10641479492188
INFO:root:current mean train loss 13344.80758194485
INFO:root:current train perplexity192.06666564941406
INFO:root:current mean train loss 13341.029879350235
INFO:root:current train perplexity192.05311584472656

100%|██████████| 1/1 [08:40<00:00, 520.33s/it][A100%|██████████| 1/1 [08:40<00:00, 520.33s/it]
INFO:root:final mean train loss: 13326.187705255325
INFO:root:final train perplexity: 192.01364135742188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.52s/it][A100%|██████████| 1/1 [00:38<00:00, 38.54s/it]
INFO:root:eval mean loss: 12739.851285460993
INFO:root:eval perplexity: 172.71136474609375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.24s/it][A100%|██████████| 1/1 [00:37<00:00, 37.24s/it]
INFO:root:eval mean loss: 12953.911714594415
INFO:root:eval perplexity: 199.7431640625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/196
 98%|█████████▊| 196/200 [32:17:23<39:52, 598.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13326.881121735074
INFO:root:current train perplexity191.08128356933594
INFO:root:current mean train loss 13352.522349831586
INFO:root:current train perplexity191.2117156982422
INFO:root:current mean train loss 13353.23710352294
INFO:root:current train perplexity191.79229736328125
INFO:root:current mean train loss 13358.34393892626
INFO:root:current train perplexity192.22279357910156
INFO:root:current mean train loss 13351.596204998661
INFO:root:current train perplexity192.35711669921875
INFO:root:current mean train loss 13332.790507536927
INFO:root:current train perplexity191.9709014892578
INFO:root:current mean train loss 13333.745754076086
INFO:root:current train perplexity191.78041076660156
INFO:root:current mean train loss 13326.293478039439
INFO:root:current train perplexity191.66941833496094
INFO:root:current mean train loss 13330.834259209198
INFO:root:current train perplexity191.75425720214844
INFO:root:current mean train loss 13334.632050033932
INFO:root:current train perplexity191.90362548828125

100%|██████████| 1/1 [08:38<00:00, 518.74s/it][A100%|██████████| 1/1 [08:38<00:00, 518.74s/it]
INFO:root:final mean train loss: 13325.276584748299
INFO:root:final train perplexity: 191.94471740722656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.36s/it][A100%|██████████| 1/1 [00:38<00:00, 38.38s/it]
INFO:root:eval mean loss: 12719.632071420656
INFO:root:eval perplexity: 171.30506896972656
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.01s/it][A100%|██████████| 1/1 [00:38<00:00, 38.05s/it]
INFO:root:eval mean loss: 12933.594220966312
INFO:root:eval perplexity: 198.09059143066406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/197
 98%|█████████▊| 197/200 [32:27:20<29:52, 597.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13309.38703125
INFO:root:current train perplexity192.50613403320312
INFO:root:current mean train loss 13337.23732142857
INFO:root:current train perplexity192.4527130126953
INFO:root:current mean train loss 13355.175561079546
INFO:root:current train perplexity192.0369110107422
INFO:root:current mean train loss 13335.331205729166
INFO:root:current train perplexity191.86502075195312
INFO:root:current mean train loss 13331.202467105262
INFO:root:current train perplexity192.04762268066406
INFO:root:current mean train loss 13329.033977581521
INFO:root:current train perplexity192.17127990722656
INFO:root:current mean train loss 13334.921649305556
INFO:root:current train perplexity192.0687713623047
INFO:root:current mean train loss 13345.783932711694
INFO:root:current train perplexity192.2466278076172
INFO:root:current mean train loss 13338.952799107143
INFO:root:current train perplexity192.0880126953125
INFO:root:current mean train loss 13336.185344551282
INFO:root:current train perplexity191.91799926757812

100%|██████████| 1/1 [08:41<00:00, 521.08s/it][A100%|██████████| 1/1 [08:41<00:00, 521.08s/it]
INFO:root:final mean train loss: 13324.771978562878
INFO:root:final train perplexity: 191.9063720703125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.97s/it][A100%|██████████| 1/1 [00:38<00:00, 38.99s/it]
INFO:root:eval mean loss: 12715.850738308955
INFO:root:eval perplexity: 171.04330444335938
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.60s/it][A100%|██████████| 1/1 [00:37<00:00, 37.88s/it]
INFO:root:eval mean loss: 12930.31287400266
INFO:root:eval perplexity: 197.82496643066406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/198
 99%|█████████▉| 198/200 [32:37:19<19:56, 598.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13266.392260448041
INFO:root:current train perplexity191.1654052734375
INFO:root:current mean train loss 13260.87194223873
INFO:root:current train perplexity190.9350128173828
INFO:root:current mean train loss 13289.877698487191
INFO:root:current train perplexity191.50469970703125
INFO:root:current mean train loss 13287.667550587468
INFO:root:current train perplexity191.441162109375
INFO:root:current mean train loss 13284.171781994048
INFO:root:current train perplexity191.2381591796875
INFO:root:current mean train loss 13307.289253457333
INFO:root:current train perplexity191.50497436523438
INFO:root:current mean train loss 13318.673872449213
INFO:root:current train perplexity191.75389099121094
INFO:root:current mean train loss 13323.721581158206
INFO:root:current train perplexity191.73971557617188
INFO:root:current mean train loss 13330.46121398995
INFO:root:current train perplexity191.85092163085938
INFO:root:current mean train loss 13334.640296167663
INFO:root:current train perplexity191.87379455566406

100%|██████████| 1/1 [08:39<00:00, 519.97s/it][A100%|██████████| 1/1 [08:39<00:00, 519.98s/it]
INFO:root:final mean train loss: 13324.277991017987
INFO:root:final train perplexity: 191.86903381347656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:38<00:00, 38.93s/it][A100%|██████████| 1/1 [00:38<00:00, 38.94s/it]
INFO:root:eval mean loss: 12712.33128324468
INFO:root:eval perplexity: 170.8000946044922
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.24s/it][A100%|██████████| 1/1 [00:37<00:00, 37.26s/it]
INFO:root:eval mean loss: 12926.610420822251
INFO:root:eval perplexity: 197.5255889892578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/199
100%|█████████▉| 199/200 [32:47:17<09:58, 598.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13270.956312242444
INFO:root:current train perplexity192.02178955078125
INFO:root:current mean train loss 13288.912180955498
INFO:root:current train perplexity191.407470703125
INFO:root:current mean train loss 13322.951628275343
INFO:root:current train perplexity191.6874237060547
INFO:root:current mean train loss 13345.408954903292
INFO:root:current train perplexity192.14974975585938
INFO:root:current mean train loss 13321.264499268076
INFO:root:current train perplexity191.86474609375
INFO:root:current mean train loss 13329.613902548646
INFO:root:current train perplexity191.93089294433594
INFO:root:current mean train loss 13332.213193062591
INFO:root:current train perplexity191.9369354248047
INFO:root:current mean train loss 13331.077844747551
INFO:root:current train perplexity191.9654998779297
INFO:root:current mean train loss 13336.612204948793
INFO:root:current train perplexity191.99404907226562
INFO:root:current mean train loss 13333.779969924633
INFO:root:current train perplexity191.819091796875

100%|██████████| 1/1 [08:43<00:00, 524.00s/it][A100%|██████████| 1/1 [08:43<00:00, 524.00s/it]
INFO:root:final mean train loss: 13323.62753517397
INFO:root:final train perplexity: 191.81982421875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.87s/it][A100%|██████████| 1/1 [00:37<00:00, 37.89s/it]
INFO:root:eval mean loss: 12706.50742464539
INFO:root:eval perplexity: 170.3982391357422
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:37<00:00, 37.61s/it][A100%|██████████| 1/1 [00:37<00:00, 37.63s/it]
INFO:root:eval mean loss: 12920.686398769947
INFO:root:eval perplexity: 197.04769897460938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: alll12_alll12_not_concat_200e_128/200
100%|██████████| 200/200 [32:57:18<00:00, 598.92s/it]100%|██████████| 200/200 [32:57:18<00:00, 593.19s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:51<00:00, 51.62s/it]100%|██████████| 1/1 [00:51<00:00, 51.63s/it]
INFO:root:eval mean loss: 12706.50742464539
INFO:root:eval perplexity: 170.3982391357422
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:42<00:00, 42.73s/it]100%|██████████| 1/1 [00:42<00:00, 42.74s/it]
INFO:root:eval mean loss: 12920.686398769947
INFO:root:eval perplexity: 197.04769897460938
INFO:root:evalaution complete
INFO:root:save model final: alll12_alll12_not_concat_200e_128/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x147c7c414f06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x147c7c40c8e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x147c7c331e09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x147c7c415a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x147c7c32f948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x147c7c415a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x147c7c2eab46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x147c7bd4f46a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x147d785aba27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x147d785abbe0]
python(+0x24a989) [0x563a4c4b4989]
python(+0x24a9bd) [0x563a4c4b49bd]
python(+0x24aa14) [0x563a4c4b4a14]
python(+0x108f75) [0x563a4c372f75]
python(Py_RunMain+0x313) [0x563a4c4b7983]
python(Py_BytesMain+0x39) [0x563a4c4b7bc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x147d785890b3]
python(+0x1d6e13) [0x563a4c440e13]
/opt/slurm/data/slurmd/job30006352/slurm_script: line 255: 2623392 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path sentence-transformers/all-MiniLM-L12-v1 --data_config data_config.json --data_folder fast_processed_data_allminil12_final --output alll12_alll12_not_concat_200e_128 --epochs 200 --save_head  --save_epochs 1 --external_embedding --test_eval --not_concat_self --batch_size 128
"
