INFO:root:Output: small_val_1160
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['encoder.layer.2.crossattention.self.key.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.1.crossattention.self.value.bias', 'cls.predictions.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'cls.predictions.decoder.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24477.505070233587
INFO:root:current train perplexity15639.44921875
INFO:root:current mean train loss 20575.486617658604
INFO:root:current train perplexity3324.3828125
INFO:root:current mean train loss 17775.98801669628
INFO:root:current train perplexity1105.7666015625
INFO:root:current mean train loss 15878.314582843828
INFO:root:current train perplexity518.8909301757812
INFO:root:current mean train loss 14501.663545841684
INFO:root:current train perplexity301.5804443359375
INFO:root:current mean train loss 13455.627340326326
INFO:root:current train perplexity200.31573486328125
INFO:root:current mean train loss 12643.573704622675
INFO:root:current train perplexity145.42881774902344
INFO:root:current mean train loss 11991.193911212258
INFO:root:current train perplexity112.72032928466797
INFO:root:current mean train loss 11456.750769083705
INFO:root:current train perplexity91.35193634033203

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:33<00:00, 393.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:33<00:00, 393.30s/it]
INFO:root:final mean train loss: 11026.544077842465
INFO:root:final train perplexity: 77.50096130371094
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.09s/it]
INFO:root:eval mean loss: 6419.175850509751
INFO:root:eval perplexity: 13.406320571899414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/1
  0%|          | 1/200 [07:48<25:52:14, 468.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6832.379115513393
INFO:root:current train perplexity14.56052303314209
INFO:root:current mean train loss 6736.417129088785
INFO:root:current train perplexity14.428878784179688
INFO:root:current mean train loss 6709.218882095411
INFO:root:current train perplexity14.198004722595215
INFO:root:current mean train loss 6638.124370164902
INFO:root:current train perplexity13.780315399169922
INFO:root:current mean train loss 6584.455272477733
INFO:root:current train perplexity13.478819847106934
INFO:root:current mean train loss 6534.4875310111565
INFO:root:current train perplexity13.208091735839844
INFO:root:current mean train loss 6491.335614124279
INFO:root:current train perplexity12.934389114379883
INFO:root:current mean train loss 6444.050768127873
INFO:root:current train perplexity12.694062232971191
INFO:root:current mean train loss 6399.9641237318
INFO:root:current train perplexity12.468001365661621
INFO:root:current mean train loss 6355.680589232187
INFO:root:current train perplexity12.264399528503418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:45<00:00, 405.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:45<00:00, 405.77s/it]
INFO:root:final mean train loss: 6318.858000478437
INFO:root:final train perplexity: 12.097177505493164
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.63s/it]
INFO:root:eval mean loss: 5555.160021193484
INFO:root:eval perplexity: 9.453105926513672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/2
  1%|          | 2/200 [15:22<25:17:48, 459.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5999.582747395833
INFO:root:current train perplexity10.690078735351562
INFO:root:current mean train loss 5892.692259680706
INFO:root:current train perplexity10.285030364990234
INFO:root:current mean train loss 5870.604651162791
INFO:root:current train perplexity10.144396781921387
INFO:root:current mean train loss 5850.66996217758
INFO:root:current train perplexity10.032023429870605
INFO:root:current mean train loss 5827.7458360786895
INFO:root:current train perplexity9.947481155395508
INFO:root:current mean train loss 5802.225397261833
INFO:root:current train perplexity9.860214233398438
INFO:root:current mean train loss 5777.503976911839
INFO:root:current train perplexity9.779951095581055
INFO:root:current mean train loss 5758.797403572989
INFO:root:current train perplexity9.702095985412598
INFO:root:current mean train loss 5746.260129888804
INFO:root:current train perplexity9.633222579956055
INFO:root:current mean train loss 5727.457591039105
INFO:root:current train perplexity9.54924488067627

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:55<00:00, 415.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:55<00:00, 415.90s/it]
INFO:root:final mean train loss: 5703.8548470774
INFO:root:final train perplexity: 9.49091911315918
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.15s/it]
INFO:root:eval mean loss: 5193.666562777039
INFO:root:eval perplexity: 8.167526245117188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/3
  2%|â–         | 3/200 [23:07<25:17:57, 462.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5577.103579313859
INFO:root:current train perplexity8.863709449768066
INFO:root:current mean train loss 5495.492195439532
INFO:root:current train perplexity8.752226829528809
INFO:root:current mean train loss 5495.102236897422
INFO:root:current train perplexity8.693758010864258
INFO:root:current mean train loss 5467.719468060662
INFO:root:current train perplexity8.6111478805542
INFO:root:current mean train loss 5456.442776438756
INFO:root:current train perplexity8.590510368347168
INFO:root:current mean train loss 5440.333312171367
INFO:root:current train perplexity8.537327766418457
INFO:root:current mean train loss 5430.125302530598
INFO:root:current train perplexity8.503252983093262
INFO:root:current mean train loss 5420.018974082598
INFO:root:current train perplexity8.467273712158203
INFO:root:current mean train loss 5409.709530799097
INFO:root:current train perplexity8.432485580444336
INFO:root:current mean train loss 5398.819238069644
INFO:root:current train perplexity8.396697044372559

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:55<00:00, 415.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:55<00:00, 415.39s/it]
INFO:root:final mean train loss: 5387.7071396612355
INFO:root:final train perplexity: 8.377975463867188
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.83s/it]
INFO:root:eval mean loss: 4977.51678856383
INFO:root:eval perplexity: 7.483956336975098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/4
  2%|â–         | 4/200 [30:50<25:10:54, 462.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5336.312925277218
INFO:root:current train perplexity8.01822280883789
INFO:root:current mean train loss 5254.77532353292
INFO:root:current train perplexity7.928850173950195
INFO:root:current mean train loss 5257.598785004058
INFO:root:current train perplexity7.952418327331543
INFO:root:current mean train loss 5246.545593077322
INFO:root:current train perplexity7.904701232910156
INFO:root:current mean train loss 5238.880520636963
INFO:root:current train perplexity7.868919849395752
INFO:root:current mean train loss 5228.194415938383
INFO:root:current train perplexity7.838253021240234
INFO:root:current mean train loss 5220.159353023475
INFO:root:current train perplexity7.812448501586914
INFO:root:current mean train loss 5211.983407788987
INFO:root:current train perplexity7.795615196228027
INFO:root:current mean train loss 5198.846723168622
INFO:root:current train perplexity7.7713165283203125
INFO:root:current mean train loss 5190.778094790548
INFO:root:current train perplexity7.741550445556641

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:56<00:00, 416.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:56<00:00, 416.86s/it]
INFO:root:final mean train loss: 5181.166975821218
INFO:root:final train perplexity: 7.722362518310547
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.45s/it]
INFO:root:eval mean loss: 4833.32393132203
INFO:root:eval perplexity: 7.060064315795898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/5
  2%|â–Ž         | 5/200 [38:31<25:01:17, 461.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5092.457920172275
INFO:root:current train perplexity7.373897552490234
INFO:root:current mean train loss 5082.903323825315
INFO:root:current train perplexity7.431034564971924
INFO:root:current mean train loss 5089.395187058708
INFO:root:current train perplexity7.437918663024902
INFO:root:current mean train loss 5071.858562638275
INFO:root:current train perplexity7.374215602874756
INFO:root:current mean train loss 5068.989901809866
INFO:root:current train perplexity7.36243200302124
INFO:root:current mean train loss 5056.873565956923
INFO:root:current train perplexity7.339076995849609
INFO:root:current mean train loss 5049.568627585827
INFO:root:current train perplexity7.320316314697266
INFO:root:current mean train loss 5049.196705323918
INFO:root:current train perplexity7.314483165740967
INFO:root:current mean train loss 5045.209303882039
INFO:root:current train perplexity7.2977399826049805
INFO:root:current mean train loss 5037.570546500599
INFO:root:current train perplexity7.283257007598877

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:51<00:00, 411.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:51<00:00, 411.53s/it]
INFO:root:final mean train loss: 5028.946336377052
INFO:root:final train perplexity: 7.272243976593018
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.11s/it]
INFO:root:eval mean loss: 4718.656184203236
INFO:root:eval perplexity: 6.740175247192383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/6
  3%|â–Ž         | 6/200 [46:07<24:47:14, 459.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4902.170846492686
INFO:root:current train perplexity6.961585521697998
INFO:root:current mean train loss 4953.6297698767
INFO:root:current train perplexity7.031937122344971
INFO:root:current mean train loss 4934.903245192308
INFO:root:current train perplexity7.013389587402344
INFO:root:current mean train loss 4935.514620294489
INFO:root:current train perplexity7.006682872772217
INFO:root:current mean train loss 4932.368453535724
INFO:root:current train perplexity6.995290756225586
INFO:root:current mean train loss 4923.62155614431
INFO:root:current train perplexity6.973849773406982
INFO:root:current mean train loss 4923.356702660114
INFO:root:current train perplexity6.971079349517822
INFO:root:current mean train loss 4920.647059592537
INFO:root:current train perplexity6.959982395172119
INFO:root:current mean train loss 4916.924032776527
INFO:root:current train perplexity6.950885772705078
INFO:root:current mean train loss 4914.54829189216
INFO:root:current train perplexity6.939525604248047

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:47<00:00, 407.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:47<00:00, 407.07s/it]
INFO:root:final mean train loss: 4909.138374820833
INFO:root:final train perplexity: 6.93649959564209
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.33s/it]
INFO:root:eval mean loss: 4631.184833499557
INFO:root:eval perplexity: 6.505937576293945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/7
  4%|â–Ž         | 7/200 [53:39<24:31:09, 457.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4805.588094815341
INFO:root:current train perplexity6.747670650482178
INFO:root:current mean train loss 4855.3478547127015
INFO:root:current train perplexity6.80290412902832
INFO:root:current mean train loss 4846.888957184437
INFO:root:current train perplexity6.754918575286865
INFO:root:current mean train loss 4845.491345730634
INFO:root:current train perplexity6.7458906173706055
INFO:root:current mean train loss 4839.270155820742
INFO:root:current train perplexity6.727759838104248
INFO:root:current mean train loss 4833.139905335022
INFO:root:current train perplexity6.709578990936279
INFO:root:current mean train loss 4832.226183057013
INFO:root:current train perplexity6.708847999572754
INFO:root:current mean train loss 4833.410041132036
INFO:root:current train perplexity6.702533721923828
INFO:root:current mean train loss 4824.79769793951
INFO:root:current train perplexity6.686935901641846
INFO:root:current mean train loss 4817.738589046139
INFO:root:current train perplexity6.679354190826416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:50<00:00, 410.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:50<00:00, 410.95s/it]
INFO:root:final mean train loss: 4813.07167514678
INFO:root:final train perplexity: 6.678518772125244
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.22s/it]
INFO:root:eval mean loss: 4559.712132230718
INFO:root:eval perplexity: 6.3205976486206055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/8
  4%|â–         | 8/200 [1:02:27<25:35:36, 479.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4755.629596044147
INFO:root:current train perplexity6.471183776855469
INFO:root:current mean train loss 4747.580642793808
INFO:root:current train perplexity6.501151084899902
INFO:root:current mean train loss 4742.735031301984
INFO:root:current train perplexity6.502834320068359
INFO:root:current mean train loss 4752.8523581428635
INFO:root:current train perplexity6.501284122467041
INFO:root:current mean train loss 4756.372154153449
INFO:root:current train perplexity6.508828163146973
INFO:root:current mean train loss 4747.710401084452
INFO:root:current train perplexity6.493978500366211
INFO:root:current mean train loss 4744.168181222309
INFO:root:current train perplexity6.489349842071533
INFO:root:current mean train loss 4742.178619744737
INFO:root:current train perplexity6.481833457946777
INFO:root:current mean train loss 4737.266749517942
INFO:root:current train perplexity6.473292350769043
INFO:root:current mean train loss 4733.678950514749
INFO:root:current train perplexity6.4638190269470215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:52<00:00, 412.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:52<00:00, 412.44s/it]
INFO:root:final mean train loss: 4731.43360827046
INFO:root:final train perplexity: 6.466837406158447
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.49s/it]
INFO:root:eval mean loss: 4500.775286735372
INFO:root:eval perplexity: 6.1717448234558105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/9
  4%|â–         | 9/200 [1:11:16<26:16:53, 495.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4654.9257262323945
INFO:root:current train perplexity6.2456560134887695
INFO:root:current mean train loss 4665.439307497259
INFO:root:current train perplexity6.294924259185791
INFO:root:current mean train loss 4687.971286900369
INFO:root:current train perplexity6.331653118133545
INFO:root:current mean train loss 4682.088386802981
INFO:root:current train perplexity6.319420337677002
INFO:root:current mean train loss 4674.515994061837
INFO:root:current train perplexity6.31296968460083
INFO:root:current mean train loss 4675.630761889776
INFO:root:current train perplexity6.310208320617676
INFO:root:current mean train loss 4677.340703154107
INFO:root:current train perplexity6.315924644470215
INFO:root:current mean train loss 4667.272764925827
INFO:root:current train perplexity6.301208972930908
INFO:root:current mean train loss 4669.864320599527
INFO:root:current train perplexity6.298885822296143
INFO:root:current mean train loss 4665.5207356100345
INFO:root:current train perplexity6.291613578796387

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:55<00:00, 415.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:55<00:00, 415.12s/it]
INFO:root:final mean train loss: 4661.275536444879
INFO:root:final train perplexity: 6.290295124053955
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.23s/it]
INFO:root:eval mean loss: 4451.134296390182
INFO:root:eval perplexity: 6.049092769622803
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/10
  5%|â–Œ         | 10/200 [1:19:31<26:08:18, 495.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4647.985954188093
INFO:root:current train perplexity6.168811321258545
INFO:root:current mean train loss 4611.432283028544
INFO:root:current train perplexity6.13844108581543
INFO:root:current mean train loss 4621.070270497312
INFO:root:current train perplexity6.1513471603393555
INFO:root:current mean train loss 4616.195297039908
INFO:root:current train perplexity6.1562724113464355
INFO:root:current mean train loss 4619.4202083197415
INFO:root:current train perplexity6.153708457946777
INFO:root:current mean train loss 4612.505680169878
INFO:root:current train perplexity6.152342319488525
INFO:root:current mean train loss 4612.780179592576
INFO:root:current train perplexity6.151516914367676
INFO:root:current mean train loss 4610.81329447559
INFO:root:current train perplexity6.1481709480285645
INFO:root:current mean train loss 4604.839293253164
INFO:root:current train perplexity6.142947196960449
INFO:root:current mean train loss 4603.856603168491
INFO:root:current train perplexity6.142405986785889

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:53<00:00, 413.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:53<00:00, 413.24s/it]
INFO:root:final mean train loss: 4600.958704794607
INFO:root:final train perplexity: 6.142374038696289
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.32s/it]
INFO:root:eval mean loss: 4405.238307222407
INFO:root:eval perplexity: 5.937861442565918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/11
  6%|â–Œ         | 11/200 [1:28:15<26:27:02, 503.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4550.352572737069
INFO:root:current train perplexity6.002882480621338
INFO:root:current mean train loss 4570.578644614806
INFO:root:current train perplexity6.033691883087158
INFO:root:current mean train loss 4558.469752082426
INFO:root:current train perplexity6.009268283843994
INFO:root:current mean train loss 4558.9234849402455
INFO:root:current train perplexity6.0229716300964355
INFO:root:current mean train loss 4556.1438474557235
INFO:root:current train perplexity6.021500587463379
INFO:root:current mean train loss 4552.113548265811
INFO:root:current train perplexity6.013883590698242
INFO:root:current mean train loss 4551.5007288681545
INFO:root:current train perplexity6.015079975128174
INFO:root:current mean train loss 4548.748370741344
INFO:root:current train perplexity6.009085178375244
INFO:root:current mean train loss 4549.551222739924
INFO:root:current train perplexity6.010207653045654
INFO:root:current mean train loss 4548.8049148204
INFO:root:current train perplexity6.009195327758789

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:51<00:00, 411.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:51<00:00, 411.52s/it]
INFO:root:final mean train loss: 4545.446586485832
INFO:root:final train perplexity: 6.009311199188232
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.37s/it]
INFO:root:eval mean loss: 4371.064917165337
INFO:root:eval perplexity: 5.8563714027404785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/12
  6%|â–Œ         | 12/200 [1:36:20<26:00:52, 498.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4517.961983449835
INFO:root:current train perplexity5.930127143859863
INFO:root:current mean train loss 4500.399421574519
INFO:root:current train perplexity5.918858528137207
INFO:root:current mean train loss 4503.455880064884
INFO:root:current train perplexity5.925155162811279
INFO:root:current mean train loss 4496.802053871637
INFO:root:current train perplexity5.909808158874512
INFO:root:current mean train loss 4502.089565084438
INFO:root:current train perplexity5.909390449523926
INFO:root:current mean train loss 4495.946101135767
INFO:root:current train perplexity5.903993129730225
INFO:root:current mean train loss 4493.331419317671
INFO:root:current train perplexity5.899731636047363
INFO:root:current mean train loss 4497.371306259827
INFO:root:current train perplexity5.894227981567383
INFO:root:current mean train loss 4498.803751309358
INFO:root:current train perplexity5.896078586578369

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:53<00:00, 413.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:53<00:00, 413.20s/it]
INFO:root:final mean train loss: 4497.642232956425
INFO:root:final train perplexity: 5.897036552429199
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.56s/it]
INFO:root:eval mean loss: 4334.087163397607
INFO:root:eval perplexity: 5.769454479217529
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/13
  6%|â–‹         | 13/200 [1:44:45<25:58:47, 500.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4720.325846354167
INFO:root:current train perplexity6.0707783699035645
INFO:root:current mean train loss 4470.2827551388045
INFO:root:current train perplexity5.788926601409912
INFO:root:current mean train loss 4469.4131857585435
INFO:root:current train perplexity5.791408538818359
INFO:root:current mean train loss 4468.702321672597
INFO:root:current train perplexity5.799936294555664
INFO:root:current mean train loss 4470.5533498759305
INFO:root:current train perplexity5.804784297943115
INFO:root:current mean train loss 4466.784590309704
INFO:root:current train perplexity5.807198524475098
INFO:root:current mean train loss 4462.249662737743
INFO:root:current train perplexity5.806639194488525
INFO:root:current mean train loss 4458.690510604663
INFO:root:current train perplexity5.799805641174316
INFO:root:current mean train loss 4457.128557825148
INFO:root:current train perplexity5.796962738037109
INFO:root:current mean train loss 4457.059991813313
INFO:root:current train perplexity5.795588493347168

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:48<00:00, 408.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:48<00:00, 408.02s/it]
INFO:root:final mean train loss: 4453.401048229587
INFO:root:final train perplexity: 5.795001029968262
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.92s/it]
INFO:root:eval mean loss: 4308.920415350732
INFO:root:eval perplexity: 5.711038589477539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/14
  7%|â–‹         | 14/200 [1:52:21<25:09:25, 486.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4402.759454900568
INFO:root:current train perplexity5.621352195739746
INFO:root:current mean train loss 4407.587219788147
INFO:root:current train perplexity5.711862564086914
INFO:root:current mean train loss 4397.988889865966
INFO:root:current train perplexity5.706268787384033
INFO:root:current mean train loss 4402.284486629572
INFO:root:current train perplexity5.703714370727539
INFO:root:current mean train loss 4400.555796528095
INFO:root:current train perplexity5.7002787590026855
INFO:root:current mean train loss 4403.220456117753
INFO:root:current train perplexity5.7028656005859375
INFO:root:current mean train loss 4410.136116589735
INFO:root:current train perplexity5.706748962402344
INFO:root:current mean train loss 4410.610907145526
INFO:root:current train perplexity5.701879501342773
INFO:root:current mean train loss 4412.399201229674
INFO:root:current train perplexity5.704775810241699
INFO:root:current mean train loss 4414.948392530959
INFO:root:current train perplexity5.701694011688232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:44<00:00, 404.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:44<00:00, 404.53s/it]
INFO:root:final mean train loss: 4411.537851825838
INFO:root:final train perplexity: 5.700075149536133
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.69s/it]
INFO:root:eval mean loss: 4280.930877036237
INFO:root:eval perplexity: 5.646764755249023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/15
  8%|â–Š         | 15/200 [1:59:56<24:32:11, 477.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4434.3849069695725
INFO:root:current train perplexity5.692729473114014
INFO:root:current mean train loss 4374.08359457064
INFO:root:current train perplexity5.596635818481445
INFO:root:current mean train loss 4372.803926093393
INFO:root:current train perplexity5.613148212432861
INFO:root:current mean train loss 4371.592641035218
INFO:root:current train perplexity5.614543437957764
INFO:root:current mean train loss 4376.881985102178
INFO:root:current train perplexity5.620969772338867
INFO:root:current mean train loss 4374.384783500422
INFO:root:current train perplexity5.616239547729492
INFO:root:current mean train loss 4373.38546136662
INFO:root:current train perplexity5.616176605224609
INFO:root:current mean train loss 4376.219833522579
INFO:root:current train perplexity5.61903715133667
INFO:root:current mean train loss 4375.8713951250575
INFO:root:current train perplexity5.619668006896973
INFO:root:current mean train loss 4375.712332475432
INFO:root:current train perplexity5.616629600524902

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:47<00:00, 407.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:47<00:00, 407.85s/it]
INFO:root:final mean train loss: 4375.780237505513
INFO:root:final train perplexity: 5.62022590637207
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.42s/it]
INFO:root:eval mean loss: 4259.356086893285
INFO:root:eval perplexity: 5.597714900970459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/16
  8%|â–Š         | 16/200 [2:07:30<24:01:47, 470.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4373.244493272569
INFO:root:current train perplexity5.621274471282959
INFO:root:current mean train loss 4322.0190352792815
INFO:root:current train perplexity5.549753189086914
INFO:root:current mean train loss 4335.387159708838
INFO:root:current train perplexity5.547614097595215
INFO:root:current mean train loss 4333.759695443903
INFO:root:current train perplexity5.540551662445068
INFO:root:current mean train loss 4339.54122031433
INFO:root:current train perplexity5.542113304138184
INFO:root:current mean train loss 4339.060881815554
INFO:root:current train perplexity5.535975933074951
INFO:root:current mean train loss 4338.35368850927
INFO:root:current train perplexity5.531742572784424
INFO:root:current mean train loss 4337.910101847275
INFO:root:current train perplexity5.538086414337158
INFO:root:current mean train loss 4337.975416780815
INFO:root:current train perplexity5.534635543823242
INFO:root:current mean train loss 4340.171897649508
INFO:root:current train perplexity5.539745330810547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.92s/it]
INFO:root:final mean train loss: 4340.551353823754
INFO:root:final train perplexity: 5.542651176452637
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.28s/it]
INFO:root:eval mean loss: 4234.913601922651
INFO:root:eval perplexity: 5.542662143707275
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/17
  8%|â–Š         | 17/200 [2:15:58<24:29:26, 481.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4267.498123604911
INFO:root:current train perplexity5.433315753936768
INFO:root:current mean train loss 4305.584528718171
INFO:root:current train perplexity5.460864067077637
INFO:root:current mean train loss 4301.790704995014
INFO:root:current train perplexity5.467403888702393
INFO:root:current mean train loss 4304.686196944963
INFO:root:current train perplexity5.46613073348999
INFO:root:current mean train loss 4305.07875864314
INFO:root:current train perplexity5.471081733703613
INFO:root:current mean train loss 4316.655131516502
INFO:root:current train perplexity5.4749932289123535
INFO:root:current mean train loss 4312.055811315822
INFO:root:current train perplexity5.468451499938965
INFO:root:current mean train loss 4310.714526201105
INFO:root:current train perplexity5.465015888214111
INFO:root:current mean train loss 4311.629865269461
INFO:root:current train perplexity5.472407341003418
INFO:root:current mean train loss 4310.511993701955
INFO:root:current train perplexity5.47453498840332

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:49<00:00, 409.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:49<00:00, 409.66s/it]
INFO:root:final mean train loss: 4309.331292306223
INFO:root:final train perplexity: 5.474801063537598
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.06s/it]
INFO:root:eval mean loss: 4217.114167774823
INFO:root:eval perplexity: 5.502910137176514
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/18
  9%|â–‰         | 18/200 [2:24:07<24:27:35, 483.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4278.622819767442
INFO:root:current train perplexity5.426926136016846
INFO:root:current mean train loss 4291.469275841346
INFO:root:current train perplexity5.426030158996582
INFO:root:current mean train loss 4284.662522304206
INFO:root:current train perplexity5.416193008422852
INFO:root:current mean train loss 4290.3863728248
INFO:root:current train perplexity5.428667068481445
INFO:root:current mean train loss 4291.589520249894
INFO:root:current train perplexity5.425563335418701
INFO:root:current mean train loss 4291.843626356037
INFO:root:current train perplexity5.42309045791626
INFO:root:current mean train loss 4287.918168087213
INFO:root:current train perplexity5.41736364364624
INFO:root:current mean train loss 4284.708840782197
INFO:root:current train perplexity5.413132667541504
INFO:root:current mean train loss 4281.159552414646
INFO:root:current train perplexity5.410658359527588
INFO:root:current mean train loss 4280.478142553271
INFO:root:current train perplexity5.408411979675293

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:43<00:00, 403.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:43<00:00, 403.46s/it]
INFO:root:final mean train loss: 4279.646953582764
INFO:root:final train perplexity: 5.411057949066162
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.62s/it]
INFO:root:eval mean loss: 4200.824731272163
INFO:root:eval perplexity: 5.466783046722412
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/19
 10%|â–‰         | 19/200 [2:32:30<24:37:12, 489.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4224.6241766237745
INFO:root:current train perplexity5.274877071380615
INFO:root:current mean train loss 4222.5611677359275
INFO:root:current train perplexity5.285902500152588
INFO:root:current mean train loss 4251.993784627117
INFO:root:current train perplexity5.314530849456787
INFO:root:current mean train loss 4243.591273120326
INFO:root:current train perplexity5.324816703796387
INFO:root:current mean train loss 4248.58912215476
INFO:root:current train perplexity5.32712459564209
INFO:root:current mean train loss 4246.6100591254535
INFO:root:current train perplexity5.331670761108398
INFO:root:current mean train loss 4254.123984435004
INFO:root:current train perplexity5.344457626342773
INFO:root:current mean train loss 4254.856879304157
INFO:root:current train perplexity5.34471321105957
INFO:root:current mean train loss 4254.763614784537
INFO:root:current train perplexity5.347800254821777
INFO:root:current mean train loss 4257.04142637684
INFO:root:current train perplexity5.350893974304199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:44<00:00, 404.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:44<00:00, 404.67s/it]
INFO:root:final mean train loss: 4250.618084876768
INFO:root:final train perplexity: 5.34943962097168
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.79s/it]
INFO:root:eval mean loss: 4184.158466312057
INFO:root:eval perplexity: 5.430063247680664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/20
 10%|â–ˆ         | 20/200 [2:40:22<24:13:02, 484.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4262.726603879767
INFO:root:current train perplexity5.311596870422363
INFO:root:current mean train loss 4249.520449464426
INFO:root:current train perplexity5.297936916351318
INFO:root:current mean train loss 4240.4609082785355
INFO:root:current train perplexity5.296159267425537
INFO:root:current mean train loss 4238.83545465921
INFO:root:current train perplexity5.306311130523682
INFO:root:current mean train loss 4234.317394514229
INFO:root:current train perplexity5.300429344177246
INFO:root:current mean train loss 4231.490045264283
INFO:root:current train perplexity5.298097610473633
INFO:root:current mean train loss 4232.907353263705
INFO:root:current train perplexity5.298007011413574
INFO:root:current mean train loss 4236.258278908309
INFO:root:current train perplexity5.3066229820251465
INFO:root:current mean train loss 4234.285870482119
INFO:root:current train perplexity5.3055419921875
INFO:root:current mean train loss 4231.042871246497
INFO:root:current train perplexity5.300547122955322

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:43<00:00, 403.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:43<00:00, 403.48s/it]
INFO:root:final mean train loss: 4226.513639573128
INFO:root:final train perplexity: 5.298808574676514
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.95s/it]
INFO:root:eval mean loss: 4172.887388838099
INFO:root:eval perplexity: 5.40537166595459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/21
 10%|â–ˆ         | 21/200 [2:49:04<24:38:33, 495.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4176.416416452892
INFO:root:current train perplexity5.230902671813965
INFO:root:current mean train loss 4194.641227311003
INFO:root:current train perplexity5.260738849639893
INFO:root:current mean train loss 4198.281255486306
INFO:root:current train perplexity5.246889591217041
INFO:root:current mean train loss 4195.4218730043
INFO:root:current train perplexity5.236931324005127
INFO:root:current mean train loss 4201.303397266462
INFO:root:current train perplexity5.244928359985352
INFO:root:current mean train loss 4200.377894810268
INFO:root:current train perplexity5.238869667053223
INFO:root:current mean train loss 4202.412137193122
INFO:root:current train perplexity5.240460395812988
INFO:root:current mean train loss 4203.488829054453
INFO:root:current train perplexity5.240860462188721
INFO:root:current mean train loss 4205.346810909566
INFO:root:current train perplexity5.2425689697265625
INFO:root:current mean train loss 4203.970473627763
INFO:root:current train perplexity5.245144367218018

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:43<00:00, 403.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:43<00:00, 403.89s/it]
INFO:root:final mean train loss: 4202.272632844986
INFO:root:final train perplexity: 5.248373508453369
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.03s/it]
INFO:root:eval mean loss: 4155.1587987588655
INFO:root:eval perplexity: 5.366758823394775
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/22
 11%|â–ˆ         | 22/200 [2:56:32<23:47:36, 481.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4191.5774609375
INFO:root:current train perplexity5.194532871246338
INFO:root:current mean train loss 4182.607449776786
INFO:root:current train perplexity5.202700138092041
INFO:root:current mean train loss 4175.5950390625
INFO:root:current train perplexity5.183977127075195
INFO:root:current mean train loss 4174.816578125
INFO:root:current train perplexity5.18911075592041
INFO:root:current mean train loss 4175.656043893914
INFO:root:current train perplexity5.192044734954834
INFO:root:current mean train loss 4180.516691151494
INFO:root:current train perplexity5.197097301483154
INFO:root:current mean train loss 4178.106155598958
INFO:root:current train perplexity5.1985368728637695
INFO:root:current mean train loss 4182.540425907258
INFO:root:current train perplexity5.201411724090576
INFO:root:current mean train loss 4182.327553013393
INFO:root:current train perplexity5.200354099273682
INFO:root:current mean train loss 4184.3034149639425
INFO:root:current train perplexity5.201779842376709

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.64s/it]
INFO:root:final mean train loss: 4179.0599575658
INFO:root:final train perplexity: 5.200526237487793
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.72s/it]
INFO:root:eval mean loss: 4145.025582820811
INFO:root:eval perplexity: 5.344813823699951
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/23
 12%|â–ˆâ–        | 23/200 [3:03:56<23:06:34, 470.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4161.033044286521
INFO:root:current train perplexity5.112167835235596
INFO:root:current mean train loss 4158.91007353569
INFO:root:current train perplexity5.135351657867432
INFO:root:current mean train loss 4158.870364778876
INFO:root:current train perplexity5.137304782867432
INFO:root:current mean train loss 4164.562620476705
INFO:root:current train perplexity5.146836757659912
INFO:root:current mean train loss 4166.308562916505
INFO:root:current train perplexity5.15217924118042
INFO:root:current mean train loss 4159.814268030393
INFO:root:current train perplexity5.1459784507751465
INFO:root:current mean train loss 4154.347742038799
INFO:root:current train perplexity5.139312267303467
INFO:root:current mean train loss 4159.246787820282
INFO:root:current train perplexity5.14959716796875
INFO:root:current mean train loss 4158.86208681342
INFO:root:current train perplexity5.153313159942627
INFO:root:current mean train loss 4158.960679699421
INFO:root:current train perplexity5.153130054473877

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.73s/it]
INFO:root:final mean train loss: 4155.6757546086465
INFO:root:final train perplexity: 5.152769565582275
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.51s/it]
INFO:root:eval mean loss: 4133.793687319925
INFO:root:eval perplexity: 5.320593357086182
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/24
 12%|â–ˆâ–        | 24/200 [3:11:19<22:35:40, 462.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4106.112135667067
INFO:root:current train perplexity5.073266506195068
INFO:root:current mean train loss 4121.499098852667
INFO:root:current train perplexity5.096800327301025
INFO:root:current mean train loss 4118.646437392612
INFO:root:current train perplexity5.085350036621094
INFO:root:current mean train loss 4129.317092466233
INFO:root:current train perplexity5.104692459106445
INFO:root:current mean train loss 4129.042045888493
INFO:root:current train perplexity5.106698036193848
INFO:root:current mean train loss 4134.98393463806
INFO:root:current train perplexity5.11060905456543
INFO:root:current mean train loss 4137.551396371314
INFO:root:current train perplexity5.113968372344971
INFO:root:current mean train loss 4141.66290352649
INFO:root:current train perplexity5.11513614654541
INFO:root:current mean train loss 4140.5725199039
INFO:root:current train perplexity5.117984294891357
INFO:root:current mean train loss 4139.554419216306
INFO:root:current train perplexity5.1134724617004395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.20s/it]
INFO:root:final mean train loss: 4136.199902011502
INFO:root:final train perplexity: 5.113327980041504
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.42s/it]
INFO:root:eval mean loss: 4123.97777627715
INFO:root:eval perplexity: 5.299516201019287
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/25
 12%|â–ˆâ–Ž        | 25/200 [3:18:40<22:08:43, 455.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4086.4348317155936
INFO:root:current train perplexity5.074682712554932
INFO:root:current mean train loss 4098.209473883087
INFO:root:current train perplexity5.04875373840332
INFO:root:current mean train loss 4111.460956280048
INFO:root:current train perplexity5.058791637420654
INFO:root:current mean train loss 4117.89262156857
INFO:root:current train perplexity5.068857192993164
INFO:root:current mean train loss 4117.923746418618
INFO:root:current train perplexity5.066912651062012
INFO:root:current mean train loss 4117.055463125392
INFO:root:current train perplexity5.063076496124268
INFO:root:current mean train loss 4118.063452113511
INFO:root:current train perplexity5.065859317779541
INFO:root:current mean train loss 4121.725773244388
INFO:root:current train perplexity5.069890022277832
INFO:root:current mean train loss 4121.634656997358
INFO:root:current train perplexity5.074344158172607

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:45<00:00, 405.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:45<00:00, 405.19s/it]
INFO:root:final mean train loss: 4115.767731143582
INFO:root:final train perplexity: 5.072275638580322
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.19s/it]
INFO:root:eval mean loss: 4117.507845398382
INFO:root:eval perplexity: 5.285669803619385
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/26
 13%|â–ˆâ–Ž        | 26/200 [3:26:12<21:57:58, 454.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4151.6171875
INFO:root:current train perplexity5.12404203414917
INFO:root:current mean train loss 4086.2820303373246
INFO:root:current train perplexity5.032931804656982
INFO:root:current mean train loss 4097.384073303518
INFO:root:current train perplexity5.044501304626465
INFO:root:current mean train loss 4099.401391840136
INFO:root:current train perplexity5.040805339813232
INFO:root:current mean train loss 4108.008203005029
INFO:root:current train perplexity5.055135726928711
INFO:root:current mean train loss 4099.351261056151
INFO:root:current train perplexity5.04356575012207
INFO:root:current mean train loss 4101.43244102013
INFO:root:current train perplexity5.035825252532959
INFO:root:current mean train loss 4102.975266517305
INFO:root:current train perplexity5.040022373199463
INFO:root:current mean train loss 4100.574104696697
INFO:root:current train perplexity5.036417484283447
INFO:root:current mean train loss 4098.7715306728915
INFO:root:current train perplexity5.034004211425781

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.19s/it]
INFO:root:final mean train loss: 4096.989642420122
INFO:root:final train perplexity: 5.0348358154296875
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.18s/it]
INFO:root:eval mean loss: 4102.809608405363
INFO:root:eval perplexity: 5.25434684753418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/27
 14%|â–ˆâ–Ž        | 27/200 [3:33:36<21:42:06, 451.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4110.266731770834
INFO:root:current train perplexity4.968666076660156
INFO:root:current mean train loss 4058.091830842391
INFO:root:current train perplexity4.975407123565674
INFO:root:current mean train loss 4057.0722633539244
INFO:root:current train perplexity4.974565505981445
INFO:root:current mean train loss 4071.8254425533232
INFO:root:current train perplexity4.991340160369873
INFO:root:current mean train loss 4082.5868134647967
INFO:root:current train perplexity5.005574703216553
INFO:root:current mean train loss 4077.267892426426
INFO:root:current train perplexity4.995173931121826
INFO:root:current mean train loss 4079.852829252414
INFO:root:current train perplexity4.995824813842773
INFO:root:current mean train loss 4080.846949778737
INFO:root:current train perplexity4.994832515716553
INFO:root:current mean train loss 4084.120909221626
INFO:root:current train perplexity4.998271942138672
INFO:root:current mean train loss 4080.652421394723
INFO:root:current train perplexity4.996199607849121

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.79s/it]
INFO:root:final mean train loss: 4079.2471889372796
INFO:root:final train perplexity: 4.999715328216553
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.24s/it]
INFO:root:eval mean loss: 4096.552846922096
INFO:root:eval perplexity: 5.241070747375488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/28
 14%|â–ˆâ–        | 28/200 [3:41:00<21:27:41, 449.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4096.151494565217
INFO:root:current train perplexity4.981637954711914
INFO:root:current mean train loss 4065.9399096481197
INFO:root:current train perplexity4.9520978927612305
INFO:root:current mean train loss 4072.360093189462
INFO:root:current train perplexity4.972415924072266
INFO:root:current mean train loss 4062.753834443934
INFO:root:current train perplexity4.963118076324463
INFO:root:current mean train loss 4073.608573895538
INFO:root:current train perplexity4.970565319061279
INFO:root:current mean train loss 4074.966744125687
INFO:root:current train perplexity4.970927715301514
INFO:root:current mean train loss 4067.43075537031
INFO:root:current train perplexity4.9658684730529785
INFO:root:current mean train loss 4063.9381368592235
INFO:root:current train perplexity4.963695526123047
INFO:root:current mean train loss 4067.41426095696
INFO:root:current train perplexity4.966277599334717
INFO:root:current mean train loss 4065.331726801615
INFO:root:current train perplexity4.965425968170166

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:44<00:00, 404.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:44<00:00, 404.08s/it]
INFO:root:final mean train loss: 4061.0619524063604
INFO:root:final train perplexity: 4.963973045349121
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.23s/it]
INFO:root:eval mean loss: 4092.022419381649
INFO:root:eval perplexity: 5.231478214263916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/29
 14%|â–ˆâ–        | 29/200 [3:48:28<21:19:05, 448.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4073.721986832157
INFO:root:current train perplexity4.932978630065918
INFO:root:current mean train loss 4051.531546323354
INFO:root:current train perplexity4.922125339508057
INFO:root:current mean train loss 4066.684475192776
INFO:root:current train perplexity4.935964584350586
INFO:root:current mean train loss 4068.3069209072887
INFO:root:current train perplexity4.935018539428711
INFO:root:current mean train loss 4065.509032070222
INFO:root:current train perplexity4.930953502655029
INFO:root:current mean train loss 4060.235132249735
INFO:root:current train perplexity4.930084228515625
INFO:root:current mean train loss 4055.0696787403426
INFO:root:current train perplexity4.9268951416015625
INFO:root:current mean train loss 4055.384017839967
INFO:root:current train perplexity4.930955410003662
INFO:root:current mean train loss 4052.4472559298847
INFO:root:current train perplexity4.928063869476318
INFO:root:current mean train loss 4047.502346739477
INFO:root:current train perplexity4.9304633140563965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.12s/it]
INFO:root:final mean train loss: 4044.076040514054
INFO:root:final train perplexity: 4.9308180809021
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.39s/it]
INFO:root:eval mean loss: 4082.1913525736923
INFO:root:eval perplexity: 5.210721015930176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/30
 15%|â–ˆâ–Œ        | 30/200 [3:55:46<21:02:29, 445.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4031.252710586939
INFO:root:current train perplexity4.925444602966309
INFO:root:current mean train loss 4022.9658132868703
INFO:root:current train perplexity4.904020309448242
INFO:root:current mean train loss 4028.439465383107
INFO:root:current train perplexity4.8912529945373535
INFO:root:current mean train loss 4024.0475800550794
INFO:root:current train perplexity4.887112617492676
INFO:root:current mean train loss 4031.2886759903545
INFO:root:current train perplexity4.89178466796875
INFO:root:current mean train loss 4028.128798447646
INFO:root:current train perplexity4.891594409942627
INFO:root:current mean train loss 4028.2086982070373
INFO:root:current train perplexity4.894511699676514
INFO:root:current mean train loss 4032.8337517971922
INFO:root:current train perplexity4.8983683586120605
INFO:root:current mean train loss 4032.805242126974
INFO:root:current train perplexity4.901889801025391
INFO:root:current mean train loss 4031.9178475896897
INFO:root:current train perplexity4.901584148406982

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.59s/it]
INFO:root:final mean train loss: 4028.3445820346956
INFO:root:final train perplexity: 4.900310516357422
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.67s/it]
INFO:root:eval mean loss: 4075.7331006205673
INFO:root:eval perplexity: 5.197131156921387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/31
 16%|â–ˆâ–Œ        | 31/200 [4:03:57<21:33:15, 459.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4007.126407704455
INFO:root:current train perplexity4.850605010986328
INFO:root:current mean train loss 4002.406887755102
INFO:root:current train perplexity4.840519428253174
INFO:root:current mean train loss 3995.103437539537
INFO:root:current train perplexity4.828249454498291
INFO:root:current mean train loss 4006.845845247208
INFO:root:current train perplexity4.843432426452637
INFO:root:current mean train loss 4011.4556707258457
INFO:root:current train perplexity4.852175712585449
INFO:root:current mean train loss 4013.536502817213
INFO:root:current train perplexity4.862634181976318
INFO:root:current mean train loss 4017.003876439939
INFO:root:current train perplexity4.867342472076416
INFO:root:current mean train loss 4012.3687301288487
INFO:root:current train perplexity4.867332935333252
INFO:root:current mean train loss 4014.801562384703
INFO:root:current train perplexity4.871118068695068
INFO:root:current mean train loss 4015.111537204247
INFO:root:current train perplexity4.870756149291992

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:45<00:00, 405.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:45<00:00, 405.74s/it]
INFO:root:final mean train loss: 4013.742436132123
INFO:root:final train perplexity: 4.872160911560059
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.60s/it]
INFO:root:eval mean loss: 4068.989905391179
INFO:root:eval perplexity: 5.182979106903076
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/32
 16%|â–ˆâ–Œ        | 32/200 [4:12:07<21:51:21, 468.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3995.5137162642045
INFO:root:current train perplexity4.775619029998779
INFO:root:current mean train loss 4012.939650012601
INFO:root:current train perplexity4.830032825469971
INFO:root:current mean train loss 3992.2233283547794
INFO:root:current train perplexity4.818908214569092
INFO:root:current mean train loss 3985.8112731073943
INFO:root:current train perplexity4.825582981109619
INFO:root:current mean train loss 3994.899039534684
INFO:root:current train perplexity4.836120128631592
INFO:root:current mean train loss 3995.9010641012105
INFO:root:current train perplexity4.8364410400390625
INFO:root:current mean train loss 3999.677758229962
INFO:root:current train perplexity4.8376054763793945
INFO:root:current mean train loss 4001.505958648075
INFO:root:current train perplexity4.83830451965332
INFO:root:current mean train loss 4002.56544710572
INFO:root:current train perplexity4.839633941650391
INFO:root:current mean train loss 4001.8188798674737
INFO:root:current train perplexity4.843127250671387

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:46<00:00, 406.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:46<00:00, 406.29s/it]
INFO:root:final mean train loss: 3997.788761631135
INFO:root:final train perplexity: 4.841590881347656
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.55s/it]
INFO:root:eval mean loss: 4061.4712450825577
INFO:root:eval perplexity: 5.167245388031006
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/33
 16%|â–ˆâ–‹        | 33/200 [4:19:36<21:27:56, 462.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3938.0675416976687
INFO:root:current train perplexity4.772230625152588
INFO:root:current mean train loss 3962.1868005296205
INFO:root:current train perplexity4.804040908813477
INFO:root:current mean train loss 3961.535220302103
INFO:root:current train perplexity4.803832530975342
INFO:root:current mean train loss 3971.3807510922434
INFO:root:current train perplexity4.805076599121094
INFO:root:current mean train loss 3981.6105914847126
INFO:root:current train perplexity4.809025287628174
INFO:root:current mean train loss 3977.593863180645
INFO:root:current train perplexity4.801718235015869
INFO:root:current mean train loss 3980.4837154889
INFO:root:current train perplexity4.808469295501709
INFO:root:current mean train loss 3978.389723311558
INFO:root:current train perplexity4.804131507873535
INFO:root:current mean train loss 3980.297632316863
INFO:root:current train perplexity4.805539131164551
INFO:root:current mean train loss 3987.4791950610074
INFO:root:current train perplexity4.815993785858154

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:35<00:00, 395.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:35<00:00, 395.20s/it]
INFO:root:final mean train loss: 3984.163183950609
INFO:root:final train perplexity: 4.815633296966553
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.61s/it]
INFO:root:eval mean loss: 4057.4394306155805
INFO:root:eval perplexity: 5.1588287353515625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/34
 17%|â–ˆâ–‹        | 34/200 [4:27:43<21:39:54, 469.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3998.797899702905
INFO:root:current train perplexity4.786562442779541
INFO:root:current mean train loss 3963.956782826206
INFO:root:current train perplexity4.765266418457031
INFO:root:current mean train loss 3961.832008727802
INFO:root:current train perplexity4.771754741668701
INFO:root:current mean train loss 3964.006624699924
INFO:root:current train perplexity4.767004489898682
INFO:root:current mean train loss 3963.815788900776
INFO:root:current train perplexity4.767570972442627
INFO:root:current mean train loss 3967.5928987145635
INFO:root:current train perplexity4.776773452758789
INFO:root:current mean train loss 3970.4649856499163
INFO:root:current train perplexity4.781622886657715
INFO:root:current mean train loss 3969.0442109856317
INFO:root:current train perplexity4.780549049377441
INFO:root:current mean train loss 3972.6900515638454
INFO:root:current train perplexity4.784570693969727
INFO:root:current mean train loss 3971.643080486451
INFO:root:current train perplexity4.786515712738037

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:32<00:00, 392.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:32<00:00, 392.90s/it]
INFO:root:final mean train loss: 3968.897359232749
INFO:root:final train perplexity: 4.786717414855957
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.31s/it]
INFO:root:eval mean loss: 4054.1018031776375
INFO:root:eval perplexity: 5.151870250701904
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/35
 18%|â–ˆâ–Š        | 35/200 [4:35:11<21:14:18, 463.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3983.90176275712
INFO:root:current train perplexity4.786113739013672
INFO:root:current mean train loss 3960.039373472416
INFO:root:current train perplexity4.748425483703613
INFO:root:current mean train loss 3962.4564773395496
INFO:root:current train perplexity4.758162498474121
INFO:root:current mean train loss 3960.6456798060276
INFO:root:current train perplexity4.7556586265563965
INFO:root:current mean train loss 3958.239942323689
INFO:root:current train perplexity4.757195472717285
INFO:root:current mean train loss 3961.364539059127
INFO:root:current train perplexity4.756089687347412
INFO:root:current mean train loss 3961.6987027827
INFO:root:current train perplexity4.759380340576172
INFO:root:current mean train loss 3959.1997847550947
INFO:root:current train perplexity4.758798122406006
INFO:root:current mean train loss 3957.2284028592508
INFO:root:current train perplexity4.757106781005859
INFO:root:current mean train loss 3956.759053901462
INFO:root:current train perplexity4.758579254150391

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:34<00:00, 394.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:34<00:00, 394.91s/it]
INFO:root:final mean train loss: 3953.746691057759
INFO:root:final train perplexity: 4.758190631866455
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.57s/it]
INFO:root:eval mean loss: 4050.22073948637
INFO:root:eval perplexity: 5.143790245056152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/36
 18%|â–ˆâ–Š        | 36/200 [4:42:30<20:46:50, 456.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3908.4540819190015
INFO:root:current train perplexity4.706739902496338
INFO:root:current mean train loss 3916.121750449114
INFO:root:current train perplexity4.699450969696045
INFO:root:current mean train loss 3929.951273954704
INFO:root:current train perplexity4.712623119354248
INFO:root:current mean train loss 3935.635880975452
INFO:root:current train perplexity4.722464084625244
INFO:root:current mean train loss 3932.6018226827196
INFO:root:current train perplexity4.726889610290527
INFO:root:current mean train loss 3933.8879669033486
INFO:root:current train perplexity4.729714393615723
INFO:root:current mean train loss 3938.384622054676
INFO:root:current train perplexity4.731175422668457
INFO:root:current mean train loss 3940.8945721986183
INFO:root:current train perplexity4.732712268829346
INFO:root:current mean train loss 3942.3743308840367
INFO:root:current train perplexity4.731423854827881
INFO:root:current mean train loss 3944.2322195375823
INFO:root:current train perplexity4.735287666320801

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:51<00:00, 411.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:51<00:00, 411.65s/it]
INFO:root:final mean train loss: 3941.34781400619
INFO:root:final train perplexity: 4.734971523284912
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.82s/it]
INFO:root:eval mean loss: 4042.15018977172
INFO:root:eval perplexity: 5.1270318031311035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/37
 18%|â–ˆâ–Š        | 37/200 [4:50:14<20:44:58, 458.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3902.733560341283
INFO:root:current train perplexity4.662593841552734
INFO:root:current mean train loss 3904.515290715144
INFO:root:current train perplexity4.671910762786865
INFO:root:current mean train loss 3913.6390641551907
INFO:root:current train perplexity4.68806266784668
INFO:root:current mean train loss 3907.1231012658227
INFO:root:current train perplexity4.689766883850098
INFO:root:current mean train loss 3914.2189453125
INFO:root:current train perplexity4.696016788482666
INFO:root:current mean train loss 3918.281490858062
INFO:root:current train perplexity4.698974609375
INFO:root:current mean train loss 3919.439198797212
INFO:root:current train perplexity4.699848175048828
INFO:root:current mean train loss 3926.1831066971304
INFO:root:current train perplexity4.706971645355225
INFO:root:current mean train loss 3931.8658983283867
INFO:root:current train perplexity4.711320400238037

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:50<00:00, 410.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:50<00:00, 410.54s/it]
INFO:root:final mean train loss: 3928.2985246719854
INFO:root:final train perplexity: 4.710657119750977
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.75s/it]
INFO:root:eval mean loss: 4038.7698100205007
INFO:root:eval perplexity: 5.120028018951416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/38
 19%|â–ˆâ–‰        | 38/200 [4:57:50<20:36:12, 457.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3848.82958984375
INFO:root:current train perplexity4.521981716156006
INFO:root:current mean train loss 3921.1453395213894
INFO:root:current train perplexity4.676578998565674
INFO:root:current mean train loss 3913.6269916102215
INFO:root:current train perplexity4.67318868637085
INFO:root:current mean train loss 3915.5814583655633
INFO:root:current train perplexity4.672235012054443
INFO:root:current mean train loss 3911.5081753789937
INFO:root:current train perplexity4.669578552246094
INFO:root:current mean train loss 3913.596216160071
INFO:root:current train perplexity4.668904781341553
INFO:root:current mean train loss 3918.199234135313
INFO:root:current train perplexity4.676677703857422
INFO:root:current mean train loss 3915.7085638141225
INFO:root:current train perplexity4.680383205413818
INFO:root:current mean train loss 3917.7436210280785
INFO:root:current train perplexity4.681544780731201
INFO:root:current mean train loss 3919.849200040663
INFO:root:current train perplexity4.684804916381836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:56<00:00, 416.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:56<00:00, 416.33s/it]
INFO:root:final mean train loss: 3915.9735034819573
INFO:root:final train perplexity: 4.687807083129883
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.54s/it]
INFO:root:eval mean loss: 4034.438933676862
INFO:root:eval perplexity: 5.1110687255859375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/39
 20%|â–ˆâ–‰        | 39/200 [5:05:31<20:30:40, 458.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3859.5906205610795
INFO:root:current train perplexity4.601615905761719
INFO:root:current mean train loss 3887.1496252111488
INFO:root:current train perplexity4.633061408996582
INFO:root:current mean train loss 3896.4485858356784
INFO:root:current train perplexity4.639424800872803
INFO:root:current mean train loss 3896.7695383151627
INFO:root:current train perplexity4.654156684875488
INFO:root:current mean train loss 3900.511290464378
INFO:root:current train perplexity4.662939071655273
INFO:root:current mean train loss 3904.320660316781
INFO:root:current train perplexity4.663717269897461
INFO:root:current mean train loss 3902.455567205401
INFO:root:current train perplexity4.659224987030029
INFO:root:current mean train loss 3904.6359478699674
INFO:root:current train perplexity4.6641106605529785
INFO:root:current mean train loss 3905.476950235049
INFO:root:current train perplexity4.663624286651611
INFO:root:current mean train loss 3906.7484577065898
INFO:root:current train perplexity4.665557861328125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:57<00:00, 417.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:57<00:00, 417.48s/it]
INFO:root:final mean train loss: 3904.5644394659225
INFO:root:final train perplexity: 4.666753768920898
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.39s/it]
INFO:root:eval mean loss: 4034.565403715093
INFO:root:eval perplexity: 5.111331462860107
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/40
 20%|â–ˆâ–ˆ        | 40/200 [5:13:13<20:26:00, 459.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3895.942999588816
INFO:root:current train perplexity4.645524978637695
INFO:root:current mean train loss 3891.8178444229256
INFO:root:current train perplexity4.646644592285156
INFO:root:current mean train loss 3888.8877053456763
INFO:root:current train perplexity4.6420769691467285
INFO:root:current mean train loss 3897.557881992065
INFO:root:current train perplexity4.643430233001709
INFO:root:current mean train loss 3897.9830301872016
INFO:root:current train perplexity4.645660400390625
INFO:root:current mean train loss 3901.072366291847
INFO:root:current train perplexity4.648411273956299
INFO:root:current mean train loss 3898.976554217362
INFO:root:current train perplexity4.6455888748168945
INFO:root:current mean train loss 3904.173621335514
INFO:root:current train perplexity4.653803825378418
INFO:root:current mean train loss 3900.301038804945
INFO:root:current train perplexity4.649240970611572
INFO:root:current mean train loss 3897.28810719022
INFO:root:current train perplexity4.648697376251221

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:50<00:00, 410.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:50<00:00, 410.87s/it]
INFO:root:final mean train loss: 3894.0868753002537
INFO:root:final train perplexity: 4.6475019454956055
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.83s/it]
INFO:root:eval mean loss: 4028.76077854887
INFO:root:eval perplexity: 5.099347114562988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/41
 20%|â–ˆâ–ˆ        | 41/200 [5:21:02<20:25:28, 462.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3845.162995515046
INFO:root:current train perplexity4.613061428070068
INFO:root:current mean train loss 3864.0474574772393
INFO:root:current train perplexity4.596315383911133
INFO:root:current mean train loss 3869.3192692559196
INFO:root:current train perplexity4.608212947845459
INFO:root:current mean train loss 3870.0485511336487
INFO:root:current train perplexity4.601588249206543
INFO:root:current mean train loss 3871.5500934252414
INFO:root:current train perplexity4.608452796936035
INFO:root:current mean train loss 3872.6741718675876
INFO:root:current train perplexity4.605421543121338
INFO:root:current mean train loss 3875.180391886588
INFO:root:current train perplexity4.6051836013793945
INFO:root:current mean train loss 3879.950702063811
INFO:root:current train perplexity4.613061904907227
INFO:root:current mean train loss 3885.3654796964743
INFO:root:current train perplexity4.621456146240234
INFO:root:current mean train loss 3885.2851304400956
INFO:root:current train perplexity4.622718811035156

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:56<00:00, 416.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:56<00:00, 416.83s/it]
INFO:root:final mean train loss: 3881.199659286007
INFO:root:final train perplexity: 4.623932361602783
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.05s/it]
INFO:root:eval mean loss: 4023.770601313165
INFO:root:eval perplexity: 5.089068412780762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/42
 21%|â–ˆâ–ˆ        | 42/200 [5:29:29<20:52:40, 475.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3809.223779296875
INFO:root:current train perplexity4.563638210296631
INFO:root:current mean train loss 3833.5656467013887
INFO:root:current train perplexity4.5763349533081055
INFO:root:current mean train loss 3850.0968386386303
INFO:root:current train perplexity4.577407360076904
INFO:root:current mean train loss 3862.717000204058
INFO:root:current train perplexity4.591745853424072
INFO:root:current mean train loss 3866.704428205819
INFO:root:current train perplexity4.593655586242676
INFO:root:current mean train loss 3869.5634418808413
INFO:root:current train perplexity4.596734046936035
INFO:root:current mean train loss 3869.6249065729576
INFO:root:current train perplexity4.5998311042785645
INFO:root:current mean train loss 3873.9150420519773
INFO:root:current train perplexity4.601684093475342
INFO:root:current mean train loss 3870.868783916542
INFO:root:current train perplexity4.598939895629883
INFO:root:current mean train loss 3870.7588828020553
INFO:root:current train perplexity4.599279880523682

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:03<00:00, 423.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:03<00:00, 423.28s/it]
INFO:root:final mean train loss: 3869.4470145317814
INFO:root:final train perplexity: 4.602542400360107
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.43s/it]
INFO:root:eval mean loss: 4020.1567140403367
INFO:root:eval perplexity: 5.081636905670166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/43
 22%|â–ˆâ–ˆâ–       | 43/200 [5:38:17<21:26:29, 491.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3904.5444733375725
INFO:root:current train perplexity4.596948623657227
INFO:root:current mean train loss 3875.6357626748254
INFO:root:current train perplexity4.589352607727051
INFO:root:current mean train loss 3868.7519320264273
INFO:root:current train perplexity4.574937343597412
INFO:root:current mean train loss 3865.7389168697614
INFO:root:current train perplexity4.575666427612305
INFO:root:current mean train loss 3865.743140364877
INFO:root:current train perplexity4.573809623718262
INFO:root:current mean train loss 3866.312828668134
INFO:root:current train perplexity4.578733444213867
INFO:root:current mean train loss 3865.0159522927197
INFO:root:current train perplexity4.578857421875
INFO:root:current mean train loss 3861.2416535450666
INFO:root:current train perplexity4.578258037567139
INFO:root:current mean train loss 3862.8598056490027
INFO:root:current train perplexity4.583620071411133
INFO:root:current mean train loss 3861.747636004192
INFO:root:current train perplexity4.583056449890137

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:56<00:00, 416.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:56<00:00, 416.75s/it]
INFO:root:final mean train loss: 3858.880871865057
INFO:root:final train perplexity: 4.583395481109619
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.52s/it]
INFO:root:eval mean loss: 4019.726165987921
INFO:root:eval perplexity: 5.080751419067383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/44
 22%|â–ˆâ–ˆâ–       | 44/200 [5:46:38<21:25:11, 494.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3797.614626416973
INFO:root:current train perplexity4.5110626220703125
INFO:root:current mean train loss 3834.38017384106
INFO:root:current train perplexity4.529139995574951
INFO:root:current mean train loss 3840.452469419198
INFO:root:current train perplexity4.545438289642334
INFO:root:current mean train loss 3839.6632813891115
INFO:root:current train perplexity4.545058250427246
INFO:root:current mean train loss 3846.5327099717642
INFO:root:current train perplexity4.546175956726074
INFO:root:current mean train loss 3850.210676965177
INFO:root:current train perplexity4.555962562561035
INFO:root:current mean train loss 3845.9716373097876
INFO:root:current train perplexity4.554512977600098
INFO:root:current mean train loss 3849.1190385475616
INFO:root:current train perplexity4.559195518493652
INFO:root:current mean train loss 3847.4356128589525
INFO:root:current train perplexity4.559764862060547
INFO:root:current mean train loss 3850.247671293786
INFO:root:current train perplexity4.561851501464844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:55<00:00, 415.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:55<00:00, 415.58s/it]
INFO:root:final mean train loss: 3848.1908221090994
INFO:root:final train perplexity: 4.564105987548828
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.12s/it]
INFO:root:eval mean loss: 4014.9330275515294
INFO:root:eval perplexity: 5.070914268493652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [5:54:20<20:52:11, 484.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3835.2886362884005
INFO:root:current train perplexity4.515480995178223
INFO:root:current mean train loss 3845.6222407502946
INFO:root:current train perplexity4.549727916717529
INFO:root:current mean train loss 3839.948827559423
INFO:root:current train perplexity4.547316074371338
INFO:root:current mean train loss 3836.608273986986
INFO:root:current train perplexity4.54263162612915
INFO:root:current mean train loss 3836.2900060848992
INFO:root:current train perplexity4.543559551239014
INFO:root:current mean train loss 3837.1022311570605
INFO:root:current train perplexity4.543074131011963
INFO:root:current mean train loss 3841.954048955567
INFO:root:current train perplexity4.545419216156006
INFO:root:current mean train loss 3844.9242951766305
INFO:root:current train perplexity4.544018745422363
INFO:root:current mean train loss 3842.1945138560463
INFO:root:current train perplexity4.545302391052246
INFO:root:current mean train loss 3841.3618706314355
INFO:root:current train perplexity4.545370578765869

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:56<00:00, 416.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:56<00:00, 416.91s/it]
INFO:root:final mean train loss: 3837.874046202629
INFO:root:final train perplexity: 4.545566082000732
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.66s/it]
INFO:root:eval mean loss: 4013.319341131981
INFO:root:eval perplexity: 5.0676069259643555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [6:02:15<20:36:40, 481.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3846.8303477728546
INFO:root:current train perplexity4.530264854431152
INFO:root:current mean train loss 3833.240104264128
INFO:root:current train perplexity4.504960060119629
INFO:root:current mean train loss 3827.5619906879097
INFO:root:current train perplexity4.511711120605469
INFO:root:current mean train loss 3835.125370534954
INFO:root:current train perplexity4.5238447189331055
INFO:root:current mean train loss 3839.395563750502
INFO:root:current train perplexity4.52655029296875
INFO:root:current mean train loss 3836.1344922047233
INFO:root:current train perplexity4.524562358856201
INFO:root:current mean train loss 3837.5799027976245
INFO:root:current train perplexity4.531554698944092
INFO:root:current mean train loss 3833.3149280374023
INFO:root:current train perplexity4.527836799621582
INFO:root:current mean train loss 3832.5050928804426
INFO:root:current train perplexity4.527771472930908
INFO:root:current mean train loss 3831.606305695369
INFO:root:current train perplexity4.527797222137451

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:00<00:00, 420.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:00<00:00, 420.87s/it]
INFO:root:final mean train loss: 3827.9037927812146
INFO:root:final train perplexity: 4.527720928192139
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.02s/it]
INFO:root:eval mean loss: 4013.471773188165
INFO:root:eval perplexity: 5.067918300628662
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [6:11:17<21:14:07, 499.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3814.520341796875
INFO:root:current train perplexity4.450470924377441
INFO:root:current mean train loss 3809.1077120535715
INFO:root:current train perplexity4.491029262542725
INFO:root:current mean train loss 3809.891534978693
INFO:root:current train perplexity4.490700721740723
INFO:root:current mean train loss 3817.5682721354165
INFO:root:current train perplexity4.501791000366211
INFO:root:current mean train loss 3817.2570065789473
INFO:root:current train perplexity4.50361442565918
INFO:root:current mean train loss 3818.8131475033965
INFO:root:current train perplexity4.5045342445373535
INFO:root:current mean train loss 3817.77761754919
INFO:root:current train perplexity4.505545139312744
INFO:root:current mean train loss 3817.6397300277217
INFO:root:current train perplexity4.508890628814697
INFO:root:current mean train loss 3818.729519810268
INFO:root:current train perplexity4.510283470153809
INFO:root:current mean train loss 3819.566339393029
INFO:root:current train perplexity4.5086541175842285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:58<00:00, 418.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:58<00:00, 418.31s/it]
INFO:root:final mean train loss: 3816.8339947731265
INFO:root:final train perplexity: 4.50799036026001
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.28s/it]
INFO:root:eval mean loss: 4010.4747929133423
INFO:root:eval perplexity: 5.0617804527282715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/48
 24%|â–ˆâ–ˆâ–       | 48/200 [6:19:01<20:39:05, 489.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3810.2075018825303
INFO:root:current train perplexity4.464278221130371
INFO:root:current mean train loss 3816.0822593814037
INFO:root:current train perplexity4.469470024108887
INFO:root:current mean train loss 3803.8881206175465
INFO:root:current train perplexity4.465755462646484
INFO:root:current mean train loss 3800.993791943742
INFO:root:current train perplexity4.47516393661499
INFO:root:current mean train loss 3801.7366506130306
INFO:root:current train perplexity4.4799113273620605
INFO:root:current mean train loss 3805.4302624658285
INFO:root:current train perplexity4.473963260650635
INFO:root:current mean train loss 3806.9671235873443
INFO:root:current train perplexity4.478260040283203
INFO:root:current mean train loss 3806.0588232359514
INFO:root:current train perplexity4.481817245483398
INFO:root:current mean train loss 3806.440251627973
INFO:root:current train perplexity4.483253479003906
INFO:root:current mean train loss 3809.440098123172
INFO:root:current train perplexity4.490694046020508

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:58<00:00, 418.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:58<00:00, 418.17s/it]
INFO:root:final mean train loss: 3807.161494901103
INFO:root:final train perplexity: 4.49082088470459
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.98s/it]
INFO:root:eval mean loss: 4007.5833056294327
INFO:root:eval perplexity: 5.05586576461792
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/49
 24%|â–ˆâ–ˆâ–       | 49/200 [6:26:45<20:11:47, 481.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3801.9191545758927
INFO:root:current train perplexity4.427913665771484
INFO:root:current mean train loss 3798.3135506994436
INFO:root:current train perplexity4.447086811065674
INFO:root:current mean train loss 3789.4433115536403
INFO:root:current train perplexity4.454675674438477
INFO:root:current mean train loss 3793.356620144661
INFO:root:current train perplexity4.460402965545654
INFO:root:current mean train loss 3793.6666431310464
INFO:root:current train perplexity4.46277379989624
INFO:root:current mean train loss 3796.2937040635575
INFO:root:current train perplexity4.465869903564453
INFO:root:current mean train loss 3794.418555606119
INFO:root:current train perplexity4.464181900024414
INFO:root:current mean train loss 3797.053235002173
INFO:root:current train perplexity4.466996192932129
INFO:root:current mean train loss 3796.386327467382
INFO:root:current train perplexity4.468306541442871
INFO:root:current mean train loss 3801.148247311743
INFO:root:current train perplexity4.474970817565918

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:54<00:00, 414.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:54<00:00, 414.96s/it]
INFO:root:final mean train loss: 3798.2498008974135
INFO:root:final train perplexity: 4.475058555603027
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.66s/it]
INFO:root:eval mean loss: 4006.407231756981
INFO:root:eval perplexity: 5.053460597991943
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [6:34:24<19:47:03, 474.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3776.5705665048927
INFO:root:current train perplexity4.410346031188965
INFO:root:current mean train loss 3781.219293488929
INFO:root:current train perplexity4.425785541534424
INFO:root:current mean train loss 3783.8795251750626
INFO:root:current train perplexity4.434202194213867
INFO:root:current mean train loss 3786.2364676339284
INFO:root:current train perplexity4.437397003173828
INFO:root:current mean train loss 3789.903360921061
INFO:root:current train perplexity4.44843864440918
INFO:root:current mean train loss 3788.05318678918
INFO:root:current train perplexity4.452051162719727
INFO:root:current mean train loss 3783.476542591537
INFO:root:current train perplexity4.451584815979004
INFO:root:current mean train loss 3783.6517253011575
INFO:root:current train perplexity4.451892852783203
INFO:root:current mean train loss 3785.3844679852614
INFO:root:current train perplexity4.45326566696167

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:58<00:00, 418.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:58<00:00, 418.77s/it]
INFO:root:final mean train loss: 3787.3783268467073
INFO:root:final train perplexity: 4.455905437469482
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.42s/it]
INFO:root:eval mean loss: 4006.243669658688
INFO:root:eval perplexity: 5.053127765655518
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [6:42:11<19:32:53, 472.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3719.9705636160716
INFO:root:current train perplexity4.395702362060547
INFO:root:current mean train loss 3774.888890917056
INFO:root:current train perplexity4.4157938957214355
INFO:root:current mean train loss 3776.217969221769
INFO:root:current train perplexity4.428213596343994
INFO:root:current mean train loss 3786.33601781988
INFO:root:current train perplexity4.430148601531982
INFO:root:current mean train loss 3787.9992045934428
INFO:root:current train perplexity4.437488555908203
INFO:root:current mean train loss 3785.084383089867
INFO:root:current train perplexity4.436407089233398
INFO:root:current mean train loss 3781.797076104304
INFO:root:current train perplexity4.436868667602539
INFO:root:current mean train loss 3778.1595070500352
INFO:root:current train perplexity4.437774658203125
INFO:root:current mean train loss 3781.24669003398
INFO:root:current train perplexity4.441256999969482
INFO:root:current mean train loss 3781.491992618178
INFO:root:current train perplexity4.439981937408447

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:57<00:00, 417.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:57<00:00, 417.74s/it]
INFO:root:final mean train loss: 3779.06934953505
INFO:root:final train perplexity: 4.441322326660156
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.90s/it]
INFO:root:eval mean loss: 4003.901187112145
INFO:root:eval perplexity: 5.048342704772949
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [6:50:17<19:35:47, 476.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3780.787386067708
INFO:root:current train perplexity4.485938549041748
INFO:root:current mean train loss 3750.4353154721466
INFO:root:current train perplexity4.397166728973389
INFO:root:current mean train loss 3753.2918036882265
INFO:root:current train perplexity4.400996685028076
INFO:root:current mean train loss 3754.7341796875
INFO:root:current train perplexity4.408750534057617
INFO:root:current mean train loss 3760.414610198607
INFO:root:current train perplexity4.408278942108154
INFO:root:current mean train loss 3763.0722286483615
INFO:root:current train perplexity4.411429405212402
INFO:root:current mean train loss 3760.7617350260416
INFO:root:current train perplexity4.415879726409912
INFO:root:current mean train loss 3764.633668870192
INFO:root:current train perplexity4.419218063354492
INFO:root:current mean train loss 3770.5705281825153
INFO:root:current train perplexity4.421749591827393
INFO:root:current mean train loss 3771.643369780994
INFO:root:current train perplexity4.422940254211426

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:00<00:00, 420.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:00<00:00, 420.82s/it]
INFO:root:final mean train loss: 3769.8878442702753
INFO:root:final train perplexity: 4.425263404846191
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.13s/it]
INFO:root:eval mean loss: 4000.08563622008
INFO:root:eval perplexity: 5.040559768676758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [6:58:03<19:19:52, 473.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3764.2842433763585
INFO:root:current train perplexity4.465454578399658
INFO:root:current mean train loss 3765.213380891133
INFO:root:current train perplexity4.4198102951049805
INFO:root:current mean train loss 3753.9806833309976
INFO:root:current train perplexity4.4055352210998535
INFO:root:current mean train loss 3762.9422528057275
INFO:root:current train perplexity4.409730434417725
INFO:root:current mean train loss 3757.6244407275044
INFO:root:current train perplexity4.407291889190674
INFO:root:current mean train loss 3764.177961710534
INFO:root:current train perplexity4.4143242835998535
INFO:root:current mean train loss 3766.224058784987
INFO:root:current train perplexity4.413437843322754
INFO:root:current mean train loss 3761.827628614497
INFO:root:current train perplexity4.407524585723877
INFO:root:current mean train loss 3764.051764042091
INFO:root:current train perplexity4.410292625427246
INFO:root:current mean train loss 3766.136729065801
INFO:root:current train perplexity4.411663055419922

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:55<00:00, 415.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:55<00:00, 415.00s/it]
INFO:root:final mean train loss: 3760.679271697998
INFO:root:final train perplexity: 4.409214973449707
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.43s/it]
INFO:root:eval mean loss: 4001.0530512383643
INFO:root:eval perplexity: 5.042532920837402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [7:05:46<19:04:23, 470.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3743.8421276461695
INFO:root:current train perplexity4.417171955108643
INFO:root:current mean train loss 3744.6599027910306
INFO:root:current train perplexity4.381194114685059
INFO:root:current mean train loss 3755.636576070414
INFO:root:current train perplexity4.394986152648926
INFO:root:current mean train loss 3745.2321327416917
INFO:root:current train perplexity4.383678436279297
INFO:root:current mean train loss 3748.6752046023057
INFO:root:current train perplexity4.390588760375977
INFO:root:current mean train loss 3751.1329899732227
INFO:root:current train perplexity4.396090984344482
INFO:root:current mean train loss 3749.088732929502
INFO:root:current train perplexity4.3968586921691895
INFO:root:current mean train loss 3750.426902760559
INFO:root:current train perplexity4.396355628967285
INFO:root:current mean train loss 3751.6874668015757
INFO:root:current train perplexity4.396090030670166
INFO:root:current mean train loss 3753.3974077038297
INFO:root:current train perplexity4.394567966461182

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:58<00:00, 418.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:58<00:00, 418.03s/it]
INFO:root:final mean train loss: 3752.0604131760138
INFO:root:final train perplexity: 4.394248008728027
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.66s/it]
INFO:root:eval mean loss: 4001.6491993572695
INFO:root:eval perplexity: 5.043747901916504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [7:14:10<19:21:06, 480.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3706.806377704327
INFO:root:current train perplexity4.336978435516357
INFO:root:current mean train loss 3744.9489412376347
INFO:root:current train perplexity4.364776611328125
INFO:root:current mean train loss 3746.3526759446913
INFO:root:current train perplexity4.368023872375488
INFO:root:current mean train loss 3741.8154052014197
INFO:root:current train perplexity4.362369537353516
INFO:root:current mean train loss 3738.282671465689
INFO:root:current train perplexity4.362515449523926
INFO:root:current mean train loss 3735.295720880682
INFO:root:current train perplexity4.366840362548828
INFO:root:current mean train loss 3737.1650031482295
INFO:root:current train perplexity4.3702192306518555
INFO:root:current mean train loss 3740.2960332269113
INFO:root:current train perplexity4.376168251037598
INFO:root:current mean train loss 3742.977362722549
INFO:root:current train perplexity4.378248691558838
INFO:root:current mean train loss 3746.870330128045
INFO:root:current train perplexity4.381065368652344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:00<00:00, 420.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:00<00:00, 420.86s/it]
INFO:root:final mean train loss: 3744.8187378298853
INFO:root:final train perplexity: 4.381711006164551
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.66s/it]
INFO:root:eval mean loss: 3998.2596686613474
INFO:root:eval perplexity: 5.036839962005615
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [7:22:22<19:21:02, 483.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3737.9385388962764
INFO:root:current train perplexity4.361705303192139
INFO:root:current mean train loss 3723.4020846619896
INFO:root:current train perplexity4.34411096572876
INFO:root:current mean train loss 3729.0636198839197
INFO:root:current train perplexity4.346168041229248
INFO:root:current mean train loss 3731.430735123604
INFO:root:current train perplexity4.349030017852783
INFO:root:current mean train loss 3731.4359035278594
INFO:root:current train perplexity4.357367038726807
INFO:root:current mean train loss 3734.594862692099
INFO:root:current train perplexity4.359970569610596
INFO:root:current mean train loss 3739.9759168669098
INFO:root:current train perplexity4.364707946777344
INFO:root:current mean train loss 3739.667580804991
INFO:root:current train perplexity4.365684509277344
INFO:root:current mean train loss 3740.637391505866
INFO:root:current train perplexity4.366689205169678
INFO:root:current mean train loss 3740.4219703875724
INFO:root:current train perplexity4.366653919219971

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:58<00:00, 418.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:58<00:00, 418.89s/it]
INFO:root:final mean train loss: 3736.039273846534
INFO:root:final train perplexity: 4.366560459136963
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.90s/it]
INFO:root:eval mean loss: 3996.3277406083776
INFO:root:eval perplexity: 5.032907009124756
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [7:30:09<19:00:42, 478.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3691.826620205966
INFO:root:current train perplexity4.285582065582275
INFO:root:current mean train loss 3708.342228452621
INFO:root:current train perplexity4.323785781860352
INFO:root:current mean train loss 3714.663241038603
INFO:root:current train perplexity4.32318115234375
INFO:root:current mean train loss 3712.8934150803257
INFO:root:current train perplexity4.323456764221191
INFO:root:current mean train loss 3724.127859933036
INFO:root:current train perplexity4.336303234100342
INFO:root:current mean train loss 3725.1104395411035
INFO:root:current train perplexity4.34205436706543
INFO:root:current mean train loss 3725.166584416746
INFO:root:current train perplexity4.34531831741333
INFO:root:current mean train loss 3726.108038532181
INFO:root:current train perplexity4.350730895996094
INFO:root:current mean train loss 3727.584253643549
INFO:root:current train perplexity4.350121974945068
INFO:root:current mean train loss 3730.1213603873525
INFO:root:current train perplexity4.351857662200928

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:51<00:00, 411.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:51<00:00, 411.46s/it]
INFO:root:final mean train loss: 3727.925726982855
INFO:root:final train perplexity: 4.352605819702148
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.36s/it]
INFO:root:eval mean loss: 3996.380403992132
INFO:root:eval perplexity: 5.033013343811035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [7:37:46<18:37:38, 472.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3716.5166790674602
INFO:root:current train perplexity4.337642669677734
INFO:root:current mean train loss 3696.501330042178
INFO:root:current train perplexity4.294125080108643
INFO:root:current mean train loss 3705.273551679836
INFO:root:current train perplexity4.301949977874756
INFO:root:current mean train loss 3699.1048123278238
INFO:root:current train perplexity4.305706024169922
INFO:root:current mean train loss 3704.811003518156
INFO:root:current train perplexity4.31325626373291
INFO:root:current mean train loss 3707.980479591058
INFO:root:current train perplexity4.316215991973877
INFO:root:current mean train loss 3710.7413980015085
INFO:root:current train perplexity4.320272445678711
INFO:root:current mean train loss 3712.8077429375203
INFO:root:current train perplexity4.327029705047607
INFO:root:current mean train loss 3715.2065944561123
INFO:root:current train perplexity4.331967830657959
INFO:root:current mean train loss 3720.1730936749577
INFO:root:current train perplexity4.336204528808594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:56<00:00, 416.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:56<00:00, 416.45s/it]
INFO:root:final mean train loss: 3719.0403356244487
INFO:root:final train perplexity: 4.337373733520508
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.04s/it]
INFO:root:eval mean loss: 3996.11381974457
INFO:root:eval perplexity: 5.032471179962158
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [7:45:27<18:21:48, 468.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3707.9095063545333
INFO:root:current train perplexity4.30324649810791
INFO:root:current mean train loss 3691.6029345417583
INFO:root:current train perplexity4.281848907470703
INFO:root:current mean train loss 3705.7169275037477
INFO:root:current train perplexity4.297524452209473
INFO:root:current mean train loss 3709.8761983290515
INFO:root:current train perplexity4.309110641479492
INFO:root:current mean train loss 3707.7753372354364
INFO:root:current train perplexity4.315568923950195
INFO:root:current mean train loss 3709.2439200005474
INFO:root:current train perplexity4.319165229797363
INFO:root:current mean train loss 3709.198898565574
INFO:root:current train perplexity4.319319725036621
INFO:root:current mean train loss 3711.3488196386593
INFO:root:current train perplexity4.318756103515625
INFO:root:current mean train loss 3711.5958567289754
INFO:root:current train perplexity4.319900989532471
INFO:root:current mean train loss 3711.372986531282
INFO:root:current train perplexity4.320489406585693

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:50<00:00, 410.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:50<00:00, 410.51s/it]
INFO:root:final mean train loss: 3709.8846960375386
INFO:root:final train perplexity: 4.32173490524292
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.48s/it]
INFO:root:eval mean loss: 3996.9319193955007
INFO:root:eval perplexity: 5.034136772155762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [7:53:07<18:07:59, 466.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3698.531682654272
INFO:root:current train perplexity4.307657718658447
INFO:root:current mean train loss 3709.0238303072624
INFO:root:current train perplexity4.311851501464844
INFO:root:current mean train loss 3704.9681847138218
INFO:root:current train perplexity4.31290864944458
INFO:root:current mean train loss 3694.7989795050707
INFO:root:current train perplexity4.305307388305664
INFO:root:current mean train loss 3696.223127711541
INFO:root:current train perplexity4.302872180938721
INFO:root:current mean train loss 3700.0331213231325
INFO:root:current train perplexity4.308149814605713
INFO:root:current mean train loss 3698.3362913061487
INFO:root:current train perplexity4.304431915283203
INFO:root:current mean train loss 3700.9532914167803
INFO:root:current train perplexity4.306964874267578
INFO:root:current mean train loss 3702.4098832235672
INFO:root:current train perplexity4.30640983581543
INFO:root:current mean train loss 3706.8661391167648
INFO:root:current train perplexity4.310846328735352

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:53<00:00, 413.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:53<00:00, 413.85s/it]
INFO:root:final mean train loss: 3703.514621673092
INFO:root:final train perplexity: 4.310886859893799
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.02s/it]
INFO:root:eval mean loss: 3997.030666486591
INFO:root:eval perplexity: 5.034337043762207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [8:00:51<17:58:19, 465.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3681.8799641927085
INFO:root:current train perplexity4.2533698081970215
INFO:root:current mean train loss 3691.886293135862
INFO:root:current train perplexity4.28391695022583
INFO:root:current mean train loss 3696.590594035823
INFO:root:current train perplexity4.290011882781982
INFO:root:current mean train loss 3698.9321661266554
INFO:root:current train perplexity4.293285369873047
INFO:root:current mean train loss 3699.496316334061
INFO:root:current train perplexity4.2958550453186035
INFO:root:current mean train loss 3699.3849161853173
INFO:root:current train perplexity4.293782711029053
INFO:root:current mean train loss 3697.831697910981
INFO:root:current train perplexity4.2927446365356445
INFO:root:current mean train loss 3696.211752439545
INFO:root:current train perplexity4.2944512367248535
INFO:root:current mean train loss 3695.1141815701626
INFO:root:current train perplexity4.293177127838135
INFO:root:current mean train loss 3696.745546597961
INFO:root:current train perplexity4.294487953186035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:58<00:00, 418.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:58<00:00, 418.83s/it]
INFO:root:final mean train loss: 3693.861760970085
INFO:root:final train perplexity: 4.294500827789307
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.74s/it]
INFO:root:eval mean loss: 3997.3640119403813
INFO:root:eval perplexity: 5.03501558303833
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [8:08:36<17:50:21, 465.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3657.7479106702303
INFO:root:current train perplexity4.24003791809082
INFO:root:current mean train loss 3676.408996895032
INFO:root:current train perplexity4.266651153564453
INFO:root:current mean train loss 3680.8520913334214
INFO:root:current train perplexity4.269225597381592
INFO:root:current mean train loss 3683.7269883554195
INFO:root:current train perplexity4.272521018981934
INFO:root:current mean train loss 3687.733175998264
INFO:root:current train perplexity4.272739410400391
INFO:root:current mean train loss 3688.8798988149947
INFO:root:current train perplexity4.2786993980407715
INFO:root:current mean train loss 3688.4528913978193
INFO:root:current train perplexity4.277982234954834
INFO:root:current mean train loss 3690.196769359277
INFO:root:current train perplexity4.283951759338379
INFO:root:current mean train loss 3690.141362059183
INFO:root:current train perplexity4.283387184143066

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:58<00:00, 418.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:58<00:00, 418.03s/it]
INFO:root:final mean train loss: 3686.7201854336645
INFO:root:final train perplexity: 4.2824177742004395
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.03s/it]
INFO:root:eval mean loss: 3994.657863752216
INFO:root:eval perplexity: 5.0295090675354
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [8:16:17<17:39:43, 464.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3702.6658528645835
INFO:root:current train perplexity4.333616733551025
INFO:root:current mean train loss 3688.2534227093447
INFO:root:current train perplexity4.268412113189697
INFO:root:current mean train loss 3674.47206574238
INFO:root:current train perplexity4.256938457489014
INFO:root:current mean train loss 3674.2812935102106
INFO:root:current train perplexity4.26551628112793
INFO:root:current mean train loss 3682.0531033120733
INFO:root:current train perplexity4.270152568817139
INFO:root:current mean train loss 3686.011926002578
INFO:root:current train perplexity4.267135143280029
INFO:root:current mean train loss 3686.0157363410813
INFO:root:current train perplexity4.266380786895752
INFO:root:current mean train loss 3682.5459022576238
INFO:root:current train perplexity4.263800144195557
INFO:root:current mean train loss 3683.8081997198005
INFO:root:current train perplexity4.2667951583862305
INFO:root:current mean train loss 3684.028064275765
INFO:root:current train perplexity4.268193244934082

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:52<00:00, 412.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:52<00:00, 412.83s/it]
INFO:root:final mean train loss: 3680.3419341425742
INFO:root:final train perplexity: 4.271655082702637
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.98s/it]
INFO:root:eval mean loss: 3992.623408757203
INFO:root:eval perplexity: 5.025372505187988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [8:24:05<17:34:25, 465.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3647.9608931107955
INFO:root:current train perplexity4.225800037384033
INFO:root:current mean train loss 3686.988846512528
INFO:root:current train perplexity4.254709243774414
INFO:root:current mean train loss 3664.4109083419726
INFO:root:current train perplexity4.246394634246826
INFO:root:current mean train loss 3652.405698132285
INFO:root:current train perplexity4.2382121086120605
INFO:root:current mean train loss 3658.199398142868
INFO:root:current train perplexity4.237940788269043
INFO:root:current mean train loss 3664.0192990536325
INFO:root:current train perplexity4.242537975311279
INFO:root:current mean train loss 3668.491162988441
INFO:root:current train perplexity4.248571395874023
INFO:root:current mean train loss 3670.290239250945
INFO:root:current train perplexity4.251698970794678
INFO:root:current mean train loss 3674.387788633824
INFO:root:current train perplexity4.255170822143555
INFO:root:current mean train loss 3672.6324161399734
INFO:root:current train perplexity4.254237174987793

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.68s/it]
INFO:root:final mean train loss: 3670.7412100761167
INFO:root:final train perplexity: 4.255505084991455
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.71s/it]
INFO:root:eval mean loss: 3993.250907302748
INFO:root:eval perplexity: 5.02664852142334
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [8:32:23<17:49:16, 475.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3606.3670847039475
INFO:root:current train perplexity4.219164848327637
INFO:root:current mean train loss 3664.558458344275
INFO:root:current train perplexity4.2364606857299805
INFO:root:current mean train loss 3664.0001750231877
INFO:root:current train perplexity4.234144687652588
INFO:root:current mean train loss 3665.8646205794475
INFO:root:current train perplexity4.234640121459961
INFO:root:current mean train loss 3667.215062252946
INFO:root:current train perplexity4.239107608795166
INFO:root:current mean train loss 3663.060097167028
INFO:root:current train perplexity4.2327189445495605
INFO:root:current mean train loss 3668.098955835395
INFO:root:current train perplexity4.2397990226745605
INFO:root:current mean train loss 3666.0095347270517
INFO:root:current train perplexity4.241664409637451
INFO:root:current mean train loss 3664.440408522684
INFO:root:current train perplexity4.238084316253662
INFO:root:current mean train loss 3665.720338906505
INFO:root:current train perplexity4.244115352630615

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:32<00:00, 392.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:32<00:00, 392.04s/it]
INFO:root:final mean train loss: 3665.637082253733
INFO:root:final train perplexity: 4.246944904327393
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.28s/it]
INFO:root:eval mean loss: 3993.919710632757
INFO:root:eval perplexity: 5.028007984161377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [8:40:36<17:52:45, 480.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3620.259919343171
INFO:root:current train perplexity4.133533954620361
INFO:root:current mean train loss 3639.322194497416
INFO:root:current train perplexity4.194830894470215
INFO:root:current mean train loss 3656.5216553809882
INFO:root:current train perplexity4.227933406829834
INFO:root:current mean train loss 3658.4368833022745
INFO:root:current train perplexity4.225949764251709
INFO:root:current mean train loss 3660.0018256229873
INFO:root:current train perplexity4.222950458526611
INFO:root:current mean train loss 3654.664152836664
INFO:root:current train perplexity4.219254016876221
INFO:root:current mean train loss 3654.9965462083833
INFO:root:current train perplexity4.223296165466309
INFO:root:current mean train loss 3655.277509308911
INFO:root:current train perplexity4.227544784545898
INFO:root:current mean train loss 3655.8297451254534
INFO:root:current train perplexity4.229233741760254
INFO:root:current mean train loss 3658.6784628463793
INFO:root:current train perplexity4.231243133544922

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.36s/it]
INFO:root:final mean train loss: 3657.1374736908942
INFO:root:final train perplexity: 4.232727527618408
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.08s/it]
INFO:root:eval mean loss: 3991.223850980718
INFO:root:eval perplexity: 5.0225300788879395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [8:47:58<17:19:38, 469.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3626.1419503348216
INFO:root:current train perplexity4.181848049163818
INFO:root:current mean train loss 3625.452888093171
INFO:root:current train perplexity4.191649913787842
INFO:root:current mean train loss 3636.1442175033244
INFO:root:current train perplexity4.2027459144592285
INFO:root:current mean train loss 3645.325203329058
INFO:root:current train perplexity4.208947658538818
INFO:root:current mean train loss 3644.644027815194
INFO:root:current train perplexity4.208560466766357
INFO:root:current mean train loss 3651.7383711485104
INFO:root:current train perplexity4.2139716148376465
INFO:root:current mean train loss 3652.197915769562
INFO:root:current train perplexity4.211777687072754
INFO:root:current mean train loss 3652.927556667198
INFO:root:current train perplexity4.216180801391602
INFO:root:current mean train loss 3653.6367582218377
INFO:root:current train perplexity4.218679428100586
INFO:root:current mean train loss 3655.1295869715073
INFO:root:current train perplexity4.220483303070068

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:33<00:00, 393.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:33<00:00, 393.32s/it]
INFO:root:final mean train loss: 3650.3940190961284
INFO:root:final train perplexity: 4.221480846405029
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.90s/it]
INFO:root:eval mean loss: 3994.063931945368
INFO:root:eval perplexity: 5.028300762176514
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [8:55:26<16:57:35, 462.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3642.5244765170787
INFO:root:current train perplexity4.198365211486816
INFO:root:current mean train loss 3652.7556954763986
INFO:root:current train perplexity4.211903095245361
INFO:root:current mean train loss 3650.275218822338
INFO:root:current train perplexity4.209737777709961
INFO:root:current mean train loss 3646.5585232837557
INFO:root:current train perplexity4.201959609985352
INFO:root:current mean train loss 3639.8232295120274
INFO:root:current train perplexity4.1961669921875
INFO:root:current mean train loss 3642.506879550098
INFO:root:current train perplexity4.199537754058838
INFO:root:current mean train loss 3646.0512862376067
INFO:root:current train perplexity4.202506065368652
INFO:root:current mean train loss 3646.873141179656
INFO:root:current train perplexity4.20559024810791
INFO:root:current mean train loss 3648.7972477271464
INFO:root:current train perplexity4.20930814743042
INFO:root:current mean train loss 3645.46082695064
INFO:root:current train perplexity4.2065043449401855

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:35<00:00, 395.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:35<00:00, 395.35s/it]
INFO:root:final mean train loss: 3642.3130419331214
INFO:root:final train perplexity: 4.208044052124023
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.43s/it]
INFO:root:eval mean loss: 3992.610891788564
INFO:root:eval perplexity: 5.0253472328186035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [9:03:58<17:22:32, 477.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3618.5603314568016
INFO:root:current train perplexity4.171516418457031
INFO:root:current mean train loss 3616.2443782983237
INFO:root:current train perplexity4.178733825683594
INFO:root:current mean train loss 3620.956215178349
INFO:root:current train perplexity4.176194667816162
INFO:root:current mean train loss 3631.2921744235223
INFO:root:current train perplexity4.189608573913574
INFO:root:current mean train loss 3624.598277157532
INFO:root:current train perplexity4.18779993057251
INFO:root:current mean train loss 3625.7645895070045
INFO:root:current train perplexity4.191127777099609
INFO:root:current mean train loss 3629.8526159424205
INFO:root:current train perplexity4.192649841308594
INFO:root:current mean train loss 3631.8463097380577
INFO:root:current train perplexity4.194814205169678
INFO:root:current mean train loss 3635.699941991499
INFO:root:current train perplexity4.19586181640625
INFO:root:current mean train loss 3638.909159663348
INFO:root:current train perplexity4.198033332824707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:31<00:00, 391.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:31<00:00, 391.50s/it]
INFO:root:final mean train loss: 3636.9976068927394
INFO:root:final train perplexity: 4.199228763580322
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.35s/it]
INFO:root:eval mean loss: 3991.996808856937
INFO:root:eval perplexity: 5.024098873138428
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [9:11:58<17:16:02, 478.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3593.1775936837926
INFO:root:current train perplexity4.173788070678711
INFO:root:current mean train loss 3605.2271014519456
INFO:root:current train perplexity4.172418594360352
INFO:root:current mean train loss 3620.8821460620775
INFO:root:current train perplexity4.180633068084717
INFO:root:current mean train loss 3621.062424513623
INFO:root:current train perplexity4.182916641235352
INFO:root:current mean train loss 3622.5100358285677
INFO:root:current train perplexity4.1778244972229
INFO:root:current mean train loss 3622.9463471496256
INFO:root:current train perplexity4.17862606048584
INFO:root:current mean train loss 3624.2341749454667
INFO:root:current train perplexity4.179354190826416
INFO:root:current mean train loss 3624.9794477982955
INFO:root:current train perplexity4.182366847991943
INFO:root:current mean train loss 3627.3147040867834
INFO:root:current train perplexity4.18410062789917
INFO:root:current mean train loss 3632.4992416111345
INFO:root:current train perplexity4.186521053314209

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.74s/it]
INFO:root:final mean train loss: 3630.865169955838
INFO:root:final train perplexity: 4.189081192016602
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.75s/it]
INFO:root:eval mean loss: 3992.5921293218084
INFO:root:eval perplexity: 5.0253095626831055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [9:20:24<17:25:51, 486.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3598.2706754314368
INFO:root:current train perplexity4.12050724029541
INFO:root:current mean train loss 3603.437808465101
INFO:root:current train perplexity4.137475490570068
INFO:root:current mean train loss 3603.7627702920176
INFO:root:current train perplexity4.148139476776123
INFO:root:current mean train loss 3617.20165416915
INFO:root:current train perplexity4.161378860473633
INFO:root:current mean train loss 3616.8998228804203
INFO:root:current train perplexity4.160303592681885
INFO:root:current mean train loss 3612.6564019958387
INFO:root:current train perplexity4.162001609802246
INFO:root:current mean train loss 3618.0832922161967
INFO:root:current train perplexity4.164584159851074
INFO:root:current mean train loss 3621.3073077941654
INFO:root:current train perplexity4.1704325675964355
INFO:root:current mean train loss 3620.5815573299633
INFO:root:current train perplexity4.171076774597168
INFO:root:current mean train loss 3626.8035728352024
INFO:root:current train perplexity4.178308963775635

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:35<00:00, 395.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:35<00:00, 395.47s/it]
INFO:root:final mean train loss: 3624.117550388459
INFO:root:final train perplexity: 4.177944183349609
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.76s/it]
INFO:root:eval mean loss: 3993.473151457225
INFO:root:eval perplexity: 5.027100086212158
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [9:28:50<17:30:23, 492.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3630.5961393229168
INFO:root:current train perplexity4.145499229431152
INFO:root:current mean train loss 3610.138888113839
INFO:root:current train perplexity4.138818740844727
INFO:root:current mean train loss 3613.685403053977
INFO:root:current train perplexity4.144493579864502
INFO:root:current mean train loss 3613.2998470052084
INFO:root:current train perplexity4.155824184417725
INFO:root:current mean train loss 3616.5848139391446
INFO:root:current train perplexity4.161475658416748
INFO:root:current mean train loss 3617.3606865658967
INFO:root:current train perplexity4.160599231719971
INFO:root:current mean train loss 3616.9338708043983
INFO:root:current train perplexity4.160711765289307
INFO:root:current mean train loss 3618.88064484627
INFO:root:current train perplexity4.165318965911865
INFO:root:current mean train loss 3620.2467416294644
INFO:root:current train perplexity4.1656622886657715
INFO:root:current mean train loss 3620.517067558093
INFO:root:current train perplexity4.167117595672607

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:30<00:00, 390.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:30<00:00, 390.85s/it]
INFO:root:final mean train loss: 3617.170083507415
INFO:root:final train perplexity: 4.166507720947266
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.13s/it]
INFO:root:eval mean loss: 3993.3594200188386
INFO:root:eval perplexity: 5.026869297027588
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [9:36:03<16:44:53, 474.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3577.8270219550077
INFO:root:current train perplexity4.119555473327637
INFO:root:current mean train loss 3597.19568071209
INFO:root:current train perplexity4.138302803039551
INFO:root:current mean train loss 3608.3044778668836
INFO:root:current train perplexity4.151236057281494
INFO:root:current mean train loss 3605.9837789909025
INFO:root:current train perplexity4.144558906555176
INFO:root:current mean train loss 3608.824585719138
INFO:root:current train perplexity4.152463912963867
INFO:root:current mean train loss 3609.462770857901
INFO:root:current train perplexity4.156115531921387
INFO:root:current mean train loss 3611.1278632011804
INFO:root:current train perplexity4.156052589416504
INFO:root:current mean train loss 3610.7318796520794
INFO:root:current train perplexity4.154036998748779
INFO:root:current mean train loss 3611.8175536832887
INFO:root:current train perplexity4.153509616851807
INFO:root:current mean train loss 3612.7597790365908
INFO:root:current train perplexity4.155547618865967

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:31<00:00, 391.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:31<00:00, 391.31s/it]
INFO:root:final mean train loss: 3610.6894500486314
INFO:root:final train perplexity: 4.155868053436279
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.75s/it]
INFO:root:eval mean loss: 3993.419173869681
INFO:root:eval perplexity: 5.02699089050293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [9:43:16<16:10:28, 462.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3611.3990545587226
INFO:root:current train perplexity4.140111446380615
INFO:root:current mean train loss 3594.2268718300065
INFO:root:current train perplexity4.121031761169434
INFO:root:current mean train loss 3601.242267202266
INFO:root:current train perplexity4.1294169425964355
INFO:root:current mean train loss 3597.1568188289243
INFO:root:current train perplexity4.129443168640137
INFO:root:current mean train loss 3597.463317746786
INFO:root:current train perplexity4.130166530609131
INFO:root:current mean train loss 3599.39670125119
INFO:root:current train perplexity4.128845691680908
INFO:root:current mean train loss 3600.6226522222096
INFO:root:current train perplexity4.134681224822998
INFO:root:current mean train loss 3602.0415946487833
INFO:root:current train perplexity4.138873100280762
INFO:root:current mean train loss 3603.712617987602
INFO:root:current train perplexity4.141758441925049
INFO:root:current mean train loss 3607.3215947925864
INFO:root:current train perplexity4.145766735076904

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:34<00:00, 394.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:34<00:00, 394.26s/it]
INFO:root:final mean train loss: 3604.5181262108586
INFO:root:final train perplexity: 4.145761966705322
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.13s/it]
INFO:root:eval mean loss: 3994.444872700576
INFO:root:eval perplexity: 5.029076099395752
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [9:50:33<15:47:00, 454.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3583.054472952178
INFO:root:current train perplexity4.112963676452637
INFO:root:current mean train loss 3594.7106234296484
INFO:root:current train perplexity4.1157708168029785
INFO:root:current mean train loss 3592.1840077275815
INFO:root:current train perplexity4.119359970092773
INFO:root:current mean train loss 3591.536883590813
INFO:root:current train perplexity4.121176242828369
INFO:root:current mean train loss 3595.476181855899
INFO:root:current train perplexity4.123503684997559
INFO:root:current mean train loss 3595.8913411186613
INFO:root:current train perplexity4.1213579177856445
INFO:root:current mean train loss 3599.5895496635817
INFO:root:current train perplexity4.1297125816345215
INFO:root:current mean train loss 3597.88706983583
INFO:root:current train perplexity4.130089282989502
INFO:root:current mean train loss 3598.659751340465
INFO:root:current train perplexity4.132779598236084

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:30<00:00, 390.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:30<00:00, 390.11s/it]
INFO:root:final mean train loss: 3596.6646141544466
INFO:root:final train perplexity: 4.132936954498291
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.60s/it]
INFO:root:eval mean loss: 3994.5296189328456
INFO:root:eval perplexity: 5.029247760772705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [9:57:46<15:26:07, 448.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3571.7170061383927
INFO:root:current train perplexity4.0949554443359375
INFO:root:current mean train loss 3592.669403931805
INFO:root:current train perplexity4.1285529136657715
INFO:root:current mean train loss 3585.6834203747735
INFO:root:current train perplexity4.116117477416992
INFO:root:current mean train loss 3583.9304588889454
INFO:root:current train perplexity4.108323097229004
INFO:root:current mean train loss 3587.3645625383906
INFO:root:current train perplexity4.1121826171875
INFO:root:current mean train loss 3586.287369887975
INFO:root:current train perplexity4.111027240753174
INFO:root:current mean train loss 3591.7871548245726
INFO:root:current train perplexity4.117506504058838
INFO:root:current mean train loss 3592.551340321672
INFO:root:current train perplexity4.120086669921875
INFO:root:current mean train loss 3592.7772290916396
INFO:root:current train perplexity4.120495319366455
INFO:root:current mean train loss 3591.8838862342373
INFO:root:current train perplexity4.1203508377075195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:35<00:00, 395.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:35<00:00, 395.04s/it]
INFO:root:final mean train loss: 3590.3918987397224
INFO:root:final train perplexity: 4.122720718383789
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.63s/it]
INFO:root:eval mean loss: 3992.6008179576684
INFO:root:eval perplexity: 5.025326728820801
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [10:05:05<15:13:06, 445.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3543.9365071614584
INFO:root:current train perplexity4.0435404777526855
INFO:root:current mean train loss 3576.353411599864
INFO:root:current train perplexity4.083614349365234
INFO:root:current mean train loss 3582.5058457485466
INFO:root:current train perplexity4.092149257659912
INFO:root:current mean train loss 3578.649636501736
INFO:root:current train perplexity4.093144416809082
INFO:root:current mean train loss 3583.056206466491
INFO:root:current train perplexity4.10258674621582
INFO:root:current mean train loss 3583.781819819478
INFO:root:current train perplexity4.104983806610107
INFO:root:current mean train loss 3580.0620557831553
INFO:root:current train perplexity4.101465702056885
INFO:root:current mean train loss 3583.65883379316
INFO:root:current train perplexity4.106863498687744
INFO:root:current mean train loss 3584.8163709020323
INFO:root:current train perplexity4.109602451324463
INFO:root:current mean train loss 3586.241532722848
INFO:root:current train perplexity4.111161231994629

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:28<00:00, 388.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:28<00:00, 388.19s/it]
INFO:root:final mean train loss: 3585.108180507537
INFO:root:final train perplexity: 4.1141357421875
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.80s/it]
INFO:root:eval mean loss: 3994.134647883422
INFO:root:eval perplexity: 5.028444290161133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [10:12:15<14:55:56, 440.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3585.3959324048915
INFO:root:current train perplexity4.114839553833008
INFO:root:current mean train loss 3567.33867068407
INFO:root:current train perplexity4.092606544494629
INFO:root:current mean train loss 3567.254595974636
INFO:root:current train perplexity4.096751689910889
INFO:root:current mean train loss 3572.226329697175
INFO:root:current train perplexity4.095034122467041
INFO:root:current mean train loss 3571.81888401762
INFO:root:current train perplexity4.094503879547119
INFO:root:current mean train loss 3570.564245395405
INFO:root:current train perplexity4.095697402954102
INFO:root:current mean train loss 3575.386326087229
INFO:root:current train perplexity4.0978899002075195
INFO:root:current mean train loss 3575.2827033627245
INFO:root:current train perplexity4.096150875091553
INFO:root:current mean train loss 3577.2078138052475
INFO:root:current train perplexity4.096442699432373
INFO:root:current mean train loss 3578.361520422112
INFO:root:current train perplexity4.10111141204834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:31<00:00, 391.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:31<00:00, 391.89s/it]
INFO:root:final mean train loss: 3577.936542634041
INFO:root:final train perplexity: 4.102511882781982
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.75s/it]
INFO:root:eval mean loss: 3995.408000540226
INFO:root:eval perplexity: 5.031035423278809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [10:19:28<14:44:04, 438.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3567.1065161920365
INFO:root:current train perplexity4.069777488708496
INFO:root:current mean train loss 3568.4011323652194
INFO:root:current train perplexity4.079525947570801
INFO:root:current mean train loss 3575.4930245535716
INFO:root:current train perplexity4.0841875076293945
INFO:root:current mean train loss 3578.0342209922583
INFO:root:current train perplexity4.084388256072998
INFO:root:current mean train loss 3577.0066053917126
INFO:root:current train perplexity4.091087818145752
INFO:root:current mean train loss 3575.7953765926613
INFO:root:current train perplexity4.093102931976318
INFO:root:current mean train loss 3575.1973700908775
INFO:root:current train perplexity4.092069625854492
INFO:root:current mean train loss 3574.2278937510687
INFO:root:current train perplexity4.091099262237549
INFO:root:current mean train loss 3577.436644773334
INFO:root:current train perplexity4.095503330230713
INFO:root:current mean train loss 3574.29698907215
INFO:root:current train perplexity4.094167232513428

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.56s/it]
INFO:root:final mean train loss: 3572.203921041181
INFO:root:final train perplexity: 4.093243598937988
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.83s/it]
INFO:root:eval mean loss: 3996.491403133311
INFO:root:eval perplexity: 5.033239841461182
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [10:26:50<14:38:51, 439.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3528.1311723758013
INFO:root:current train perplexity4.083961486816406
INFO:root:current mean train loss 3551.809461415243
INFO:root:current train perplexity4.065469741821289
INFO:root:current mean train loss 3550.908268501569
INFO:root:current train perplexity4.059915542602539
INFO:root:current mean train loss 3555.0800759644635
INFO:root:current train perplexity4.058152198791504
INFO:root:current mean train loss 3556.7063344203802
INFO:root:current train perplexity4.068480491638184
INFO:root:current mean train loss 3557.4076210828794
INFO:root:current train perplexity4.071256160736084
INFO:root:current mean train loss 3564.1303642165494
INFO:root:current train perplexity4.077452182769775
INFO:root:current mean train loss 3566.441457456762
INFO:root:current train perplexity4.0823259353637695
INFO:root:current mean train loss 3568.0278881923236
INFO:root:current train perplexity4.083977222442627
INFO:root:current mean train loss 3567.844955623086
INFO:root:current train perplexity4.0833048820495605

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.37s/it]
INFO:root:final mean train loss: 3567.369767158262
INFO:root:final train perplexity: 4.08544397354126
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.86s/it]
INFO:root:eval mean loss: 3995.995479069703
INFO:root:eval perplexity: 5.032230377197266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [10:34:13<14:34:03, 440.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3565.222791306516
INFO:root:current train perplexity4.106131076812744
INFO:root:current mean train loss 3576.4900400589922
INFO:root:current train perplexity4.086581707000732
INFO:root:current mean train loss 3559.4197745998863
INFO:root:current train perplexity4.0687737464904785
INFO:root:current mean train loss 3558.36849403931
INFO:root:current train perplexity4.067061424255371
INFO:root:current mean train loss 3564.2324825005244
INFO:root:current train perplexity4.067580223083496
INFO:root:current mean train loss 3558.3572714629513
INFO:root:current train perplexity4.067269802093506
INFO:root:current mean train loss 3560.877254244349
INFO:root:current train perplexity4.070156097412109
INFO:root:current mean train loss 3564.1131815674157
INFO:root:current train perplexity4.070560932159424
INFO:root:current mean train loss 3566.0465700403997
INFO:root:current train perplexity4.072906970977783
INFO:root:current mean train loss 3563.412432919334
INFO:root:current train perplexity4.075127124786377

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.31s/it]
INFO:root:final mean train loss: 3560.3606927317956
INFO:root:final train perplexity: 4.07416296005249
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.16s/it]
INFO:root:eval mean loss: 3997.5902004377217
INFO:root:eval perplexity: 5.035475730895996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [10:41:38<14:29:12, 441.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3562.351677911932
INFO:root:current train perplexity4.065884113311768
INFO:root:current mean train loss 3552.166551159274
INFO:root:current train perplexity4.057663917541504
INFO:root:current mean train loss 3547.2634641161153
INFO:root:current train perplexity4.053819179534912
INFO:root:current mean train loss 3552.498408615757
INFO:root:current train perplexity4.0634965896606445
INFO:root:current mean train loss 3549.9289019574176
INFO:root:current train perplexity4.067378997802734
INFO:root:current mean train loss 3552.4774251302083
INFO:root:current train perplexity4.067262649536133
INFO:root:current mean train loss 3553.270846627505
INFO:root:current train perplexity4.066130638122559
INFO:root:current mean train loss 3556.2943857357204
INFO:root:current train perplexity4.067079544067383
INFO:root:current mean train loss 3557.04342904788
INFO:root:current train perplexity4.065790176391602
INFO:root:current mean train loss 3559.5414665821336
INFO:root:current train perplexity4.067239284515381

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.41s/it]
INFO:root:final mean train loss: 3554.9465090843937
INFO:root:final train perplexity: 4.065469741821289
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.73s/it]
INFO:root:eval mean loss: 3996.8619739721853
INFO:root:eval perplexity: 5.033993721008301
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [10:49:02<14:22:47, 442.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3544.460236080109
INFO:root:current train perplexity4.015726089477539
INFO:root:current mean train loss 3546.0040994655865
INFO:root:current train perplexity4.037217140197754
INFO:root:current mean train loss 3537.762599698491
INFO:root:current train perplexity4.044997215270996
INFO:root:current mean train loss 3538.4938406615875
INFO:root:current train perplexity4.047593593597412
INFO:root:current mean train loss 3541.600725672415
INFO:root:current train perplexity4.045480728149414
INFO:root:current mean train loss 3543.6542673873223
INFO:root:current train perplexity4.048636436462402
INFO:root:current mean train loss 3548.167693309295
INFO:root:current train perplexity4.052768230438232
INFO:root:current mean train loss 3551.215884627396
INFO:root:current train perplexity4.056160926818848
INFO:root:current mean train loss 3550.5869038781866
INFO:root:current train perplexity4.0545806884765625
INFO:root:current mean train loss 3550.8437114648236
INFO:root:current train perplexity4.0552659034729

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:42<00:00, 402.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:42<00:00, 402.01s/it]
INFO:root:final mean train loss: 3548.469794119558
INFO:root:final train perplexity: 4.055094242095947
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.29s/it]
INFO:root:eval mean loss: 3999.4105129377217
INFO:root:eval perplexity: 5.039185047149658
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [10:56:28<14:17:22, 443.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3517.9810670664615
INFO:root:current train perplexity4.025393486022949
INFO:root:current mean train loss 3532.7717670641446
INFO:root:current train perplexity4.031008243560791
INFO:root:current mean train loss 3528.0498974789552
INFO:root:current train perplexity4.028421401977539
INFO:root:current mean train loss 3531.6983547159284
INFO:root:current train perplexity4.0359368324279785
INFO:root:current mean train loss 3535.2208135325436
INFO:root:current train perplexity4.037032127380371
INFO:root:current mean train loss 3540.007564938841
INFO:root:current train perplexity4.039741039276123
INFO:root:current mean train loss 3544.1367085623137
INFO:root:current train perplexity4.043948650360107
INFO:root:current mean train loss 3547.58607239482
INFO:root:current train perplexity4.045153617858887
INFO:root:current mean train loss 3547.6490443478224
INFO:root:current train perplexity4.046772480010986
INFO:root:current mean train loss 3546.4357776897205
INFO:root:current train perplexity4.0475006103515625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.95s/it]
INFO:root:final mean train loss: 3543.56540015436
INFO:root:final train perplexity: 4.047255516052246
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.39s/it]
INFO:root:eval mean loss: 4000.0683888103945
INFO:root:eval perplexity: 5.040524959564209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [11:03:50<14:09:04, 442.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3489.1912919056567
INFO:root:current train perplexity4.0240654945373535
INFO:root:current mean train loss 3520.1239129604573
INFO:root:current train perplexity4.0276031494140625
INFO:root:current mean train loss 3536.7191376498095
INFO:root:current train perplexity4.03536319732666
INFO:root:current mean train loss 3540.0772392655426
INFO:root:current train perplexity4.033023357391357
INFO:root:current mean train loss 3539.412473292341
INFO:root:current train perplexity4.033729553222656
INFO:root:current mean train loss 3537.7735876106435
INFO:root:current train perplexity4.035098552703857
INFO:root:current mean train loss 3535.878372304745
INFO:root:current train perplexity4.03516960144043
INFO:root:current mean train loss 3538.23144405889
INFO:root:current train perplexity4.035951137542725
INFO:root:current mean train loss 3540.022044870769
INFO:root:current train perplexity4.036440372467041
INFO:root:current mean train loss 3540.6889815520462
INFO:root:current train perplexity4.036837577819824

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.73s/it]
INFO:root:final mean train loss: 3537.4392635591566
INFO:root:final train perplexity: 4.037485122680664
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.43s/it]
INFO:root:eval mean loss: 3998.639111674424
INFO:root:eval perplexity: 5.037612438201904
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [11:11:12<14:01:28, 442.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3508.3600849721624
INFO:root:current train perplexity4.010180950164795
INFO:root:current mean train loss 3513.0064416569185
INFO:root:current train perplexity4.00940465927124
INFO:root:current mean train loss 3517.014424712816
INFO:root:current train perplexity4.024901390075684
INFO:root:current mean train loss 3522.5554943626857
INFO:root:current train perplexity4.026002407073975
INFO:root:current mean train loss 3525.1152624486654
INFO:root:current train perplexity4.02437686920166
INFO:root:current mean train loss 3530.8518619569845
INFO:root:current train perplexity4.02756929397583
INFO:root:current mean train loss 3530.47235169612
INFO:root:current train perplexity4.025836944580078
INFO:root:current mean train loss 3533.37503009103
INFO:root:current train perplexity4.02980899810791
INFO:root:current mean train loss 3534.9301834880566
INFO:root:current train perplexity4.030730247497559
INFO:root:current mean train loss 3536.106678816806
INFO:root:current train perplexity4.03084135055542

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.19s/it]
INFO:root:final mean train loss: 3533.4442308487432
INFO:root:final train perplexity: 4.031127452850342
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.69s/it]
INFO:root:eval mean loss: 4001.122584566157
INFO:root:eval perplexity: 5.042673587799072
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [11:18:33<13:52:43, 442.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3520.834416118421
INFO:root:current train perplexity3.993962049484253
INFO:root:current mean train loss 3536.8564916366186
INFO:root:current train perplexity4.012441635131836
INFO:root:current mean train loss 3535.1520615399895
INFO:root:current train perplexity4.018790245056152
INFO:root:current mean train loss 3524.6597334849685
INFO:root:current train perplexity4.011554718017578
INFO:root:current mean train loss 3525.5033864030934
INFO:root:current train perplexity4.013144016265869
INFO:root:current mean train loss 3526.926943687631
INFO:root:current train perplexity4.010791778564453
INFO:root:current mean train loss 3526.891574865108
INFO:root:current train perplexity4.014092922210693
INFO:root:current mean train loss 3528.129879741549
INFO:root:current train perplexity4.017853736877441
INFO:root:current mean train loss 3529.8133093466304
INFO:root:current train perplexity4.021072864532471

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:35<00:00, 395.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:35<00:00, 395.72s/it]
INFO:root:final mean train loss: 3528.3449646119147
INFO:root:final train perplexity: 4.023024559020996
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.90s/it]
INFO:root:eval mean loss: 4000.1242866245566
INFO:root:eval perplexity: 5.040638446807861
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [11:25:49<13:41:59, 440.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3723.7333984375
INFO:root:current train perplexity4.123022079467773
INFO:root:current mean train loss 3530.7192145782765
INFO:root:current train perplexity4.005911827087402
INFO:root:current mean train loss 3521.602195100831
INFO:root:current train perplexity4.000932693481445
INFO:root:current mean train loss 3516.0085126920894
INFO:root:current train perplexity3.9942448139190674
INFO:root:current mean train loss 3522.224823831033
INFO:root:current train perplexity4.006236553192139
INFO:root:current mean train loss 3522.671687647552
INFO:root:current train perplexity4.009696960449219
INFO:root:current mean train loss 3522.7420089493935
INFO:root:current train perplexity4.007465362548828
INFO:root:current mean train loss 3519.5134197468437
INFO:root:current train perplexity4.006836414337158
INFO:root:current mean train loss 3522.275782222914
INFO:root:current train perplexity4.007991790771484
INFO:root:current mean train loss 3523.165871249481
INFO:root:current train perplexity4.0126848220825195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:33<00:00, 393.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:33<00:00, 393.86s/it]
INFO:root:final mean train loss: 3521.949375460225
INFO:root:final train perplexity: 4.0128865242004395
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.46s/it]
INFO:root:eval mean loss: 4004.2652423398713
INFO:root:eval perplexity: 5.049086570739746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [11:33:04<13:31:33, 438.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3515.0518687855115
INFO:root:current train perplexity3.949943780899048
INFO:root:current mean train loss 3508.2981528892174
INFO:root:current train perplexity3.9910802841186523
INFO:root:current mean train loss 3506.964616965344
INFO:root:current train perplexity3.9920217990875244
INFO:root:current mean train loss 3504.598344710862
INFO:root:current train perplexity3.991834878921509
INFO:root:current mean train loss 3503.5208832306876
INFO:root:current train perplexity3.9861903190612793
INFO:root:current mean train loss 3505.527843019967
INFO:root:current train perplexity3.987468957901001
INFO:root:current mean train loss 3507.19963790469
INFO:root:current train perplexity3.9932122230529785
INFO:root:current mean train loss 3513.172409637065
INFO:root:current train perplexity3.994684934616089
INFO:root:current mean train loss 3512.9761916229963
INFO:root:current train perplexity3.996084213256836
INFO:root:current mean train loss 3515.651841533171
INFO:root:current train perplexity3.999786853790283

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:31<00:00, 391.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:31<00:00, 391.42s/it]
INFO:root:final mean train loss: 3515.8465640160343
INFO:root:final train perplexity: 4.003236770629883
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.57s/it]
INFO:root:eval mean loss: 4004.1629647329346
INFO:root:eval perplexity: 5.048877239227295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [11:40:15<13:20:19, 436.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3469.371941817434
INFO:root:current train perplexity4.02512788772583
INFO:root:current mean train loss 3506.0663713727677
INFO:root:current train perplexity3.9711453914642334
INFO:root:current mean train loss 3522.1170213951914
INFO:root:current train perplexity3.982640027999878
INFO:root:current mean train loss 3518.367962780417
INFO:root:current train perplexity3.988602638244629
INFO:root:current mean train loss 3519.7047844570407
INFO:root:current train perplexity3.9887890815734863
INFO:root:current mean train loss 3516.8810832881745
INFO:root:current train perplexity3.9882607460021973
INFO:root:current mean train loss 3513.2884136933308
INFO:root:current train perplexity3.9887382984161377
INFO:root:current mean train loss 3509.8149281635733
INFO:root:current train perplexity3.9916484355926514
INFO:root:current mean train loss 3510.9175639356304
INFO:root:current train perplexity3.9927382469177246
INFO:root:current mean train loss 3514.9052479342354
INFO:root:current train perplexity3.996349573135376

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:33<00:00, 393.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:33<00:00, 393.46s/it]
INFO:root:final mean train loss: 3511.109665593793
INFO:root:final train perplexity: 3.9957621097564697
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.70s/it]
INFO:root:eval mean loss: 4002.7284758006426
INFO:root:eval perplexity: 5.045949459075928
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [11:47:31<13:12:34, 436.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3497.8212800202546
INFO:root:current train perplexity4.010117053985596
INFO:root:current mean train loss 3500.0068282480315
INFO:root:current train perplexity3.9780566692352295
INFO:root:current mean train loss 3498.9949730692456
INFO:root:current train perplexity3.980853319168091
INFO:root:current mean train loss 3502.9559643480025
INFO:root:current train perplexity3.9835896492004395
INFO:root:current mean train loss 3496.9770399178497
INFO:root:current train perplexity3.9805314540863037
INFO:root:current mean train loss 3503.188004495523
INFO:root:current train perplexity3.9857892990112305
INFO:root:current mean train loss 3505.611843662779
INFO:root:current train perplexity3.9852144718170166
INFO:root:current mean train loss 3508.3007419591427
INFO:root:current train perplexity3.9878320693969727
INFO:root:current mean train loss 3508.946053778246
INFO:root:current train perplexity3.989720344543457
INFO:root:current mean train loss 3509.1501988942828
INFO:root:current train perplexity3.9897069931030273

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.23s/it]
INFO:root:final mean train loss: 3507.1799341632473
INFO:root:final train perplexity: 3.9895718097686768
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.52s/it]
INFO:root:eval mean loss: 4005.1046739943486
INFO:root:eval perplexity: 5.050800800323486
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [11:54:51<13:07:26, 437.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3484.8096330915178
INFO:root:current train perplexity3.959204912185669
INFO:root:current mean train loss 3494.3611906828705
INFO:root:current train perplexity3.9654245376586914
INFO:root:current mean train loss 3501.2490618766624
INFO:root:current train perplexity3.9758787155151367
INFO:root:current mean train loss 3504.21495598181
INFO:root:current train perplexity3.9775142669677734
INFO:root:current mean train loss 3507.6841791262573
INFO:root:current train perplexity3.9818427562713623
INFO:root:current mean train loss 3508.7611560857185
INFO:root:current train perplexity3.9840269088745117
INFO:root:current mean train loss 3504.2190072127214
INFO:root:current train perplexity3.9781250953674316
INFO:root:current mean train loss 3501.1649224728953
INFO:root:current train perplexity3.9767699241638184
INFO:root:current mean train loss 3502.888358439371
INFO:root:current train perplexity3.978743076324463
INFO:root:current mean train loss 3501.8844925008357
INFO:root:current train perplexity3.9771833419799805

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.65s/it]
INFO:root:final mean train loss: 3501.698638977543
INFO:root:final train perplexity: 3.9809539318084717
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.76s/it]
INFO:root:eval mean loss: 4003.1798069730717
INFO:root:eval perplexity: 5.046871185302734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [12:02:11<13:01:23, 438.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3461.6573117278344
INFO:root:current train perplexity3.958217144012451
INFO:root:current mean train loss 3497.7869471836757
INFO:root:current train perplexity3.9497907161712646
INFO:root:current mean train loss 3491.077302155671
INFO:root:current train perplexity3.9645233154296875
INFO:root:current mean train loss 3492.726395943422
INFO:root:current train perplexity3.9658639430999756
INFO:root:current mean train loss 3490.425279191062
INFO:root:current train perplexity3.96354079246521
INFO:root:current mean train loss 3491.3757220807433
INFO:root:current train perplexity3.9648048877716064
INFO:root:current mean train loss 3493.354520284555
INFO:root:current train perplexity3.9693429470062256
INFO:root:current mean train loss 3498.584246587946
INFO:root:current train perplexity3.9713587760925293
INFO:root:current mean train loss 3498.6120414326624
INFO:root:current train perplexity3.971839427947998
INFO:root:current mean train loss 3498.810802924924
INFO:root:current train perplexity3.9720892906188965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.80s/it]
INFO:root:final mean train loss: 3496.64769160363
INFO:root:final train perplexity: 3.9730284214019775
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.24s/it]
INFO:root:eval mean loss: 4005.3079652177526
INFO:root:eval perplexity: 5.051216125488281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [12:09:35<12:57:30, 440.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3477.994561887255
INFO:root:current train perplexity3.965097665786743
INFO:root:current mean train loss 3491.636039683361
INFO:root:current train perplexity3.957434892654419
INFO:root:current mean train loss 3494.0237886345244
INFO:root:current train perplexity3.962444305419922
INFO:root:current mean train loss 3493.6446821859417
INFO:root:current train perplexity3.952847719192505
INFO:root:current mean train loss 3491.533880872367
INFO:root:current train perplexity3.9546449184417725
INFO:root:current mean train loss 3494.3446149047186
INFO:root:current train perplexity3.961291551589966
INFO:root:current mean train loss 3494.2549848190283
INFO:root:current train perplexity3.9648725986480713
INFO:root:current mean train loss 3494.0906119314873
INFO:root:current train perplexity3.9633357524871826
INFO:root:current mean train loss 3493.9665765459754
INFO:root:current train perplexity3.964794635772705
INFO:root:current mean train loss 3495.0817088098056
INFO:root:current train perplexity3.9675509929656982

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.75s/it]
INFO:root:final mean train loss: 3491.569101456673
INFO:root:final train perplexity: 3.965075731277466
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.45s/it]
INFO:root:eval mean loss: 4008.6398648742243
INFO:root:eval perplexity: 5.058026313781738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [12:16:54<12:49:26, 439.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3455.708152641684
INFO:root:current train perplexity3.907285690307617
INFO:root:current mean train loss 3470.0959027368317
INFO:root:current train perplexity3.919257402420044
INFO:root:current mean train loss 3473.043311866554
INFO:root:current train perplexity3.9273288249969482
INFO:root:current mean train loss 3481.8340986246517
INFO:root:current train perplexity3.9382903575897217
INFO:root:current mean train loss 3482.866470503132
INFO:root:current train perplexity3.941856861114502
INFO:root:current mean train loss 3486.6386238330165
INFO:root:current train perplexity3.945079803466797
INFO:root:current mean train loss 3486.786213575256
INFO:root:current train perplexity3.948946475982666
INFO:root:current mean train loss 3490.0890106482625
INFO:root:current train perplexity3.953632354736328
INFO:root:current mean train loss 3492.103994811372
INFO:root:current train perplexity3.9570913314819336
INFO:root:current mean train loss 3492.0413114450275
INFO:root:current train perplexity3.958277940750122

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.45s/it]
INFO:root:final mean train loss: 3487.2930553805445
INFO:root:final train perplexity: 3.9583921432495117
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.56s/it]
INFO:root:eval mean loss: 4006.41741640348
INFO:root:eval perplexity: 5.053482532501221
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [12:24:16<12:43:05, 440.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3487.389353282416
INFO:root:current train perplexity3.9769530296325684
INFO:root:current mean train loss 3483.944675102919
INFO:root:current train perplexity3.9509811401367188
INFO:root:current mean train loss 3489.2493434720272
INFO:root:current train perplexity3.9521405696868896
INFO:root:current mean train loss 3488.043621343878
INFO:root:current train perplexity3.9482598304748535
INFO:root:current mean train loss 3485.321819166555
INFO:root:current train perplexity3.9472808837890625
INFO:root:current mean train loss 3482.4786366188546
INFO:root:current train perplexity3.94650936126709
INFO:root:current mean train loss 3483.5782944709285
INFO:root:current train perplexity3.946619749069214
INFO:root:current mean train loss 3481.6701921167087
INFO:root:current train perplexity3.9489057064056396
INFO:root:current mean train loss 3485.2272901348038
INFO:root:current train perplexity3.9508614540100098
INFO:root:current mean train loss 3484.39744149714
INFO:root:current train perplexity3.9504306316375732

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.15s/it]
INFO:root:final mean train loss: 3482.145982373145
INFO:root:final train perplexity: 3.9503629207611084
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.62s/it]
INFO:root:eval mean loss: 4007.8698020556294
INFO:root:eval perplexity: 5.056450843811035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [12:31:38<12:36:47, 440.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3467.605738932292
INFO:root:current train perplexity3.9490251541137695
INFO:root:current mean train loss 3469.2122977120534
INFO:root:current train perplexity3.9370131492614746
INFO:root:current mean train loss 3479.966052911932
INFO:root:current train perplexity3.9340264797210693
INFO:root:current mean train loss 3483.7527161458333
INFO:root:current train perplexity3.9353272914886475
INFO:root:current mean train loss 3481.1942814555923
INFO:root:current train perplexity3.9385271072387695
INFO:root:current mean train loss 3476.2981309442935
INFO:root:current train perplexity3.9389145374298096
INFO:root:current mean train loss 3480.5440635850696
INFO:root:current train perplexity3.9403436183929443
INFO:root:current mean train loss 3478.749562436996
INFO:root:current train perplexity3.9396677017211914
INFO:root:current mean train loss 3479.6788727678572
INFO:root:current train perplexity3.940096855163574
INFO:root:current mean train loss 3478.358092197516
INFO:root:current train perplexity3.941532611846924

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.92s/it]
INFO:root:final mean train loss: 3476.5599655028313
INFO:root:final train perplexity: 3.941667079925537
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.92s/it]
INFO:root:eval mean loss: 4008.2487602504434
INFO:root:eval perplexity: 5.057226181030273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [12:38:59<12:29:40, 440.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3455.875291203878
INFO:root:current train perplexity3.9112393856048584
INFO:root:current mean train loss 3457.429776884819
INFO:root:current train perplexity3.9206490516662598
INFO:root:current mean train loss 3472.27427775784
INFO:root:current train perplexity3.923200845718384
INFO:root:current mean train loss 3473.8968152078573
INFO:root:current train perplexity3.922146797180176
INFO:root:current mean train loss 3474.415496510255
INFO:root:current train perplexity3.9261019229888916
INFO:root:current mean train loss 3474.238072704492
INFO:root:current train perplexity3.9283435344696045
INFO:root:current mean train loss 3476.217079978038
INFO:root:current train perplexity3.9327638149261475
INFO:root:current mean train loss 3473.440491736011
INFO:root:current train perplexity3.9315731525421143
INFO:root:current mean train loss 3474.7375687354015
INFO:root:current train perplexity3.9324145317077637
INFO:root:current mean train loss 3475.2718594028165
INFO:root:current train perplexity3.9349913597106934

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.15s/it]
INFO:root:final mean train loss: 3472.5895447269563
INFO:root:final train perplexity: 3.9354960918426514
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.21s/it]
INFO:root:eval mean loss: 4010.440640929743
INFO:root:eval perplexity: 5.061710357666016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [12:46:19<12:21:46, 440.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3439.466051038805
INFO:root:current train perplexity3.88220477104187
INFO:root:current mean train loss 3454.716220396351
INFO:root:current train perplexity3.8946590423583984
INFO:root:current mean train loss 3458.770973441527
INFO:root:current train perplexity3.9064245223999023
INFO:root:current mean train loss 3464.6413892663045
INFO:root:current train perplexity3.9150915145874023
INFO:root:current mean train loss 3465.260352855302
INFO:root:current train perplexity3.917041540145874
INFO:root:current mean train loss 3465.4937911445113
INFO:root:current train perplexity3.9167263507843018
INFO:root:current mean train loss 3467.061216406815
INFO:root:current train perplexity3.9195199012756348
INFO:root:current mean train loss 3468.5209167711955
INFO:root:current train perplexity3.922800302505493
INFO:root:current mean train loss 3467.121022234059
INFO:root:current train perplexity3.9239532947540283
INFO:root:current mean train loss 3470.839730671749
INFO:root:current train perplexity3.9285972118377686

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:42<00:00, 402.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:42<00:00, 402.02s/it]
INFO:root:final mean train loss: 3468.082602162515
INFO:root:final train perplexity: 3.9285054206848145
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.59s/it]
INFO:root:eval mean loss: 4009.6657264655364
INFO:root:eval perplexity: 5.06012487411499
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [12:53:44<12:16:38, 441.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3438.808290423769
INFO:root:current train perplexity3.8799986839294434
INFO:root:current mean train loss 3446.460980439306
INFO:root:current train perplexity3.903590440750122
INFO:root:current mean train loss 3451.2832480338107
INFO:root:current train perplexity3.907665252685547
INFO:root:current mean train loss 3450.470233812069
INFO:root:current train perplexity3.9062917232513428
INFO:root:current mean train loss 3455.6069512071017
INFO:root:current train perplexity3.908223867416382
INFO:root:current mean train loss 3457.4248303650616
INFO:root:current train perplexity3.911221504211426
INFO:root:current mean train loss 3462.576433129918
INFO:root:current train perplexity3.9156100749969482
INFO:root:current mean train loss 3466.31444640273
INFO:root:current train perplexity3.9186317920684814
INFO:root:current mean train loss 3465.6655037172377
INFO:root:current train perplexity3.9196343421936035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.45s/it]
INFO:root:final mean train loss: 3462.81055438134
INFO:root:final train perplexity: 3.920341968536377
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.59s/it]
INFO:root:eval mean loss: 4011.979265361813
INFO:root:eval perplexity: 5.064861297607422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [13:01:05<12:08:33, 441.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3396.8117327008927
INFO:root:current train perplexity3.8601174354553223
INFO:root:current mean train loss 3480.146235670999
INFO:root:current train perplexity3.91178297996521
INFO:root:current mean train loss 3462.7252981582124
INFO:root:current train perplexity3.897874593734741
INFO:root:current mean train loss 3455.9036702208878
INFO:root:current train perplexity3.9059736728668213
INFO:root:current mean train loss 3462.4880143149185
INFO:root:current train perplexity3.910372734069824
INFO:root:current mean train loss 3462.1085645686944
INFO:root:current train perplexity3.913057327270508
INFO:root:current mean train loss 3460.4236736768944
INFO:root:current train perplexity3.909698247909546
INFO:root:current mean train loss 3459.0898109446825
INFO:root:current train perplexity3.9098570346832275
INFO:root:current mean train loss 3460.6751302083335
INFO:root:current train perplexity3.9125711917877197
INFO:root:current mean train loss 3460.1940686479293
INFO:root:current train perplexity3.9139459133148193

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.94s/it]
INFO:root:final mean train loss: 3458.8934326171875
INFO:root:final train perplexity: 3.9142889976501465
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.60s/it]
INFO:root:eval mean loss: 4014.80357414949
INFO:root:eval perplexity: 5.070648670196533
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [13:08:29<12:02:25, 442.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3435.9062662760416
INFO:root:current train perplexity3.8543918132781982
INFO:root:current mean train loss 3436.5023755944294
INFO:root:current train perplexity3.8617560863494873
INFO:root:current mean train loss 3435.7440497819766
INFO:root:current train perplexity3.872997760772705
INFO:root:current mean train loss 3453.2919015066964
INFO:root:current train perplexity3.8918228149414062
INFO:root:current mean train loss 3458.5616452136674
INFO:root:current train perplexity3.896690845489502
INFO:root:current mean train loss 3453.583907103307
INFO:root:current train perplexity3.8933231830596924
INFO:root:current mean train loss 3454.6577481897866
INFO:root:current train perplexity3.8957443237304688
INFO:root:current mean train loss 3453.2307886937283
INFO:root:current train perplexity3.8987882137298584
INFO:root:current mean train loss 3453.2057464412387
INFO:root:current train perplexity3.9012393951416016
INFO:root:current mean train loss 3454.2953789382686
INFO:root:current train perplexity3.9037365913391113

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.49s/it]
INFO:root:final mean train loss: 3453.537214648339
INFO:root:final train perplexity: 3.9060254096984863
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.30s/it]
INFO:root:eval mean loss: 4013.89618309508
INFO:root:eval perplexity: 5.068788528442383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [13:15:54<11:56:32, 443.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3387.2064686650815
INFO:root:current train perplexity3.8452870845794678
INFO:root:current mean train loss 3437.2983755716464
INFO:root:current train perplexity3.8647265434265137
INFO:root:current mean train loss 3443.0739100161154
INFO:root:current train perplexity3.87896990776062
INFO:root:current mean train loss 3440.515737622146
INFO:root:current train perplexity3.8805549144744873
INFO:root:current mean train loss 3440.5537374870714
INFO:root:current train perplexity3.8844096660614014
INFO:root:current mean train loss 3443.757268201781
INFO:root:current train perplexity3.8909053802490234
INFO:root:current mean train loss 3446.785464658783
INFO:root:current train perplexity3.8946831226348877
INFO:root:current mean train loss 3448.8905939336964
INFO:root:current train perplexity3.898573637008667
INFO:root:current mean train loss 3449.43701379528
INFO:root:current train perplexity3.898252487182617
INFO:root:current mean train loss 3450.1184970777185
INFO:root:current train perplexity3.8968887329101562

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.85s/it]
INFO:root:final mean train loss: 3449.3942877246486
INFO:root:final train perplexity: 3.899646282196045
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.75s/it]
INFO:root:eval mean loss: 4015.252602435173
INFO:root:eval perplexity: 5.071569442749023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [13:23:16<11:48:38, 442.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3393.540755733367
INFO:root:current train perplexity3.841585397720337
INFO:root:current mean train loss 3420.201484971374
INFO:root:current train perplexity3.8634183406829834
INFO:root:current mean train loss 3418.0745854893803
INFO:root:current train perplexity3.872424840927124
INFO:root:current mean train loss 3425.2844577570336
INFO:root:current train perplexity3.8778979778289795
INFO:root:current mean train loss 3426.6836991099913
INFO:root:current train perplexity3.8776073455810547
INFO:root:current mean train loss 3431.9746305246586
INFO:root:current train perplexity3.8807685375213623
INFO:root:current mean train loss 3439.046979078967
INFO:root:current train perplexity3.886399984359741
INFO:root:current mean train loss 3441.236627038624
INFO:root:current train perplexity3.8882970809936523
INFO:root:current mean train loss 3447.0481747330023
INFO:root:current train perplexity3.8938326835632324
INFO:root:current mean train loss 3446.8184624332876
INFO:root:current train perplexity3.891932487487793

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:33<00:00, 393.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:33<00:00, 393.50s/it]
INFO:root:final mean train loss: 3445.582286588607
INFO:root:final train perplexity: 3.8937859535217285
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.87s/it]
INFO:root:eval mean loss: 4016.0991332142066
INFO:root:eval perplexity: 5.073306083679199
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [13:30:32<11:37:57, 440.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3420.562318459535
INFO:root:current train perplexity3.873223066329956
INFO:root:current mean train loss 3441.755646849708
INFO:root:current train perplexity3.8782007694244385
INFO:root:current mean train loss 3438.66219211722
INFO:root:current train perplexity3.882697582244873
INFO:root:current mean train loss 3449.4863972621683
INFO:root:current train perplexity3.886640787124634
INFO:root:current mean train loss 3445.831090835884
INFO:root:current train perplexity3.8836476802825928
INFO:root:current mean train loss 3444.0009339851
INFO:root:current train perplexity3.882431983947754
INFO:root:current mean train loss 3446.557991994938
INFO:root:current train perplexity3.88362717628479
INFO:root:current mean train loss 3447.9649844860032
INFO:root:current train perplexity3.886101722717285
INFO:root:current mean train loss 3445.550796672471
INFO:root:current train perplexity3.8855319023132324
INFO:root:current mean train loss 3444.5563099041533
INFO:root:current train perplexity3.886436939239502

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.34s/it]
INFO:root:final mean train loss: 3440.7580850662725
INFO:root:final train perplexity: 3.8863823413848877
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.67s/it]
INFO:root:eval mean loss: 4017.8350856050533
INFO:root:eval perplexity: 5.076868057250977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [13:37:52<11:30:00, 440.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3370.172633394282
INFO:root:current train perplexity3.834470510482788
INFO:root:current mean train loss 3417.293123206314
INFO:root:current train perplexity3.8653979301452637
INFO:root:current mean train loss 3416.8217447257716
INFO:root:current train perplexity3.858299493789673
INFO:root:current mean train loss 3421.2490438411833
INFO:root:current train perplexity3.8651535511016846
INFO:root:current mean train loss 3426.7895589738882
INFO:root:current train perplexity3.8634634017944336
INFO:root:current mean train loss 3434.57972195641
INFO:root:current train perplexity3.87064528465271
INFO:root:current mean train loss 3436.974125999203
INFO:root:current train perplexity3.873225450515747
INFO:root:current mean train loss 3435.414660595507
INFO:root:current train perplexity3.873309373855591
INFO:root:current mean train loss 3438.025349982936
INFO:root:current train perplexity3.8779590129852295
INFO:root:current mean train loss 3437.7859564743926
INFO:root:current train perplexity3.878669261932373

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.27s/it]
INFO:root:final mean train loss: 3436.4163113870927
INFO:root:final train perplexity: 3.879729986190796
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.26s/it]
INFO:root:eval mean loss: 4016.545342627992
INFO:root:eval perplexity: 5.074220657348633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [13:45:16<11:24:18, 441.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3413.6874866832386
INFO:root:current train perplexity3.8480613231658936
INFO:root:current mean train loss 3423.528548702117
INFO:root:current train perplexity3.8528194427490234
INFO:root:current mean train loss 3416.7748736213234
INFO:root:current train perplexity3.854691505432129
INFO:root:current mean train loss 3427.8374855578786
INFO:root:current train perplexity3.8628735542297363
INFO:root:current mean train loss 3431.3900358430633
INFO:root:current train perplexity3.861734390258789
INFO:root:current mean train loss 3430.0655440596847
INFO:root:current train perplexity3.8656198978424072
INFO:root:current mean train loss 3430.227631500477
INFO:root:current train perplexity3.868231773376465
INFO:root:current mean train loss 3433.167231801014
INFO:root:current train perplexity3.8677048683166504
INFO:root:current mean train loss 3432.3482187728437
INFO:root:current train perplexity3.867513418197632
INFO:root:current mean train loss 3435.457925494928
INFO:root:current train perplexity3.8729248046875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.30s/it]
INFO:root:final mean train loss: 3431.543973061346
INFO:root:final train perplexity: 3.872279405593872
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.49s/it]
INFO:root:eval mean loss: 4019.192510943041
INFO:root:eval perplexity: 5.079655170440674
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [13:52:39<11:17:45, 442.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3380.122353205605
INFO:root:current train perplexity3.8524169921875
INFO:root:current mean train loss 3404.0396466401457
INFO:root:current train perplexity3.86413311958313
INFO:root:current mean train loss 3410.4324779437975
INFO:root:current train perplexity3.85722017288208
INFO:root:current mean train loss 3418.372307054924
INFO:root:current train perplexity3.8635404109954834
INFO:root:current mean train loss 3422.202483801296
INFO:root:current train perplexity3.8574509620666504
INFO:root:current mean train loss 3426.3381872363457
INFO:root:current train perplexity3.861701726913452
INFO:root:current mean train loss 3427.8202451127686
INFO:root:current train perplexity3.860811948776245
INFO:root:current mean train loss 3428.2468613690817
INFO:root:current train perplexity3.8610453605651855
INFO:root:current mean train loss 3428.686645932159
INFO:root:current train perplexity3.8640871047973633
INFO:root:current mean train loss 3430.9037852698275
INFO:root:current train perplexity3.867765188217163

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.78s/it]
INFO:root:final mean train loss: 3428.502998721215
INFO:root:final train perplexity: 3.8676364421844482
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.85s/it]
INFO:root:eval mean loss: 4019.477346866689
INFO:root:eval perplexity: 5.0802412033081055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [14:00:01<11:10:27, 442.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3405.556210799956
INFO:root:current train perplexity3.828935146331787
INFO:root:current mean train loss 3404.0416124131943
INFO:root:current train perplexity3.8424689769744873
INFO:root:current mean train loss 3408.2308597353554
INFO:root:current train perplexity3.847250461578369
INFO:root:current mean train loss 3414.1287193606804
INFO:root:current train perplexity3.844850778579712
INFO:root:current mean train loss 3417.4408713176754
INFO:root:current train perplexity3.8524978160858154
INFO:root:current mean train loss 3420.830433432985
INFO:root:current train perplexity3.8581762313842773
INFO:root:current mean train loss 3422.1447350037256
INFO:root:current train perplexity3.85932993888855
INFO:root:current mean train loss 3422.9054323980627
INFO:root:current train perplexity3.858454942703247
INFO:root:current mean train loss 3423.5969552216384
INFO:root:current train perplexity3.8584773540496826
INFO:root:current mean train loss 3425.76806640625
INFO:root:current train perplexity3.8611061573028564

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.64s/it]
INFO:root:final mean train loss: 3423.9901794925813
INFO:root:final train perplexity: 3.8607568740844727
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.44s/it]
INFO:root:eval mean loss: 4020.7911541445037
INFO:root:eval perplexity: 5.082940101623535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/110
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [14:07:26<11:04:13, 442.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3413.830220282832
INFO:root:current train perplexity3.8326597213745117
INFO:root:current mean train loss 3414.162161203736
INFO:root:current train perplexity3.8295698165893555
INFO:root:current mean train loss 3420.8192186799956
INFO:root:current train perplexity3.842604637145996
INFO:root:current mean train loss 3424.025411882627
INFO:root:current train perplexity3.8493716716766357
INFO:root:current mean train loss 3426.8987835782555
INFO:root:current train perplexity3.8487279415130615
INFO:root:current mean train loss 3422.311825767082
INFO:root:current train perplexity3.8439619541168213
INFO:root:current mean train loss 3423.4084828619752
INFO:root:current train perplexity3.846064567565918
INFO:root:current mean train loss 3420.450631882321
INFO:root:current train perplexity3.8478240966796875
INFO:root:current mean train loss 3420.722630974918
INFO:root:current train perplexity3.852231025695801
INFO:root:current mean train loss 3422.348611116653
INFO:root:current train perplexity3.854761838912964

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.11s/it]
INFO:root:final mean train loss: 3419.816318204326
INFO:root:final train perplexity: 3.8544042110443115
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.58s/it]
INFO:root:eval mean loss: 4020.0499951518173
INFO:root:eval perplexity: 5.081416606903076
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/111
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [14:14:48<10:56:34, 442.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3429.054303048671
INFO:root:current train perplexity3.8421950340270996
INFO:root:current mean train loss 3421.070752475351
INFO:root:current train perplexity3.8396551609039307
INFO:root:current mean train loss 3417.7967150751306
INFO:root:current train perplexity3.842420816421509
INFO:root:current mean train loss 3413.805312045785
INFO:root:current train perplexity3.836627244949341
INFO:root:current mean train loss 3413.4761283608186
INFO:root:current train perplexity3.840914487838745
INFO:root:current mean train loss 3413.506232864406
INFO:root:current train perplexity3.8437540531158447
INFO:root:current mean train loss 3417.76039001376
INFO:root:current train perplexity3.847871780395508
INFO:root:current mean train loss 3415.7623866467798
INFO:root:current train perplexity3.8481953144073486
INFO:root:current mean train loss 3418.338524509847
INFO:root:current train perplexity3.8498921394348145
INFO:root:current mean train loss 3419.3684539640326
INFO:root:current train perplexity3.8493854999542236

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.09s/it]
INFO:root:final mean train loss: 3416.481300169422
INFO:root:final train perplexity: 3.8493363857269287
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.55s/it]
INFO:root:eval mean loss: 4023.4118427249555
INFO:root:eval perplexity: 5.0883307456970215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/112
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [14:22:13<10:50:18, 443.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3398.093441611842
INFO:root:current train perplexity3.8219690322875977
INFO:root:current mean train loss 3386.9493026342147
INFO:root:current train perplexity3.8277063369750977
INFO:root:current mean train loss 3393.641750529661
INFO:root:current train perplexity3.8262710571289062
INFO:root:current mean train loss 3403.712827581092
INFO:root:current train perplexity3.8352320194244385
INFO:root:current mean train loss 3405.6154326467804
INFO:root:current train perplexity3.8371148109436035
INFO:root:current mean train loss 3403.6085670791754
INFO:root:current train perplexity3.8345139026641846
INFO:root:current mean train loss 3407.35526149393
INFO:root:current train perplexity3.8377761840820312
INFO:root:current mean train loss 3410.2095650918827
INFO:root:current train perplexity3.839672565460205
INFO:root:current mean train loss 3411.614018854749
INFO:root:current train perplexity3.841611623764038

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.73s/it]
INFO:root:final mean train loss: 3411.623755854945
INFO:root:final train perplexity: 3.841966390609741
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.98s/it]
INFO:root:eval mean loss: 4024.6728377105496
INFO:root:eval perplexity: 5.0909247398376465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/113
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [14:29:34<10:41:57, 442.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3339.8177897135415
INFO:root:current train perplexity3.8643288612365723
INFO:root:current mean train loss 3381.479255157767
INFO:root:current train perplexity3.801419258117676
INFO:root:current mean train loss 3401.762281596367
INFO:root:current train perplexity3.825547695159912
INFO:root:current mean train loss 3400.1668552109118
INFO:root:current train perplexity3.825444459915161
INFO:root:current mean train loss 3399.4219652653924
INFO:root:current train perplexity3.8260693550109863
INFO:root:current mean train loss 3406.092704515097
INFO:root:current train perplexity3.833099365234375
INFO:root:current mean train loss 3406.8058887690454
INFO:root:current train perplexity3.8328566551208496
INFO:root:current mean train loss 3407.7028780811033
INFO:root:current train perplexity3.83394193649292
INFO:root:current mean train loss 3410.8291216288526
INFO:root:current train perplexity3.836761713027954
INFO:root:current mean train loss 3409.630741765729
INFO:root:current train perplexity3.8341290950775146

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.47s/it]
INFO:root:final mean train loss: 3407.0138824216783
INFO:root:final train perplexity: 3.8349854946136475
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.05s/it]
INFO:root:eval mean loss: 4024.273834012079
INFO:root:eval perplexity: 5.090103626251221
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/114
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [14:36:56<10:34:15, 442.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3372.980224609375
INFO:root:current train perplexity3.818608045578003
INFO:root:current mean train loss 3401.546342729448
INFO:root:current train perplexity3.845364570617676
INFO:root:current mean train loss 3393.731054224674
INFO:root:current train perplexity3.8326542377471924
INFO:root:current mean train loss 3401.722238620378
INFO:root:current train perplexity3.8305609226226807
INFO:root:current mean train loss 3402.659513524559
INFO:root:current train perplexity3.82938814163208
INFO:root:current mean train loss 3400.7728355094177
INFO:root:current train perplexity3.827876329421997
INFO:root:current mean train loss 3406.5541828361547
INFO:root:current train perplexity3.827395439147949
INFO:root:current mean train loss 3405.282460401833
INFO:root:current train perplexity3.8277368545532227
INFO:root:current mean train loss 3403.2008819768225
INFO:root:current train perplexity3.8262290954589844
INFO:root:current mean train loss 3405.2553887812155
INFO:root:current train perplexity3.828343629837036

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.64s/it]
INFO:root:final mean train loss: 3404.2877361543715
INFO:root:final train perplexity: 3.8308627605438232
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.14s/it]
INFO:root:eval mean loss: 4026.346006136414
INFO:root:eval perplexity: 5.094370365142822
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/115
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [14:44:17<10:25:54, 441.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3350.7477770353617
INFO:root:current train perplexity3.7766189575195312
INFO:root:current mean train loss 3362.6888048188025
INFO:root:current train perplexity3.796079635620117
INFO:root:current mean train loss 3384.109173221675
INFO:root:current train perplexity3.8077375888824463
INFO:root:current mean train loss 3390.470501077586
INFO:root:current train perplexity3.8110594749450684
INFO:root:current mean train loss 3391.0750910137604
INFO:root:current train perplexity3.8087244033813477
INFO:root:current mean train loss 3395.304262723537
INFO:root:current train perplexity3.811225652694702
INFO:root:current mean train loss 3397.0766388580373
INFO:root:current train perplexity3.8151206970214844
INFO:root:current mean train loss 3401.4994475427025
INFO:root:current train perplexity3.8185834884643555
INFO:root:current mean train loss 3401.876210269765
INFO:root:current train perplexity3.819470167160034
INFO:root:current mean train loss 3399.761479391237
INFO:root:current train perplexity3.821025848388672

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:34<00:00, 394.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:34<00:00, 394.54s/it]
INFO:root:final mean train loss: 3399.4267442764776
INFO:root:final train perplexity: 3.8235228061676025
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.53s/it]
INFO:root:eval mean loss: 4026.910474844858
INFO:root:eval perplexity: 5.09553337097168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/116
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [14:51:33<10:16:19, 440.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3413.227936921296
INFO:root:current train perplexity3.836629867553711
INFO:root:current mean train loss 3402.5015225147636
INFO:root:current train perplexity3.8121070861816406
INFO:root:current mean train loss 3398.768738599601
INFO:root:current train perplexity3.8056418895721436
INFO:root:current mean train loss 3393.4660316023987
INFO:root:current train perplexity3.805881977081299
INFO:root:current mean train loss 3398.069849947856
INFO:root:current train perplexity3.8125674724578857
INFO:root:current mean train loss 3398.110871809031
INFO:root:current train perplexity3.8122434616088867
INFO:root:current mean train loss 3399.0392342161335
INFO:root:current train perplexity3.8133397102355957
INFO:root:current mean train loss 3399.767084806461
INFO:root:current train perplexity3.816256046295166
INFO:root:current mean train loss 3398.7394948680285
INFO:root:current train perplexity3.815744400024414
INFO:root:current mean train loss 3399.6911120697646
INFO:root:current train perplexity3.819767951965332

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.45s/it]
INFO:root:final mean train loss: 3396.6728742661016
INFO:root:final train perplexity: 3.8193705081939697
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.46s/it]
INFO:root:eval mean loss: 4029.1475596326463
INFO:root:eval perplexity: 5.10014533996582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/117
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [14:58:53<10:09:01, 440.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3388.9589425223216
INFO:root:current train perplexity3.786813259124756
INFO:root:current mean train loss 3388.452068865741
INFO:root:current train perplexity3.7896740436553955
INFO:root:current mean train loss 3384.645920254322
INFO:root:current train perplexity3.795804500579834
INFO:root:current mean train loss 3392.553579028685
INFO:root:current train perplexity3.80379581451416
INFO:root:current mean train loss 3394.9966201957614
INFO:root:current train perplexity3.80523681640625
INFO:root:current mean train loss 3395.7600627007887
INFO:root:current train perplexity3.807821035385132
INFO:root:current mean train loss 3395.7206988957923
INFO:root:current train perplexity3.811864137649536
INFO:root:current mean train loss 3397.3112816220237
INFO:root:current train perplexity3.8122222423553467
INFO:root:current mean train loss 3396.691584019461
INFO:root:current train perplexity3.813148021697998
INFO:root:current mean train loss 3396.611784028242
INFO:root:current train perplexity3.8151676654815674

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.60s/it]
INFO:root:final mean train loss: 3393.3943558969804
INFO:root:final train perplexity: 3.814434051513672
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.46s/it]
INFO:root:eval mean loss: 4030.200732075576
INFO:root:eval perplexity: 5.102317810058594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/118
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [15:06:17<10:03:04, 441.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3385.2795750817586
INFO:root:current train perplexity3.792337417602539
INFO:root:current mean train loss 3375.8171779392483
INFO:root:current train perplexity3.782038927078247
INFO:root:current mean train loss 3378.1516876848636
INFO:root:current train perplexity3.7915756702423096
INFO:root:current mean train loss 3381.449439401877
INFO:root:current train perplexity3.792731523513794
INFO:root:current mean train loss 3388.1432284318566
INFO:root:current train perplexity3.795370101928711
INFO:root:current mean train loss 3387.700926835146
INFO:root:current train perplexity3.7952091693878174
INFO:root:current mean train loss 3389.929111510376
INFO:root:current train perplexity3.800081253051758
INFO:root:current mean train loss 3391.0133630026075
INFO:root:current train perplexity3.8028695583343506
INFO:root:current mean train loss 3389.8222743132783
INFO:root:current train perplexity3.806997776031494
INFO:root:current mean train loss 3390.757313862838
INFO:root:current train perplexity3.806889772415161

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.90s/it]
INFO:root:final mean train loss: 3388.746782733548
INFO:root:final train perplexity: 3.8074464797973633
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.97s/it]
INFO:root:eval mean loss: 4031.5876222434617
INFO:root:eval perplexity: 5.105179786682129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/119
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [15:13:37<9:55:19, 440.98s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3390.5343328737745
INFO:root:current train perplexity3.799487829208374
INFO:root:current mean train loss 3377.3795303445777
INFO:root:current train perplexity3.7876787185668945
INFO:root:current mean train loss 3374.45702055061
INFO:root:current train perplexity3.790983200073242
INFO:root:current mean train loss 3369.9716045673076
INFO:root:current train perplexity3.790677547454834
INFO:root:current mean train loss 3372.8597642175373
INFO:root:current train perplexity3.7921507358551025
INFO:root:current mean train loss 3377.7042557565787
INFO:root:current train perplexity3.7939515113830566
INFO:root:current mean train loss 3381.9752229142664
INFO:root:current train perplexity3.796989917755127
INFO:root:current mean train loss 3386.168350402588
INFO:root:current train perplexity3.800755739212036
INFO:root:current mean train loss 3385.544737693706
INFO:root:current train perplexity3.8011183738708496
INFO:root:current mean train loss 3387.666470019223
INFO:root:current train perplexity3.8024816513061523

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.81s/it]
INFO:root:final mean train loss: 3385.7221995938207
INFO:root:final train perplexity: 3.802905797958374
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.02s/it]
INFO:root:eval mean loss: 4033.077283494016
INFO:root:eval perplexity: 5.108255386352539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/120
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [15:21:03<9:49:40, 442.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3374.8375802767478
INFO:root:current train perplexity3.779258966445923
INFO:root:current mean train loss 3369.31337829206
INFO:root:current train perplexity3.7779572010040283
INFO:root:current mean train loss 3367.6453880987574
INFO:root:current train perplexity3.7710208892822266
INFO:root:current mean train loss 3375.0471592640147
INFO:root:current train perplexity3.783496379852295
INFO:root:current mean train loss 3377.573014535675
INFO:root:current train perplexity3.7886624336242676
INFO:root:current mean train loss 3375.691148133525
INFO:root:current train perplexity3.7916195392608643
INFO:root:current mean train loss 3381.2847376173654
INFO:root:current train perplexity3.7956759929656982
INFO:root:current mean train loss 3383.9626715739255
INFO:root:current train perplexity3.7986223697662354
INFO:root:current mean train loss 3386.186233538271
INFO:root:current train perplexity3.799844741821289
INFO:root:current mean train loss 3385.4391074076184
INFO:root:current train perplexity3.7988955974578857

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 397.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 397.00s/it]
INFO:root:final mean train loss: 3383.3960722646407
INFO:root:final train perplexity: 3.79941725730896
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.03s/it]
INFO:root:eval mean loss: 4032.783859361148
INFO:root:eval perplexity: 5.107649803161621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/121
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [15:28:24<9:41:58, 442.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3369.046445020989
INFO:root:current train perplexity3.7895376682281494
INFO:root:current mean train loss 3376.0765914460144
INFO:root:current train perplexity3.787121534347534
INFO:root:current mean train loss 3369.025900851475
INFO:root:current train perplexity3.7757973670959473
INFO:root:current mean train loss 3369.520416010303
INFO:root:current train perplexity3.7800862789154053
INFO:root:current mean train loss 3373.6642036519675
INFO:root:current train perplexity3.779517650604248
INFO:root:current mean train loss 3373.159773892196
INFO:root:current train perplexity3.7802228927612305
INFO:root:current mean train loss 3377.469187403369
INFO:root:current train perplexity3.7842459678649902
INFO:root:current mean train loss 3376.567059413706
INFO:root:current train perplexity3.7842185497283936
INFO:root:current mean train loss 3378.5225958202673
INFO:root:current train perplexity3.78605055809021
INFO:root:current mean train loss 3381.540865908981
INFO:root:current train perplexity3.7916200160980225

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.49s/it]
INFO:root:final mean train loss: 3379.2010648788946
INFO:root:final train perplexity: 3.793133497238159
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.31s/it]
INFO:root:eval mean loss: 4032.0503068207004
INFO:root:eval perplexity: 5.10613489151001
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/122
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [15:35:46<9:34:46, 442.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3375.06689453125
INFO:root:current train perplexity3.7788338661193848
INFO:root:current mean train loss 3366.032705078125
INFO:root:current train perplexity3.7908177375793457
INFO:root:current mean train loss 3372.669430042614
INFO:root:current train perplexity3.7898409366607666
INFO:root:current mean train loss 3373.1538385416666
INFO:root:current train perplexity3.7857468128204346
INFO:root:current mean train loss 3376.826780941612
INFO:root:current train perplexity3.788301944732666
INFO:root:current mean train loss 3377.4162775985055
INFO:root:current train perplexity3.785417318344116
INFO:root:current mean train loss 3378.3642834924767
INFO:root:current train perplexity3.7861948013305664
INFO:root:current mean train loss 3378.859976688508
INFO:root:current train perplexity3.786905288696289
INFO:root:current mean train loss 3377.7186847098214
INFO:root:current train perplexity3.7865326404571533
INFO:root:current mean train loss 3377.445426933093
INFO:root:current train perplexity3.786787509918213

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.03s/it]
INFO:root:final mean train loss: 3375.209670897453
INFO:root:final train perplexity: 3.787165880203247
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.15s/it]
INFO:root:eval mean loss: 4033.3466017702794
INFO:root:eval perplexity: 5.1088128089904785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/123
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [15:43:04<9:25:41, 440.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3350.7498970491342
INFO:root:current train perplexity3.765657424926758
INFO:root:current mean train loss 3344.2140512935453
INFO:root:current train perplexity3.762219190597534
INFO:root:current mean train loss 3351.0470984361195
INFO:root:current train perplexity3.7618653774261475
INFO:root:current mean train loss 3362.2087759311767
INFO:root:current train perplexity3.773174285888672
INFO:root:current mean train loss 3365.8072684151784
INFO:root:current train perplexity3.77968430519104
INFO:root:current mean train loss 3374.5482054198383
INFO:root:current train perplexity3.7811527252197266
INFO:root:current mean train loss 3376.8596480943447
INFO:root:current train perplexity3.7826900482177734
INFO:root:current mean train loss 3374.7307640260815
INFO:root:current train perplexity3.7791855335235596
INFO:root:current mean train loss 3374.723079279622
INFO:root:current train perplexity3.7811412811279297
INFO:root:current mean train loss 3374.789346130309
INFO:root:current train perplexity3.782437562942505

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:28<00:00, 388.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:28<00:00, 388.74s/it]
INFO:root:final mean train loss: 3371.993196364372
INFO:root:final train perplexity: 3.782362222671509
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.24s/it]
INFO:root:eval mean loss: 4034.4177107574246
INFO:root:eval perplexity: 5.111024856567383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/124
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [15:50:14<9:14:02, 437.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3338.5624060997598
INFO:root:current train perplexity3.720677614212036
INFO:root:current mean train loss 3362.5349185004907
INFO:root:current train perplexity3.7586987018585205
INFO:root:current mean train loss 3364.8792275759774
INFO:root:current train perplexity3.76137375831604
INFO:root:current mean train loss 3367.1683796055786
INFO:root:current train perplexity3.7622671127319336
INFO:root:current mean train loss 3366.326967942496
INFO:root:current train perplexity3.763822317123413
INFO:root:current mean train loss 3369.1474530886476
INFO:root:current train perplexity3.770181179046631
INFO:root:current mean train loss 3370.9645957229104
INFO:root:current train perplexity3.7722108364105225
INFO:root:current mean train loss 3373.449427396097
INFO:root:current train perplexity3.773092269897461
INFO:root:current mean train loss 3372.2090591790297
INFO:root:current train perplexity3.776674509048462
INFO:root:current mean train loss 3371.8381480689486
INFO:root:current train perplexity3.778127908706665

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:34<00:00, 394.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:34<00:00, 394.43s/it]
INFO:root:final mean train loss: 3369.1134545110885
INFO:root:final train perplexity: 3.7780675888061523
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.34s/it]
INFO:root:eval mean loss: 4035.3280453512853
INFO:root:eval perplexity: 5.112907409667969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/125
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [15:57:45<9:11:58, 441.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3372.58392025726
INFO:root:current train perplexity3.7717769145965576
INFO:root:current mean train loss 3360.894739812343
INFO:root:current train perplexity3.769861936569214
INFO:root:current mean train loss 3363.7455613764632
INFO:root:current train perplexity3.7703583240509033
INFO:root:current mean train loss 3362.5221213433974
INFO:root:current train perplexity3.767815113067627
INFO:root:current mean train loss 3362.553950674787
INFO:root:current train perplexity3.765904426574707
INFO:root:current mean train loss 3365.6369934591507
INFO:root:current train perplexity3.7673611640930176
INFO:root:current mean train loss 3364.4114422668545
INFO:root:current train perplexity3.7678797245025635
INFO:root:current mean train loss 3367.1441089692194
INFO:root:current train perplexity3.769742012023926
INFO:root:current mean train loss 3368.5867174464684
INFO:root:current train perplexity3.7732956409454346

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:34<00:00, 394.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:34<00:00, 394.68s/it]
INFO:root:final mean train loss: 3365.5023322566863
INFO:root:final train perplexity: 3.7726893424987793
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.89s/it]
INFO:root:eval mean loss: 4038.3623289284133
INFO:root:eval perplexity: 5.119184970855713
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/126
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [16:05:03<9:03:19, 440.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3371.479178292411
INFO:root:current train perplexity3.8237595558166504
INFO:root:current mean train loss 3351.8594206337616
INFO:root:current train perplexity3.752318859100342
INFO:root:current mean train loss 3356.7981310858245
INFO:root:current train perplexity3.753706932067871
INFO:root:current mean train loss 3359.1759172371235
INFO:root:current train perplexity3.7591123580932617
INFO:root:current mean train loss 3352.6139476879225
INFO:root:current train perplexity3.7596640586853027
INFO:root:current mean train loss 3358.0174779647436
INFO:root:current train perplexity3.764176845550537
INFO:root:current mean train loss 3359.8380571393636
INFO:root:current train perplexity3.7631351947784424
INFO:root:current mean train loss 3364.2744841622834
INFO:root:current train perplexity3.7680423259735107
INFO:root:current mean train loss 3364.953612978721
INFO:root:current train perplexity3.768296241760254
INFO:root:current mean train loss 3364.5796762485356
INFO:root:current train perplexity3.7661921977996826

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.09s/it]
INFO:root:final mean train loss: 3362.3036570395193
INFO:root:final train perplexity: 3.767930507659912
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.66s/it]
INFO:root:eval mean loss: 4038.706452931073
INFO:root:eval perplexity: 5.119897365570068
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/127
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [16:12:26<8:56:56, 441.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3316.969547526042
INFO:root:current train perplexity3.7649223804473877
INFO:root:current mean train loss 3337.9457880434784
INFO:root:current train perplexity3.7658114433288574
INFO:root:current mean train loss 3348.0187602198403
INFO:root:current train perplexity3.769151210784912
INFO:root:current mean train loss 3354.38167937748
INFO:root:current train perplexity3.762852907180786
INFO:root:current mean train loss 3355.353733880836
INFO:root:current train perplexity3.7589690685272217
INFO:root:current mean train loss 3353.905400485437
INFO:root:current train perplexity3.7587337493896484
INFO:root:current mean train loss 3355.6416412601625
INFO:root:current train perplexity3.7571187019348145
INFO:root:current mean train loss 3356.9177048049605
INFO:root:current train perplexity3.7584824562072754
INFO:root:current mean train loss 3357.049890960506
INFO:root:current train perplexity3.757979393005371
INFO:root:current mean train loss 3359.3561149889
INFO:root:current train perplexity3.761143922805786

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:35<00:00, 395.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:35<00:00, 395.49s/it]
INFO:root:final mean train loss: 3358.527373098558
INFO:root:final train perplexity: 3.7623214721679688
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.19s/it]
INFO:root:eval mean loss: 4038.840612533245
INFO:root:eval perplexity: 5.120174407958984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/128
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [16:19:44<8:48:27, 440.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3318.3263841711955
INFO:root:current train perplexity3.7493579387664795
INFO:root:current mean train loss 3362.496524469639
INFO:root:current train perplexity3.757293462753296
INFO:root:current mean train loss 3358.831509029919
INFO:root:current train perplexity3.7545828819274902
INFO:root:current mean train loss 3359.9001956148413
INFO:root:current train perplexity3.7629342079162598
INFO:root:current mean train loss 3356.218744805519
INFO:root:current train perplexity3.7544078826904297
INFO:root:current mean train loss 3354.631985316085
INFO:root:current train perplexity3.7560367584228516
INFO:root:current mean train loss 3355.620786124975
INFO:root:current train perplexity3.756742238998413
INFO:root:current mean train loss 3357.4582492517075
INFO:root:current train perplexity3.758624792098999
INFO:root:current mean train loss 3356.092664864634
INFO:root:current train perplexity3.7570977210998535
INFO:root:current mean train loss 3356.804875035973
INFO:root:current train perplexity3.7566616535186768

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.35s/it]
INFO:root:final mean train loss: 3355.689151763916
INFO:root:final train perplexity: 3.758111000061035
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.01s/it]
INFO:root:eval mean loss: 4038.751102961547
INFO:root:eval perplexity: 5.119988918304443
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/129
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [16:27:03<8:40:35, 439.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3354.611052482359
INFO:root:current train perplexity3.722404718399048
INFO:root:current mean train loss 3344.0444745944656
INFO:root:current train perplexity3.7399723529815674
INFO:root:current mean train loss 3359.452560622971
INFO:root:current train perplexity3.7564995288848877
INFO:root:current mean train loss 3359.7914190839783
INFO:root:current train perplexity3.757624864578247
INFO:root:current mean train loss 3355.879078451276
INFO:root:current train perplexity3.75734543800354
INFO:root:current mean train loss 3358.562544598193
INFO:root:current train perplexity3.7616069316864014
INFO:root:current mean train loss 3357.632093619998
INFO:root:current train perplexity3.7576069831848145
INFO:root:current mean train loss 3358.5566419609268
INFO:root:current train perplexity3.757047653198242
INFO:root:current mean train loss 3354.709027562331
INFO:root:current train perplexity3.753638505935669
INFO:root:current mean train loss 3354.6211482948443
INFO:root:current train perplexity3.7531611919403076

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:35<00:00, 395.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:35<00:00, 395.04s/it]
INFO:root:final mean train loss: 3353.388840583063
INFO:root:final train perplexity: 3.7547013759613037
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.81s/it]
INFO:root:eval mean loss: 4040.035028119459
INFO:root:eval perplexity: 5.122648239135742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/130
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [16:34:20<8:31:59, 438.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3358.699469150641
INFO:root:current train perplexity3.7566404342651367
INFO:root:current mean train loss 3358.7626232997977
INFO:root:current train perplexity3.759390354156494
INFO:root:current mean train loss 3353.7683503857215
INFO:root:current train perplexity3.7483389377593994
INFO:root:current mean train loss 3354.3506255473358
INFO:root:current train perplexity3.749152660369873
INFO:root:current mean train loss 3353.1348379217684
INFO:root:current train perplexity3.750035524368286
INFO:root:current mean train loss 3346.9917567435355
INFO:root:current train perplexity3.7473905086517334
INFO:root:current mean train loss 3346.643284948406
INFO:root:current train perplexity3.747326135635376
INFO:root:current mean train loss 3346.9118725024314
INFO:root:current train perplexity3.7451462745666504
INFO:root:current mean train loss 3351.49787926475
INFO:root:current train perplexity3.748713493347168
INFO:root:current mean train loss 3351.9598811172955
INFO:root:current train perplexity3.7500264644622803

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:35<00:00, 395.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:35<00:00, 395.32s/it]
INFO:root:final mean train loss: 3350.46288311866
INFO:root:final train perplexity: 3.750370740890503
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.42s/it]
INFO:root:eval mean loss: 4041.5683455230496
INFO:root:eval perplexity: 5.12582540512085
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/131
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [16:41:38<8:24:26, 438.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3314.079797623005
INFO:root:current train perplexity3.7410500049591064
INFO:root:current mean train loss 3346.5237430909865
INFO:root:current train perplexity3.7373223304748535
INFO:root:current mean train loss 3347.0944211396127
INFO:root:current train perplexity3.7478013038635254
INFO:root:current mean train loss 3344.9078865161205
INFO:root:current train perplexity3.7392144203186035
INFO:root:current mean train loss 3347.101495866541
INFO:root:current train perplexity3.740151882171631
INFO:root:current mean train loss 3347.2850834987717
INFO:root:current train perplexity3.7403063774108887
INFO:root:current mean train loss 3347.8491369421367
INFO:root:current train perplexity3.7433714866638184
INFO:root:current mean train loss 3348.102660315742
INFO:root:current train perplexity3.7439661026000977
INFO:root:current mean train loss 3347.324898711906
INFO:root:current train perplexity3.7432284355163574
INFO:root:current mean train loss 3348.2640980254255
INFO:root:current train perplexity3.743396043777466

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.70s/it]
INFO:root:final mean train loss: 3346.842691421509
INFO:root:final train perplexity: 3.7450172901153564
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.04s/it]
INFO:root:eval mean loss: 4041.4821327155364
INFO:root:eval perplexity: 5.12564754486084
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/132
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [16:49:02<8:19:01, 440.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3318.2321954900567
INFO:root:current train perplexity3.7233879566192627
INFO:root:current mean train loss 3320.3847640498993
INFO:root:current train perplexity3.727646589279175
INFO:root:current mean train loss 3322.830472579657
INFO:root:current train perplexity3.731220006942749
INFO:root:current mean train loss 3323.414512956646
INFO:root:current train perplexity3.7237935066223145
INFO:root:current mean train loss 3329.7550282237294
INFO:root:current train perplexity3.726165771484375
INFO:root:current mean train loss 3333.127805197776
INFO:root:current train perplexity3.7280776500701904
INFO:root:current mean train loss 3335.6747390863547
INFO:root:current train perplexity3.732313394546509
INFO:root:current mean train loss 3337.695244593336
INFO:root:current train perplexity3.7333922386169434
INFO:root:current mean train loss 3340.8882509822733
INFO:root:current train perplexity3.7348246574401855
INFO:root:current mean train loss 3343.5125291434883
INFO:root:current train perplexity3.73822021484375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.68s/it]
INFO:root:final mean train loss: 3343.4599075317383
INFO:root:final train perplexity: 3.740022659301758
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.23s/it]
INFO:root:eval mean loss: 4043.941686751995
INFO:root:eval perplexity: 5.130747318267822
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/133
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [16:56:23<8:12:03, 440.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3329.6193963913693
INFO:root:current train perplexity3.7334322929382324
INFO:root:current mean train loss 3325.8640166674654
INFO:root:current train perplexity3.7237815856933594
INFO:root:current mean train loss 3332.3131934336384
INFO:root:current train perplexity3.730646848678589
INFO:root:current mean train loss 3337.049224937586
INFO:root:current train perplexity3.7350423336029053
INFO:root:current mean train loss 3339.300434812871
INFO:root:current train perplexity3.7340259552001953
INFO:root:current mean train loss 3346.7535372203874
INFO:root:current train perplexity3.7373275756835938
INFO:root:current mean train loss 3343.576055144113
INFO:root:current train perplexity3.733696937561035
INFO:root:current mean train loss 3341.733155256799
INFO:root:current train perplexity3.732560873031616
INFO:root:current mean train loss 3341.4920143666714
INFO:root:current train perplexity3.7331807613372803
INFO:root:current mean train loss 3343.7156448760384
INFO:root:current train perplexity3.7360613346099854

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.56s/it]
INFO:root:final mean train loss: 3341.025641472109
INFO:root:final train perplexity: 3.7364327907562256
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.83s/it]
INFO:root:eval mean loss: 4045.949473279588
INFO:root:eval perplexity: 5.134914398193359
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/134
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [17:03:46<8:05:27, 441.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3340.839874697403
INFO:root:current train perplexity3.7338194847106934
INFO:root:current mean train loss 3322.898247612847
INFO:root:current train perplexity3.710089683532715
INFO:root:current mean train loss 3323.5080575415127
INFO:root:current train perplexity3.712172746658325
INFO:root:current mean train loss 3327.921702588022
INFO:root:current train perplexity3.717533826828003
INFO:root:current mean train loss 3332.0346161342222
INFO:root:current train perplexity3.7218000888824463
INFO:root:current mean train loss 3338.6130084624015
INFO:root:current train perplexity3.725421190261841
INFO:root:current mean train loss 3343.0733291466795
INFO:root:current train perplexity3.732754945755005
INFO:root:current mean train loss 3341.1935272018886
INFO:root:current train perplexity3.731700897216797
INFO:root:current mean train loss 3341.6472260467494
INFO:root:current train perplexity3.7327699661254883
INFO:root:current mean train loss 3339.858967931337
INFO:root:current train perplexity3.73087477684021

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.11s/it]
INFO:root:final mean train loss: 3337.9975019270373
INFO:root:final train perplexity: 3.731971263885498
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.13s/it]
INFO:root:eval mean loss: 4044.2656284629875
INFO:root:eval perplexity: 5.1314191818237305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/135
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [17:11:09<7:58:34, 441.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3339.5802820905856
INFO:root:current train perplexity3.7200891971588135
INFO:root:current mean train loss 3332.7482732847416
INFO:root:current train perplexity3.733698844909668
INFO:root:current mean train loss 3332.476622003808
INFO:root:current train perplexity3.7281601428985596
INFO:root:current mean train loss 3336.2348690787844
INFO:root:current train perplexity3.728576183319092
INFO:root:current mean train loss 3339.3011370123304
INFO:root:current train perplexity3.730419397354126
INFO:root:current mean train loss 3340.3080848074537
INFO:root:current train perplexity3.7296533584594727
INFO:root:current mean train loss 3342.365277162532
INFO:root:current train perplexity3.7289392948150635
INFO:root:current mean train loss 3342.4132210140206
INFO:root:current train perplexity3.7279317378997803
INFO:root:current mean train loss 3340.9186292351037
INFO:root:current train perplexity3.7278642654418945
INFO:root:current mean train loss 3337.973803636124
INFO:root:current train perplexity3.727541208267212

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.87s/it]
INFO:root:final mean train loss: 3335.1579392340877
INFO:root:final train perplexity: 3.727792739868164
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.79s/it]
INFO:root:eval mean loss: 4046.9949197972073
INFO:root:eval perplexity: 5.137086391448975
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/136
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [17:19:39<8:12:59, 462.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3312.273302801724
INFO:root:current train perplexity3.709850788116455
INFO:root:current mean train loss 3329.7238782586896
INFO:root:current train perplexity3.7203969955444336
INFO:root:current mean train loss 3326.638889645035
INFO:root:current train perplexity3.7148547172546387
INFO:root:current mean train loss 3334.6971703659965
INFO:root:current train perplexity3.7209322452545166
INFO:root:current mean train loss 3337.906559812949
INFO:root:current train perplexity3.7226786613464355
INFO:root:current mean train loss 3338.102032481101
INFO:root:current train perplexity3.7222325801849365
INFO:root:current mean train loss 3337.511966799718
INFO:root:current train perplexity3.7224302291870117
INFO:root:current mean train loss 3334.2685363847086
INFO:root:current train perplexity3.720285177230835
INFO:root:current mean train loss 3334.1288809276352
INFO:root:current train perplexity3.721008062362671
INFO:root:current mean train loss 3334.751356996422
INFO:root:current train perplexity3.723602294921875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:43<00:00, 403.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:43<00:00, 403.25s/it]
INFO:root:final mean train loss: 3332.439712216777
INFO:root:final train perplexity: 3.7237966060638428
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.95s/it]
INFO:root:eval mean loss: 4046.491995304189
INFO:root:eval perplexity: 5.136041164398193
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/137
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [17:28:15<8:22:17, 478.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3312.2850894325657
INFO:root:current train perplexity3.700824499130249
INFO:root:current mean train loss 3324.724981219952
INFO:root:current train perplexity3.7060935497283936
INFO:root:current mean train loss 3326.5858009467693
INFO:root:current train perplexity3.7111246585845947
INFO:root:current mean train loss 3326.961481408228
INFO:root:current train perplexity3.7150025367736816
INFO:root:current mean train loss 3326.2773432567865
INFO:root:current train perplexity3.7164688110351562
INFO:root:current mean train loss 3328.169793034401
INFO:root:current train perplexity3.717909812927246
INFO:root:current mean train loss 3326.4216508824193
INFO:root:current train perplexity3.7162909507751465
INFO:root:current mean train loss 3330.5909238035574
INFO:root:current train perplexity3.7202537059783936
INFO:root:current mean train loss 3330.849496715695
INFO:root:current train perplexity3.719245433807373

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.24s/it]
INFO:root:final mean train loss: 3329.3242224416426
INFO:root:final train perplexity: 3.7192227840423584
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.28s/it]
INFO:root:eval mean loss: 4047.656973764406
INFO:root:eval perplexity: 5.138461112976074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/138
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [17:36:30<8:19:25, 483.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3367.0515950520835
INFO:root:current train perplexity3.5493385791778564
INFO:root:current mean train loss 3301.55967697588
INFO:root:current train perplexity3.678243398666382
INFO:root:current mean train loss 3309.08038480411
INFO:root:current train perplexity3.6908135414123535
INFO:root:current mean train loss 3314.787302753713
INFO:root:current train perplexity3.7000675201416016
INFO:root:current mean train loss 3320.967033745929
INFO:root:current train perplexity3.700155735015869
INFO:root:current mean train loss 3322.4073425656998
INFO:root:current train perplexity3.701150894165039
INFO:root:current mean train loss 3324.3224296000467
INFO:root:current train perplexity3.7036609649658203
INFO:root:current mean train loss 3324.4548305115354
INFO:root:current train perplexity3.70603346824646
INFO:root:current mean train loss 3327.19156130818
INFO:root:current train perplexity3.70947003364563
INFO:root:current mean train loss 3327.5857558139537
INFO:root:current train perplexity3.7119085788726807

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.69s/it]
INFO:root:final mean train loss: 3326.6023546649562
INFO:root:final train perplexity: 3.71523118019104
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.06s/it]
INFO:root:eval mean loss: 4049.4406080313606
INFO:root:eval perplexity: 5.1421685218811035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/139
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [17:45:09<8:22:09, 493.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3381.060635653409
INFO:root:current train perplexity3.657172203063965
INFO:root:current mean train loss 3318.476848430462
INFO:root:current train perplexity3.7027060985565186
INFO:root:current mean train loss 3317.2569389162472
INFO:root:current train perplexity3.6964223384857178
INFO:root:current mean train loss 3308.1599325198454
INFO:root:current train perplexity3.6870505809783936
INFO:root:current mean train loss 3313.287358267754
INFO:root:current train perplexity3.6927804946899414
INFO:root:current mean train loss 3315.155832906525
INFO:root:current train perplexity3.700634717941284
INFO:root:current mean train loss 3317.6620590284883
INFO:root:current train perplexity3.7012436389923096
INFO:root:current mean train loss 3320.260320864649
INFO:root:current train perplexity3.7017319202423096
INFO:root:current mean train loss 3322.3607970965627
INFO:root:current train perplexity3.7063639163970947
INFO:root:current mean train loss 3325.6650353106133
INFO:root:current train perplexity3.7090365886688232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.83s/it]
INFO:root:final mean train loss: 3323.3212042162495
INFO:root:final train perplexity: 3.7104249000549316
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.11s/it]
INFO:root:eval mean loss: 4051.052843459109
INFO:root:eval perplexity: 5.145522594451904
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/140
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [17:53:41<8:19:25, 499.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3303.5054224917762
INFO:root:current train perplexity3.6869900226593018
INFO:root:current mean train loss 3298.4513893448006
INFO:root:current train perplexity3.6851210594177246
INFO:root:current mean train loss 3299.334861720534
INFO:root:current train perplexity3.696542263031006
INFO:root:current mean train loss 3307.5831731240205
INFO:root:current train perplexity3.6977908611297607
INFO:root:current mean train loss 3311.790021582264
INFO:root:current train perplexity3.6996395587921143
INFO:root:current mean train loss 3315.3729447969354
INFO:root:current train perplexity3.70196270942688
INFO:root:current mean train loss 3314.044854036248
INFO:root:current train perplexity3.7008583545684814
INFO:root:current mean train loss 3317.9485657841838
INFO:root:current train perplexity3.7034900188446045
INFO:root:current mean train loss 3319.710187192365
INFO:root:current train perplexity3.7044026851654053
INFO:root:current mean train loss 3321.703601060936
INFO:root:current train perplexity3.704983949661255

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.19s/it]
INFO:root:final mean train loss: 3321.971312553652
INFO:root:final train perplexity: 3.708449125289917
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.09s/it]
INFO:root:eval mean loss: 4049.6165087544327
INFO:root:eval perplexity: 5.142533779144287
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/141
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [18:01:07<7:55:26, 483.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3272.8828577112267
INFO:root:current train perplexity3.7080724239349365
INFO:root:current mean train loss 3309.664585383858
INFO:root:current train perplexity3.6979897022247314
INFO:root:current mean train loss 3312.5094838415475
INFO:root:current train perplexity3.7006752490997314
INFO:root:current mean train loss 3314.3069967567376
INFO:root:current train perplexity3.7050399780273438
INFO:root:current mean train loss 3320.077730487046
INFO:root:current train perplexity3.7065560817718506
INFO:root:current mean train loss 3318.9538370382174
INFO:root:current train perplexity3.702571392059326
INFO:root:current mean train loss 3319.801517955044
INFO:root:current train perplexity3.704375743865967
INFO:root:current mean train loss 3319.9009873758814
INFO:root:current train perplexity3.7045891284942627
INFO:root:current mean train loss 3320.647524998583
INFO:root:current train perplexity3.7058634757995605
INFO:root:current mean train loss 3319.7069177390945
INFO:root:current train perplexity3.70261287689209

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.98s/it]
INFO:root:final mean train loss: 3317.8802703119095
INFO:root:final train perplexity: 3.7024686336517334
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.52s/it]
INFO:root:eval mean loss: 4052.2867024739585
INFO:root:eval perplexity: 5.148090362548828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/142
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [18:09:10<7:47:08, 483.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3368.12607421875
INFO:root:current train perplexity3.688695192337036
INFO:root:current mean train loss 3342.3624421296295
INFO:root:current train perplexity3.6881439685821533
INFO:root:current mean train loss 3331.1983117935506
INFO:root:current train perplexity3.6902096271514893
INFO:root:current mean train loss 3329.0376406541513
INFO:root:current train perplexity3.692181348800659
INFO:root:current mean train loss 3322.921573051365
INFO:root:current train perplexity3.6954152584075928
INFO:root:current mean train loss 3326.4361405702393
INFO:root:current train perplexity3.698653221130371
INFO:root:current mean train loss 3322.7740738035186
INFO:root:current train perplexity3.6954054832458496
INFO:root:current mean train loss 3320.059792530293
INFO:root:current train perplexity3.6963775157928467
INFO:root:current mean train loss 3318.014597562687
INFO:root:current train perplexity3.698070764541626
INFO:root:current mean train loss 3318.8222630138703
INFO:root:current train perplexity3.7008776664733887

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.45s/it]
INFO:root:final mean train loss: 3317.8876659024145
INFO:root:final train perplexity: 3.702479600906372
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.18s/it]
INFO:root:eval mean loss: 4052.1758366578015
INFO:root:eval perplexity: 5.147859573364258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/143
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [18:16:33<7:27:43, 471.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3310.2957451398984
INFO:root:current train perplexity3.675513505935669
INFO:root:current mean train loss 3302.850340089598
INFO:root:current train perplexity3.674050807952881
INFO:root:current mean train loss 3302.451888221772
INFO:root:current train perplexity3.6787972450256348
INFO:root:current mean train loss 3307.8636962178844
INFO:root:current train perplexity3.6806771755218506
INFO:root:current mean train loss 3308.3414651082817
INFO:root:current train perplexity3.6831772327423096
INFO:root:current mean train loss 3310.452391678896
INFO:root:current train perplexity3.6865768432617188
INFO:root:current mean train loss 3313.661007894513
INFO:root:current train perplexity3.690209150314331
INFO:root:current mean train loss 3311.2012214917354
INFO:root:current train perplexity3.6912083625793457
INFO:root:current mean train loss 3313.551279377966
INFO:root:current train perplexity3.694031238555908
INFO:root:current mean train loss 3314.785816180491
INFO:root:current train perplexity3.6971018314361572

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.54s/it]
INFO:root:final mean train loss: 3314.2559952274446
INFO:root:final train perplexity: 3.6971781253814697
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.66s/it]
INFO:root:eval mean loss: 4054.877947002438
INFO:root:eval perplexity: 5.153487682342529
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/144
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [18:23:58<7:12:25, 463.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3314.794783049939
INFO:root:current train perplexity3.67010235786438
INFO:root:current mean train loss 3305.764941082885
INFO:root:current train perplexity3.679060220718384
INFO:root:current mean train loss 3306.669874214081
INFO:root:current train perplexity3.678408145904541
INFO:root:current mean train loss 3301.143625634348
INFO:root:current train perplexity3.677173137664795
INFO:root:current mean train loss 3305.236893816692
INFO:root:current train perplexity3.6795575618743896
INFO:root:current mean train loss 3307.5425123709733
INFO:root:current train perplexity3.6851892471313477
INFO:root:current mean train loss 3312.2818654143866
INFO:root:current train perplexity3.688990831375122
INFO:root:current mean train loss 3314.1448274046065
INFO:root:current train perplexity3.6915714740753174
INFO:root:current mean train loss 3313.5247373838683
INFO:root:current train perplexity3.6916086673736572
INFO:root:current mean train loss 3311.9596900980055
INFO:root:current train perplexity3.6915342807769775

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:42<00:00, 402.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:42<00:00, 402.99s/it]
INFO:root:final mean train loss: 3311.1861852830457
INFO:root:final train perplexity: 3.6927034854888916
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.32s/it]
INFO:root:eval mean loss: 4055.556775681516
INFO:root:eval perplexity: 5.15490198135376
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/145
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [18:32:14<7:13:42, 473.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3310.931210275424
INFO:root:current train perplexity3.670673370361328
INFO:root:current mean train loss 3306.4097570263366
INFO:root:current train perplexity3.675719738006592
INFO:root:current mean train loss 3302.033268166325
INFO:root:current train perplexity3.679108142852783
INFO:root:current mean train loss 3302.221042473668
INFO:root:current train perplexity3.680776834487915
INFO:root:current mean train loss 3305.3965061827685
INFO:root:current train perplexity3.682589054107666
INFO:root:current mean train loss 3306.7889716569766
INFO:root:current train perplexity3.6843950748443604
INFO:root:current mean train loss 3310.8082747741605
INFO:root:current train perplexity3.685654878616333
INFO:root:current mean train loss 3310.030435554595
INFO:root:current train perplexity3.686690330505371
INFO:root:current mean train loss 3310.7750637778304
INFO:root:current train perplexity3.687694549560547
INFO:root:current mean train loss 3309.90735054215
INFO:root:current train perplexity3.687629461288452

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:47<00:00, 407.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:47<00:00, 407.35s/it]
INFO:root:final mean train loss: 3308.195326466714
INFO:root:final train perplexity: 3.6883482933044434
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.36s/it]
INFO:root:eval mean loss: 4057.212655141844
INFO:root:eval perplexity: 5.15835428237915
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/146
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [18:39:45<6:59:56, 466.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3294.64112785681
INFO:root:current train perplexity3.665193557739258
INFO:root:current mean train loss 3316.4861556184505
INFO:root:current train perplexity3.6728272438049316
INFO:root:current mean train loss 3311.529572104693
INFO:root:current train perplexity3.6769347190856934
INFO:root:current mean train loss 3311.720228148416
INFO:root:current train perplexity3.673466920852661
INFO:root:current mean train loss 3307.722478503078
INFO:root:current train perplexity3.6739675998687744
INFO:root:current mean train loss 3304.9798564608136
INFO:root:current train perplexity3.675825834274292
INFO:root:current mean train loss 3305.80634267827
INFO:root:current train perplexity3.676576614379883
INFO:root:current mean train loss 3305.4530288716182
INFO:root:current train perplexity3.6762189865112305
INFO:root:current mean train loss 3306.6345150077495
INFO:root:current train perplexity3.6800343990325928
INFO:root:current mean train loss 3307.626403240531
INFO:root:current train perplexity3.6823689937591553

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:42<00:00, 402.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:42<00:00, 402.36s/it]
INFO:root:final mean train loss: 3304.582456404163
INFO:root:final train perplexity: 3.6830952167510986
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.56s/it]
INFO:root:eval mean loss: 4056.663849526263
INFO:root:eval perplexity: 5.157209396362305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/147
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [18:47:11<6:46:33, 460.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3284.951197916667
INFO:root:current train perplexity3.6598739624023438
INFO:root:current mean train loss 3300.7646833147323
INFO:root:current train perplexity3.6773674488067627
INFO:root:current mean train loss 3306.4568110795453
INFO:root:current train perplexity3.683274745941162
INFO:root:current mean train loss 3299.109632161458
INFO:root:current train perplexity3.675028085708618
INFO:root:current mean train loss 3299.60187448602
INFO:root:current train perplexity3.673602342605591
INFO:root:current mean train loss 3300.75485266644
INFO:root:current train perplexity3.6733453273773193
INFO:root:current mean train loss 3304.4218362991896
INFO:root:current train perplexity3.6764416694641113
INFO:root:current mean train loss 3304.6372996471773
INFO:root:current train perplexity3.6753900051116943
INFO:root:current mean train loss 3308.3598660714288
INFO:root:current train perplexity3.680363655090332
INFO:root:current mean train loss 3306.406360176282
INFO:root:current train perplexity3.6809208393096924

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:44<00:00, 404.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:44<00:00, 404.08s/it]
INFO:root:final mean train loss: 3303.6594859092465
INFO:root:final train perplexity: 3.6817541122436523
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.65s/it]
INFO:root:eval mean loss: 4056.6385575964096
INFO:root:eval perplexity: 5.157157897949219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/148
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [18:55:21<6:46:42, 469.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3303.484660320971
INFO:root:current train perplexity3.677206516265869
INFO:root:current mean train loss 3295.423673369194
INFO:root:current train perplexity3.673335552215576
INFO:root:current mean train loss 3296.0624007909123
INFO:root:current train perplexity3.6692399978637695
INFO:root:current mean train loss 3301.1368143664326
INFO:root:current train perplexity3.6726441383361816
INFO:root:current mean train loss 3301.778541201637
INFO:root:current train perplexity3.6723473072052
INFO:root:current mean train loss 3299.5272633469126
INFO:root:current train perplexity3.6733903884887695
INFO:root:current mean train loss 3299.820377199053
INFO:root:current train perplexity3.6730847358703613
INFO:root:current mean train loss 3299.3423827501397
INFO:root:current train perplexity3.6725964546203613
INFO:root:current mean train loss 3300.2911831779093
INFO:root:current train perplexity3.6741528511047363
INFO:root:current mean train loss 3301.930111455287
INFO:root:current train perplexity3.675408363342285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.33s/it]
INFO:root:final mean train loss: 3299.621894344207
INFO:root:final train perplexity: 3.675893783569336
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.09s/it]
INFO:root:eval mean loss: 4058.6998853751106
INFO:root:eval perplexity: 5.161457061767578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/149
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [19:05:27<7:13:36, 510.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3300.8506771548764
INFO:root:current train perplexity3.6679463386535645
INFO:root:current mean train loss 3293.130271392343
INFO:root:current train perplexity3.662203788757324
INFO:root:current mean train loss 3295.6205844944693
INFO:root:current train perplexity3.6674094200134277
INFO:root:current mean train loss 3296.262039691896
INFO:root:current train perplexity3.6666007041931152
INFO:root:current mean train loss 3295.9214414142057
INFO:root:current train perplexity3.6672565937042236
INFO:root:current mean train loss 3295.204303154082
INFO:root:current train perplexity3.667996644973755
INFO:root:current mean train loss 3298.766151439264
INFO:root:current train perplexity3.6705355644226074
INFO:root:current mean train loss 3298.8626509906367
INFO:root:current train perplexity3.6738572120666504
INFO:root:current mean train loss 3300.4883048146394
INFO:root:current train perplexity3.6745247840881348
INFO:root:current mean train loss 3302.2725079918487
INFO:root:current train perplexity3.6760427951812744

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.80s/it]
INFO:root:final mean train loss: 3299.712107504568
INFO:root:final train perplexity: 3.6760244369506836
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.17s/it]
INFO:root:eval mean loss: 4059.9747669409353
INFO:root:eval perplexity: 5.164119243621826
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/150
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [19:14:05<7:07:12, 512.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3294.414193201547
INFO:root:current train perplexity3.682692527770996
INFO:root:current mean train loss 3296.2242609532036
INFO:root:current train perplexity3.667726993560791
INFO:root:current mean train loss 3296.2534824741324
INFO:root:current train perplexity3.667412042617798
INFO:root:current mean train loss 3292.7188246495143
INFO:root:current train perplexity3.6634669303894043
INFO:root:current mean train loss 3294.529008211736
INFO:root:current train perplexity3.664391040802002
INFO:root:current mean train loss 3297.2763031973864
INFO:root:current train perplexity3.670733690261841
INFO:root:current mean train loss 3296.1888859084406
INFO:root:current train perplexity3.672091245651245
INFO:root:current mean train loss 3293.7753402079748
INFO:root:current train perplexity3.6707253456115723
INFO:root:current mean train loss 3297.361060629432
INFO:root:current train perplexity3.671257972717285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.65s/it]
INFO:root:final mean train loss: 3297.378535362982
INFO:root:final train perplexity: 3.6726415157318115
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.15s/it]
INFO:root:eval mean loss: 4060.0491120899824
INFO:root:eval perplexity: 5.164275169372559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/151
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [19:22:30<6:56:45, 510.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3277.1736188616073
INFO:root:current train perplexity3.6519172191619873
INFO:root:current mean train loss 3295.0410064982475
INFO:root:current train perplexity3.665471076965332
INFO:root:current mean train loss 3291.5280525834087
INFO:root:current train perplexity3.665248155593872
INFO:root:current mean train loss 3289.7132755242264
INFO:root:current train perplexity3.6684584617614746
INFO:root:current mean train loss 3290.355271397996
INFO:root:current train perplexity3.667729139328003
INFO:root:current mean train loss 3291.8441776072486
INFO:root:current train perplexity3.6642792224884033
INFO:root:current mean train loss 3291.8307208543556
INFO:root:current train perplexity3.665121555328369
INFO:root:current mean train loss 3297.3986460727547
INFO:root:current train perplexity3.6667940616607666
INFO:root:current mean train loss 3298.8421786661634
INFO:root:current train perplexity3.6688625812530518
INFO:root:current mean train loss 3301.7931593250414
INFO:root:current train perplexity3.6714863777160645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.83s/it]
INFO:root:final mean train loss: 3295.8976158019036
INFO:root:final train perplexity: 3.6704964637756348
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.04s/it]
INFO:root:eval mean loss: 4059.4313757064497
INFO:root:eval perplexity: 5.162985801696777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/152
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [19:31:25<6:54:04, 517.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3301.2530924479165
INFO:root:current train perplexity3.6491987705230713
INFO:root:current mean train loss 3289.5224397078805
INFO:root:current train perplexity3.655271053314209
INFO:root:current mean train loss 3289.7672999182414
INFO:root:current train perplexity3.6594228744506836
INFO:root:current mean train loss 3284.082884579613
INFO:root:current train perplexity3.656130313873291
INFO:root:current mean train loss 3290.1824412885917
INFO:root:current train perplexity3.6590352058410645
INFO:root:current mean train loss 3292.3210909056434
INFO:root:current train perplexity3.661940813064575
INFO:root:current mean train loss 3293.4338366996953
INFO:root:current train perplexity3.659360885620117
INFO:root:current mean train loss 3295.321255599869
INFO:root:current train perplexity3.6623926162719727
INFO:root:current mean train loss 3293.9664466904715
INFO:root:current train perplexity3.6637625694274902
INFO:root:current mean train loss 3294.241594625171
INFO:root:current train perplexity3.664780378341675

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.96s/it]
INFO:root:final mean train loss: 3292.032388994771
INFO:root:final train perplexity: 3.6649036407470703
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.39s/it]
INFO:root:eval mean loss: 4060.823100205009
INFO:root:eval perplexity: 5.165891647338867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/153
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [19:40:23<6:50:23, 523.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3247.694972826087
INFO:root:current train perplexity3.619626522064209
INFO:root:current mean train loss 3282.496351784807
INFO:root:current train perplexity3.6517510414123535
INFO:root:current mean train loss 3283.0564490348233
INFO:root:current train perplexity3.6477034091949463
INFO:root:current mean train loss 3282.5976524707335
INFO:root:current train perplexity3.646235227584839
INFO:root:current mean train loss 3285.311125771092
INFO:root:current train perplexity3.652190685272217
INFO:root:current mean train loss 3288.375495750179
INFO:root:current train perplexity3.6542563438415527
INFO:root:current mean train loss 3288.291375761813
INFO:root:current train perplexity3.6573452949523926
INFO:root:current mean train loss 3291.95620495386
INFO:root:current train perplexity3.661320209503174
INFO:root:current mean train loss 3294.653153596788
INFO:root:current train perplexity3.6621556282043457
INFO:root:current mean train loss 3294.6791320337893
INFO:root:current train perplexity3.663452386856079

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:30<00:00, 390.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:30<00:00, 390.74s/it]
INFO:root:final mean train loss: 3292.029786632907
INFO:root:final train perplexity: 3.6648995876312256
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.40s/it]
INFO:root:eval mean loss: 4061.158092309397
INFO:root:eval perplexity: 5.166590690612793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/154
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [19:47:37<6:20:58, 496.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3317.301332535282
INFO:root:current train perplexity3.693734884262085
INFO:root:current mean train loss 3283.2524153148856
INFO:root:current train perplexity3.6567912101745605
INFO:root:current mean train loss 3281.9330610795455
INFO:root:current train perplexity3.6478896141052246
INFO:root:current mean train loss 3284.76744904763
INFO:root:current train perplexity3.6531856060028076
INFO:root:current mean train loss 3282.629691351871
INFO:root:current train perplexity3.657371997833252
INFO:root:current mean train loss 3281.9182280632062
INFO:root:current train perplexity3.6565091609954834
INFO:root:current mean train loss 3286.4816631432004
INFO:root:current train perplexity3.660512924194336
INFO:root:current mean train loss 3289.3244732440576
INFO:root:current train perplexity3.663083076477051
INFO:root:current mean train loss 3291.9710918109768
INFO:root:current train perplexity3.6605310440063477
INFO:root:current mean train loss 3290.008914672983
INFO:root:current train perplexity3.6593711376190186

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.42s/it]
INFO:root:final mean train loss: 3287.9360563831947
INFO:root:final train perplexity: 3.6589853763580322
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.48s/it]
INFO:root:eval mean loss: 4064.2220900515294
INFO:root:eval perplexity: 5.1729960441589355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/155
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [19:56:25<6:19:42, 506.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3330.7748021834936
INFO:root:current train perplexity3.6649703979492188
INFO:root:current mean train loss 3287.168537825989
INFO:root:current train perplexity3.644340991973877
INFO:root:current mean train loss 3290.0362114686845
INFO:root:current train perplexity3.651571750640869
INFO:root:current mean train loss 3286.8582363972623
INFO:root:current train perplexity3.654362201690674
INFO:root:current mean train loss 3283.5119462067555
INFO:root:current train perplexity3.6577093601226807
INFO:root:current mean train loss 3285.49214084604
INFO:root:current train perplexity3.656000852584839
INFO:root:current mean train loss 3286.183468814187
INFO:root:current train perplexity3.655280590057373
INFO:root:current mean train loss 3288.1016018135783
INFO:root:current train perplexity3.6554384231567383
INFO:root:current mean train loss 3288.2856355105596
INFO:root:current train perplexity3.6536834239959717
INFO:root:current mean train loss 3289.8436267596844
INFO:root:current train perplexity3.6579577922821045

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.57s/it]
INFO:root:final mean train loss: 3287.3699721674766
INFO:root:final train perplexity: 3.6581685543060303
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.36s/it]
INFO:root:eval mean loss: 4063.72476001496
INFO:root:eval perplexity: 5.171955108642578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/156
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [20:05:09<6:15:07, 511.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3275.6715529421544
INFO:root:current train perplexity3.602606773376465
INFO:root:current mean train loss 3290.094479100234
INFO:root:current train perplexity3.637089729309082
INFO:root:current mean train loss 3278.467888094636
INFO:root:current train perplexity3.635496139526367
INFO:root:current mean train loss 3280.0361236660215
INFO:root:current train perplexity3.6384024620056152
INFO:root:current mean train loss 3281.6759429180647
INFO:root:current train perplexity3.642540693283081
INFO:root:current mean train loss 3277.5655162748517
INFO:root:current train perplexity3.6423285007476807
INFO:root:current mean train loss 3277.5591748575152
INFO:root:current train perplexity3.6436898708343506
INFO:root:current mean train loss 3281.2244531511465
INFO:root:current train perplexity3.6466925144195557
INFO:root:current mean train loss 3284.9106477019077
INFO:root:current train perplexity3.649467706680298
INFO:root:current mean train loss 3286.2639358665524
INFO:root:current train perplexity3.6515860557556152

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.86s/it]
INFO:root:final mean train loss: 3283.8325731831214
INFO:root:final train perplexity: 3.653066396713257
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.52s/it]
INFO:root:eval mean loss: 4064.89794921875
INFO:root:eval perplexity: 5.174410343170166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/157
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [20:13:53<6:09:19, 515.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3259.998770419034
INFO:root:current train perplexity3.6642916202545166
INFO:root:current mean train loss 3257.024601499496
INFO:root:current train perplexity3.6428678035736084
INFO:root:current mean train loss 3269.519891237745
INFO:root:current train perplexity3.6444897651672363
INFO:root:current mean train loss 3276.6407082141286
INFO:root:current train perplexity3.650552272796631
INFO:root:current mean train loss 3278.0864182692308
INFO:root:current train perplexity3.6502089500427246
INFO:root:current mean train loss 3280.9679810670045
INFO:root:current train perplexity3.6489667892456055
INFO:root:current mean train loss 3285.2996354663646
INFO:root:current train perplexity3.652782917022705
INFO:root:current mean train loss 3285.735030460989
INFO:root:current train perplexity3.6528494358062744
INFO:root:current mean train loss 3287.4107753106723
INFO:root:current train perplexity3.6545917987823486
INFO:root:current mean train loss 3286.299854793848
INFO:root:current train perplexity3.6525821685791016

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.71s/it]
INFO:root:final mean train loss: 3283.201264535227
INFO:root:final train perplexity: 3.6521568298339844
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.22s/it]
INFO:root:eval mean loss: 4064.5167054521276
INFO:root:eval perplexity: 5.17361307144165
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/158
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [20:22:40<6:03:07, 518.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3306.2027878534227
INFO:root:current train perplexity3.6587271690368652
INFO:root:current mean train loss 3293.018487286714
INFO:root:current train perplexity3.6437489986419678
INFO:root:current mean train loss 3287.507992588522
INFO:root:current train perplexity3.64172101020813
INFO:root:current mean train loss 3279.7339997094523
INFO:root:current train perplexity3.6441855430603027
INFO:root:current mean train loss 3282.6053759449246
INFO:root:current train perplexity3.6506190299987793
INFO:root:current mean train loss 3283.4059755044127
INFO:root:current train perplexity3.6492931842803955
INFO:root:current mean train loss 3281.3620439762444
INFO:root:current train perplexity3.651043653488159
INFO:root:current mean train loss 3285.155831473214
INFO:root:current train perplexity3.650418281555176
INFO:root:current mean train loss 3283.0914257133545
INFO:root:current train perplexity3.6489756107330322
INFO:root:current mean train loss 3283.040464977609
INFO:root:current train perplexity3.648073434829712

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.99s/it]
INFO:root:final mean train loss: 3280.6044552095473
INFO:root:final train perplexity: 3.648416757583618
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.12s/it]
INFO:root:eval mean loss: 4065.789256427305
INFO:root:eval perplexity: 5.176276206970215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/159
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [20:31:38<5:58:23, 524.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3276.6923690580984
INFO:root:current train perplexity3.640997886657715
INFO:root:current mean train loss 3267.1993900767543
INFO:root:current train perplexity3.6259734630584717
INFO:root:current mean train loss 3268.7996938782862
INFO:root:current train perplexity3.627448558807373
INFO:root:current mean train loss 3265.4072489365735
INFO:root:current train perplexity3.632702350616455
INFO:root:current mean train loss 3271.678452283207
INFO:root:current train perplexity3.6369118690490723
INFO:root:current mean train loss 3272.221961454001
INFO:root:current train perplexity3.6393930912017822
INFO:root:current mean train loss 3275.063255344169
INFO:root:current train perplexity3.638317346572876
INFO:root:current mean train loss 3277.331124034837
INFO:root:current train perplexity3.639741897583008
INFO:root:current mean train loss 3279.053536311083
INFO:root:current train perplexity3.643937587738037
INFO:root:current mean train loss 3279.4526709135234
INFO:root:current train perplexity3.6441073417663574

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:42<00:00, 402.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:42<00:00, 402.36s/it]
INFO:root:final mean train loss: 3277.4340281332693
INFO:root:final train perplexity: 3.6438562870025635
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.37s/it]
INFO:root:eval mean loss: 4066.4525657275044
INFO:root:eval perplexity: 5.177664756774902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/160
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [20:40:56<5:56:24, 534.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3270.751248516614
INFO:root:current train perplexity3.622990369796753
INFO:root:current mean train loss 3268.3309210239177
INFO:root:current train perplexity3.6396291255950928
INFO:root:current mean train loss 3274.342330659162
INFO:root:current train perplexity3.6419389247894287
INFO:root:current mean train loss 3280.8596713184365
INFO:root:current train perplexity3.6414687633514404
INFO:root:current mean train loss 3278.763069933292
INFO:root:current train perplexity3.6401429176330566
INFO:root:current mean train loss 3280.313976228546
INFO:root:current train perplexity3.6403238773345947
INFO:root:current mean train loss 3276.456051091909
INFO:root:current train perplexity3.6411871910095215
INFO:root:current mean train loss 3278.092360999679
INFO:root:current train perplexity3.642218589782715
INFO:root:current mean train loss 3277.072893058074
INFO:root:current train perplexity3.643265962600708
INFO:root:current mean train loss 3278.897249714712
INFO:root:current train perplexity3.643475294113159

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.34s/it]
INFO:root:final mean train loss: 3277.0236217129614
INFO:root:final train perplexity: 3.643266439437866
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.23s/it]
INFO:root:eval mean loss: 4067.731216755319
INFO:root:eval perplexity: 5.180342197418213
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/161
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [20:49:17<5:40:51, 524.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3272.2698034527657
INFO:root:current train perplexity3.620922565460205
INFO:root:current mean train loss 3266.6660378196025
INFO:root:current train perplexity3.621814012527466
INFO:root:current mean train loss 3271.8714935621733
INFO:root:current train perplexity3.6243069171905518
INFO:root:current mean train loss 3276.1027396741765
INFO:root:current train perplexity3.6315460205078125
INFO:root:current mean train loss 3272.888580635588
INFO:root:current train perplexity3.630906105041504
INFO:root:current mean train loss 3274.497972010754
INFO:root:current train perplexity3.631103515625
INFO:root:current mean train loss 3273.263294825214
INFO:root:current train perplexity3.631389617919922
INFO:root:current mean train loss 3274.2039929866187
INFO:root:current train perplexity3.633384943008423
INFO:root:current mean train loss 3274.602003714681
INFO:root:current train perplexity3.6356427669525146
INFO:root:current mean train loss 3277.1790357162645
INFO:root:current train perplexity3.639925479888916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:46<00:00, 406.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:46<00:00, 406.51s/it]
INFO:root:final mean train loss: 3274.393676511703
INFO:root:final train perplexity: 3.6394882202148438
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.60s/it]
INFO:root:eval mean loss: 4067.586929645944
INFO:root:eval perplexity: 5.180039405822754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/162
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [20:58:07<5:33:20, 526.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3268.6237253289473
INFO:root:current train perplexity3.6346685886383057
INFO:root:current mean train loss 3280.235718399439
INFO:root:current train perplexity3.6467056274414062
INFO:root:current mean train loss 3276.185744670286
INFO:root:current train perplexity3.6364026069641113
INFO:root:current mean train loss 3279.5977545243277
INFO:root:current train perplexity3.633953332901001
INFO:root:current mean train loss 3280.7035624802716
INFO:root:current train perplexity3.636448860168457
INFO:root:current mean train loss 3279.099707851891
INFO:root:current train perplexity3.635087251663208
INFO:root:current mean train loss 3277.835603782599
INFO:root:current train perplexity3.6334681510925293
INFO:root:current mean train loss 3275.4299592791863
INFO:root:current train perplexity3.634305000305176
INFO:root:current mean train loss 3276.5359486840957
INFO:root:current train perplexity3.63680100440979

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:43<00:00, 403.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:43<00:00, 403.17s/it]
INFO:root:final mean train loss: 3273.3085282233455
INFO:root:final train perplexity: 3.637930154800415
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.70s/it]
INFO:root:eval mean loss: 4067.492989181627
INFO:root:eval perplexity: 5.179842472076416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/163
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [21:06:13<5:17:02, 514.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3288.4090983072915
INFO:root:current train perplexity3.637366771697998
INFO:root:current mean train loss 3243.9649693757583
INFO:root:current train perplexity3.62955641746521
INFO:root:current mean train loss 3266.4632418026476
INFO:root:current train perplexity3.6398403644561768
INFO:root:current mean train loss 3265.375816219317
INFO:root:current train perplexity3.637441873550415
INFO:root:current mean train loss 3265.496832229955
INFO:root:current train perplexity3.6397275924682617
INFO:root:current mean train loss 3267.6842315249132
INFO:root:current train perplexity3.6386594772338867
INFO:root:current mean train loss 3269.6654828073174
INFO:root:current train perplexity3.635495901107788
INFO:root:current mean train loss 3268.91093555521
INFO:root:current train perplexity3.632175922393799
INFO:root:current mean train loss 3268.909056249027
INFO:root:current train perplexity3.632345676422119
INFO:root:current mean train loss 3273.400288696965
INFO:root:current train perplexity3.6343994140625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.74s/it]
INFO:root:final mean train loss: 3270.9717081131475
INFO:root:final train perplexity: 3.6345770359039307
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.34s/it]
INFO:root:eval mean loss: 4068.604703429743
INFO:root:eval perplexity: 5.182171821594238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/164
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [21:14:53<5:09:33, 515.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3283.2837357954545
INFO:root:current train perplexity3.6139957904815674
INFO:root:current mean train loss 3271.900221266188
INFO:root:current train perplexity3.617795467376709
INFO:root:current mean train loss 3275.876830476155
INFO:root:current train perplexity3.6270666122436523
INFO:root:current mean train loss 3275.4532804335813
INFO:root:current train perplexity3.634232759475708
INFO:root:current mean train loss 3281.0009331993233
INFO:root:current train perplexity3.6418447494506836
INFO:root:current mean train loss 3277.2037642566656
INFO:root:current train perplexity3.6415648460388184
INFO:root:current mean train loss 3274.1190443273067
INFO:root:current train perplexity3.637517213821411
INFO:root:current mean train loss 3272.371473180929
INFO:root:current train perplexity3.63550066947937
INFO:root:current mean train loss 3272.990479719771
INFO:root:current train perplexity3.6342577934265137
INFO:root:current mean train loss 3272.845882143592
INFO:root:current train perplexity3.6338164806365967

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.00s/it]
INFO:root:final mean train loss: 3269.0979337999897
INFO:root:final train perplexity: 3.6318917274475098
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.03s/it]
INFO:root:eval mean loss: 4068.539803579344
INFO:root:eval perplexity: 5.182036399841309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/165
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [21:22:31<4:50:47, 498.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3280.4306383634867
INFO:root:current train perplexity3.6358377933502197
INFO:root:current mean train loss 3265.8602736016283
INFO:root:current train perplexity3.6247408390045166
INFO:root:current mean train loss 3272.1717991937785
INFO:root:current train perplexity3.6352202892303467
INFO:root:current mean train loss 3271.381999718358
INFO:root:current train perplexity3.629647970199585
INFO:root:current mean train loss 3269.3610944725165
INFO:root:current train perplexity3.6307213306427
INFO:root:current mean train loss 3267.057230513909
INFO:root:current train perplexity3.629807710647583
INFO:root:current mean train loss 3269.6215634939167
INFO:root:current train perplexity3.6304421424865723
INFO:root:current mean train loss 3272.0798764288506
INFO:root:current train perplexity3.630769729614258
INFO:root:current mean train loss 3272.3670605111033
INFO:root:current train perplexity3.6326253414154053
INFO:root:current mean train loss 3270.3446171109904
INFO:root:current train perplexity3.629298448562622

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.05s/it]
INFO:root:final mean train loss: 3267.2344383731966
INFO:root:final train perplexity: 3.629223108291626
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.57s/it]
INFO:root:eval mean loss: 4069.73626405973
INFO:root:eval perplexity: 5.184543609619141
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/166
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [21:31:27<4:48:49, 509.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3261.1894079137733
INFO:root:current train perplexity3.632542610168457
INFO:root:current mean train loss 3264.7505517193654
INFO:root:current train perplexity3.6176517009735107
INFO:root:current mean train loss 3269.7693269032216
INFO:root:current train perplexity3.6269023418426514
INFO:root:current mean train loss 3264.832173105409
INFO:root:current train perplexity3.6236987113952637
INFO:root:current mean train loss 3266.5439538888686
INFO:root:current train perplexity3.621692657470703
INFO:root:current mean train loss 3270.5633839095112
INFO:root:current train perplexity3.6227481365203857
INFO:root:current mean train loss 3269.799408299691
INFO:root:current train perplexity3.6236913204193115
INFO:root:current mean train loss 3270.7599113705724
INFO:root:current train perplexity3.625459909439087
INFO:root:current mean train loss 3268.320642842635
INFO:root:current train perplexity3.6265807151794434
INFO:root:current mean train loss 3269.0639345566174
INFO:root:current train perplexity3.628011703491211

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.16s/it]
INFO:root:final mean train loss: 3266.204070245066
INFO:root:final train perplexity: 3.6277472972869873
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.68s/it]
INFO:root:eval mean loss: 4070.1816614029253
INFO:root:eval perplexity: 5.1854777336120605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/167
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [21:40:11<4:42:40, 513.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3303.7136648995534
INFO:root:current train perplexity3.6315133571624756
INFO:root:current mean train loss 3267.6330258969906
INFO:root:current train perplexity3.626150131225586
INFO:root:current mean train loss 3257.7776907413563
INFO:root:current train perplexity3.6201388835906982
INFO:root:current mean train loss 3261.588634707323
INFO:root:current train perplexity3.617908000946045
INFO:root:current mean train loss 3264.700019082256
INFO:root:current train perplexity3.621217966079712
INFO:root:current mean train loss 3268.4627327321846
INFO:root:current train perplexity3.622741937637329
INFO:root:current mean train loss 3268.3245124876967
INFO:root:current train perplexity3.6255009174346924
INFO:root:current mean train loss 3269.4394866735756
INFO:root:current train perplexity3.624741792678833
INFO:root:current mean train loss 3269.219991754772
INFO:root:current train perplexity3.6246957778930664
INFO:root:current mean train loss 3268.2386927640373
INFO:root:current train perplexity3.625746488571167

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.71s/it]
INFO:root:final mean train loss: 3265.266303954586
INFO:root:final train perplexity: 3.626406192779541
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.05s/it]
INFO:root:eval mean loss: 4070.5633536264404
INFO:root:eval perplexity: 5.186278820037842
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/168
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [21:49:04<4:37:12, 519.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3278.6872161155525
INFO:root:current train perplexity3.6113200187683105
INFO:root:current mean train loss 3286.652640816215
INFO:root:current train perplexity3.6383590698242188
INFO:root:current mean train loss 3269.6270375192903
INFO:root:current train perplexity3.631671905517578
INFO:root:current mean train loss 3263.1551773471665
INFO:root:current train perplexity3.6231250762939453
INFO:root:current mean train loss 3264.6881613290066
INFO:root:current train perplexity3.624427080154419
INFO:root:current mean train loss 3261.835997298717
INFO:root:current train perplexity3.6187403202056885
INFO:root:current mean train loss 3266.0481515175447
INFO:root:current train perplexity3.6192679405212402
INFO:root:current mean train loss 3267.746028361057
INFO:root:current train perplexity3.624309539794922
INFO:root:current mean train loss 3269.1993615273764
INFO:root:current train perplexity3.625535011291504
INFO:root:current mean train loss 3267.068230443896
INFO:root:current train perplexity3.624528646469116

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.49s/it]
INFO:root:final mean train loss: 3263.639918604205
INFO:root:final train perplexity: 3.624079704284668
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.40s/it]
INFO:root:eval mean loss: 4070.936246398493
INFO:root:eval perplexity: 5.1870598793029785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/169
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [21:56:54<4:20:46, 504.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3276.2609576056984
INFO:root:current train perplexity3.6156184673309326
INFO:root:current mean train loss 3258.0681411035803
INFO:root:current train perplexity3.60919189453125
INFO:root:current mean train loss 3262.1192884711154
INFO:root:current train perplexity3.6227035522460938
INFO:root:current mean train loss 3259.3671040331196
INFO:root:current train perplexity3.617769479751587
INFO:root:current mean train loss 3254.3630652586266
INFO:root:current train perplexity3.6135008335113525
INFO:root:current mean train loss 3254.9064046371655
INFO:root:current train perplexity3.614945888519287
INFO:root:current mean train loss 3259.3191739271315
INFO:root:current train perplexity3.6178057193756104
INFO:root:current mean train loss 3262.218667752892
INFO:root:current train perplexity3.6208877563476562
INFO:root:current mean train loss 3263.303383886604
INFO:root:current train perplexity3.6197383403778076
INFO:root:current mean train loss 3264.250662850782
INFO:root:current train perplexity3.62119460105896

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:33<00:00, 393.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:33<00:00, 393.03s/it]
INFO:root:final mean train loss: 3262.3844869675177
INFO:root:final train perplexity: 3.6222851276397705
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.80s/it]
INFO:root:eval mean loss: 4071.2978723404253
INFO:root:eval perplexity: 5.18781852722168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/170
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [22:06:47<4:25:41, 531.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3250.289650092691
INFO:root:current train perplexity3.6127731800079346
INFO:root:current mean train loss 3242.4063022061714
INFO:root:current train perplexity3.5955734252929688
INFO:root:current mean train loss 3242.625541068412
INFO:root:current train perplexity3.6048803329467773
INFO:root:current mean train loss 3252.6766075198034
INFO:root:current train perplexity3.6153552532196045
INFO:root:current mean train loss 3251.37489734392
INFO:root:current train perplexity3.6121625900268555
INFO:root:current mean train loss 3254.779361513305
INFO:root:current train perplexity3.6164512634277344
INFO:root:current mean train loss 3259.0238672467754
INFO:root:current train perplexity3.619047164916992
INFO:root:current mean train loss 3260.858590147398
INFO:root:current train perplexity3.619215488433838
INFO:root:current mean train loss 3261.888671022355
INFO:root:current train perplexity3.6201367378234863
INFO:root:current mean train loss 3261.371356729422
INFO:root:current train perplexity3.6185355186462402

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:35<00:00, 395.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:35<00:00, 395.77s/it]
INFO:root:final mean train loss: 3260.013282468242
INFO:root:final train perplexity: 3.618898391723633
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.22s/it]
INFO:root:eval mean loss: 4070.935700977948
INFO:root:eval perplexity: 5.18705940246582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/171
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [22:17:11<4:30:16, 559.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3285.9543129081158
INFO:root:current train perplexity3.6068789958953857
INFO:root:current mean train loss 3272.586571973241
INFO:root:current train perplexity3.620171546936035
INFO:root:current mean train loss 3265.1864996635068
INFO:root:current train perplexity3.62532901763916
INFO:root:current mean train loss 3263.5448673258684
INFO:root:current train perplexity3.6241610050201416
INFO:root:current mean train loss 3256.331452526934
INFO:root:current train perplexity3.619549036026001
INFO:root:current mean train loss 3254.568187141755
INFO:root:current train perplexity3.6151185035705566
INFO:root:current mean train loss 3254.7435886548915
INFO:root:current train perplexity3.6151771545410156
INFO:root:current mean train loss 3258.111673486901
INFO:root:current train perplexity3.617082118988037
INFO:root:current mean train loss 3260.722236114115
INFO:root:current train perplexity3.6171553134918213
INFO:root:current mean train loss 3261.013435056069
INFO:root:current train perplexity3.617314100265503

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.53s/it]
INFO:root:final mean train loss: 3258.691060404624
INFO:root:final train perplexity: 3.6170105934143066
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.19s/it]
INFO:root:eval mean loss: 4072.8944654532356
INFO:root:eval perplexity: 5.191169261932373
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/172
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [22:26:26<4:20:18, 557.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3250.1927604166667
INFO:root:current train perplexity3.622204303741455
INFO:root:current mean train loss 3252.0926353236605
INFO:root:current train perplexity3.6127078533172607
INFO:root:current mean train loss 3264.038514737216
INFO:root:current train perplexity3.6193349361419678
INFO:root:current mean train loss 3259.3643743489583
INFO:root:current train perplexity3.6150996685028076
INFO:root:current mean train loss 3260.393728926809
INFO:root:current train perplexity3.616661310195923
INFO:root:current mean train loss 3261.2997826086958
INFO:root:current train perplexity3.6160483360290527
INFO:root:current mean train loss 3259.021306061921
INFO:root:current train perplexity3.6163902282714844
INFO:root:current mean train loss 3260.4008206275203
INFO:root:current train perplexity3.616889476776123
INFO:root:current mean train loss 3262.6394478236607
INFO:root:current train perplexity3.617882013320923
INFO:root:current mean train loss 3262.0425345552885
INFO:root:current train perplexity3.6174585819244385

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.67s/it]
INFO:root:final mean train loss: 3259.092073994298
INFO:root:final train perplexity: 3.6175827980041504
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.40s/it]
INFO:root:eval mean loss: 4073.121699772828
INFO:root:eval perplexity: 5.191645622253418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/173
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [22:34:20<3:59:41, 532.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3253.8721762048194
INFO:root:current train perplexity3.624898910522461
INFO:root:current mean train loss 3262.8721783747437
INFO:root:current train perplexity3.6139447689056396
INFO:root:current mean train loss 3258.6272611045165
INFO:root:current train perplexity3.6137280464172363
INFO:root:current mean train loss 3259.389791224706
INFO:root:current train perplexity3.6092119216918945
INFO:root:current mean train loss 3266.2632998511904
INFO:root:current train perplexity3.6134252548217773
INFO:root:current mean train loss 3259.8460959275835
INFO:root:current train perplexity3.6114397048950195
INFO:root:current mean train loss 3257.505926218773
INFO:root:current train perplexity3.6097068786621094
INFO:root:current mean train loss 3258.5009509947718
INFO:root:current train perplexity3.6109535694122314
INFO:root:current mean train loss 3260.06966247213
INFO:root:current train perplexity3.613039016723633
INFO:root:current mean train loss 3257.998141501224
INFO:root:current train perplexity3.6123106479644775

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:42<00:00, 402.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:42<00:00, 402.72s/it]
INFO:root:final mean train loss: 3255.4563531567974
INFO:root:final train perplexity: 3.612398147583008
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.39s/it]
INFO:root:eval mean loss: 4075.0344203651375
INFO:root:eval perplexity: 5.195663928985596
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/174
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [22:43:20<3:51:43, 534.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3235.5528738839284
INFO:root:current train perplexity3.598233699798584
INFO:root:current mean train loss 3240.683676834506
INFO:root:current train perplexity3.598219156265259
INFO:root:current mean train loss 3248.8294002362545
INFO:root:current train perplexity3.6032750606536865
INFO:root:current mean train loss 3253.9518075147857
INFO:root:current train perplexity3.606998920440674
INFO:root:current mean train loss 3249.4574817416624
INFO:root:current train perplexity3.601018190383911
INFO:root:current mean train loss 3251.5639718664074
INFO:root:current train perplexity3.602053165435791
INFO:root:current mean train loss 3253.8713976008503
INFO:root:current train perplexity3.6046459674835205
INFO:root:current mean train loss 3254.139168489748
INFO:root:current train perplexity3.6055514812469482
INFO:root:current mean train loss 3257.4416783393835
INFO:root:current train perplexity3.6098556518554688
INFO:root:current mean train loss 3257.4888803922804
INFO:root:current train perplexity3.6116786003112793

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.48s/it]
INFO:root:final mean train loss: 3254.9065304417763
INFO:root:final train perplexity: 3.6116139888763428
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.31s/it]
INFO:root:eval mean loss: 4075.1261981937055
INFO:root:eval perplexity: 5.19585657119751
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/175
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [22:52:31<3:44:51, 539.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3248.893061474116
INFO:root:current train perplexity3.6107358932495117
INFO:root:current mean train loss 3247.789444046404
INFO:root:current train perplexity3.600069522857666
INFO:root:current mean train loss 3248.8022256806544
INFO:root:current train perplexity3.6010563373565674
INFO:root:current mean train loss 3250.294539449209
INFO:root:current train perplexity3.602471113204956
INFO:root:current mean train loss 3251.3900207641846
INFO:root:current train perplexity3.603707790374756
INFO:root:current mean train loss 3253.3519170948975
INFO:root:current train perplexity3.607982635498047
INFO:root:current mean train loss 3255.1242427798643
INFO:root:current train perplexity3.60752272605896
INFO:root:current mean train loss 3253.2039234223444
INFO:root:current train perplexity3.606189012527466
INFO:root:current mean train loss 3253.6648793798663
INFO:root:current train perplexity3.6070780754089355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.48s/it]
INFO:root:final mean train loss: 3253.7661044828355
INFO:root:final train perplexity: 3.609989643096924
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.69s/it]
INFO:root:eval mean loss: 4074.732136178524
INFO:root:eval perplexity: 5.195028305053711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/176
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [23:02:06<3:40:07, 550.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3229.3481794084823
INFO:root:current train perplexity3.505225896835327
INFO:root:current mean train loss 3267.829594407126
INFO:root:current train perplexity3.6067910194396973
INFO:root:current mean train loss 3259.033936726298
INFO:root:current train perplexity3.6018192768096924
INFO:root:current mean train loss 3254.238802931596
INFO:root:current train perplexity3.601489543914795
INFO:root:current mean train loss 3255.7631703969596
INFO:root:current train perplexity3.600299596786499
INFO:root:current mean train loss 3252.0379010262573
INFO:root:current train perplexity3.599433660507202
INFO:root:current mean train loss 3250.77784651076
INFO:root:current train perplexity3.6011528968811035
INFO:root:current mean train loss 3252.6138334152893
INFO:root:current train perplexity3.6056861877441406
INFO:root:current mean train loss 3253.983477700008
INFO:root:current train perplexity3.60728120803833
INFO:root:current mean train loss 3256.556359338392
INFO:root:current train perplexity3.6109514236450195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.18s/it]
INFO:root:final mean train loss: 3253.7313239189884
INFO:root:final train perplexity: 3.6099395751953125
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.59s/it]
INFO:root:eval mean loss: 4076.06620539672
INFO:root:eval perplexity: 5.197832107543945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/177
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [23:12:04<3:36:27, 564.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3241.4972005208333
INFO:root:current train perplexity3.5469138622283936
INFO:root:current mean train loss 3244.962697435462
INFO:root:current train perplexity3.5793707370758057
INFO:root:current mean train loss 3248.2896189135176
INFO:root:current train perplexity3.6039586067199707
INFO:root:current mean train loss 3245.6475027901784
INFO:root:current train perplexity3.604428291320801
INFO:root:current mean train loss 3248.851143637048
INFO:root:current train perplexity3.6018481254577637
INFO:root:current mean train loss 3247.999484223301
INFO:root:current train perplexity3.5995006561279297
INFO:root:current mean train loss 3251.0632681497714
INFO:root:current train perplexity3.6008493900299072
INFO:root:current mean train loss 3254.0916859019885
INFO:root:current train perplexity3.6041419506073
INFO:root:current mean train loss 3254.4336944018405
INFO:root:current train perplexity3.604602575302124
INFO:root:current mean train loss 3253.332154521004
INFO:root:current train perplexity3.606180429458618

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:42<00:00, 402.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:42<00:00, 402.41s/it]
INFO:root:final mean train loss: 3251.2040979939125
INFO:root:final train perplexity: 3.606342077255249
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.71s/it]
INFO:root:eval mean loss: 4075.8926387272827
INFO:root:eval perplexity: 5.197465896606445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/178
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [23:19:52<3:16:22, 535.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3265.6301481827445
INFO:root:current train perplexity3.5965847969055176
INFO:root:current mean train loss 3266.5758165809198
INFO:root:current train perplexity3.60058331489563
INFO:root:current mean train loss 3260.598009870726
INFO:root:current train perplexity3.5965209007263184
INFO:root:current mean train loss 3262.3259383163218
INFO:root:current train perplexity3.601825714111328
INFO:root:current mean train loss 3264.323432074653
INFO:root:current train perplexity3.605135917663574
INFO:root:current mean train loss 3258.552575193445
INFO:root:current train perplexity3.6051690578460693
INFO:root:current mean train loss 3256.9317213520767
INFO:root:current train perplexity3.604259729385376
INFO:root:current mean train loss 3253.5619627555543
INFO:root:current train perplexity3.6047022342681885
INFO:root:current mean train loss 3251.7309131274683
INFO:root:current train perplexity3.602865695953369
INFO:root:current mean train loss 3252.3504259103297
INFO:root:current train perplexity3.606081008911133

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.53s/it]
INFO:root:final mean train loss: 3251.036190217541
INFO:root:final train perplexity: 3.6061038970947266
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.80s/it]
INFO:root:eval mean loss: 4075.362718514517
INFO:root:eval perplexity: 5.196353912353516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/179
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [23:30:06<3:15:40, 559.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3236.9540070564517
INFO:root:current train perplexity3.6060070991516113
INFO:root:current mean train loss 3244.5391519561067
INFO:root:current train perplexity3.6003639698028564
INFO:root:current mean train loss 3241.2333244554925
INFO:root:current train perplexity3.6041548252105713
INFO:root:current mean train loss 3241.8814759960346
INFO:root:current train perplexity3.6035499572753906
INFO:root:current mean train loss 3244.9820548143853
INFO:root:current train perplexity3.6029281616210938
INFO:root:current mean train loss 3247.038899279808
INFO:root:current train perplexity3.600303888320923
INFO:root:current mean train loss 3249.30057541353
INFO:root:current train perplexity3.603686571121216
INFO:root:current mean train loss 3252.1262864975206
INFO:root:current train perplexity3.606127977371216
INFO:root:current mean train loss 3252.6031592560735
INFO:root:current train perplexity3.604740619659424
INFO:root:current mean train loss 3250.9888586910915
INFO:root:current train perplexity3.603001832962036

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.42s/it]
INFO:root:final mean train loss: 3250.4394909643356
INFO:root:final train perplexity: 3.605254650115967
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.75s/it]
INFO:root:eval mean loss: 4075.70029573914
INFO:root:eval perplexity: 5.1970624923706055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/180
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [23:39:39<3:07:48, 563.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3260.2035444210737
INFO:root:current train perplexity3.6246936321258545
INFO:root:current mean train loss 3244.999174488534
INFO:root:current train perplexity3.604114532470703
INFO:root:current mean train loss 3240.41418201654
INFO:root:current train perplexity3.596571922302246
INFO:root:current mean train loss 3246.3437694448285
INFO:root:current train perplexity3.596066474914551
INFO:root:current mean train loss 3245.6206549642297
INFO:root:current train perplexity3.5977625846862793
INFO:root:current mean train loss 3245.3771266052586
INFO:root:current train perplexity3.596508502960205
INFO:root:current mean train loss 3244.1514470394413
INFO:root:current train perplexity3.5946662425994873
INFO:root:current mean train loss 3247.2277673455474
INFO:root:current train perplexity3.597039222717285
INFO:root:current mean train loss 3249.6123614305534
INFO:root:current train perplexity3.600924015045166
INFO:root:current mean train loss 3249.80534374168
INFO:root:current train perplexity3.6001875400543213

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.96s/it]
INFO:root:final mean train loss: 3247.611794748614
INFO:root:final train perplexity: 3.6012349128723145
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.67s/it]
INFO:root:eval mean loss: 4076.743029005984
INFO:root:eval perplexity: 5.199253559112549
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/181
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [23:47:30<2:49:34, 535.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3257.449790142952
INFO:root:current train perplexity3.583556890487671
INFO:root:current mean train loss 3244.4455416932396
INFO:root:current train perplexity3.6003799438476562
INFO:root:current mean train loss 3248.391077698001
INFO:root:current train perplexity3.5986828804016113
INFO:root:current mean train loss 3256.9586318837805
INFO:root:current train perplexity3.6066503524780273
INFO:root:current mean train loss 3253.419454348434
INFO:root:current train perplexity3.602837085723877
INFO:root:current mean train loss 3251.1298038127
INFO:root:current train perplexity3.6030595302581787
INFO:root:current mean train loss 3252.7483393154703
INFO:root:current train perplexity3.602308750152588
INFO:root:current mean train loss 3250.995825097264
INFO:root:current train perplexity3.601849317550659
INFO:root:current mean train loss 3251.2745446359395
INFO:root:current train perplexity3.602322578430176
INFO:root:current mean train loss 3250.4619826384305
INFO:root:current train perplexity3.6014182567596436

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.99s/it]
INFO:root:final mean train loss: 3246.793032246251
INFO:root:final train perplexity: 3.600072145462036
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.16s/it]
INFO:root:eval mean loss: 4077.5518028313386
INFO:root:eval perplexity: 5.200954914093018
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/182
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [23:59:26<2:56:56, 589.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3238.8067205255684
INFO:root:current train perplexity3.6108193397521973
INFO:root:current mean train loss 3237.0312484248993
INFO:root:current train perplexity3.6061413288116455
INFO:root:current mean train loss 3237.375048828125
INFO:root:current train perplexity3.5933940410614014
INFO:root:current mean train loss 3244.3554632482396
INFO:root:current train perplexity3.5959579944610596
INFO:root:current mean train loss 3245.4309505923766
INFO:root:current train perplexity3.5927915573120117
INFO:root:current mean train loss 3244.5890717377533
INFO:root:current train perplexity3.5975611209869385
INFO:root:current mean train loss 3246.2754756083013
INFO:root:current train perplexity3.596318483352661
INFO:root:current mean train loss 3247.943281767384
INFO:root:current train perplexity3.5997958183288574
INFO:root:current mean train loss 3250.00699270148
INFO:root:current train perplexity3.600781202316284
INFO:root:current mean train loss 3250.351526965396
INFO:root:current train perplexity3.6004090309143066

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.70s/it]
INFO:root:final mean train loss: 3247.095023862777
INFO:root:final train perplexity: 3.6005005836486816
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.07s/it]
INFO:root:eval mean loss: 4077.2854540669327
INFO:root:eval perplexity: 5.2003936767578125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/183
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [24:08:19<2:42:14, 572.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3237.189964657738
INFO:root:current train perplexity3.604621171951294
INFO:root:current mean train loss 3257.2137728263997
INFO:root:current train perplexity3.602945327758789
INFO:root:current mean train loss 3248.776477654171
INFO:root:current train perplexity3.6000583171844482
INFO:root:current mean train loss 3248.0168678977275
INFO:root:current train perplexity3.600996255874634
INFO:root:current mean train loss 3247.7972024542723
INFO:root:current train perplexity3.6002068519592285
INFO:root:current mean train loss 3247.1559559905086
INFO:root:current train perplexity3.600400924682617
INFO:root:current mean train loss 3249.1848560638196
INFO:root:current train perplexity3.600706100463867
INFO:root:current mean train loss 3250.152043613819
INFO:root:current train perplexity3.5990049839019775
INFO:root:current mean train loss 3247.3775494731317
INFO:root:current train perplexity3.5981979370117188
INFO:root:current mean train loss 3247.476475288811
INFO:root:current train perplexity3.5990376472473145

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.62s/it]
INFO:root:final mean train loss: 3246.21277366146
INFO:root:final train perplexity: 3.599247932434082
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.45s/it]
INFO:root:eval mean loss: 4077.9487114223184
INFO:root:eval perplexity: 5.201789379119873
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/184
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [24:16:19<2:25:19, 544.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3250.697334397007
INFO:root:current train perplexity3.59761381149292
INFO:root:current mean train loss 3254.246028074744
INFO:root:current train perplexity3.593592405319214
INFO:root:current mean train loss 3249.7782329263723
INFO:root:current train perplexity3.589998483657837
INFO:root:current mean train loss 3247.8507682203926
INFO:root:current train perplexity3.590867280960083
INFO:root:current mean train loss 3246.3748652302284
INFO:root:current train perplexity3.590013265609741
INFO:root:current mean train loss 3247.1340712565675
INFO:root:current train perplexity3.59224534034729
INFO:root:current mean train loss 3246.6755050909323
INFO:root:current train perplexity3.593916416168213
INFO:root:current mean train loss 3245.254045577983
INFO:root:current train perplexity3.5944406986236572
INFO:root:current mean train loss 3248.9397297803353
INFO:root:current train perplexity3.5960090160369873
INFO:root:current mean train loss 3247.8267051626062
INFO:root:current train perplexity3.5970864295959473

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.73s/it]
INFO:root:final mean train loss: 3244.4569198854506
INFO:root:final train perplexity: 3.5967557430267334
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.19s/it]
INFO:root:eval mean loss: 4078.793218085106
INFO:root:eval perplexity: 5.203567028045654
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/185
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [24:25:26<2:16:22, 545.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3236.471896014636
INFO:root:current train perplexity3.581145763397217
INFO:root:current mean train loss 3229.6036520164107
INFO:root:current train perplexity3.5868160724639893
INFO:root:current mean train loss 3232.3395261046708
INFO:root:current train perplexity3.593865394592285
INFO:root:current mean train loss 3236.87720370733
INFO:root:current train perplexity3.590390920639038
INFO:root:current mean train loss 3239.7791837242303
INFO:root:current train perplexity3.5909104347229004
INFO:root:current mean train loss 3242.176273747841
INFO:root:current train perplexity3.590139150619507
INFO:root:current mean train loss 3243.7485991577687
INFO:root:current train perplexity3.5918359756469727
INFO:root:current mean train loss 3244.1491617734073
INFO:root:current train perplexity3.5932300090789795
INFO:root:current mean train loss 3245.2269746782567
INFO:root:current train perplexity3.593122959136963
INFO:root:current mean train loss 3243.867555082514
INFO:root:current train perplexity3.5917141437530518

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:44<00:00, 404.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:44<00:00, 404.71s/it]
INFO:root:final mean train loss: 3240.8478520916356
INFO:root:final train perplexity: 3.591637372970581
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.26s/it]
INFO:root:eval mean loss: 4078.2829312804743
INFO:root:eval perplexity: 5.202492713928223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/186
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [24:34:58<2:09:09, 553.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3251.385924591415
INFO:root:current train perplexity3.6123859882354736
INFO:root:current mean train loss 3249.7107847489137
INFO:root:current train perplexity3.6074979305267334
INFO:root:current mean train loss 3251.02947721581
INFO:root:current train perplexity3.5984714031219482
INFO:root:current mean train loss 3249.4095727097465
INFO:root:current train perplexity3.593815326690674
INFO:root:current mean train loss 3248.812874983958
INFO:root:current train perplexity3.5916082859039307
INFO:root:current mean train loss 3247.284237083422
INFO:root:current train perplexity3.5933611392974854
INFO:root:current mean train loss 3249.151330584175
INFO:root:current train perplexity3.5951602458953857
INFO:root:current mean train loss 3247.353669802752
INFO:root:current train perplexity3.5950913429260254
INFO:root:current mean train loss 3246.0131530417666
INFO:root:current train perplexity3.59464693069458
INFO:root:current mean train loss 3245.910518379559
INFO:root:current train perplexity3.595226764678955

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.03s/it]
INFO:root:final mean train loss: 3243.024103533837
INFO:root:final train perplexity: 3.5947227478027344
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.35s/it]
INFO:root:eval mean loss: 4078.6493690436614
INFO:root:eval perplexity: 5.203263759613037
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/187
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [24:42:52<1:54:43, 529.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3254.5897666529604
INFO:root:current train perplexity3.590052843093872
INFO:root:current mean train loss 3245.522100360577
INFO:root:current train perplexity3.591425895690918
INFO:root:current mean train loss 3242.6325038069385
INFO:root:current train perplexity3.5897293090820312
INFO:root:current mean train loss 3241.566019951543
INFO:root:current train perplexity3.5903031826019287
INFO:root:current mean train loss 3239.924523062658
INFO:root:current train perplexity3.588624954223633
INFO:root:current mean train loss 3244.0169015066963
INFO:root:current train perplexity3.5941383838653564
INFO:root:current mean train loss 3247.075005620504
INFO:root:current train perplexity3.596076250076294
INFO:root:current mean train loss 3246.623618993219
INFO:root:current train perplexity3.5954363346099854
INFO:root:current mean train loss 3245.4453801501395
INFO:root:current train perplexity3.595174551010132

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:44<00:00, 404.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:44<00:00, 404.57s/it]
INFO:root:final mean train loss: 3242.6454641280634
INFO:root:final train perplexity: 3.5941853523254395
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.76s/it]
INFO:root:eval mean loss: 4077.913463403147
INFO:root:eval perplexity: 5.201715469360352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/188
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [24:53:52<1:53:44, 568.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3211.2383626302085
INFO:root:current train perplexity3.534050226211548
INFO:root:current mean train loss 3241.9899736422935
INFO:root:current train perplexity3.5749244689941406
INFO:root:current mean train loss 3239.537686653325
INFO:root:current train perplexity3.583319902420044
INFO:root:current mean train loss 3245.6469871596537
INFO:root:current train perplexity3.59352445602417
INFO:root:current mean train loss 3241.9393513492555
INFO:root:current train perplexity3.592214584350586
INFO:root:current mean train loss 3242.329142818868
INFO:root:current train perplexity3.594202995300293
INFO:root:current mean train loss 3239.438680215459
INFO:root:current train perplexity3.593885898590088
INFO:root:current mean train loss 3241.3019373583084
INFO:root:current train perplexity3.591036319732666
INFO:root:current mean train loss 3241.2967156853206
INFO:root:current train perplexity3.5909738540649414
INFO:root:current mean train loss 3246.0783285857037
INFO:root:current train perplexity3.593594551086426

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.65s/it]
INFO:root:final mean train loss: 3242.547110096101
INFO:root:final train perplexity: 3.5940465927124023
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.04s/it]
INFO:root:eval mean loss: 4078.593632258422
INFO:root:eval perplexity: 5.203146457672119
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/189
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [25:03:48<1:45:47, 577.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3212.8679643110795
INFO:root:current train perplexity3.583129644393921
INFO:root:current mean train loss 3228.990942602759
INFO:root:current train perplexity3.583484411239624
INFO:root:current mean train loss 3243.2177861652103
INFO:root:current train perplexity3.58970046043396
INFO:root:current mean train loss 3244.3580797201566
INFO:root:current train perplexity3.5912280082702637
INFO:root:current mean train loss 3240.0774098045927
INFO:root:current train perplexity3.592083215713501
INFO:root:current mean train loss 3238.2763356546598
INFO:root:current train perplexity3.590182304382324
INFO:root:current mean train loss 3236.568810096154
INFO:root:current train perplexity3.5878138542175293
INFO:root:current mean train loss 3239.0937578976573
INFO:root:current train perplexity3.5904037952423096
INFO:root:current mean train loss 3238.577106292386
INFO:root:current train perplexity3.588191509246826
INFO:root:current mean train loss 3241.913824523189
INFO:root:current train perplexity3.5903265476226807

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.10s/it]
INFO:root:final mean train loss: 3240.847323079263
INFO:root:final train perplexity: 3.5916366577148438
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.76s/it]
INFO:root:eval mean loss: 4078.1876818068486
INFO:root:eval perplexity: 5.2022929191589355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/190
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [25:14:55<1:40:39, 603.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3224.4856984991775
INFO:root:current train perplexity3.5981273651123047
INFO:root:current mean train loss 3258.4001813616073
INFO:root:current train perplexity3.596782922744751
INFO:root:current mean train loss 3252.44839937393
INFO:root:current train perplexity3.5904452800750732
INFO:root:current mean train loss 3252.793740969093
INFO:root:current train perplexity3.592608690261841
INFO:root:current mean train loss 3244.963040955027
INFO:root:current train perplexity3.5906083583831787
INFO:root:current mean train loss 3244.8895012004755
INFO:root:current train perplexity3.5896987915039062
INFO:root:current mean train loss 3241.569057877499
INFO:root:current train perplexity3.5883665084838867
INFO:root:current mean train loss 3240.4097114318934
INFO:root:current train perplexity3.5871591567993164
INFO:root:current mean train loss 3238.6602146768164
INFO:root:current train perplexity3.58723521232605
INFO:root:current mean train loss 3239.5249950587427
INFO:root:current train perplexity3.58712100982666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:37<00:00, 397.50s/it]
INFO:root:final mean train loss: 3238.211218864687
INFO:root:final train perplexity: 3.5879032611846924
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.61s/it]
INFO:root:eval mean loss: 4079.46816129211
INFO:root:eval perplexity: 5.204987049102783
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/191
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [25:25:23<1:31:42, 611.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3295.415192780671
INFO:root:current train perplexity3.6065196990966797
INFO:root:current mean train loss 3262.3494748093012
INFO:root:current train perplexity3.592794418334961
INFO:root:current mean train loss 3252.5536227457324
INFO:root:current train perplexity3.592989444732666
INFO:root:current mean train loss 3249.866710417861
INFO:root:current train perplexity3.590484142303467
INFO:root:current mean train loss 3245.758104096531
INFO:root:current train perplexity3.5893311500549316
INFO:root:current mean train loss 3248.311938522889
INFO:root:current train perplexity3.589672327041626
INFO:root:current mean train loss 3243.320888002143
INFO:root:current train perplexity3.5876317024230957
INFO:root:current mean train loss 3241.0994327340527
INFO:root:current train perplexity3.5864644050598145
INFO:root:current mean train loss 3239.243194764586
INFO:root:current train perplexity3.5861525535583496
INFO:root:current mean train loss 3239.7448143161746
INFO:root:current train perplexity3.586928606033325

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:36<00:00, 396.89s/it]
INFO:root:final mean train loss: 3238.152426873484
INFO:root:final train perplexity: 3.587820291519165
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.93s/it]
INFO:root:eval mean loss: 4078.9255301834
INFO:root:eval perplexity: 5.2038445472717285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/192
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [25:36:31<1:23:45, 628.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3209.6552315848216
INFO:root:current train perplexity3.5680322647094727
INFO:root:current mean train loss 3237.8812608506946
INFO:root:current train perplexity3.5837209224700928
INFO:root:current mean train loss 3234.5663366439494
INFO:root:current train perplexity3.5854525566101074
INFO:root:current mean train loss 3237.8351314715487
INFO:root:current train perplexity3.5880396366119385
INFO:root:current mean train loss 3242.615267488326
INFO:root:current train perplexity3.5887770652770996
INFO:root:current mean train loss 3236.9578115873246
INFO:root:current train perplexity3.583651304244995
INFO:root:current mean train loss 3238.684136626476
INFO:root:current train perplexity3.5861945152282715
INFO:root:current mean train loss 3238.023285700999
INFO:root:current train perplexity3.5873525142669678
INFO:root:current mean train loss 3237.6431260525824
INFO:root:current train perplexity3.5856237411499023
INFO:root:current mean train loss 3238.7442100810495
INFO:root:current train perplexity3.5863378047943115

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:38<00:00, 398.01s/it]
INFO:root:final mean train loss: 3238.149928862049
INFO:root:final train perplexity: 3.5878164768218994
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.88s/it]
INFO:root:eval mean loss: 4079.1988603307846
INFO:root:eval perplexity: 5.204419136047363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/193
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [25:45:18<1:09:45, 597.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3244.1551031068316
INFO:root:current train perplexity3.6134822368621826
INFO:root:current mean train loss 3243.9697675371503
INFO:root:current train perplexity3.6057167053222656
INFO:root:current mean train loss 3244.453371150013
INFO:root:current train perplexity3.596700429916382
INFO:root:current mean train loss 3238.7185848669824
INFO:root:current train perplexity3.594881772994995
INFO:root:current mean train loss 3243.0480863342973
INFO:root:current train perplexity3.5921785831451416
INFO:root:current mean train loss 3242.222487644596
INFO:root:current train perplexity3.589071035385132
INFO:root:current mean train loss 3241.12402457657
INFO:root:current train perplexity3.5891313552856445
INFO:root:current mean train loss 3239.819590264342
INFO:root:current train perplexity3.586928129196167
INFO:root:current mean train loss 3242.4554934247108
INFO:root:current train perplexity3.588275909423828
INFO:root:current mean train loss 3241.77206560056
INFO:root:current train perplexity3.5873606204986572

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.67s/it]
INFO:root:final mean train loss: 3238.1420199486515
INFO:root:final train perplexity: 3.587806224822998
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.53s/it]
INFO:root:eval mean loss: 4079.462343472961
INFO:root:eval perplexity: 5.204975128173828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/194
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [25:53:20<56:17, 562.99s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3205.7774347043505
INFO:root:current train perplexity3.5492024421691895
INFO:root:current mean train loss 3224.9587046642177
INFO:root:current train perplexity3.570497989654541
INFO:root:current mean train loss 3230.5230250871514
INFO:root:current train perplexity3.5816650390625
INFO:root:current mean train loss 3231.4327583856393
INFO:root:current train perplexity3.582108497619629
INFO:root:current mean train loss 3233.8511776131168
INFO:root:current train perplexity3.582334041595459
INFO:root:current mean train loss 3236.9824697283348
INFO:root:current train perplexity3.586280107498169
INFO:root:current mean train loss 3240.6717051141272
INFO:root:current train perplexity3.5891528129577637
INFO:root:current mean train loss 3238.4080464328813
INFO:root:current train perplexity3.5873918533325195
INFO:root:current mean train loss 3239.3270646665687
INFO:root:current train perplexity3.5878822803497314
INFO:root:current mean train loss 3240.18377294049
INFO:root:current train perplexity3.588357925415039

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.70s/it]
INFO:root:final mean train loss: 3237.6582971388293
INFO:root:final train perplexity: 3.587120532989502
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.86s/it]
INFO:root:eval mean loss: 4079.103287067819
INFO:root:eval perplexity: 5.204220294952393
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/195
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [26:00:54<44:11, 530.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3252.744285454184
INFO:root:current train perplexity3.606011152267456
INFO:root:current mean train loss 3247.3753331982116
INFO:root:current train perplexity3.5912961959838867
INFO:root:current mean train loss 3247.717619789153
INFO:root:current train perplexity3.5874109268188477
INFO:root:current mean train loss 3244.5933392452994
INFO:root:current train perplexity3.5852580070495605
INFO:root:current mean train loss 3241.8884511378337
INFO:root:current train perplexity3.585146903991699
INFO:root:current mean train loss 3237.1038781236025
INFO:root:current train perplexity3.5840837955474854
INFO:root:current mean train loss 3235.454608367318
INFO:root:current train perplexity3.5836539268493652
INFO:root:current mean train loss 3236.6262361428485
INFO:root:current train perplexity3.584704875946045
INFO:root:current mean train loss 3238.6579697845423
INFO:root:current train perplexity3.5846831798553467
INFO:root:current mean train loss 3238.731849837477
INFO:root:current train perplexity3.5851495265960693

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:39<00:00, 399.79s/it]
INFO:root:final mean train loss: 3236.446058519425
INFO:root:final train perplexity: 3.5854053497314453
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.96s/it]
INFO:root:eval mean loss: 4079.1152326435063
INFO:root:eval perplexity: 5.204244136810303
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/196
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [26:08:53<34:20, 515.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3254.8174666219684
INFO:root:current train perplexity3.5993542671203613
INFO:root:current mean train loss 3241.8527583504865
INFO:root:current train perplexity3.5922651290893555
INFO:root:current mean train loss 3245.8113634202364
INFO:root:current train perplexity3.5914409160614014
INFO:root:current mean train loss 3245.204825336342
INFO:root:current train perplexity3.589434862136841
INFO:root:current mean train loss 3246.4118694166555
INFO:root:current train perplexity3.591069221496582
INFO:root:current mean train loss 3245.096209490741
INFO:root:current train perplexity3.5905239582061768
INFO:root:current mean train loss 3241.3536408065497
INFO:root:current train perplexity3.587606906890869
INFO:root:current mean train loss 3241.730991089981
INFO:root:current train perplexity3.589022397994995
INFO:root:current mean train loss 3240.208523126622
INFO:root:current train perplexity3.587653398513794
INFO:root:current mean train loss 3239.024659213014
INFO:root:current train perplexity3.5863466262817383

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:40<00:00, 400.24s/it]
INFO:root:final mean train loss: 3236.5392714469663
INFO:root:final train perplexity: 3.5855374336242676
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.89s/it]
INFO:root:eval mean loss: 4079.657699260306
INFO:root:eval perplexity: 5.205386161804199
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/197
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [26:17:10<25:28, 509.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3236.030126953125
INFO:root:current train perplexity3.581094264984131
INFO:root:current mean train loss 3235.904169921875
INFO:root:current train perplexity3.577897787094116
INFO:root:current mean train loss 3233.6577752130684
INFO:root:current train perplexity3.579634428024292
INFO:root:current mean train loss 3230.611327473958
INFO:root:current train perplexity3.578249216079712
INFO:root:current mean train loss 3234.1594212582236
INFO:root:current train perplexity3.5773725509643555
INFO:root:current mean train loss 3235.572900390625
INFO:root:current train perplexity3.577301025390625
INFO:root:current mean train loss 3236.6150224247685
INFO:root:current train perplexity3.5790610313415527
INFO:root:current mean train loss 3235.0966692918346
INFO:root:current train perplexity3.5791821479797363
INFO:root:current mean train loss 3237.1286160714285
INFO:root:current train perplexity3.580143690109253
INFO:root:current mean train loss 3236.0190747696315
INFO:root:current train perplexity3.5815138816833496

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.25s/it]
INFO:root:final mean train loss: 3233.799912606516
INFO:root:final train perplexity: 3.5816640853881836
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.44s/it]
INFO:root:eval mean loss: 4079.805998240802
INFO:root:eval perplexity: 5.205697536468506
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/198
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [26:25:28<16:52, 506.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3229.3032550122366
INFO:root:current train perplexity3.584341287612915
INFO:root:current mean train loss 3242.516911074112
INFO:root:current train perplexity3.5865232944488525
INFO:root:current mean train loss 3245.2438360962346
INFO:root:current train perplexity3.593416929244995
INFO:root:current mean train loss 3240.6726252702756
INFO:root:current train perplexity3.5889885425567627
INFO:root:current mean train loss 3233.4127447471856
INFO:root:current train perplexity3.5865421295166016
INFO:root:current mean train loss 3237.7379139921472
INFO:root:current train perplexity3.590345859527588
INFO:root:current mean train loss 3238.1474602225935
INFO:root:current train perplexity3.5860867500305176
INFO:root:current mean train loss 3237.944015405492
INFO:root:current train perplexity3.5837576389312744
INFO:root:current mean train loss 3238.0453001132505
INFO:root:current train perplexity3.5819895267486572
INFO:root:current mean train loss 3237.708281508297
INFO:root:current train perplexity3.583000659942627

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.78s/it]
INFO:root:final mean train loss: 3234.613767562374
INFO:root:final train perplexity: 3.582814931869507
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.61s/it]
INFO:root:eval mean loss: 4079.745184715758
INFO:root:eval perplexity: 5.205570697784424
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/199
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [26:35:16<08:50, 530.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3233.6680841131524
INFO:root:current train perplexity3.590956211090088
INFO:root:current mean train loss 3231.9705829720224
INFO:root:current train perplexity3.575913190841675
INFO:root:current mean train loss 3230.6124120758163
INFO:root:current train perplexity3.579962968826294
INFO:root:current mean train loss 3233.475901884191
INFO:root:current train perplexity3.5794572830200195
INFO:root:current mean train loss 3235.849621308554
INFO:root:current train perplexity3.5818326473236084
INFO:root:current mean train loss 3235.797917245003
INFO:root:current train perplexity3.5846750736236572
INFO:root:current mean train loss 3234.814122775529
INFO:root:current train perplexity3.58304762840271
INFO:root:current mean train loss 3236.5930200473094
INFO:root:current train perplexity3.582982063293457
INFO:root:current mean train loss 3238.073745813166
INFO:root:current train perplexity3.5844523906707764
INFO:root:current mean train loss 3237.838356734044
INFO:root:current train perplexity3.583744525909424

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:41<00:00, 401.10s/it]
INFO:root:final mean train loss: 3235.2396199626305
INFO:root:final train perplexity: 3.5836997032165527
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.42s/it]
INFO:root:eval mean loss: 4079.718841769171
INFO:root:eval perplexity: 5.205514907836914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1160/200
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [26:43:43<00:00, 523.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [26:43:44<00:00, 481.12s/it]
INFO:root:evaluating final model
INFO:root:start evaluating
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.52s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.52s/it]
INFO:root:eval mean loss: 4079.718841769171
INFO:root:eval perplexity: 5.205514907836914
INFO:root:evalaution complete
INFO:root:save model final: small_val_1160/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x14f94bbd7f06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x14f94bbcf8e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x14f94baf4e09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x14f94bbd8a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x14f94baf2948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x14f94bbd8a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x14f94baadb46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x14f94b51246a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x14fa47d2ea27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x14fa47d2ebe0]
python(+0x24a989) [0x55ae6c077989]
python(+0x24a9bd) [0x55ae6c0779bd]
python(+0x24aa14) [0x55ae6c077a14]
python(+0x108f75) [0x55ae6bf35f75]
python(Py_RunMain+0x313) [0x55ae6c07a983]
python(Py_BytesMain+0x39) [0x55ae6c07abc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x14fa47d0c0b3]
python(+0x1d6e13) [0x55ae6c003e13]
/opt/slurm/data/slurmd/job26146344/slurm_script: line 136: 580617 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path sentence-transformers/multi-qa-MiniLM-L6-cos-v1 --data_config data_config.json --data_folder fast_processed_data_1160_final  --output small_val_1160 --batch_size 128 --epochs 200 --save_head  --save_epochs 1 --external_embedding
"
