INFO:root:Output: multil6_fair_baseline
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
Some weights of BertLMHeadModelBaseline were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'cls.predictions.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.value.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.2.crossattention.self.key.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.key.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.key.bias', 'cls.predictions.decoder.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.query.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24303.66911300505
INFO:root:current train perplexity14010.0498046875
INFO:root:current mean train loss 20019.979202653896
INFO:root:current train perplexity2689.890869140625
INFO:root:current mean train loss 17401.119640337583
INFO:root:current train perplexity943.0435791015625
INFO:root:current mean train loss 15684.207731242168
INFO:root:current train perplexity482.9718322753906
INFO:root:current mean train loss 14476.453944999374
INFO:root:current train perplexity300.9142150878906
INFO:root:current mean train loss 13586.67431559109
INFO:root:current train perplexity211.56417846679688
INFO:root:current mean train loss 12877.795454164432
INFO:root:current train perplexity160.29400634765625
INFO:root:current mean train loss 12317.189263679209
INFO:root:current train perplexity128.013671875
INFO:root:current mean train loss 11844.27406536777
INFO:root:current train perplexity106.2854232788086

100%|██████████| 1/1 [02:27<00:00, 147.93s/it][A100%|██████████| 1/1 [02:27<00:00, 147.93s/it]
INFO:root:final mean train loss: 11454.273323428246
INFO:root:final train perplexity: 91.74766540527344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 7217.28425241024
INFO:root:eval perplexity: 18.512718200683594
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 7680.6283106161345
INFO:root:eval perplexity: 23.120372772216797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/1
  0%|          | 1/200 [02:44<9:06:36, 164.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7617.086844308035
INFO:root:current train perplexity20.329378128051758
INFO:root:current mean train loss 7640.204671984521
INFO:root:current train perplexity20.078378677368164
INFO:root:current mean train loss 7505.897326483243
INFO:root:current train perplexity19.21358299255371
INFO:root:current mean train loss 7423.323394874797
INFO:root:current train perplexity18.6154727935791
INFO:root:current mean train loss 7342.9463118569565
INFO:root:current train perplexity18.04969596862793
INFO:root:current mean train loss 7273.477071968997
INFO:root:current train perplexity17.565387725830078
INFO:root:current mean train loss 7210.942577481466
INFO:root:current train perplexity17.131481170654297
INFO:root:current mean train loss 7151.082676996773
INFO:root:current train perplexity16.70033836364746
INFO:root:current mean train loss 7086.67873332462
INFO:root:current train perplexity16.310041427612305
INFO:root:current mean train loss 7027.881845089409
INFO:root:current train perplexity15.956141471862793

100%|██████████| 1/1 [02:27<00:00, 147.67s/it][A100%|██████████| 1/1 [02:27<00:00, 147.67s/it]
INFO:root:final mean train loss: 6974.880180481941
INFO:root:final train perplexity: 15.670687675476074
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.27s/it][A100%|██████████| 1/1 [00:08<00:00,  8.27s/it]
INFO:root:eval mean loss: 6060.498929936835
INFO:root:eval perplexity: 11.596321105957031
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.33s/it][A100%|██████████| 1/1 [00:08<00:00,  8.33s/it]
INFO:root:eval mean loss: 6665.656727892288
INFO:root:eval perplexity: 15.26677131652832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/2
  1%|          | 2/200 [05:29<9:03:18, 164.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6562.612369791666
INFO:root:current train perplexity12.873906135559082
INFO:root:current mean train loss 6414.72004076087
INFO:root:current train perplexity12.537312507629395
INFO:root:current mean train loss 6382.705416515261
INFO:root:current train perplexity12.321775436401367
INFO:root:current mean train loss 6362.881381758432
INFO:root:current train perplexity12.19443416595459
INFO:root:current mean train loss 6330.021904414533
INFO:root:current train perplexity12.086764335632324
INFO:root:current mean train loss 6299.743245600728
INFO:root:current train perplexity11.957825660705566
INFO:root:current mean train loss 6271.106697789634
INFO:root:current train perplexity11.852520942687988
INFO:root:current mean train loss 6249.253926737325
INFO:root:current train perplexity11.749289512634277
INFO:root:current mean train loss 6226.681269770897
INFO:root:current train perplexity11.63892936706543
INFO:root:current mean train loss 6205.219231343921
INFO:root:current train perplexity11.53178596496582

100%|██████████| 1/1 [02:27<00:00, 147.94s/it][A100%|██████████| 1/1 [02:27<00:00, 147.94s/it]
INFO:root:final mean train loss: 6178.852143564532
INFO:root:final train perplexity: 11.44709587097168
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.27s/it][A100%|██████████| 1/1 [00:08<00:00,  8.27s/it]
INFO:root:eval mean loss: 5584.483907496676
INFO:root:eval perplexity: 9.565865516662598
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.33s/it][A100%|██████████| 1/1 [00:08<00:00,  8.33s/it]
INFO:root:eval mean loss: 6258.012577570922
INFO:root:eval perplexity: 12.922721862792969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/3
  2%|▏         | 3/200 [08:14<9:00:51, 164.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5833.818975033967
INFO:root:current train perplexity10.371906280517578
INFO:root:current mean train loss 5889.336429751016
INFO:root:current train perplexity10.368046760559082
INFO:root:current mean train loss 5904.090410856923
INFO:root:current train perplexity10.281698226928711
INFO:root:current mean train loss 5891.020980976684
INFO:root:current train perplexity10.18164348602295
INFO:root:current mean train loss 5867.602788397607
INFO:root:current train perplexity10.130293846130371
INFO:root:current mean train loss 5857.073330881035
INFO:root:current train perplexity10.092495918273926
INFO:root:current mean train loss 5839.579740325291
INFO:root:current train perplexity10.019383430480957
INFO:root:current mean train loss 5823.81843569005
INFO:root:current train perplexity9.953540802001953
INFO:root:current mean train loss 5810.005475513555
INFO:root:current train perplexity9.894478797912598
INFO:root:current mean train loss 5800.286104774682
INFO:root:current train perplexity9.841695785522461

100%|██████████| 1/1 [02:27<00:00, 147.92s/it][A100%|██████████| 1/1 [02:27<00:00, 147.92s/it]
INFO:root:final mean train loss: 5784.620478353193
INFO:root:final train perplexity: 9.798215866088867
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 5316.657451656693
INFO:root:eval perplexity: 8.584001541137695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.37s/it][A100%|██████████| 1/1 [00:08<00:00,  8.37s/it]
INFO:root:eval mean loss: 6030.892387660682
INFO:root:eval perplexity: 11.776602745056152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/4
  2%|▏         | 4/200 [10:59<8:58:24, 164.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5639.414172757057
INFO:root:current train perplexity9.231160163879395
INFO:root:current mean train loss 5631.511897662213
INFO:root:current train perplexity9.21945858001709
INFO:root:current mean train loss 5600.879848992154
INFO:root:current train perplexity9.139946937561035
INFO:root:current mean train loss 5590.82813385102
INFO:root:current train perplexity9.09007453918457
INFO:root:current mean train loss 5575.849712469185
INFO:root:current train perplexity9.05783748626709
INFO:root:current mean train loss 5568.344054371175
INFO:root:current train perplexity9.01537036895752
INFO:root:current mean train loss 5565.85320377501
INFO:root:current train perplexity8.998346328735352
INFO:root:current mean train loss 5556.9887722031035
INFO:root:current train perplexity8.96102523803711
INFO:root:current mean train loss 5551.595827692539
INFO:root:current train perplexity8.926087379455566
INFO:root:current mean train loss 5544.219811526585
INFO:root:current train perplexity8.899124145507812

100%|██████████| 1/1 [02:27<00:00, 147.81s/it][A100%|██████████| 1/1 [02:27<00:00, 147.81s/it]
INFO:root:final mean train loss: 5535.716000956873
INFO:root:final train perplexity: 8.881762504577637
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.37s/it][A100%|██████████| 1/1 [00:08<00:00,  8.37s/it]
INFO:root:eval mean loss: 5141.439809812721
INFO:root:eval perplexity: 7.996845722198486
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.33s/it][A100%|██████████| 1/1 [00:08<00:00,  8.33s/it]
INFO:root:eval mean loss: 5883.776647689495
INFO:root:eval perplexity: 11.08903694152832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/5
  2%|▎         | 5/200 [13:43<8:55:38, 164.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5438.962064302885
INFO:root:current train perplexity8.506282806396484
INFO:root:current mean train loss 5426.397014810027
INFO:root:current train perplexity8.5105562210083
INFO:root:current mean train loss 5430.403949561977
INFO:root:current train perplexity8.503719329833984
INFO:root:current mean train loss 5413.822882098083
INFO:root:current train perplexity8.453743934631348
INFO:root:current mean train loss 5402.997219355068
INFO:root:current train perplexity8.41104507446289
INFO:root:current mean train loss 5391.401914352388
INFO:root:current train perplexity8.379307746887207
INFO:root:current mean train loss 5386.098522777289
INFO:root:current train perplexity8.356775283813477
INFO:root:current mean train loss 5378.945422842312
INFO:root:current train perplexity8.334569931030273
INFO:root:current mean train loss 5374.045927536502
INFO:root:current train perplexity8.315675735473633
INFO:root:current mean train loss 5363.142199044029
INFO:root:current train perplexity8.29056453704834

100%|██████████| 1/1 [02:28<00:00, 148.53s/it][A100%|██████████| 1/1 [02:28<00:00, 148.53s/it]
INFO:root:final mean train loss: 5356.90296751453
INFO:root:final train perplexity: 8.276772499084473
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.25s/it][A100%|██████████| 1/1 [00:08<00:00,  8.25s/it]
INFO:root:eval mean loss: 5015.849941821809
INFO:root:eval perplexity: 7.60086727142334
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.32s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 5778.04064162234
INFO:root:eval perplexity: 10.619800567626953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/6
  3%|▎         | 6/200 [16:29<8:53:34, 165.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5188.672093168218
INFO:root:current train perplexity7.9356184005737305
INFO:root:current mean train loss 5235.939021311649
INFO:root:current train perplexity7.999608993530273
INFO:root:current mean train loss 5261.5163781787705
INFO:root:current train perplexity8.001276016235352
INFO:root:current mean train loss 5260.605067712086
INFO:root:current train perplexity7.982248783111572
INFO:root:current mean train loss 5250.069930176874
INFO:root:current train perplexity7.9456658363342285
INFO:root:current mean train loss 5249.646573640311
INFO:root:current train perplexity7.936206817626953
INFO:root:current mean train loss 5245.551914032312
INFO:root:current train perplexity7.921250343322754
INFO:root:current mean train loss 5239.727726008199
INFO:root:current train perplexity7.900045871734619
INFO:root:current mean train loss 5238.215636414367
INFO:root:current train perplexity7.881557941436768
INFO:root:current mean train loss 5231.925677097083
INFO:root:current train perplexity7.8582258224487305

100%|██████████| 1/1 [02:27<00:00, 147.81s/it][A100%|██████████| 1/1 [02:27<00:00, 147.81s/it]
INFO:root:final mean train loss: 5222.877695391255
INFO:root:final train perplexity: 7.850493907928467
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.22s/it][A100%|██████████| 1/1 [00:08<00:00,  8.22s/it]
INFO:root:eval mean loss: 4917.57532344304
INFO:root:eval perplexity: 7.304737567901611
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.40s/it][A100%|██████████| 1/1 [00:08<00:00,  8.40s/it]
INFO:root:eval mean loss: 5692.923599567819
INFO:root:eval perplexity: 10.256531715393066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/7
  4%|▎         | 7/200 [19:14<8:50:30, 164.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5149.264692826705
INFO:root:current train perplexity7.545254707336426
INFO:root:current mean train loss 5124.195104586694
INFO:root:current train perplexity7.52580451965332
INFO:root:current mean train loss 5135.74255323223
INFO:root:current train perplexity7.563418865203857
INFO:root:current mean train loss 5126.915180732834
INFO:root:current train perplexity7.561365127563477
INFO:root:current mean train loss 5134.2239010989015
INFO:root:current train perplexity7.567922592163086
INFO:root:current mean train loss 5131.210719313063
INFO:root:current train perplexity7.56262731552124
INFO:root:current mean train loss 5122.715027880487
INFO:root:current train perplexity7.547001838684082
INFO:root:current mean train loss 5120.794313948675
INFO:root:current train perplexity7.538612365722656
INFO:root:current mean train loss 5119.4889140168125
INFO:root:current train perplexity7.525481700897217
INFO:root:current mean train loss 5119.599993864529
INFO:root:current train perplexity7.5273942947387695

100%|██████████| 1/1 [02:27<00:00, 147.65s/it][A100%|██████████| 1/1 [02:27<00:00, 147.65s/it]
INFO:root:final mean train loss: 5114.945982902281
INFO:root:final train perplexity: 7.523217678070068
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 4835.856864333999
INFO:root:eval perplexity: 7.067301273345947
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.39s/it][A100%|██████████| 1/1 [00:08<00:00,  8.39s/it]
INFO:root:eval mean loss: 5628.223490830009
INFO:root:eval perplexity: 9.988734245300293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/8
  4%|▍         | 8/200 [21:58<8:47:26, 164.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4990.539256262401
INFO:root:current train perplexity7.241650104522705
INFO:root:current mean train loss 5002.679010496549
INFO:root:current train perplexity7.210183143615723
INFO:root:current mean train loss 5021.753059648289
INFO:root:current train perplexity7.274568557739258
INFO:root:current mean train loss 5041.430557797435
INFO:root:current train perplexity7.32462739944458
INFO:root:current mean train loss 5044.580342830386
INFO:root:current train perplexity7.29445743560791
INFO:root:current mean train loss 5045.354258887933
INFO:root:current train perplexity7.29689884185791
INFO:root:current mean train loss 5043.913410721861
INFO:root:current train perplexity7.287027835845947
INFO:root:current mean train loss 5035.295181054432
INFO:root:current train perplexity7.277191638946533
INFO:root:current mean train loss 5029.838161640897
INFO:root:current train perplexity7.26785135269165
INFO:root:current mean train loss 5028.672996576453
INFO:root:current train perplexity7.259797096252441

100%|██████████| 1/1 [02:27<00:00, 147.85s/it][A100%|██████████| 1/1 [02:27<00:00, 147.85s/it]
INFO:root:final mean train loss: 5025.05771729254
INFO:root:final train perplexity: 7.2610955238342285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.25s/it][A100%|██████████| 1/1 [00:08<00:00,  8.25s/it]
INFO:root:eval mean loss: 4772.3481583832
INFO:root:eval perplexity: 6.888116359710693
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 5576.564965647163
INFO:root:eval perplexity: 9.779946327209473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/9
  4%|▍         | 9/200 [24:43<8:44:37, 164.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4947.380488006162
INFO:root:current train perplexity7.112498760223389
INFO:root:current mean train loss 4933.782309370431
INFO:root:current train perplexity7.0926513671875
INFO:root:current mean train loss 4951.6961251009
INFO:root:current train perplexity7.096965789794922
INFO:root:current mean train loss 4959.573877874411
INFO:root:current train perplexity7.094386577606201
INFO:root:current mean train loss 4956.441398993166
INFO:root:current train perplexity7.079791069030762
INFO:root:current mean train loss 4958.979324581326
INFO:root:current train perplexity7.075236797332764
INFO:root:current mean train loss 4958.89767778968
INFO:root:current train perplexity7.068070411682129
INFO:root:current mean train loss 4957.704426450025
INFO:root:current train perplexity7.064913272857666
INFO:root:current mean train loss 4955.35844889136
INFO:root:current train perplexity7.058117389678955
INFO:root:current mean train loss 4954.1583489556515
INFO:root:current train perplexity7.050879955291748

100%|██████████| 1/1 [02:27<00:00, 147.55s/it][A100%|██████████| 1/1 [02:27<00:00, 147.55s/it]
INFO:root:final mean train loss: 4949.24040197557
INFO:root:final train perplexity: 7.047117233276367
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.27s/it][A100%|██████████| 1/1 [00:08<00:00,  8.27s/it]
INFO:root:eval mean loss: 4719.35094608821
INFO:root:eval perplexity: 6.742068767547607
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.39s/it][A100%|██████████| 1/1 [00:08<00:00,  8.39s/it]
INFO:root:eval mean loss: 5535.277260638298
INFO:root:eval perplexity: 9.616216659545898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/10
  5%|▌         | 10/200 [27:27<8:41:37, 164.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4853.503615753561
INFO:root:current train perplexity6.835381984710693
INFO:root:current mean train loss 4886.0635529416895
INFO:root:current train perplexity6.859492301940918
INFO:root:current mean train loss 4890.385208403338
INFO:root:current train perplexity6.866213321685791
INFO:root:current mean train loss 4878.665522190386
INFO:root:current train perplexity6.862477779388428
INFO:root:current mean train loss 4886.736162986039
INFO:root:current train perplexity6.875594139099121
INFO:root:current mean train loss 4892.427479692898
INFO:root:current train perplexity6.881513595581055
INFO:root:current mean train loss 4889.659189036037
INFO:root:current train perplexity6.8765645027160645
INFO:root:current mean train loss 4892.247310378892
INFO:root:current train perplexity6.877959728240967
INFO:root:current mean train loss 4890.7723103980015
INFO:root:current train perplexity6.8767266273498535
INFO:root:current mean train loss 4890.354514132725
INFO:root:current train perplexity6.872695446014404

100%|██████████| 1/1 [02:27<00:00, 147.45s/it][A100%|██████████| 1/1 [02:27<00:00, 147.45s/it]
INFO:root:final mean train loss: 4885.483454058247
INFO:root:final train perplexity: 6.872064113616943
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.26s/it][A100%|██████████| 1/1 [00:08<00:00,  8.26s/it]
INFO:root:eval mean loss: 4677.641023243573
INFO:root:eval perplexity: 6.629310607910156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.41s/it][A100%|██████████| 1/1 [00:08<00:00,  8.41s/it]
INFO:root:eval mean loss: 5498.808240525266
INFO:root:eval perplexity: 9.473876953125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/11
  6%|▌         | 11/200 [30:12<8:38:32, 164.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4829.593413254311
INFO:root:current train perplexity6.71390438079834
INFO:root:current mean train loss 4835.637199197861
INFO:root:current train perplexity6.74171257019043
INFO:root:current mean train loss 4835.697097193489
INFO:root:current train perplexity6.745243072509766
INFO:root:current mean train loss 4850.756852339712
INFO:root:current train perplexity6.764930248260498
INFO:root:current mean train loss 4847.4507728279
INFO:root:current train perplexity6.7588348388671875
INFO:root:current mean train loss 4835.344894591141
INFO:root:current train perplexity6.739963054656982
INFO:root:current mean train loss 4835.612213712246
INFO:root:current train perplexity6.736588954925537
INFO:root:current mean train loss 4830.6207345189405
INFO:root:current train perplexity6.726511478424072
INFO:root:current mean train loss 4830.583815926226
INFO:root:current train perplexity6.721240997314453
INFO:root:current mean train loss 4830.536355927843
INFO:root:current train perplexity6.716030597686768

100%|██████████| 1/1 [02:27<00:00, 147.70s/it][A100%|██████████| 1/1 [02:27<00:00, 147.70s/it]
INFO:root:final mean train loss: 4827.193710204094
INFO:root:final train perplexity: 6.715831279754639
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.26s/it][A100%|██████████| 1/1 [00:08<00:00,  8.26s/it]
INFO:root:eval mean loss: 4636.321586879432
INFO:root:eval perplexity: 6.519464492797852
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.40s/it][A100%|██████████| 1/1 [00:08<00:00,  8.40s/it]
INFO:root:eval mean loss: 5471.113700271499
INFO:root:eval perplexity: 9.367192268371582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/12
  6%|▌         | 12/200 [32:56<8:35:48, 164.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4777.042506167763
INFO:root:current train perplexity6.592073440551758
INFO:root:current mean train loss 4759.493662359776
INFO:root:current train perplexity6.572902679443359
INFO:root:current mean train loss 4762.312019994703
INFO:root:current train perplexity6.580521583557129
INFO:root:current mean train loss 4763.414181170886
INFO:root:current train perplexity6.574708461761475
INFO:root:current mean train loss 4770.221577099116
INFO:root:current train perplexity6.58483362197876
INFO:root:current mean train loss 4774.152730271796
INFO:root:current train perplexity6.581412315368652
INFO:root:current mean train loss 4772.046890456385
INFO:root:current train perplexity6.582658290863037
INFO:root:current mean train loss 4780.948099695362
INFO:root:current train perplexity6.589416980743408
INFO:root:current mean train loss 4778.736473791027
INFO:root:current train perplexity6.580237865447998

100%|██████████| 1/1 [02:27<00:00, 147.98s/it][A100%|██████████| 1/1 [02:27<00:00, 147.98s/it]
INFO:root:final mean train loss: 4776.79093219388
INFO:root:final train perplexity: 6.5836029052734375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 4604.683133172651
INFO:root:eval perplexity: 6.436589241027832
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.41s/it][A100%|██████████| 1/1 [00:08<00:00,  8.41s/it]
INFO:root:eval mean loss: 5438.82360233821
INFO:root:eval perplexity: 9.24432373046875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/13
  6%|▋         | 13/200 [35:41<8:33:23, 164.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4824.507649739583
INFO:root:current train perplexity6.530674934387207
INFO:root:current mean train loss 4710.877550439927
INFO:root:current train perplexity6.416424751281738
INFO:root:current mean train loss 4721.259537118996
INFO:root:current train perplexity6.439899444580078
INFO:root:current mean train loss 4731.557144215398
INFO:root:current train perplexity6.465685844421387
INFO:root:current mean train loss 4727.469489691571
INFO:root:current train perplexity6.462697505950928
INFO:root:current mean train loss 4730.360035587258
INFO:root:current train perplexity6.474461555480957
INFO:root:current mean train loss 4734.46304083424
INFO:root:current train perplexity6.483297824859619
INFO:root:current mean train loss 4738.790889560922
INFO:root:current train perplexity6.483371257781982
INFO:root:current mean train loss 4733.500594693726
INFO:root:current train perplexity6.470041275024414
INFO:root:current mean train loss 4735.722376150678
INFO:root:current train perplexity6.4703874588012695

100%|██████████| 1/1 [02:27<00:00, 147.54s/it][A100%|██████████| 1/1 [02:27<00:00, 147.55s/it]
INFO:root:final mean train loss: 4732.182563781738
INFO:root:final train perplexity: 6.468750476837158
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.26s/it][A100%|██████████| 1/1 [00:08<00:00,  8.26s/it]
INFO:root:eval mean loss: 4571.321147080009
INFO:root:eval perplexity: 6.350337982177734
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.37s/it][A100%|██████████| 1/1 [00:08<00:00,  8.37s/it]
INFO:root:eval mean loss: 5414.555168855275
INFO:root:eval perplexity: 9.15304183959961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/14
  7%|▋         | 14/200 [38:26<8:30:23, 164.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4681.732288707386
INFO:root:current train perplexity6.263856410980225
INFO:root:current mean train loss 4709.9938370988175
INFO:root:current train perplexity6.379392623901367
INFO:root:current mean train loss 4697.512903584123
INFO:root:current train perplexity6.387513637542725
INFO:root:current mean train loss 4694.670543609324
INFO:root:current train perplexity6.358450412750244
INFO:root:current mean train loss 4692.503521327555
INFO:root:current train perplexity6.348371505737305
INFO:root:current mean train loss 4697.825708437806
INFO:root:current train perplexity6.356192111968994
INFO:root:current mean train loss 4697.289292655483
INFO:root:current train perplexity6.353978633880615
INFO:root:current mean train loss 4697.154079861111
INFO:root:current train perplexity6.356715679168701
INFO:root:current mean train loss 4694.742714313926
INFO:root:current train perplexity6.359875202178955
INFO:root:current mean train loss 4694.0072711563525
INFO:root:current train perplexity6.360243320465088

100%|██████████| 1/1 [02:27<00:00, 147.25s/it][A100%|██████████| 1/1 [02:27<00:00, 147.25s/it]
INFO:root:final mean train loss: 4690.492205589048
INFO:root:final train perplexity: 6.363221645355225
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.28s/it][A100%|██████████| 1/1 [00:08<00:00,  8.28s/it]
INFO:root:eval mean loss: 4544.682023285129
INFO:root:eval perplexity: 6.282298564910889
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 5394.232851285461
INFO:root:eval perplexity: 9.077292442321777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/15
  8%|▊         | 15/200 [41:10<8:27:12, 164.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4585.455052425987
INFO:root:current train perplexity6.165561676025391
INFO:root:current mean train loss 4673.249068572742
INFO:root:current train perplexity6.2983903884887695
INFO:root:current mean train loss 4679.945787403682
INFO:root:current train perplexity6.300041198730469
INFO:root:current mean train loss 4669.23497348893
INFO:root:current train perplexity6.2905497550964355
INFO:root:current mean train loss 4658.543716904087
INFO:root:current train perplexity6.290432929992676
INFO:root:current mean train loss 4655.248174825385
INFO:root:current train perplexity6.284198760986328
INFO:root:current mean train loss 4658.96574143023
INFO:root:current train perplexity6.289339542388916
INFO:root:current mean train loss 4662.339298083819
INFO:root:current train perplexity6.294877529144287
INFO:root:current mean train loss 4659.2959219870845
INFO:root:current train perplexity6.285213947296143
INFO:root:current mean train loss 4657.662695684423
INFO:root:current train perplexity6.273962497711182

100%|██████████| 1/1 [02:27<00:00, 147.52s/it][A100%|██████████| 1/1 [02:27<00:00, 147.52s/it]
INFO:root:final mean train loss: 4652.815182347452
INFO:root:final train perplexity: 6.2693352699279785
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.23s/it][A100%|██████████| 1/1 [00:08<00:00,  8.23s/it]
INFO:root:eval mean loss: 4520.764965300865
INFO:root:eval perplexity: 6.2218337059021
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.37s/it][A100%|██████████| 1/1 [00:08<00:00,  8.37s/it]
INFO:root:eval mean loss: 5374.062184868129
INFO:root:eval perplexity: 9.002730369567871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/16
  8%|▊         | 16/200 [43:54<8:24:21, 164.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4642.611183449074
INFO:root:current train perplexity6.12347936630249
INFO:root:current mean train loss 4604.625780481053
INFO:root:current train perplexity6.1386189460754395
INFO:root:current mean train loss 4605.18874543984
INFO:root:current train perplexity6.1224751472473145
INFO:root:current mean train loss 4612.2146152881305
INFO:root:current train perplexity6.148367881774902
INFO:root:current mean train loss 4614.344425817842
INFO:root:current train perplexity6.155905723571777
INFO:root:current mean train loss 4615.609599220233
INFO:root:current train perplexity6.170009613037109
INFO:root:current mean train loss 4611.510275711474
INFO:root:current train perplexity6.168704032897949
INFO:root:current mean train loss 4617.787411612362
INFO:root:current train perplexity6.181464195251465
INFO:root:current mean train loss 4619.080487879761
INFO:root:current train perplexity6.182769298553467
INFO:root:current mean train loss 4621.685439421521
INFO:root:current train perplexity6.183305740356445

100%|██████████| 1/1 [02:27<00:00, 147.61s/it][A100%|██████████| 1/1 [02:27<00:00, 147.61s/it]
INFO:root:final mean train loss: 4618.540204632667
INFO:root:final train perplexity: 6.185128688812256
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.26s/it][A100%|██████████| 1/1 [00:08<00:00,  8.26s/it]
INFO:root:eval mean loss: 4498.426245290337
INFO:root:eval perplexity: 6.1658830642700195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 5357.037937029034
INFO:root:eval perplexity: 8.940274238586426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/17
  8%|▊         | 17/200 [46:39<8:21:36, 164.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4622.212179129464
INFO:root:current train perplexity6.074146747589111
INFO:root:current mean train loss 4588.055472366898
INFO:root:current train perplexity6.083713531494141
INFO:root:current mean train loss 4589.250601520944
INFO:root:current train perplexity6.103049278259277
INFO:root:current mean train loss 4590.498596373601
INFO:root:current train perplexity6.105318069458008
INFO:root:current mean train loss 4590.465180495689
INFO:root:current train perplexity6.110100269317627
INFO:root:current mean train loss 4593.80103588639
INFO:root:current train perplexity6.116017818450928
INFO:root:current mean train loss 4590.957847871555
INFO:root:current train perplexity6.118884563446045
INFO:root:current mean train loss 4589.323444807611
INFO:root:current train perplexity6.116443634033203
INFO:root:current mean train loss 4586.682890274139
INFO:root:current train perplexity6.10446834564209
INFO:root:current mean train loss 4587.725913373161
INFO:root:current train perplexity6.104483604431152

100%|██████████| 1/1 [02:27<00:00, 147.40s/it][A100%|██████████| 1/1 [02:27<00:00, 147.40s/it]
INFO:root:final mean train loss: 4586.156171121905
INFO:root:final train perplexity: 6.106607437133789
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 4480.602334746232
INFO:root:eval perplexity: 6.121603488922119
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 5339.903010375111
INFO:root:eval perplexity: 8.877852439880371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/18
  9%|▉         | 18/200 [49:23<8:18:45, 164.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4531.349234647529
INFO:root:current train perplexity6.008787155151367
INFO:root:current mean train loss 4567.686371489838
INFO:root:current train perplexity6.032870769500732
INFO:root:current mean train loss 4572.412821702997
INFO:root:current train perplexity6.053862571716309
INFO:root:current mean train loss 4566.280314720754
INFO:root:current train perplexity6.045246601104736
INFO:root:current mean train loss 4561.404639663869
INFO:root:current train perplexity6.033468246459961
INFO:root:current mean train loss 4560.419680881676
INFO:root:current train perplexity6.033321857452393
INFO:root:current mean train loss 4559.030459485566
INFO:root:current train perplexity6.03244161605835
INFO:root:current mean train loss 4556.035227553521
INFO:root:current train perplexity6.027556419372559
INFO:root:current mean train loss 4557.90223891144
INFO:root:current train perplexity6.031333923339844
INFO:root:current mean train loss 4555.917009015857
INFO:root:current train perplexity6.028657913208008

100%|██████████| 1/1 [02:27<00:00, 147.59s/it][A100%|██████████| 1/1 [02:27<00:00, 147.59s/it]
INFO:root:final mean train loss: 4555.504368443643
INFO:root:final train perplexity: 6.033205032348633
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.37s/it][A100%|██████████| 1/1 [00:08<00:00,  8.37s/it]
INFO:root:eval mean loss: 4461.704832252881
INFO:root:eval perplexity: 6.075002670288086
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 5328.429384488586
INFO:root:eval perplexity: 8.836296081542969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/19
 10%|▉         | 19/200 [52:08<8:16:11, 164.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4566.7333984375
INFO:root:current train perplexity5.9918131828308105
INFO:root:current mean train loss 4540.519518315397
INFO:root:current train perplexity5.96068811416626
INFO:root:current mean train loss 4539.483383847422
INFO:root:current train perplexity5.961047649383545
INFO:root:current mean train loss 4534.21189319578
INFO:root:current train perplexity5.95703125
INFO:root:current mean train loss 4539.279367789461
INFO:root:current train perplexity5.966220855712891
INFO:root:current mean train loss 4540.6375433338535
INFO:root:current train perplexity5.970231533050537
INFO:root:current mean train loss 4540.376764112903
INFO:root:current train perplexity5.972285270690918
INFO:root:current mean train loss 4536.7415896643015
INFO:root:current train perplexity5.9759602546691895
INFO:root:current mean train loss 4533.451984051392
INFO:root:current train perplexity5.968268871307373
INFO:root:current mean train loss 4530.861030329916
INFO:root:current train perplexity5.966987609863281

100%|██████████| 1/1 [02:27<00:00, 147.82s/it][A100%|██████████| 1/1 [02:27<00:00, 147.82s/it]
INFO:root:final mean train loss: 4528.048847075432
INFO:root:final train perplexity: 5.96820592880249
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 4444.936835106383
INFO:root:eval perplexity: 6.0339508056640625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.34s/it][A100%|██████████| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 5313.501828457447
INFO:root:eval perplexity: 8.782522201538086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/20
 10%|█         | 20/200 [54:53<8:13:40, 164.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4499.999772411282
INFO:root:current train perplexity5.934835433959961
INFO:root:current mean train loss 4517.729785463345
INFO:root:current train perplexity5.919414043426514
INFO:root:current mean train loss 4511.210242783241
INFO:root:current train perplexity5.901498794555664
INFO:root:current mean train loss 4508.038035613248
INFO:root:current train perplexity5.902137279510498
INFO:root:current mean train loss 4514.658562155331
INFO:root:current train perplexity5.907858371734619
INFO:root:current mean train loss 4515.533466045673
INFO:root:current train perplexity5.903804302215576
INFO:root:current mean train loss 4511.859855871823
INFO:root:current train perplexity5.902154445648193
INFO:root:current mean train loss 4507.05691500175
INFO:root:current train perplexity5.9004645347595215
INFO:root:current mean train loss 4509.62795043519
INFO:root:current train perplexity5.906040191650391
INFO:root:current mean train loss 4507.273155172625
INFO:root:current train perplexity5.908042907714844

100%|██████████| 1/1 [02:27<00:00, 147.55s/it][A100%|██████████| 1/1 [02:27<00:00, 147.55s/it]
INFO:root:final mean train loss: 4503.086586736864
INFO:root:final train perplexity: 5.90971565246582
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.34s/it][A100%|██████████| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 4429.657569398271
INFO:root:eval perplexity: 5.9967851638793945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 5302.60763658023
INFO:root:eval perplexity: 8.743488311767578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/21
 10%|█         | 21/200 [57:37<8:10:54, 164.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4483.323030841884
INFO:root:current train perplexity5.890746116638184
INFO:root:current mean train loss 4484.738309026478
INFO:root:current train perplexity5.885091781616211
INFO:root:current mean train loss 4475.463744659995
INFO:root:current train perplexity5.868551254272461
INFO:root:current mean train loss 4464.771805682689
INFO:root:current train perplexity5.84083890914917
INFO:root:current mean train loss 4476.841793215504
INFO:root:current train perplexity5.848877429962158
INFO:root:current mean train loss 4479.491923552552
INFO:root:current train perplexity5.853909015655518
INFO:root:current mean train loss 4477.620989432042
INFO:root:current train perplexity5.852681636810303
INFO:root:current mean train loss 4483.886027707892
INFO:root:current train perplexity5.8619914054870605
INFO:root:current mean train loss 4483.284697817546
INFO:root:current train perplexity5.85706901550293
INFO:root:current mean train loss 4480.17261146143
INFO:root:current train perplexity5.84700870513916

100%|██████████| 1/1 [02:27<00:00, 147.48s/it][A100%|██████████| 1/1 [02:27<00:00, 147.48s/it]
INFO:root:final mean train loss: 4476.354682922363
INFO:root:final train perplexity: 5.847718238830566
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.33s/it][A100%|██████████| 1/1 [00:08<00:00,  8.33s/it]
INFO:root:eval mean loss: 4415.748277163675
INFO:root:eval perplexity: 5.963150978088379
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.33s/it][A100%|██████████| 1/1 [00:08<00:00,  8.33s/it]
INFO:root:eval mean loss: 5290.785447140957
INFO:root:eval perplexity: 8.70132064819336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/22
 11%|█         | 22/200 [1:00:22<8:08:02, 164.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4424.086604817709
INFO:root:current train perplexity5.757457256317139
INFO:root:current mean train loss 4445.035735212054
INFO:root:current train perplexity5.7987236976623535
INFO:root:current mean train loss 4446.441584694602
INFO:root:current train perplexity5.794466972351074
INFO:root:current mean train loss 4452.7079401041665
INFO:root:current train perplexity5.797302722930908
INFO:root:current mean train loss 4451.129058388158
INFO:root:current train perplexity5.785264015197754
INFO:root:current mean train loss 4454.962798063859
INFO:root:current train perplexity5.789575099945068
INFO:root:current mean train loss 4455.939376808449
INFO:root:current train perplexity5.790314674377441
INFO:root:current mean train loss 4455.601492250504
INFO:root:current train perplexity5.789538860321045
INFO:root:current mean train loss 4456.4807458147325
INFO:root:current train perplexity5.789934158325195
INFO:root:current mean train loss 4457.017972255609
INFO:root:current train perplexity5.793863296508789

100%|██████████| 1/1 [02:27<00:00, 147.54s/it][A100%|██████████| 1/1 [02:27<00:00, 147.54s/it]
INFO:root:final mean train loss: 4453.00730711414
INFO:root:final train perplexity: 5.794099807739258
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 4403.977120041001
INFO:root:eval perplexity: 5.934834957122803
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.33s/it][A100%|██████████| 1/1 [00:08<00:00,  8.33s/it]
INFO:root:eval mean loss: 5281.256874030363
INFO:root:eval perplexity: 8.667484283447266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/23
 12%|█▏        | 23/200 [1:03:06<8:05:17, 164.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4450.762542356928
INFO:root:current train perplexity5.7668585777282715
INFO:root:current mean train loss 4432.108345073429
INFO:root:current train perplexity5.7258992195129395
INFO:root:current mean train loss 4427.5373655932535
INFO:root:current train perplexity5.7247138023376465
INFO:root:current mean train loss 4423.012890370022
INFO:root:current train perplexity5.721137046813965
INFO:root:current mean train loss 4424.586690646028
INFO:root:current train perplexity5.731544494628906
INFO:root:current mean train loss 4422.548309692592
INFO:root:current train perplexity5.731180191040039
INFO:root:current mean train loss 4428.776901937683
INFO:root:current train perplexity5.736934661865234
INFO:root:current mean train loss 4431.073005841914
INFO:root:current train perplexity5.738823890686035
INFO:root:current mean train loss 4431.711988161806
INFO:root:current train perplexity5.740176200866699
INFO:root:current mean train loss 4433.659290954031
INFO:root:current train perplexity5.743995666503906

100%|██████████| 1/1 [02:27<00:00, 147.53s/it][A100%|██████████| 1/1 [02:27<00:00, 147.53s/it]
INFO:root:final mean train loss: 4431.034226940525
INFO:root:final train perplexity: 5.744088172912598
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.32s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 4392.576528562721
INFO:root:eval perplexity: 5.90753698348999
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.32s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 5273.76503629211
INFO:root:eval perplexity: 8.640970230102539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/24
 12%|█▏        | 24/200 [1:05:51<8:02:30, 164.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4383.007651528159
INFO:root:current train perplexity5.689882755279541
INFO:root:current mean train loss 4397.85225657518
INFO:root:current train perplexity5.693603992462158
INFO:root:current mean train loss 4412.893786243557
INFO:root:current train perplexity5.710911750793457
INFO:root:current mean train loss 4413.894973325608
INFO:root:current train perplexity5.705761432647705
INFO:root:current mean train loss 4412.769136945488
INFO:root:current train perplexity5.702479839324951
INFO:root:current mean train loss 4416.794502167936
INFO:root:current train perplexity5.704622745513916
INFO:root:current mean train loss 4415.371639621586
INFO:root:current train perplexity5.699134826660156
INFO:root:current mean train loss 4412.517373491328
INFO:root:current train perplexity5.691046714782715
INFO:root:current mean train loss 4413.902452530951
INFO:root:current train perplexity5.693869113922119
INFO:root:current mean train loss 4413.831229108855
INFO:root:current train perplexity5.697692394256592

100%|██████████| 1/1 [02:27<00:00, 147.44s/it][A100%|██████████| 1/1 [02:27<00:00, 147.44s/it]
INFO:root:final mean train loss: 4410.422420132545
INFO:root:final train perplexity: 5.697566986083984
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 4384.041964483599
INFO:root:eval perplexity: 5.887184143066406
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.33s/it][A100%|██████████| 1/1 [00:08<00:00,  8.33s/it]
INFO:root:eval mean loss: 5268.621865996232
INFO:root:eval perplexity: 8.622817039489746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/25
 12%|█▎        | 25/200 [1:08:35<7:59:38, 164.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4336.572980784406
INFO:root:current train perplexity5.6050848960876465
INFO:root:current mean train loss 4360.542392136464
INFO:root:current train perplexity5.610448837280273
INFO:root:current mean train loss 4358.602250013065
INFO:root:current train perplexity5.612342357635498
INFO:root:current mean train loss 4364.378743489583
INFO:root:current train perplexity5.618865966796875
INFO:root:current mean train loss 4375.081759710828
INFO:root:current train perplexity5.628699779510498
INFO:root:current mean train loss 4380.909171535893
INFO:root:current train perplexity5.630330562591553
INFO:root:current mean train loss 4382.599996018307
INFO:root:current train perplexity5.6355390548706055
INFO:root:current mean train loss 4390.4244664350945
INFO:root:current train perplexity5.641045570373535
INFO:root:current mean train loss 4393.9374880509595
INFO:root:current train perplexity5.64844274520874

100%|██████████| 1/1 [02:27<00:00, 147.54s/it][A100%|██████████| 1/1 [02:27<00:00, 147.54s/it]
INFO:root:final mean train loss: 4390.056524338261
INFO:root:final train perplexity: 5.651970863342285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 4371.9349512411345
INFO:root:eval perplexity: 5.858434200286865
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 5255.2192521332
INFO:root:eval perplexity: 8.575688362121582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/26
 13%|█▎        | 26/200 [1:11:19<7:56:58, 164.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4286.071707589285
INFO:root:current train perplexity5.625218391418457
INFO:root:current mean train loss 4363.879243939837
INFO:root:current train perplexity5.581482887268066
INFO:root:current mean train loss 4375.402958229544
INFO:root:current train perplexity5.600844860076904
INFO:root:current mean train loss 4370.10243488523
INFO:root:current train perplexity5.594737529754639
INFO:root:current mean train loss 4371.650707347973
INFO:root:current train perplexity5.605136394500732
INFO:root:current mean train loss 4381.106371636927
INFO:root:current train perplexity5.608263969421387
INFO:root:current mean train loss 4376.468844519023
INFO:root:current train perplexity5.609610080718994
INFO:root:current mean train loss 4369.948400343662
INFO:root:current train perplexity5.604487419128418
INFO:root:current mean train loss 4372.642090751336
INFO:root:current train perplexity5.6116414070129395
INFO:root:current mean train loss 4371.810732874087
INFO:root:current train perplexity5.609865665435791

100%|██████████| 1/1 [02:27<00:00, 147.63s/it][A100%|██████████| 1/1 [02:27<00:00, 147.63s/it]
INFO:root:final mean train loss: 4370.225822079567
INFO:root:final train perplexity: 5.607923984527588
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.28s/it][A100%|██████████| 1/1 [00:08<00:00,  8.28s/it]
INFO:root:eval mean loss: 4360.393149517952
INFO:root:eval perplexity: 5.831153392791748
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 5248.490997963763
INFO:root:eval perplexity: 8.552127838134766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/27
 14%|█▎        | 27/200 [1:14:04<7:54:14, 164.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4378.517447916666
INFO:root:current train perplexity5.676895618438721
INFO:root:current mean train loss 4370.945911175272
INFO:root:current train perplexity5.578240871429443
INFO:root:current mean train loss 4348.473363690044
INFO:root:current train perplexity5.557250499725342
INFO:root:current mean train loss 4337.921989707342
INFO:root:current train perplexity5.54401969909668
INFO:root:current mean train loss 4346.168240540286
INFO:root:current train perplexity5.553458213806152
INFO:root:current mean train loss 4348.770449977245
INFO:root:current train perplexity5.55764627456665
INFO:root:current mean train loss 4355.354761337652
INFO:root:current train perplexity5.5665602684021
INFO:root:current mean train loss 4356.107478898055
INFO:root:current train perplexity5.566681861877441
INFO:root:current mean train loss 4356.3865339220665
INFO:root:current train perplexity5.568210124969482
INFO:root:current mean train loss 4354.660405727032
INFO:root:current train perplexity5.565608024597168

100%|██████████| 1/1 [02:27<00:00, 147.38s/it][A100%|██████████| 1/1 [02:27<00:00, 147.38s/it]
INFO:root:final mean train loss: 4352.414382319296
INFO:root:final train perplexity: 5.568654537200928
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 4352.195638020833
INFO:root:eval perplexity: 5.811856746673584
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.33s/it][A100%|██████████| 1/1 [00:08<00:00,  8.33s/it]
INFO:root:eval mean loss: 5247.091341492132
INFO:root:eval perplexity: 8.547231674194336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/28
 14%|█▍        | 28/200 [1:16:48<7:51:21, 164.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4317.087497877038
INFO:root:current train perplexity5.480751991271973
INFO:root:current mean train loss 4295.75329093623
INFO:root:current train perplexity5.489034175872803
INFO:root:current mean train loss 4301.201340474356
INFO:root:current train perplexity5.502516746520996
INFO:root:current mean train loss 4313.348733340993
INFO:root:current train perplexity5.517600059509277
INFO:root:current mean train loss 4321.4709438026375
INFO:root:current train perplexity5.517555236816406
INFO:root:current mean train loss 4327.707181562201
INFO:root:current train perplexity5.520072937011719
INFO:root:current mean train loss 4331.818410319272
INFO:root:current train perplexity5.518895626068115
INFO:root:current mean train loss 4329.415528019104
INFO:root:current train perplexity5.516077995300293
INFO:root:current mean train loss 4335.72781939408
INFO:root:current train perplexity5.519832611083984
INFO:root:current mean train loss 4335.877469179561
INFO:root:current train perplexity5.525528907775879

100%|██████████| 1/1 [02:27<00:00, 147.36s/it][A100%|██████████| 1/1 [02:27<00:00, 147.36s/it]
INFO:root:final mean train loss: 4334.299713626985
INFO:root:final train perplexity: 5.528997421264648
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.30s/it][A100%|██████████| 1/1 [00:08<00:00,  8.30s/it]
INFO:root:eval mean loss: 4344.708189619349
INFO:root:eval perplexity: 5.79428768157959
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.34s/it][A100%|██████████| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 5235.646035918107
INFO:root:eval perplexity: 8.50732707977295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/29
 14%|█▍        | 29/200 [1:19:33<7:48:33, 164.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4284.348743069557
INFO:root:current train perplexity5.431588649749756
INFO:root:current mean train loss 4309.858840127028
INFO:root:current train perplexity5.474750518798828
INFO:root:current mean train loss 4312.62136431277
INFO:root:current train perplexity5.467526435852051
INFO:root:current mean train loss 4319.184219222055
INFO:root:current train perplexity5.480912208557129
INFO:root:current mean train loss 4315.46482562355
INFO:root:current train perplexity5.48045539855957
INFO:root:current mean train loss 4323.7524703720865
INFO:root:current train perplexity5.490281581878662
INFO:root:current mean train loss 4321.821645020305
INFO:root:current train perplexity5.491765022277832
INFO:root:current mean train loss 4322.124276929612
INFO:root:current train perplexity5.490316390991211
INFO:root:current mean train loss 4323.6124944767225
INFO:root:current train perplexity5.49074125289917
INFO:root:current mean train loss 4323.371289639416
INFO:root:current train perplexity5.493856430053711

100%|██████████| 1/1 [02:27<00:00, 147.51s/it][A100%|██████████| 1/1 [02:27<00:00, 147.51s/it]
INFO:root:final mean train loss: 4317.369445431617
INFO:root:final train perplexity: 5.492191791534424
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 4335.573533078457
INFO:root:eval perplexity: 5.772923946380615
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.34s/it][A100%|██████████| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 5232.610727296654
INFO:root:eval perplexity: 8.496771812438965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/30
 15%|█▌        | 30/200 [1:22:17<7:45:52, 164.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4293.781331380208
INFO:root:current train perplexity5.473323345184326
INFO:root:current mean train loss 4274.509892086331
INFO:root:current train perplexity5.447779178619385
INFO:root:current mean train loss 4286.639905857741
INFO:root:current train perplexity5.444156169891357
INFO:root:current mean train loss 4285.651698469764
INFO:root:current train perplexity5.435076713562012
INFO:root:current mean train loss 4284.205504675932
INFO:root:current train perplexity5.4287190437316895
INFO:root:current mean train loss 4289.163321925006
INFO:root:current train perplexity5.433687686920166
INFO:root:current mean train loss 4287.214859796802
INFO:root:current train perplexity5.435037612915039
INFO:root:current mean train loss 4293.484994106267
INFO:root:current train perplexity5.444244384765625
INFO:root:current mean train loss 4297.556594066597
INFO:root:current train perplexity5.450020790100098
INFO:root:current mean train loss 4298.615841996556
INFO:root:current train perplexity5.450146198272705

100%|██████████| 1/1 [02:27<00:00, 147.54s/it][A100%|██████████| 1/1 [02:27<00:00, 147.54s/it]
INFO:root:final mean train loss: 4300.54798704578
INFO:root:final train perplexity: 5.455861568450928
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.25s/it][A100%|██████████| 1/1 [00:08<00:00,  8.25s/it]
INFO:root:eval mean loss: 4328.239630083665
INFO:root:eval perplexity: 5.755827903747559
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.30s/it][A100%|██████████| 1/1 [00:08<00:00,  8.30s/it]
INFO:root:eval mean loss: 5227.231850482048
INFO:root:eval perplexity: 8.478102684020996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/31
 16%|█▌        | 31/200 [1:25:01<7:43:03, 164.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4255.908135596742
INFO:root:current train perplexity5.389986991882324
INFO:root:current mean train loss 4280.298765013818
INFO:root:current train perplexity5.396146297454834
INFO:root:current mean train loss 4279.747021879744
INFO:root:current train perplexity5.412410736083984
INFO:root:current mean train loss 4275.99474077472
INFO:root:current train perplexity5.408151626586914
INFO:root:current mean train loss 4285.116474194281
INFO:root:current train perplexity5.414254188537598
INFO:root:current mean train loss 4281.868074797189
INFO:root:current train perplexity5.410511493682861
INFO:root:current mean train loss 4279.502940630434
INFO:root:current train perplexity5.406578540802002
INFO:root:current mean train loss 4285.7710555764725
INFO:root:current train perplexity5.415724754333496
INFO:root:current mean train loss 4288.679173565249
INFO:root:current train perplexity5.418671131134033
INFO:root:current mean train loss 4287.382300242954
INFO:root:current train perplexity5.421243667602539

100%|██████████| 1/1 [02:27<00:00, 147.43s/it][A100%|██████████| 1/1 [02:27<00:00, 147.43s/it]
INFO:root:final mean train loss: 4285.111344921974
INFO:root:final train perplexity: 5.422735691070557
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.22s/it][A100%|██████████| 1/1 [00:08<00:00,  8.22s/it]
INFO:root:eval mean loss: 4323.019288840869
INFO:root:eval perplexity: 5.743690490722656
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.32s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 5224.227130429965
INFO:root:eval perplexity: 8.467693328857422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/32
 16%|█▌        | 32/200 [1:27:46<7:40:11, 164.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4200.573828125
INFO:root:current train perplexity5.304117202758789
INFO:root:current mean train loss 4238.427416204637
INFO:root:current train perplexity5.344723224639893
INFO:root:current mean train loss 4245.396196193321
INFO:root:current train perplexity5.355596542358398
INFO:root:current mean train loss 4260.764533588248
INFO:root:current train perplexity5.374404430389404
INFO:root:current mean train loss 4262.933080786401
INFO:root:current train perplexity5.371006965637207
INFO:root:current mean train loss 4267.546570594031
INFO:root:current train perplexity5.376498699188232
INFO:root:current mean train loss 4273.524176258349
INFO:root:current train perplexity5.383190155029297
INFO:root:current mean train loss 4271.8277482796975
INFO:root:current train perplexity5.379724025726318
INFO:root:current mean train loss 4273.973386101974
INFO:root:current train perplexity5.386034965515137
INFO:root:current mean train loss 4273.514683716459
INFO:root:current train perplexity5.387257099151611

100%|██████████| 1/1 [02:27<00:00, 147.87s/it][A100%|██████████| 1/1 [02:27<00:00, 147.87s/it]
INFO:root:final mean train loss: 4268.970987566056
INFO:root:final train perplexity: 5.3883137702941895
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.25s/it][A100%|██████████| 1/1 [00:08<00:00,  8.25s/it]
INFO:root:eval mean loss: 4314.4564581255545
INFO:root:eval perplexity: 5.7238383293151855
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 5217.528580036569
INFO:root:eval perplexity: 8.44453239440918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/33
 16%|█▋        | 33/200 [1:30:30<7:37:46, 164.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4224.877197265625
INFO:root:current train perplexity5.321066379547119
INFO:root:current mean train loss 4221.976228491661
INFO:root:current train perplexity5.303831577301025
INFO:root:current mean train loss 4228.3882587853495
INFO:root:current train perplexity5.30859899520874
INFO:root:current mean train loss 4230.62757928181
INFO:root:current train perplexity5.32603645324707
INFO:root:current mean train loss 4238.855207735725
INFO:root:current train perplexity5.330638408660889
INFO:root:current mean train loss 4244.920283966336
INFO:root:current train perplexity5.334087371826172
INFO:root:current mean train loss 4245.781132164404
INFO:root:current train perplexity5.337409973144531
INFO:root:current mean train loss 4253.065245382127
INFO:root:current train perplexity5.344499588012695
INFO:root:current mean train loss 4256.426574494858
INFO:root:current train perplexity5.350283622741699
INFO:root:current mean train loss 4255.452228803625
INFO:root:current train perplexity5.354781150817871

100%|██████████| 1/1 [02:27<00:00, 147.65s/it][A100%|██████████| 1/1 [02:27<00:00, 147.65s/it]
INFO:root:final mean train loss: 4253.3103467879755
INFO:root:final train perplexity: 5.355125427246094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.23s/it][A100%|██████████| 1/1 [00:08<00:00,  8.23s/it]
INFO:root:eval mean loss: 4310.156045683732
INFO:root:eval perplexity: 5.713893413543701
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.30s/it][A100%|██████████| 1/1 [00:08<00:00,  8.30s/it]
INFO:root:eval mean loss: 5216.655384253103
INFO:root:eval perplexity: 8.441516876220703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/34
 17%|█▋        | 34/200 [1:33:15<7:35:01, 164.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4215.646243672975
INFO:root:current train perplexity5.292305946350098
INFO:root:current mean train loss 4227.646013226426
INFO:root:current train perplexity5.298347473144531
INFO:root:current mean train loss 4235.207001520699
INFO:root:current train perplexity5.311227321624756
INFO:root:current mean train loss 4237.868522705736
INFO:root:current train perplexity5.320489406585693
INFO:root:current mean train loss 4235.321788229001
INFO:root:current train perplexity5.316850185394287
INFO:root:current mean train loss 4239.691266435667
INFO:root:current train perplexity5.320456027984619
INFO:root:current mean train loss 4244.041866296805
INFO:root:current train perplexity5.326299667358398
INFO:root:current mean train loss 4239.75085433386
INFO:root:current train perplexity5.3204665184021
INFO:root:current mean train loss 4242.2214568496165
INFO:root:current train perplexity5.323544025421143
INFO:root:current mean train loss 4243.061322040342
INFO:root:current train perplexity5.326779842376709

100%|██████████| 1/1 [02:27<00:00, 147.76s/it][A100%|██████████| 1/1 [02:27<00:00, 147.76s/it]
INFO:root:final mean train loss: 4239.983851709673
INFO:root:final train perplexity: 5.327043533325195
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.24s/it][A100%|██████████| 1/1 [00:08<00:00,  8.25s/it]
INFO:root:eval mean loss: 4303.052453873005
INFO:root:eval perplexity: 5.697503089904785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 5212.23319758422
INFO:root:eval perplexity: 8.42626667022705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/35
 18%|█▊        | 35/200 [1:35:59<7:32:23, 164.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4220.207086876978
INFO:root:current train perplexity5.284841537475586
INFO:root:current mean train loss 4215.843816831792
INFO:root:current train perplexity5.263021469116211
INFO:root:current mean train loss 4224.182674941197
INFO:root:current train perplexity5.27510404586792
INFO:root:current mean train loss 4222.29395884008
INFO:root:current train perplexity5.289272785186768
INFO:root:current mean train loss 4226.482639511841
INFO:root:current train perplexity5.289440631866455
INFO:root:current mean train loss 4229.436756614989
INFO:root:current train perplexity5.290231704711914
INFO:root:current mean train loss 4227.564791110549
INFO:root:current train perplexity5.290419101715088
INFO:root:current mean train loss 4227.627957266929
INFO:root:current train perplexity5.294938564300537
INFO:root:current mean train loss 4229.633653243654
INFO:root:current train perplexity5.29649543762207
INFO:root:current mean train loss 4230.4098644782625
INFO:root:current train perplexity5.298924446105957

100%|██████████| 1/1 [02:27<00:00, 147.52s/it][A100%|██████████| 1/1 [02:27<00:00, 147.52s/it]
INFO:root:final mean train loss: 4226.641783068257
INFO:root:final train perplexity: 5.299076557159424
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.25s/it][A100%|██████████| 1/1 [00:08<00:00,  8.26s/it]
INFO:root:eval mean loss: 4297.6930667525485
INFO:root:eval perplexity: 5.6851701736450195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.30s/it][A100%|██████████| 1/1 [00:08<00:00,  8.30s/it]
INFO:root:eval mean loss: 5207.284003075133
INFO:root:eval perplexity: 8.40923023223877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/36
 18%|█▊        | 36/200 [1:38:44<7:29:33, 164.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4194.937384945223
INFO:root:current train perplexity5.248105049133301
INFO:root:current mean train loss 4210.700639204545
INFO:root:current train perplexity5.24190616607666
INFO:root:current mean train loss 4216.487105632077
INFO:root:current train perplexity5.262223243713379
INFO:root:current mean train loss 4223.595371295623
INFO:root:current train perplexity5.274061679840088
INFO:root:current mean train loss 4221.822663168154
INFO:root:current train perplexity5.277309417724609
INFO:root:current mean train loss 4223.123539731288
INFO:root:current train perplexity5.27691125869751
INFO:root:current mean train loss 4219.386269204308
INFO:root:current train perplexity5.271666049957275
INFO:root:current mean train loss 4220.105197620513
INFO:root:current train perplexity5.269901275634766
INFO:root:current mean train loss 4219.887580811373
INFO:root:current train perplexity5.27199125289917
INFO:root:current mean train loss 4215.966078305075
INFO:root:current train perplexity5.2689595222473145

100%|██████████| 1/1 [02:27<00:00, 147.81s/it][A100%|██████████| 1/1 [02:27<00:00, 147.82s/it]
INFO:root:final mean train loss: 4212.724272943312
INFO:root:final train perplexity: 5.270059585571289
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 4291.700809992797
INFO:root:eval perplexity: 5.67141056060791
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 5206.938911167443
INFO:root:eval perplexity: 8.408044815063477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/37
 18%|█▊        | 37/200 [1:41:29<7:27:00, 164.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4227.6880062705595
INFO:root:current train perplexity5.258878231048584
INFO:root:current mean train loss 4230.509605368589
INFO:root:current train perplexity5.244450092315674
INFO:root:current mean train loss 4214.2008391816735
INFO:root:current train perplexity5.234668731689453
INFO:root:current mean train loss 4205.050949985166
INFO:root:current train perplexity5.234525203704834
INFO:root:current mean train loss 4199.054860124685
INFO:root:current train perplexity5.2339324951171875
INFO:root:current mean train loss 4201.321781857274
INFO:root:current train perplexity5.235874176025391
INFO:root:current mean train loss 4203.833883205935
INFO:root:current train perplexity5.242430686950684
INFO:root:current mean train loss 4206.276896005306
INFO:root:current train perplexity5.247378826141357
INFO:root:current mean train loss 4204.565393407384
INFO:root:current train perplexity5.2443389892578125

100%|██████████| 1/1 [02:27<00:00, 147.48s/it][A100%|██████████| 1/1 [02:27<00:00, 147.48s/it]
INFO:root:final mean train loss: 4199.970467044461
INFO:root:final train perplexity: 5.243607997894287
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.27s/it][A100%|██████████| 1/1 [00:08<00:00,  8.27s/it]
INFO:root:eval mean loss: 4288.05870802859
INFO:root:eval perplexity: 5.6630635261535645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 5204.5075129515735
INFO:root:eval perplexity: 8.399687767028809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/38
 19%|█▉        | 38/200 [1:44:13<7:24:07, 164.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4293.826171875
INFO:root:current train perplexity5.079526424407959
INFO:root:current mean train loss 4155.608834572209
INFO:root:current train perplexity5.138724327087402
INFO:root:current mean train loss 4171.653534386545
INFO:root:current train perplexity5.187820911407471
INFO:root:current mean train loss 4198.122262079723
INFO:root:current train perplexity5.219102382659912
INFO:root:current mean train loss 4200.118786227318
INFO:root:current train perplexity5.220395088195801
INFO:root:current mean train loss 4194.083005385655
INFO:root:current train perplexity5.218504428863525
INFO:root:current mean train loss 4196.463652602871
INFO:root:current train perplexity5.221977233886719
INFO:root:current mean train loss 4191.801824491021
INFO:root:current train perplexity5.221426010131836
INFO:root:current mean train loss 4189.74786871011
INFO:root:current train perplexity5.218666076660156
INFO:root:current mean train loss 4190.603113590549
INFO:root:current train perplexity5.217345714569092

100%|██████████| 1/1 [02:27<00:00, 147.50s/it][A100%|██████████| 1/1 [02:27<00:00, 147.50s/it]
INFO:root:final mean train loss: 4186.195015691942
INFO:root:final train perplexity: 5.215187072753906
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.28s/it][A100%|██████████| 1/1 [00:08<00:00,  8.28s/it]
INFO:root:eval mean loss: 4282.961327086104
INFO:root:eval perplexity: 5.651401996612549
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 5196.900243448027
INFO:root:eval perplexity: 8.373601913452148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/39
 20%|█▉        | 39/200 [1:46:57<7:21:19, 164.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4161.691805752841
INFO:root:current train perplexity5.185283660888672
INFO:root:current mean train loss 4212.030390009149
INFO:root:current train perplexity5.214231491088867
INFO:root:current mean train loss 4177.064050466528
INFO:root:current train perplexity5.184791088104248
INFO:root:current mean train loss 4177.688733263414
INFO:root:current train perplexity5.191429615020752
INFO:root:current mean train loss 4168.57153557919
INFO:root:current train perplexity5.176312446594238
INFO:root:current mean train loss 4168.684661088858
INFO:root:current train perplexity5.177899360656738
INFO:root:current mean train loss 4169.847922766852
INFO:root:current train perplexity5.180275917053223
INFO:root:current mean train loss 4173.267551341641
INFO:root:current train perplexity5.18142032623291
INFO:root:current mean train loss 4175.074940635596
INFO:root:current train perplexity5.187058448791504
INFO:root:current mean train loss 4174.311920601503
INFO:root:current train perplexity5.186056613922119

100%|██████████| 1/1 [02:27<00:00, 147.54s/it][A100%|██████████| 1/1 [02:27<00:00, 147.54s/it]
INFO:root:final mean train loss: 4172.500206239762
INFO:root:final train perplexity: 5.187085151672363
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.26s/it][A100%|██████████| 1/1 [00:08<00:00,  8.26s/it]
INFO:root:eval mean loss: 4277.586687236813
INFO:root:eval perplexity: 5.639133453369141
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.46s/it][A100%|██████████| 1/1 [00:08<00:00,  8.46s/it]
INFO:root:eval mean loss: 5196.312132923315
INFO:root:eval perplexity: 8.371585845947266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/40
 20%|██        | 40/200 [1:49:42<7:18:40, 164.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4177.786839535362
INFO:root:current train perplexity5.1674628257751465
INFO:root:current mean train loss 4145.40844111082
INFO:root:current train perplexity5.1247029304504395
INFO:root:current mean train loss 4163.6486392783245
INFO:root:current train perplexity5.141091823577881
INFO:root:current mean train loss 4158.955192924667
INFO:root:current train perplexity5.1463704109191895
INFO:root:current mean train loss 4165.427176755482
INFO:root:current train perplexity5.148551940917969
INFO:root:current mean train loss 4169.695460677836
INFO:root:current train perplexity5.153012275695801
INFO:root:current mean train loss 4171.431506919553
INFO:root:current train perplexity5.159555912017822
INFO:root:current mean train loss 4170.890316683328
INFO:root:current train perplexity5.161504745483398
INFO:root:current mean train loss 4163.842687585851
INFO:root:current train perplexity5.16323184967041
INFO:root:current mean train loss 4164.421473589245
INFO:root:current train perplexity5.164021015167236

100%|██████████| 1/1 [02:27<00:00, 147.19s/it][A100%|██████████| 1/1 [02:27<00:00, 147.20s/it]
INFO:root:final mean train loss: 4162.27002070027
INFO:root:final train perplexity: 5.166192531585693
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.30s/it][A100%|██████████| 1/1 [00:08<00:00,  8.30s/it]
INFO:root:eval mean loss: 4274.322650016622
INFO:root:eval perplexity: 5.63169527053833
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 5196.336692431294
INFO:root:eval perplexity: 8.37166976928711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/41
 20%|██        | 41/200 [1:52:26<7:15:38, 164.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4133.057119864005
INFO:root:current train perplexity5.10310697555542
INFO:root:current mean train loss 4150.06855353408
INFO:root:current train perplexity5.116385459899902
INFO:root:current mean train loss 4141.462042048114
INFO:root:current train perplexity5.1385040283203125
INFO:root:current mean train loss 4143.788933336917
INFO:root:current train perplexity5.129182815551758
INFO:root:current mean train loss 4146.1328651017275
INFO:root:current train perplexity5.120612144470215
INFO:root:current mean train loss 4152.7337208699
INFO:root:current train perplexity5.1308512687683105
INFO:root:current mean train loss 4146.1049886457085
INFO:root:current train perplexity5.1315484046936035
INFO:root:current mean train loss 4149.559927288407
INFO:root:current train perplexity5.131763935089111
INFO:root:current mean train loss 4151.033117218202
INFO:root:current train perplexity5.139591693878174
INFO:root:current mean train loss 4154.7435959833465
INFO:root:current train perplexity5.14370059967041

100%|██████████| 1/1 [02:27<00:00, 147.68s/it][A100%|██████████| 1/1 [02:27<00:00, 147.68s/it]
INFO:root:final mean train loss: 4150.206221672796
INFO:root:final train perplexity: 5.141663074493408
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 4270.32811114805
INFO:root:eval perplexity: 5.622607231140137
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.41s/it][A100%|██████████| 1/1 [00:08<00:00,  8.41s/it]
INFO:root:eval mean loss: 5192.792478737256
INFO:root:eval perplexity: 8.35954761505127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/42
 21%|██        | 42/200 [1:55:11<7:13:08, 164.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4127.222663225446
INFO:root:current train perplexity5.0926690101623535
INFO:root:current mean train loss 4124.852971281829
INFO:root:current train perplexity5.062007904052734
INFO:root:current mean train loss 4131.136183718418
INFO:root:current train perplexity5.080185890197754
INFO:root:current mean train loss 4128.843731051772
INFO:root:current train perplexity5.091604709625244
INFO:root:current mean train loss 4126.363412019577
INFO:root:current train perplexity5.094724655151367
INFO:root:current mean train loss 4125.131240873247
INFO:root:current train perplexity5.100039482116699
INFO:root:current mean train loss 4130.901272607038
INFO:root:current train perplexity5.102398872375488
INFO:root:current mean train loss 4133.797707403274
INFO:root:current train perplexity5.11013126373291
INFO:root:current mean train loss 4137.638643513754
INFO:root:current train perplexity5.113026142120361
INFO:root:current mean train loss 4139.907196273396
INFO:root:current train perplexity5.115464210510254

100%|██████████| 1/1 [02:28<00:00, 148.11s/it][A100%|██████████| 1/1 [02:28<00:00, 148.11s/it]
INFO:root:final mean train loss: 4137.027155414705
INFO:root:final train perplexity: 5.114997386932373
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.27s/it][A100%|██████████| 1/1 [00:08<00:00,  8.27s/it]
INFO:root:eval mean loss: 4267.174631538121
INFO:root:eval perplexity: 5.615440368652344
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.37s/it][A100%|██████████| 1/1 [00:08<00:00,  8.37s/it]
INFO:root:eval mean loss: 5193.735955853835
INFO:root:eval perplexity: 8.362771034240723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/43
 22%|██▏       | 43/200 [1:57:56<7:10:46, 164.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4124.0005280250725
INFO:root:current train perplexity5.092635631561279
INFO:root:current mean train loss 4127.526923759834
INFO:root:current train perplexity5.0857319831848145
INFO:root:current mean train loss 4118.5679504645705
INFO:root:current train perplexity5.081910133361816
INFO:root:current mean train loss 4111.706938006788
INFO:root:current train perplexity5.072232246398926
INFO:root:current mean train loss 4116.02049238149
INFO:root:current train perplexity5.0800700187683105
INFO:root:current mean train loss 4118.967730274517
INFO:root:current train perplexity5.0854620933532715
INFO:root:current mean train loss 4120.246948811722
INFO:root:current train perplexity5.086517810821533
INFO:root:current mean train loss 4122.295020122708
INFO:root:current train perplexity5.087228298187256
INFO:root:current mean train loss 4126.460719134601
INFO:root:current train perplexity5.091602325439453
INFO:root:current mean train loss 4128.80906908636
INFO:root:current train perplexity5.09514856338501

100%|██████████| 1/1 [02:27<00:00, 147.33s/it][A100%|██████████| 1/1 [02:27<00:00, 147.33s/it]
INFO:root:final mean train loss: 4126.503025916315
INFO:root:final train perplexity: 5.093803405761719
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.25s/it][A100%|██████████| 1/1 [00:08<00:00,  8.25s/it]
INFO:root:eval mean loss: 4263.1844335244905
INFO:root:eval perplexity: 5.606386661529541
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 5189.184291541999
INFO:root:eval perplexity: 8.347221374511719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/44
 22%|██▏       | 44/200 [2:00:40<7:07:43, 164.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4118.144311044731
INFO:root:current train perplexity5.045165538787842
INFO:root:current mean train loss 4109.934625284562
INFO:root:current train perplexity5.044739723205566
INFO:root:current mean train loss 4107.612186021539
INFO:root:current train perplexity5.041727066040039
INFO:root:current mean train loss 4114.08993765024
INFO:root:current train perplexity5.04684591293335
INFO:root:current mean train loss 4116.506535498372
INFO:root:current train perplexity5.05298376083374
INFO:root:current mean train loss 4114.263700232532
INFO:root:current train perplexity5.054574012756348
INFO:root:current mean train loss 4115.620508712557
INFO:root:current train perplexity5.05798864364624
INFO:root:current mean train loss 4117.474562562416
INFO:root:current train perplexity5.059767723083496
INFO:root:current mean train loss 4113.836586724718
INFO:root:current train perplexity5.060800552368164
INFO:root:current mean train loss 4116.801046698377
INFO:root:current train perplexity5.068646430969238

100%|██████████| 1/1 [02:27<00:00, 147.33s/it][A100%|██████████| 1/1 [02:27<00:00, 147.33s/it]
INFO:root:final mean train loss: 4116.054231766731
INFO:root:final train perplexity: 5.072848796844482
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 4259.423907773715
INFO:root:eval perplexity: 5.5978684425354
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.40s/it][A100%|██████████| 1/1 [00:08<00:00,  8.40s/it]
INFO:root:eval mean loss: 5189.711405003324
INFO:root:eval perplexity: 8.349020004272461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/45
 22%|██▎       | 45/200 [2:03:24<7:04:49, 164.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4116.051149529926
INFO:root:current train perplexity5.017579555511475
INFO:root:current mean train loss 4120.92753783412
INFO:root:current train perplexity5.0658860206604
INFO:root:current mean train loss 4105.070185245234
INFO:root:current train perplexity5.043710231781006
INFO:root:current mean train loss 4104.790740201733
INFO:root:current train perplexity5.0422797203063965
INFO:root:current mean train loss 4107.638935163909
INFO:root:current train perplexity5.04428768157959
INFO:root:current mean train loss 4103.932104885258
INFO:root:current train perplexity5.042350769042969
INFO:root:current mean train loss 4103.340052325375
INFO:root:current train perplexity5.044266223907471
INFO:root:current mean train loss 4104.414927767828
INFO:root:current train perplexity5.042758941650391
INFO:root:current mean train loss 4105.867578579744
INFO:root:current train perplexity5.0464324951171875
INFO:root:current mean train loss 4106.764580719662
INFO:root:current train perplexity5.048959732055664

100%|██████████| 1/1 [02:28<00:00, 148.20s/it][A100%|██████████| 1/1 [02:28<00:00, 148.20s/it]
INFO:root:final mean train loss: 4103.822568462741
INFO:root:final train perplexity: 5.048427104949951
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.69s/it][A100%|██████████| 1/1 [00:08<00:00,  8.69s/it]
INFO:root:eval mean loss: 4255.962582419104
INFO:root:eval perplexity: 5.5900397300720215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.80s/it][A100%|██████████| 1/1 [00:08<00:00,  8.80s/it]
INFO:root:eval mean loss: 5184.179261552526
INFO:root:eval perplexity: 8.330155372619629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/46
 23%|██▎       | 46/200 [2:06:10<7:03:15, 164.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4055.310652547808
INFO:root:current train perplexity4.947399139404297
INFO:root:current mean train loss 4052.4898045705463
INFO:root:current train perplexity4.981917381286621
INFO:root:current mean train loss 4064.3654346251756
INFO:root:current train perplexity4.987855434417725
INFO:root:current mean train loss 4071.35126514071
INFO:root:current train perplexity5.004536151885986
INFO:root:current mean train loss 4078.3612648680073
INFO:root:current train perplexity5.0121660232543945
INFO:root:current mean train loss 4085.996833922371
INFO:root:current train perplexity5.016908168792725
INFO:root:current mean train loss 4088.205475631325
INFO:root:current train perplexity5.018871784210205
INFO:root:current mean train loss 4090.5105874908327
INFO:root:current train perplexity5.019664764404297
INFO:root:current mean train loss 4094.810701750829
INFO:root:current train perplexity5.024001598358154
INFO:root:current mean train loss 4094.3994824824686
INFO:root:current train perplexity5.026027679443359

100%|██████████| 1/1 [02:28<00:00, 148.58s/it][A100%|██████████| 1/1 [02:28<00:00, 148.58s/it]
INFO:root:final mean train loss: 4093.6170229757986
INFO:root:final train perplexity: 5.028141975402832
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.63s/it][A100%|██████████| 1/1 [00:08<00:00,  8.63s/it]
INFO:root:eval mean loss: 4253.545920946919
INFO:root:eval perplexity: 5.584579944610596
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.67s/it][A100%|██████████| 1/1 [00:08<00:00,  8.67s/it]
INFO:root:eval mean loss: 5185.398054839871
INFO:root:eval perplexity: 8.334307670593262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/47
 24%|██▎       | 47/200 [2:08:56<7:01:28, 165.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4067.346953125
INFO:root:current train perplexity4.991011142730713
INFO:root:current mean train loss 4080.858324497768
INFO:root:current train perplexity4.997218132019043
INFO:root:current mean train loss 4061.9078053977273
INFO:root:current train perplexity4.978048801422119
INFO:root:current mean train loss 4073.00376171875
INFO:root:current train perplexity4.985946178436279
INFO:root:current mean train loss 4073.343640522204
INFO:root:current train perplexity4.986043930053711
INFO:root:current mean train loss 4081.556963315217
INFO:root:current train perplexity4.995188236236572
INFO:root:current mean train loss 4082.1980179398147
INFO:root:current train perplexity4.998755931854248
INFO:root:current mean train loss 4086.123755985383
INFO:root:current train perplexity5.0059709548950195
INFO:root:current mean train loss 4086.463814453125
INFO:root:current train perplexity5.004811763763428
INFO:root:current mean train loss 4086.0087810496793
INFO:root:current train perplexity5.005359172821045

100%|██████████| 1/1 [02:27<00:00, 147.51s/it][A100%|██████████| 1/1 [02:27<00:00, 147.51s/it]
INFO:root:final mean train loss: 4082.5420131068076
INFO:root:final train perplexity: 5.006219387054443
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.24s/it][A100%|██████████| 1/1 [00:08<00:00,  8.24s/it]
INFO:root:eval mean loss: 4252.257294783355
INFO:root:eval perplexity: 5.581669330596924
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 5184.164488447474
INFO:root:eval perplexity: 8.330105781555176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/48
 24%|██▍       | 48/200 [2:11:41<6:58:03, 165.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4066.2630365210844
INFO:root:current train perplexity4.93821907043457
INFO:root:current mean train loss 4058.5561416709356
INFO:root:current train perplexity4.944774150848389
INFO:root:current mean train loss 4059.5564836158346
INFO:root:current train perplexity4.958370208740234
INFO:root:current mean train loss 4057.550679259138
INFO:root:current train perplexity4.962830066680908
INFO:root:current mean train loss 4065.1142906678638
INFO:root:current train perplexity4.9686408042907715
INFO:root:current mean train loss 4075.7780422518226
INFO:root:current train perplexity4.97659158706665
INFO:root:current mean train loss 4073.5283306786464
INFO:root:current train perplexity4.976506233215332
INFO:root:current mean train loss 4072.6763608891083
INFO:root:current train perplexity4.977739334106445
INFO:root:current mean train loss 4075.468560051405
INFO:root:current train perplexity4.983266353607178
INFO:root:current mean train loss 4073.74558858008
INFO:root:current train perplexity4.9834465980529785

100%|██████████| 1/1 [02:27<00:00, 147.56s/it][A100%|██████████| 1/1 [02:27<00:00, 147.56s/it]
INFO:root:final mean train loss: 4071.9442958831787
INFO:root:final train perplexity: 4.985331058502197
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 4246.809613599845
INFO:root:eval perplexity: 5.569388389587402
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 5184.183043134974
INFO:root:eval perplexity: 8.330169677734375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/49
 24%|██▍       | 49/200 [2:14:25<6:54:53, 164.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4028.243856241415
INFO:root:current train perplexity4.909991264343262
INFO:root:current mean train loss 4030.0008103934883
INFO:root:current train perplexity4.928791522979736
INFO:root:current mean train loss 4049.771839259826
INFO:root:current train perplexity4.9453444480896
INFO:root:current mean train loss 4057.308059263107
INFO:root:current train perplexity4.956862449645996
INFO:root:current mean train loss 4058.1680890800026
INFO:root:current train perplexity4.956753730773926
INFO:root:current mean train loss 4058.7691540919786
INFO:root:current train perplexity4.960556507110596
INFO:root:current mean train loss 4058.774483665544
INFO:root:current train perplexity4.9649882316589355
INFO:root:current mean train loss 4055.604813181495
INFO:root:current train perplexity4.9598917961120605
INFO:root:current mean train loss 4060.12093345565
INFO:root:current train perplexity4.962614059448242
INFO:root:current mean train loss 4066.3304540670724
INFO:root:current train perplexity4.967855930328369

100%|██████████| 1/1 [02:30<00:00, 150.28s/it][A100%|██████████| 1/1 [02:30<00:00, 150.28s/it]
INFO:root:final mean train loss: 4062.9709645548173
INFO:root:final train perplexity: 4.967713356018066
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 4244.896875692598
INFO:root:eval perplexity: 5.565081596374512
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.32s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 5182.5727400543
INFO:root:eval perplexity: 8.324685096740723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/50
 25%|██▌       | 50/200 [2:17:12<6:53:53, 165.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4044.293725832544
INFO:root:current train perplexity4.933568954467773
INFO:root:current mean train loss 4052.1993855998744
INFO:root:current train perplexity4.937978267669678
INFO:root:current mean train loss 4062.2631860433216
INFO:root:current train perplexity4.935993194580078
INFO:root:current mean train loss 4064.9879838757047
INFO:root:current train perplexity4.9428019523620605
INFO:root:current mean train loss 4062.0793261327344
INFO:root:current train perplexity4.945169925689697
INFO:root:current mean train loss 4059.9924503893208
INFO:root:current train perplexity4.9462995529174805
INFO:root:current mean train loss 4060.6657421455875
INFO:root:current train perplexity4.9495697021484375
INFO:root:current mean train loss 4061.647208241259
INFO:root:current train perplexity4.951427936553955
INFO:root:current mean train loss 4057.030728044181
INFO:root:current train perplexity4.947359085083008

100%|██████████| 1/1 [02:30<00:00, 150.28s/it][A100%|██████████| 1/1 [02:30<00:00, 150.28s/it]
INFO:root:final mean train loss: 4052.8357412276728
INFO:root:final train perplexity: 4.9478888511657715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 4242.948299326795
INFO:root:eval perplexity: 5.56069803237915
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.33s/it][A100%|██████████| 1/1 [00:08<00:00,  8.33s/it]
INFO:root:eval mean loss: 5180.543567846853
INFO:root:eval perplexity: 8.317779541015625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/51
 26%|██▌       | 51/200 [2:20:00<6:52:20, 166.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4117.693917410715
INFO:root:current train perplexity4.923282146453857
INFO:root:current mean train loss 4022.9631256388725
INFO:root:current train perplexity4.888930320739746
INFO:root:current mean train loss 4020.49315698596
INFO:root:current train perplexity4.88903284072876
INFO:root:current mean train loss 4021.2087338724045
INFO:root:current train perplexity4.894841194152832
INFO:root:current mean train loss 4024.2353215697945
INFO:root:current train perplexity4.901834487915039
INFO:root:current mean train loss 4031.232081907976
INFO:root:current train perplexity4.908330917358398
INFO:root:current mean train loss 4035.400299323646
INFO:root:current train perplexity4.906931400299072
INFO:root:current mean train loss 4036.756255110723
INFO:root:current train perplexity4.909783840179443
INFO:root:current mean train loss 4039.515880636714
INFO:root:current train perplexity4.915225505828857
INFO:root:current mean train loss 4041.9429421556297
INFO:root:current train perplexity4.921152591705322

100%|██████████| 1/1 [02:28<00:00, 148.06s/it][A100%|██████████| 1/1 [02:28<00:00, 148.06s/it]
INFO:root:final mean train loss: 4042.851907114829
INFO:root:final train perplexity: 4.928437232971191
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.32s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 4238.755701809065
INFO:root:eval perplexity: 5.551280498504639
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.37s/it][A100%|██████████| 1/1 [00:08<00:00,  8.37s/it]
INFO:root:eval mean loss: 5180.151284075798
INFO:root:eval perplexity: 8.316445350646973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/52
 26%|██▌       | 52/200 [2:22:45<6:48:50, 165.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4068.495540364583
INFO:root:current train perplexity4.955973148345947
INFO:root:current mean train loss 4026.8909901494567
INFO:root:current train perplexity4.877647876739502
INFO:root:current mean train loss 4036.192365779433
INFO:root:current train perplexity4.88679313659668
INFO:root:current mean train loss 4034.24431656126
INFO:root:current train perplexity4.889960289001465
INFO:root:current mean train loss 4027.0760024472893
INFO:root:current train perplexity4.883776664733887
INFO:root:current mean train loss 4024.3350334685983
INFO:root:current train perplexity4.889336585998535
INFO:root:current mean train loss 4028.136045874619
INFO:root:current train perplexity4.895111560821533
INFO:root:current mean train loss 4029.0248026387676
INFO:root:current train perplexity4.89748477935791
INFO:root:current mean train loss 4032.0310954275305
INFO:root:current train perplexity4.902050971984863
INFO:root:current mean train loss 4037.6334280545593
INFO:root:current train perplexity4.9101667404174805

100%|██████████| 1/1 [02:28<00:00, 148.38s/it][A100%|██████████| 1/1 [02:28<00:00, 148.38s/it]
INFO:root:final mean train loss: 4034.1168609742194
INFO:root:final train perplexity: 4.911482810974121
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 4240.591658355496
INFO:root:eval perplexity: 5.555401802062988
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 5183.16279850953
INFO:root:eval perplexity: 8.32669448852539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/53
 26%|██▋       | 53/200 [2:25:30<6:45:46, 165.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4053.5492951766305
INFO:root:current train perplexity4.902585983276367
INFO:root:current mean train loss 4026.1477884432165
INFO:root:current train perplexity4.866931915283203
INFO:root:current mean train loss 4020.4667476089544
INFO:root:current train perplexity4.871247291564941
INFO:root:current mean train loss 4020.5231669045083
INFO:root:current train perplexity4.8756256103515625
INFO:root:current mean train loss 4025.275798680371
INFO:root:current train perplexity4.88389253616333
INFO:root:current mean train loss 4031.776128181764
INFO:root:current train perplexity4.892433166503906
INFO:root:current mean train loss 4031.677073275105
INFO:root:current train perplexity4.897871017456055
INFO:root:current mean train loss 4030.5161281390474
INFO:root:current train perplexity4.895698070526123
INFO:root:current mean train loss 4033.7733873666275
INFO:root:current train perplexity4.900057792663574
INFO:root:current mean train loss 4029.5106615126456
INFO:root:current train perplexity4.8944878578186035

100%|██████████| 1/1 [02:29<00:00, 149.08s/it][A100%|██████████| 1/1 [02:29<00:00, 149.08s/it]
INFO:root:final mean train loss: 4024.6373938283614
INFO:root:final train perplexity: 4.893148422241211
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.33s/it][A100%|██████████| 1/1 [00:08<00:00,  8.33s/it]
INFO:root:eval mean loss: 4236.704849567819
INFO:root:eval perplexity: 5.546677112579346
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.28s/it][A100%|██████████| 1/1 [00:08<00:00,  8.28s/it]
INFO:root:eval mean loss: 5183.067026124779
INFO:root:eval perplexity: 8.326369285583496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/54
 27%|██▋       | 54/200 [2:28:16<6:43:19, 165.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3984.9085890246974
INFO:root:current train perplexity4.814614772796631
INFO:root:current mean train loss 3992.430300647066
INFO:root:current train perplexity4.8490071296691895
INFO:root:current mean train loss 4004.3829097334956
INFO:root:current train perplexity4.858757495880127
INFO:root:current mean train loss 4014.518629183582
INFO:root:current train perplexity4.861837863922119
INFO:root:current mean train loss 4020.5732314249203
INFO:root:current train perplexity4.867451190948486
INFO:root:current mean train loss 4020.0893761586335
INFO:root:current train perplexity4.871458053588867
INFO:root:current mean train loss 4021.37533545154
INFO:root:current train perplexity4.870049476623535
INFO:root:current mean train loss 4019.6919095604267
INFO:root:current train perplexity4.871707439422607
INFO:root:current mean train loss 4021.146073067088
INFO:root:current train perplexity4.8738274574279785
INFO:root:current mean train loss 4021.1910574776784
INFO:root:current train perplexity4.876419544219971

100%|██████████| 1/1 [02:28<00:00, 148.50s/it][A100%|██████████| 1/1 [02:28<00:00, 148.50s/it]
INFO:root:final mean train loss: 4015.0104381192114
INFO:root:final train perplexity: 4.874598026275635
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.45s/it][A100%|██████████| 1/1 [00:08<00:00,  8.45s/it]
INFO:root:eval mean loss: 4235.2653254515735
INFO:root:eval perplexity: 5.543449401855469
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.54s/it][A100%|██████████| 1/1 [00:08<00:00,  8.54s/it]
INFO:root:eval mean loss: 5182.856904158355
INFO:root:eval perplexity: 8.325654029846191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/55
 28%|██▊       | 55/200 [2:31:02<6:40:35, 165.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3973.620905949519
INFO:root:current train perplexity4.744411945343018
INFO:root:current mean train loss 3984.090368915805
INFO:root:current train perplexity4.816632270812988
INFO:root:current mean train loss 3985.9875886669715
INFO:root:current train perplexity4.838022232055664
INFO:root:current mean train loss 3996.2776779129795
INFO:root:current train perplexity4.841179847717285
INFO:root:current mean train loss 4004.8521581141445
INFO:root:current train perplexity4.844308376312256
INFO:root:current mean train loss 4002.9806059941734
INFO:root:current train perplexity4.845985412597656
INFO:root:current mean train loss 4003.1718054638595
INFO:root:current train perplexity4.846591949462891
INFO:root:current mean train loss 4003.3326784373944
INFO:root:current train perplexity4.854569911956787
INFO:root:current mean train loss 4005.6334404564586
INFO:root:current train perplexity4.85339879989624
INFO:root:current mean train loss 4009.277803951178
INFO:root:current train perplexity4.857728958129883

100%|██████████| 1/1 [02:28<00:00, 148.27s/it][A100%|██████████| 1/1 [02:28<00:00, 148.27s/it]
INFO:root:final mean train loss: 4006.444828156502
INFO:root:final train perplexity: 4.858153343200684
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.38s/it][A100%|██████████| 1/1 [00:08<00:00,  8.38s/it]
INFO:root:eval mean loss: 4233.960340134641
INFO:root:eval perplexity: 5.540524482727051
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 5180.600005887079
INFO:root:eval perplexity: 8.317974090576172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/56
 28%|██▊       | 56/200 [2:33:47<6:37:29, 165.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3952.7828447057846
INFO:root:current train perplexity4.7903666496276855
INFO:root:current mean train loss 3977.306786777211
INFO:root:current train perplexity4.8136820793151855
INFO:root:current mean train loss 3983.7117756831985
INFO:root:current train perplexity4.824991703033447
INFO:root:current mean train loss 3985.093637427954
INFO:root:current train perplexity4.827526569366455
INFO:root:current mean train loss 3986.9387529275027
INFO:root:current train perplexity4.826859951019287
INFO:root:current mean train loss 3988.290565281507
INFO:root:current train perplexity4.830009460449219
INFO:root:current mean train loss 3993.588047222155
INFO:root:current train perplexity4.830498695373535
INFO:root:current mean train loss 3993.5879883466155
INFO:root:current train perplexity4.827934265136719
INFO:root:current mean train loss 3997.0979868631016
INFO:root:current train perplexity4.833247661590576
INFO:root:current mean train loss 3998.674153473964
INFO:root:current train perplexity4.837531566619873

100%|██████████| 1/1 [02:28<00:00, 148.36s/it][A100%|██████████| 1/1 [02:28<00:00, 148.36s/it]
INFO:root:final mean train loss: 3996.3341527138987
INFO:root:final train perplexity: 4.838812828063965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 4230.521219456449
INFO:root:eval perplexity: 5.532825469970703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.40s/it][A100%|██████████| 1/1 [00:08<00:00,  8.40s/it]
INFO:root:eval mean loss: 5181.174067071143
INFO:root:eval perplexity: 8.319925308227539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/57
 28%|██▊       | 57/200 [2:36:32<6:34:32, 165.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3994.432985617898
INFO:root:current train perplexity4.797680854797363
INFO:root:current mean train loss 3992.1871314264113
INFO:root:current train perplexity4.808911323547363
INFO:root:current mean train loss 3980.9305845971203
INFO:root:current train perplexity4.793097496032715
INFO:root:current mean train loss 3983.8088922205106
INFO:root:current train perplexity4.797382831573486
INFO:root:current mean train loss 3989.428699132898
INFO:root:current train perplexity4.806648254394531
INFO:root:current mean train loss 3993.0862617011544
INFO:root:current train perplexity4.81016206741333
INFO:root:current mean train loss 3989.7071986074666
INFO:root:current train perplexity4.810962200164795
INFO:root:current mean train loss 3990.161004759934
INFO:root:current train perplexity4.81585693359375
INFO:root:current mean train loss 3988.653344012701
INFO:root:current train perplexity4.817839622497559
INFO:root:current mean train loss 3990.0902075323133
INFO:root:current train perplexity4.8228535652160645

100%|██████████| 1/1 [02:28<00:00, 148.79s/it][A100%|██████████| 1/1 [02:28<00:00, 148.79s/it]
INFO:root:final mean train loss: 3988.167677725515
INFO:root:final train perplexity: 4.823247909545898
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 4230.78902613863
INFO:root:eval perplexity: 5.533424377441406
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 5184.023491176307
INFO:root:eval perplexity: 8.329623222351074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/58
 29%|██▉       | 58/200 [2:39:18<6:31:55, 165.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3922.7931625124006
INFO:root:current train perplexity4.754958629608154
INFO:root:current mean train loss 3945.8770235213765
INFO:root:current train perplexity4.75676155090332
INFO:root:current mean train loss 3953.6018679078543
INFO:root:current train perplexity4.774649143218994
INFO:root:current mean train loss 3959.511889581181
INFO:root:current train perplexity4.777337074279785
INFO:root:current mean train loss 3969.842509786717
INFO:root:current train perplexity4.785861492156982
INFO:root:current mean train loss 3972.9437496530863
INFO:root:current train perplexity4.789133071899414
INFO:root:current mean train loss 3974.0664522795296
INFO:root:current train perplexity4.794757843017578
INFO:root:current mean train loss 3979.721544658216
INFO:root:current train perplexity4.800857067108154
INFO:root:current mean train loss 3982.185730192642
INFO:root:current train perplexity4.8028693199157715
INFO:root:current mean train loss 3982.9349650445383
INFO:root:current train perplexity4.809049129486084

100%|██████████| 1/1 [02:28<00:00, 148.54s/it][A100%|██████████| 1/1 [02:28<00:00, 148.54s/it]
INFO:root:final mean train loss: 3979.8446182743196
INFO:root:final train perplexity: 4.807436466217041
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.39s/it][A100%|██████████| 1/1 [00:08<00:00,  8.39s/it]
INFO:root:eval mean loss: 4229.2191014932405
INFO:root:eval perplexity: 5.529913425445557
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.41s/it][A100%|██████████| 1/1 [00:08<00:00,  8.42s/it]
INFO:root:eval mean loss: 5183.458857975953
INFO:root:eval perplexity: 8.3277006149292
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/59
 30%|██▉       | 59/200 [2:42:04<6:29:09, 165.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3971.572265625
INFO:root:current train perplexity4.763156414031982
INFO:root:current mean train loss 3981.1472039473683
INFO:root:current train perplexity4.7768449783325195
INFO:root:current mean train loss 3985.5227942660285
INFO:root:current train perplexity4.780482769012451
INFO:root:current mean train loss 3978.800978668295
INFO:root:current train perplexity4.773532867431641
INFO:root:current mean train loss 3969.8762015243497
INFO:root:current train perplexity4.772331714630127
INFO:root:current mean train loss 3971.703073264421
INFO:root:current train perplexity4.782451152801514
INFO:root:current mean train loss 3972.8529731307053
INFO:root:current train perplexity4.782449245452881
INFO:root:current mean train loss 3968.8973763907466
INFO:root:current train perplexity4.780020713806152
INFO:root:current mean train loss 3971.5520411950165
INFO:root:current train perplexity4.787313938140869
INFO:root:current mean train loss 3974.2361294935954
INFO:root:current train perplexity4.78954553604126

100%|██████████| 1/1 [02:28<00:00, 148.44s/it][A100%|██████████| 1/1 [02:28<00:00, 148.44s/it]
INFO:root:final mean train loss: 3971.1841243620843
INFO:root:final train perplexity: 4.791038513183594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.41s/it][A100%|██████████| 1/1 [00:08<00:00,  8.41s/it]
INFO:root:eval mean loss: 4225.665873642509
INFO:root:eval perplexity: 5.521973133087158
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.39s/it][A100%|██████████| 1/1 [00:08<00:00,  8.39s/it]
INFO:root:eval mean loss: 5181.173660170102
INFO:root:eval perplexity: 8.319923400878906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/60
 30%|███       | 60/200 [2:44:49<6:26:24, 165.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3922.4283957179587
INFO:root:current train perplexity4.733406066894531
INFO:root:current mean train loss 3929.721742427549
INFO:root:current train perplexity4.725411415100098
INFO:root:current mean train loss 3945.1361394629257
INFO:root:current train perplexity4.735295295715332
INFO:root:current mean train loss 3948.630805264677
INFO:root:current train perplexity4.739309787750244
INFO:root:current mean train loss 3953.5486222109867
INFO:root:current train perplexity4.75358772277832
INFO:root:current mean train loss 3956.660904694921
INFO:root:current train perplexity4.758447170257568
INFO:root:current mean train loss 3961.731718577412
INFO:root:current train perplexity4.76383113861084
INFO:root:current mean train loss 3964.6922493029924
INFO:root:current train perplexity4.767902374267578
INFO:root:current mean train loss 3964.2718601682486
INFO:root:current train perplexity4.769870281219482
INFO:root:current mean train loss 3965.570411502889
INFO:root:current train perplexity4.774083137512207

100%|██████████| 1/1 [02:28<00:00, 148.42s/it][A100%|██████████| 1/1 [02:28<00:00, 148.42s/it]
INFO:root:final mean train loss: 3962.330752649615
INFO:root:final train perplexity: 4.774331569671631
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 4224.884561308732
INFO:root:eval perplexity: 5.520226955413818
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 5180.786486037234
INFO:root:eval perplexity: 8.31860637664795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/61
 30%|███       | 61/200 [2:47:35<6:23:29, 165.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3941.335684940733
INFO:root:current train perplexity4.723101615905762
INFO:root:current mean train loss 3937.9405471883356
INFO:root:current train perplexity4.713199615478516
INFO:root:current mean train loss 3939.4589384391334
INFO:root:current train perplexity4.719146728515625
INFO:root:current mean train loss 3942.613840186935
INFO:root:current train perplexity4.731649398803711
INFO:root:current mean train loss 3949.239236255936
INFO:root:current train perplexity4.747354984283447
INFO:root:current mean train loss 3951.605292403109
INFO:root:current train perplexity4.749312877655029
INFO:root:current mean train loss 3955.0557838228938
INFO:root:current train perplexity4.7530317306518555
INFO:root:current mean train loss 3955.4230811229354
INFO:root:current train perplexity4.756375312805176
INFO:root:current mean train loss 3955.7270262846146
INFO:root:current train perplexity4.756515026092529
INFO:root:current mean train loss 3958.220568810553
INFO:root:current train perplexity4.761261463165283

100%|██████████| 1/1 [02:28<00:00, 148.69s/it][A100%|██████████| 1/1 [02:28<00:00, 148.69s/it]
INFO:root:final mean train loss: 3955.2464645139635
INFO:root:final train perplexity: 4.761006832122803
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.32s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 4225.9495477338205
INFO:root:eval perplexity: 5.522606372833252
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.39s/it][A100%|██████████| 1/1 [00:08<00:00,  8.39s/it]
INFO:root:eval mean loss: 5185.526938580452
INFO:root:eval perplexity: 8.334748268127441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/62
 31%|███       | 62/200 [2:50:20<6:20:49, 165.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3960.9652600740133
INFO:root:current train perplexity4.76469612121582
INFO:root:current mean train loss 3938.0892966245992
INFO:root:current train perplexity4.737532615661621
INFO:root:current mean train loss 3939.2426211599577
INFO:root:current train perplexity4.735304355621338
INFO:root:current mean train loss 3937.638286812698
INFO:root:current train perplexity4.729162693023682
INFO:root:current mean train loss 3942.3711223563764
INFO:root:current train perplexity4.729245185852051
INFO:root:current mean train loss 3948.642763589811
INFO:root:current train perplexity4.7389373779296875
INFO:root:current mean train loss 3948.3270985555305
INFO:root:current train perplexity4.740581512451172
INFO:root:current mean train loss 3949.03968498182
INFO:root:current train perplexity4.746574878692627
INFO:root:current mean train loss 3951.21417079478
INFO:root:current train perplexity4.7478156089782715

100%|██████████| 1/1 [02:28<00:00, 148.73s/it][A100%|██████████| 1/1 [02:28<00:00, 148.73s/it]
INFO:root:final mean train loss: 3947.208273118542
INFO:root:final train perplexity: 4.745932579040527
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 4224.88957571476
INFO:root:eval perplexity: 5.52023983001709
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.41s/it][A100%|██████████| 1/1 [00:08<00:00,  8.41s/it]
INFO:root:eval mean loss: 5184.82360233821
INFO:root:eval perplexity: 8.332350730895996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/63
 32%|███▏      | 63/200 [2:53:06<6:18:07, 165.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4125.617594401042
INFO:root:current train perplexity4.742863178253174
INFO:root:current mean train loss 3937.8706647261833
INFO:root:current train perplexity4.7238383293151855
INFO:root:current mean train loss 3937.5188637719366
INFO:root:current train perplexity4.723085880279541
INFO:root:current mean train loss 3934.7495947104476
INFO:root:current train perplexity4.7185187339782715
INFO:root:current mean train loss 3934.7513067278614
INFO:root:current train perplexity4.705564022064209
INFO:root:current mean train loss 3937.8505218687874
INFO:root:current train perplexity4.717089653015137
INFO:root:current mean train loss 3939.5074311061876
INFO:root:current train perplexity4.722087383270264
INFO:root:current mean train loss 3939.9774383501513
INFO:root:current train perplexity4.723082542419434
INFO:root:current mean train loss 3940.0252373910334
INFO:root:current train perplexity4.726394176483154
INFO:root:current mean train loss 3942.309620330236
INFO:root:current train perplexity4.72863245010376

100%|██████████| 1/1 [02:29<00:00, 149.54s/it][A100%|██████████| 1/1 [02:29<00:00, 149.54s/it]
INFO:root:final mean train loss: 3939.8164320914975
INFO:root:final train perplexity: 4.732111930847168
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.52s/it][A100%|██████████| 1/1 [00:08<00:00,  8.52s/it]
INFO:root:eval mean loss: 4222.379004945146
INFO:root:eval perplexity: 5.514638900756836
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.46s/it][A100%|██████████| 1/1 [00:08<00:00,  8.46s/it]
INFO:root:eval mean loss: 5182.905714968418
INFO:root:eval perplexity: 8.32581901550293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/64
 32%|███▏      | 64/200 [2:55:53<6:16:09, 165.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3811.575927734375
INFO:root:current train perplexity4.557109355926514
INFO:root:current mean train loss 3893.0426542264922
INFO:root:current train perplexity4.649248123168945
INFO:root:current mean train loss 3900.97611471601
INFO:root:current train perplexity4.664514541625977
INFO:root:current mean train loss 3908.2894754195136
INFO:root:current train perplexity4.678402423858643
INFO:root:current mean train loss 3919.2746938440923
INFO:root:current train perplexity4.690739631652832
INFO:root:current mean train loss 3927.3571911119434
INFO:root:current train perplexity4.69624137878418
INFO:root:current mean train loss 3925.4471921031095
INFO:root:current train perplexity4.697303771972656
INFO:root:current mean train loss 3931.597150456553
INFO:root:current train perplexity4.705985069274902
INFO:root:current mean train loss 3933.870296906308
INFO:root:current train perplexity4.709057331085205
INFO:root:current mean train loss 3934.0799923675904
INFO:root:current train perplexity4.713263988494873

100%|██████████| 1/1 [02:29<00:00, 149.12s/it][A100%|██████████| 1/1 [02:29<00:00, 149.12s/it]
INFO:root:final mean train loss: 3931.244003234371
INFO:root:final train perplexity: 4.716134548187256
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.43s/it][A100%|██████████| 1/1 [00:08<00:00,  8.43s/it]
INFO:root:eval mean loss: 4221.967139710771
INFO:root:eval perplexity: 5.513720512390137
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.38s/it][A100%|██████████| 1/1 [00:08<00:00,  8.38s/it]
INFO:root:eval mean loss: 5184.548634197695
INFO:root:eval perplexity: 8.331412315368652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/65
 32%|███▎      | 65/200 [2:58:39<6:13:32, 166.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3894.301937705592
INFO:root:current train perplexity4.658258438110352
INFO:root:current mean train loss 3883.148306197479
INFO:root:current train perplexity4.634353160858154
INFO:root:current mean train loss 3897.121715806935
INFO:root:current train perplexity4.650807857513428
INFO:root:current mean train loss 3911.3158261290164
INFO:root:current train perplexity4.676846027374268
INFO:root:current mean train loss 3911.834600844645
INFO:root:current train perplexity4.683139801025391
INFO:root:current mean train loss 3913.765128721851
INFO:root:current train perplexity4.686975002288818
INFO:root:current mean train loss 3920.523972321789
INFO:root:current train perplexity4.689507961273193
INFO:root:current mean train loss 3917.7598966935416
INFO:root:current train perplexity4.692399024963379
INFO:root:current mean train loss 3922.2538069840316
INFO:root:current train perplexity4.698596954345703
INFO:root:current mean train loss 3925.930278856944
INFO:root:current train perplexity4.700767517089844

100%|██████████| 1/1 [02:28<00:00, 148.85s/it][A100%|██████████| 1/1 [02:28<00:00, 148.85s/it]
INFO:root:final mean train loss: 3923.842548985635
INFO:root:final train perplexity: 4.702383041381836
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.57s/it][A100%|██████████| 1/1 [00:08<00:00,  8.57s/it]
INFO:root:eval mean loss: 4219.59474041445
INFO:root:eval perplexity: 5.508433818817139
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.51s/it][A100%|██████████| 1/1 [00:08<00:00,  8.51s/it]
INFO:root:eval mean loss: 5186.559360801751
INFO:root:eval perplexity: 8.338266372680664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/66
 33%|███▎      | 66/200 [3:01:25<6:10:54, 166.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3928.4706940827546
INFO:root:current train perplexity4.703952312469482
INFO:root:current mean train loss 3907.424802765133
INFO:root:current train perplexity4.66473913192749
INFO:root:current mean train loss 3911.810422115914
INFO:root:current train perplexity4.675533294677734
INFO:root:current mean train loss 3905.015790000239
INFO:root:current train perplexity4.678637981414795
INFO:root:current mean train loss 3916.7839858615707
INFO:root:current train perplexity4.6917266845703125
INFO:root:current mean train loss 3916.578958413633
INFO:root:current train perplexity4.692994117736816
INFO:root:current mean train loss 3919.15815328449
INFO:root:current train perplexity4.690885066986084
INFO:root:current mean train loss 3918.6895676393783
INFO:root:current train perplexity4.689567565917969
INFO:root:current mean train loss 3917.996269106144
INFO:root:current train perplexity4.685812950134277
INFO:root:current mean train loss 3918.9912109375
INFO:root:current train perplexity4.686477184295654

100%|██████████| 1/1 [02:29<00:00, 149.24s/it][A100%|██████████| 1/1 [02:29<00:00, 149.24s/it]
INFO:root:final mean train loss: 3916.242228231122
INFO:root:final train perplexity: 4.688304424285889
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.30s/it][A100%|██████████| 1/1 [00:08<00:00,  8.30s/it]
INFO:root:eval mean loss: 4216.669731410682
INFO:root:eval perplexity: 5.501921653747559
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.54s/it][A100%|██████████| 1/1 [00:08<00:00,  8.54s/it]
INFO:root:eval mean loss: 5186.359946392952
INFO:root:eval perplexity: 8.337586402893066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/67
 34%|███▎      | 67/200 [3:04:12<6:08:20, 166.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3913.2281040736607
INFO:root:current train perplexity4.6641058921813965
INFO:root:current mean train loss 3878.690822120949
INFO:root:current train perplexity4.629116535186768
INFO:root:current mean train loss 3883.617115816157
INFO:root:current train perplexity4.639436721801758
INFO:root:current mean train loss 3893.9694139167445
INFO:root:current train perplexity4.641568183898926
INFO:root:current mean train loss 3898.7896007318604
INFO:root:current train perplexity4.655676364898682
INFO:root:current mean train loss 3897.128643399533
INFO:root:current train perplexity4.657712936401367
INFO:root:current mean train loss 3899.369772699311
INFO:root:current train perplexity4.657890319824219
INFO:root:current mean train loss 3909.3997575201956
INFO:root:current train perplexity4.671280384063721
INFO:root:current mean train loss 3909.511767578125
INFO:root:current train perplexity4.670229911804199
INFO:root:current mean train loss 3910.1968817889374
INFO:root:current train perplexity4.672792434692383

100%|██████████| 1/1 [02:29<00:00, 149.16s/it][A100%|██████████| 1/1 [02:29<00:00, 149.16s/it]
INFO:root:final mean train loss: 3908.7923526763916
INFO:root:final train perplexity: 4.674544334411621
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.63s/it][A100%|██████████| 1/1 [00:08<00:00,  8.63s/it]
INFO:root:eval mean loss: 4217.636046930408
INFO:root:eval perplexity: 5.504072189331055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.71s/it][A100%|██████████| 1/1 [00:08<00:00,  8.71s/it]
INFO:root:eval mean loss: 5188.552943885749
INFO:root:eval perplexity: 8.345067977905273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/68
 34%|███▍      | 68/200 [3:06:58<6:05:59, 166.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3885.5291378997094
INFO:root:current train perplexity4.621099948883057
INFO:root:current mean train loss 3890.399342356862
INFO:root:current train perplexity4.649304389953613
INFO:root:current mean train loss 3894.8146018197017
INFO:root:current train perplexity4.641444206237793
INFO:root:current mean train loss 3897.302671026558
INFO:root:current train perplexity4.643052577972412
INFO:root:current mean train loss 3889.073474754867
INFO:root:current train perplexity4.637812614440918
INFO:root:current mean train loss 3898.226424468376
INFO:root:current train perplexity4.647843837738037
INFO:root:current mean train loss 3900.0812008681232
INFO:root:current train perplexity4.64979887008667
INFO:root:current mean train loss 3904.743814337462
INFO:root:current train perplexity4.657895088195801
INFO:root:current mean train loss 3903.688204619384
INFO:root:current train perplexity4.657804489135742
INFO:root:current mean train loss 3903.973021554795
INFO:root:current train perplexity4.658692836761475

100%|██████████| 1/1 [02:28<00:00, 148.69s/it][A100%|██████████| 1/1 [02:28<00:00, 148.69s/it]
INFO:root:final mean train loss: 3900.9023820815546
INFO:root:final train perplexity: 4.66001558303833
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.67s/it][A100%|██████████| 1/1 [00:08<00:00,  8.67s/it]
INFO:root:eval mean loss: 4217.1689453125
INFO:root:eval perplexity: 5.5030317306518555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.80s/it][A100%|██████████| 1/1 [00:08<00:00,  8.80s/it]
INFO:root:eval mean loss: 5188.037968195922
INFO:root:eval perplexity: 8.34330940246582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/69
 34%|███▍      | 69/200 [3:09:45<6:03:16, 166.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3862.1988166360293
INFO:root:current train perplexity4.599546432495117
INFO:root:current mean train loss 3877.504468905215
INFO:root:current train perplexity4.610360145568848
INFO:root:current mean train loss 3889.494518021663
INFO:root:current train perplexity4.623082160949707
INFO:root:current mean train loss 3892.11893960893
INFO:root:current train perplexity4.629921913146973
INFO:root:current mean train loss 3899.3199232824627
INFO:root:current train perplexity4.63671875
INFO:root:current mean train loss 3898.995025025522
INFO:root:current train perplexity4.638502597808838
INFO:root:current mean train loss 3899.029816658266
INFO:root:current train perplexity4.643105983734131
INFO:root:current mean train loss 3902.5939333492843
INFO:root:current train perplexity4.6492791175842285
INFO:root:current mean train loss 3898.764952537456
INFO:root:current train perplexity4.646345615386963
INFO:root:current mean train loss 3897.1232956365834
INFO:root:current train perplexity4.646233081817627

100%|██████████| 1/1 [02:29<00:00, 149.30s/it][A100%|██████████| 1/1 [02:29<00:00, 149.30s/it]
INFO:root:final mean train loss: 3894.298094041886
INFO:root:final train perplexity: 4.647889614105225
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.59s/it][A100%|██████████| 1/1 [00:08<00:00,  8.59s/it]
INFO:root:eval mean loss: 4216.424351036126
INFO:root:eval perplexity: 5.501375198364258
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.70s/it][A100%|██████████| 1/1 [00:08<00:00,  8.70s/it]
INFO:root:eval mean loss: 5189.644894863697
INFO:root:eval perplexity: 8.348793983459473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/70
 35%|███▌      | 70/200 [3:12:32<6:00:48, 166.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3873.8762165651483
INFO:root:current train perplexity4.6148576736450195
INFO:root:current mean train loss 3872.5375116696146
INFO:root:current train perplexity4.623101711273193
INFO:root:current mean train loss 3884.770463508989
INFO:root:current train perplexity4.620079517364502
INFO:root:current mean train loss 3887.919447194899
INFO:root:current train perplexity4.631740570068359
INFO:root:current mean train loss 3882.466124557462
INFO:root:current train perplexity4.626168251037598
INFO:root:current mean train loss 3886.3444125426263
INFO:root:current train perplexity4.631871223449707
INFO:root:current mean train loss 3887.325390921377
INFO:root:current train perplexity4.636012554168701
INFO:root:current mean train loss 3890.7569954813075
INFO:root:current train perplexity4.635234355926514
INFO:root:current mean train loss 3889.8777162420874
INFO:root:current train perplexity4.6352925300598145
INFO:root:current mean train loss 3891.351412044203
INFO:root:current train perplexity4.635951519012451

100%|██████████| 1/1 [02:29<00:00, 149.12s/it][A100%|██████████| 1/1 [02:29<00:00, 149.12s/it]
INFO:root:final mean train loss: 3888.838329192131
INFO:root:final train perplexity: 4.637888431549072
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.34s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 4216.7699121786345
INFO:root:eval perplexity: 5.502144813537598
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.52s/it][A100%|██████████| 1/1 [00:08<00:00,  8.52s/it]
INFO:root:eval mean loss: 5189.66116917387
INFO:root:eval perplexity: 8.348849296569824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/71
 36%|███▌      | 71/200 [3:15:18<5:57:54, 166.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3808.715361182369
INFO:root:current train perplexity4.534308433532715
INFO:root:current mean train loss 3847.5663974784807
INFO:root:current train perplexity4.578862190246582
INFO:root:current mean train loss 3860.177567957046
INFO:root:current train perplexity4.5853118896484375
INFO:root:current mean train loss 3866.031653131386
INFO:root:current train perplexity4.594064235687256
INFO:root:current mean train loss 3870.415569166555
INFO:root:current train perplexity4.604010105133057
INFO:root:current mean train loss 3872.762432656801
INFO:root:current train perplexity4.607635974884033
INFO:root:current mean train loss 3872.3471482032423
INFO:root:current train perplexity4.6105523109436035
INFO:root:current mean train loss 3874.7091355703024
INFO:root:current train perplexity4.611278533935547
INFO:root:current mean train loss 3880.1477163418217
INFO:root:current train perplexity4.620338439941406
INFO:root:current mean train loss 3882.8411661994246
INFO:root:current train perplexity4.621914863586426

100%|██████████| 1/1 [02:29<00:00, 149.24s/it][A100%|██████████| 1/1 [02:29<00:00, 149.25s/it]
INFO:root:final mean train loss: 3880.704734740719
INFO:root:final train perplexity: 4.6230292320251465
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.65s/it][A100%|██████████| 1/1 [00:08<00:00,  8.65s/it]
INFO:root:eval mean loss: 4217.972997354277
INFO:root:eval perplexity: 5.504822254180908
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.75s/it][A100%|██████████| 1/1 [00:08<00:00,  8.75s/it]
INFO:root:eval mean loss: 5192.29398167387
INFO:root:eval perplexity: 8.357843399047852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/72
 36%|███▌      | 72/200 [3:18:05<5:55:27, 166.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3859.8276399739584
INFO:root:current train perplexity4.552944183349609
INFO:root:current mean train loss 3863.2977999441964
INFO:root:current train perplexity4.588740348815918
INFO:root:current mean train loss 3853.773037109375
INFO:root:current train perplexity4.587520599365234
INFO:root:current mean train loss 3865.0582610677084
INFO:root:current train perplexity4.597379684448242
INFO:root:current mean train loss 3864.6686451480264
INFO:root:current train perplexity4.598221302032471
INFO:root:current mean train loss 3866.22590905231
INFO:root:current train perplexity4.598494052886963
INFO:root:current mean train loss 3865.9891995804396
INFO:root:current train perplexity4.602406978607178
INFO:root:current mean train loss 3870.8835572076614
INFO:root:current train perplexity4.6063690185546875
INFO:root:current mean train loss 3877.592173828125
INFO:root:current train perplexity4.609938621520996
INFO:root:current mean train loss 3876.872238581731
INFO:root:current train perplexity4.611657619476318

100%|██████████| 1/1 [02:29<00:00, 149.17s/it][A100%|██████████| 1/1 [02:29<00:00, 149.17s/it]
INFO:root:final mean train loss: 3874.1965610134985
INFO:root:final train perplexity: 4.611175060272217
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.71s/it][A100%|██████████| 1/1 [00:08<00:00,  8.71s/it]
INFO:root:eval mean loss: 4217.421234347296
INFO:root:eval perplexity: 5.503593921661377
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.81s/it][A100%|██████████| 1/1 [00:08<00:00,  8.81s/it]
INFO:root:eval mean loss: 5196.703266982491
INFO:root:eval perplexity: 8.372925758361816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/73
 36%|███▋      | 73/200 [3:20:52<5:52:53, 166.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3846.059693853539
INFO:root:current train perplexity4.564995765686035
INFO:root:current mean train loss 3865.4206996563353
INFO:root:current train perplexity4.582005500793457
INFO:root:current mean train loss 3861.5278984582046
INFO:root:current train perplexity4.57342004776001
INFO:root:current mean train loss 3864.416298649641
INFO:root:current train perplexity4.582932472229004
INFO:root:current mean train loss 3861.3458997517146
INFO:root:current train perplexity4.578883171081543
INFO:root:current mean train loss 3861.6448620752035
INFO:root:current train perplexity4.584046840667725
INFO:root:current mean train loss 3863.1576580086703
INFO:root:current train perplexity4.586845874786377
INFO:root:current mean train loss 3867.316128434806
INFO:root:current train perplexity4.590895652770996
INFO:root:current mean train loss 3868.6347678369198
INFO:root:current train perplexity4.595149517059326
INFO:root:current mean train loss 3869.910452050086
INFO:root:current train perplexity4.597972393035889

100%|██████████| 1/1 [02:29<00:00, 149.04s/it][A100%|██████████| 1/1 [02:29<00:00, 149.04s/it]
INFO:root:final mean train loss: 3867.3385172197895
INFO:root:final train perplexity: 4.598714828491211
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.67s/it][A100%|██████████| 1/1 [00:08<00:00,  8.67s/it]
INFO:root:eval mean loss: 4216.848856175199
INFO:root:eval perplexity: 5.502320289611816
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.71s/it][A100%|██████████| 1/1 [00:08<00:00,  8.71s/it]
INFO:root:eval mean loss: 5193.017268187611
INFO:root:eval perplexity: 8.36031436920166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/74
 37%|███▋      | 74/200 [3:23:39<5:50:06, 166.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3825.361784211882
INFO:root:current train perplexity4.541016101837158
INFO:root:current mean train loss 3847.430206458606
INFO:root:current train perplexity4.576311111450195
INFO:root:current mean train loss 3847.613724226804
INFO:root:current train perplexity4.5727858543396
INFO:root:current mean train loss 3853.6821563798753
INFO:root:current train perplexity4.577469348907471
INFO:root:current mean train loss 3851.4356214597124
INFO:root:current train perplexity4.572331428527832
INFO:root:current mean train loss 3851.957108499233
INFO:root:current train perplexity4.573713779449463
INFO:root:current mean train loss 3854.6064481390194
INFO:root:current train perplexity4.580266952514648
INFO:root:current mean train loss 3856.7340175855325
INFO:root:current train perplexity4.582136631011963
INFO:root:current mean train loss 3858.7440630808956
INFO:root:current train perplexity4.584799766540527
INFO:root:current mean train loss 3862.8404234300106
INFO:root:current train perplexity4.585102558135986

100%|██████████| 1/1 [02:29<00:00, 149.08s/it][A100%|██████████| 1/1 [02:29<00:00, 149.08s/it]
INFO:root:final mean train loss: 3859.8630980214766
INFO:root:final train perplexity: 4.585172653198242
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.81s/it][A100%|██████████| 1/1 [00:08<00:00,  8.81s/it]
INFO:root:eval mean loss: 4217.094856424535
INFO:root:eval perplexity: 5.502867698669434
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.75s/it][A100%|██████████| 1/1 [00:08<00:00,  8.75s/it]
INFO:root:eval mean loss: 5192.764752327128
INFO:root:eval perplexity: 8.359451293945312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/75
 38%|███▊      | 75/200 [3:26:26<5:47:25, 166.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3842.963556463068
INFO:root:current train perplexity4.559695243835449
INFO:root:current mean train loss 3837.816425879397
INFO:root:current train perplexity4.557342052459717
INFO:root:current mean train loss 3841.749699519231
INFO:root:current train perplexity4.556612491607666
INFO:root:current mean train loss 3851.5107275023497
INFO:root:current train perplexity4.563812255859375
INFO:root:current mean train loss 3859.3633140304046
INFO:root:current train perplexity4.5683746337890625
INFO:root:current mean train loss 3859.023093502191
INFO:root:current train perplexity4.568686008453369
INFO:root:current mean train loss 3857.7463336993696
INFO:root:current train perplexity4.568474292755127
INFO:root:current mean train loss 3854.590945896726
INFO:root:current train perplexity4.568161964416504
INFO:root:current mean train loss 3856.568635017641
INFO:root:current train perplexity4.571239948272705

100%|██████████| 1/1 [02:28<00:00, 148.81s/it][A100%|██████████| 1/1 [02:28<00:00, 148.81s/it]
INFO:root:final mean train loss: 3852.9879617383403
INFO:root:final train perplexity: 4.572751998901367
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.42s/it][A100%|██████████| 1/1 [00:08<00:00,  8.42s/it]
INFO:root:eval mean loss: 4216.851652537677
INFO:root:eval perplexity: 5.502326965332031
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.57s/it][A100%|██████████| 1/1 [00:08<00:00,  8.57s/it]
INFO:root:eval mean loss: 5198.5597296099295
INFO:root:eval perplexity: 8.379283905029297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/76
 38%|███▊      | 76/200 [3:29:12<5:44:13, 166.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3795.3928571428573
INFO:root:current train perplexity4.596944332122803
INFO:root:current mean train loss 3845.672824182243
INFO:root:current train perplexity4.504309177398682
INFO:root:current mean train loss 3851.7958194161383
INFO:root:current train perplexity4.524876117706299
INFO:root:current mean train loss 3846.1554547536643
INFO:root:current train perplexity4.534611225128174
INFO:root:current mean train loss 3845.9947776700706
INFO:root:current train perplexity4.54428768157959
INFO:root:current mean train loss 3846.8952482626046
INFO:root:current train perplexity4.551021575927734
INFO:root:current mean train loss 3845.4695403399146
INFO:root:current train perplexity4.550647258758545
INFO:root:current mean train loss 3849.2186339727723
INFO:root:current train perplexity4.558435440063477
INFO:root:current mean train loss 3849.3530893621246
INFO:root:current train perplexity4.558671951293945
INFO:root:current mean train loss 3848.9482190385543
INFO:root:current train perplexity4.560491561889648

100%|██████████| 1/1 [02:29<00:00, 149.06s/it][A100%|██████████| 1/1 [02:29<00:00, 149.06s/it]
INFO:root:final mean train loss: 3846.6848137147963
INFO:root:final train perplexity: 4.561394214630127
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.44s/it][A100%|██████████| 1/1 [00:08<00:00,  8.44s/it]
INFO:root:eval mean loss: 4214.312944993905
INFO:root:eval perplexity: 5.496681213378906
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.48s/it][A100%|██████████| 1/1 [00:08<00:00,  8.48s/it]
INFO:root:eval mean loss: 5196.914557707225
INFO:root:eval perplexity: 8.373647689819336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/77
 38%|███▊      | 77/200 [3:31:58<5:41:17, 166.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3820.0127766927085
INFO:root:current train perplexity4.589909076690674
INFO:root:current mean train loss 3817.9714567764945
INFO:root:current train perplexity4.5213942527771
INFO:root:current mean train loss 3826.337329669331
INFO:root:current train perplexity4.524343967437744
INFO:root:current mean train loss 3833.2079310825893
INFO:root:current train perplexity4.531983852386475
INFO:root:current mean train loss 3832.698123941077
INFO:root:current train perplexity4.531958103179932
INFO:root:current mean train loss 3833.960572000152
INFO:root:current train perplexity4.531792640686035
INFO:root:current mean train loss 3840.5698250127034
INFO:root:current train perplexity4.535458087921143
INFO:root:current mean train loss 3836.8355243389424
INFO:root:current train perplexity4.538568019866943
INFO:root:current mean train loss 3838.338878870303
INFO:root:current train perplexity4.541599273681641
INFO:root:current mean train loss 3841.969462677169
INFO:root:current train perplexity4.547884464263916

100%|██████████| 1/1 [02:29<00:00, 149.63s/it][A100%|██████████| 1/1 [02:29<00:00, 149.63s/it]
INFO:root:final mean train loss: 3840.2361007813483
INFO:root:final train perplexity: 4.549803733825684
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.65s/it][A100%|██████████| 1/1 [00:08<00:00,  8.65s/it]
INFO:root:eval mean loss: 4215.429278867465
INFO:root:eval perplexity: 5.499162673950195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.71s/it][A100%|██████████| 1/1 [00:08<00:00,  8.71s/it]
INFO:root:eval mean loss: 5201.244066170767
INFO:root:eval perplexity: 8.388486862182617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/78
 39%|███▉      | 78/200 [3:34:45<5:39:00, 166.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3864.2068720278535
INFO:root:current train perplexity4.539988994598389
INFO:root:current mean train loss 3825.589337604802
INFO:root:current train perplexity4.521732807159424
INFO:root:current mean train loss 3818.175948754554
INFO:root:current train perplexity4.514505863189697
INFO:root:current mean train loss 3823.075156008127
INFO:root:current train perplexity4.522352695465088
INFO:root:current mean train loss 3818.7525239407873
INFO:root:current train perplexity4.519145488739014
INFO:root:current mean train loss 3825.480147119234
INFO:root:current train perplexity4.520900726318359
INFO:root:current mean train loss 3829.671502714938
INFO:root:current train perplexity4.527642250061035
INFO:root:current mean train loss 3830.232506294303
INFO:root:current train perplexity4.530777454376221
INFO:root:current mean train loss 3831.1417501827345
INFO:root:current train perplexity4.53333854675293
INFO:root:current mean train loss 3834.5984952684857
INFO:root:current train perplexity4.536741733551025

100%|██████████| 1/1 [02:29<00:00, 149.80s/it][A100%|██████████| 1/1 [02:29<00:00, 149.81s/it]
INFO:root:final mean train loss: 3834.4336848105154
INFO:root:final train perplexity: 4.539400577545166
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.46s/it][A100%|██████████| 1/1 [00:08<00:00,  8.46s/it]
INFO:root:eval mean loss: 4212.962951227283
INFO:root:eval perplexity: 5.49368143081665
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.52s/it][A100%|██████████| 1/1 [00:08<00:00,  8.52s/it]
INFO:root:eval mean loss: 5198.064742284464
INFO:root:eval perplexity: 8.377588272094727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/79
 40%|███▉      | 79/200 [3:37:32<5:36:25, 166.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3743.2882907006046
INFO:root:current train perplexity4.473390102386475
INFO:root:current mean train loss 3802.4704776210638
INFO:root:current train perplexity4.485405921936035
INFO:root:current mean train loss 3815.837850463339
INFO:root:current train perplexity4.5004048347473145
INFO:root:current mean train loss 3819.424152662387
INFO:root:current train perplexity4.501891136169434
INFO:root:current mean train loss 3824.004822768634
INFO:root:current train perplexity4.509264945983887
INFO:root:current mean train loss 3825.418798644215
INFO:root:current train perplexity4.518026828765869
INFO:root:current mean train loss 3829.009647230339
INFO:root:current train perplexity4.520620822906494
INFO:root:current mean train loss 3829.7929543887867
INFO:root:current train perplexity4.524040222167969
INFO:root:current mean train loss 3832.0724113455176
INFO:root:current train perplexity4.525550365447998
INFO:root:current mean train loss 3830.1555991331566
INFO:root:current train perplexity4.525198459625244

100%|██████████| 1/1 [02:28<00:00, 148.45s/it][A100%|██████████| 1/1 [02:28<00:00, 148.45s/it]
INFO:root:final mean train loss: 3827.1331502237626
INFO:root:final train perplexity: 4.526345252990723
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.60s/it][A100%|██████████| 1/1 [00:08<00:00,  8.60s/it]
INFO:root:eval mean loss: 4215.3956965453235
INFO:root:eval perplexity: 5.499088287353516
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.70s/it][A100%|██████████| 1/1 [00:08<00:00,  8.70s/it]
INFO:root:eval mean loss: 5200.581426958665
INFO:root:eval perplexity: 8.386215209960938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/80
 40%|████      | 80/200 [3:40:18<5:33:10, 166.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3794.671856219952
INFO:root:current train perplexity4.4968390464782715
INFO:root:current mean train loss 3777.882146821605
INFO:root:current train perplexity4.468747138977051
INFO:root:current mean train loss 3803.7939289683577
INFO:root:current train perplexity4.498043537139893
INFO:root:current mean train loss 3806.1636181496588
INFO:root:current train perplexity4.499906539916992
INFO:root:current mean train loss 3805.6750310319976
INFO:root:current train perplexity4.502383232116699
INFO:root:current mean train loss 3815.139098101954
INFO:root:current train perplexity4.508907794952393
INFO:root:current mean train loss 3819.611763298978
INFO:root:current train perplexity4.513836860656738
INFO:root:current mean train loss 3823.3250060126647
INFO:root:current train perplexity4.515622615814209
INFO:root:current mean train loss 3823.9002849956237
INFO:root:current train perplexity4.514072418212891
INFO:root:current mean train loss 3824.4264114916136
INFO:root:current train perplexity4.517998218536377

100%|██████████| 1/1 [02:29<00:00, 149.69s/it][A100%|██████████| 1/1 [02:29<00:00, 149.69s/it]
INFO:root:final mean train loss: 3821.8157631658737
INFO:root:final train perplexity: 4.516859531402588
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 4215.290297055075
INFO:root:eval perplexity: 5.4988532066345215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 5202.528062319925
INFO:root:eval perplexity: 8.392891883850098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/81
 40%|████      | 81/200 [3:43:05<5:30:26, 166.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3774.8295015375666
INFO:root:current train perplexity4.435975074768066
INFO:root:current mean train loss 3814.1046283747874
INFO:root:current train perplexity4.478584289550781
INFO:root:current mean train loss 3806.7795439808956
INFO:root:current train perplexity4.489304542541504
INFO:root:current mean train loss 3805.17260812545
INFO:root:current train perplexity4.491039276123047
INFO:root:current mean train loss 3808.0766585177225
INFO:root:current train perplexity4.495880603790283
INFO:root:current mean train loss 3813.462934811329
INFO:root:current train perplexity4.496674537658691
INFO:root:current mean train loss 3814.819443102782
INFO:root:current train perplexity4.5040388107299805
INFO:root:current mean train loss 3816.08252835561
INFO:root:current train perplexity4.502635478973389
INFO:root:current mean train loss 3816.094698314824
INFO:root:current train perplexity4.504395008087158
INFO:root:current mean train loss 3817.4461101463503
INFO:root:current train perplexity4.503098964691162

100%|██████████| 1/1 [02:28<00:00, 148.94s/it][A100%|██████████| 1/1 [02:28<00:00, 148.94s/it]
INFO:root:final mean train loss: 3815.627659274686
INFO:root:final train perplexity: 4.505845069885254
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.37s/it][A100%|██████████| 1/1 [00:08<00:00,  8.37s/it]
INFO:root:eval mean loss: 4214.27055802582
INFO:root:eval perplexity: 5.496586322784424
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.82s/it][A100%|██████████| 1/1 [00:08<00:00,  8.82s/it]
INFO:root:eval mean loss: 5201.975066489362
INFO:root:eval perplexity: 8.390996932983398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/82
 41%|████      | 82/200 [3:45:51<5:27:34, 166.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3809.484521484375
INFO:root:current train perplexity4.499050140380859
INFO:root:current mean train loss 3807.542921496976
INFO:root:current train perplexity4.492125034332275
INFO:root:current mean train loss 3809.143482881434
INFO:root:current train perplexity4.505961894989014
INFO:root:current mean train loss 3809.767363556338
INFO:root:current train perplexity4.499974727630615
INFO:root:current mean train loss 3804.128019831731
INFO:root:current train perplexity4.4913129806518555
INFO:root:current mean train loss 3804.231180936796
INFO:root:current train perplexity4.4900922775268555
INFO:root:current mean train loss 3810.6963770276716
INFO:root:current train perplexity4.498643398284912
INFO:root:current mean train loss 3813.0845641685637
INFO:root:current train perplexity4.499423027038574
INFO:root:current mean train loss 3814.3292189213266
INFO:root:current train perplexity4.499518394470215
INFO:root:current mean train loss 3816.694930822562
INFO:root:current train perplexity4.500978946685791

100%|██████████| 1/1 [02:29<00:00, 149.31s/it][A100%|██████████| 1/1 [02:29<00:00, 149.31s/it]
INFO:root:final mean train loss: 3811.8427362749653
INFO:root:final train perplexity: 4.499122142791748
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.67s/it][A100%|██████████| 1/1 [00:08<00:00,  8.67s/it]
INFO:root:eval mean loss: 4214.017107158688
INFO:root:eval perplexity: 5.496024131774902
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.43s/it][A100%|██████████| 1/1 [00:08<00:00,  8.43s/it]
INFO:root:eval mean loss: 5201.538996703236
INFO:root:eval perplexity: 8.389496803283691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/83
 42%|████▏     | 83/200 [3:48:38<5:24:52, 166.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3823.9925401475693
INFO:root:current train perplexity4.482722282409668
INFO:root:current mean train loss 3818.588757848447
INFO:root:current train perplexity4.47727632522583
INFO:root:current mean train loss 3804.5185268387595
INFO:root:current train perplexity4.474013328552246
INFO:root:current mean train loss 3804.8931450962036
INFO:root:current train perplexity4.473493576049805
INFO:root:current mean train loss 3805.3262478064253
INFO:root:current train perplexity4.4746413230896
INFO:root:current mean train loss 3809.5848568633437
INFO:root:current train perplexity4.481008529663086
INFO:root:current mean train loss 3810.7804144719785
INFO:root:current train perplexity4.484645366668701
INFO:root:current mean train loss 3807.424803087627
INFO:root:current train perplexity4.484591007232666
INFO:root:current mean train loss 3808.035697715998
INFO:root:current train perplexity4.486026287078857
INFO:root:current mean train loss 3807.343095409041
INFO:root:current train perplexity4.486917018890381

100%|██████████| 1/1 [02:28<00:00, 148.58s/it][A100%|██████████| 1/1 [02:28<00:00, 148.58s/it]
INFO:root:final mean train loss: 3804.1672712141467
INFO:root:final train perplexity: 4.485517501831055
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.74s/it][A100%|██████████| 1/1 [00:08<00:00,  8.74s/it]
INFO:root:eval mean loss: 4215.540134294659
INFO:root:eval perplexity: 5.4994096755981445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.61s/it][A100%|██████████| 1/1 [00:08<00:00,  8.61s/it]
INFO:root:eval mean loss: 5203.784600440492
INFO:root:eval perplexity: 8.397205352783203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/84
 42%|████▏     | 84/200 [3:51:24<5:21:51, 166.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3802.059229891065
INFO:root:current train perplexity4.426467418670654
INFO:root:current mean train loss 3781.4800604212355
INFO:root:current train perplexity4.4390459060668945
INFO:root:current mean train loss 3786.3891448411555
INFO:root:current train perplexity4.453964710235596
INFO:root:current mean train loss 3787.863645157724
INFO:root:current train perplexity4.458926677703857
INFO:root:current mean train loss 3794.682324322419
INFO:root:current train perplexity4.463888168334961
INFO:root:current mean train loss 3796.677123809654
INFO:root:current train perplexity4.47093391418457
INFO:root:current mean train loss 3798.3400082083645
INFO:root:current train perplexity4.468751430511475
INFO:root:current mean train loss 3800.088609430731
INFO:root:current train perplexity4.469285488128662
INFO:root:current mean train loss 3799.8123511611116
INFO:root:current train perplexity4.473145008087158
INFO:root:current mean train loss 3799.4762027005827
INFO:root:current train perplexity4.473300933837891

100%|██████████| 1/1 [02:29<00:00, 149.11s/it][A100%|██████████| 1/1 [02:29<00:00, 149.11s/it]
INFO:root:final mean train loss: 3797.1321200093917
INFO:root:final train perplexity: 4.473085403442383
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.49s/it][A100%|██████████| 1/1 [00:08<00:00,  8.49s/it]
INFO:root:eval mean loss: 4215.224429299646
INFO:root:eval perplexity: 5.498706817626953
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.65s/it][A100%|██████████| 1/1 [00:08<00:00,  8.65s/it]
INFO:root:eval mean loss: 5206.81852386691
INFO:root:eval perplexity: 8.407628059387207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/85
 42%|████▎     | 85/200 [3:54:11<5:19:06, 166.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3780.871365704114
INFO:root:current train perplexity4.4138007164001465
INFO:root:current mean train loss 3786.747858654853
INFO:root:current train perplexity4.437037944793701
INFO:root:current mean train loss 3786.4729590193774
INFO:root:current train perplexity4.445128917694092
INFO:root:current mean train loss 3781.344894046834
INFO:root:current train perplexity4.441748142242432
INFO:root:current mean train loss 3781.031222986528
INFO:root:current train perplexity4.446887493133545
INFO:root:current mean train loss 3786.2770106393027
INFO:root:current train perplexity4.456674098968506
INFO:root:current mean train loss 3787.71603065457
INFO:root:current train perplexity4.461484909057617
INFO:root:current mean train loss 3792.0842140991053
INFO:root:current train perplexity4.463380813598633
INFO:root:current mean train loss 3795.5007990814315
INFO:root:current train perplexity4.464754581451416
INFO:root:current mean train loss 3794.782921577742
INFO:root:current train perplexity4.463520050048828

100%|██████████| 1/1 [02:29<00:00, 149.42s/it][A100%|██████████| 1/1 [02:29<00:00, 149.42s/it]
INFO:root:final mean train loss: 3791.7774677891884
INFO:root:final train perplexity: 4.463645935058594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.60s/it][A100%|██████████| 1/1 [00:08<00:00,  8.60s/it]
INFO:root:eval mean loss: 4215.4264288286795
INFO:root:eval perplexity: 5.499156475067139
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.70s/it][A100%|██████████| 1/1 [00:08<00:00,  8.70s/it]
INFO:root:eval mean loss: 5206.713545129654
INFO:root:eval perplexity: 8.407267570495605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/86
 43%|████▎     | 86/200 [3:56:58<5:16:36, 166.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3764.0156811242814
INFO:root:current train perplexity4.386260986328125
INFO:root:current mean train loss 3777.4617482557655
INFO:root:current train perplexity4.4230780601501465
INFO:root:current mean train loss 3784.7130394912347
INFO:root:current train perplexity4.4321208000183105
INFO:root:current mean train loss 3780.777519127503
INFO:root:current train perplexity4.430368900299072
INFO:root:current mean train loss 3776.164982413854
INFO:root:current train perplexity4.433408260345459
INFO:root:current mean train loss 3781.0831662751543
INFO:root:current train perplexity4.438180923461914
INFO:root:current mean train loss 3782.6834309895835
INFO:root:current train perplexity4.441232681274414
INFO:root:current mean train loss 3784.5562692954854
INFO:root:current train perplexity4.445886611938477
INFO:root:current mean train loss 3787.886258818789
INFO:root:current train perplexity4.449026107788086
INFO:root:current mean train loss 3789.237168888915
INFO:root:current train perplexity4.454298973083496

100%|██████████| 1/1 [02:29<00:00, 149.18s/it][A100%|██████████| 1/1 [02:29<00:00, 149.18s/it]
INFO:root:final mean train loss: 3786.71887471599
INFO:root:final train perplexity: 4.454746723175049
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.34s/it][A100%|██████████| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 4214.5206671099295
INFO:root:eval perplexity: 5.4971418380737305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.42s/it][A100%|██████████| 1/1 [00:08<00:00,  8.42s/it]
INFO:root:eval mean loss: 5210.800992492243
INFO:root:eval perplexity: 8.421332359313965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/87
 44%|████▎     | 87/200 [3:59:44<5:13:38, 166.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3782.772738486842
INFO:root:current train perplexity4.429831504821777
INFO:root:current mean train loss 3772.3320512820515
INFO:root:current train perplexity4.427391529083252
INFO:root:current mean train loss 3772.53797586732
INFO:root:current train perplexity4.438652515411377
INFO:root:current mean train loss 3774.9671788469145
INFO:root:current train perplexity4.438875675201416
INFO:root:current mean train loss 3775.3688146109535
INFO:root:current train perplexity4.443787574768066
INFO:root:current mean train loss 3779.93064231552
INFO:root:current train perplexity4.445874214172363
INFO:root:current mean train loss 3783.7550001405125
INFO:root:current train perplexity4.444639205932617
INFO:root:current mean train loss 3786.4344778768673
INFO:root:current train perplexity4.446747779846191
INFO:root:current mean train loss 3787.0885000218227
INFO:root:current train perplexity4.447098255157471

100%|██████████| 1/1 [02:29<00:00, 149.55s/it][A100%|██████████| 1/1 [02:29<00:00, 149.55s/it]
INFO:root:final mean train loss: 3782.2972329662693
INFO:root:final train perplexity: 4.446981906890869
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.48s/it][A100%|██████████| 1/1 [00:08<00:00,  8.48s/it]
INFO:root:eval mean loss: 4215.179666722074
INFO:root:eval perplexity: 5.498607158660889
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.68s/it][A100%|██████████| 1/1 [00:08<00:00,  8.68s/it]
INFO:root:eval mean loss: 5211.489470786237
INFO:root:eval perplexity: 8.423704147338867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/88
 44%|████▍     | 88/200 [4:02:31<5:11:07, 166.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3807.0764973958335
INFO:root:current train perplexity4.387937068939209
INFO:root:current mean train loss 3765.5250564130765
INFO:root:current train perplexity4.422305107116699
INFO:root:current mean train loss 3770.3492317387622
INFO:root:current train perplexity4.426692008972168
INFO:root:current mean train loss 3766.9151712046205
INFO:root:current train perplexity4.428945541381836
INFO:root:current mean train loss 3768.9493350651364
INFO:root:current train perplexity4.423807144165039
INFO:root:current mean train loss 3768.2750023297713
INFO:root:current train perplexity4.424426078796387
INFO:root:current mean train loss 3773.1259263577945
INFO:root:current train perplexity4.42836332321167
INFO:root:current mean train loss 3773.822275001667
INFO:root:current train perplexity4.428767204284668
INFO:root:current mean train loss 3776.547090561274
INFO:root:current train perplexity4.431575298309326
INFO:root:current mean train loss 3778.4399251842815
INFO:root:current train perplexity4.4345502853393555

100%|██████████| 1/1 [02:29<00:00, 149.49s/it][A100%|██████████| 1/1 [02:29<00:00, 149.49s/it]
INFO:root:final mean train loss: 3776.6126956939697
INFO:root:final train perplexity: 4.4370198249816895
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 4216.570322888962
INFO:root:eval perplexity: 5.5017008781433105
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.73s/it][A100%|██████████| 1/1 [00:08<00:00,  8.73s/it]
INFO:root:eval mean loss: 5214.863594650376
INFO:root:eval perplexity: 8.435334205627441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/89
 44%|████▍     | 89/200 [4:05:18<5:08:26, 166.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3740.139071377841
INFO:root:current train perplexity4.392087936401367
INFO:root:current mean train loss 3789.622362841357
INFO:root:current train perplexity4.419500827789307
INFO:root:current mean train loss 3784.049937749926
INFO:root:current train perplexity4.402209758758545
INFO:root:current mean train loss 3787.487713681923
INFO:root:current train perplexity4.407800197601318
INFO:root:current mean train loss 3782.3134046865493
INFO:root:current train perplexity4.409181594848633
INFO:root:current mean train loss 3775.4104754005625
INFO:root:current train perplexity4.411189079284668
INFO:root:current mean train loss 3774.962582152721
INFO:root:current train perplexity4.417969703674316
INFO:root:current mean train loss 3775.44362789535
INFO:root:current train perplexity4.422541618347168
INFO:root:current mean train loss 3774.0063530749076
INFO:root:current train perplexity4.423660755157471
INFO:root:current mean train loss 3771.3731307564663
INFO:root:current train perplexity4.424638271331787

100%|██████████| 1/1 [02:29<00:00, 149.37s/it][A100%|██████████| 1/1 [02:29<00:00, 149.37s/it]
INFO:root:final mean train loss: 3769.7718959931403
INFO:root:final train perplexity: 4.425060272216797
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.40s/it][A100%|██████████| 1/1 [00:08<00:00,  8.40s/it]
INFO:root:eval mean loss: 4217.630007480053
INFO:root:eval perplexity: 5.504058361053467
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.63s/it][A100%|██████████| 1/1 [00:08<00:00,  8.63s/it]
INFO:root:eval mean loss: 5214.487048426418
INFO:root:eval perplexity: 8.434035301208496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/90
 45%|████▌     | 90/200 [4:08:05<5:05:37, 166.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3729.33642578125
INFO:root:current train perplexity4.395747184753418
INFO:root:current mean train loss 3747.889176569065
INFO:root:current train perplexity4.406816482543945
INFO:root:current mean train loss 3763.4074840806934
INFO:root:current train perplexity4.408992767333984
INFO:root:current mean train loss 3769.2288087468164
INFO:root:current train perplexity4.413234233856201
INFO:root:current mean train loss 3765.9991726021776
INFO:root:current train perplexity4.405107021331787
INFO:root:current mean train loss 3767.383649351969
INFO:root:current train perplexity4.40767240524292
INFO:root:current mean train loss 3767.4298101619297
INFO:root:current train perplexity4.40930700302124
INFO:root:current mean train loss 3766.839218967316
INFO:root:current train perplexity4.408816337585449
INFO:root:current mean train loss 3767.904990246299
INFO:root:current train perplexity4.412385940551758
INFO:root:current mean train loss 3768.5724093465215
INFO:root:current train perplexity4.415003299713135

100%|██████████| 1/1 [02:29<00:00, 149.45s/it][A100%|██████████| 1/1 [02:29<00:00, 149.45s/it]
INFO:root:final mean train loss: 3764.654046950802
INFO:root:final train perplexity: 4.416134357452393
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.59s/it][A100%|██████████| 1/1 [00:08<00:00,  8.59s/it]
INFO:root:eval mean loss: 4217.207221714318
INFO:root:eval perplexity: 5.503117561340332
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.87s/it][A100%|██████████| 1/1 [00:08<00:00,  8.87s/it]
INFO:root:eval mean loss: 5213.895687887854
INFO:root:eval perplexity: 8.43199634552002
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/91
 46%|████▌     | 91/200 [4:10:52<5:03:08, 166.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3718.0312861689813
INFO:root:current train perplexity4.359033107757568
INFO:root:current mean train loss 3757.2156011626475
INFO:root:current train perplexity4.4010844230651855
INFO:root:current mean train loss 3751.0076640797083
INFO:root:current train perplexity4.393572807312012
INFO:root:current mean train loss 3758.0704692875574
INFO:root:current train perplexity4.399089813232422
INFO:root:current mean train loss 3759.666240325856
INFO:root:current train perplexity4.403334617614746
INFO:root:current mean train loss 3762.5699530064044
INFO:root:current train perplexity4.406651496887207
INFO:root:current mean train loss 3762.397411875748
INFO:root:current train perplexity4.408159255981445
INFO:root:current mean train loss 3761.805958576019
INFO:root:current train perplexity4.404784202575684
INFO:root:current mean train loss 3762.79399402254
INFO:root:current train perplexity4.407006740570068
INFO:root:current mean train loss 3762.87977035506
INFO:root:current train perplexity4.406908988952637

100%|██████████| 1/1 [02:29<00:00, 149.51s/it][A100%|██████████| 1/1 [02:29<00:00, 149.51s/it]
INFO:root:final mean train loss: 3760.443303631198
INFO:root:final train perplexity: 4.408804416656494
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.73s/it][A100%|██████████| 1/1 [00:08<00:00,  8.73s/it]
INFO:root:eval mean loss: 4217.854100869902
INFO:root:eval perplexity: 5.5045576095581055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.86s/it][A100%|██████████| 1/1 [00:08<00:00,  8.86s/it]
INFO:root:eval mean loss: 5218.501864818816
INFO:root:eval perplexity: 8.447893142700195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/92
 46%|████▌     | 92/200 [4:13:39<5:00:39, 167.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3725.93671875
INFO:root:current train perplexity4.338010787963867
INFO:root:current mean train loss 3759.997873263889
INFO:root:current train perplexity4.377180099487305
INFO:root:current mean train loss 3761.626145902593
INFO:root:current train perplexity4.393579959869385
INFO:root:current mean train loss 3761.787047428871
INFO:root:current train perplexity4.396450996398926
INFO:root:current mean train loss 3763.0183212104885
INFO:root:current train perplexity4.404191017150879
INFO:root:current mean train loss 3756.986314891209
INFO:root:current train perplexity4.397291660308838
INFO:root:current mean train loss 3756.2513241264764
INFO:root:current train perplexity4.395374774932861
INFO:root:current mean train loss 3758.3023935746173
INFO:root:current train perplexity4.396115779876709
INFO:root:current mean train loss 3758.5267478714445
INFO:root:current train perplexity4.396890163421631
INFO:root:current mean train loss 3757.4268121239975
INFO:root:current train perplexity4.398362159729004

100%|██████████| 1/1 [02:29<00:00, 149.45s/it][A100%|██████████| 1/1 [02:29<00:00, 149.46s/it]
INFO:root:final mean train loss: 3754.169672996767
INFO:root:final train perplexity: 4.397906303405762
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.51s/it][A100%|██████████| 1/1 [00:08<00:00,  8.51s/it]
INFO:root:eval mean loss: 4216.791678787124
INFO:root:eval perplexity: 5.502193450927734
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.63s/it][A100%|██████████| 1/1 [00:08<00:00,  8.63s/it]
INFO:root:eval mean loss: 5217.9001499473625
INFO:root:eval perplexity: 8.445815086364746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/93
 46%|████▋     | 93/200 [4:16:26<4:57:47, 166.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3751.3876385356107
INFO:root:current train perplexity4.385743141174316
INFO:root:current mean train loss 3741.834626311189
INFO:root:current train perplexity4.390646934509277
INFO:root:current mean train loss 3738.073504412616
INFO:root:current train perplexity4.377304553985596
INFO:root:current mean train loss 3745.0205298776877
INFO:root:current train perplexity4.387954235076904
INFO:root:current mean train loss 3743.2008213706263
INFO:root:current train perplexity4.384464263916016
INFO:root:current mean train loss 3746.1093844419024
INFO:root:current train perplexity4.383764266967773
INFO:root:current mean train loss 3747.997145111416
INFO:root:current train perplexity4.384912967681885
INFO:root:current mean train loss 3747.9012226089335
INFO:root:current train perplexity4.385647773742676
INFO:root:current mean train loss 3749.7803487359133
INFO:root:current train perplexity4.3856377601623535
INFO:root:current mean train loss 3750.850007300918
INFO:root:current train perplexity4.390202522277832

100%|██████████| 1/1 [02:29<00:00, 149.07s/it][A100%|██████████| 1/1 [02:29<00:00, 149.07s/it]
INFO:root:final mean train loss: 3749.2062922446958
INFO:root:final train perplexity: 4.389303207397461
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.30s/it][A100%|██████████| 1/1 [00:08<00:00,  8.30s/it]
INFO:root:eval mean loss: 4218.461448290669
INFO:root:eval perplexity: 5.505910396575928
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.42s/it][A100%|██████████| 1/1 [00:08<00:00,  8.42s/it]
INFO:root:eval mean loss: 5220.004638671875
INFO:root:eval perplexity: 8.453084945678711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/94
 47%|████▋     | 94/200 [4:19:12<4:54:31, 166.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3726.9518229166665
INFO:root:current train perplexity4.335805892944336
INFO:root:current mean train loss 3731.5795381053395
INFO:root:current train perplexity4.354094505310059
INFO:root:current mean train loss 3740.1448736304783
INFO:root:current train perplexity4.361311912536621
INFO:root:current mean train loss 3734.5176880230592
INFO:root:current train perplexity4.359504222869873
INFO:root:current mean train loss 3738.097955606465
INFO:root:current train perplexity4.360870838165283
INFO:root:current mean train loss 3744.150712305751
INFO:root:current train perplexity4.370065212249756
INFO:root:current mean train loss 3741.493476457493
INFO:root:current train perplexity4.366062164306641
INFO:root:current mean train loss 3745.1056319438667
INFO:root:current train perplexity4.372277736663818
INFO:root:current mean train loss 3743.463993130784
INFO:root:current train perplexity4.374481678009033
INFO:root:current mean train loss 3746.650871461373
INFO:root:current train perplexity4.378937721252441

100%|██████████| 1/1 [02:29<00:00, 149.26s/it][A100%|██████████| 1/1 [02:29<00:00, 149.26s/it]
INFO:root:final mean train loss: 3744.673535439276
INFO:root:final train perplexity: 4.381459712982178
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.37s/it][A100%|██████████| 1/1 [00:08<00:00,  8.37s/it]
INFO:root:eval mean loss: 4217.444086602393
INFO:root:eval perplexity: 5.503644943237305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.50s/it][A100%|██████████| 1/1 [00:08<00:00,  8.50s/it]
INFO:root:eval mean loss: 5216.833288314495
INFO:root:eval perplexity: 8.442131042480469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/95
 48%|████▊     | 95/200 [4:21:59<4:51:36, 166.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3704.8839959613347
INFO:root:current train perplexity4.303605556488037
INFO:root:current mean train loss 3713.906968602594
INFO:root:current train perplexity4.332289218902588
INFO:root:current mean train loss 3725.759672304838
INFO:root:current train perplexity4.355130195617676
INFO:root:current mean train loss 3725.234590578212
INFO:root:current train perplexity4.358776092529297
INFO:root:current mean train loss 3730.857825584661
INFO:root:current train perplexity4.366406440734863
INFO:root:current mean train loss 3733.5496199442364
INFO:root:current train perplexity4.3662848472595215
INFO:root:current mean train loss 3733.927489122961
INFO:root:current train perplexity4.363509654998779
INFO:root:current mean train loss 3739.716431468215
INFO:root:current train perplexity4.367429256439209
INFO:root:current mean train loss 3740.1674827424695
INFO:root:current train perplexity4.369565486907959
INFO:root:current mean train loss 3741.3058600878194
INFO:root:current train perplexity4.372132778167725

100%|██████████| 1/1 [02:29<00:00, 149.35s/it][A100%|██████████| 1/1 [02:29<00:00, 149.35s/it]
INFO:root:final mean train loss: 3739.395625698951
INFO:root:final train perplexity: 4.3723464012146
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.63s/it][A100%|██████████| 1/1 [00:08<00:00,  8.63s/it]
INFO:root:eval mean loss: 4218.3552280723625
INFO:root:eval perplexity: 5.505673408508301
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.75s/it][A100%|██████████| 1/1 [00:08<00:00,  8.75s/it]
INFO:root:eval mean loss: 5220.008034131206
INFO:root:eval perplexity: 8.453097343444824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/96
 48%|████▊     | 96/200 [4:24:46<4:49:01, 166.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3729.623003148321
INFO:root:current train perplexity4.341301918029785
INFO:root:current mean train loss 3739.137112006456
INFO:root:current train perplexity4.362820148468018
INFO:root:current mean train loss 3738.105435832163
INFO:root:current train perplexity4.366966247558594
INFO:root:current mean train loss 3736.0253979425665
INFO:root:current train perplexity4.359150409698486
INFO:root:current mean train loss 3735.8186631131225
INFO:root:current train perplexity4.352218151092529
INFO:root:current mean train loss 3739.6516436218585
INFO:root:current train perplexity4.359288692474365
INFO:root:current mean train loss 3737.445327507145
INFO:root:current train perplexity4.358729362487793
INFO:root:current mean train loss 3738.7840896069306
INFO:root:current train perplexity4.360997200012207
INFO:root:current mean train loss 3737.345724244431
INFO:root:current train perplexity4.359825134277344
INFO:root:current mean train loss 3736.2019646377325
INFO:root:current train perplexity4.36264705657959

100%|██████████| 1/1 [02:29<00:00, 149.09s/it][A100%|██████████| 1/1 [02:29<00:00, 149.09s/it]
INFO:root:final mean train loss: 3733.7997694938413
INFO:root:final train perplexity: 4.362703800201416
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.65s/it][A100%|██████████| 1/1 [00:08<00:00,  8.65s/it]
INFO:root:eval mean loss: 4219.969170752992
INFO:root:eval perplexity: 5.509267330169678
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.65s/it][A100%|██████████| 1/1 [00:08<00:00,  8.65s/it]
INFO:root:eval mean loss: 5226.910992561503
INFO:root:eval perplexity: 8.476990699768066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/97
 48%|████▊     | 97/200 [4:27:32<4:46:14, 166.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3729.8432845052084
INFO:root:current train perplexity4.341060161590576
INFO:root:current mean train loss 3719.0886662946427
INFO:root:current train perplexity4.343132019042969
INFO:root:current mean train loss 3718.902784090909
INFO:root:current train perplexity4.344362735748291
INFO:root:current mean train loss 3720.893264973958
INFO:root:current train perplexity4.349945068359375
INFO:root:current mean train loss 3721.4251706414475
INFO:root:current train perplexity4.348529815673828
INFO:root:current mean train loss 3723.3368057914404
INFO:root:current train perplexity4.349517345428467
INFO:root:current mean train loss 3722.8977159288193
INFO:root:current train perplexity4.351933002471924
INFO:root:current mean train loss 3725.6976379788307
INFO:root:current train perplexity4.351099014282227
INFO:root:current mean train loss 3728.615092075893
INFO:root:current train perplexity4.355820178985596
INFO:root:current mean train loss 3731.902966746795
INFO:root:current train perplexity4.356971263885498

100%|██████████| 1/1 [02:29<00:00, 149.50s/it][A100%|██████████| 1/1 [02:29<00:00, 149.51s/it]
INFO:root:final mean train loss: 3730.1016912767964
INFO:root:final train perplexity: 4.356343746185303
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.67s/it][A100%|██████████| 1/1 [00:08<00:00,  8.67s/it]
INFO:root:eval mean loss: 4219.620503310616
INFO:root:eval perplexity: 5.508489608764648
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.70s/it][A100%|██████████| 1/1 [00:08<00:00,  8.70s/it]
INFO:root:eval mean loss: 5227.09680262356
INFO:root:eval perplexity: 8.477638244628906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/98
 49%|████▉     | 98/200 [4:30:20<4:43:40, 166.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3710.7248329254517
INFO:root:current train perplexity4.31423807144165
INFO:root:current mean train loss 3718.2601004845455
INFO:root:current train perplexity4.335974216461182
INFO:root:current mean train loss 3719.4860805336243
INFO:root:current train perplexity4.331839084625244
INFO:root:current mean train loss 3728.8599939570413
INFO:root:current train perplexity4.342875003814697
INFO:root:current mean train loss 3723.2010980767986
INFO:root:current train perplexity4.341935634613037
INFO:root:current mean train loss 3727.4454029534736
INFO:root:current train perplexity4.344853401184082
INFO:root:current mean train loss 3725.9669237709327
INFO:root:current train perplexity4.344796180725098
INFO:root:current mean train loss 3726.401271776221
INFO:root:current train perplexity4.344404220581055
INFO:root:current mean train loss 3726.3894720369126
INFO:root:current train perplexity4.344447135925293
INFO:root:current mean train loss 3727.19675424601
INFO:root:current train perplexity4.3466362953186035

100%|██████████| 1/1 [02:28<00:00, 148.79s/it][A100%|██████████| 1/1 [02:28<00:00, 148.79s/it]
INFO:root:final mean train loss: 3724.746603012085
INFO:root:final train perplexity: 4.347148895263672
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.32s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 4219.99006988309
INFO:root:eval perplexity: 5.50931453704834
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.41s/it][A100%|██████████| 1/1 [00:08<00:00,  8.41s/it]
INFO:root:eval mean loss: 5230.103938109486
INFO:root:eval perplexity: 8.488067626953125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/99
 50%|████▉     | 99/200 [4:33:06<4:40:23, 166.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3720.952371115213
INFO:root:current train perplexity4.345455646514893
INFO:root:current mean train loss 3703.032694392179
INFO:root:current train perplexity4.311637878417969
INFO:root:current mean train loss 3717.367164008806
INFO:root:current train perplexity4.323953628540039
INFO:root:current mean train loss 3725.0910500919117
INFO:root:current train perplexity4.331220626831055
INFO:root:current mean train loss 3721.2594871754072
INFO:root:current train perplexity4.328171253204346
INFO:root:current mean train loss 3718.572906339229
INFO:root:current train perplexity4.327558994293213
INFO:root:current mean train loss 3719.9342311301557
INFO:root:current train perplexity4.328342437744141
INFO:root:current mean train loss 3721.696823023665
INFO:root:current train perplexity4.332862377166748
INFO:root:current mean train loss 3722.0529059036544
INFO:root:current train perplexity4.336165904998779
INFO:root:current mean train loss 3723.12251055397
INFO:root:current train perplexity4.3393754959106445

100%|██████████| 1/1 [02:29<00:00, 149.68s/it][A100%|██████████| 1/1 [02:29<00:00, 149.68s/it]
INFO:root:final mean train loss: 3720.1626690280054
INFO:root:final train perplexity: 4.33929443359375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.53s/it][A100%|██████████| 1/1 [00:08<00:00,  8.53s/it]
INFO:root:eval mean loss: 4218.904303800975
INFO:root:eval perplexity: 5.506895542144775
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.50s/it][A100%|██████████| 1/1 [00:08<00:00,  8.51s/it]
INFO:root:eval mean loss: 5229.455136995789
INFO:root:eval perplexity: 8.48581600189209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/100
 50%|█████     | 100/200 [4:35:53<4:37:49, 166.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3716.185608526673
INFO:root:current train perplexity4.3143839836120605
INFO:root:current mean train loss 3710.7902586663786
INFO:root:current train perplexity4.318841934204102
INFO:root:current mean train loss 3707.893091718489
INFO:root:current train perplexity4.320865154266357
INFO:root:current mean train loss 3713.7992986616932
INFO:root:current train perplexity4.3251848220825195
INFO:root:current mean train loss 3706.566771237788
INFO:root:current train perplexity4.321731090545654
INFO:root:current mean train loss 3707.2932825868634
INFO:root:current train perplexity4.3237481117248535
INFO:root:current mean train loss 3710.6511488929495
INFO:root:current train perplexity4.322642803192139
INFO:root:current mean train loss 3712.830805352394
INFO:root:current train perplexity4.32379674911499
INFO:root:current mean train loss 3717.078085894049
INFO:root:current train perplexity4.32703161239624

100%|██████████| 1/1 [02:29<00:00, 149.45s/it][A100%|██████████| 1/1 [02:29<00:00, 149.45s/it]
INFO:root:final mean train loss: 3714.6343131526824
INFO:root:final train perplexity: 4.329841136932373
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.50s/it][A100%|██████████| 1/1 [00:08<00:00,  8.50s/it]
INFO:root:eval mean loss: 4220.5152440713655
INFO:root:eval perplexity: 5.510484218597412
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.43s/it][A100%|██████████| 1/1 [00:08<00:00,  8.43s/it]
INFO:root:eval mean loss: 5234.158871481604
INFO:root:eval perplexity: 8.502152442932129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/101
 50%|█████     | 101/200 [4:38:39<4:35:01, 166.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3732.571044921875
INFO:root:current train perplexity4.292272090911865
INFO:root:current mean train loss 3695.5489216742117
INFO:root:current train perplexity4.26826810836792
INFO:root:current mean train loss 3674.941015860885
INFO:root:current train perplexity4.281120300292969
INFO:root:current mean train loss 3690.257165964729
INFO:root:current train perplexity4.2911696434021
INFO:root:current mean train loss 3695.0978050138206
INFO:root:current train perplexity4.299488544464111
INFO:root:current mean train loss 3697.89895756287
INFO:root:current train perplexity4.302840709686279
INFO:root:current mean train loss 3702.466057615579
INFO:root:current train perplexity4.308497905731201
INFO:root:current mean train loss 3702.4050548504906
INFO:root:current train perplexity4.308858394622803
INFO:root:current mean train loss 3703.8096368688043
INFO:root:current train perplexity4.310090065002441
INFO:root:current mean train loss 3708.3236096097194
INFO:root:current train perplexity4.317697525024414

100%|██████████| 1/1 [02:29<00:00, 149.47s/it][A100%|██████████| 1/1 [02:29<00:00, 149.47s/it]
INFO:root:final mean train loss: 3710.878317740656
INFO:root:final train perplexity: 4.323429107666016
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.69s/it][A100%|██████████| 1/1 [00:08<00:00,  8.69s/it]
INFO:root:eval mean loss: 4221.004299299091
INFO:root:eval perplexity: 5.5115742683410645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.50s/it][A100%|██████████| 1/1 [00:08<00:00,  8.50s/it]
INFO:root:eval mean loss: 5232.4845342974295
INFO:root:eval perplexity: 8.49633502960205
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/102
 51%|█████     | 102/200 [4:41:26<4:32:22, 166.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3740.2352213541667
INFO:root:current train perplexity4.333500385284424
INFO:root:current mean train loss 3691.8821437669835
INFO:root:current train perplexity4.302135467529297
INFO:root:current mean train loss 3720.2893690952037
INFO:root:current train perplexity4.318450927734375
INFO:root:current mean train loss 3714.5784931485614
INFO:root:current train perplexity4.315185546875
INFO:root:current mean train loss 3714.1385348032754
INFO:root:current train perplexity4.315249919891357
INFO:root:current mean train loss 3715.848070103914
INFO:root:current train perplexity4.313395977020264
INFO:root:current mean train loss 3710.3859196360518
INFO:root:current train perplexity4.310516357421875
INFO:root:current mean train loss 3708.3468169525786
INFO:root:current train perplexity4.313838481903076
INFO:root:current mean train loss 3710.473724477569
INFO:root:current train perplexity4.31486701965332
INFO:root:current mean train loss 3709.381173956199
INFO:root:current train perplexity4.313636779785156

100%|██████████| 1/1 [02:29<00:00, 149.12s/it][A100%|██████████| 1/1 [02:29<00:00, 149.12s/it]
INFO:root:final mean train loss: 3705.496152447116
INFO:root:final train perplexity: 4.314258575439453
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.61s/it][A100%|██████████| 1/1 [00:08<00:00,  8.61s/it]
INFO:root:eval mean loss: 4222.062448055186
INFO:root:eval perplexity: 5.513932704925537
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.65s/it][A100%|██████████| 1/1 [00:08<00:00,  8.66s/it]
INFO:root:eval mean loss: 5237.586067362035
INFO:root:eval perplexity: 8.514076232910156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/103
 52%|█████▏    | 103/200 [4:44:13<4:29:33, 166.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3699.5242548403535
INFO:root:current train perplexity4.256292343139648
INFO:root:current mean train loss 3700.2997252921746
INFO:root:current train perplexity4.2999114990234375
INFO:root:current mean train loss 3689.928489787696
INFO:root:current train perplexity4.287631988525391
INFO:root:current mean train loss 3693.505349929857
INFO:root:current train perplexity4.292032718658447
INFO:root:current mean train loss 3698.8755535008495
INFO:root:current train perplexity4.299789905548096
INFO:root:current mean train loss 3697.4177502838193
INFO:root:current train perplexity4.293354034423828
INFO:root:current mean train loss 3699.3445917561194
INFO:root:current train perplexity4.297425270080566
INFO:root:current mean train loss 3701.8512288749134
INFO:root:current train perplexity4.301558494567871
INFO:root:current mean train loss 3702.2388754342915
INFO:root:current train perplexity4.303927421569824
INFO:root:current mean train loss 3704.1662981192444
INFO:root:current train perplexity4.308343887329102

100%|██████████| 1/1 [02:29<00:00, 149.32s/it][A100%|██████████| 1/1 [02:29<00:00, 149.32s/it]
INFO:root:final mean train loss: 3702.346317845006
INFO:root:final train perplexity: 4.308899879455566
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 4223.315883338874
INFO:root:eval perplexity: 5.516728401184082
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.43s/it][A100%|██████████| 1/1 [00:08<00:00,  8.43s/it]
INFO:root:eval mean loss: 5237.351505360705
INFO:root:eval perplexity: 8.513259887695312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/104
 52%|█████▏    | 104/200 [4:46:59<4:26:36, 166.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3710.1357658140123
INFO:root:current train perplexity4.288317680358887
INFO:root:current mean train loss 3690.1641240010736
INFO:root:current train perplexity4.299492359161377
INFO:root:current mean train loss 3684.2366652715773
INFO:root:current train perplexity4.283055782318115
INFO:root:current mean train loss 3691.1153361617257
INFO:root:current train perplexity4.288572311401367
INFO:root:current mean train loss 3694.205552244961
INFO:root:current train perplexity4.291825771331787
INFO:root:current mean train loss 3694.8797393626414
INFO:root:current train perplexity4.291443824768066
INFO:root:current mean train loss 3694.3407382874407
INFO:root:current train perplexity4.294716835021973
INFO:root:current mean train loss 3696.9217270461054
INFO:root:current train perplexity4.296369552612305
INFO:root:current mean train loss 3699.3685242507145
INFO:root:current train perplexity4.298253059387207
INFO:root:current mean train loss 3699.7397148878053
INFO:root:current train perplexity4.299548149108887

100%|██████████| 1/1 [02:29<00:00, 149.69s/it][A100%|██████████| 1/1 [02:29<00:00, 149.69s/it]
INFO:root:final mean train loss: 3696.14420447811
INFO:root:final train perplexity: 4.298369884490967
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.78s/it][A100%|██████████| 1/1 [00:08<00:00,  8.78s/it]
INFO:root:eval mean loss: 4222.23134488586
INFO:root:eval perplexity: 5.514307975769043
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.73s/it][A100%|██████████| 1/1 [00:08<00:00,  8.73s/it]
INFO:root:eval mean loss: 5238.375225094193
INFO:root:eval perplexity: 8.516824722290039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/105
 52%|█████▎    | 105/200 [4:49:47<4:24:15, 166.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3686.2038073417466
INFO:root:current train perplexity4.251875400543213
INFO:root:current mean train loss 3695.0160746402876
INFO:root:current train perplexity4.284460067749023
INFO:root:current mean train loss 3686.730898805243
INFO:root:current train perplexity4.2789201736450195
INFO:root:current mean train loss 3689.9284739986633
INFO:root:current train perplexity4.285312175750732
INFO:root:current mean train loss 3691.0746080402905
INFO:root:current train perplexity4.284278869628906
INFO:root:current mean train loss 3693.4452268922482
INFO:root:current train perplexity4.288066864013672
INFO:root:current mean train loss 3691.2016219495795
INFO:root:current train perplexity4.288754463195801
INFO:root:current mean train loss 3692.5015669269073
INFO:root:current train perplexity4.286623001098633
INFO:root:current mean train loss 3690.9050141653943
INFO:root:current train perplexity4.287461280822754
INFO:root:current mean train loss 3695.204860504443
INFO:root:current train perplexity4.291640281677246

100%|██████████| 1/1 [02:29<00:00, 149.11s/it][A100%|██████████| 1/1 [02:29<00:00, 149.11s/it]
INFO:root:final mean train loss: 3692.720918409286
INFO:root:final train perplexity: 4.292568683624268
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.48s/it][A100%|██████████| 1/1 [00:08<00:00,  8.48s/it]
INFO:root:eval mean loss: 4223.460076947585
INFO:root:eval perplexity: 5.517050266265869
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.64s/it][A100%|██████████| 1/1 [00:08<00:00,  8.64s/it]
INFO:root:eval mean loss: 5242.19588735594
INFO:root:eval perplexity: 8.530141830444336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/106
 53%|█████▎    | 106/200 [4:52:33<4:21:17, 166.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3682.490436959774
INFO:root:current train perplexity4.265211582183838
INFO:root:current mean train loss 3680.728723227572
INFO:root:current train perplexity4.2630438804626465
INFO:root:current mean train loss 3679.6142232176744
INFO:root:current train perplexity4.2653961181640625
INFO:root:current mean train loss 3686.6673566394993
INFO:root:current train perplexity4.271827697753906
INFO:root:current mean train loss 3688.1300881746365
INFO:root:current train perplexity4.2751946449279785
INFO:root:current mean train loss 3685.025749025223
INFO:root:current train perplexity4.271857261657715
INFO:root:current mean train loss 3685.634789020238
INFO:root:current train perplexity4.274129867553711
INFO:root:current mean train loss 3686.880923760145
INFO:root:current train perplexity4.276647090911865
INFO:root:current mean train loss 3686.818305473823
INFO:root:current train perplexity4.277672290802002
INFO:root:current mean train loss 3689.441248731603
INFO:root:current train perplexity4.282079219818115

100%|██████████| 1/1 [02:28<00:00, 148.72s/it][A100%|██████████| 1/1 [02:28<00:00, 148.72s/it]
INFO:root:final mean train loss: 3687.6716327667236
INFO:root:final train perplexity: 4.2840256690979
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.34s/it][A100%|██████████| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 4225.64086221465
INFO:root:eval perplexity: 5.521917819976807
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.37s/it][A100%|██████████| 1/1 [00:08<00:00,  8.37s/it]
INFO:root:eval mean loss: 5241.526907413564
INFO:root:eval perplexity: 8.527809143066406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/107
 54%|█████▎    | 107/200 [4:55:19<4:18:01, 166.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3646.4024147727273
INFO:root:current train perplexity4.248727798461914
INFO:root:current mean train loss 3668.8683908770163
INFO:root:current train perplexity4.263309955596924
INFO:root:current mean train loss 3665.239617800245
INFO:root:current train perplexity4.250316143035889
INFO:root:current mean train loss 3673.984337175396
INFO:root:current train perplexity4.254781723022461
INFO:root:current mean train loss 3673.8837885259272
INFO:root:current train perplexity4.2597150802612305
INFO:root:current mean train loss 3680.0844805743245
INFO:root:current train perplexity4.265099048614502
INFO:root:current mean train loss 3685.140515416269
INFO:root:current train perplexity4.269114017486572
INFO:root:current mean train loss 3688.31640495654
INFO:root:current train perplexity4.273435115814209
INFO:root:current mean train loss 3689.0744728846857
INFO:root:current train perplexity4.2773613929748535
INFO:root:current mean train loss 3688.417690352994
INFO:root:current train perplexity4.279973030090332

100%|██████████| 1/1 [02:29<00:00, 149.19s/it][A100%|██████████| 1/1 [02:29<00:00, 149.19s/it]
INFO:root:final mean train loss: 3684.6913821312687
INFO:root:final train perplexity: 4.278992176055908
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.43s/it][A100%|██████████| 1/1 [00:08<00:00,  8.43s/it]
INFO:root:eval mean loss: 4225.075200506982
INFO:root:eval perplexity: 5.520654678344727
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 5244.343687666224
INFO:root:eval perplexity: 8.53763484954834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/108
 54%|█████▍    | 108/200 [4:58:05<4:15:09, 166.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3677.1573156932045
INFO:root:current train perplexity4.266256332397461
INFO:root:current mean train loss 3672.0341212734857
INFO:root:current train perplexity4.258333206176758
INFO:root:current mean train loss 3663.2773511763307
INFO:root:current train perplexity4.2488508224487305
INFO:root:current mean train loss 3666.5580341769974
INFO:root:current train perplexity4.2509589195251465
INFO:root:current mean train loss 3670.347308758268
INFO:root:current train perplexity4.258941173553467
INFO:root:current mean train loss 3672.7022611845027
INFO:root:current train perplexity4.263490200042725
INFO:root:current mean train loss 3678.259224685968
INFO:root:current train perplexity4.25984001159668
INFO:root:current mean train loss 3680.0998010397893
INFO:root:current train perplexity4.2609992027282715
INFO:root:current mean train loss 3680.5412252521182
INFO:root:current train perplexity4.26397705078125
INFO:root:current mean train loss 3681.3549695673514
INFO:root:current train perplexity4.266932487487793

100%|██████████| 1/1 [02:27<00:00, 147.83s/it][A100%|██████████| 1/1 [02:27<00:00, 147.83s/it]
INFO:root:final mean train loss: 3679.5824119198705
INFO:root:final train perplexity: 4.270375728607178
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.28s/it][A100%|██████████| 1/1 [00:08<00:00,  8.28s/it]
INFO:root:eval mean loss: 4225.384237519393
INFO:root:eval perplexity: 5.521344184875488
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.38s/it][A100%|██████████| 1/1 [00:08<00:00,  8.38s/it]
INFO:root:eval mean loss: 5244.7953028036345
INFO:root:eval perplexity: 8.539213180541992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/109
 55%|█████▍    | 109/200 [5:00:50<4:11:37, 165.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3682.775651958627
INFO:root:current train perplexity4.251701831817627
INFO:root:current mean train loss 3668.687991136696
INFO:root:current train perplexity4.248715877532959
INFO:root:current mean train loss 3672.912989542493
INFO:root:current train perplexity4.2626261711120605
INFO:root:current mean train loss 3672.134058209442
INFO:root:current train perplexity4.256657600402832
INFO:root:current mean train loss 3676.4728070884753
INFO:root:current train perplexity4.258703231811523
INFO:root:current mean train loss 3677.5658132148915
INFO:root:current train perplexity4.2580037117004395
INFO:root:current mean train loss 3678.045463641603
INFO:root:current train perplexity4.25645637512207
INFO:root:current mean train loss 3676.5013077831145
INFO:root:current train perplexity4.261030197143555
INFO:root:current mean train loss 3676.3821916372167
INFO:root:current train perplexity4.263799667358398
INFO:root:current mean train loss 3677.8042859628445
INFO:root:current train perplexity4.263803958892822

100%|██████████| 1/1 [02:27<00:00, 147.71s/it][A100%|██████████| 1/1 [02:27<00:00, 147.71s/it]
INFO:root:final mean train loss: 3675.584917191536
INFO:root:final train perplexity: 4.263645648956299
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.24s/it][A100%|██████████| 1/1 [00:08<00:00,  8.24s/it]
INFO:root:eval mean loss: 4226.600866439495
INFO:root:eval perplexity: 5.524061679840088
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.33s/it][A100%|██████████| 1/1 [00:08<00:00,  8.33s/it]
INFO:root:eval mean loss: 5248.292826767509
INFO:root:eval perplexity: 8.551432609558105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/110
 55%|█████▌    | 110/200 [5:03:34<4:08:14, 165.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3657.6193044155457
INFO:root:current train perplexity4.254425048828125
INFO:root:current mean train loss 3656.188012831704
INFO:root:current train perplexity4.243745803833008
INFO:root:current mean train loss 3661.5562328489023
INFO:root:current train perplexity4.247711658477783
INFO:root:current mean train loss 3660.83075450404
INFO:root:current train perplexity4.248038291931152
INFO:root:current mean train loss 3663.9228576787577
INFO:root:current train perplexity4.251385688781738
INFO:root:current mean train loss 3670.8958114070597
INFO:root:current train perplexity4.250824451446533
INFO:root:current mean train loss 3671.316940914373
INFO:root:current train perplexity4.249881744384766
INFO:root:current mean train loss 3670.895431969071
INFO:root:current train perplexity4.249861240386963
INFO:root:current mean train loss 3671.6422998213525
INFO:root:current train perplexity4.249548435211182
INFO:root:current mean train loss 3673.463674418651
INFO:root:current train perplexity4.254765510559082

100%|██████████| 1/1 [02:27<00:00, 147.45s/it][A100%|██████████| 1/1 [02:27<00:00, 147.45s/it]
INFO:root:final mean train loss: 3670.6088323900776
INFO:root:final train perplexity: 4.255283355712891
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 4228.166746315381
INFO:root:eval perplexity: 5.527561187744141
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 5250.301544838763
INFO:root:eval perplexity: 8.55846118927002
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/111
 56%|█████▌    | 111/200 [5:06:19<4:04:59, 165.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3660.053988752694
INFO:root:current train perplexity4.232340335845947
INFO:root:current mean train loss 3668.5770387700536
INFO:root:current train perplexity4.248980522155762
INFO:root:current mean train loss 3667.0898837312175
INFO:root:current train perplexity4.246034145355225
INFO:root:current mean train loss 3666.865001589753
INFO:root:current train perplexity4.2443318367004395
INFO:root:current mean train loss 3667.7341213343816
INFO:root:current train perplexity4.238356113433838
INFO:root:current mean train loss 3666.0995993931006
INFO:root:current train perplexity4.241497039794922
INFO:root:current mean train loss 3670.519766506323
INFO:root:current train perplexity4.2440571784973145
INFO:root:current mean train loss 3672.0451188626707
INFO:root:current train perplexity4.250406742095947
INFO:root:current mean train loss 3670.173046159368
INFO:root:current train perplexity4.252371788024902
INFO:root:current mean train loss 3670.6987799400013
INFO:root:current train perplexity4.25029993057251

100%|██████████| 1/1 [02:28<00:00, 148.25s/it][A100%|██████████| 1/1 [02:28<00:00, 148.25s/it]
INFO:root:final mean train loss: 3667.504986547655
INFO:root:final train perplexity: 4.250075817108154
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.32s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 4228.041649351729
INFO:root:eval perplexity: 5.527280330657959
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.34s/it][A100%|██████████| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 5252.546547747673
INFO:root:eval perplexity: 8.56632137298584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/112
 56%|█████▌    | 112/200 [5:09:04<4:02:14, 165.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3657.710043174342
INFO:root:current train perplexity4.212611675262451
INFO:root:current mean train loss 3652.0233298277244
INFO:root:current train perplexity4.218323230743408
INFO:root:current mean train loss 3651.4486112950212
INFO:root:current train perplexity4.221953392028809
INFO:root:current mean train loss 3653.5570485561707
INFO:root:current train perplexity4.224058628082275
INFO:root:current mean train loss 3661.017457287721
INFO:root:current train perplexity4.229913711547852
INFO:root:current mean train loss 3665.1090857241334
INFO:root:current train perplexity4.230844974517822
INFO:root:current mean train loss 3664.5215718440872
INFO:root:current train perplexity4.233756065368652
INFO:root:current mean train loss 3661.7057997985457
INFO:root:current train perplexity4.2333245277404785
INFO:root:current mean train loss 3662.905361819134
INFO:root:current train perplexity4.239103317260742

100%|██████████| 1/1 [02:27<00:00, 147.87s/it][A100%|██████████| 1/1 [02:27<00:00, 147.87s/it]
INFO:root:final mean train loss: 3662.409377621066
INFO:root:final train perplexity: 4.241540431976318
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.24s/it][A100%|██████████| 1/1 [00:08<00:00,  8.24s/it]
INFO:root:eval mean loss: 4229.019292303857
INFO:root:eval perplexity: 5.52946662902832
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 5252.253082058954
INFO:root:eval perplexity: 8.565293312072754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/113
 56%|█████▋    | 113/200 [5:11:49<3:59:16, 165.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3754.49560546875
INFO:root:current train perplexity4.1760945320129395
INFO:root:current mean train loss 3628.393059295358
INFO:root:current train perplexity4.217698097229004
INFO:root:current mean train loss 3632.988016664101
INFO:root:current train perplexity4.209721565246582
INFO:root:current mean train loss 3643.2564330651817
INFO:root:current train perplexity4.208756446838379
INFO:root:current mean train loss 3652.1912572212314
INFO:root:current train perplexity4.219603538513184
INFO:root:current mean train loss 3650.5783458429114
INFO:root:current train perplexity4.2210164070129395
INFO:root:current mean train loss 3654.771060469139
INFO:root:current train perplexity4.225593090057373
INFO:root:current mean train loss 3655.4077471411583
INFO:root:current train perplexity4.228381633758545
INFO:root:current mean train loss 3659.558770090676
INFO:root:current train perplexity4.234060764312744
INFO:root:current mean train loss 3663.324261738216
INFO:root:current train perplexity4.236553192138672

100%|██████████| 1/1 [02:27<00:00, 147.56s/it][A100%|██████████| 1/1 [02:27<00:00, 147.56s/it]
INFO:root:final mean train loss: 3660.2620085439376
INFO:root:final train perplexity: 4.237948894500732
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 4228.556406873337
INFO:root:eval perplexity: 5.528430938720703
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.43s/it][A100%|██████████| 1/1 [00:08<00:00,  8.43s/it]
INFO:root:eval mean loss: 5253.16564162234
INFO:root:eval perplexity: 8.568488121032715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/114
 57%|█████▋    | 114/200 [5:14:33<3:56:21, 164.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3637.4366566051135
INFO:root:current train perplexity4.256260871887207
INFO:root:current mean train loss 3658.079932960304
INFO:root:current train perplexity4.2251200675964355
INFO:root:current mean train loss 3655.6878193498223
INFO:root:current train perplexity4.222556114196777
INFO:root:current mean train loss 3660.012441751658
INFO:root:current train perplexity4.227173805236816
INFO:root:current mean train loss 3661.708252547141
INFO:root:current train perplexity4.225066661834717
INFO:root:current mean train loss 3650.151893212604
INFO:root:current train perplexity4.218514919281006
INFO:root:current mean train loss 3651.536471252941
INFO:root:current train perplexity4.222349643707275
INFO:root:current mean train loss 3653.297788037865
INFO:root:current train perplexity4.222376823425293
INFO:root:current mean train loss 3652.3796025474917
INFO:root:current train perplexity4.2242889404296875
INFO:root:current mean train loss 3655.1974060527577
INFO:root:current train perplexity4.227756500244141

100%|██████████| 1/1 [02:27<00:00, 147.64s/it][A100%|██████████| 1/1 [02:27<00:00, 147.64s/it]
INFO:root:final mean train loss: 3654.9049667235345
INFO:root:final train perplexity: 4.229001045227051
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.28s/it][A100%|██████████| 1/1 [00:08<00:00,  8.28s/it]
INFO:root:eval mean loss: 4230.38315014129
INFO:root:eval perplexity: 5.5325164794921875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.38s/it][A100%|██████████| 1/1 [00:08<00:00,  8.38s/it]
INFO:root:eval mean loss: 5255.667672664561
INFO:root:eval perplexity: 8.577260971069336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/115
 57%|█████▊    | 115/200 [5:17:18<3:53:28, 164.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3612.111392372533
INFO:root:current train perplexity4.166551113128662
INFO:root:current mean train loss 3634.0155839679624
INFO:root:current train perplexity4.20650577545166
INFO:root:current mean train loss 3644.7853256992007
INFO:root:current train perplexity4.21335506439209
INFO:root:current mean train loss 3649.741520896601
INFO:root:current train perplexity4.217331886291504
INFO:root:current mean train loss 3645.1798261765366
INFO:root:current train perplexity4.218113899230957
INFO:root:current mean train loss 3644.7906195432925
INFO:root:current train perplexity4.218722820281982
INFO:root:current mean train loss 3649.3646549847285
INFO:root:current train perplexity4.2210211753845215
INFO:root:current mean train loss 3652.8017578125
INFO:root:current train perplexity4.221693515777588
INFO:root:current mean train loss 3652.5819227430557
INFO:root:current train perplexity4.220517158508301
INFO:root:current mean train loss 3654.2487681391967
INFO:root:current train perplexity4.222268581390381

100%|██████████| 1/1 [02:27<00:00, 147.68s/it][A100%|██████████| 1/1 [02:27<00:00, 147.68s/it]
INFO:root:final mean train loss: 3652.208001905872
INFO:root:final train perplexity: 4.224503993988037
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.28s/it][A100%|██████████| 1/1 [00:08<00:00,  8.28s/it]
INFO:root:eval mean loss: 4229.819202612478
INFO:root:eval perplexity: 5.531254291534424
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.38s/it][A100%|██████████| 1/1 [00:08<00:00,  8.38s/it]
INFO:root:eval mean loss: 5253.510679853724
INFO:root:eval perplexity: 8.569700241088867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/116
 58%|█████▊    | 116/200 [5:20:03<3:50:37, 164.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3629.1266818576387
INFO:root:current train perplexity4.190070629119873
INFO:root:current mean train loss 3629.6241887610727
INFO:root:current train perplexity4.1808929443359375
INFO:root:current mean train loss 3641.822223680135
INFO:root:current train perplexity4.2053985595703125
INFO:root:current mean train loss 3637.312966629635
INFO:root:current train perplexity4.207077980041504
INFO:root:current mean train loss 3642.3669330677326
INFO:root:current train perplexity4.207492828369141
INFO:root:current mean train loss 3643.4758560209616
INFO:root:current train perplexity4.207924842834473
INFO:root:current mean train loss 3645.796149197568
INFO:root:current train perplexity4.210740566253662
INFO:root:current mean train loss 3642.4378008940853
INFO:root:current train perplexity4.209445476531982
INFO:root:current mean train loss 3646.2265678138224
INFO:root:current train perplexity4.212812900543213
INFO:root:current mean train loss 3649.230699195574
INFO:root:current train perplexity4.215333461761475

100%|██████████| 1/1 [02:27<00:00, 147.54s/it][A100%|██████████| 1/1 [02:27<00:00, 147.54s/it]
INFO:root:final mean train loss: 3647.8399420092182
INFO:root:final train perplexity: 4.217229843139648
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.27s/it][A100%|██████████| 1/1 [00:08<00:00,  8.27s/it]
INFO:root:eval mean loss: 4230.785450603945
INFO:root:eval perplexity: 5.533416271209717
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.42s/it][A100%|██████████| 1/1 [00:08<00:00,  8.42s/it]
INFO:root:eval mean loss: 5256.377744417664
INFO:root:eval perplexity: 8.579751968383789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/117
 58%|█████▊    | 117/200 [5:22:47<3:47:47, 164.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3590.175767299107
INFO:root:current train perplexity4.155088901519775
INFO:root:current mean train loss 3614.207174117477
INFO:root:current train perplexity4.1711039543151855
INFO:root:current mean train loss 3632.6077688663563
INFO:root:current train perplexity4.189382076263428
INFO:root:current mean train loss 3637.599662575793
INFO:root:current train perplexity4.202640533447266
INFO:root:current mean train loss 3638.3679693112426
INFO:root:current train perplexity4.206362247467041
INFO:root:current mean train loss 3641.8361305308117
INFO:root:current train perplexity4.207731246948242
INFO:root:current mean train loss 3646.1365453524854
INFO:root:current train perplexity4.208456039428711
INFO:root:current mean train loss 3649.547567230017
INFO:root:current train perplexity4.209413528442383
INFO:root:current mean train loss 3645.2081504958833
INFO:root:current train perplexity4.207968235015869
INFO:root:current mean train loss 3647.001617855949
INFO:root:current train perplexity4.209954738616943

100%|██████████| 1/1 [02:27<00:00, 147.74s/it][A100%|██████████| 1/1 [02:27<00:00, 147.74s/it]
INFO:root:final mean train loss: 3643.400311254686
INFO:root:final train perplexity: 4.209849834442139
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.26s/it][A100%|██████████| 1/1 [00:08<00:00,  8.26s/it]
INFO:root:eval mean loss: 4230.269470647717
INFO:root:eval perplexity: 5.532262325286865
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.44s/it][A100%|██████████| 1/1 [00:08<00:00,  8.44s/it]
INFO:root:eval mean loss: 5260.629939951795
INFO:root:eval perplexity: 8.594683647155762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/118
 59%|█████▉    | 118/200 [5:25:32<3:45:04, 164.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3645.1039187409156
INFO:root:current train perplexity4.236955165863037
INFO:root:current mean train loss 3647.647633372487
INFO:root:current train perplexity4.2186784744262695
INFO:root:current mean train loss 3648.296819741834
INFO:root:current train perplexity4.214074611663818
INFO:root:current mean train loss 3643.771467292274
INFO:root:current train perplexity4.21051025390625
INFO:root:current mean train loss 3649.814145055904
INFO:root:current train perplexity4.214632034301758
INFO:root:current mean train loss 3649.120290289048
INFO:root:current train perplexity4.21368932723999
INFO:root:current mean train loss 3648.691747591247
INFO:root:current train perplexity4.209144115447998
INFO:root:current mean train loss 3647.5860203040884
INFO:root:current train perplexity4.209024429321289
INFO:root:current mean train loss 3645.0619946318025
INFO:root:current train perplexity4.205525875091553
INFO:root:current mean train loss 3644.5891519750794
INFO:root:current train perplexity4.206481456756592

100%|██████████| 1/1 [02:27<00:00, 147.54s/it][A100%|██████████| 1/1 [02:27<00:00, 147.54s/it]
INFO:root:final mean train loss: 3640.7624605855635
INFO:root:final train perplexity: 4.205470561981201
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.27s/it][A100%|██████████| 1/1 [00:08<00:00,  8.27s/it]
INFO:root:eval mean loss: 4233.287240968529
INFO:root:eval perplexity: 5.539017677307129
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.41s/it][A100%|██████████| 1/1 [00:08<00:00,  8.41s/it]
INFO:root:eval mean loss: 5264.184710563497
INFO:root:eval perplexity: 8.607186317443848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/119
 60%|█████▉    | 119/200 [5:28:16<3:42:16, 164.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3648.0239114200367
INFO:root:current train perplexity4.178347587585449
INFO:root:current mean train loss 3619.188950292322
INFO:root:current train perplexity4.172051906585693
INFO:root:current mean train loss 3630.833699382159
INFO:root:current train perplexity4.180108070373535
INFO:root:current mean train loss 3634.51187803263
INFO:root:current train perplexity4.185736656188965
INFO:root:current mean train loss 3635.020751953125
INFO:root:current train perplexity4.193310260772705
INFO:root:current mean train loss 3633.884362859432
INFO:root:current train perplexity4.19369649887085
INFO:root:current mean train loss 3635.015201972926
INFO:root:current train perplexity4.195285797119141
INFO:root:current mean train loss 3634.5545750197653
INFO:root:current train perplexity4.1943135261535645
INFO:root:current mean train loss 3634.1827666554973
INFO:root:current train perplexity4.194868087768555
INFO:root:current mean train loss 3637.3078128080638
INFO:root:current train perplexity4.196911334991455

100%|██████████| 1/1 [02:27<00:00, 147.79s/it][A100%|██████████| 1/1 [02:27<00:00, 147.79s/it]
INFO:root:final mean train loss: 3636.4731075532973
INFO:root:final train perplexity: 4.19835901260376
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.26s/it][A100%|██████████| 1/1 [00:08<00:00,  8.26s/it]
INFO:root:eval mean loss: 4232.54920212766
INFO:root:eval perplexity: 5.537364482879639
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 5263.097247617465
INFO:root:eval perplexity: 8.60335922241211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/120
 60%|██████    | 120/200 [5:31:01<3:39:32, 164.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3641.1691977290784
INFO:root:current train perplexity4.156647205352783
INFO:root:current mean train loss 3612.2050213124016
INFO:root:current train perplexity4.148665428161621
INFO:root:current mean train loss 3617.4930405782457
INFO:root:current train perplexity4.162425518035889
INFO:root:current mean train loss 3623.582400521196
INFO:root:current train perplexity4.167591094970703
INFO:root:current mean train loss 3625.6626040390115
INFO:root:current train perplexity4.173212051391602
INFO:root:current mean train loss 3625.177443065882
INFO:root:current train perplexity4.178508758544922
INFO:root:current mean train loss 3628.296663090383
INFO:root:current train perplexity4.1831512451171875
INFO:root:current mean train loss 3631.1596602488885
INFO:root:current train perplexity4.187508583068848
INFO:root:current mean train loss 3634.6947810180804
INFO:root:current train perplexity4.191534996032715
INFO:root:current mean train loss 3634.957923801649
INFO:root:current train perplexity4.1914963722229

100%|██████████| 1/1 [02:27<00:00, 147.49s/it][A100%|██████████| 1/1 [02:27<00:00, 147.49s/it]
INFO:root:final mean train loss: 3632.9560633013325
INFO:root:final train perplexity: 4.192538261413574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 4233.549548426418
INFO:root:eval perplexity: 5.539605140686035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.34s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 5266.8614649130095
INFO:root:eval perplexity: 8.616612434387207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/121
 60%|██████    | 121/200 [5:33:45<3:36:44, 164.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3621.542633512127
INFO:root:current train perplexity4.150567531585693
INFO:root:current mean train loss 3635.658431184506
INFO:root:current train perplexity4.158979415893555
INFO:root:current mean train loss 3635.742061314958
INFO:root:current train perplexity4.169273376464844
INFO:root:current mean train loss 3625.6912998126704
INFO:root:current train perplexity4.167883396148682
INFO:root:current mean train loss 3627.8099378304
INFO:root:current train perplexity4.171488285064697
INFO:root:current mean train loss 3625.421337201692
INFO:root:current train perplexity4.172761917114258
INFO:root:current mean train loss 3628.1225260172646
INFO:root:current train perplexity4.175150394439697
INFO:root:current mean train loss 3630.5384147474942
INFO:root:current train perplexity4.181610107421875
INFO:root:current mean train loss 3631.191117617773
INFO:root:current train perplexity4.184022426605225
INFO:root:current mean train loss 3631.626226509986
INFO:root:current train perplexity4.185850620269775

100%|██████████| 1/1 [02:27<00:00, 147.79s/it][A100%|██████████| 1/1 [02:27<00:00, 147.79s/it]
INFO:root:final mean train loss: 3628.3763372359736
INFO:root:final train perplexity: 4.184969902038574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.28s/it][A100%|██████████| 1/1 [00:08<00:00,  8.28s/it]
INFO:root:eval mean loss: 4233.613237962655
INFO:root:eval perplexity: 5.53974723815918
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.34s/it][A100%|██████████| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 5268.392612754876
INFO:root:eval perplexity: 8.622008323669434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/122
 61%|██████    | 122/200 [5:36:30<3:34:02, 164.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3626.055598958333
INFO:root:current train perplexity4.148848533630371
INFO:root:current mean train loss 3626.9460100446427
INFO:root:current train perplexity4.173417091369629
INFO:root:current mean train loss 3620.947059659091
INFO:root:current train perplexity4.16837215423584
INFO:root:current mean train loss 3619.274401041667
INFO:root:current train perplexity4.167744159698486
INFO:root:current mean train loss 3625.7297116570726
INFO:root:current train perplexity4.167905330657959
INFO:root:current mean train loss 3627.4145078974184
INFO:root:current train perplexity4.170454502105713
INFO:root:current mean train loss 3626.320317563657
INFO:root:current train perplexity4.170621395111084
INFO:root:current mean train loss 3628.1379334677417
INFO:root:current train perplexity4.178168773651123
INFO:root:current mean train loss 3629.836386439732
INFO:root:current train perplexity4.182509422302246
INFO:root:current mean train loss 3631.1808971854966
INFO:root:current train perplexity4.183305740356445

100%|██████████| 1/1 [02:27<00:00, 147.78s/it][A100%|██████████| 1/1 [02:27<00:00, 147.78s/it]
INFO:root:final mean train loss: 3626.941892070155
INFO:root:final train perplexity: 4.182602405548096
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 4236.354383103391
INFO:root:eval perplexity: 5.545890808105469
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 5269.238291638962
INFO:root:eval perplexity: 8.624992370605469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/123
 62%|██████▏   | 123/200 [5:39:15<3:31:18, 164.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3625.4227074312876
INFO:root:current train perplexity4.157689094543457
INFO:root:current mean train loss 3617.852461684597
INFO:root:current train perplexity4.1641998291015625
INFO:root:current mean train loss 3627.1275725347837
INFO:root:current train perplexity4.169973373413086
INFO:root:current mean train loss 3626.989347054504
INFO:root:current train perplexity4.171648979187012
INFO:root:current mean train loss 3625.795425825731
INFO:root:current train perplexity4.176255226135254
INFO:root:current mean train loss 3624.6365864199183
INFO:root:current train perplexity4.177484512329102
INFO:root:current mean train loss 3622.1450395486363
INFO:root:current train perplexity4.173951148986816
INFO:root:current mean train loss 3622.7402418582374
INFO:root:current train perplexity4.173799514770508
INFO:root:current mean train loss 3622.667556503486
INFO:root:current train perplexity4.172959804534912
INFO:root:current mean train loss 3625.2236511913466
INFO:root:current train perplexity4.175961017608643

100%|██████████| 1/1 [02:27<00:00, 147.57s/it][A100%|██████████| 1/1 [02:27<00:00, 147.57s/it]
INFO:root:final mean train loss: 3622.7871557051135
INFO:root:final train perplexity: 4.17575216293335
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.37s/it][A100%|██████████| 1/1 [00:08<00:00,  8.37s/it]
INFO:root:eval mean loss: 4236.435034352837
INFO:root:eval perplexity: 5.546072006225586
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 5270.20606853945
INFO:root:eval perplexity: 8.62840461730957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/124
 62%|██████▏   | 124/200 [5:41:59<3:28:32, 164.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3602.618134550996
INFO:root:current train perplexity4.123535633087158
INFO:root:current mean train loss 3599.4120646371894
INFO:root:current train perplexity4.135401725769043
INFO:root:current mean train loss 3618.2552645444052
INFO:root:current train perplexity4.141257286071777
INFO:root:current mean train loss 3620.2589364210357
INFO:root:current train perplexity4.146711349487305
INFO:root:current mean train loss 3620.24018166847
INFO:root:current train perplexity4.152447700500488
INFO:root:current mean train loss 3621.258694050074
INFO:root:current train perplexity4.157050132751465
INFO:root:current mean train loss 3618.4044523335747
INFO:root:current train perplexity4.1607160568237305
INFO:root:current mean train loss 3621.28088178285
INFO:root:current train perplexity4.165525436401367
INFO:root:current mean train loss 3619.6909738662666
INFO:root:current train perplexity4.167606353759766
INFO:root:current mean train loss 3622.213734893337
INFO:root:current train perplexity4.170104026794434

100%|██████████| 1/1 [02:27<00:00, 147.63s/it][A100%|██████████| 1/1 [02:27<00:00, 147.63s/it]
INFO:root:final mean train loss: 3619.3475115376136
INFO:root:final train perplexity: 4.170089244842529
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.33s/it][A100%|██████████| 1/1 [00:08<00:00,  8.33s/it]
INFO:root:eval mean loss: 4236.577557070035
INFO:root:eval perplexity: 5.54639196395874
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.33s/it][A100%|██████████| 1/1 [00:08<00:00,  8.33s/it]
INFO:root:eval mean loss: 5271.620458291777
INFO:root:eval perplexity: 8.63339614868164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/125
 62%|██████▎   | 125/200 [5:44:44<3:25:46, 164.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3626.0618711529355
INFO:root:current train perplexity4.1540727615356445
INFO:root:current mean train loss 3607.196214225424
INFO:root:current train perplexity4.148096561431885
INFO:root:current mean train loss 3611.118881786946
INFO:root:current train perplexity4.153331279754639
INFO:root:current mean train loss 3613.3103645343826
INFO:root:current train perplexity4.155137062072754
INFO:root:current mean train loss 3609.811223521261
INFO:root:current train perplexity4.152514457702637
INFO:root:current mean train loss 3613.8456366894043
INFO:root:current train perplexity4.1592912673950195
INFO:root:current mean train loss 3615.0725576157906
INFO:root:current train perplexity4.160386085510254
INFO:root:current mean train loss 3617.490848546034
INFO:root:current train perplexity4.162911415100098
INFO:root:current mean train loss 3617.7542981242177
INFO:root:current train perplexity4.1627702713012695

100%|██████████| 1/1 [02:27<00:00, 147.94s/it][A100%|██████████| 1/1 [02:27<00:00, 147.94s/it]
INFO:root:final mean train loss: 3616.348477209768
INFO:root:final train perplexity: 4.165157318115234
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 4238.189446199025
INFO:root:eval perplexity: 5.550008773803711
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 5273.858891913232
INFO:root:eval perplexity: 8.641302108764648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/126
 63%|██████▎   | 126/200 [5:47:29<3:23:08, 164.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3636.782470703125
INFO:root:current train perplexity4.219597339630127
INFO:root:current mean train loss 3611.7805951555197
INFO:root:current train perplexity4.163687229156494
INFO:root:current mean train loss 3603.656608544686
INFO:root:current train perplexity4.15875768661499
INFO:root:current mean train loss 3604.9420185896784
INFO:root:current train perplexity4.156100749969482
INFO:root:current mean train loss 3603.722355723088
INFO:root:current train perplexity4.150686740875244
INFO:root:current mean train loss 3604.425840960922
INFO:root:current train perplexity4.152325630187988
INFO:root:current mean train loss 3607.7236352257514
INFO:root:current train perplexity4.155452251434326
INFO:root:current mean train loss 3609.406985184428
INFO:root:current train perplexity4.155782699584961
INFO:root:current mean train loss 3612.634248603528
INFO:root:current train perplexity4.157691478729248
INFO:root:current mean train loss 3614.548562181298
INFO:root:current train perplexity4.157140731811523

100%|██████████| 1/1 [02:27<00:00, 147.68s/it][A100%|██████████| 1/1 [02:27<00:00, 147.68s/it]
INFO:root:final mean train loss: 3612.1408648337087
INFO:root:final train perplexity: 4.1582489013671875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 4237.7134862588655
INFO:root:eval perplexity: 5.548940181732178
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.32s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 5275.655683801529
INFO:root:eval perplexity: 8.647651672363281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/127
 64%|██████▎   | 127/200 [5:50:14<3:20:21, 164.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3609.2638346354165
INFO:root:current train perplexity4.137124061584473
INFO:root:current mean train loss 3591.3833984375
INFO:root:current train perplexity4.1452484130859375
INFO:root:current mean train loss 3596.2363508357557
INFO:root:current train perplexity4.144219398498535
INFO:root:current mean train loss 3601.005667937748
INFO:root:current train perplexity4.136977672576904
INFO:root:current mean train loss 3600.9191470961973
INFO:root:current train perplexity4.137741565704346
INFO:root:current mean train loss 3598.117779600273
INFO:root:current train perplexity4.137413501739502
INFO:root:current mean train loss 3603.73662109375
INFO:root:current train perplexity4.145187854766846
INFO:root:current mean train loss 3608.8694639832825
INFO:root:current train perplexity4.150163173675537
INFO:root:current mean train loss 3611.6189375239646
INFO:root:current train perplexity4.151611804962158
INFO:root:current mean train loss 3611.130937553364
INFO:root:current train perplexity4.150806903839111

100%|██████████| 1/1 [02:30<00:00, 150.04s/it][A100%|██████████| 1/1 [02:30<00:00, 150.04s/it]
INFO:root:final mean train loss: 3609.016328565536
INFO:root:final train perplexity: 4.1531267166137695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.41s/it][A100%|██████████| 1/1 [00:08<00:00,  8.41s/it]
INFO:root:eval mean loss: 4237.574050795102
INFO:root:eval perplexity: 5.5486273765563965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.41s/it][A100%|██████████| 1/1 [00:08<00:00,  8.41s/it]
INFO:root:eval mean loss: 5275.511699703568
INFO:root:eval perplexity: 8.647147178649902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/128
 64%|██████▍   | 128/200 [5:53:01<3:18:30, 165.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3592.537947944973
INFO:root:current train perplexity4.143087863922119
INFO:root:current mean train loss 3607.6277828061484
INFO:root:current train perplexity4.144443511962891
INFO:root:current mean train loss 3600.013756174678
INFO:root:current train perplexity4.135399341583252
INFO:root:current mean train loss 3599.1985218532313
INFO:root:current train perplexity4.137766361236572
INFO:root:current mean train loss 3605.8460667386967
INFO:root:current train perplexity4.144184112548828
INFO:root:current mean train loss 3603.9629424406967
INFO:root:current train perplexity4.14347505569458
INFO:root:current mean train loss 3603.412901754364
INFO:root:current train perplexity4.13798189163208
INFO:root:current mean train loss 3605.5295305476316
INFO:root:current train perplexity4.138865947723389
INFO:root:current mean train loss 3608.4279966111026
INFO:root:current train perplexity4.145096302032471
INFO:root:current mean train loss 3608.893707572962
INFO:root:current train perplexity4.149001598358154

100%|██████████| 1/1 [02:28<00:00, 148.66s/it][A100%|██████████| 1/1 [02:28<00:00, 148.66s/it]
INFO:root:final mean train loss: 3605.566968671737
INFO:root:final train perplexity: 4.147478103637695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.32s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 4238.68692514406
INFO:root:eval perplexity: 5.5511250495910645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.39s/it][A100%|██████████| 1/1 [00:08<00:00,  8.39s/it]
INFO:root:eval mean loss: 5276.904850953014
INFO:root:eval perplexity: 8.652070999145508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/129
 64%|██████▍   | 129/200 [5:55:46<3:15:49, 165.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3566.521224483367
INFO:root:current train perplexity4.149591445922852
INFO:root:current mean train loss 3595.6843820819417
INFO:root:current train perplexity4.136598587036133
INFO:root:current mean train loss 3602.9327334449404
INFO:root:current train perplexity4.140821933746338
INFO:root:current mean train loss 3601.742166847621
INFO:root:current train perplexity4.138275623321533
INFO:root:current mean train loss 3600.700003285419
INFO:root:current train perplexity4.133316516876221
INFO:root:current mean train loss 3600.7502501177023
INFO:root:current train perplexity4.131508827209473
INFO:root:current mean train loss 3599.684684451144
INFO:root:current train perplexity4.134676933288574
INFO:root:current mean train loss 3601.3378258325497
INFO:root:current train perplexity4.134947776794434
INFO:root:current mean train loss 3603.2808630767713
INFO:root:current train perplexity4.1407928466796875
INFO:root:current mean train loss 3602.6200770655714
INFO:root:current train perplexity4.1412553787231445

100%|██████████| 1/1 [02:28<00:00, 148.23s/it][A100%|██████████| 1/1 [02:28<00:00, 148.24s/it]
INFO:root:final mean train loss: 3603.1795782273816
INFO:root:final train perplexity: 4.14357328414917
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.32s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 4239.348243226396
INFO:root:eval perplexity: 5.552608489990234
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 5277.97180781804
INFO:root:eval perplexity: 8.655847549438477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/130
 65%|██████▌   | 130/200 [5:58:32<3:12:57, 165.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3631.499762119391
INFO:root:current train perplexity4.1333184242248535
INFO:root:current mean train loss 3605.9280979513264
INFO:root:current train perplexity4.11653470993042
INFO:root:current mean train loss 3606.393467859244
INFO:root:current train perplexity4.131965637207031
INFO:root:current mean train loss 3605.233698031895
INFO:root:current train perplexity4.130975246429443
INFO:root:current mean train loss 3609.4378792799685
INFO:root:current train perplexity4.13629150390625
INFO:root:current mean train loss 3607.918830262929
INFO:root:current train perplexity4.135224342346191
INFO:root:current mean train loss 3610.3327308141384
INFO:root:current train perplexity4.140010833740234
INFO:root:current mean train loss 3609.936933752326
INFO:root:current train perplexity4.142048358917236
INFO:root:current mean train loss 3606.7509003231153
INFO:root:current train perplexity4.138364315032959
INFO:root:current mean train loss 3603.7788592938796
INFO:root:current train perplexity4.1369805335998535

100%|██████████| 1/1 [02:28<00:00, 148.47s/it][A100%|██████████| 1/1 [02:28<00:00, 148.47s/it]
INFO:root:final mean train loss: 3599.0256886636057
INFO:root:final train perplexity: 4.136788368225098
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 4240.790568899601
INFO:root:eval perplexity: 5.555849075317383
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.41s/it][A100%|██████████| 1/1 [00:08<00:00,  8.41s/it]
INFO:root:eval mean loss: 5280.551896332004
INFO:root:eval perplexity: 8.664985656738281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/131
 66%|██████▌   | 131/200 [6:01:17<3:10:14, 165.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3586.2469144780584
INFO:root:current train perplexity4.090339660644531
INFO:root:current mean train loss 3593.687282432504
INFO:root:current train perplexity4.1069817543029785
INFO:root:current mean train loss 3595.010590958692
INFO:root:current train perplexity4.1075897216796875
INFO:root:current mean train loss 3592.0530143979645
INFO:root:current train perplexity4.1118316650390625
INFO:root:current mean train loss 3590.2204376835152
INFO:root:current train perplexity4.1078362464904785
INFO:root:current mean train loss 3591.082166040619
INFO:root:current train perplexity4.114471435546875
INFO:root:current mean train loss 3593.894691997923
INFO:root:current train perplexity4.119665622711182
INFO:root:current mean train loss 3593.6519440391776
INFO:root:current train perplexity4.123958587646484
INFO:root:current mean train loss 3595.1348982161303
INFO:root:current train perplexity4.12923526763916
INFO:root:current mean train loss 3596.4809534219903
INFO:root:current train perplexity4.130913734436035

100%|██████████| 1/1 [02:28<00:00, 148.44s/it][A100%|██████████| 1/1 [02:28<00:00, 148.44s/it]
INFO:root:final mean train loss: 3595.60792492282
INFO:root:final train perplexity: 4.131214618682861
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 4241.11245532746
INFO:root:eval perplexity: 5.556572437286377
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 5281.44657649047
INFO:root:eval perplexity: 8.668155670166016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/132
 66%|██████▌   | 132/200 [6:04:02<3:07:28, 165.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3578.387912819602
INFO:root:current train perplexity4.107100963592529
INFO:root:current mean train loss 3586.238388356855
INFO:root:current train perplexity4.116350173950195
INFO:root:current mean train loss 3581.2211847043504
INFO:root:current train perplexity4.111323833465576
INFO:root:current mean train loss 3585.153523877641
INFO:root:current train perplexity4.119873046875
INFO:root:current mean train loss 3589.918809559581
INFO:root:current train perplexity4.121567249298096
INFO:root:current mean train loss 3594.516231612472
INFO:root:current train perplexity4.122422218322754
INFO:root:current mean train loss 3595.9918635943463
INFO:root:current train perplexity4.124394416809082
INFO:root:current mean train loss 3596.7358776774627
INFO:root:current train perplexity4.124999046325684
INFO:root:current mean train loss 3597.120838473136
INFO:root:current train perplexity4.126882553100586
INFO:root:current mean train loss 3597.2427292109783
INFO:root:current train perplexity4.129516124725342

100%|██████████| 1/1 [02:28<00:00, 148.20s/it][A100%|██████████| 1/1 [02:28<00:00, 148.20s/it]
INFO:root:final mean train loss: 3594.52917849633
INFO:root:final train perplexity: 4.129456043243408
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.25s/it][A100%|██████████| 1/1 [00:08<00:00,  8.25s/it]
INFO:root:eval mean loss: 4242.744021151928
INFO:root:eval perplexity: 5.560238838195801
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.34s/it][A100%|██████████| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 5285.969369874779
INFO:root:eval perplexity: 8.684199333190918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/133
 66%|██████▋   | 133/200 [6:06:48<3:04:37, 165.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3584.5555323040676
INFO:root:current train perplexity4.095198631286621
INFO:root:current mean train loss 3584.619416219325
INFO:root:current train perplexity4.121853828430176
INFO:root:current mean train loss 3580.876984686906
INFO:root:current train perplexity4.111979007720947
INFO:root:current mean train loss 3581.5157157961003
INFO:root:current train perplexity4.108994483947754
INFO:root:current mean train loss 3583.7879941870274
INFO:root:current train perplexity4.112788677215576
INFO:root:current mean train loss 3584.381054514043
INFO:root:current train perplexity4.109805583953857
INFO:root:current mean train loss 3587.177087752168
INFO:root:current train perplexity4.112966537475586
INFO:root:current mean train loss 3589.004779460702
INFO:root:current train perplexity4.116057395935059
INFO:root:current mean train loss 3592.1451191112037
INFO:root:current train perplexity4.1224470138549805
INFO:root:current mean train loss 3592.2301830319475
INFO:root:current train perplexity4.121662616729736

100%|██████████| 1/1 [02:27<00:00, 147.88s/it][A100%|██████████| 1/1 [02:27<00:00, 147.88s/it]
INFO:root:final mean train loss: 3590.0840902020855
INFO:root:final train perplexity: 4.122220993041992
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.28s/it][A100%|██████████| 1/1 [00:08<00:00,  8.28s/it]
INFO:root:eval mean loss: 4243.589816046099
INFO:root:eval perplexity: 5.562140464782715
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 5284.433418869126
INFO:root:eval perplexity: 8.678747177124023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/134
 67%|██████▋   | 134/200 [6:09:32<3:01:41, 165.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3592.8171455490756
INFO:root:current train perplexity4.115214824676514
INFO:root:current mean train loss 3589.1720691703217
INFO:root:current train perplexity4.107211589813232
INFO:root:current mean train loss 3588.802958696091
INFO:root:current train perplexity4.105896472930908
INFO:root:current mean train loss 3590.238212811658
INFO:root:current train perplexity4.108051776885986
INFO:root:current mean train loss 3592.554276452196
INFO:root:current train perplexity4.110411643981934
INFO:root:current mean train loss 3594.5697664972363
INFO:root:current train perplexity4.110980033874512
INFO:root:current mean train loss 3591.5349204778317
INFO:root:current train perplexity4.113307476043701
INFO:root:current mean train loss 3590.961771567972
INFO:root:current train perplexity4.114999294281006
INFO:root:current mean train loss 3590.156978497686
INFO:root:current train perplexity4.117981433868408
INFO:root:current mean train loss 3590.195607429921
INFO:root:current train perplexity4.1190505027771

100%|██████████| 1/1 [02:27<00:00, 147.93s/it][A100%|██████████| 1/1 [02:27<00:00, 147.93s/it]
INFO:root:final mean train loss: 3588.1261609600438
INFO:root:final train perplexity: 4.119038105010986
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 4242.185952044548
INFO:root:eval perplexity: 5.55898380279541
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 5284.4877375609485
INFO:root:eval perplexity: 8.67894172668457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/135
 68%|██████▊   | 135/200 [6:12:17<2:58:52, 165.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3579.450439453125
INFO:root:current train perplexity4.091950416564941
INFO:root:current mean train loss 3575.248742471194
INFO:root:current train perplexity4.085024356842041
INFO:root:current mean train loss 3572.9042364961356
INFO:root:current train perplexity4.096142292022705
INFO:root:current mean train loss 3576.933699393964
INFO:root:current train perplexity4.094883441925049
INFO:root:current mean train loss 3583.1819357344402
INFO:root:current train perplexity4.098116874694824
INFO:root:current mean train loss 3584.83947859321
INFO:root:current train perplexity4.101868152618408
INFO:root:current mean train loss 3589.786671791582
INFO:root:current train perplexity4.1049346923828125
INFO:root:current mean train loss 3589.8544094492136
INFO:root:current train perplexity4.109438419342041
INFO:root:current mean train loss 3587.799327516176
INFO:root:current train perplexity4.1104912757873535
INFO:root:current mean train loss 3587.9289899909827
INFO:root:current train perplexity4.112751007080078

100%|██████████| 1/1 [02:28<00:00, 148.07s/it][A100%|██████████| 1/1 [02:28<00:00, 148.07s/it]
INFO:root:final mean train loss: 3584.0116270126837
INFO:root:final train perplexity: 4.112356662750244
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.28s/it][A100%|██████████| 1/1 [00:08<00:00,  8.28s/it]
INFO:root:eval mean loss: 4245.064903313387
INFO:root:eval perplexity: 5.565459728240967
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.43s/it][A100%|██████████| 1/1 [00:08<00:00,  8.43s/it]
INFO:root:eval mean loss: 5288.424139793883
INFO:root:eval perplexity: 8.692922592163086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/136
 68%|██████▊   | 136/200 [6:15:02<2:56:06, 165.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3586.2345377604165
INFO:root:current train perplexity4.086281776428223
INFO:root:current mean train loss 3584.56734233999
INFO:root:current train perplexity4.0970377922058105
INFO:root:current mean train loss 3578.6006607959494
INFO:root:current train perplexity4.09229040145874
INFO:root:current mean train loss 3578.1086703357155
INFO:root:current train perplexity4.093297004699707
INFO:root:current mean train loss 3579.4911016507317
INFO:root:current train perplexity4.095178604125977
INFO:root:current mean train loss 3578.621708884556
INFO:root:current train perplexity4.100649356842041
INFO:root:current mean train loss 3580.9871198940136
INFO:root:current train perplexity4.104994773864746
INFO:root:current mean train loss 3583.1036086900413
INFO:root:current train perplexity4.10550594329834
INFO:root:current mean train loss 3585.0113598330045
INFO:root:current train perplexity4.1084771156311035
INFO:root:current mean train loss 3584.5776555178254
INFO:root:current train perplexity4.1095099449157715

100%|██████████| 1/1 [02:27<00:00, 147.88s/it][A100%|██████████| 1/1 [02:27<00:00, 147.88s/it]
INFO:root:final mean train loss: 3582.0751646718672
INFO:root:final train perplexity: 4.109216213226318
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.27s/it][A100%|██████████| 1/1 [00:08<00:00,  8.27s/it]
INFO:root:eval mean loss: 4245.775331754211
INFO:root:eval perplexity: 5.567058563232422
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.34s/it][A100%|██████████| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 5287.867282732159
INFO:root:eval perplexity: 8.690943717956543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/137
 68%|██████▊   | 137/200 [6:17:47<2:53:15, 165.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3562.1617315995068
INFO:root:current train perplexity4.076737403869629
INFO:root:current mean train loss 3569.9443459535255
INFO:root:current train perplexity4.0770721435546875
INFO:root:current mean train loss 3582.8832345736228
INFO:root:current train perplexity4.092771530151367
INFO:root:current mean train loss 3583.858447265625
INFO:root:current train perplexity4.098567962646484
INFO:root:current mean train loss 3580.7934742937186
INFO:root:current train perplexity4.1000447273254395
INFO:root:current mean train loss 3580.8266552324053
INFO:root:current train perplexity4.102699279785156
INFO:root:current mean train loss 3580.523122400517
INFO:root:current train perplexity4.105313301086426
INFO:root:current mean train loss 3581.0302943199686
INFO:root:current train perplexity4.105977535247803
INFO:root:current mean train loss 3581.2451450113476
INFO:root:current train perplexity4.103468894958496

100%|██████████| 1/1 [02:28<00:00, 148.07s/it][A100%|██████████| 1/1 [02:28<00:00, 148.07s/it]
INFO:root:final mean train loss: 3579.6670375331755
INFO:root:final train perplexity: 4.105313777923584
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 4245.437255859375
INFO:root:eval perplexity: 5.56629753112793
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.38s/it][A100%|██████████| 1/1 [00:08<00:00,  8.38s/it]
INFO:root:eval mean loss: 5291.639584372229
INFO:root:eval perplexity: 8.704360008239746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/138
 69%|██████▉   | 138/200 [6:20:32<2:50:31, 165.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3562.887451171875
INFO:root:current train perplexity4.168010711669922
INFO:root:current mean train loss 3574.680777836772
INFO:root:current train perplexity4.106541156768799
INFO:root:current mean train loss 3566.2680279210285
INFO:root:current train perplexity4.094430923461914
INFO:root:current mean train loss 3565.9697201165427
INFO:root:current train perplexity4.085925102233887
INFO:root:current mean train loss 3568.2542109714254
INFO:root:current train perplexity4.083423137664795
INFO:root:current mean train loss 3570.5290430269943
INFO:root:current train perplexity4.083851337432861
INFO:root:current mean train loss 3573.6897713580533
INFO:root:current train perplexity4.088562965393066
INFO:root:current mean train loss 3578.0821288367933
INFO:root:current train perplexity4.0934576988220215
INFO:root:current mean train loss 3577.192771066022
INFO:root:current train perplexity4.095349311828613
INFO:root:current mean train loss 3579.7163978145763
INFO:root:current train perplexity4.099959850311279

100%|██████████| 1/1 [02:27<00:00, 147.63s/it][A100%|██████████| 1/1 [02:27<00:00, 147.63s/it]
INFO:root:final mean train loss: 3576.083772413192
INFO:root:final train perplexity: 4.099514484405518
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.24s/it][A100%|██████████| 1/1 [00:08<00:00,  8.24s/it]
INFO:root:eval mean loss: 4247.25491917387
INFO:root:eval perplexity: 5.570389747619629
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.34s/it][A100%|██████████| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 5294.340659283577
INFO:root:eval perplexity: 8.71397876739502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/139
 70%|██████▉   | 139/200 [6:23:17<2:47:35, 164.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3551.0947265625
INFO:root:current train perplexity3.998486280441284
INFO:root:current mean train loss 3563.0170106630067
INFO:root:current train perplexity4.0832743644714355
INFO:root:current mean train loss 3572.726321830569
INFO:root:current train perplexity4.0926642417907715
INFO:root:current mean train loss 3570.970214058732
INFO:root:current train perplexity4.089380741119385
INFO:root:current mean train loss 3570.9485890929136
INFO:root:current train perplexity4.0961079597473145
INFO:root:current mean train loss 3578.59477338399
INFO:root:current train perplexity4.095729351043701
INFO:root:current mean train loss 3573.3690255472584
INFO:root:current train perplexity4.0946760177612305
INFO:root:current mean train loss 3575.3332327240464
INFO:root:current train perplexity4.092965602874756
INFO:root:current mean train loss 3576.7844292467826
INFO:root:current train perplexity4.09495735168457
INFO:root:current mean train loss 3576.458959183761
INFO:root:current train perplexity4.096399784088135

100%|██████████| 1/1 [02:27<00:00, 147.45s/it][A100%|██████████| 1/1 [02:27<00:00, 147.45s/it]
INFO:root:final mean train loss: 3574.359758007911
INFO:root:final train perplexity: 4.09672737121582
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.24s/it][A100%|██████████| 1/1 [00:08<00:00,  8.25s/it]
INFO:root:eval mean loss: 4246.601460341866
INFO:root:eval perplexity: 5.5689191818237305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.33s/it][A100%|██████████| 1/1 [00:08<00:00,  8.33s/it]
INFO:root:eval mean loss: 5295.485808676862
INFO:root:eval perplexity: 8.718063354492188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/140
 70%|███████   | 140/200 [6:26:01<2:44:41, 164.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3552.2526726973683
INFO:root:current train perplexity4.060761451721191
INFO:root:current mean train loss 3551.0097245929624
INFO:root:current train perplexity4.0723443031311035
INFO:root:current mean train loss 3560.673340958547
INFO:root:current train perplexity4.0710954666137695
INFO:root:current mean train loss 3565.1913687487754
INFO:root:current train perplexity4.079814910888672
INFO:root:current mean train loss 3568.404240938246
INFO:root:current train perplexity4.079107284545898
INFO:root:current mean train loss 3570.3225469276854
INFO:root:current train perplexity4.084771633148193
INFO:root:current mean train loss 3567.376211631664
INFO:root:current train perplexity4.085285663604736
INFO:root:current mean train loss 3567.8493115845577
INFO:root:current train perplexity4.0853071212768555
INFO:root:current mean train loss 3570.4703528621985
INFO:root:current train perplexity4.086368560791016
INFO:root:current mean train loss 3573.1897291447053
INFO:root:current train perplexity4.089724540710449

100%|██████████| 1/1 [02:28<00:00, 148.25s/it][A100%|██████████| 1/1 [02:28<00:00, 148.25s/it]
INFO:root:final mean train loss: 3570.8647637521067
INFO:root:final train perplexity: 4.0910820960998535
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.27s/it][A100%|██████████| 1/1 [00:08<00:00,  8.27s/it]
INFO:root:eval mean loss: 4247.0148440962985
INFO:root:eval perplexity: 5.569849491119385
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 5294.343883325022
INFO:root:eval perplexity: 8.713993072509766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/141
 70%|███████   | 141/200 [6:28:46<2:42:05, 164.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3617.0949345341437
INFO:root:current train perplexity4.1020965576171875
INFO:root:current mean train loss 3585.040423535925
INFO:root:current train perplexity4.090115070343018
INFO:root:current mean train loss 3578.389687155837
INFO:root:current train perplexity4.093254566192627
INFO:root:current mean train loss 3573.5770685505063
INFO:root:current train perplexity4.077359199523926
INFO:root:current mean train loss 3572.539395834858
INFO:root:current train perplexity4.084648609161377
INFO:root:current mean train loss 3573.2904110642494
INFO:root:current train perplexity4.088654041290283
INFO:root:current mean train loss 3573.0457901901414
INFO:root:current train perplexity4.087059497833252
INFO:root:current mean train loss 3572.9386290244584
INFO:root:current train perplexity4.088527679443359
INFO:root:current mean train loss 3572.308034912995
INFO:root:current train perplexity4.08762264251709
INFO:root:current mean train loss 3570.9412137291833
INFO:root:current train perplexity4.086686611175537

100%|██████████| 1/1 [02:27<00:00, 147.87s/it][A100%|██████████| 1/1 [02:27<00:00, 147.88s/it]
INFO:root:final mean train loss: 3567.8855074605635
INFO:root:final train perplexity: 4.086276054382324
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.25s/it][A100%|██████████| 1/1 [00:08<00:00,  8.25s/it]
INFO:root:eval mean loss: 4249.408696600732
INFO:root:eval perplexity: 5.575243949890137
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.37s/it]
INFO:root:eval mean loss: 5299.568991370235
INFO:root:eval perplexity: 8.732629776000977
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/142
 71%|███████   | 142/200 [6:31:31<2:39:20, 164.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3580.6294503348213
INFO:root:current train perplexity4.071305751800537
INFO:root:current mean train loss 3568.1686396846067
INFO:root:current train perplexity4.091888904571533
INFO:root:current mean train loss 3568.0558656083776
INFO:root:current train perplexity4.087575435638428
INFO:root:current mean train loss 3565.7524253731344
INFO:root:current train perplexity4.083433628082275
INFO:root:current mean train loss 3563.4723155756105
INFO:root:current train perplexity4.076749324798584
INFO:root:current mean train loss 3564.960042165596
INFO:root:current train perplexity4.074775695800781
INFO:root:current mean train loss 3562.6112320066436
INFO:root:current train perplexity4.0753278732299805
INFO:root:current mean train loss 3565.2342763472575
INFO:root:current train perplexity4.079399585723877
INFO:root:current mean train loss 3565.8018323704155
INFO:root:current train perplexity4.079978942871094
INFO:root:current mean train loss 3567.051560411096
INFO:root:current train perplexity4.0825724601745605

100%|██████████| 1/1 [02:27<00:00, 147.58s/it][A100%|██████████| 1/1 [02:27<00:00, 147.58s/it]
INFO:root:final mean train loss: 3566.4365256524857
INFO:root:final train perplexity: 4.083940505981445
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.30s/it][A100%|██████████| 1/1 [00:08<00:00,  8.30s/it]
INFO:root:eval mean loss: 4249.608090231604
INFO:root:eval perplexity: 5.5756940841674805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.41s/it][A100%|██████████| 1/1 [00:08<00:00,  8.41s/it]
INFO:root:eval mean loss: 5297.194283992686
INFO:root:eval perplexity: 8.724156379699707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/143
 72%|███████▏  | 143/200 [6:34:16<2:36:31, 164.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3538.901503452035
INFO:root:current train perplexity4.078914642333984
INFO:root:current mean train loss 3555.7986283735795
INFO:root:current train perplexity4.067916393280029
INFO:root:current mean train loss 3564.5119417920523
INFO:root:current train perplexity4.066085338592529
INFO:root:current mean train loss 3564.2848331017676
INFO:root:current train perplexity4.06531286239624
INFO:root:current mean train loss 3563.7455795666974
INFO:root:current train perplexity4.069401264190674
INFO:root:current mean train loss 3564.7229808716047
INFO:root:current train perplexity4.070608615875244
INFO:root:current mean train loss 3564.9971485286255
INFO:root:current train perplexity4.072066783905029
INFO:root:current mean train loss 3565.360560872834
INFO:root:current train perplexity4.075223445892334
INFO:root:current mean train loss 3565.6091685085817
INFO:root:current train perplexity4.077016830444336
INFO:root:current mean train loss 3566.7140445324926
INFO:root:current train perplexity4.0781474113464355

100%|██████████| 1/1 [02:27<00:00, 147.70s/it][A100%|██████████| 1/1 [02:27<00:00, 147.70s/it]
INFO:root:final mean train loss: 3562.4134266761043
INFO:root:final train perplexity: 4.0774641036987305
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 4249.180051113697
INFO:root:eval perplexity: 5.574728488922119
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.43s/it][A100%|██████████| 1/1 [00:08<00:00,  8.43s/it]
INFO:root:eval mean loss: 5300.153540212212
INFO:root:eval perplexity: 8.734718322753906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/144
 72%|███████▏  | 144/200 [6:37:00<2:33:46, 164.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3574.5384976256128
INFO:root:current train perplexity4.0984063148498535
INFO:root:current mean train loss 3554.116107460679
INFO:root:current train perplexity4.069117546081543
INFO:root:current mean train loss 3559.509190775959
INFO:root:current train perplexity4.062512397766113
INFO:root:current mean train loss 3557.327866252671
INFO:root:current train perplexity4.065126895904541
INFO:root:current mean train loss 3558.215563179913
INFO:root:current train perplexity4.069889068603516
INFO:root:current mean train loss 3558.0757761988148
INFO:root:current train perplexity4.070444107055664
INFO:root:current mean train loss 3560.3825807351673
INFO:root:current train perplexity4.07382345199585
INFO:root:current mean train loss 3561.642031328021
INFO:root:current train perplexity4.075684547424316
INFO:root:current mean train loss 3560.527694038723
INFO:root:current train perplexity4.07461404800415
INFO:root:current mean train loss 3562.9959309895835
INFO:root:current train perplexity4.075458526611328

100%|██████████| 1/1 [02:28<00:00, 148.16s/it][A100%|██████████| 1/1 [02:28<00:00, 148.16s/it]
INFO:root:final mean train loss: 3561.0723977242747
INFO:root:final train perplexity: 4.0753068923950195
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.30s/it][A100%|██████████| 1/1 [00:08<00:00,  8.30s/it]
INFO:root:eval mean loss: 4250.354379640404
INFO:root:eval perplexity: 5.577375888824463
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.32s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 5301.30740248227
INFO:root:eval perplexity: 8.738838195800781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/145
 72%|███████▎  | 145/200 [6:39:45<2:31:06, 164.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3564.454374668962
INFO:root:current train perplexity4.043272972106934
INFO:root:current mean train loss 3556.4812242040093
INFO:root:current train perplexity4.061800479888916
INFO:root:current mean train loss 3564.446431399312
INFO:root:current train perplexity4.069479942321777
INFO:root:current mean train loss 3561.122691204953
INFO:root:current train perplexity4.063205242156982
INFO:root:current mean train loss 3563.0507498680895
INFO:root:current train perplexity4.068112373352051
INFO:root:current mean train loss 3561.858560470008
INFO:root:current train perplexity4.069126605987549
INFO:root:current mean train loss 3558.387734582464
INFO:root:current train perplexity4.067989826202393
INFO:root:current mean train loss 3557.751695152956
INFO:root:current train perplexity4.068692684173584
INFO:root:current mean train loss 3557.165074589366
INFO:root:current train perplexity4.067330837249756
INFO:root:current mean train loss 3559.642864780207
INFO:root:current train perplexity4.06857442855835

100%|██████████| 1/1 [02:27<00:00, 147.88s/it][A100%|██████████| 1/1 [02:27<00:00, 147.88s/it]
INFO:root:final mean train loss: 3557.452419957807
INFO:root:final train perplexity: 4.069490432739258
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.30s/it][A100%|██████████| 1/1 [00:08<00:00,  8.30s/it]
INFO:root:eval mean loss: 4252.116740774601
INFO:root:eval perplexity: 5.581352710723877
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.39s/it][A100%|██████████| 1/1 [00:08<00:00,  8.39s/it]
INFO:root:eval mean loss: 5301.985471035572
INFO:root:eval perplexity: 8.741262435913086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/146
 73%|███████▎  | 146/200 [6:42:30<2:28:22, 164.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3523.8825792910447
INFO:root:current train perplexity4.042688369750977
INFO:root:current mean train loss 3544.256300874813
INFO:root:current train perplexity4.069551467895508
INFO:root:current mean train loss 3550.059454185686
INFO:root:current train perplexity4.061938762664795
INFO:root:current mean train loss 3549.2787939586174
INFO:root:current train perplexity4.0625505447387695
INFO:root:current mean train loss 3549.9669416864626
INFO:root:current train perplexity4.060489654541016
INFO:root:current mean train loss 3553.383323602155
INFO:root:current train perplexity4.062899589538574
INFO:root:current mean train loss 3551.0054915169367
INFO:root:current train perplexity4.0628132820129395
INFO:root:current mean train loss 3556.7975469437542
INFO:root:current train perplexity4.067475318908691
INFO:root:current mean train loss 3557.2791045473796
INFO:root:current train perplexity4.064324378967285
INFO:root:current mean train loss 3558.4286306513377
INFO:root:current train perplexity4.065100193023682

100%|██████████| 1/1 [02:28<00:00, 148.29s/it][A100%|██████████| 1/1 [02:28<00:00, 148.29s/it]
INFO:root:final mean train loss: 3554.9220262958156
INFO:root:final train perplexity: 4.065430164337158
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.27s/it][A100%|██████████| 1/1 [00:08<00:00,  8.27s/it]
INFO:root:eval mean loss: 4251.91719304078
INFO:root:eval perplexity: 5.580901622772217
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.32s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 5303.9698114056955
INFO:root:eval perplexity: 8.748358726501465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/147
 74%|███████▎  | 147/200 [6:45:16<2:25:42, 164.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3559.3961848958334
INFO:root:current train perplexity4.052134037017822
INFO:root:current mean train loss 3550.2813016183036
INFO:root:current train perplexity4.056110382080078
INFO:root:current mean train loss 3545.227214133523
INFO:root:current train perplexity4.052552223205566
INFO:root:current mean train loss 3544.641100260417
INFO:root:current train perplexity4.0480546951293945
INFO:root:current mean train loss 3546.4622825863485
INFO:root:current train perplexity4.051820755004883
INFO:root:current mean train loss 3550.005474269701
INFO:root:current train perplexity4.055666923522949
INFO:root:current mean train loss 3551.420050998264
INFO:root:current train perplexity4.053370475769043
INFO:root:current mean train loss 3555.4481536668345
INFO:root:current train perplexity4.057327747344971
INFO:root:current mean train loss 3557.1066925223213
INFO:root:current train perplexity4.060652732849121
INFO:root:current mean train loss 3557.067535556891
INFO:root:current train perplexity4.064100742340088

100%|██████████| 1/1 [02:27<00:00, 147.84s/it][A100%|██████████| 1/1 [02:27<00:00, 147.85s/it]
INFO:root:final mean train loss: 3553.6301665152273
INFO:root:final train perplexity: 4.063358306884766
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.30s/it][A100%|██████████| 1/1 [00:08<00:00,  8.30s/it]
INFO:root:eval mean loss: 4252.319625096964
INFO:root:eval perplexity: 5.581811904907227
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.37s/it][A100%|██████████| 1/1 [00:08<00:00,  8.37s/it]
INFO:root:eval mean loss: 5303.590042871786
INFO:root:eval perplexity: 8.746999740600586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/148
 74%|███████▍  | 148/200 [6:48:00<2:22:55, 164.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3547.993693524096
INFO:root:current train perplexity4.0335164070129395
INFO:root:current mean train loss 3557.171195942196
INFO:root:current train perplexity4.045546531677246
INFO:root:current mean train loss 3560.2878901073873
INFO:root:current train perplexity4.050031661987305
INFO:root:current mean train loss 3548.7687121358927
INFO:root:current train perplexity4.0489702224731445
INFO:root:current mean train loss 3552.6045038132443
INFO:root:current train perplexity4.054146766662598
INFO:root:current mean train loss 3550.6949448233813
INFO:root:current train perplexity4.052164554595947
INFO:root:current mean train loss 3553.745333446765
INFO:root:current train perplexity4.055075645446777
INFO:root:current mean train loss 3554.149084800048
INFO:root:current train perplexity4.058507442474365
INFO:root:current mean train loss 3552.95665024685
INFO:root:current train perplexity4.058817386627197
INFO:root:current mean train loss 3553.3110490645663
INFO:root:current train perplexity4.058614730834961

100%|██████████| 1/1 [02:27<00:00, 147.57s/it][A100%|██████████| 1/1 [02:27<00:00, 147.57s/it]
INFO:root:final mean train loss: 3550.6835459432295
INFO:root:final train perplexity: 4.058638095855713
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.30s/it][A100%|██████████| 1/1 [00:08<00:00,  8.30s/it]
INFO:root:eval mean loss: 4252.0590681793
INFO:root:eval perplexity: 5.581221580505371
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.38s/it][A100%|██████████| 1/1 [00:08<00:00,  8.38s/it]
INFO:root:eval mean loss: 5305.694413854721
INFO:root:eval perplexity: 8.754528999328613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/149
 74%|███████▍  | 149/200 [6:50:45<2:20:05, 164.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3562.351750300481
INFO:root:current train perplexity4.063997268676758
INFO:root:current mean train loss 3553.4854972799412
INFO:root:current train perplexity4.055093288421631
INFO:root:current mean train loss 3552.89748862355
INFO:root:current train perplexity4.056416034698486
INFO:root:current mean train loss 3553.1661561151295
INFO:root:current train perplexity4.0606184005737305
INFO:root:current mean train loss 3551.79726134881
INFO:root:current train perplexity4.060586929321289
INFO:root:current mean train loss 3553.7179271097716
INFO:root:current train perplexity4.061667442321777
INFO:root:current mean train loss 3553.7029833207084
INFO:root:current train perplexity4.057303428649902
INFO:root:current mean train loss 3552.4811091947495
INFO:root:current train perplexity4.057806015014648
INFO:root:current mean train loss 3554.3511235400883
INFO:root:current train perplexity4.057155132293701
INFO:root:current mean train loss 3551.614485939865
INFO:root:current train perplexity4.055723667144775

100%|██████████| 1/1 [02:28<00:00, 148.03s/it][A100%|██████████| 1/1 [02:28<00:00, 148.03s/it]
INFO:root:final mean train loss: 3548.8350272640105
INFO:root:final train perplexity: 4.055678844451904
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 4253.779873462434
INFO:root:eval perplexity: 5.585107326507568
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.34s/it][A100%|██████████| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 5306.579385527482
INFO:root:eval perplexity: 8.757699966430664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/150
 75%|███████▌  | 150/200 [6:53:30<2:17:23, 164.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3540.8168082189077
INFO:root:current train perplexity4.0614542961120605
INFO:root:current mean train loss 3528.919724354193
INFO:root:current train perplexity4.042613983154297
INFO:root:current mean train loss 3536.311129873014
INFO:root:current train perplexity4.038037300109863
INFO:root:current mean train loss 3537.61719239505
INFO:root:current train perplexity4.040561199188232
INFO:root:current mean train loss 3541.001955571299
INFO:root:current train perplexity4.043622016906738
INFO:root:current mean train loss 3544.031162777807
INFO:root:current train perplexity4.05070161819458
INFO:root:current mean train loss 3545.555330159156
INFO:root:current train perplexity4.049002647399902
INFO:root:current mean train loss 3547.3340030140216
INFO:root:current train perplexity4.051752090454102
INFO:root:current mean train loss 3547.982249700188
INFO:root:current train perplexity4.0528082847595215

100%|██████████| 1/1 [02:28<00:00, 148.12s/it][A100%|██████████| 1/1 [02:28<00:00, 148.12s/it]
INFO:root:final mean train loss: 3547.131590627855
INFO:root:final train perplexity: 4.052954196929932
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.32s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 4255.002320201685
INFO:root:eval perplexity: 5.587868690490723
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.39s/it][A100%|██████████| 1/1 [00:08<00:00,  8.39s/it]
INFO:root:eval mean loss: 5305.091514641512
INFO:root:eval perplexity: 8.752370834350586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/151
 76%|███████▌  | 151/200 [6:56:15<2:14:42, 164.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3530.630057198661
INFO:root:current train perplexity3.9961719512939453
INFO:root:current mean train loss 3565.4716112368574
INFO:root:current train perplexity4.045890808105469
INFO:root:current mean train loss 3545.1546259341035
INFO:root:current train perplexity4.035104751586914
INFO:root:current mean train loss 3543.9478946648514
INFO:root:current train perplexity4.0408711433410645
INFO:root:current mean train loss 3546.047907948787
INFO:root:current train perplexity4.0445709228515625
INFO:root:current mean train loss 3547.8095187877525
INFO:root:current train perplexity4.043947696685791
INFO:root:current mean train loss 3543.1745311856466
INFO:root:current train perplexity4.039593696594238
INFO:root:current mean train loss 3547.0773621900416
INFO:root:current train perplexity4.043646335601807
INFO:root:current mean train loss 3545.187315760049
INFO:root:current train perplexity4.045071601867676
INFO:root:current mean train loss 3544.512793022585
INFO:root:current train perplexity4.045924663543701

100%|██████████| 1/1 [02:27<00:00, 147.83s/it][A100%|██████████| 1/1 [02:27<00:00, 147.83s/it]
INFO:root:final mean train loss: 3544.60883374368
INFO:root:final train perplexity: 4.048921585083008
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 4253.590354540669
INFO:root:eval perplexity: 5.58467960357666
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 5306.631898271276
INFO:root:eval perplexity: 8.757885932922363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/152
 76%|███████▌  | 152/200 [6:59:00<2:11:55, 164.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3472.941162109375
INFO:root:current train perplexity3.9537322521209717
INFO:root:current mean train loss 3545.925547724185
INFO:root:current train perplexity4.027337551116943
INFO:root:current mean train loss 3548.155496002907
INFO:root:current train perplexity4.031399726867676
INFO:root:current mean train loss 3545.226004464286
INFO:root:current train perplexity4.035649299621582
INFO:root:current mean train loss 3543.0897690370857
INFO:root:current train perplexity4.038843154907227
INFO:root:current mean train loss 3543.3397750113772
INFO:root:current train perplexity4.03622579574585
INFO:root:current mean train loss 3540.3526394975866
INFO:root:current train perplexity4.036924839019775
INFO:root:current mean train loss 3540.8664960527753
INFO:root:current train perplexity4.037285804748535
INFO:root:current mean train loss 3542.8832022263227
INFO:root:current train perplexity4.040876388549805
INFO:root:current mean train loss 3544.8839195376536
INFO:root:current train perplexity4.044021129608154

100%|██████████| 1/1 [02:27<00:00, 147.57s/it][A100%|██████████| 1/1 [02:27<00:00, 147.57s/it]
INFO:root:final mean train loss: 3541.644343837615
INFO:root:final train perplexity: 4.044188976287842
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.38s/it][A100%|██████████| 1/1 [00:08<00:00,  8.38s/it]
INFO:root:eval mean loss: 4254.780140112478
INFO:root:eval perplexity: 5.587367534637451
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.38s/it][A100%|██████████| 1/1 [00:08<00:00,  8.38s/it]
INFO:root:eval mean loss: 5308.568416514295
INFO:root:eval perplexity: 8.764824867248535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/153
 76%|███████▋  | 153/200 [7:01:44<2:09:06, 164.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3479.8431449558425
INFO:root:current train perplexity3.9824271202087402
INFO:root:current mean train loss 3543.734674717353
INFO:root:current train perplexity4.033342361450195
INFO:root:current mean train loss 3548.4810084868973
INFO:root:current train perplexity4.032745838165283
INFO:root:current mean train loss 3548.16946080447
INFO:root:current train perplexity4.0354509353637695
INFO:root:current mean train loss 3541.900634765625
INFO:root:current train perplexity4.035816669464111
INFO:root:current mean train loss 3542.65477301924
INFO:root:current train perplexity4.032873630523682
INFO:root:current mean train loss 3541.8506619620284
INFO:root:current train perplexity4.035251140594482
INFO:root:current mean train loss 3542.476334230204
INFO:root:current train perplexity4.0359625816345215
INFO:root:current mean train loss 3542.3438559030415
INFO:root:current train perplexity4.035771369934082
INFO:root:current mean train loss 3540.6056631631736
INFO:root:current train perplexity4.038073539733887

100%|██████████| 1/1 [02:27<00:00, 147.63s/it][A100%|██████████| 1/1 [02:27<00:00, 147.63s/it]
INFO:root:final mean train loss: 3538.9531977253578
INFO:root:final train perplexity: 4.039897918701172
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.34s/it][A100%|██████████| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 4255.07553295379
INFO:root:eval perplexity: 5.588034152984619
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.33s/it][A100%|██████████| 1/1 [00:08<00:00,  8.33s/it]
INFO:root:eval mean loss: 5309.855266165226
INFO:root:eval perplexity: 8.769438743591309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/154
 77%|███████▋  | 154/200 [7:04:29<2:06:18, 164.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3494.5005434097784
INFO:root:current train perplexity3.98490047454834
INFO:root:current mean train loss 3523.2870963293176
INFO:root:current train perplexity4.011338233947754
INFO:root:current mean train loss 3532.046435335498
INFO:root:current train perplexity4.023815155029297
INFO:root:current mean train loss 3540.5014751699396
INFO:root:current train perplexity4.0325775146484375
INFO:root:current mean train loss 3541.771245898891
INFO:root:current train perplexity4.038355827331543
INFO:root:current mean train loss 3534.6564058637887
INFO:root:current train perplexity4.033840656280518
INFO:root:current mean train loss 3533.6395958176504
INFO:root:current train perplexity4.032537460327148
INFO:root:current mean train loss 3534.6996729651164
INFO:root:current train perplexity4.034157752990723
INFO:root:current mean train loss 3536.4061759645756
INFO:root:current train perplexity4.03642463684082
INFO:root:current mean train loss 3540.6003777230467
INFO:root:current train perplexity4.038394927978516

100%|██████████| 1/1 [02:27<00:00, 147.89s/it][A100%|██████████| 1/1 [02:27<00:00, 147.89s/it]
INFO:root:final mean train loss: 3538.4982227202386
INFO:root:final train perplexity: 4.039173603057861
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.30s/it][A100%|██████████| 1/1 [00:08<00:00,  8.30s/it]
INFO:root:eval mean loss: 4256.833954939605
INFO:root:eval perplexity: 5.592009544372559
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.34s/it][A100%|██████████| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 5311.111371412345
INFO:root:eval perplexity: 8.773942947387695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/155
 78%|███████▊  | 155/200 [7:07:14<2:03:34, 164.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3514.1725573417466
INFO:root:current train perplexity3.985295295715332
INFO:root:current mean train loss 3516.664977588242
INFO:root:current train perplexity4.025460720062256
INFO:root:current mean train loss 3527.4716613003397
INFO:root:current train perplexity4.032416820526123
INFO:root:current mean train loss 3532.4074469372235
INFO:root:current train perplexity4.027261734008789
INFO:root:current mean train loss 3536.618479387635
INFO:root:current train perplexity4.029351711273193
INFO:root:current mean train loss 3532.9131434622855
INFO:root:current train perplexity4.030439853668213
INFO:root:current mean train loss 3534.896207758705
INFO:root:current train perplexity4.031580448150635
INFO:root:current mean train loss 3537.1519311226107
INFO:root:current train perplexity4.0328521728515625
INFO:root:current mean train loss 3537.94092204261
INFO:root:current train perplexity4.033047199249268
INFO:root:current mean train loss 3537.6219345921527
INFO:root:current train perplexity4.034338474273682

100%|██████████| 1/1 [02:27<00:00, 147.72s/it][A100%|██████████| 1/1 [02:27<00:00, 147.72s/it]
INFO:root:final mean train loss: 3535.4910918820287
INFO:root:final train perplexity: 4.034383773803711
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.34s/it][A100%|██████████| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 4257.342511981937
INFO:root:eval perplexity: 5.5931596755981445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.34s/it][A100%|██████████| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 5311.925684286348
INFO:root:eval perplexity: 8.77686595916748
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/156
 78%|███████▊  | 156/200 [7:09:59<2:00:48, 164.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3515.875498670213
INFO:root:current train perplexity4.018850326538086
INFO:root:current mean train loss 3512.254635350234
INFO:root:current train perplexity4.015584945678711
INFO:root:current mean train loss 3516.204308143029
INFO:root:current train perplexity4.009267807006836
INFO:root:current mean train loss 3521.006077483339
INFO:root:current train perplexity4.0116400718688965
INFO:root:current mean train loss 3525.668394221022
INFO:root:current train perplexity4.019257068634033
INFO:root:current mean train loss 3528.1888255898652
INFO:root:current train perplexity4.02205228805542
INFO:root:current mean train loss 3533.4158748762316
INFO:root:current train perplexity4.026241779327393
INFO:root:current mean train loss 3536.6628009433566
INFO:root:current train perplexity4.029843330383301
INFO:root:current mean train loss 3538.46915843833
INFO:root:current train perplexity4.031705379486084
INFO:root:current mean train loss 3536.5710670930407
INFO:root:current train perplexity4.0328145027160645

100%|██████████| 1/1 [02:27<00:00, 147.99s/it][A100%|██████████| 1/1 [02:27<00:00, 147.99s/it]
INFO:root:final mean train loss: 3534.4379437354305
INFO:root:final train perplexity: 4.032707691192627
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.26s/it][A100%|██████████| 1/1 [00:08<00:00,  8.26s/it]
INFO:root:eval mean loss: 4257.349017204122
INFO:root:eval perplexity: 5.593173980712891
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.32s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 5314.157740816157
INFO:root:eval perplexity: 8.784879684448242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/157
 78%|███████▊  | 157/200 [7:12:43<1:58:05, 164.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3545.9346413352273
INFO:root:current train perplexity3.9969608783721924
INFO:root:current mean train loss 3520.8263057585687
INFO:root:current train perplexity3.996673107147217
INFO:root:current mean train loss 3514.5883147594977
INFO:root:current train perplexity4.009644031524658
INFO:root:current mean train loss 3521.3293278224032
INFO:root:current train perplexity4.008194446563721
INFO:root:current mean train loss 3527.059831086882
INFO:root:current train perplexity4.019629001617432
INFO:root:current mean train loss 3526.7193988422014
INFO:root:current train perplexity4.024738311767578
INFO:root:current mean train loss 3525.45342095062
INFO:root:current train perplexity4.023187637329102
INFO:root:current mean train loss 3526.5131270048632
INFO:root:current train perplexity4.025715351104736
INFO:root:current mean train loss 3531.1975157620614
INFO:root:current train perplexity4.0280609130859375
INFO:root:current mean train loss 3534.306875562418
INFO:root:current train perplexity4.028791904449463

100%|██████████| 1/1 [02:27<00:00, 147.88s/it][A100%|██████████| 1/1 [02:27<00:00, 147.88s/it]
INFO:root:final mean train loss: 3532.3309898376465
INFO:root:final train perplexity: 4.029357433319092
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 4257.057639696919
INFO:root:eval perplexity: 5.592514991760254
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.32s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 5314.344897980385
INFO:root:eval perplexity: 8.785552024841309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/158
 79%|███████▉  | 158/200 [7:15:28<1:55:21, 164.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3522.3122442336307
INFO:root:current train perplexity4.019484043121338
INFO:root:current mean train loss 3527.8027493529526
INFO:root:current train perplexity4.028313159942627
INFO:root:current mean train loss 3533.2081052830918
INFO:root:current train perplexity4.0245490074157715
INFO:root:current mean train loss 3529.2154820129563
INFO:root:current train perplexity4.021819114685059
INFO:root:current mean train loss 3529.7101302013025
INFO:root:current train perplexity4.023142337799072
INFO:root:current mean train loss 3527.176392252026
INFO:root:current train perplexity4.020760536193848
INFO:root:current mean train loss 3523.105190363405
INFO:root:current train perplexity4.0189738273620605
INFO:root:current mean train loss 3528.59814037158
INFO:root:current train perplexity4.022421836853027
INFO:root:current mean train loss 3528.397532793489
INFO:root:current train perplexity4.023809432983398
INFO:root:current mean train loss 3532.1369126934874
INFO:root:current train perplexity4.026291370391846

100%|██████████| 1/1 [02:27<00:00, 147.81s/it][A100%|██████████| 1/1 [02:27<00:00, 147.81s/it]
INFO:root:final mean train loss: 3530.3095257051527
INFO:root:final train perplexity: 4.026144504547119
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 4258.246556058843
INFO:root:eval perplexity: 5.595205307006836
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 5316.377901983599
INFO:root:eval perplexity: 8.792859077453613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/159
 80%|███████▉  | 159/200 [7:18:13<1:52:36, 164.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3523.133513974472
INFO:root:current train perplexity4.018221855163574
INFO:root:current mean train loss 3509.8000873766446
INFO:root:current train perplexity4.005187511444092
INFO:root:current mean train loss 3514.5604153453646
INFO:root:current train perplexity4.013049602508545
INFO:root:current mean train loss 3516.9160393151956
INFO:root:current train perplexity4.0138325691223145
INFO:root:current mean train loss 3517.317666347366
INFO:root:current train perplexity4.0159010887146
INFO:root:current mean train loss 3519.18985803073
INFO:root:current train perplexity4.015436172485352
INFO:root:current mean train loss 3525.3926210588206
INFO:root:current train perplexity4.017453670501709
INFO:root:current mean train loss 3525.752350843061
INFO:root:current train perplexity4.017151832580566
INFO:root:current mean train loss 3523.9706750950777
INFO:root:current train perplexity4.014918327331543
INFO:root:current mean train loss 3528.6608496998906
INFO:root:current train perplexity4.020018577575684

100%|██████████| 1/1 [02:27<00:00, 147.86s/it][A100%|██████████| 1/1 [02:27<00:00, 147.86s/it]
INFO:root:final mean train loss: 3526.6365029119675
INFO:root:final train perplexity: 4.0203142166137695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.26s/it][A100%|██████████| 1/1 [00:08<00:00,  8.26s/it]
INFO:root:eval mean loss: 4259.239503684619
INFO:root:eval perplexity: 5.597451210021973
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.34s/it][A100%|██████████| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 5316.163899739583
INFO:root:eval perplexity: 8.792089462280273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/160
 80%|████████  | 160/200 [7:20:58<1:49:51, 164.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3540.2319954015034
INFO:root:current train perplexity4.0497870445251465
INFO:root:current mean train loss 3528.5926643243715
INFO:root:current train perplexity4.020108222961426
INFO:root:current mean train loss 3521.9776860719085
INFO:root:current train perplexity4.005375862121582
INFO:root:current mean train loss 3519.6584872041967
INFO:root:current train perplexity4.007033824920654
INFO:root:current mean train loss 3524.214453328875
INFO:root:current train perplexity4.012248992919922
INFO:root:current mean train loss 3527.04907943383
INFO:root:current train perplexity4.013365268707275
INFO:root:current mean train loss 3525.1166772856454
INFO:root:current train perplexity4.0144171714782715
INFO:root:current mean train loss 3525.2696829368583
INFO:root:current train perplexity4.014213562011719
INFO:root:current mean train loss 3527.7367622453603
INFO:root:current train perplexity4.016671180725098
INFO:root:current mean train loss 3529.073732713148
INFO:root:current train perplexity4.018787860870361

100%|██████████| 1/1 [02:28<00:00, 148.05s/it][A100%|██████████| 1/1 [02:28<00:00, 148.05s/it]
INFO:root:final mean train loss: 3525.656956149686
INFO:root:final train perplexity: 4.018760681152344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.27s/it][A100%|██████████| 1/1 [00:08<00:00,  8.27s/it]
INFO:root:eval mean loss: 4258.519027385306
INFO:root:eval perplexity: 5.595821380615234
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 5316.999155031029
INFO:root:eval perplexity: 8.79509449005127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/161
 80%|████████  | 161/200 [7:23:43<1:47:08, 164.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3507.5739156788795
INFO:root:current train perplexity4.007768154144287
INFO:root:current mean train loss 3528.903531814004
INFO:root:current train perplexity4.015058994293213
INFO:root:current mean train loss 3527.8469816732904
INFO:root:current train perplexity4.0124735832214355
INFO:root:current mean train loss 3527.281554071786
INFO:root:current train perplexity4.012153625488281
INFO:root:current mean train loss 3525.1328661407533
INFO:root:current train perplexity4.010190963745117
INFO:root:current mean train loss 3527.7366072022733
INFO:root:current train perplexity4.009116172790527
INFO:root:current mean train loss 3527.6412383722254
INFO:root:current train perplexity4.013565540313721
INFO:root:current mean train loss 3528.5630062738246
INFO:root:current train perplexity4.0160813331604
INFO:root:current mean train loss 3529.1576088751585
INFO:root:current train perplexity4.016380786895752
INFO:root:current mean train loss 3526.4934997249397
INFO:root:current train perplexity4.015474319458008

100%|██████████| 1/1 [02:27<00:00, 147.61s/it][A100%|██████████| 1/1 [02:27<00:00, 147.61s/it]
INFO:root:final mean train loss: 3523.4088137841995
INFO:root:final train perplexity: 4.01519775390625
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.27s/it][A100%|██████████| 1/1 [00:08<00:00,  8.27s/it]
INFO:root:eval mean loss: 4260.107918813719
INFO:root:eval perplexity: 5.599416732788086
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.33s/it][A100%|██████████| 1/1 [00:08<00:00,  8.33s/it]
INFO:root:eval mean loss: 5318.171483682402
INFO:root:eval perplexity: 8.799309730529785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/162
 81%|████████  | 162/200 [7:26:27<1:44:19, 164.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3544.921484375
INFO:root:current train perplexity4.00490140914917
INFO:root:current mean train loss 3529.1439841245992
INFO:root:current train perplexity4.007335186004639
INFO:root:current mean train loss 3521.28591267214
INFO:root:current train perplexity4.006509780883789
INFO:root:current mean train loss 3521.245969516416
INFO:root:current train perplexity4.005461692810059
INFO:root:current mean train loss 3521.4284958964645
INFO:root:current train perplexity4.002166748046875
INFO:root:current mean train loss 3522.7036202566965
INFO:root:current train perplexity4.004240036010742
INFO:root:current mean train loss 3525.594248468413
INFO:root:current train perplexity4.0066118240356445
INFO:root:current mean train loss 3524.325033473369
INFO:root:current train perplexity4.009957313537598
INFO:root:current mean train loss 3525.6258368976955
INFO:root:current train perplexity4.013305187225342

100%|██████████| 1/1 [02:27<00:00, 147.55s/it][A100%|██████████| 1/1 [02:27<00:00, 147.55s/it]
INFO:root:final mean train loss: 3523.334613984631
INFO:root:final train perplexity: 4.015079975128174
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.28s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 4260.13973501219
INFO:root:eval perplexity: 5.599489688873291
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 5319.257121633976
INFO:root:eval perplexity: 8.80321979522705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/163
 82%|████████▏ | 163/200 [7:29:12<1:41:32, 164.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3434.1787109375
INFO:root:current train perplexity3.987889528274536
INFO:root:current mean train loss 3531.880240727397
INFO:root:current train perplexity3.998298168182373
INFO:root:current mean train loss 3532.4107227043564
INFO:root:current train perplexity4.006330966949463
INFO:root:current mean train loss 3524.479149746029
INFO:root:current train perplexity4.011807441711426
INFO:root:current mean train loss 3519.4066680075216
INFO:root:current train perplexity4.011336326599121
INFO:root:current mean train loss 3525.760807226951
INFO:root:current train perplexity4.012921333312988
INFO:root:current mean train loss 3527.101774655369
INFO:root:current train perplexity4.015420436859131
INFO:root:current mean train loss 3525.5660652171496
INFO:root:current train perplexity4.011704444885254
INFO:root:current mean train loss 3524.3506516091998
INFO:root:current train perplexity4.011528015136719
INFO:root:current mean train loss 3525.545867886126
INFO:root:current train perplexity4.011915683746338

100%|██████████| 1/1 [02:28<00:00, 148.24s/it][A100%|██████████| 1/1 [02:28<00:00, 148.24s/it]
INFO:root:final mean train loss: 3520.1152512335007
INFO:root:final train perplexity: 4.009984493255615
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.25s/it][A100%|██████████| 1/1 [00:08<00:00,  8.25s/it]
INFO:root:eval mean loss: 4261.478106992465
INFO:root:eval perplexity: 5.602519989013672
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 5321.416154144504
INFO:root:eval perplexity: 8.810993194580078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/164
 82%|████████▏ | 164/200 [7:31:57<1:38:52, 164.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3507.6900745738635
INFO:root:current train perplexity3.9520797729492188
INFO:root:current mean train loss 3516.051977759009
INFO:root:current train perplexity3.9994254112243652
INFO:root:current mean train loss 3516.5381657749554
INFO:root:current train perplexity4.002730369567871
INFO:root:current mean train loss 3518.6649079644794
INFO:root:current train perplexity4.003600597381592
INFO:root:current mean train loss 3519.8900880094284
INFO:root:current train perplexity4.0055108070373535
INFO:root:current mean train loss 3519.192379468108
INFO:root:current train perplexity4.004402160644531
INFO:root:current mean train loss 3518.0446469670624
INFO:root:current train perplexity4.006237030029297
INFO:root:current mean train loss 3520.8300520283933
INFO:root:current train perplexity4.007363319396973
INFO:root:current mean train loss 3521.8997972820016
INFO:root:current train perplexity4.008896827697754
INFO:root:current mean train loss 3523.417840381878
INFO:root:current train perplexity4.009498119354248

100%|██████████| 1/1 [02:27<00:00, 147.59s/it][A100%|██████████| 1/1 [02:27<00:00, 147.59s/it]
INFO:root:final mean train loss: 3519.109687374484
INFO:root:final train perplexity: 4.00839376449585
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.32s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 4261.723811156361
INFO:root:eval perplexity: 5.6030778884887695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.37s/it][A100%|██████████| 1/1 [00:08<00:00,  8.37s/it]
INFO:root:eval mean loss: 5321.316058219747
INFO:root:eval perplexity: 8.810633659362793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/165
 82%|████████▎ | 165/200 [7:34:41<1:36:05, 164.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3527.0594289679275
INFO:root:current train perplexity3.9953582286834717
INFO:root:current mean train loss 3505.0326286764707
INFO:root:current train perplexity3.99772047996521
INFO:root:current mean train loss 3511.882136932791
INFO:root:current train perplexity3.995666980743408
INFO:root:current mean train loss 3511.9555227823766
INFO:root:current train perplexity3.9956188201904297
INFO:root:current mean train loss 3510.01069965226
INFO:root:current train perplexity3.9955151081085205
INFO:root:current mean train loss 3514.3451936754877
INFO:root:current train perplexity3.9973483085632324
INFO:root:current mean train loss 3516.0896851966377
INFO:root:current train perplexity3.997493028640747
INFO:root:current mean train loss 3516.995170158206
INFO:root:current train perplexity4.0002264976501465
INFO:root:current mean train loss 3516.7493528335813
INFO:root:current train perplexity4.002684593200684
INFO:root:current mean train loss 3519.545838929883
INFO:root:current train perplexity4.006362438201904

100%|██████████| 1/1 [02:27<00:00, 147.63s/it][A100%|██████████| 1/1 [02:27<00:00, 147.63s/it]
INFO:root:final mean train loss: 3517.266220831102
INFO:root:final train perplexity: 4.005479335784912
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.26s/it][A100%|██████████| 1/1 [00:08<00:00,  8.26s/it]
INFO:root:eval mean loss: 4262.164431308178
INFO:root:eval perplexity: 5.6040754318237305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.32s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 5323.190308482935
INFO:root:eval perplexity: 8.817389488220215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/166
 83%|████████▎ | 166/200 [7:37:26<1:33:18, 164.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3498.9154640480324
INFO:root:current train perplexity4.0005059242248535
INFO:root:current mean train loss 3512.4737481545276
INFO:root:current train perplexity3.9875833988189697
INFO:root:current mean train loss 3513.982921986853
INFO:root:current train perplexity3.993788719177246
INFO:root:current mean train loss 3519.9513435947056
INFO:root:current train perplexity3.9961061477661133
INFO:root:current mean train loss 3519.762022353447
INFO:root:current train perplexity4.0013861656188965
INFO:root:current mean train loss 3519.501963780094
INFO:root:current train perplexity4.001045227050781
INFO:root:current mean train loss 3522.9167293566834
INFO:root:current train perplexity4.003281593322754
INFO:root:current mean train loss 3524.572648123173
INFO:root:current train perplexity4.0031538009643555
INFO:root:current mean train loss 3520.088727847264
INFO:root:current train perplexity4.002744197845459
INFO:root:current mean train loss 3518.3060799179984
INFO:root:current train perplexity4.0026774406433105

100%|██████████| 1/1 [02:27<00:00, 147.52s/it][A100%|██████████| 1/1 [02:27<00:00, 147.52s/it]
INFO:root:final mean train loss: 3515.0858067543277
INFO:root:final train perplexity: 4.002035140991211
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 4261.613359167221
INFO:root:eval perplexity: 5.602827548980713
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.38s/it][A100%|██████████| 1/1 [00:08<00:00,  8.38s/it]
INFO:root:eval mean loss: 5323.026110926418
INFO:root:eval perplexity: 8.816797256469727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/167
 84%|████████▎ | 167/200 [7:40:10<1:30:31, 164.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3540.938671875
INFO:root:current train perplexity4.034578800201416
INFO:root:current mean train loss 3534.0767126012734
INFO:root:current train perplexity4.019680500030518
INFO:root:current mean train loss 3521.7329122340425
INFO:root:current train perplexity4.010664463043213
INFO:root:current mean train loss 3522.2670067630597
INFO:root:current train perplexity4.001791477203369
INFO:root:current mean train loss 3517.229330549569
INFO:root:current train perplexity3.9950830936431885
INFO:root:current mean train loss 3515.9757721232477
INFO:root:current train perplexity3.9926795959472656
INFO:root:current mean train loss 3518.7789942944146
INFO:root:current train perplexity3.9938559532165527
INFO:root:current mean train loss 3517.151901307398
INFO:root:current train perplexity3.9977777004241943
INFO:root:current mean train loss 3516.978380251216
INFO:root:current train perplexity4.000559329986572
INFO:root:current mean train loss 3517.765016345672
INFO:root:current train perplexity4.001263618469238

100%|██████████| 1/1 [02:27<00:00, 147.93s/it][A100%|██████████| 1/1 [02:27<00:00, 147.93s/it]
INFO:root:final mean train loss: 3514.3596374142553
INFO:root:final train perplexity: 4.000888824462891
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.26s/it][A100%|██████████| 1/1 [00:08<00:00,  8.26s/it]
INFO:root:eval mean loss: 4263.128845647717
INFO:root:eval perplexity: 5.60626220703125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.40s/it][A100%|██████████| 1/1 [00:08<00:00,  8.40s/it]
INFO:root:eval mean loss: 5322.636890167885
INFO:root:eval perplexity: 8.81539249420166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/168
 84%|████████▍ | 168/200 [7:42:55<1:27:49, 164.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3465.1673782703488
INFO:root:current train perplexity3.9587559700012207
INFO:root:current mean train loss 3493.3666548295455
INFO:root:current train perplexity3.9825990200042725
INFO:root:current mean train loss 3502.182053554205
INFO:root:current train perplexity3.9923360347747803
INFO:root:current mean train loss 3507.349548873679
INFO:root:current train perplexity3.9876832962036133
INFO:root:current mean train loss 3507.258948332569
INFO:root:current train perplexity3.993319272994995
INFO:root:current mean train loss 3507.9362604130697
INFO:root:current train perplexity3.9903204441070557
INFO:root:current mean train loss 3509.536111929554
INFO:root:current train perplexity3.992619752883911
INFO:root:current mean train loss 3510.9018952278557
INFO:root:current train perplexity3.994983434677124
INFO:root:current mean train loss 3511.9965157107245
INFO:root:current train perplexity3.996244192123413
INFO:root:current mean train loss 3514.850240826733
INFO:root:current train perplexity3.9985854625701904

100%|██████████| 1/1 [02:27<00:00, 147.69s/it][A100%|██████████| 1/1 [02:27<00:00, 147.69s/it]
INFO:root:final mean train loss: 3512.9428680789088
INFO:root:final train perplexity: 3.9986531734466553
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.27s/it][A100%|██████████| 1/1 [00:08<00:00,  8.27s/it]
INFO:root:eval mean loss: 4263.200775362921
INFO:root:eval perplexity: 5.606425762176514
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.38s/it][A100%|██████████| 1/1 [00:08<00:00,  8.38s/it]
INFO:root:eval mean loss: 5324.920507119902
INFO:root:eval perplexity: 8.823627471923828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/169
 84%|████████▍ | 169/200 [7:45:40<1:25:04, 164.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3531.8787530637255
INFO:root:current train perplexity4.037044525146484
INFO:root:current mean train loss 3509.6800318837954
INFO:root:current train perplexity3.980929136276245
INFO:root:current mean train loss 3511.420188387077
INFO:root:current train perplexity3.9845356941223145
INFO:root:current mean train loss 3515.058127031027
INFO:root:current train perplexity3.9934213161468506
INFO:root:current mean train loss 3518.1737766984825
INFO:root:current train perplexity3.9934935569763184
INFO:root:current mean train loss 3516.2770428943113
INFO:root:current train perplexity3.991938591003418
INFO:root:current mean train loss 3511.468552362351
INFO:root:current train perplexity3.9899556636810303
INFO:root:current mean train loss 3514.2022820484144
INFO:root:current train perplexity3.991429567337036
INFO:root:current mean train loss 3516.288604341859
INFO:root:current train perplexity3.9951305389404297
INFO:root:current mean train loss 3514.6242170043047
INFO:root:current train perplexity3.9941277503967285

100%|██████████| 1/1 [02:27<00:00, 147.79s/it][A100%|██████████| 1/1 [02:27<00:00, 147.80s/it]
INFO:root:final mean train loss: 3510.4580433137953
INFO:root:final train perplexity: 3.9947350025177
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 4264.08422158965
INFO:root:eval perplexity: 5.608428001403809
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.37s/it][A100%|██████████| 1/1 [00:08<00:00,  8.37s/it]
INFO:root:eval mean loss: 5326.812671417885
INFO:root:eval perplexity: 8.830458641052246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/170
 85%|████████▌ | 170/200 [7:48:25<1:22:20, 164.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3501.2789285950744
INFO:root:current train perplexity4.009692668914795
INFO:root:current mean train loss 3499.5127352348663
INFO:root:current train perplexity3.9944968223571777
INFO:root:current mean train loss 3500.7243888000726
INFO:root:current train perplexity3.9805638790130615
INFO:root:current mean train loss 3504.0183669916432
INFO:root:current train perplexity3.98752498626709
INFO:root:current mean train loss 3501.2473288143383
INFO:root:current train perplexity3.9891624450683594
INFO:root:current mean train loss 3501.5897869731107
INFO:root:current train perplexity3.9868476390838623
INFO:root:current mean train loss 3502.526042284119
INFO:root:current train perplexity3.9887847900390625
INFO:root:current mean train loss 3505.342413820611
INFO:root:current train perplexity3.9916844367980957
INFO:root:current mean train loss 3509.53603077934
INFO:root:current train perplexity3.993945837020874
INFO:root:current mean train loss 3511.539224920979
INFO:root:current train perplexity3.9924511909484863

100%|██████████| 1/1 [02:27<00:00, 147.69s/it][A100%|██████████| 1/1 [02:27<00:00, 147.69s/it]
INFO:root:final mean train loss: 3509.2058062399587
INFO:root:final train perplexity: 3.9927620887756348
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.26s/it][A100%|██████████| 1/1 [00:08<00:00,  8.26s/it]
INFO:root:eval mean loss: 4264.706142993684
INFO:root:eval perplexity: 5.609837532043457
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.38s/it][A100%|██████████| 1/1 [00:08<00:00,  8.38s/it]
INFO:root:eval mean loss: 5326.010430518617
INFO:root:eval perplexity: 8.82756233215332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/171
 86%|████████▌ | 171/200 [7:51:09<1:19:35, 164.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3478.9102218400185
INFO:root:current train perplexity3.9367611408233643
INFO:root:current mean train loss 3504.1012935067365
INFO:root:current train perplexity3.9600043296813965
INFO:root:current mean train loss 3503.4949855161517
INFO:root:current train perplexity3.974595069885254
INFO:root:current mean train loss 3509.114193950102
INFO:root:current train perplexity3.9836955070495605
INFO:root:current mean train loss 3508.0584839651365
INFO:root:current train perplexity3.9814412593841553
INFO:root:current mean train loss 3509.7696083243773
INFO:root:current train perplexity3.985306739807129
INFO:root:current mean train loss 3513.3063360897677
INFO:root:current train perplexity3.992553949356079
INFO:root:current mean train loss 3510.347920443897
INFO:root:current train perplexity3.988703489303589
INFO:root:current mean train loss 3506.2186427132892
INFO:root:current train perplexity3.986126184463501
INFO:root:current mean train loss 3510.239537046762
INFO:root:current train perplexity3.990522623062134

100%|██████████| 1/1 [02:27<00:00, 147.94s/it][A100%|██████████| 1/1 [02:27<00:00, 147.94s/it]
INFO:root:final mean train loss: 3508.598715751402
INFO:root:final train perplexity: 3.9918062686920166
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.34s/it][A100%|██████████| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 4263.560285419437
INFO:root:eval perplexity: 5.60723876953125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.40s/it][A100%|██████████| 1/1 [00:08<00:00,  8.40s/it]
INFO:root:eval mean loss: 5325.813788231383
INFO:root:eval perplexity: 8.826852798461914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/172
 86%|████████▌ | 172/200 [7:53:54<1:16:53, 164.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3498.8315462239584
INFO:root:current train perplexity3.994107723236084
INFO:root:current mean train loss 3501.1071372767856
INFO:root:current train perplexity3.992765426635742
INFO:root:current mean train loss 3503.3270854048296
INFO:root:current train perplexity3.988684892654419
INFO:root:current mean train loss 3500.060591796875
INFO:root:current train perplexity3.987520217895508
INFO:root:current mean train loss 3504.4723118832235
INFO:root:current train perplexity3.986349582672119
INFO:root:current mean train loss 3505.523349609375
INFO:root:current train perplexity3.9860777854919434
INFO:root:current mean train loss 3506.7060326244214
INFO:root:current train perplexity3.985807418823242
INFO:root:current mean train loss 3506.706124621976
INFO:root:current train perplexity3.9870686531066895
INFO:root:current mean train loss 3507.591210658482
INFO:root:current train perplexity3.988663673400879
INFO:root:current mean train loss 3508.5818447015226
INFO:root:current train perplexity3.9888057708740234

100%|██████████| 1/1 [02:27<00:00, 147.76s/it][A100%|██████████| 1/1 [02:27<00:00, 147.76s/it]
INFO:root:final mean train loss: 3506.797882756879
INFO:root:final train perplexity: 3.9889707565307617
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 4264.385375110815
INFO:root:eval perplexity: 5.6091108322143555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.34s/it][A100%|██████████| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 5327.6449346880545
INFO:root:eval perplexity: 8.833462715148926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/173
 86%|████████▋ | 173/200 [7:56:39<1:14:08, 164.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3491.53563570689
INFO:root:current train perplexity3.9722957611083984
INFO:root:current mean train loss 3489.0438425866632
INFO:root:current train perplexity3.9833478927612305
INFO:root:current mean train loss 3500.3884855344522
INFO:root:current train perplexity3.994708776473999
INFO:root:current mean train loss 3506.8238458459123
INFO:root:current train perplexity3.9886302947998047
INFO:root:current mean train loss 3503.873670115974
INFO:root:current train perplexity3.9837677478790283
INFO:root:current mean train loss 3507.3923147211353
INFO:root:current train perplexity3.9873924255371094
INFO:root:current mean train loss 3506.1815977306005
INFO:root:current train perplexity3.9877824783325195
INFO:root:current mean train loss 3506.8558058074914
INFO:root:current train perplexity3.989262819290161
INFO:root:current mean train loss 3509.345768929608
INFO:root:current train perplexity3.9891738891601562
INFO:root:current mean train loss 3508.299012410192
INFO:root:current train perplexity3.9871022701263428

100%|██████████| 1/1 [02:27<00:00, 147.76s/it][A100%|██████████| 1/1 [02:27<00:00, 147.76s/it]
INFO:root:final mean train loss: 3505.5990073911607
INFO:root:final train perplexity: 3.98708438873291
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.33s/it][A100%|██████████| 1/1 [00:08<00:00,  8.33s/it]
INFO:root:eval mean loss: 4265.741552041777
INFO:root:eval perplexity: 5.612189292907715
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.37s/it][A100%|██████████| 1/1 [00:08<00:00,  8.37s/it]
INFO:root:eval mean loss: 5327.690559549535
INFO:root:eval perplexity: 8.833629608154297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/174
 87%|████████▋ | 174/200 [7:59:24<1:11:23, 164.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3506.3131975446427
INFO:root:current train perplexity3.963775157928467
INFO:root:current mean train loss 3495.378069013825
INFO:root:current train perplexity3.9762356281280518
INFO:root:current mean train loss 3499.715023289841
INFO:root:current train perplexity3.971919298171997
INFO:root:current mean train loss 3509.734840178429
INFO:root:current train perplexity3.9867706298828125
INFO:root:current mean train loss 3511.5621171318103
INFO:root:current train perplexity3.9864389896392822
INFO:root:current mean train loss 3510.469878169284
INFO:root:current train perplexity3.9853293895721436
INFO:root:current mean train loss 3505.5241780481188
INFO:root:current train perplexity3.983365058898926
INFO:root:current mean train loss 3508.208980362575
INFO:root:current train perplexity3.9839694499969482
INFO:root:current mean train loss 3508.791989173418
INFO:root:current train perplexity3.98647403717041
INFO:root:current mean train loss 3507.475975429254
INFO:root:current train perplexity3.985795497894287

100%|██████████| 1/1 [02:27<00:00, 147.50s/it][A100%|██████████| 1/1 [02:27<00:00, 147.50s/it]
INFO:root:final mean train loss: 3504.776117570939
INFO:root:final train perplexity: 3.985790252685547
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.32s/it][A100%|██████████| 1/1 [00:08<00:00,  8.32s/it]
INFO:root:eval mean loss: 4264.973293439716
INFO:root:eval perplexity: 5.610444068908691
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 5328.13759488586
INFO:root:eval perplexity: 8.835243225097656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/175
 88%|████████▊ | 175/200 [8:02:08<1:08:36, 164.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3490.8501765703913
INFO:root:current train perplexity3.9723095893859863
INFO:root:current mean train loss 3511.0420731587624
INFO:root:current train perplexity3.9829647541046143
INFO:root:current mean train loss 3508.50336244513
INFO:root:current train perplexity3.9737095832824707
INFO:root:current mean train loss 3512.5658910459742
INFO:root:current train perplexity3.9789929389953613
INFO:root:current mean train loss 3503.4538290448086
INFO:root:current train perplexity3.977400541305542
INFO:root:current mean train loss 3504.4329868628706
INFO:root:current train perplexity3.980106830596924
INFO:root:current mean train loss 3502.6417440651826
INFO:root:current train perplexity3.9784371852874756
INFO:root:current mean train loss 3503.6325017477902
INFO:root:current train perplexity3.980919361114502
INFO:root:current mean train loss 3504.6920018010464
INFO:root:current train perplexity3.9826138019561768

100%|██████████| 1/1 [02:27<00:00, 147.70s/it][A100%|██████████| 1/1 [02:27<00:00, 147.70s/it]
INFO:root:final mean train loss: 3503.768807872649
INFO:root:final train perplexity: 3.984206438064575
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 4265.7263737671765
INFO:root:eval perplexity: 5.612151622772217
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.38s/it][A100%|██████████| 1/1 [00:08<00:00,  8.38s/it]
INFO:root:eval mean loss: 5329.893024850399
INFO:root:eval perplexity: 8.841588020324707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/176
 88%|████████▊ | 176/200 [8:04:53<1:05:52, 164.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3469.1663643973216
INFO:root:current train perplexity3.9947283267974854
INFO:root:current mean train loss 3494.811612423335
INFO:root:current train perplexity3.9857380390167236
INFO:root:current mean train loss 3483.8829339806007
INFO:root:current train perplexity3.9697916507720947
INFO:root:current mean train loss 3489.577838711319
INFO:root:current train perplexity3.963212490081787
INFO:root:current mean train loss 3493.3361576464604
INFO:root:current train perplexity3.974832534790039
INFO:root:current mean train loss 3494.9334935897436
INFO:root:current train perplexity3.9794669151306152
INFO:root:current mean train loss 3495.5689252825114
INFO:root:current train perplexity3.9775209426879883
INFO:root:current mean train loss 3498.071933082678
INFO:root:current train perplexity3.9794387817382812
INFO:root:current mean train loss 3500.916029541318
INFO:root:current train perplexity3.9776365756988525
INFO:root:current mean train loss 3502.8429144845645
INFO:root:current train perplexity3.979078769683838

100%|██████████| 1/1 [02:27<00:00, 147.67s/it][A100%|██████████| 1/1 [02:27<00:00, 147.67s/it]
INFO:root:final mean train loss: 3500.433134448144
INFO:root:final train perplexity: 3.9789669513702393
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.39s/it][A100%|██████████| 1/1 [00:08<00:00,  8.39s/it]
INFO:root:eval mean loss: 4265.79016199856
INFO:root:eval perplexity: 5.612298965454102
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 5329.853390957447
INFO:root:eval perplexity: 8.841446876525879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/177
 88%|████████▊ | 177/200 [8:07:38<1:03:07, 164.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3466.422802734375
INFO:root:current train perplexity3.9557273387908936
INFO:root:current mean train loss 3489.091253396739
INFO:root:current train perplexity3.9918863773345947
INFO:root:current mean train loss 3493.046932912427
INFO:root:current train perplexity3.9712328910827637
INFO:root:current mean train loss 3494.306424386161
INFO:root:current train perplexity3.978008985519409
INFO:root:current mean train loss 3498.600509459714
INFO:root:current train perplexity3.980455160140991
INFO:root:current mean train loss 3500.7532567885314
INFO:root:current train perplexity3.98105788230896
INFO:root:current mean train loss 3502.6728662506353
INFO:root:current train perplexity3.9803812503814697
INFO:root:current mean train loss 3502.0146259014423
INFO:root:current train perplexity3.9792416095733643
INFO:root:current mean train loss 3499.3818311445552
INFO:root:current train perplexity3.9780235290527344
INFO:root:current mean train loss 3499.953599139771
INFO:root:current train perplexity3.9766433238983154

100%|██████████| 1/1 [02:27<00:00, 147.65s/it][A100%|██████████| 1/1 [02:27<00:00, 147.65s/it]
INFO:root:final mean train loss: 3499.828412640479
INFO:root:final train perplexity: 3.9780173301696777
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 4266.827023769947
INFO:root:eval perplexity: 5.614651203155518
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.34s/it][A100%|██████████| 1/1 [00:08<00:00,  8.34s/it]
INFO:root:eval mean loss: 5330.8656378130545
INFO:root:eval perplexity: 8.845105171203613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/178
 89%|████████▉ | 178/200 [8:10:22<1:00:22, 164.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3481.3461064877715
INFO:root:current train perplexity3.9564244747161865
INFO:root:current mean train loss 3501.2125948774137
INFO:root:current train perplexity3.9666714668273926
INFO:root:current mean train loss 3488.836410454036
INFO:root:current train perplexity3.9647345542907715
INFO:root:current mean train loss 3488.242021968121
INFO:root:current train perplexity3.966691732406616
INFO:root:current mean train loss 3488.5117072067083
INFO:root:current train perplexity3.9667177200317383
INFO:root:current mean train loss 3493.396980125179
INFO:root:current train perplexity3.972090244293213
INFO:root:current mean train loss 3497.753442657128
INFO:root:current train perplexity3.9761295318603516
INFO:root:current mean train loss 3497.1100300937933
INFO:root:current train perplexity3.973302125930786
INFO:root:current mean train loss 3497.1742932677703
INFO:root:current train perplexity3.974787473678589
INFO:root:current mean train loss 3498.7660524444746
INFO:root:current train perplexity3.975475549697876

100%|██████████| 1/1 [02:27<00:00, 147.50s/it][A100%|██████████| 1/1 [02:27<00:00, 147.50s/it]
INFO:root:final mean train loss: 3498.588699279293
INFO:root:final train perplexity: 3.976072072982788
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.25s/it][A100%|██████████| 1/1 [00:08<00:00,  8.25s/it]
INFO:root:eval mean loss: 4267.070707280585
INFO:root:eval perplexity: 5.61520528793335
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.30s/it][A100%|██████████| 1/1 [00:08<00:00,  8.30s/it]
INFO:root:eval mean loss: 5331.026952432402
INFO:root:eval perplexity: 8.845688819885254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/179
 90%|████████▉ | 179/200 [8:13:06<57:35, 164.56s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3476.6846884450606
INFO:root:current train perplexity3.9640824794769287
INFO:root:current mean train loss 3509.8001625119273
INFO:root:current train perplexity3.9736452102661133
INFO:root:current mean train loss 3497.820984679383
INFO:root:current train perplexity3.965921401977539
INFO:root:current mean train loss 3492.846514468467
INFO:root:current train perplexity3.965780735015869
INFO:root:current mean train loss 3496.946973335992
INFO:root:current train perplexity3.9664628505706787
INFO:root:current mean train loss 3498.2172764205216
INFO:root:current train perplexity3.971270799636841
INFO:root:current mean train loss 3496.046657943121
INFO:root:current train perplexity3.9684998989105225
INFO:root:current mean train loss 3498.0509739574427
INFO:root:current train perplexity3.9722485542297363
INFO:root:current mean train loss 3499.429796790388
INFO:root:current train perplexity3.9733572006225586
INFO:root:current mean train loss 3499.7238714461937
INFO:root:current train perplexity3.9749934673309326

100%|██████████| 1/1 [02:27<00:00, 147.54s/it][A100%|██████████| 1/1 [02:27<00:00, 147.55s/it]
INFO:root:final mean train loss: 3497.275392409294
INFO:root:final train perplexity: 3.9740123748779297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 4267.70571704621
INFO:root:eval perplexity: 5.616647243499756
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 5331.530065658245
INFO:root:eval perplexity: 8.847509384155273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/180
 90%|█████████ | 180/200 [8:15:51<54:50, 164.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3461.5430376101763
INFO:root:current train perplexity3.947559118270874
INFO:root:current mean train loss 3494.330675303507
INFO:root:current train perplexity3.9728333950042725
INFO:root:current mean train loss 3501.550549367482
INFO:root:current train perplexity3.9779884815216064
INFO:root:current mean train loss 3502.984688997972
INFO:root:current train perplexity3.97761869430542
INFO:root:current mean train loss 3504.9183102131974
INFO:root:current train perplexity3.972975969314575
INFO:root:current mean train loss 3502.010469058007
INFO:root:current train perplexity3.975158929824829
INFO:root:current mean train loss 3503.6990804418524
INFO:root:current train perplexity3.9742045402526855
INFO:root:current mean train loss 3502.4571802451583
INFO:root:current train perplexity3.9748618602752686
INFO:root:current mean train loss 3499.910499618221
INFO:root:current train perplexity3.9758763313293457
INFO:root:current mean train loss 3499.4774046421558
INFO:root:current train perplexity3.9734771251678467

100%|██████████| 1/1 [02:27<00:00, 147.58s/it][A100%|██████████| 1/1 [02:27<00:00, 147.58s/it]
INFO:root:final mean train loss: 3496.784626499299
INFO:root:final train perplexity: 3.973243474960327
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.27s/it][A100%|██████████| 1/1 [00:08<00:00,  8.27s/it]
INFO:root:eval mean loss: 4266.8074215287015
INFO:root:eval perplexity: 5.614607810974121
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.30s/it][A100%|██████████| 1/1 [00:08<00:00,  8.30s/it]
INFO:root:eval mean loss: 5331.920508851396
INFO:root:eval perplexity: 8.848922729492188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/181
 90%|█████████ | 181/200 [8:18:35<52:05, 164.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3521.85107421875
INFO:root:current train perplexity3.9747233390808105
INFO:root:current mean train loss 3508.8497223107993
INFO:root:current train perplexity3.959866523742676
INFO:root:current mean train loss 3500.8284531566296
INFO:root:current train perplexity3.965174674987793
INFO:root:current mean train loss 3499.2793032071777
INFO:root:current train perplexity3.9711174964904785
INFO:root:current mean train loss 3495.512053009648
INFO:root:current train perplexity3.9633305072784424
INFO:root:current mean train loss 3495.48810896795
INFO:root:current train perplexity3.9609487056732178
INFO:root:current mean train loss 3495.7473857708655
INFO:root:current train perplexity3.9640214443206787
INFO:root:current mean train loss 3496.2846921540327
INFO:root:current train perplexity3.9659910202026367
INFO:root:current mean train loss 3496.785904236921
INFO:root:current train perplexity3.967404842376709
INFO:root:current mean train loss 3499.226740384933
INFO:root:current train perplexity3.970248222351074

100%|██████████| 1/1 [02:27<00:00, 147.96s/it][A100%|██████████| 1/1 [02:27<00:00, 147.96s/it]
INFO:root:final mean train loss: 3496.1600674659976
INFO:root:final train perplexity: 3.972264528274536
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.26s/it][A100%|██████████| 1/1 [00:08<00:00,  8.26s/it]
INFO:root:eval mean loss: 4267.599905460439
INFO:root:eval perplexity: 5.616406440734863
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 5331.910776124779
INFO:root:eval perplexity: 8.848886489868164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/182
 91%|█████████ | 182/200 [8:21:20<49:22, 164.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3487.278750887784
INFO:root:current train perplexity3.9574623107910156
INFO:root:current mean train loss 3500.869216229839
INFO:root:current train perplexity3.973083019256592
INFO:root:current mean train loss 3501.9900764016543
INFO:root:current train perplexity3.9753921031951904
INFO:root:current mean train loss 3504.1728935134242
INFO:root:current train perplexity3.9757773876190186
INFO:root:current mean train loss 3506.1885162688873
INFO:root:current train perplexity3.976363182067871
INFO:root:current mean train loss 3501.354767120636
INFO:root:current train perplexity3.976720094680786
INFO:root:current mean train loss 3502.823580629771
INFO:root:current train perplexity3.975644588470459
INFO:root:current mean train loss 3501.729669068191
INFO:root:current train perplexity3.975200653076172
INFO:root:current mean train loss 3500.20100083379
INFO:root:current train perplexity3.9714927673339844
INFO:root:current mean train loss 3498.7966300924413
INFO:root:current train perplexity3.9714879989624023

100%|██████████| 1/1 [02:27<00:00, 147.59s/it][A100%|██████████| 1/1 [02:27<00:00, 147.59s/it]
INFO:root:final mean train loss: 3495.929838980398
INFO:root:final train perplexity: 3.971902847290039
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.27s/it][A100%|██████████| 1/1 [00:08<00:00,  8.27s/it]
INFO:root:eval mean loss: 4267.358717032358
INFO:root:eval perplexity: 5.6158599853515625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.33s/it][A100%|██████████| 1/1 [00:08<00:00,  8.33s/it]
INFO:root:eval mean loss: 5330.955665101396
INFO:root:eval perplexity: 8.845431327819824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/183
 92%|█████████▏| 183/200 [8:24:05<46:37, 164.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3515.397720579117
INFO:root:current train perplexity3.9778964519500732
INFO:root:current mean train loss 3506.354138707822
INFO:root:current train perplexity3.9718620777130127
INFO:root:current mean train loss 3499.23486328125
INFO:root:current train perplexity3.9751992225646973
INFO:root:current mean train loss 3495.5006786167787
INFO:root:current train perplexity3.9652223587036133
INFO:root:current mean train loss 3493.5301089194113
INFO:root:current train perplexity3.965595245361328
INFO:root:current mean train loss 3494.082689952681
INFO:root:current train perplexity3.9667162895202637
INFO:root:current mean train loss 3497.680976326829
INFO:root:current train perplexity3.968329668045044
INFO:root:current mean train loss 3498.249684185063
INFO:root:current train perplexity3.9667913913726807
INFO:root:current mean train loss 3496.5627927990113
INFO:root:current train perplexity3.9679245948791504
INFO:root:current mean train loss 3497.2532194618866
INFO:root:current train perplexity3.9700865745544434

100%|██████████| 1/1 [02:27<00:00, 147.37s/it][A100%|██████████| 1/1 [02:27<00:00, 147.37s/it]
INFO:root:final mean train loss: 3495.2973502374466
INFO:root:final train perplexity: 3.970912456512451
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.28s/it][A100%|██████████| 1/1 [00:08<00:00,  8.28s/it]
INFO:root:eval mean loss: 4267.931593874668
INFO:root:eval perplexity: 5.617159843444824
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 5332.39436675809
INFO:root:eval perplexity: 8.850635528564453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/184
 92%|█████████▏| 184/200 [8:26:49<43:51, 164.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3486.93808456206
INFO:root:current train perplexity3.9762299060821533
INFO:root:current mean train loss 3506.7930087262425
INFO:root:current train perplexity3.977041482925415
INFO:root:current mean train loss 3503.527820319707
INFO:root:current train perplexity3.970876932144165
INFO:root:current mean train loss 3502.2957154965466
INFO:root:current train perplexity3.973388910293579
INFO:root:current mean train loss 3500.9869791666665
INFO:root:current train perplexity3.973855495452881
INFO:root:current mean train loss 3497.4836861899353
INFO:root:current train perplexity3.968196153640747
INFO:root:current mean train loss 3499.1783674669337
INFO:root:current train perplexity3.9699795246124268
INFO:root:current mean train loss 3497.3018534421612
INFO:root:current train perplexity3.9702601432800293
INFO:root:current mean train loss 3496.520150430988
INFO:root:current train perplexity3.9695677757263184
INFO:root:current mean train loss 3496.2361888315845
INFO:root:current train perplexity3.967474937438965

100%|██████████| 1/1 [02:27<00:00, 147.66s/it][A100%|██████████| 1/1 [02:27<00:00, 147.66s/it]
INFO:root:final mean train loss: 3493.381372944001
INFO:root:final train perplexity: 3.967912435531616
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.29s/it][A100%|██████████| 1/1 [00:08<00:00,  8.29s/it]
INFO:root:eval mean loss: 4267.997942985372
INFO:root:eval perplexity: 5.617310523986816
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.39s/it][A100%|██████████| 1/1 [00:08<00:00,  8.39s/it]
INFO:root:eval mean loss: 5333.336737450133
INFO:root:eval perplexity: 8.854048728942871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/185
 92%|█████████▎| 185/200 [8:29:34<41:07, 164.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3481.354340758505
INFO:root:current train perplexity3.9681427478790283
INFO:root:current mean train loss 3493.632491980185
INFO:root:current train perplexity3.9665658473968506
INFO:root:current mean train loss 3491.106190671203
INFO:root:current train perplexity3.9604685306549072
INFO:root:current mean train loss 3494.865056583938
INFO:root:current train perplexity3.9651618003845215
INFO:root:current mean train loss 3495.017394637265
INFO:root:current train perplexity3.963782787322998
INFO:root:current mean train loss 3499.194228836086
INFO:root:current train perplexity3.966052532196045
INFO:root:current mean train loss 3498.9047258289993
INFO:root:current train perplexity3.966637372970581
INFO:root:current mean train loss 3500.101020940308
INFO:root:current train perplexity3.9690775871276855
INFO:root:current mean train loss 3496.869437815522
INFO:root:current train perplexity3.96808123588562
INFO:root:current mean train loss 3495.852900161198
INFO:root:current train perplexity3.9678590297698975

100%|██████████| 1/1 [02:27<00:00, 147.79s/it][A100%|██████████| 1/1 [02:27<00:00, 147.79s/it]
INFO:root:final mean train loss: 3493.543971215525
INFO:root:final train perplexity: 3.9681663513183594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.26s/it][A100%|██████████| 1/1 [00:08<00:00,  8.26s/it]
INFO:root:eval mean loss: 4268.896048038564
INFO:root:eval perplexity: 5.619351863861084
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.39s/it][A100%|██████████| 1/1 [00:08<00:00,  8.39s/it]
INFO:root:eval mean loss: 5334.213861993018
INFO:root:eval perplexity: 8.857224464416504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/186
 93%|█████████▎| 186/200 [8:32:18<38:24, 164.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3466.0012403466235
INFO:root:current train perplexity3.9254541397094727
INFO:root:current mean train loss 3488.9302397539273
INFO:root:current train perplexity3.9622161388397217
INFO:root:current mean train loss 3492.5276406318053
INFO:root:current train perplexity3.9589810371398926
INFO:root:current mean train loss 3487.132211295825
INFO:root:current train perplexity3.9624311923980713
INFO:root:current mean train loss 3490.0016187475935
INFO:root:current train perplexity3.9642677307128906
INFO:root:current mean train loss 3491.9413284743664
INFO:root:current train perplexity3.9656264781951904
INFO:root:current mean train loss 3496.473212762691
INFO:root:current train perplexity3.9687507152557373
INFO:root:current mean train loss 3493.996642833744
INFO:root:current train perplexity3.9678337574005127
INFO:root:current mean train loss 3493.276678212197
INFO:root:current train perplexity3.9682047367095947
INFO:root:current mean train loss 3493.880709724465
INFO:root:current train perplexity3.965252161026001

100%|██████████| 1/1 [02:29<00:00, 149.04s/it][A100%|██████████| 1/1 [02:29<00:00, 149.04s/it]
INFO:root:final mean train loss: 3491.512784342612
INFO:root:final train perplexity: 3.9649879932403564
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.39s/it][A100%|██████████| 1/1 [00:08<00:00,  8.39s/it]
INFO:root:eval mean loss: 4268.600466464428
INFO:root:eval perplexity: 5.618679046630859
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.44s/it][A100%|██████████| 1/1 [00:08<00:00,  8.44s/it]
INFO:root:eval mean loss: 5334.191856438387
INFO:root:eval perplexity: 8.857146263122559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/187
 94%|█████████▎| 187/200 [8:35:05<35:45, 165.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3477.8638723273025
INFO:root:current train perplexity3.946359157562256
INFO:root:current mean train loss 3490.7606958633814
INFO:root:current train perplexity3.957542896270752
INFO:root:current mean train loss 3487.364487884004
INFO:root:current train perplexity3.959000825881958
INFO:root:current mean train loss 3490.02265872231
INFO:root:current train perplexity3.9626035690307617
INFO:root:current mean train loss 3493.6967280224117
INFO:root:current train perplexity3.9659266471862793
INFO:root:current mean train loss 3495.3680015756304
INFO:root:current train perplexity3.968008041381836
INFO:root:current mean train loss 3491.8753779788667
INFO:root:current train perplexity3.9652435779571533
INFO:root:current mean train loss 3492.536835446148
INFO:root:current train perplexity3.9632394313812256
INFO:root:current mean train loss 3492.3257959802722
INFO:root:current train perplexity3.962682008743286

100%|██████████| 1/1 [02:28<00:00, 148.38s/it][A100%|██████████| 1/1 [02:28<00:00, 148.38s/it]
INFO:root:final mean train loss: 3491.2982912371235
INFO:root:final train perplexity: 3.9646527767181396
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.27s/it][A100%|██████████| 1/1 [00:08<00:00,  8.27s/it]
INFO:root:eval mean loss: 4268.88863551363
INFO:root:eval perplexity: 5.619335174560547
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.38s/it][A100%|██████████| 1/1 [00:08<00:00,  8.38s/it]
INFO:root:eval mean loss: 5334.171533895723
INFO:root:eval perplexity: 8.857069969177246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/188
 94%|█████████▍| 188/200 [8:37:50<33:01, 165.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3457.4447428385415
INFO:root:current train perplexity3.9496898651123047
INFO:root:current mean train loss 3485.6061561362258
INFO:root:current train perplexity3.950679302215576
INFO:root:current mean train loss 3497.8936593191966
INFO:root:current train perplexity3.9592344760894775
INFO:root:current mean train loss 3492.031540873814
INFO:root:current train perplexity3.9573943614959717
INFO:root:current mean train loss 3493.037587357514
INFO:root:current train perplexity3.9621222019195557
INFO:root:current mean train loss 3491.3352220660413
INFO:root:current train perplexity3.9627840518951416
INFO:root:current mean train loss 3490.651737649642
INFO:root:current train perplexity3.95982027053833
INFO:root:current mean train loss 3490.798214126956
INFO:root:current train perplexity3.958901882171631
INFO:root:current mean train loss 3493.3654210528875
INFO:root:current train perplexity3.9595305919647217
INFO:root:current mean train loss 3492.6151375839218
INFO:root:current train perplexity3.961435556411743

100%|██████████| 1/1 [02:28<00:00, 148.01s/it][A100%|██████████| 1/1 [02:28<00:00, 148.01s/it]
INFO:root:final mean train loss: 3489.3837492542884
INFO:root:final train perplexity: 3.961658477783203
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.26s/it][A100%|██████████| 1/1 [00:08<00:00,  8.26s/it]
INFO:root:eval mean loss: 4269.050570007757
INFO:root:eval perplexity: 5.619702339172363
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.37s/it][A100%|██████████| 1/1 [00:08<00:00,  8.37s/it]
INFO:root:eval mean loss: 5334.26818934231
INFO:root:eval perplexity: 8.857422828674316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/189
 94%|█████████▍| 189/200 [8:40:35<30:15, 165.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3485.057950106534
INFO:root:current train perplexity3.9712424278259277
INFO:root:current mean train loss 3490.137110254786
INFO:root:current train perplexity3.990222930908203
INFO:root:current mean train loss 3479.120551086715
INFO:root:current train perplexity3.9604930877685547
INFO:root:current mean train loss 3484.278295191921
INFO:root:current train perplexity3.957496166229248
INFO:root:current mean train loss 3487.440435033645
INFO:root:current train perplexity3.956676721572876
INFO:root:current mean train loss 3489.603244729238
INFO:root:current train perplexity3.9587900638580322
INFO:root:current mean train loss 3489.0487074532016
INFO:root:current train perplexity3.957106590270996
INFO:root:current mean train loss 3491.017237838981
INFO:root:current train perplexity3.9585940837860107
INFO:root:current mean train loss 3492.8586031423397
INFO:root:current train perplexity3.959439754486084
INFO:root:current mean train loss 3494.1014378837644
INFO:root:current train perplexity3.960592269897461

100%|██████████| 1/1 [02:28<00:00, 148.05s/it][A100%|██████████| 1/1 [02:28<00:00, 148.05s/it]
INFO:root:final mean train loss: 3489.4759793435373
INFO:root:final train perplexity: 3.9618029594421387
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.31s/it][A100%|██████████| 1/1 [00:08<00:00,  8.31s/it]
INFO:root:eval mean loss: 4269.264797345966
INFO:root:eval perplexity: 5.620189666748047
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.36s/it][A100%|██████████| 1/1 [00:08<00:00,  8.36s/it]
INFO:root:eval mean loss: 5334.774585480385
INFO:root:eval perplexity: 8.85925579071045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/190
 95%|█████████▌| 190/200 [8:43:20<27:30, 165.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3527.186407791941
INFO:root:current train perplexity3.9919004440307617
INFO:root:current mean train loss 3504.12446863511
INFO:root:current train perplexity3.9736902713775635
INFO:root:current mean train loss 3501.232207833904
INFO:root:current train perplexity3.9575438499450684
INFO:root:current mean train loss 3499.7292036576705
INFO:root:current train perplexity3.9653921127319336
INFO:root:current mean train loss 3495.6082883120152
INFO:root:current train perplexity3.9662766456604004
INFO:root:current mean train loss 3493.481716266257
INFO:root:current train perplexity3.9630126953125
INFO:root:current mean train loss 3486.251418303211
INFO:root:current train perplexity3.9566192626953125
INFO:root:current mean train loss 3485.1711907950494
INFO:root:current train perplexity3.956296682357788
INFO:root:current mean train loss 3489.355706332513
INFO:root:current train perplexity3.9603264331817627
INFO:root:current mean train loss 3490.7413684732896
INFO:root:current train perplexity3.959402561187744

100%|██████████| 1/1 [02:27<00:00, 147.68s/it][A100%|██████████| 1/1 [02:27<00:00, 147.68s/it]
INFO:root:final mean train loss: 3489.350649741388
INFO:root:final train perplexity: 3.9616074562072754
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.30s/it][A100%|██████████| 1/1 [00:08<00:00,  8.30s/it]
INFO:root:eval mean loss: 4269.324630845523
INFO:root:eval perplexity: 5.620326042175293
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.33s/it][A100%|██████████| 1/1 [00:08<00:00,  8.33s/it]
INFO:root:eval mean loss: 5335.358052138741
INFO:root:eval perplexity: 8.861368179321289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/191
 96%|█████████▌| 191/200 [8:46:04<24:44, 164.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3506.613425925926
INFO:root:current train perplexity4.0043206214904785
INFO:root:current mean train loss 3488.702479084646
INFO:root:current train perplexity3.963456392288208
INFO:root:current mean train loss 3482.720089009155
INFO:root:current train perplexity3.964909791946411
INFO:root:current mean train loss 3483.564812243167
INFO:root:current train perplexity3.965515375137329
INFO:root:current mean train loss 3481.9421764078966
INFO:root:current train perplexity3.9615895748138428
INFO:root:current mean train loss 3485.924772722219
INFO:root:current train perplexity3.960613965988159
INFO:root:current mean train loss 3487.37458102821
INFO:root:current train perplexity3.9613637924194336
INFO:root:current mean train loss 3487.8496080317227
INFO:root:current train perplexity3.957801342010498
INFO:root:current mean train loss 3487.5409819707907
INFO:root:current train perplexity3.9571924209594727
INFO:root:current mean train loss 3490.7810113900687
INFO:root:current train perplexity3.9576189517974854

100%|██████████| 1/1 [02:28<00:00, 148.69s/it][A100%|██████████| 1/1 [02:28<00:00, 148.69s/it]
INFO:root:final mean train loss: 3487.5216331481934
INFO:root:final train perplexity: 3.958749294281006
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.39s/it][A100%|██████████| 1/1 [00:08<00:00,  8.40s/it]
INFO:root:eval mean loss: 4269.431574828236
INFO:root:eval perplexity: 5.620567798614502
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.41s/it][A100%|██████████| 1/1 [00:08<00:00,  8.41s/it]
INFO:root:eval mean loss: 5335.168715023825
INFO:root:eval perplexity: 8.86068344116211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/192
 96%|█████████▌| 192/200 [8:48:50<22:01, 165.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3522.80419921875
INFO:root:current train perplexity3.9527366161346436
INFO:root:current mean train loss 3491.5951280381946
INFO:root:current train perplexity3.9523844718933105
INFO:root:current mean train loss 3489.0461259557846
INFO:root:current train perplexity3.9505205154418945
INFO:root:current mean train loss 3481.8332096840018
INFO:root:current train perplexity3.951261520385742
INFO:root:current mean train loss 3485.5037317034844
INFO:root:current train perplexity3.95658016204834
INFO:root:current mean train loss 3487.0172331337617
INFO:root:current train perplexity3.953625202178955
INFO:root:current mean train loss 3490.135734113558
INFO:root:current train perplexity3.9571268558502197
INFO:root:current mean train loss 3489.3133001833544
INFO:root:current train perplexity3.9571328163146973
INFO:root:current mean train loss 3490.0574414647267
INFO:root:current train perplexity3.9592411518096924
INFO:root:current mean train loss 3488.6997132979614
INFO:root:current train perplexity3.95821475982666

100%|██████████| 1/1 [02:30<00:00, 150.03s/it][A100%|██████████| 1/1 [02:30<00:00, 150.03s/it]
INFO:root:final mean train loss: 3487.078359357772
INFO:root:final train perplexity: 3.9580576419830322
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.63s/it][A100%|██████████| 1/1 [00:08<00:00,  8.63s/it]
INFO:root:eval mean loss: 4269.436777967087
INFO:root:eval perplexity: 5.620581150054932
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.73s/it][A100%|██████████| 1/1 [00:08<00:00,  8.73s/it]
INFO:root:eval mean loss: 5336.089989195479
INFO:root:eval perplexity: 8.864022254943848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/193
 96%|█████████▋| 193/200 [8:51:38<19:21, 165.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3498.7092852925143
INFO:root:current train perplexity3.9596149921417236
INFO:root:current mean train loss 3513.608574287041
INFO:root:current train perplexity3.9632275104522705
INFO:root:current mean train loss 3499.2415163644546
INFO:root:current train perplexity3.953577756881714
INFO:root:current mean train loss 3495.1435077100036
INFO:root:current train perplexity3.9539010524749756
INFO:root:current mean train loss 3487.195777083627
INFO:root:current train perplexity3.945300340652466
INFO:root:current mean train loss 3485.7900386128854
INFO:root:current train perplexity3.9456827640533447
INFO:root:current mean train loss 3481.5259161158633
INFO:root:current train perplexity3.949131965637207
INFO:root:current mean train loss 3487.4187468455584
INFO:root:current train perplexity3.9549243450164795
INFO:root:current mean train loss 3489.107256797709
INFO:root:current train perplexity3.9547665119171143
INFO:root:current mean train loss 3489.9744962366617
INFO:root:current train perplexity3.9579241275787354

100%|██████████| 1/1 [02:30<00:00, 150.41s/it][A100%|██████████| 1/1 [02:30<00:00, 150.42s/it]
INFO:root:final mean train loss: 3486.242750044792
INFO:root:final train perplexity: 3.9567527770996094
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.71s/it][A100%|██████████| 1/1 [00:08<00:00,  8.71s/it]
INFO:root:eval mean loss: 4269.35599339262
INFO:root:eval perplexity: 5.620396137237549
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.69s/it][A100%|██████████| 1/1 [00:08<00:00,  8.69s/it]
INFO:root:eval mean loss: 5335.747333499557
INFO:root:eval perplexity: 8.86277961730957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/194
 97%|█████████▋| 194/200 [8:54:26<16:39, 166.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3495.8064778645835
INFO:root:current train perplexity3.959892511367798
INFO:root:current mean train loss 3480.765093064466
INFO:root:current train perplexity3.9423131942749023
INFO:root:current mean train loss 3480.511972617343
INFO:root:current train perplexity3.9550564289093018
INFO:root:current mean train loss 3483.9118381076387
INFO:root:current train perplexity3.958275556564331
INFO:root:current mean train loss 3485.894054336717
INFO:root:current train perplexity3.9605274200439453
INFO:root:current mean train loss 3486.8786483736953
INFO:root:current train perplexity3.959951162338257
INFO:root:current mean train loss 3488.1360662082375
INFO:root:current train perplexity3.9575343132019043
INFO:root:current mean train loss 3487.835919620194
INFO:root:current train perplexity3.9578239917755127
INFO:root:current mean train loss 3487.4751820009546
INFO:root:current train perplexity3.956669807434082
INFO:root:current mean train loss 3487.720597099681
INFO:root:current train perplexity3.956482410430908

100%|██████████| 1/1 [02:30<00:00, 150.21s/it][A100%|██████████| 1/1 [02:30<00:00, 150.21s/it]
INFO:root:final mean train loss: 3486.5470210659887
INFO:root:final train perplexity: 3.9572277069091797
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.68s/it][A100%|██████████| 1/1 [00:08<00:00,  8.68s/it]
INFO:root:eval mean loss: 4269.372577640182
INFO:root:eval perplexity: 5.6204352378845215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.65s/it][A100%|██████████| 1/1 [00:08<00:00,  8.65s/it]
INFO:root:eval mean loss: 5335.979050656582
INFO:root:eval perplexity: 8.86362075805664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/195
 98%|█████████▊| 195/200 [8:57:14<13:54, 166.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3527.6301352290784
INFO:root:current train perplexity3.971776008605957
INFO:root:current mean train loss 3496.376102471502
INFO:root:current train perplexity3.963346242904663
INFO:root:current mean train loss 3493.696354103825
INFO:root:current train perplexity3.9552199840545654
INFO:root:current mean train loss 3490.168719533426
INFO:root:current train perplexity3.9561588764190674
INFO:root:current mean train loss 3488.4091514969705
INFO:root:current train perplexity3.9540188312530518
INFO:root:current mean train loss 3487.2171764066693
INFO:root:current train perplexity3.9552195072174072
INFO:root:current mean train loss 3489.4321026027837
INFO:root:current train perplexity3.9537558555603027
INFO:root:current mean train loss 3488.235463500494
INFO:root:current train perplexity3.9540717601776123
INFO:root:current mean train loss 3487.83351627301
INFO:root:current train perplexity3.9544520378112793
INFO:root:current mean train loss 3488.0965551986933
INFO:root:current train perplexity3.9546806812286377

100%|██████████| 1/1 [02:30<00:00, 150.27s/it][A100%|██████████| 1/1 [02:30<00:00, 150.27s/it]
INFO:root:final mean train loss: 3485.1951317325716
INFO:root:final train perplexity: 3.9551167488098145
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.61s/it][A100%|██████████| 1/1 [00:08<00:00,  8.61s/it]
INFO:root:eval mean loss: 4269.456009668661
INFO:root:eval perplexity: 5.62062406539917
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.63s/it][A100%|██████████| 1/1 [00:08<00:00,  8.63s/it]
INFO:root:eval mean loss: 5336.271792580896
INFO:root:eval perplexity: 8.864681243896484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/196
 98%|█████████▊| 196/200 [9:00:02<11:08, 167.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3504.708113485308
INFO:root:current train perplexity3.9500486850738525
INFO:root:current mean train loss 3483.7369333598426
INFO:root:current train perplexity3.94109845161438
INFO:root:current mean train loss 3481.9853250453534
INFO:root:current train perplexity3.943634033203125
INFO:root:current mean train loss 3480.0046286933753
INFO:root:current train perplexity3.9480481147766113
INFO:root:current mean train loss 3483.0401566891396
INFO:root:current train perplexity3.9494097232818604
INFO:root:current mean train loss 3479.964603915206
INFO:root:current train perplexity3.946617603302002
INFO:root:current mean train loss 3482.672650247142
INFO:root:current train perplexity3.9535419940948486
INFO:root:current mean train loss 3484.1352239854955
INFO:root:current train perplexity3.95428466796875
INFO:root:current mean train loss 3485.397863896248
INFO:root:current train perplexity3.9572348594665527
INFO:root:current mean train loss 3488.666192103073
INFO:root:current train perplexity3.956639528274536

100%|██████████| 1/1 [02:29<00:00, 149.95s/it][A100%|██████████| 1/1 [02:29<00:00, 149.95s/it]
INFO:root:final mean train loss: 3485.638024176321
INFO:root:final train perplexity: 3.9558091163635254
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 4269.691432222407
INFO:root:eval perplexity: 5.621159553527832
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.35s/it][A100%|██████████| 1/1 [00:08<00:00,  8.35s/it]
INFO:root:eval mean loss: 5336.477147744902
INFO:root:eval perplexity: 8.865426063537598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/197
 98%|█████████▊| 197/200 [9:02:49<08:21, 167.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3487.135576171875
INFO:root:current train perplexity3.930911064147949
INFO:root:current mean train loss 3479.25185546875
INFO:root:current train perplexity3.933192014694214
INFO:root:current mean train loss 3483.526377840909
INFO:root:current train perplexity3.9435601234436035
INFO:root:current mean train loss 3482.0616998697915
INFO:root:current train perplexity3.946892261505127
INFO:root:current mean train loss 3480.883136821546
INFO:root:current train perplexity3.948280096054077
INFO:root:current mean train loss 3481.3307642663044
INFO:root:current train perplexity3.9476540088653564
INFO:root:current mean train loss 3482.9701898871526
INFO:root:current train perplexity3.9491899013519287
INFO:root:current mean train loss 3486.9068170362902
INFO:root:current train perplexity3.949923038482666
INFO:root:current mean train loss 3485.7001637834824
INFO:root:current train perplexity3.9525234699249268
INFO:root:current mean train loss 3486.742311448317
INFO:root:current train perplexity3.9530131816864014

100%|██████████| 1/1 [02:29<00:00, 150.00s/it][A100%|██████████| 1/1 [02:29<00:00, 150.00s/it]
INFO:root:final mean train loss: 3484.233030996015
INFO:root:final train perplexity: 3.9536163806915283
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.56s/it][A100%|██████████| 1/1 [00:08<00:00,  8.56s/it]
INFO:root:eval mean loss: 4269.595230427194
INFO:root:eval perplexity: 5.620940208435059
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.86s/it][A100%|██████████| 1/1 [00:08<00:00,  8.87s/it]
INFO:root:eval mean loss: 5336.260776817376
INFO:root:eval perplexity: 8.864639282226562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/198
 99%|█████████▉| 198/200 [9:05:36<05:34, 167.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3474.907473644578
INFO:root:current train perplexity3.9574649333953857
INFO:root:current mean train loss 3480.0318476775956
INFO:root:current train perplexity3.9653196334838867
INFO:root:current mean train loss 3481.7328747860533
INFO:root:current train perplexity3.956298589706421
INFO:root:current mean train loss 3484.873214522479
INFO:root:current train perplexity3.953981637954712
INFO:root:current mean train loss 3486.6185982587667
INFO:root:current train perplexity3.9526097774505615
INFO:root:current mean train loss 3487.0565170890063
INFO:root:current train perplexity3.957199811935425
INFO:root:current mean train loss 3485.2638002007457
INFO:root:current train perplexity3.9527337551116943
INFO:root:current mean train loss 3485.9330802128234
INFO:root:current train perplexity3.951227903366089
INFO:root:current mean train loss 3485.9324355336034
INFO:root:current train perplexity3.950529098510742
INFO:root:current mean train loss 3485.7487559507726
INFO:root:current train perplexity3.9519059658050537

100%|██████████| 1/1 [02:30<00:00, 150.56s/it][A100%|██████████| 1/1 [02:30<00:00, 150.56s/it]
INFO:root:final mean train loss: 3482.8972339630127
INFO:root:final train perplexity: 3.951533317565918
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.62s/it][A100%|██████████| 1/1 [00:08<00:00,  8.62s/it]
INFO:root:eval mean loss: 4269.741292317708
INFO:root:eval perplexity: 5.621272087097168
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.65s/it][A100%|██████████| 1/1 [00:08<00:00,  8.66s/it]
INFO:root:eval mean loss: 5336.553001025044
INFO:root:eval perplexity: 8.865697860717773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/199
100%|█████████▉| 199/200 [9:08:25<02:47, 167.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3468.8639305030906
INFO:root:current train perplexity3.932044744491577
INFO:root:current mean train loss 3484.154312213678
INFO:root:current train perplexity3.9431846141815186
INFO:root:current mean train loss 3481.551444876235
INFO:root:current train perplexity3.948535203933716
INFO:root:current mean train loss 3485.9460474194775
INFO:root:current train perplexity3.950875759124756
INFO:root:current mean train loss 3480.7646454541114
INFO:root:current train perplexity3.949596643447876
INFO:root:current mean train loss 3482.9694295453946
INFO:root:current train perplexity3.9514243602752686
INFO:root:current mean train loss 3483.6993968207307
INFO:root:current train perplexity3.9504122734069824
INFO:root:current mean train loss 3484.9587334441176
INFO:root:current train perplexity3.9507551193237305
INFO:root:current mean train loss 3486.5811009947565
INFO:root:current train perplexity3.953434944152832
INFO:root:current mean train loss 3485.179922279027
INFO:root:current train perplexity3.9509365558624268

100%|██████████| 1/1 [02:30<00:00, 150.58s/it][A100%|██████████| 1/1 [02:30<00:00, 150.58s/it]
INFO:root:final mean train loss: 3482.528381778348
INFO:root:final train perplexity: 3.950958013534546
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.73s/it][A100%|██████████| 1/1 [00:08<00:00,  8.73s/it]
INFO:root:eval mean loss: 4269.710802443484
INFO:root:eval perplexity: 5.621203422546387
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|██████████| 1/1 [00:08<00:00,  8.64s/it][A100%|██████████| 1/1 [00:08<00:00,  8.64s/it]
INFO:root:eval mean loss: 5336.52623905696
INFO:root:eval perplexity: 8.86560344696045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_fair_baseline/200
100%|██████████| 200/200 [9:11:13<00:00, 167.76s/it]100%|██████████| 200/200 [9:11:13<00:00, 165.37s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:08<00:00,  8.50s/it]100%|██████████| 1/1 [00:08<00:00,  8.50s/it]
INFO:root:eval mean loss: 4269.710802443484
INFO:root:eval perplexity: 5.621203422546387
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:08<00:00,  8.68s/it]100%|██████████| 1/1 [00:08<00:00,  8.68s/it]
INFO:root:eval mean loss: 5336.52623905696
INFO:root:eval perplexity: 8.86560344696045
INFO:root:evalaution complete
INFO:root:save model final: multil6_fair_baseline/final
