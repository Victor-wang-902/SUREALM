INFO:root:Output: small_multiqa_multiqa_not_cross
INFO:root:Steps per epochs:1983
INFO:root:Total steps:396600
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12511.439650410353
INFO:root:current train perplexity20733.6875
INFO:root:current mean train loss 10664.707504809203
INFO:root:current train perplexity4583.86083984375
INFO:root:current mean train loss 9204.541763560828
INFO:root:current train perplexity1407.701416015625
INFO:root:current mean train loss 8204.765048607847
INFO:root:current train perplexity646.4470825195312
INFO:root:current mean train loss 7507.3559903009145
INFO:root:current train perplexity372.8059997558594
INFO:root:current mean train loss 6983.667356971906
INFO:root:current train perplexity247.0767059326172
INFO:root:current mean train loss 6576.183036313037
INFO:root:current train perplexity179.81394958496094
INFO:root:current mean train loss 6247.380738985255
INFO:root:current train perplexity138.79237365722656
INFO:root:current mean train loss 5984.541762711607
INFO:root:current train perplexity112.34417724609375
INFO:root:current mean train loss 5758.915157833615
INFO:root:current train perplexity94.12052917480469
INFO:root:current mean train loss 5564.982720441879
INFO:root:current train perplexity80.87345886230469
INFO:root:current mean train loss 5399.108154907735
INFO:root:current train perplexity70.93540954589844
INFO:root:current mean train loss 5253.281794852711
INFO:root:current train perplexity63.190616607666016
INFO:root:current mean train loss 5127.042307528536
INFO:root:current train perplexity57.0462760925293
INFO:root:current mean train loss 5012.702679716165
INFO:root:current train perplexity52.07918930053711
INFO:root:current mean train loss 4911.537371532257
INFO:root:current train perplexity48.01393127441406
INFO:root:current mean train loss 4819.004745438493
INFO:root:current train perplexity44.61124801635742
INFO:root:current mean train loss 4732.425610663693
INFO:root:current train perplexity41.70640563964844
INFO:root:current mean train loss 4652.502910917341
INFO:root:current train perplexity39.214195251464844

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:15<00:00, 315.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:15<00:00, 315.68s/it]
INFO:root:final mean train loss: 4590.342566293475
INFO:root:final train perplexity: 37.34579086303711
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.02s/it]
INFO:root:eval mean loss: 2986.033094906638
INFO:root:eval perplexity: 11.188966751098633
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.61s/it]
INFO:root:eval mean loss: 3278.248653763575
INFO:root:eval perplexity: 14.600297927856445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/1
  0%|          | 1/200 [06:06<20:14:52, 366.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3238.9373474121094
INFO:root:current train perplexity12.387115478515625
INFO:root:current mean train loss 3173.031656199488
INFO:root:current train perplexity12.129878997802734
INFO:root:current mean train loss 3162.114091661241
INFO:root:current train perplexity11.984735488891602
INFO:root:current mean train loss 3137.4404868596716
INFO:root:current train perplexity11.854183197021484
INFO:root:current mean train loss 3130.1587225107046
INFO:root:current train perplexity11.80019474029541
INFO:root:current mean train loss 3120.1999913888385
INFO:root:current train perplexity11.70762825012207
INFO:root:current mean train loss 3104.5633743087965
INFO:root:current train perplexity11.590198516845703
INFO:root:current mean train loss 3093.7711549897435
INFO:root:current train perplexity11.494298934936523
INFO:root:current mean train loss 3081.6277250402113
INFO:root:current train perplexity11.394624710083008
INFO:root:current mean train loss 3074.311796629793
INFO:root:current train perplexity11.324190139770508
INFO:root:current mean train loss 3062.17836298905
INFO:root:current train perplexity11.231921195983887
INFO:root:current mean train loss 3050.383033451641
INFO:root:current train perplexity11.134806632995605
INFO:root:current mean train loss 3043.1113066422313
INFO:root:current train perplexity11.050433158874512
INFO:root:current mean train loss 3035.610575296234
INFO:root:current train perplexity10.96714973449707
INFO:root:current mean train loss 3026.9969566905565
INFO:root:current train perplexity10.885541915893555
INFO:root:current mean train loss 3018.7627085179956
INFO:root:current train perplexity10.820178031921387
INFO:root:current mean train loss 3012.1472276744275
INFO:root:current train perplexity10.763526916503906
INFO:root:current mean train loss 3005.7734773364655
INFO:root:current train perplexity10.705320358276367
INFO:root:current mean train loss 2998.3664182419293
INFO:root:current train perplexity10.645894050598145
INFO:root:current mean train loss 2992.020234237384
INFO:root:current train perplexity10.581283569335938

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:09<00:00, 309.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:09<00:00, 309.92s/it]
INFO:root:final mean train loss: 2986.8823663246976
INFO:root:final train perplexity: 10.544824600219727
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.95s/it]
INFO:root:eval mean loss: 2666.394452034159
INFO:root:eval perplexity: 8.640176773071289
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.91s/it]
INFO:root:eval mean loss: 3006.818151595745
INFO:root:eval perplexity: 11.69379711151123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/2
  1%|          | 2/200 [13:35<22:48:52, 414.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2855.3547881155305
INFO:root:current train perplexity9.441328048706055
INFO:root:current mean train loss 2841.6793901257047
INFO:root:current train perplexity9.282804489135742
INFO:root:current mean train loss 2825.064750704131
INFO:root:current train perplexity9.215784072875977
INFO:root:current mean train loss 2822.442167264921
INFO:root:current train perplexity9.207974433898926
INFO:root:current mean train loss 2824.2748048002672
INFO:root:current train perplexity9.217204093933105
INFO:root:current mean train loss 2818.5518975177356
INFO:root:current train perplexity9.159849166870117
INFO:root:current mean train loss 2812.9332219465837
INFO:root:current train perplexity9.117453575134277
INFO:root:current mean train loss 2808.6665835100825
INFO:root:current train perplexity9.093803405761719
INFO:root:current mean train loss 2803.317155963948
INFO:root:current train perplexity9.071154594421387
INFO:root:current mean train loss 2795.9752622483757
INFO:root:current train perplexity9.031023979187012
INFO:root:current mean train loss 2789.9666378172647
INFO:root:current train perplexity8.99717903137207
INFO:root:current mean train loss 2787.3077363488114
INFO:root:current train perplexity8.979718208312988
INFO:root:current mean train loss 2780.44502578822
INFO:root:current train perplexity8.944794654846191
INFO:root:current mean train loss 2774.252486278308
INFO:root:current train perplexity8.9127779006958
INFO:root:current mean train loss 2771.241586944729
INFO:root:current train perplexity8.880473136901855
INFO:root:current mean train loss 2766.573196480808
INFO:root:current train perplexity8.846589088439941
INFO:root:current mean train loss 2762.6974405451047
INFO:root:current train perplexity8.822935104370117
INFO:root:current mean train loss 2758.6344292096437
INFO:root:current train perplexity8.801194190979004
INFO:root:current mean train loss 2754.2948123913156
INFO:root:current train perplexity8.773571014404297
INFO:root:current mean train loss 2749.8328159606585
INFO:root:current train perplexity8.739912033081055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:11<00:00, 311.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:11<00:00, 311.09s/it]
INFO:root:final mean train loss: 2746.4681073918346
INFO:root:final train perplexity: 8.72358226776123
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.84s/it]
INFO:root:eval mean loss: 2523.1942359437335
INFO:root:eval perplexity: 7.695309638977051
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.94s/it]
INFO:root:eval mean loss: 2886.6323112325467
INFO:root:eval perplexity: 10.599079132080078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/3
  2%|â–         | 3/200 [19:40<21:27:20, 392.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2680.746103515625
INFO:root:current train perplexity8.234780311584473
INFO:root:current mean train loss 2658.106689453125
INFO:root:current train perplexity8.180716514587402
INFO:root:current mean train loss 2645.4651064453124
INFO:root:current train perplexity8.122257232666016
INFO:root:current mean train loss 2653.1338657924107
INFO:root:current train perplexity8.107367515563965
INFO:root:current mean train loss 2648.1833528645834
INFO:root:current train perplexity8.078521728515625
INFO:root:current mean train loss 2655.0278773082387
INFO:root:current train perplexity8.093088150024414
INFO:root:current mean train loss 2653.5342262620193
INFO:root:current train perplexity8.08258056640625
INFO:root:current mean train loss 2651.6624680989585
INFO:root:current train perplexity8.071501731872559
INFO:root:current mean train loss 2650.791004136029
INFO:root:current train perplexity8.052128791809082
INFO:root:current mean train loss 2647.4996887849506
INFO:root:current train perplexity8.023785591125488
INFO:root:current mean train loss 2643.8365459914435
INFO:root:current train perplexity8.006192207336426
INFO:root:current mean train loss 2640.1856150220788
INFO:root:current train perplexity7.987636566162109
INFO:root:current mean train loss 2637.0192974609377
INFO:root:current train perplexity7.969447612762451
INFO:root:current mean train loss 2632.870080114294
INFO:root:current train perplexity7.950662612915039
INFO:root:current mean train loss 2629.75794450431
INFO:root:current train perplexity7.937130451202393
INFO:root:current mean train loss 2627.365257844002
INFO:root:current train perplexity7.926440238952637
INFO:root:current mean train loss 2624.503191879735
INFO:root:current train perplexity7.913699626922607
INFO:root:current mean train loss 2620.9279029017857
INFO:root:current train perplexity7.893981456756592
INFO:root:current mean train loss 2618.8465312236062
INFO:root:current train perplexity7.879703521728516
INFO:root:current mean train loss 2616.815870768229
INFO:root:current train perplexity7.868743419647217

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:12<00:00, 312.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:12<00:00, 312.89s/it]
INFO:root:final mean train loss: 2615.2130807173476
INFO:root:final train perplexity: 7.865721702575684
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.44s/it]
INFO:root:eval mean loss: 2435.29579930948
INFO:root:eval perplexity: 7.167266845703125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.60s/it]
INFO:root:eval mean loss: 2809.8776747250386
INFO:root:eval perplexity: 9.954205513000488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/4
  2%|â–         | 4/200 [25:46<20:47:11, 381.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2561.8931356401586
INFO:root:current train perplexity7.646965503692627
INFO:root:current mean train loss 2556.67920506643
INFO:root:current train perplexity7.605410099029541
INFO:root:current mean train loss 2541.736854810393
INFO:root:current train perplexity7.493056774139404
INFO:root:current mean train loss 2543.0870091908632
INFO:root:current train perplexity7.465668201446533
INFO:root:current mean train loss 2543.7164502685023
INFO:root:current train perplexity7.444172382354736
INFO:root:current mean train loss 2542.0545581097745
INFO:root:current train perplexity7.435431480407715
INFO:root:current mean train loss 2542.9068610836184
INFO:root:current train perplexity7.424625396728516
INFO:root:current mean train loss 2541.7006754769495
INFO:root:current train perplexity7.42020845413208
INFO:root:current mean train loss 2542.9451228475077
INFO:root:current train perplexity7.4160943031311035
INFO:root:current mean train loss 2540.8628895393695
INFO:root:current train perplexity7.405177116394043
INFO:root:current mean train loss 2539.5982688896656
INFO:root:current train perplexity7.403487682342529
INFO:root:current mean train loss 2537.8904988502168
INFO:root:current train perplexity7.396268367767334
INFO:root:current mean train loss 2537.00286956763
INFO:root:current train perplexity7.393861770629883
INFO:root:current mean train loss 2535.2872613601294
INFO:root:current train perplexity7.389387130737305
INFO:root:current mean train loss 2535.190395903896
INFO:root:current train perplexity7.38166618347168
INFO:root:current mean train loss 2532.724663282247
INFO:root:current train perplexity7.369913578033447
INFO:root:current mean train loss 2530.8326211710782
INFO:root:current train perplexity7.357345104217529
INFO:root:current mean train loss 2530.6508838802524
INFO:root:current train perplexity7.351815700531006
INFO:root:current mean train loss 2528.5903075779574
INFO:root:current train perplexity7.339869499206543
INFO:root:current mean train loss 2526.764578248622
INFO:root:current train perplexity7.333383560180664

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:07<00:00, 307.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:07<00:00, 307.73s/it]
INFO:root:final mean train loss: 2526.3995627876006
INFO:root:final train perplexity: 7.3336310386657715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.59s/it]
INFO:root:eval mean loss: 2375.936723425033
INFO:root:eval perplexity: 6.831322193145752
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.05s/it]
INFO:root:eval mean loss: 2759.588345142121
INFO:root:eval perplexity: 9.55311393737793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/5
  2%|â–Ž         | 5/200 [31:43<20:12:20, 373.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2456.08163016183
INFO:root:current train perplexity6.979992866516113
INFO:root:current mean train loss 2471.3419089939284
INFO:root:current train perplexity7.044727325439453
INFO:root:current mean train loss 2474.8889293402012
INFO:root:current train perplexity7.031895160675049
INFO:root:current mean train loss 2478.4410422643027
INFO:root:current train perplexity7.047786712646484
INFO:root:current mean train loss 2473.900877645193
INFO:root:current train perplexity7.0186991691589355
INFO:root:current mean train loss 2473.372817575115
INFO:root:current train perplexity7.028936862945557
INFO:root:current mean train loss 2474.3401146604306
INFO:root:current train perplexity7.023737907409668
INFO:root:current mean train loss 2476.7646434550384
INFO:root:current train perplexity7.032479763031006
INFO:root:current mean train loss 2473.9087191620565
INFO:root:current train perplexity7.016929626464844
INFO:root:current mean train loss 2472.090371977023
INFO:root:current train perplexity7.010397434234619
INFO:root:current mean train loss 2473.7757363407372
INFO:root:current train perplexity7.022449493408203
INFO:root:current mean train loss 2471.009467253814
INFO:root:current train perplexity7.01759147644043
INFO:root:current mean train loss 2471.153744516343
INFO:root:current train perplexity7.012289524078369
INFO:root:current mean train loss 2469.2471943232367
INFO:root:current train perplexity7.007708549499512
INFO:root:current mean train loss 2468.6155569071398
INFO:root:current train perplexity7.004085540771484
INFO:root:current mean train loss 2466.702250548083
INFO:root:current train perplexity6.99537992477417
INFO:root:current mean train loss 2464.2716803108997
INFO:root:current train perplexity6.989684104919434
INFO:root:current mean train loss 2462.2924433139406
INFO:root:current train perplexity6.981071472167969
INFO:root:current mean train loss 2462.226670510197
INFO:root:current train perplexity6.974391937255859

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:12<00:00, 312.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:12<00:00, 312.67s/it]
INFO:root:final mean train loss: 2461.9407394493824
INFO:root:final train perplexity: 6.970134735107422
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.51s/it]
INFO:root:eval mean loss: 2329.306222902122
INFO:root:eval perplexity: 6.57849645614624
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.12s/it]
INFO:root:eval mean loss: 2716.7006320818095
INFO:root:eval perplexity: 9.223849296569824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/6
  3%|â–Ž         | 6/200 [37:46<19:55:30, 369.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2576.170166015625
INFO:root:current train perplexity7.050677299499512
INFO:root:current mean train loss 2469.2159363397277
INFO:root:current train perplexity6.840682029724121
INFO:root:current mean train loss 2445.5688719488494
INFO:root:current train perplexity6.791952610015869
INFO:root:current mean train loss 2451.974954091829
INFO:root:current train perplexity6.825189590454102
INFO:root:current mean train loss 2442.8975890961074
INFO:root:current train perplexity6.820042610168457
INFO:root:current mean train loss 2445.1728717857254
INFO:root:current train perplexity6.805810451507568
INFO:root:current mean train loss 2435.7953545035616
INFO:root:current train perplexity6.781544208526611
INFO:root:current mean train loss 2434.089227303629
INFO:root:current train perplexity6.775239944458008
INFO:root:current mean train loss 2430.5353578717522
INFO:root:current train perplexity6.766603469848633
INFO:root:current mean train loss 2428.889049060072
INFO:root:current train perplexity6.759415626525879
INFO:root:current mean train loss 2425.3928133633945
INFO:root:current train perplexity6.748425006866455
INFO:root:current mean train loss 2422.012548185066
INFO:root:current train perplexity6.7344279289245605
INFO:root:current mean train loss 2419.5743930635604
INFO:root:current train perplexity6.729134559631348
INFO:root:current mean train loss 2419.446753042281
INFO:root:current train perplexity6.719965934753418
INFO:root:current mean train loss 2417.803994722659
INFO:root:current train perplexity6.716170310974121
INFO:root:current mean train loss 2417.9055193672966
INFO:root:current train perplexity6.717331409454346
INFO:root:current mean train loss 2415.8332683460776
INFO:root:current train perplexity6.711979866027832
INFO:root:current mean train loss 2414.8905679477375
INFO:root:current train perplexity6.708935260772705
INFO:root:current mean train loss 2414.332601137389
INFO:root:current train perplexity6.706029415130615
INFO:root:current mean train loss 2413.6652114763815
INFO:root:current train perplexity6.701833724975586

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.25s/it]
INFO:root:final mean train loss: 2411.2514415438945
INFO:root:final train perplexity: 6.696988582611084
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.50s/it]
INFO:root:eval mean loss: 2298.6750297816934
INFO:root:eval perplexity: 6.4175310134887695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.20s/it]
INFO:root:eval mean loss: 2694.60698380707
INFO:root:eval perplexity: 9.058682441711426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/7
  4%|â–Ž         | 7/200 [43:40<19:31:49, 364.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2397.528021918403
INFO:root:current train perplexity6.56428861618042
INFO:root:current mean train loss 2381.4152449268404
INFO:root:current train perplexity6.570597171783447
INFO:root:current mean train loss 2381.039901313432
INFO:root:current train perplexity6.539580821990967
INFO:root:current mean train loss 2379.5232240688874
INFO:root:current train perplexity6.519489288330078
INFO:root:current mean train loss 2378.2924360795455
INFO:root:current train perplexity6.516593933105469
INFO:root:current mean train loss 2379.482858547373
INFO:root:current train perplexity6.533265590667725
INFO:root:current mean train loss 2379.1365275460153
INFO:root:current train perplexity6.524648666381836
INFO:root:current mean train loss 2378.595405089822
INFO:root:current train perplexity6.518813133239746
INFO:root:current mean train loss 2374.444606939563
INFO:root:current train perplexity6.50742769241333
INFO:root:current mean train loss 2374.2386646146088
INFO:root:current train perplexity6.512818336486816
INFO:root:current mean train loss 2372.8211701098967
INFO:root:current train perplexity6.507113456726074
INFO:root:current mean train loss 2370.3482430173162
INFO:root:current train perplexity6.498138427734375
INFO:root:current mean train loss 2370.3530307512956
INFO:root:current train perplexity6.497618198394775
INFO:root:current mean train loss 2369.8731348619476
INFO:root:current train perplexity6.491254806518555
INFO:root:current mean train loss 2369.9089872847153
INFO:root:current train perplexity6.487602710723877
INFO:root:current mean train loss 2371.220012840703
INFO:root:current train perplexity6.488389015197754
INFO:root:current mean train loss 2371.9485854631007
INFO:root:current train perplexity6.490089416503906
INFO:root:current mean train loss 2371.369028075888
INFO:root:current train perplexity6.484272480010986
INFO:root:current mean train loss 2370.6594701584418
INFO:root:current train perplexity6.482465744018555
INFO:root:current mean train loss 2370.3939492202776
INFO:root:current train perplexity6.48351526260376

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:13<00:00, 313.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:13<00:00, 313.04s/it]
INFO:root:final mean train loss: 2369.770372384014
INFO:root:final train perplexity: 6.481444835662842
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.04s/it]
INFO:root:eval mean loss: 2265.799970478031
INFO:root:eval perplexity: 6.249152660369873
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.48s/it]
INFO:root:eval mean loss: 2663.6225239638743
INFO:root:eval perplexity: 8.83202075958252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/8
  4%|â–         | 8/200 [49:43<19:25:07, 364.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2325.486457170759
INFO:root:current train perplexity6.2821149826049805
INFO:root:current mean train loss 2334.1515697337964
INFO:root:current train perplexity6.301458358764648
INFO:root:current mean train loss 2331.753842357879
INFO:root:current train perplexity6.322267055511475
INFO:root:current mean train loss 2327.5139495394124
INFO:root:current train perplexity6.324260711669922
INFO:root:current mean train loss 2322.0231731546337
INFO:root:current train perplexity6.314966678619385
INFO:root:current mean train loss 2325.2044045706775
INFO:root:current train perplexity6.312061309814453
INFO:root:current mean train loss 2331.0978673259106
INFO:root:current train perplexity6.32353401184082
INFO:root:current mean train loss 2330.578929501488
INFO:root:current train perplexity6.327571868896484
INFO:root:current mean train loss 2331.84606290349
INFO:root:current train perplexity6.32289457321167
INFO:root:current mean train loss 2335.6853352429393
INFO:root:current train perplexity6.324748516082764
INFO:root:current mean train loss 2337.315714518229
INFO:root:current train perplexity6.329606056213379
INFO:root:current mean train loss 2336.4677578426144
INFO:root:current train perplexity6.327500820159912
INFO:root:current mean train loss 2339.518270812247
INFO:root:current train perplexity6.3324875831604
INFO:root:current mean train loss 2338.600043158942
INFO:root:current train perplexity6.326533317565918
INFO:root:current mean train loss 2337.1338683444033
INFO:root:current train perplexity6.322355270385742
INFO:root:current mean train loss 2338.0986934897956
INFO:root:current train perplexity6.323550701141357
INFO:root:current mean train loss 2340.199051733921
INFO:root:current train perplexity6.326686382293701
INFO:root:current mean train loss 2339.804652673023
INFO:root:current train perplexity6.323975086212158
INFO:root:current mean train loss 2338.2871970527503
INFO:root:current train perplexity6.316422462463379
INFO:root:current mean train loss 2335.9673307670178
INFO:root:current train perplexity6.306422710418701

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.62s/it]
INFO:root:final mean train loss: 2334.8056236801876
INFO:root:final train perplexity: 6.305159091949463
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.56s/it]
INFO:root:eval mean loss: 2243.6044774698025
INFO:root:eval perplexity: 6.137979030609131
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.27s/it]
INFO:root:eval mean loss: 2648.050528451906
INFO:root:eval perplexity: 8.720254898071289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/9
  4%|â–         | 9/200 [55:39<19:10:33, 361.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2283.1642080453726
INFO:root:current train perplexity6.082703590393066
INFO:root:current mean train loss 2290.2627884714225
INFO:root:current train perplexity6.1247124671936035
INFO:root:current mean train loss 2297.6475515214224
INFO:root:current train perplexity6.133267879486084
INFO:root:current mean train loss 2298.1494383378463
INFO:root:current train perplexity6.120982646942139
INFO:root:current mean train loss 2302.4227408350043
INFO:root:current train perplexity6.144163131713867
INFO:root:current mean train loss 2310.773113084876
INFO:root:current train perplexity6.166443824768066
INFO:root:current mean train loss 2311.2577804846264
INFO:root:current train perplexity6.169310092926025
INFO:root:current mean train loss 2309.5970673256734
INFO:root:current train perplexity6.162937641143799
INFO:root:current mean train loss 2306.0645429584342
INFO:root:current train perplexity6.156015872955322
INFO:root:current mean train loss 2308.797956707097
INFO:root:current train perplexity6.159745693206787
INFO:root:current mean train loss 2306.09760148081
INFO:root:current train perplexity6.15557336807251
INFO:root:current mean train loss 2308.0369878345064
INFO:root:current train perplexity6.161904811859131
INFO:root:current mean train loss 2306.6860985314124
INFO:root:current train perplexity6.158997535705566
INFO:root:current mean train loss 2307.9151149050017
INFO:root:current train perplexity6.161877632141113
INFO:root:current mean train loss 2305.908995657256
INFO:root:current train perplexity6.157352447509766
INFO:root:current mean train loss 2306.5675721315993
INFO:root:current train perplexity6.158941745758057
INFO:root:current mean train loss 2305.1624868175886
INFO:root:current train perplexity6.153237342834473
INFO:root:current mean train loss 2305.1909325307906
INFO:root:current train perplexity6.1531982421875
INFO:root:current mean train loss 2305.521490702619
INFO:root:current train perplexity6.15438175201416
INFO:root:current mean train loss 2305.3400228531636
INFO:root:current train perplexity6.155238628387451

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:11<00:00, 311.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:11<00:00, 311.71s/it]
INFO:root:final mean train loss: 2304.5080240146717
INFO:root:final train perplexity: 6.156285762786865
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.47s/it]
INFO:root:eval mean loss: 2223.3265432804187
INFO:root:eval perplexity: 6.038139343261719
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.17s/it]
INFO:root:eval mean loss: 2627.574903122922
INFO:root:eval perplexity: 8.575447082519531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/10
  5%|â–Œ         | 10/200 [1:01:42<19:06:34, 362.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2294.495957526608
INFO:root:current train perplexity6.049484729766846
INFO:root:current mean train loss 2291.888330222587
INFO:root:current train perplexity6.063284873962402
INFO:root:current mean train loss 2283.817466764202
INFO:root:current train perplexity6.037606716156006
INFO:root:current mean train loss 2285.9866076627077
INFO:root:current train perplexity6.0332722663879395
INFO:root:current mean train loss 2285.4805452716882
INFO:root:current train perplexity6.043230056762695
INFO:root:current mean train loss 2282.9885672249147
INFO:root:current train perplexity6.0460429191589355
INFO:root:current mean train loss 2282.666090436402
INFO:root:current train perplexity6.036877632141113
INFO:root:current mean train loss 2280.8278378410982
INFO:root:current train perplexity6.034882545471191
INFO:root:current mean train loss 2281.9419261374874
INFO:root:current train perplexity6.03882360458374
INFO:root:current mean train loss 2281.918439772599
INFO:root:current train perplexity6.043747901916504
INFO:root:current mean train loss 2280.222993798965
INFO:root:current train perplexity6.045205593109131
INFO:root:current mean train loss 2278.354103107958
INFO:root:current train perplexity6.040099143981934
INFO:root:current mean train loss 2279.625707122827
INFO:root:current train perplexity6.039867401123047
INFO:root:current mean train loss 2280.298710423895
INFO:root:current train perplexity6.039030075073242
INFO:root:current mean train loss 2281.3437166778795
INFO:root:current train perplexity6.041057109832764
INFO:root:current mean train loss 2279.4435771409685
INFO:root:current train perplexity6.034091949462891
INFO:root:current mean train loss 2279.2872985876415
INFO:root:current train perplexity6.034368991851807
INFO:root:current mean train loss 2278.983768236711
INFO:root:current train perplexity6.03454065322876
INFO:root:current mean train loss 2278.670694072595
INFO:root:current train perplexity6.033592224121094
INFO:root:current mean train loss 2278.5406843178644
INFO:root:current train perplexity6.029608726501465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:14<00:00, 314.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:14<00:00, 314.45s/it]
INFO:root:final mean train loss: 2277.901842787719
INFO:root:final train perplexity: 6.0284528732299805
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.59s/it]
INFO:root:eval mean loss: 2209.516444862312
INFO:root:eval perplexity: 5.971075534820557
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.54s/it]
INFO:root:eval mean loss: 2619.003729637633
INFO:root:eval perplexity: 8.515543937683105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/11
  6%|â–Œ         | 11/200 [1:07:49<19:04:57, 363.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2262.395128826762
INFO:root:current train perplexity5.896618366241455
INFO:root:current mean train loss 2269.1604876774613
INFO:root:current train perplexity5.895460605621338
INFO:root:current mean train loss 2256.7143926020267
INFO:root:current train perplexity5.8952765464782715
INFO:root:current mean train loss 2262.661084427117
INFO:root:current train perplexity5.920278549194336
INFO:root:current mean train loss 2255.72286974746
INFO:root:current train perplexity5.910121440887451
INFO:root:current mean train loss 2256.0574603292316
INFO:root:current train perplexity5.918263912200928
INFO:root:current mean train loss 2254.928340989716
INFO:root:current train perplexity5.916759967803955
INFO:root:current mean train loss 2251.522870012822
INFO:root:current train perplexity5.906163215637207
INFO:root:current mean train loss 2250.0372310319817
INFO:root:current train perplexity5.904089450836182
INFO:root:current mean train loss 2249.3425729995324
INFO:root:current train perplexity5.907254695892334
INFO:root:current mean train loss 2250.740415457204
INFO:root:current train perplexity5.911130428314209
INFO:root:current mean train loss 2250.425195806545
INFO:root:current train perplexity5.912527561187744
INFO:root:current mean train loss 2252.3451895943695
INFO:root:current train perplexity5.915701389312744
INFO:root:current mean train loss 2254.9850900713327
INFO:root:current train perplexity5.921501159667969
INFO:root:current mean train loss 2254.95911449571
INFO:root:current train perplexity5.918815612792969
INFO:root:current mean train loss 2254.1743454229636
INFO:root:current train perplexity5.91596794128418
INFO:root:current mean train loss 2253.6398972118736
INFO:root:current train perplexity5.912699222564697
INFO:root:current mean train loss 2253.854678915436
INFO:root:current train perplexity5.915103912353516
INFO:root:current mean train loss 2254.6075283467203
INFO:root:current train perplexity5.91650390625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.78s/it]
INFO:root:final mean train loss: 2254.1045989297704
INFO:root:final train perplexity: 5.9163665771484375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.33s/it]
INFO:root:eval mean loss: 2188.811437295684
INFO:root:eval perplexity: 5.871923923492432
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.27s/it]
INFO:root:eval mean loss: 2602.7799630672375
INFO:root:eval perplexity: 8.403303146362305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/12
  6%|â–Œ         | 12/200 [1:13:46<18:53:10, 361.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2247.430704752604
INFO:root:current train perplexity6.086860656738281
INFO:root:current mean train loss 2215.992032245525
INFO:root:current train perplexity5.772339820861816
INFO:root:current mean train loss 2232.6978296740303
INFO:root:current train perplexity5.812930107116699
INFO:root:current mean train loss 2223.701171875
INFO:root:current train perplexity5.811966419219971
INFO:root:current mean train loss 2228.1205076307574
INFO:root:current train perplexity5.816067695617676
INFO:root:current mean train loss 2229.142092998649
INFO:root:current train perplexity5.81416654586792
INFO:root:current mean train loss 2226.5949889225744
INFO:root:current train perplexity5.805389881134033
INFO:root:current mean train loss 2229.065746063189
INFO:root:current train perplexity5.815630912780762
INFO:root:current mean train loss 2229.7072059184793
INFO:root:current train perplexity5.818243980407715
INFO:root:current mean train loss 2231.158299240163
INFO:root:current train perplexity5.816151142120361
INFO:root:current mean train loss 2229.080209079792
INFO:root:current train perplexity5.808682918548584
INFO:root:current mean train loss 2227.7896855787485
INFO:root:current train perplexity5.8049445152282715
INFO:root:current mean train loss 2230.7477034951685
INFO:root:current train perplexity5.813557147979736
INFO:root:current mean train loss 2232.0155112675675
INFO:root:current train perplexity5.813659191131592
INFO:root:current mean train loss 2232.0680605072
INFO:root:current train perplexity5.816075325012207
INFO:root:current mean train loss 2233.9181268810034
INFO:root:current train perplexity5.819736957550049
INFO:root:current mean train loss 2234.3219139589346
INFO:root:current train perplexity5.82050895690918
INFO:root:current mean train loss 2233.453748540604
INFO:root:current train perplexity5.82234525680542
INFO:root:current mean train loss 2233.1401781535983
INFO:root:current train perplexity5.820744037628174
INFO:root:current mean train loss 2232.9485646506955
INFO:root:current train perplexity5.81780481338501

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:12<00:00, 312.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:12<00:00, 312.21s/it]
INFO:root:final mean train loss: 2232.8186551631247
INFO:root:final train perplexity: 5.817875862121582
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.79s/it]
INFO:root:eval mean loss: 2181.16264786957
INFO:root:eval perplexity: 5.835712432861328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.30s/it]
INFO:root:eval mean loss: 2598.0863192943816
INFO:root:eval perplexity: 8.371109008789062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/13
  6%|â–‹         | 13/200 [1:19:49<18:47:51, 361.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2247.612762451172
INFO:root:current train perplexity5.804060935974121
INFO:root:current mean train loss 2215.8243194580077
INFO:root:current train perplexity5.73073148727417
INFO:root:current mean train loss 2213.608349609375
INFO:root:current train perplexity5.722200870513916
INFO:root:current mean train loss 2222.815741729736
INFO:root:current train perplexity5.747198104858398
INFO:root:current mean train loss 2220.8553472609747
INFO:root:current train perplexity5.740268230438232
INFO:root:current mean train loss 2221.568035888672
INFO:root:current train perplexity5.747975826263428
INFO:root:current mean train loss 2221.323600326046
INFO:root:current train perplexity5.742705345153809
INFO:root:current mean train loss 2219.826347351074
INFO:root:current train perplexity5.7381792068481445
INFO:root:current mean train loss 2219.300364573409
INFO:root:current train perplexity5.743350982666016
INFO:root:current mean train loss 2218.897377345873
INFO:root:current train perplexity5.741959095001221
INFO:root:current mean train loss 2217.0646304859833
INFO:root:current train perplexity5.737667083740234
INFO:root:current mean train loss 2217.764436885289
INFO:root:current train perplexity5.738504886627197
INFO:root:current mean train loss 2217.3435272717084
INFO:root:current train perplexity5.738781452178955
INFO:root:current mean train loss 2217.356182306463
INFO:root:current train perplexity5.737766742706299
INFO:root:current mean train loss 2217.1713646257426
INFO:root:current train perplexity5.740567684173584
INFO:root:current mean train loss 2216.22071139687
INFO:root:current train perplexity5.741325855255127
INFO:root:current mean train loss 2215.626318736135
INFO:root:current train perplexity5.738800525665283
INFO:root:current mean train loss 2214.3321013694585
INFO:root:current train perplexity5.732314586639404
INFO:root:current mean train loss 2214.5626706972225
INFO:root:current train perplexity5.731107711791992
INFO:root:current mean train loss 2214.270582771301
INFO:root:current train perplexity5.726692199707031

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.72s/it]
INFO:root:final mean train loss: 2212.904532797578
INFO:root:final train perplexity: 5.7272162437438965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.29s/it]
INFO:root:eval mean loss: 2165.4018693207004
INFO:root:eval perplexity: 5.761800765991211
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.56s/it]
INFO:root:eval mean loss: 2582.125044585965
INFO:root:eval perplexity: 8.262545585632324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/14
  7%|â–‹         | 14/200 [1:25:45<18:36:01, 360.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2154.951765730574
INFO:root:current train perplexity5.558658599853516
INFO:root:current mean train loss 2189.6078620409444
INFO:root:current train perplexity5.612203598022461
INFO:root:current mean train loss 2192.864299532733
INFO:root:current train perplexity5.629689693450928
INFO:root:current mean train loss 2186.965151280253
INFO:root:current train perplexity5.615163803100586
INFO:root:current mean train loss 2188.2102687669835
INFO:root:current train perplexity5.612321853637695
INFO:root:current mean train loss 2190.450616761959
INFO:root:current train perplexity5.616781234741211
INFO:root:current mean train loss 2193.995884294974
INFO:root:current train perplexity5.62748384475708
INFO:root:current mean train loss 2197.083330628021
INFO:root:current train perplexity5.635008335113525
INFO:root:current mean train loss 2198.982541903515
INFO:root:current train perplexity5.63784646987915
INFO:root:current mean train loss 2199.248236950332
INFO:root:current train perplexity5.641928195953369
INFO:root:current mean train loss 2197.3121211935722
INFO:root:current train perplexity5.640557765960693
INFO:root:current mean train loss 2195.3284907814905
INFO:root:current train perplexity5.6385087966918945
INFO:root:current mean train loss 2196.2015085798553
INFO:root:current train perplexity5.644631385803223
INFO:root:current mean train loss 2196.6603028804575
INFO:root:current train perplexity5.643680572509766
INFO:root:current mean train loss 2197.1644811238693
INFO:root:current train perplexity5.645028591156006
INFO:root:current mean train loss 2197.7874093486957
INFO:root:current train perplexity5.64677619934082
INFO:root:current mean train loss 2197.864708585279
INFO:root:current train perplexity5.646655082702637
INFO:root:current mean train loss 2196.7846447072225
INFO:root:current train perplexity5.647610664367676
INFO:root:current mean train loss 2195.7663562257585
INFO:root:current train perplexity5.644552707672119
INFO:root:current mean train loss 2195.9311366516963
INFO:root:current train perplexity5.649062633514404

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.79s/it]
INFO:root:final mean train loss: 2195.28796146641
INFO:root:final train perplexity: 5.648195743560791
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.52s/it]
INFO:root:eval mean loss: 2154.0696259627107
INFO:root:eval perplexity: 5.709234714508057
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.24s/it]
INFO:root:eval mean loss: 2575.2846402648493
INFO:root:eval perplexity: 8.216451644897461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/15
  8%|â–Š         | 15/200 [1:31:39<18:25:00, 358.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2176.811267994068
INFO:root:current train perplexity5.551674842834473
INFO:root:current mean train loss 2173.5351919198965
INFO:root:current train perplexity5.488295555114746
INFO:root:current mean train loss 2176.2379481998955
INFO:root:current train perplexity5.511300086975098
INFO:root:current mean train loss 2176.229909088652
INFO:root:current train perplexity5.533452033996582
INFO:root:current mean train loss 2180.9611133457806
INFO:root:current train perplexity5.546818733215332
INFO:root:current mean train loss 2181.6666059253016
INFO:root:current train perplexity5.559817790985107
INFO:root:current mean train loss 2181.0023324015674
INFO:root:current train perplexity5.5672478675842285
INFO:root:current mean train loss 2180.086018772277
INFO:root:current train perplexity5.564892292022705
INFO:root:current mean train loss 2177.70898165915
INFO:root:current train perplexity5.56275749206543
INFO:root:current mean train loss 2177.1150902962036
INFO:root:current train perplexity5.5646748542785645
INFO:root:current mean train loss 2177.5499140180264
INFO:root:current train perplexity5.567676544189453
INFO:root:current mean train loss 2179.7129919624
INFO:root:current train perplexity5.568397521972656
INFO:root:current mean train loss 2179.438736083595
INFO:root:current train perplexity5.571605682373047
INFO:root:current mean train loss 2178.3265339387926
INFO:root:current train perplexity5.571648597717285
INFO:root:current mean train loss 2178.336484381716
INFO:root:current train perplexity5.572020530700684
INFO:root:current mean train loss 2178.1809901331994
INFO:root:current train perplexity5.5717339515686035
INFO:root:current mean train loss 2178.87864528227
INFO:root:current train perplexity5.572781085968018
INFO:root:current mean train loss 2180.2530976211738
INFO:root:current train perplexity5.576652526855469
INFO:root:current mean train loss 2178.9176348672845
INFO:root:current train perplexity5.573524475097656
INFO:root:current mean train loss 2178.8685187785873
INFO:root:current train perplexity5.573496341705322

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.70s/it]
INFO:root:final mean train loss: 2178.5745218020165
INFO:root:final train perplexity: 5.574234485626221
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.14s/it]
INFO:root:eval mean loss: 2146.783354630707
INFO:root:eval perplexity: 5.675689697265625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.05s/it]
INFO:root:eval mean loss: 2570.626641023244
INFO:root:eval perplexity: 8.185213088989258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/16
  8%|â–Š         | 16/200 [1:37:31<18:13:23, 356.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2180.3355317451583
INFO:root:current train perplexity5.529959678649902
INFO:root:current mean train loss 2173.09053976494
INFO:root:current train perplexity5.529921531677246
INFO:root:current mean train loss 2163.742633889962
INFO:root:current train perplexity5.521718502044678
INFO:root:current mean train loss 2163.564442266994
INFO:root:current train perplexity5.518388748168945
INFO:root:current mean train loss 2166.761628298749
INFO:root:current train perplexity5.518649578094482
INFO:root:current mean train loss 2169.3555856895114
INFO:root:current train perplexity5.528258323669434
INFO:root:current mean train loss 2167.452980917008
INFO:root:current train perplexity5.522106647491455
INFO:root:current mean train loss 2165.159349097661
INFO:root:current train perplexity5.511828422546387
INFO:root:current mean train loss 2163.9046445861886
INFO:root:current train perplexity5.508588790893555
INFO:root:current mean train loss 2163.014149344667
INFO:root:current train perplexity5.510346412658691
INFO:root:current mean train loss 2161.8005805349485
INFO:root:current train perplexity5.509497165679932
INFO:root:current mean train loss 2163.2877266067
INFO:root:current train perplexity5.5116190910339355
INFO:root:current mean train loss 2162.231362139494
INFO:root:current train perplexity5.511475086212158
INFO:root:current mean train loss 2161.7522196140194
INFO:root:current train perplexity5.508236885070801
INFO:root:current mean train loss 2161.4153409603905
INFO:root:current train perplexity5.50588846206665
INFO:root:current mean train loss 2162.455446900113
INFO:root:current train perplexity5.508362770080566
INFO:root:current mean train loss 2162.254457210082
INFO:root:current train perplexity5.505161285400391
INFO:root:current mean train loss 2163.294353913749
INFO:root:current train perplexity5.506545543670654
INFO:root:current mean train loss 2162.244589107805
INFO:root:current train perplexity5.503475189208984
INFO:root:current mean train loss 2163.1100401624335
INFO:root:current train perplexity5.504077911376953

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:11<00:00, 311.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:11<00:00, 311.95s/it]
INFO:root:final mean train loss: 2162.528729244969
INFO:root:final train perplexity: 5.504138469696045
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 25.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 25.00s/it]
INFO:root:eval mean loss: 2136.844810107076
INFO:root:eval perplexity: 5.630253791809082
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.52s/it]
INFO:root:eval mean loss: 2561.5242045517507
INFO:root:eval perplexity: 8.124507904052734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/17
  8%|â–Š         | 17/200 [1:43:34<18:12:58, 358.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2158.827850341797
INFO:root:current train perplexity5.488317966461182
INFO:root:current mean train loss 2144.404992935505
INFO:root:current train perplexity5.454596042633057
INFO:root:current mean train loss 2152.1088010999893
INFO:root:current train perplexity5.449425220489502
INFO:root:current mean train loss 2156.6666435949583
INFO:root:current train perplexity5.459177494049072
INFO:root:current mean train loss 2156.055136758773
INFO:root:current train perplexity5.454232692718506
INFO:root:current mean train loss 2156.580269326969
INFO:root:current train perplexity5.449305057525635
INFO:root:current mean train loss 2151.796636182208
INFO:root:current train perplexity5.445490837097168
INFO:root:current mean train loss 2153.5265552501387
INFO:root:current train perplexity5.449713706970215
INFO:root:current mean train loss 2154.064882295626
INFO:root:current train perplexity5.450128078460693
INFO:root:current mean train loss 2151.5863866149657
INFO:root:current train perplexity5.443814277648926
INFO:root:current mean train loss 2148.2743753545424
INFO:root:current train perplexity5.437418460845947
INFO:root:current mean train loss 2146.931051954276
INFO:root:current train perplexity5.437555313110352
INFO:root:current mean train loss 2145.8643351489713
INFO:root:current train perplexity5.437010288238525
INFO:root:current mean train loss 2146.7136374701686
INFO:root:current train perplexity5.43980073928833
INFO:root:current mean train loss 2146.919890865203
INFO:root:current train perplexity5.440948486328125
INFO:root:current mean train loss 2147.245784269472
INFO:root:current train perplexity5.441254138946533
INFO:root:current mean train loss 2148.827971110412
INFO:root:current train perplexity5.444062232971191
INFO:root:current mean train loss 2148.9136756709227
INFO:root:current train perplexity5.442298412322998
INFO:root:current mean train loss 2148.499712345964
INFO:root:current train perplexity5.440847396850586

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.19s/it]
INFO:root:final mean train loss: 2148.0899336868265
INFO:root:final train perplexity: 5.441816806793213
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.88s/it]
INFO:root:eval mean loss: 2134.020919908023
INFO:root:eval perplexity: 5.6174116134643555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.95s/it]
INFO:root:eval mean loss: 2561.4194392211048
INFO:root:eval perplexity: 8.123807907104492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/18
  9%|â–‰         | 18/200 [1:49:29<18:04:16, 357.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2114.5934326171873
INFO:root:current train perplexity5.35189151763916
INFO:root:current mean train loss 2143.661726888021
INFO:root:current train perplexity5.370395183563232
INFO:root:current mean train loss 2136.6949969035823
INFO:root:current train perplexity5.372677326202393
INFO:root:current mean train loss 2134.2751797035094
INFO:root:current train perplexity5.348460674285889
INFO:root:current mean train loss 2131.477144820602
INFO:root:current train perplexity5.345399379730225
INFO:root:current mean train loss 2136.2308932162746
INFO:root:current train perplexity5.377584457397461
INFO:root:current mean train loss 2132.34178557593
INFO:root:current train perplexity5.372525691986084
INFO:root:current mean train loss 2132.768062250665
INFO:root:current train perplexity5.372513771057129
INFO:root:current mean train loss 2130.5618256562984
INFO:root:current train perplexity5.371640205383301
INFO:root:current mean train loss 2130.2860116863776
INFO:root:current train perplexity5.370169162750244
INFO:root:current mean train loss 2132.1124004003423
INFO:root:current train perplexity5.367600440979004
INFO:root:current mean train loss 2133.1492114589223
INFO:root:current train perplexity5.36988639831543
INFO:root:current mean train loss 2133.6272513615145
INFO:root:current train perplexity5.371013164520264
INFO:root:current mean train loss 2133.2153157552084
INFO:root:current train perplexity5.373544692993164
INFO:root:current mean train loss 2134.4923224289646
INFO:root:current train perplexity5.3716139793396
INFO:root:current mean train loss 2135.9887411428053
INFO:root:current train perplexity5.374701976776123
INFO:root:current mean train loss 2136.7041818018643
INFO:root:current train perplexity5.379054546356201
INFO:root:current mean train loss 2136.8772680735656
INFO:root:current train perplexity5.378767967224121
INFO:root:current mean train loss 2136.2897773383397
INFO:root:current train perplexity5.380983352661133
INFO:root:current mean train loss 2137.100638097728
INFO:root:current train perplexity5.385336399078369

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.63s/it]
INFO:root:final mean train loss: 2134.8201436453014
INFO:root:final train perplexity: 5.385161876678467
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.75s/it]
INFO:root:eval mean loss: 2127.447101565963
INFO:root:eval perplexity: 5.587624549865723
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.94s/it]
INFO:root:eval mean loss: 2556.352536032386
INFO:root:eval perplexity: 8.090214729309082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/19
 10%|â–‰         | 19/200 [1:55:21<17:52:47, 355.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2055.2629228071733
INFO:root:current train perplexity5.2134175300598145
INFO:root:current mean train loss 2105.482343830046
INFO:root:current train perplexity5.297257423400879
INFO:root:current mean train loss 2111.4505131352057
INFO:root:current train perplexity5.323566913604736
INFO:root:current mean train loss 2126.833929026349
INFO:root:current train perplexity5.339430332183838
INFO:root:current mean train loss 2130.681273546264
INFO:root:current train perplexity5.350107192993164
INFO:root:current mean train loss 2126.219151756316
INFO:root:current train perplexity5.346238613128662
INFO:root:current mean train loss 2122.161184819948
INFO:root:current train perplexity5.340183258056641
INFO:root:current mean train loss 2119.2191255099224
INFO:root:current train perplexity5.334300518035889
INFO:root:current mean train loss 2120.5357070514465
INFO:root:current train perplexity5.330029487609863
INFO:root:current mean train loss 2119.8620428056365
INFO:root:current train perplexity5.326375961303711
INFO:root:current mean train loss 2117.6455197567575
INFO:root:current train perplexity5.320454120635986
INFO:root:current mean train loss 2116.69798858153
INFO:root:current train perplexity5.318945407867432
INFO:root:current mean train loss 2118.232480612597
INFO:root:current train perplexity5.3204755783081055
INFO:root:current mean train loss 2118.9871954521145
INFO:root:current train perplexity5.322554111480713
INFO:root:current mean train loss 2120.3549358298174
INFO:root:current train perplexity5.326379299163818
INFO:root:current mean train loss 2120.667120273104
INFO:root:current train perplexity5.326119422912598
INFO:root:current mean train loss 2121.200764572576
INFO:root:current train perplexity5.328052997589111
INFO:root:current mean train loss 2121.465691436874
INFO:root:current train perplexity5.3306708335876465
INFO:root:current mean train loss 2122.3116091279117
INFO:root:current train perplexity5.330099582672119
INFO:root:current mean train loss 2123.364731676497
INFO:root:current train perplexity5.332786560058594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.94s/it]
INFO:root:final mean train loss: 2122.481682158454
INFO:root:final train perplexity: 5.333014965057373
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.01s/it]
INFO:root:eval mean loss: 2116.280251360954
INFO:root:eval perplexity: 5.537390232086182
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.94s/it]
INFO:root:eval mean loss: 2545.258818065021
INFO:root:eval perplexity: 8.017146110534668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/20
 10%|â–ˆ         | 20/200 [2:01:12<17:42:41, 354.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2106.426989433093
INFO:root:current train perplexity5.1879496574401855
INFO:root:current mean train loss 2111.133011852237
INFO:root:current train perplexity5.2245306968688965
INFO:root:current mean train loss 2107.3499423868984
INFO:root:current train perplexity5.2242817878723145
INFO:root:current mean train loss 2107.632154256545
INFO:root:current train perplexity5.249230861663818
INFO:root:current mean train loss 2106.18505859375
INFO:root:current train perplexity5.256461143493652
INFO:root:current mean train loss 2108.6097538935674
INFO:root:current train perplexity5.262910842895508
INFO:root:current mean train loss 2113.379489856893
INFO:root:current train perplexity5.27044153213501
INFO:root:current mean train loss 2113.017007417382
INFO:root:current train perplexity5.2726240158081055
INFO:root:current mean train loss 2110.6313296148687
INFO:root:current train perplexity5.266711711883545
INFO:root:current mean train loss 2112.0588200805796
INFO:root:current train perplexity5.2745208740234375
INFO:root:current mean train loss 2113.7020880485293
INFO:root:current train perplexity5.2792229652404785
INFO:root:current mean train loss 2116.1244111902574
INFO:root:current train perplexity5.285503387451172
INFO:root:current mean train loss 2115.2723337439784
INFO:root:current train perplexity5.284015655517578
INFO:root:current mean train loss 2114.9054595058406
INFO:root:current train perplexity5.286469459533691
INFO:root:current mean train loss 2114.526590035805
INFO:root:current train perplexity5.292051792144775
INFO:root:current mean train loss 2113.9312594229714
INFO:root:current train perplexity5.292001247406006
INFO:root:current mean train loss 2114.8790991493956
INFO:root:current train perplexity5.294282913208008
INFO:root:current mean train loss 2113.661245406394
INFO:root:current train perplexity5.288204669952393
INFO:root:current mean train loss 2112.358914996049
INFO:root:current train perplexity5.284824371337891
INFO:root:current mean train loss 2111.4783900921466
INFO:root:current train perplexity5.282260417938232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:11<00:00, 311.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:11<00:00, 311.06s/it]
INFO:root:final mean train loss: 2109.9486111685655
INFO:root:final train perplexity: 5.2805609703063965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.24s/it]
INFO:root:eval mean loss: 2112.635143956394
INFO:root:eval perplexity: 5.521090507507324
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.26s/it]
INFO:root:eval mean loss: 2546.5418064847904
INFO:root:eval perplexity: 8.02556324005127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/21
 10%|â–ˆ         | 21/200 [2:07:13<17:43:26, 356.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2070.4344896589005
INFO:root:current train perplexity5.2071380615234375
INFO:root:current mean train loss 2089.328525641026
INFO:root:current train perplexity5.215935230255127
INFO:root:current mean train loss 2100.316987514496
INFO:root:current train perplexity5.2239766120910645
INFO:root:current mean train loss 2094.3976783323824
INFO:root:current train perplexity5.198878288269043
INFO:root:current mean train loss 2091.350884153132
INFO:root:current train perplexity5.202633857727051
INFO:root:current mean train loss 2097.0909952945844
INFO:root:current train perplexity5.215409755706787
INFO:root:current mean train loss 2100.038607341487
INFO:root:current train perplexity5.224915981292725
INFO:root:current mean train loss 2103.4854042012857
INFO:root:current train perplexity5.222001075744629
INFO:root:current mean train loss 2104.245987081082
INFO:root:current train perplexity5.224408149719238
INFO:root:current mean train loss 2104.4490420289617
INFO:root:current train perplexity5.226991176605225
INFO:root:current mean train loss 2102.744766466545
INFO:root:current train perplexity5.230698585510254
INFO:root:current mean train loss 2103.8276598445273
INFO:root:current train perplexity5.23500394821167
INFO:root:current mean train loss 2103.7464845499417
INFO:root:current train perplexity5.2365288734436035
INFO:root:current mean train loss 2102.0354335188513
INFO:root:current train perplexity5.234809875488281
INFO:root:current mean train loss 2102.413296039288
INFO:root:current train perplexity5.2364606857299805
INFO:root:current mean train loss 2102.1873770667225
INFO:root:current train perplexity5.236584186553955
INFO:root:current mean train loss 2099.579386466943
INFO:root:current train perplexity5.230907917022705
INFO:root:current mean train loss 2099.8229403484925
INFO:root:current train perplexity5.231906890869141
INFO:root:current mean train loss 2098.6633743417674
INFO:root:current train perplexity5.231955051422119
INFO:root:current mean train loss 2099.032678896664
INFO:root:current train perplexity5.234292507171631

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:10<00:00, 310.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:10<00:00, 310.16s/it]
INFO:root:final mean train loss: 2098.6094913453812
INFO:root:final train perplexity: 5.233549118041992
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.19s/it]
INFO:root:eval mean loss: 2107.744827595163
INFO:root:eval perplexity: 5.499297618865967
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.96s/it]
INFO:root:eval mean loss: 2542.0638778361867
INFO:root:eval perplexity: 7.9962263107299805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/22
 11%|â–ˆ         | 22/200 [2:13:14<17:41:01, 357.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2080.205165079195
INFO:root:current train perplexity5.178523063659668
INFO:root:current mean train loss 2080.49314712789
INFO:root:current train perplexity5.179592609405518
INFO:root:current mean train loss 2086.0235340831046
INFO:root:current train perplexity5.168736934661865
INFO:root:current mean train loss 2090.6289677760556
INFO:root:current train perplexity5.1817169189453125
INFO:root:current mean train loss 2085.8507012978166
INFO:root:current train perplexity5.171145439147949
INFO:root:current mean train loss 2083.6586375078396
INFO:root:current train perplexity5.159924030303955
INFO:root:current mean train loss 2086.163192046167
INFO:root:current train perplexity5.165146350860596
INFO:root:current mean train loss 2084.5552354741067
INFO:root:current train perplexity5.1649603843688965
INFO:root:current mean train loss 2084.9883301899877
INFO:root:current train perplexity5.169342041015625
INFO:root:current mean train loss 2083.3260585867242
INFO:root:current train perplexity5.169503211975098
INFO:root:current mean train loss 2083.9138091443747
INFO:root:current train perplexity5.1688995361328125
INFO:root:current mean train loss 2083.665638382986
INFO:root:current train perplexity5.170302867889404
INFO:root:current mean train loss 2085.660519200615
INFO:root:current train perplexity5.175764560699463
INFO:root:current mean train loss 2086.3058515689013
INFO:root:current train perplexity5.175309658050537
INFO:root:current mean train loss 2086.7505244962713
INFO:root:current train perplexity5.175445079803467
INFO:root:current mean train loss 2087.6653186679264
INFO:root:current train perplexity5.1802897453308105
INFO:root:current mean train loss 2088.904340289128
INFO:root:current train perplexity5.186211109161377
INFO:root:current mean train loss 2087.9944647688417
INFO:root:current train perplexity5.185264587402344
INFO:root:current mean train loss 2087.97257048143
INFO:root:current train perplexity5.185054779052734
INFO:root:current mean train loss 2088.409858220251
INFO:root:current train perplexity5.189228057861328

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.90s/it]
INFO:root:final mean train loss: 2087.439981142199
INFO:root:final train perplexity: 5.187649726867676
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.33s/it]
INFO:root:eval mean loss: 2102.9874025168992
INFO:root:eval perplexity: 5.478178977966309
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.40s/it]
INFO:root:eval mean loss: 2540.633419388575
INFO:root:eval perplexity: 7.986878871917725
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/23
 12%|â–ˆâ–        | 23/200 [2:19:06<17:30:38, 356.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2094.467041015625
INFO:root:current train perplexity5.164401531219482
INFO:root:current mean train loss 2085.2318834806742
INFO:root:current train perplexity5.150964736938477
INFO:root:current mean train loss 2077.274097942484
INFO:root:current train perplexity5.1319899559021
INFO:root:current mean train loss 2077.979332870092
INFO:root:current train perplexity5.12842321395874
INFO:root:current mean train loss 2078.577695262675
INFO:root:current train perplexity5.130462646484375
INFO:root:current mean train loss 2076.889158087262
INFO:root:current train perplexity5.131401062011719
INFO:root:current mean train loss 2078.2038450379305
INFO:root:current train perplexity5.139030933380127
INFO:root:current mean train loss 2078.872937629796
INFO:root:current train perplexity5.146812915802002
INFO:root:current mean train loss 2078.594481187456
INFO:root:current train perplexity5.147961139678955
INFO:root:current mean train loss 2079.2823155875158
INFO:root:current train perplexity5.146883010864258
INFO:root:current mean train loss 2078.0045215291716
INFO:root:current train perplexity5.14692497253418
INFO:root:current mean train loss 2077.0613362288273
INFO:root:current train perplexity5.142972469329834
INFO:root:current mean train loss 2078.006915898286
INFO:root:current train perplexity5.143060684204102
INFO:root:current mean train loss 2077.7335039975833
INFO:root:current train perplexity5.140600204467773
INFO:root:current mean train loss 2078.7880978987523
INFO:root:current train perplexity5.147268772125244
INFO:root:current mean train loss 2077.7127615682734
INFO:root:current train perplexity5.146425724029541
INFO:root:current mean train loss 2077.2164381760817
INFO:root:current train perplexity5.145140647888184
INFO:root:current mean train loss 2077.3535267409
INFO:root:current train perplexity5.144842147827148
INFO:root:current mean train loss 2077.735792307374
INFO:root:current train perplexity5.145560264587402

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.54s/it]
INFO:root:final mean train loss: 2077.0433260965274
INFO:root:final train perplexity: 5.145287036895752
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.78s/it]
INFO:root:eval mean loss: 2094.8564535370956
INFO:root:eval perplexity: 5.442273139953613
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.13s/it]
INFO:root:eval mean loss: 2533.7556784338985
INFO:root:eval perplexity: 7.942078590393066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/24
 12%|â–ˆâ–        | 24/200 [2:25:02<17:24:08, 355.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2090.8690359933034
INFO:root:current train perplexity4.883584976196289
INFO:root:current mean train loss 2059.02158591012
INFO:root:current train perplexity5.086874485015869
INFO:root:current mean train loss 2053.578014134209
INFO:root:current train perplexity5.0742974281311035
INFO:root:current mean train loss 2056.224637606245
INFO:root:current train perplexity5.08787727355957
INFO:root:current mean train loss 2060.2545019051367
INFO:root:current train perplexity5.086421489715576
INFO:root:current mean train loss 2067.075618826661
INFO:root:current train perplexity5.094001770019531
INFO:root:current mean train loss 2064.3256864092104
INFO:root:current train perplexity5.085966110229492
INFO:root:current mean train loss 2060.4426274711036
INFO:root:current train perplexity5.078888893127441
INFO:root:current mean train loss 2064.0069902271143
INFO:root:current train perplexity5.086747646331787
INFO:root:current mean train loss 2063.6194863787296
INFO:root:current train perplexity5.087459087371826
INFO:root:current mean train loss 2062.7337142201854
INFO:root:current train perplexity5.091953754425049
INFO:root:current mean train loss 2061.6821812851103
INFO:root:current train perplexity5.088980674743652
INFO:root:current mean train loss 2062.832020934199
INFO:root:current train perplexity5.090424060821533
INFO:root:current mean train loss 2061.708310513252
INFO:root:current train perplexity5.088338375091553
INFO:root:current mean train loss 2063.473674977512
INFO:root:current train perplexity5.093143939971924
INFO:root:current mean train loss 2064.5423259975582
INFO:root:current train perplexity5.0954766273498535
INFO:root:current mean train loss 2064.5934853497392
INFO:root:current train perplexity5.095724105834961
INFO:root:current mean train loss 2065.1660455168517
INFO:root:current train perplexity5.09339714050293
INFO:root:current mean train loss 2065.4354544609505
INFO:root:current train perplexity5.096941947937012
INFO:root:current mean train loss 2066.3538932300203
INFO:root:current train perplexity5.099183559417725

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.52s/it]
INFO:root:final mean train loss: 2065.9193366392656
INFO:root:final train perplexity: 5.100345134735107
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.91s/it]
INFO:root:eval mean loss: 2093.2937518180684
INFO:root:eval perplexity: 5.435399055480957
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.18s/it]
INFO:root:eval mean loss: 2532.106118060173
INFO:root:eval perplexity: 7.931370258331299
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/25
 12%|â–ˆâ–Ž        | 25/200 [2:30:53<17:13:34, 354.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2032.1941172281902
INFO:root:current train perplexity5.046189308166504
INFO:root:current mean train loss 2043.4586093041205
INFO:root:current train perplexity4.969963550567627
INFO:root:current mean train loss 2036.9216630118233
INFO:root:current train perplexity4.969686508178711
INFO:root:current mean train loss 2044.4903662410784
INFO:root:current train perplexity4.993451118469238
INFO:root:current mean train loss 2049.130416294314
INFO:root:current train perplexity5.018444538116455
INFO:root:current mean train loss 2047.4889004539898
INFO:root:current train perplexity5.017881870269775
INFO:root:current mean train loss 2048.0564657358022
INFO:root:current train perplexity5.025082111358643
INFO:root:current mean train loss 2050.381954129888
INFO:root:current train perplexity5.034926891326904
INFO:root:current mean train loss 2049.610554519209
INFO:root:current train perplexity5.033824443817139
INFO:root:current mean train loss 2052.0254927465926
INFO:root:current train perplexity5.0416107177734375
INFO:root:current mean train loss 2053.226658463478
INFO:root:current train perplexity5.051016807556152
INFO:root:current mean train loss 2054.1869555707503
INFO:root:current train perplexity5.053237438201904
INFO:root:current mean train loss 2054.4478399737986
INFO:root:current train perplexity5.053740978240967
INFO:root:current mean train loss 2056.1829863487774
INFO:root:current train perplexity5.0597124099731445
INFO:root:current mean train loss 2056.5279485295328
INFO:root:current train perplexity5.060540199279785
INFO:root:current mean train loss 2056.3806868425504
INFO:root:current train perplexity5.060163497924805
INFO:root:current mean train loss 2056.134625890572
INFO:root:current train perplexity5.06179141998291
INFO:root:current mean train loss 2056.279529686594
INFO:root:current train perplexity5.059532165527344
INFO:root:current mean train loss 2055.995408911454
INFO:root:current train perplexity5.057112693786621
INFO:root:current mean train loss 2057.796215794934
INFO:root:current train perplexity5.063146114349365

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:12<00:00, 312.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:12<00:00, 312.72s/it]
INFO:root:final mean train loss: 2057.1200206023664
INFO:root:final train perplexity: 5.065073490142822
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.68s/it]
INFO:root:eval mean loss: 2089.2893174624614
INFO:root:eval perplexity: 5.417824745178223
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.78s/it]
INFO:root:eval mean loss: 2531.3673749342033
INFO:root:eval perplexity: 7.926578044891357
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/26
 13%|â–ˆâ–Ž        | 26/200 [2:36:56<17:15:25, 357.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2066.015175423971
INFO:root:current train perplexity5.045282363891602
INFO:root:current mean train loss 2060.295566856438
INFO:root:current train perplexity5.043979167938232
INFO:root:current mean train loss 2055.255362482981
INFO:root:current train perplexity5.030975818634033
INFO:root:current mean train loss 2058.1157924618537
INFO:root:current train perplexity5.030710220336914
INFO:root:current mean train loss 2060.3997274039825
INFO:root:current train perplexity5.029404640197754
INFO:root:current mean train loss 2053.246089011596
INFO:root:current train perplexity5.027553558349609
INFO:root:current mean train loss 2050.632511609058
INFO:root:current train perplexity5.017887115478516
INFO:root:current mean train loss 2049.239787937015
INFO:root:current train perplexity5.016202449798584
INFO:root:current mean train loss 2048.5366475108685
INFO:root:current train perplexity5.013911724090576
INFO:root:current mean train loss 2047.8179726676658
INFO:root:current train perplexity5.013829708099365
INFO:root:current mean train loss 2049.2108257487916
INFO:root:current train perplexity5.019876956939697
INFO:root:current mean train loss 2049.178875694977
INFO:root:current train perplexity5.019412994384766
INFO:root:current mean train loss 2049.2149718205455
INFO:root:current train perplexity5.024414539337158
INFO:root:current mean train loss 2048.8699790049986
INFO:root:current train perplexity5.026102066040039
INFO:root:current mean train loss 2050.1113951323678
INFO:root:current train perplexity5.028805732727051
INFO:root:current mean train loss 2049.9366978689263
INFO:root:current train perplexity5.0279364585876465
INFO:root:current mean train loss 2048.573720798341
INFO:root:current train perplexity5.026120662689209
INFO:root:current mean train loss 2049.4958928703645
INFO:root:current train perplexity5.027196407318115
INFO:root:current mean train loss 2049.6934790582777
INFO:root:current train perplexity5.029269695281982
INFO:root:current mean train loss 2049.3051733285233
INFO:root:current train perplexity5.029148101806641

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.83s/it]
INFO:root:final mean train loss: 2047.958592740442
INFO:root:final train perplexity: 5.028609275817871
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.80s/it]
INFO:root:eval mean loss: 2087.233805771415
INFO:root:eval perplexity: 5.408827781677246
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.86s/it]
INFO:root:eval mean loss: 2528.3032802284188
INFO:root:eval perplexity: 7.906744480133057
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/27
 14%|â–ˆâ–Ž        | 27/200 [2:42:50<17:07:19, 356.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2033.8054220265356
INFO:root:current train perplexity4.91165828704834
INFO:root:current mean train loss 2033.2013557530656
INFO:root:current train perplexity4.920499801635742
INFO:root:current mean train loss 2043.2049891745398
INFO:root:current train perplexity4.952378273010254
INFO:root:current mean train loss 2042.9715934199328
INFO:root:current train perplexity4.959524154663086
INFO:root:current mean train loss 2044.4759833323383
INFO:root:current train perplexity4.9667277336120605
INFO:root:current mean train loss 2046.1825528708837
INFO:root:current train perplexity4.98180627822876
INFO:root:current mean train loss 2042.3141412705997
INFO:root:current train perplexity4.978567600250244
INFO:root:current mean train loss 2040.1480838503876
INFO:root:current train perplexity4.977520942687988
INFO:root:current mean train loss 2037.7291692275824
INFO:root:current train perplexity4.976416110992432
INFO:root:current mean train loss 2038.8777863377072
INFO:root:current train perplexity4.98326301574707
INFO:root:current mean train loss 2037.9779559245408
INFO:root:current train perplexity4.984457492828369
INFO:root:current mean train loss 2039.051005467232
INFO:root:current train perplexity4.987622261047363
INFO:root:current mean train loss 2038.8399535938743
INFO:root:current train perplexity4.991932392120361
INFO:root:current mean train loss 2039.0774869623872
INFO:root:current train perplexity4.99459171295166
INFO:root:current mean train loss 2038.3692151397997
INFO:root:current train perplexity4.9929022789001465
INFO:root:current mean train loss 2038.6815357918306
INFO:root:current train perplexity4.992855548858643
INFO:root:current mean train loss 2039.3008098165146
INFO:root:current train perplexity4.993923187255859
INFO:root:current mean train loss 2038.635890921635
INFO:root:current train perplexity4.99159574508667
INFO:root:current mean train loss 2039.3328119612613
INFO:root:current train perplexity4.991610050201416
INFO:root:current mean train loss 2038.7055277527293
INFO:root:current train perplexity4.989663124084473

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:07<00:00, 307.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:07<00:00, 307.53s/it]
INFO:root:final mean train loss: 2038.2697745288074
INFO:root:final train perplexity: 4.990330696105957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.61s/it]
INFO:root:eval mean loss: 2081.2734457245956
INFO:root:eval perplexity: 5.382816791534424
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.96s/it]
INFO:root:eval mean loss: 2526.106308091617
INFO:root:eval perplexity: 7.892550945281982
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/28
 14%|â–ˆâ–        | 28/200 [2:48:48<17:02:05, 356.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2030.4934261067708
INFO:root:current train perplexity4.9767537117004395
INFO:root:current mean train loss 2024.2368819754465
INFO:root:current train perplexity4.95449686050415
INFO:root:current mean train loss 2020.7730078125
INFO:root:current train perplexity4.932804584503174
INFO:root:current mean train loss 2026.7313990885416
INFO:root:current train perplexity4.948635101318359
INFO:root:current mean train loss 2027.7105013877467
INFO:root:current train perplexity4.958681106567383
INFO:root:current mean train loss 2023.3639780061142
INFO:root:current train perplexity4.953658103942871
INFO:root:current mean train loss 2026.6931334997107
INFO:root:current train perplexity4.964202880859375
INFO:root:current mean train loss 2026.8184656943045
INFO:root:current train perplexity4.966710090637207
INFO:root:current mean train loss 2026.291072544643
INFO:root:current train perplexity4.955306053161621
INFO:root:current mean train loss 2028.214739458133
INFO:root:current train perplexity4.95809268951416
INFO:root:current mean train loss 2029.6685851199127
INFO:root:current train perplexity4.960819721221924
INFO:root:current mean train loss 2028.5467918882978
INFO:root:current train perplexity4.956834316253662
INFO:root:current mean train loss 2026.625575022978
INFO:root:current train perplexity4.956177234649658
INFO:root:current mean train loss 2027.1937231889206
INFO:root:current train perplexity4.953726768493652
INFO:root:current mean train loss 2029.2647754733846
INFO:root:current train perplexity4.957380771636963
INFO:root:current mean train loss 2028.9628370690725
INFO:root:current train perplexity4.955514907836914
INFO:root:current mean train loss 2028.8484436946128
INFO:root:current train perplexity4.958336353302002
INFO:root:current mean train loss 2029.5892157240316
INFO:root:current train perplexity4.956451416015625
INFO:root:current mean train loss 2029.8647646484376
INFO:root:current train perplexity4.9554853439331055
INFO:root:current mean train loss 2030.400222075257
INFO:root:current train perplexity4.957005500793457

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.64s/it]
INFO:root:final mean train loss: 2030.0071185829058
INFO:root:final train perplexity: 4.957917213439941
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.12s/it]
INFO:root:eval mean loss: 2080.7833619895555
INFO:root:eval perplexity: 5.3806843757629395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.91s/it]
INFO:root:eval mean loss: 2526.642870314578
INFO:root:eval perplexity: 7.8960161209106445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/29
 14%|â–ˆâ–        | 29/200 [2:54:36<16:49:29, 354.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2025.9274437945821
INFO:root:current train perplexity4.877270698547363
INFO:root:current mean train loss 2024.76118850708
INFO:root:current train perplexity4.897523403167725
INFO:root:current mean train loss 2025.4925532928885
INFO:root:current train perplexity4.901470184326172
INFO:root:current mean train loss 2025.8055631676498
INFO:root:current train perplexity4.903059959411621
INFO:root:current mean train loss 2023.7507934570312
INFO:root:current train perplexity4.913697719573975
INFO:root:current mean train loss 2026.3089618167362
INFO:root:current train perplexity4.920636177062988
INFO:root:current mean train loss 2027.6501486012012
INFO:root:current train perplexity4.92427396774292
INFO:root:current mean train loss 2023.5009369513002
INFO:root:current train perplexity4.919053077697754
INFO:root:current mean train loss 2022.659403163756
INFO:root:current train perplexity4.922204971313477
INFO:root:current mean train loss 2023.2677828881049
INFO:root:current train perplexity4.925247669219971
INFO:root:current mean train loss 2023.9200187934623
INFO:root:current train perplexity4.92864465713501
INFO:root:current mean train loss 2023.5120946896957
INFO:root:current train perplexity4.92731237411499
INFO:root:current mean train loss 2024.8473783794202
INFO:root:current train perplexity4.929272174835205
INFO:root:current mean train loss 2024.1661973273617
INFO:root:current train perplexity4.924567699432373
INFO:root:current mean train loss 2024.675671288539
INFO:root:current train perplexity4.9252424240112305
INFO:root:current mean train loss 2023.8566827055197
INFO:root:current train perplexity4.92461633682251
INFO:root:current mean train loss 2022.6534135245827
INFO:root:current train perplexity4.923586845397949
INFO:root:current mean train loss 2022.2066547530037
INFO:root:current train perplexity4.92532205581665
INFO:root:current mean train loss 2022.422014684052
INFO:root:current train perplexity4.9265570640563965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:09<00:00, 309.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:09<00:00, 309.02s/it]
INFO:root:final mean train loss: 2021.50870312697
INFO:root:final train perplexity: 4.924798488616943
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.47s/it]
INFO:root:eval mean loss: 2079.3175918903758
INFO:root:eval perplexity: 5.374309062957764
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.65s/it]
INFO:root:eval mean loss: 2526.156082045102
INFO:root:eval perplexity: 7.892870903015137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/30
 15%|â–ˆâ–Œ        | 30/200 [3:00:37<16:48:41, 356.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1929.1660834418403
INFO:root:current train perplexity4.774759769439697
INFO:root:current mean train loss 2012.045195133314
INFO:root:current train perplexity4.863131046295166
INFO:root:current mean train loss 2014.0638048089863
INFO:root:current train perplexity4.884681224822998
INFO:root:current mean train loss 2021.8146700072057
INFO:root:current train perplexity4.891810417175293
INFO:root:current mean train loss 2014.2644851796492
INFO:root:current train perplexity4.880945682525635
INFO:root:current mean train loss 2018.3431612325792
INFO:root:current train perplexity4.897683143615723
INFO:root:current mean train loss 2015.9316863262006
INFO:root:current train perplexity4.892678260803223
INFO:root:current mean train loss 2018.0200632630686
INFO:root:current train perplexity4.897262096405029
INFO:root:current mean train loss 2016.8747501255407
INFO:root:current train perplexity4.900294303894043
INFO:root:current mean train loss 2017.2983531385364
INFO:root:current train perplexity4.898837089538574
INFO:root:current mean train loss 2017.6971107687066
INFO:root:current train perplexity4.899440288543701
INFO:root:current mean train loss 2018.6448703831225
INFO:root:current train perplexity4.902193069458008
INFO:root:current mean train loss 2018.3775112761064
INFO:root:current train perplexity4.904239654541016
INFO:root:current mean train loss 2016.6274774025378
INFO:root:current train perplexity4.900543212890625
INFO:root:current mean train loss 2014.6854098166364
INFO:root:current train perplexity4.894235134124756
INFO:root:current mean train loss 2014.942043054175
INFO:root:current train perplexity4.895394325256348
INFO:root:current mean train loss 2016.0395815833301
INFO:root:current train perplexity4.8984222412109375
INFO:root:current mean train loss 2014.886800892106
INFO:root:current train perplexity4.897323131561279
INFO:root:current mean train loss 2014.3698976093922
INFO:root:current train perplexity4.8951616287231445
INFO:root:current mean train loss 2013.6574122577265
INFO:root:current train perplexity4.89374303817749

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.57s/it]
INFO:root:final mean train loss: 2013.928156450188
INFO:root:final train perplexity: 4.895443439483643
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.78s/it]
INFO:root:eval mean loss: 2071.2526781880265
INFO:root:eval perplexity: 5.339369773864746
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.03s/it]
INFO:root:eval mean loss: 2520.142931349734
INFO:root:eval perplexity: 7.854150295257568
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/31
 16%|â–ˆâ–Œ        | 31/200 [3:06:28<16:38:55, 354.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1966.9860276442307
INFO:root:current train perplexity4.786884784698486
INFO:root:current mean train loss 1969.8734692770338
INFO:root:current train perplexity4.78848123550415
INFO:root:current mean train loss 1978.1947237538025
INFO:root:current train perplexity4.807529926300049
INFO:root:current mean train loss 1990.3627207001293
INFO:root:current train perplexity4.828295707702637
INFO:root:current mean train loss 1993.0529011471172
INFO:root:current train perplexity4.836754322052002
INFO:root:current mean train loss 1994.4900563751337
INFO:root:current train perplexity4.839398384094238
INFO:root:current mean train loss 1995.4892361674447
INFO:root:current train perplexity4.842118263244629
INFO:root:current mean train loss 1996.4552825843664
INFO:root:current train perplexity4.844609260559082
INFO:root:current mean train loss 1999.9544088072696
INFO:root:current train perplexity4.851494312286377
INFO:root:current mean train loss 2000.1724372352946
INFO:root:current train perplexity4.855544567108154
INFO:root:current mean train loss 2001.164463571173
INFO:root:current train perplexity4.8543500900268555
INFO:root:current mean train loss 2000.968819599592
INFO:root:current train perplexity4.8560099601745605
INFO:root:current mean train loss 2001.1343826866462
INFO:root:current train perplexity4.858743190765381
INFO:root:current mean train loss 2003.3111871457568
INFO:root:current train perplexity4.860295295715332
INFO:root:current mean train loss 2004.8030107880709
INFO:root:current train perplexity4.859204292297363
INFO:root:current mean train loss 2004.3741610265809
INFO:root:current train perplexity4.858105659484863
INFO:root:current mean train loss 2005.0253253857002
INFO:root:current train perplexity4.8586297035217285
INFO:root:current mean train loss 2005.0774248991752
INFO:root:current train perplexity4.861008167266846
INFO:root:current mean train loss 2005.9816666568618
INFO:root:current train perplexity4.860885143280029
INFO:root:current mean train loss 2006.0376057689186
INFO:root:current train perplexity4.862725734710693

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.54s/it]
INFO:root:final mean train loss: 2005.5118406971958
INFO:root:final train perplexity: 4.8630571365356445
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.23s/it]
INFO:root:eval mean loss: 2072.647168747922
INFO:root:eval perplexity: 5.345394134521484
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.97s/it]
INFO:root:eval mean loss: 2523.2699264634584
INFO:root:eval perplexity: 7.874262809753418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/32
 16%|â–ˆâ–Œ        | 32/200 [3:12:21<16:31:27, 354.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1954.8742562227471
INFO:root:current train perplexity4.720917224884033
INFO:root:current mean train loss 1973.261370465472
INFO:root:current train perplexity4.752317905426025
INFO:root:current mean train loss 1987.80444587111
INFO:root:current train perplexity4.809312343597412
INFO:root:current mean train loss 1987.5252770960506
INFO:root:current train perplexity4.817089557647705
INFO:root:current mean train loss 1986.691697234763
INFO:root:current train perplexity4.804495811462402
INFO:root:current mean train loss 1990.5991968537783
INFO:root:current train perplexity4.811953544616699
INFO:root:current mean train loss 1990.0672453647453
INFO:root:current train perplexity4.8106818199157715
INFO:root:current mean train loss 1988.9233562731326
INFO:root:current train perplexity4.809751510620117
INFO:root:current mean train loss 1987.4742716905769
INFO:root:current train perplexity4.807515621185303
INFO:root:current mean train loss 1990.462155743596
INFO:root:current train perplexity4.81038236618042
INFO:root:current mean train loss 1993.6871170526726
INFO:root:current train perplexity4.816423416137695
INFO:root:current mean train loss 1994.0054077255236
INFO:root:current train perplexity4.815956115722656
INFO:root:current mean train loss 1994.8430810193333
INFO:root:current train perplexity4.819159507751465
INFO:root:current mean train loss 1995.6165926003757
INFO:root:current train perplexity4.821599960327148
INFO:root:current mean train loss 1997.4125745618664
INFO:root:current train perplexity4.825685501098633
INFO:root:current mean train loss 1997.6910558615268
INFO:root:current train perplexity4.827303886413574
INFO:root:current mean train loss 1997.384332100792
INFO:root:current train perplexity4.829057693481445
INFO:root:current mean train loss 1998.477660852674
INFO:root:current train perplexity4.83297061920166
INFO:root:current mean train loss 1998.790695380854
INFO:root:current train perplexity4.835143089294434
INFO:root:current mean train loss 1999.1753107484199
INFO:root:current train perplexity4.835875511169434

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:10<00:00, 310.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:10<00:00, 310.26s/it]
INFO:root:final mean train loss: 1998.5717661709
INFO:root:final train perplexity: 4.836512088775635
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.81s/it]
INFO:root:eval mean loss: 2068.9027437250666
INFO:root:eval perplexity: 5.3292317390441895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.27s/it]
INFO:root:eval mean loss: 2520.0133857456503
INFO:root:eval perplexity: 7.853318691253662
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/33
 16%|â–ˆâ–‹        | 33/200 [3:18:23<16:32:29, 356.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1983.7979614257813
INFO:root:current train perplexity4.750366687774658
INFO:root:current mean train loss 1992.0898918151856
INFO:root:current train perplexity4.768286228179932
INFO:root:current mean train loss 1997.5391850398137
INFO:root:current train perplexity4.776358604431152
INFO:root:current mean train loss 1993.0645263671875
INFO:root:current train perplexity4.782095432281494
INFO:root:current mean train loss 1991.6387891686481
INFO:root:current train perplexity4.783132553100586
INFO:root:current mean train loss 1990.4890679495675
INFO:root:current train perplexity4.781242847442627
INFO:root:current mean train loss 1989.3186114686907
INFO:root:current train perplexity4.786316871643066
INFO:root:current mean train loss 1988.8303906892475
INFO:root:current train perplexity4.7848052978515625
INFO:root:current mean train loss 1990.7327367028524
INFO:root:current train perplexity4.793499946594238
INFO:root:current mean train loss 1990.0060614267984
INFO:root:current train perplexity4.796853542327881
INFO:root:current mean train loss 1990.8424420050856
INFO:root:current train perplexity4.800485134124756
INFO:root:current mean train loss 1991.3293446507946
INFO:root:current train perplexity4.79761266708374
INFO:root:current mean train loss 1992.027403622582
INFO:root:current train perplexity4.800629615783691
INFO:root:current mean train loss 1992.3726283353917
INFO:root:current train perplexity4.8032050132751465
INFO:root:current mean train loss 1994.1678903240047
INFO:root:current train perplexity4.807812213897705
INFO:root:current mean train loss 1993.226727764423
INFO:root:current train perplexity4.806282997131348
INFO:root:current mean train loss 1992.7273703701526
INFO:root:current train perplexity4.806257247924805
INFO:root:current mean train loss 1991.6729587901723
INFO:root:current train perplexity4.804464340209961
INFO:root:current mean train loss 1990.9893042779738
INFO:root:current train perplexity4.803631782531738
INFO:root:current mean train loss 1990.4607324716997
INFO:root:current train perplexity4.804026126861572

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.58s/it]
INFO:root:final mean train loss: 1990.1815571210268
INFO:root:final train perplexity: 4.804614543914795
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.33s/it]
INFO:root:eval mean loss: 2069.2361077924147
INFO:root:eval perplexity: 5.330669403076172
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.20s/it]
INFO:root:eval mean loss: 2521.314501606826
INFO:root:eval perplexity: 7.8616814613342285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/34
 17%|â–ˆâ–‹        | 34/200 [3:24:19<16:26:13, 356.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1980.0880348899148
INFO:root:current train perplexity4.7929840087890625
INFO:root:current mean train loss 1988.5102145954713
INFO:root:current train perplexity4.790597438812256
INFO:root:current mean train loss 1987.102168444692
INFO:root:current train perplexity4.797298431396484
INFO:root:current mean train loss 1980.8620955166198
INFO:root:current train perplexity4.782626628875732
INFO:root:current mean train loss 1983.4256062057782
INFO:root:current train perplexity4.792179107666016
INFO:root:current mean train loss 1980.989825428875
INFO:root:current train perplexity4.78338623046875
INFO:root:current mean train loss 1982.5432585092203
INFO:root:current train perplexity4.784903049468994
INFO:root:current mean train loss 1981.6093756284185
INFO:root:current train perplexity4.780398845672607
INFO:root:current mean train loss 1984.4550992819984
INFO:root:current train perplexity4.786715030670166
INFO:root:current mean train loss 1984.7487379404026
INFO:root:current train perplexity4.7812018394470215
INFO:root:current mean train loss 1983.425491092154
INFO:root:current train perplexity4.776606559753418
INFO:root:current mean train loss 1981.6974197426587
INFO:root:current train perplexity4.774742603302002
INFO:root:current mean train loss 1982.5253422557141
INFO:root:current train perplexity4.776641368865967
INFO:root:current mean train loss 1983.1362126502077
INFO:root:current train perplexity4.775811672210693
INFO:root:current mean train loss 1982.897405315753
INFO:root:current train perplexity4.773583889007568
INFO:root:current mean train loss 1983.4946087805167
INFO:root:current train perplexity4.776435852050781
INFO:root:current mean train loss 1983.8283869016007
INFO:root:current train perplexity4.777603626251221
INFO:root:current mean train loss 1983.6091263255312
INFO:root:current train perplexity4.778463363647461
INFO:root:current mean train loss 1983.8640316214787
INFO:root:current train perplexity4.780087947845459
INFO:root:current mean train loss 1984.5710942563107
INFO:root:current train perplexity4.7813849449157715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.64s/it]
INFO:root:final mean train loss: 1983.843557968563
INFO:root:final train perplexity: 4.780659198760986
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.26s/it]
INFO:root:eval mean loss: 2063.3132995172596
INFO:root:eval perplexity: 5.305194854736328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.34s/it]
INFO:root:eval mean loss: 2516.591908123476
INFO:root:eval perplexity: 7.83137321472168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/35
 18%|â–ˆâ–Š        | 35/200 [3:30:10<16:15:13, 354.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1963.6678778465757
INFO:root:current train perplexity4.708893299102783
INFO:root:current mean train loss 1966.8271188637646
INFO:root:current train perplexity4.717728614807129
INFO:root:current mean train loss 1969.959748352466
INFO:root:current train perplexity4.722775459289551
INFO:root:current mean train loss 1973.8483220599023
INFO:root:current train perplexity4.727535724639893
INFO:root:current mean train loss 1976.228596181522
INFO:root:current train perplexity4.726775646209717
INFO:root:current mean train loss 1978.337466872501
INFO:root:current train perplexity4.729648590087891
INFO:root:current mean train loss 1977.1652786298857
INFO:root:current train perplexity4.73213005065918
INFO:root:current mean train loss 1975.9495585174946
INFO:root:current train perplexity4.733448505401611
INFO:root:current mean train loss 1975.200543226545
INFO:root:current train perplexity4.736607551574707
INFO:root:current mean train loss 1977.1526840486276
INFO:root:current train perplexity4.739460468292236
INFO:root:current mean train loss 1977.0915618840693
INFO:root:current train perplexity4.743000030517578
INFO:root:current mean train loss 1977.4610277747788
INFO:root:current train perplexity4.742105007171631
INFO:root:current mean train loss 1978.4145033304253
INFO:root:current train perplexity4.7464518547058105
INFO:root:current mean train loss 1977.717715992647
INFO:root:current train perplexity4.748079299926758
INFO:root:current mean train loss 1975.694571090351
INFO:root:current train perplexity4.748810291290283
INFO:root:current mean train loss 1975.4267852285425
INFO:root:current train perplexity4.748600006103516
INFO:root:current mean train loss 1975.349240353707
INFO:root:current train perplexity4.746194362640381
INFO:root:current mean train loss 1975.6767065756296
INFO:root:current train perplexity4.746283054351807
INFO:root:current mean train loss 1975.6138109088322
INFO:root:current train perplexity4.747767448425293

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:07<00:00, 307.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:07<00:00, 307.81s/it]
INFO:root:final mean train loss: 1976.4810878120766
INFO:root:final train perplexity: 4.7529802322387695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.02s/it]
INFO:root:eval mean loss: 2063.314194699551
INFO:root:eval perplexity: 5.305200099945068
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.06s/it]
INFO:root:eval mean loss: 2518.7659150252107
INFO:root:eval perplexity: 7.845311164855957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/36
 18%|â–ˆâ–Š        | 36/200 [3:36:08<16:12:01, 355.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1960.7269398082387
INFO:root:current train perplexity4.737260341644287
INFO:root:current mean train loss 1961.3176951365429
INFO:root:current train perplexity4.725485801696777
INFO:root:current mean train loss 1964.3984241937574
INFO:root:current train perplexity4.71682071685791
INFO:root:current mean train loss 1966.1530997224177
INFO:root:current train perplexity4.7168288230896
INFO:root:current mean train loss 1975.2288981713807
INFO:root:current train perplexity4.722994327545166
INFO:root:current mean train loss 1973.4325082558707
INFO:root:current train perplexity4.7194905281066895
INFO:root:current mean train loss 1972.6487335854388
INFO:root:current train perplexity4.7243242263793945
INFO:root:current mean train loss 1970.5518039966266
INFO:root:current train perplexity4.7255120277404785
INFO:root:current mean train loss 1969.8003205135924
INFO:root:current train perplexity4.724480628967285
INFO:root:current mean train loss 1968.5022259407588
INFO:root:current train perplexity4.728381633758545
INFO:root:current mean train loss 1968.7227972768299
INFO:root:current train perplexity4.726661205291748
INFO:root:current mean train loss 1967.820750898332
INFO:root:current train perplexity4.727124214172363
INFO:root:current mean train loss 1970.2523991705266
INFO:root:current train perplexity4.730199337005615
INFO:root:current mean train loss 1969.7450033110758
INFO:root:current train perplexity4.726848125457764
INFO:root:current mean train loss 1970.541998676
INFO:root:current train perplexity4.728233337402344
INFO:root:current mean train loss 1970.2448897699423
INFO:root:current train perplexity4.727937698364258
INFO:root:current mean train loss 1970.045822437175
INFO:root:current train perplexity4.728045463562012
INFO:root:current mean train loss 1970.402976289679
INFO:root:current train perplexity4.727198123931885
INFO:root:current mean train loss 1969.9045522722467
INFO:root:current train perplexity4.7249836921691895
INFO:root:current mean train loss 1970.019337892158
INFO:root:current train perplexity4.725902080535889

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.23s/it]
INFO:root:final mean train loss: 1969.7183448225935
INFO:root:final train perplexity: 4.727697372436523
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.00s/it]
INFO:root:eval mean loss: 2058.288422713043
INFO:root:eval perplexity: 5.283680438995361
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.26s/it]
INFO:root:eval mean loss: 2514.3378079461713
INFO:root:eval perplexity: 7.816951751708984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/37
 18%|â–ˆâ–Š        | 37/200 [3:42:00<16:03:34, 354.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1989.37642124721
INFO:root:current train perplexity4.745506286621094
INFO:root:current mean train loss 1956.4969549179077
INFO:root:current train perplexity4.68028450012207
INFO:root:current mean train loss 1963.9909705446478
INFO:root:current train perplexity4.70230770111084
INFO:root:current mean train loss 1960.9565068686882
INFO:root:current train perplexity4.691761493682861
INFO:root:current mean train loss 1966.648220454421
INFO:root:current train perplexity4.704283714294434
INFO:root:current mean train loss 1965.1254603068035
INFO:root:current train perplexity4.698490619659424
INFO:root:current mean train loss 1966.3136209864526
INFO:root:current train perplexity4.704736709594727
INFO:root:current mean train loss 1965.4404836801382
INFO:root:current train perplexity4.707202911376953
INFO:root:current mean train loss 1966.4578270658778
INFO:root:current train perplexity4.708615779876709
INFO:root:current mean train loss 1966.5262634014261
INFO:root:current train perplexity4.707822322845459
INFO:root:current mean train loss 1966.880312552248
INFO:root:current train perplexity4.707693099975586
INFO:root:current mean train loss 1966.47820839307
INFO:root:current train perplexity4.706127643585205
INFO:root:current mean train loss 1968.7233672996297
INFO:root:current train perplexity4.71061372756958
INFO:root:current mean train loss 1968.1996213614223
INFO:root:current train perplexity4.710390567779541
INFO:root:current mean train loss 1968.0794525573901
INFO:root:current train perplexity4.709644794464111
INFO:root:current mean train loss 1966.9350734530942
INFO:root:current train perplexity4.705907821655273
INFO:root:current mean train loss 1965.6565643235565
INFO:root:current train perplexity4.704491138458252
INFO:root:current mean train loss 1965.3528679741753
INFO:root:current train perplexity4.704673767089844
INFO:root:current mean train loss 1964.2010140116417
INFO:root:current train perplexity4.703597545623779
INFO:root:current mean train loss 1963.5989259585306
INFO:root:current train perplexity4.704830646514893

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.08s/it]
INFO:root:final mean train loss: 1963.1246481013911
INFO:root:final train perplexity: 4.703176975250244
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.99s/it]
INFO:root:eval mean loss: 2060.2420498462434
INFO:root:eval perplexity: 5.29203462600708
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.88s/it]
INFO:root:eval mean loss: 2517.216583901263
INFO:root:eval perplexity: 7.835373878479004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/38
 19%|â–ˆâ–‰        | 38/200 [3:47:52<15:55:30, 353.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1920.7613335503472
INFO:root:current train perplexity4.613302230834961
INFO:root:current mean train loss 1935.3280542834052
INFO:root:current train perplexity4.634944915771484
INFO:root:current mean train loss 1938.6146030970983
INFO:root:current train perplexity4.628850936889648
INFO:root:current mean train loss 1941.9113723533742
INFO:root:current train perplexity4.6392316818237305
INFO:root:current mean train loss 1942.3114803699964
INFO:root:current train perplexity4.65065336227417
INFO:root:current mean train loss 1943.918043560063
INFO:root:current train perplexity4.646595001220703
INFO:root:current mean train loss 1944.4727953533793
INFO:root:current train perplexity4.646874904632568
INFO:root:current mean train loss 1948.4260368603188
INFO:root:current train perplexity4.652522563934326
INFO:root:current mean train loss 1950.0459712463019
INFO:root:current train perplexity4.653407573699951
INFO:root:current mean train loss 1950.8817398313493
INFO:root:current train perplexity4.658878803253174
INFO:root:current mean train loss 1950.7188679818332
INFO:root:current train perplexity4.658753871917725
INFO:root:current mean train loss 1953.416539621145
INFO:root:current train perplexity4.664129734039307
INFO:root:current mean train loss 1955.2415542051017
INFO:root:current train perplexity4.674227237701416
INFO:root:current mean train loss 1954.7198487235712
INFO:root:current train perplexity4.675732612609863
INFO:root:current mean train loss 1955.148627574881
INFO:root:current train perplexity4.676693439483643
INFO:root:current mean train loss 1956.5598157962934
INFO:root:current train perplexity4.679014205932617
INFO:root:current mean train loss 1956.4760047611132
INFO:root:current train perplexity4.679760932922363
INFO:root:current mean train loss 1958.0951865821992
INFO:root:current train perplexity4.680226802825928
INFO:root:current mean train loss 1957.0414505790566
INFO:root:current train perplexity4.677460193634033
INFO:root:current mean train loss 1956.878259120441
INFO:root:current train perplexity4.678732872009277

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:07<00:00, 307.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:07<00:00, 307.44s/it]
INFO:root:final mean train loss: 1956.2684665358674
INFO:root:final train perplexity: 4.677814960479736
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.46s/it]
INFO:root:eval mean loss: 2060.015712440437
INFO:root:eval perplexity: 5.291065216064453
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.21s/it]
INFO:root:eval mean loss: 2518.2097280515845
INFO:root:eval perplexity: 7.841744899749756
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/39
 20%|â–ˆâ–‰        | 39/200 [3:53:50<15:53:06, 355.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1944.033205093876
INFO:root:current train perplexity4.656646251678467
INFO:root:current mean train loss 1943.7503888165509
INFO:root:current train perplexity4.6381144523620605
INFO:root:current mean train loss 1947.2911600593393
INFO:root:current train perplexity4.651523113250732
INFO:root:current mean train loss 1945.6355240121072
INFO:root:current train perplexity4.645404815673828
INFO:root:current mean train loss 1952.2436050481094
INFO:root:current train perplexity4.64356803894043
INFO:root:current mean train loss 1950.629825904276
INFO:root:current train perplexity4.635905742645264
INFO:root:current mean train loss 1953.2806883290455
INFO:root:current train perplexity4.639289379119873
INFO:root:current mean train loss 1952.1429215879266
INFO:root:current train perplexity4.640390396118164
INFO:root:current mean train loss 1952.2532442097322
INFO:root:current train perplexity4.640151500701904
INFO:root:current mean train loss 1953.6895612371686
INFO:root:current train perplexity4.642704963684082
INFO:root:current mean train loss 1952.0569983300966
INFO:root:current train perplexity4.644840240478516
INFO:root:current mean train loss 1952.2048433339944
INFO:root:current train perplexity4.646646976470947
INFO:root:current mean train loss 1952.9802337017754
INFO:root:current train perplexity4.6494364738464355
INFO:root:current mean train loss 1952.603564919179
INFO:root:current train perplexity4.647936820983887
INFO:root:current mean train loss 1951.8054933978497
INFO:root:current train perplexity4.648318767547607
INFO:root:current mean train loss 1951.8647925930047
INFO:root:current train perplexity4.6501946449279785
INFO:root:current mean train loss 1951.5486756472812
INFO:root:current train perplexity4.651591777801514
INFO:root:current mean train loss 1950.453448257706
INFO:root:current train perplexity4.650942802429199
INFO:root:current mean train loss 1949.9956659794366
INFO:root:current train perplexity4.653212547302246
INFO:root:current mean train loss 1950.7190540558702
INFO:root:current train perplexity4.655591011047363

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.71s/it]
INFO:root:final mean train loss: 1950.0559348271343
INFO:root:final train perplexity: 4.654952049255371
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.44s/it]
INFO:root:eval mean loss: 2057.2975650002772
INFO:root:eval perplexity: 5.27944803237915
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.42s/it]
INFO:root:eval mean loss: 2518.0934716623724
INFO:root:eval perplexity: 7.840996742248535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/40
 20%|â–ˆâ–ˆ        | 40/200 [3:59:44<15:45:56, 354.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1942.7869285873219
INFO:root:current train perplexity4.618095397949219
INFO:root:current mean train loss 1939.8607661923882
INFO:root:current train perplexity4.592502593994141
INFO:root:current mean train loss 1942.9006986447132
INFO:root:current train perplexity4.59710168838501
INFO:root:current mean train loss 1941.2320070291887
INFO:root:current train perplexity4.605408668518066
INFO:root:current mean train loss 1939.4275254028576
INFO:root:current train perplexity4.60322380065918
INFO:root:current mean train loss 1939.8931760376188
INFO:root:current train perplexity4.607640743255615
INFO:root:current mean train loss 1940.0661302883952
INFO:root:current train perplexity4.609476566314697
INFO:root:current mean train loss 1941.1245167331915
INFO:root:current train perplexity4.612574100494385
INFO:root:current mean train loss 1942.9109561646758
INFO:root:current train perplexity4.614581108093262
INFO:root:current mean train loss 1943.7031902122303
INFO:root:current train perplexity4.614680290222168
INFO:root:current mean train loss 1943.4082888796775
INFO:root:current train perplexity4.618328094482422
INFO:root:current mean train loss 1944.9454422320623
INFO:root:current train perplexity4.622085094451904
INFO:root:current mean train loss 1944.5470341018067
INFO:root:current train perplexity4.623725414276123
INFO:root:current mean train loss 1946.4023574707385
INFO:root:current train perplexity4.629152297973633
INFO:root:current mean train loss 1944.9249790029157
INFO:root:current train perplexity4.628554344177246
INFO:root:current mean train loss 1944.7025163492272
INFO:root:current train perplexity4.62914514541626
INFO:root:current mean train loss 1945.1463743735808
INFO:root:current train perplexity4.630361080169678
INFO:root:current mean train loss 1943.9928537747242
INFO:root:current train perplexity4.628419399261475
INFO:root:current mean train loss 1943.8700324074266
INFO:root:current train perplexity4.629755020141602
INFO:root:current mean train loss 1944.2120199102292
INFO:root:current train perplexity4.6319451332092285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.02s/it]
INFO:root:final mean train loss: 1943.8231026653802
INFO:root:final train perplexity: 4.632125377655029
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.72s/it]
INFO:root:eval mean loss: 2054.016591173537
INFO:root:eval perplexity: 5.265458583831787
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.61s/it]
INFO:root:eval mean loss: 2513.1070868309507
INFO:root:eval perplexity: 7.80908727645874
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/41
 20%|â–ˆâ–ˆ        | 41/200 [4:05:35<15:36:36, 353.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1913.6856956481934
INFO:root:current train perplexity4.531275272369385
INFO:root:current mean train loss 1919.3936761350049
INFO:root:current train perplexity4.556834697723389
INFO:root:current mean train loss 1920.79642837112
INFO:root:current train perplexity4.545115947723389
INFO:root:current mean train loss 1926.2180570351957
INFO:root:current train perplexity4.567017555236816
INFO:root:current mean train loss 1929.717520436933
INFO:root:current train perplexity4.5695929527282715
INFO:root:current mean train loss 1929.6298553671613
INFO:root:current train perplexity4.576362609863281
INFO:root:current mean train loss 1931.8344595021215
INFO:root:current train perplexity4.578928470611572
INFO:root:current mean train loss 1928.4899771992286
INFO:root:current train perplexity4.579193115234375
INFO:root:current mean train loss 1929.1914851324898
INFO:root:current train perplexity4.579153060913086
INFO:root:current mean train loss 1932.606234753467
INFO:root:current train perplexity4.585681438446045
INFO:root:current mean train loss 1933.1803838353958
INFO:root:current train perplexity4.5872578620910645
INFO:root:current mean train loss 1934.1201424997387
INFO:root:current train perplexity4.59060001373291
INFO:root:current mean train loss 1934.6886730429567
INFO:root:current train perplexity4.59257173538208
INFO:root:current mean train loss 1934.5163681773538
INFO:root:current train perplexity4.5945353507995605
INFO:root:current mean train loss 1935.8553880497734
INFO:root:current train perplexity4.598672389984131
INFO:root:current mean train loss 1936.5845887607202
INFO:root:current train perplexity4.603201389312744
INFO:root:current mean train loss 1937.405190521816
INFO:root:current train perplexity4.6047797203063965
INFO:root:current mean train loss 1937.9389390839235
INFO:root:current train perplexity4.608035564422607
INFO:root:current mean train loss 1938.5763221451
INFO:root:current train perplexity4.610433578491211

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:08<00:00, 308.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:08<00:00, 308.17s/it]
INFO:root:final mean train loss: 1937.8956390242354
INFO:root:final train perplexity: 4.6105217933654785
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.07s/it]
INFO:root:eval mean loss: 2052.1589558919272
INFO:root:eval perplexity: 5.257553577423096
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.55s/it]
INFO:root:eval mean loss: 2515.1107186391846
INFO:root:eval perplexity: 7.821892261505127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/42
 21%|â–ˆâ–ˆ        | 42/200 [4:11:32<15:34:14, 354.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1877.9022874098557
INFO:root:current train perplexity4.450207233428955
INFO:root:current mean train loss 1908.7256302284984
INFO:root:current train perplexity4.546808242797852
INFO:root:current mean train loss 1909.0990248129401
INFO:root:current train perplexity4.533054828643799
INFO:root:current mean train loss 1916.409153557433
INFO:root:current train perplexity4.536986351013184
INFO:root:current mean train loss 1916.9508030039347
INFO:root:current train perplexity4.546333312988281
INFO:root:current mean train loss 1919.9154678552936
INFO:root:current train perplexity4.550396919250488
INFO:root:current mean train loss 1921.8729883290425
INFO:root:current train perplexity4.5554585456848145
INFO:root:current mean train loss 1922.588975903697
INFO:root:current train perplexity4.5545501708984375
INFO:root:current mean train loss 1923.4972197097459
INFO:root:current train perplexity4.55961275100708
INFO:root:current mean train loss 1923.1027024468613
INFO:root:current train perplexity4.558745384216309
INFO:root:current mean train loss 1924.7582176336532
INFO:root:current train perplexity4.56354284286499
INFO:root:current mean train loss 1927.7312430684242
INFO:root:current train perplexity4.564009189605713
INFO:root:current mean train loss 1928.005645122984
INFO:root:current train perplexity4.569174766540527
INFO:root:current mean train loss 1928.9008906205374
INFO:root:current train perplexity4.572338581085205
INFO:root:current mean train loss 1928.6929732941603
INFO:root:current train perplexity4.574420928955078
INFO:root:current mean train loss 1929.3953814660958
INFO:root:current train perplexity4.577072620391846
INFO:root:current mean train loss 1930.4874100327418
INFO:root:current train perplexity4.579787254333496
INFO:root:current mean train loss 1931.1353012949003
INFO:root:current train perplexity4.582202911376953
INFO:root:current mean train loss 1931.4377784792127
INFO:root:current train perplexity4.5840582847595215
INFO:root:current mean train loss 1932.596384115264
INFO:root:current train perplexity4.588323593139648

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:09<00:00, 309.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:09<00:00, 309.54s/it]
INFO:root:final mean train loss: 1932.0530353340307
INFO:root:final train perplexity: 4.589325904846191
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.85s/it]
INFO:root:eval mean loss: 2051.585392079455
INFO:root:eval perplexity: 5.2551140785217285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.90s/it]
INFO:root:eval mean loss: 2514.6239368628103
INFO:root:eval perplexity: 7.818782329559326
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/43
 22%|â–ˆâ–ˆâ–       | 43/200 [4:17:34<15:33:29, 356.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1935.7735392252605
INFO:root:current train perplexity4.534937381744385
INFO:root:current mean train loss 1924.7803973858172
INFO:root:current train perplexity4.532745361328125
INFO:root:current mean train loss 1918.6321803880774
INFO:root:current train perplexity4.528439044952393
INFO:root:current mean train loss 1917.8533217921402
INFO:root:current train perplexity4.533027648925781
INFO:root:current mean train loss 1917.2337217818858
INFO:root:current train perplexity4.537052154541016
INFO:root:current mean train loss 1919.528262732164
INFO:root:current train perplexity4.543867588043213
INFO:root:current mean train loss 1922.3071818033854
INFO:root:current train perplexity4.543208122253418
INFO:root:current mean train loss 1923.7690155447347
INFO:root:current train perplexity4.548890590667725
INFO:root:current mean train loss 1924.3852756730046
INFO:root:current train perplexity4.548497676849365
INFO:root:current mean train loss 1926.1946047547044
INFO:root:current train perplexity4.5528950691223145
INFO:root:current mean train loss 1927.2892592346784
INFO:root:current train perplexity4.557286262512207
INFO:root:current mean train loss 1927.5456505159361
INFO:root:current train perplexity4.5585713386535645
INFO:root:current mean train loss 1928.058042746443
INFO:root:current train perplexity4.556877136230469
INFO:root:current mean train loss 1928.5200071406543
INFO:root:current train perplexity4.558402061462402
INFO:root:current mean train loss 1928.2498291869263
INFO:root:current train perplexity4.56105899810791
INFO:root:current mean train loss 1927.6796995474622
INFO:root:current train perplexity4.562941074371338
INFO:root:current mean train loss 1927.3973343738019
INFO:root:current train perplexity4.562889099121094
INFO:root:current mean train loss 1928.2018945594743
INFO:root:current train perplexity4.565769672393799
INFO:root:current mean train loss 1927.6864327185792
INFO:root:current train perplexity4.56827974319458
INFO:root:current mean train loss 1927.2586575048574
INFO:root:current train perplexity4.568276405334473

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.17s/it]
INFO:root:final mean train loss: 1926.5212828020105
INFO:root:final train perplexity: 4.569348335266113
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.61s/it]
INFO:root:eval mean loss: 2051.3258558773823
INFO:root:eval perplexity: 5.254012584686279
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.24s/it]
INFO:root:eval mean loss: 2515.839403517703
INFO:root:eval perplexity: 7.8265557289123535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/44
 22%|â–ˆâ–ˆâ–       | 44/200 [4:23:25<15:23:06, 355.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1924.3668524559507
INFO:root:current train perplexity4.525534629821777
INFO:root:current mean train loss 1914.7388708413052
INFO:root:current train perplexity4.514693260192871
INFO:root:current mean train loss 1920.1038220363107
INFO:root:current train perplexity4.523603439331055
INFO:root:current mean train loss 1917.2519267409266
INFO:root:current train perplexity4.519886493682861
INFO:root:current mean train loss 1914.4475679333577
INFO:root:current train perplexity4.518716812133789
INFO:root:current mean train loss 1914.0673129623942
INFO:root:current train perplexity4.51979398727417
INFO:root:current mean train loss 1912.6258182673034
INFO:root:current train perplexity4.52103328704834
INFO:root:current mean train loss 1912.5038377795033
INFO:root:current train perplexity4.520869731903076
INFO:root:current mean train loss 1910.5502671711279
INFO:root:current train perplexity4.5196099281311035
INFO:root:current mean train loss 1914.0136045880906
INFO:root:current train perplexity4.528868198394775
INFO:root:current mean train loss 1917.7087706645102
INFO:root:current train perplexity4.533801555633545
INFO:root:current mean train loss 1918.1510065107004
INFO:root:current train perplexity4.534979343414307
INFO:root:current mean train loss 1918.0465495117971
INFO:root:current train perplexity4.534211158752441
INFO:root:current mean train loss 1918.687470003509
INFO:root:current train perplexity4.536659240722656
INFO:root:current mean train loss 1919.8612469697541
INFO:root:current train perplexity4.540754318237305
INFO:root:current mean train loss 1920.0887797576963
INFO:root:current train perplexity4.541731357574463
INFO:root:current mean train loss 1919.128438202627
INFO:root:current train perplexity4.540951251983643
INFO:root:current mean train loss 1920.6934333718293
INFO:root:current train perplexity4.544772624969482
INFO:root:current mean train loss 1920.4499478012276
INFO:root:current train perplexity4.544638156890869
INFO:root:current mean train loss 1921.040058184968
INFO:root:current train perplexity4.547358989715576

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:07<00:00, 307.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:07<00:00, 307.78s/it]
INFO:root:final mean train loss: 1920.3325797353677
INFO:root:final train perplexity: 4.547101020812988
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.20s/it]
INFO:root:eval mean loss: 2049.8547146844526
INFO:root:eval perplexity: 5.2477641105651855
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.39s/it]
INFO:root:eval mean loss: 2516.1566569010415
INFO:root:eval perplexity: 7.828588008880615
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [4:29:22<15:19:01, 355.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1901.335069656372
INFO:root:current train perplexity4.481740951538086
INFO:root:current mean train loss 1891.9221005323457
INFO:root:current train perplexity4.473489761352539
INFO:root:current mean train loss 1896.9456740870621
INFO:root:current train perplexity4.492156505584717
INFO:root:current mean train loss 1901.459715120085
INFO:root:current train perplexity4.5032830238342285
INFO:root:current mean train loss 1903.1205060235386
INFO:root:current train perplexity4.507238864898682
INFO:root:current mean train loss 1904.3783335584276
INFO:root:current train perplexity4.502553462982178
INFO:root:current mean train loss 1910.4253924266402
INFO:root:current train perplexity4.516142845153809
INFO:root:current mean train loss 1910.0793805347064
INFO:root:current train perplexity4.518130779266357
INFO:root:current mean train loss 1912.2669814780907
INFO:root:current train perplexity4.51758337020874
INFO:root:current mean train loss 1912.3566004329698
INFO:root:current train perplexity4.515280246734619
INFO:root:current mean train loss 1914.5935196267035
INFO:root:current train perplexity4.521266460418701
INFO:root:current mean train loss 1914.576251052909
INFO:root:current train perplexity4.5212273597717285
INFO:root:current mean train loss 1913.9283778516551
INFO:root:current train perplexity4.522225379943848
INFO:root:current mean train loss 1913.8070318943594
INFO:root:current train perplexity4.521769046783447
INFO:root:current mean train loss 1912.9643063571284
INFO:root:current train perplexity4.5228118896484375
INFO:root:current mean train loss 1913.562135584214
INFO:root:current train perplexity4.523540496826172
INFO:root:current mean train loss 1914.1764493355383
INFO:root:current train perplexity4.524356842041016
INFO:root:current mean train loss 1914.3431819301613
INFO:root:current train perplexity4.52451753616333
INFO:root:current mean train loss 1914.5619955431239
INFO:root:current train perplexity4.525343894958496
INFO:root:current mean train loss 1915.7782525647197
INFO:root:current train perplexity4.52885627746582

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.84s/it]
INFO:root:final mean train loss: 1915.211629693459
INFO:root:final train perplexity: 4.528773307800293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.57s/it]
INFO:root:eval mean loss: 2049.356881648936
INFO:root:eval perplexity: 5.245652198791504
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.62s/it]
INFO:root:eval mean loss: 2515.7344399310173
INFO:root:eval perplexity: 7.825883865356445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [4:35:20<15:14:54, 356.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1908.6058816792051
INFO:root:current train perplexity4.485065460205078
INFO:root:current mean train loss 1902.8559334264935
INFO:root:current train perplexity4.4715352058410645
INFO:root:current mean train loss 1902.6887867340413
INFO:root:current train perplexity4.488794326782227
INFO:root:current mean train loss 1904.542054984826
INFO:root:current train perplexity4.490194320678711
INFO:root:current mean train loss 1908.2087691658005
INFO:root:current train perplexity4.50264310836792
INFO:root:current mean train loss 1908.339606122593
INFO:root:current train perplexity4.501008033752441
INFO:root:current mean train loss 1908.876031592729
INFO:root:current train perplexity4.499454498291016
INFO:root:current mean train loss 1909.1845782838009
INFO:root:current train perplexity4.502267837524414
INFO:root:current mean train loss 1910.9925616087896
INFO:root:current train perplexity4.500924587249756
INFO:root:current mean train loss 1911.4302261772505
INFO:root:current train perplexity4.504236698150635
INFO:root:current mean train loss 1911.9708867386246
INFO:root:current train perplexity4.506059646606445
INFO:root:current mean train loss 1912.739867233806
INFO:root:current train perplexity4.510185718536377
INFO:root:current mean train loss 1912.0201647577576
INFO:root:current train perplexity4.510337829589844
INFO:root:current mean train loss 1911.9615934621934
INFO:root:current train perplexity4.507994651794434
INFO:root:current mean train loss 1910.1107863504126
INFO:root:current train perplexity4.503863334655762
INFO:root:current mean train loss 1909.4864398490622
INFO:root:current train perplexity4.5040974617004395
INFO:root:current mean train loss 1909.2517259042934
INFO:root:current train perplexity4.504409313201904
INFO:root:current mean train loss 1909.2638021016107
INFO:root:current train perplexity4.50524377822876
INFO:root:current mean train loss 1910.084457016194
INFO:root:current train perplexity4.5088114738464355
INFO:root:current mean train loss 1910.6739816834142
INFO:root:current train perplexity4.510863304138184

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.65s/it]
INFO:root:final mean train loss: 1910.1868752129922
INFO:root:final train perplexity: 4.510861873626709
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.46s/it]
INFO:root:eval mean loss: 2052.833636777621
INFO:root:eval perplexity: 5.260423183441162
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.84s/it]
INFO:root:eval mean loss: 2522.7375955784573
INFO:root:eval perplexity: 7.870835781097412
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [4:41:13<15:06:19, 355.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1897.2705601283483
INFO:root:current train perplexity4.4298996925354
INFO:root:current mean train loss 1909.090439305161
INFO:root:current train perplexity4.465800762176514
INFO:root:current mean train loss 1901.4818569925808
INFO:root:current train perplexity4.471538543701172
INFO:root:current mean train loss 1897.8081815326634
INFO:root:current train perplexity4.4627556800842285
INFO:root:current mean train loss 1894.8707527865367
INFO:root:current train perplexity4.456973075866699
INFO:root:current mean train loss 1897.9951012652853
INFO:root:current train perplexity4.465158462524414
INFO:root:current mean train loss 1899.7896658561292
INFO:root:current train perplexity4.471900463104248
INFO:root:current mean train loss 1899.6530469545446
INFO:root:current train perplexity4.470920085906982
INFO:root:current mean train loss 1899.0309054028482
INFO:root:current train perplexity4.467007637023926
INFO:root:current mean train loss 1900.8087110500298
INFO:root:current train perplexity4.472887992858887
INFO:root:current mean train loss 1902.6805366557803
INFO:root:current train perplexity4.474669456481934
INFO:root:current mean train loss 1901.9868578775497
INFO:root:current train perplexity4.471619129180908
INFO:root:current mean train loss 1902.1085226708458
INFO:root:current train perplexity4.47495698928833
INFO:root:current mean train loss 1903.0520362690283
INFO:root:current train perplexity4.475975513458252
INFO:root:current mean train loss 1903.135708288134
INFO:root:current train perplexity4.47967529296875
INFO:root:current mean train loss 1903.2292693595266
INFO:root:current train perplexity4.482370376586914
INFO:root:current mean train loss 1903.876199135932
INFO:root:current train perplexity4.483489513397217
INFO:root:current mean train loss 1903.7587765024289
INFO:root:current train perplexity4.4833984375
INFO:root:current mean train loss 1903.946110266152
INFO:root:current train perplexity4.485175609588623

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.23s/it]
INFO:root:final mean train loss: 1903.6097476437906
INFO:root:final train perplexity: 4.487524509429932
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.90s/it]
INFO:root:eval mean loss: 2045.3024923987423
INFO:root:eval perplexity: 5.228479862213135
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.26s/it]
INFO:root:eval mean loss: 2511.5751057076964
INFO:root:eval perplexity: 7.799307346343994
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/48
 24%|â–ˆâ–ˆâ–       | 48/200 [4:47:09<15:00:25, 355.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1849.3219401041667
INFO:root:current train perplexity4.400985240936279
INFO:root:current mean train loss 1885.9548095703126
INFO:root:current train perplexity4.42420768737793
INFO:root:current mean train loss 1892.309684434048
INFO:root:current train perplexity4.438194751739502
INFO:root:current mean train loss 1890.584281218998
INFO:root:current train perplexity4.4399309158325195
INFO:root:current mean train loss 1896.038341549793
INFO:root:current train perplexity4.453986167907715
INFO:root:current mean train loss 1899.821797017218
INFO:root:current train perplexity4.463381767272949
INFO:root:current mean train loss 1895.727415999746
INFO:root:current train perplexity4.451570510864258
INFO:root:current mean train loss 1894.006088833042
INFO:root:current train perplexity4.454272270202637
INFO:root:current mean train loss 1895.9394600148582
INFO:root:current train perplexity4.456399917602539
INFO:root:current mean train loss 1899.1385043118169
INFO:root:current train perplexity4.461247444152832
INFO:root:current mean train loss 1898.8384647764008
INFO:root:current train perplexity4.4624152183532715
INFO:root:current mean train loss 1898.0434453168791
INFO:root:current train perplexity4.459659576416016
INFO:root:current mean train loss 1897.7963029272762
INFO:root:current train perplexity4.457596302032471
INFO:root:current mean train loss 1899.7955082766457
INFO:root:current train perplexity4.4633283615112305
INFO:root:current mean train loss 1898.726710105869
INFO:root:current train perplexity4.463010787963867
INFO:root:current mean train loss 1899.316983485458
INFO:root:current train perplexity4.466550350189209
INFO:root:current mean train loss 1899.0815871861696
INFO:root:current train perplexity4.468464374542236
INFO:root:current mean train loss 1898.9995980576941
INFO:root:current train perplexity4.468170642852783
INFO:root:current mean train loss 1898.8186028430614
INFO:root:current train perplexity4.468765735626221
INFO:root:current mean train loss 1899.174979410595
INFO:root:current train perplexity4.470391273498535

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.19s/it]
INFO:root:final mean train loss: 1898.8977157277286
INFO:root:final train perplexity: 4.470879077911377
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.87s/it]
INFO:root:eval mean loss: 2049.8314771719856
INFO:root:eval perplexity: 5.247665882110596
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.02s/it]
INFO:root:eval mean loss: 2520.9252518457724
INFO:root:eval perplexity: 7.859175682067871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/49
 24%|â–ˆâ–ˆâ–       | 49/200 [4:53:01<14:52:00, 354.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1899.9912948608398
INFO:root:current train perplexity4.4161787033081055
INFO:root:current mean train loss 1895.2930390329072
INFO:root:current train perplexity4.4304986000061035
INFO:root:current mean train loss 1886.378012295427
INFO:root:current train perplexity4.412827968597412
INFO:root:current mean train loss 1889.052945791957
INFO:root:current train perplexity4.425937175750732
INFO:root:current mean train loss 1891.573582401982
INFO:root:current train perplexity4.428175926208496
INFO:root:current mean train loss 1892.582012434651
INFO:root:current train perplexity4.430168628692627
INFO:root:current mean train loss 1888.160172281386
INFO:root:current train perplexity4.427790641784668
INFO:root:current mean train loss 1886.9635883602289
INFO:root:current train perplexity4.427147388458252
INFO:root:current mean train loss 1887.7943081488977
INFO:root:current train perplexity4.432234764099121
INFO:root:current mean train loss 1888.5675681445732
INFO:root:current train perplexity4.433809280395508
INFO:root:current mean train loss 1889.5231960799342
INFO:root:current train perplexity4.4401021003723145
INFO:root:current mean train loss 1890.8758701284025
INFO:root:current train perplexity4.442663669586182
INFO:root:current mean train loss 1891.9052176537452
INFO:root:current train perplexity4.444228172302246
INFO:root:current mean train loss 1891.9314125221413
INFO:root:current train perplexity4.444978713989258
INFO:root:current mean train loss 1892.2801451443295
INFO:root:current train perplexity4.445642948150635
INFO:root:current mean train loss 1894.2711539405445
INFO:root:current train perplexity4.449282169342041
INFO:root:current mean train loss 1895.2837311239803
INFO:root:current train perplexity4.451578140258789
INFO:root:current mean train loss 1894.238144801891
INFO:root:current train perplexity4.449887752532959
INFO:root:current mean train loss 1894.5652371202493
INFO:root:current train perplexity4.451934814453125
INFO:root:current mean train loss 1894.3251020538141
INFO:root:current train perplexity4.451590061187744

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.17s/it]
INFO:root:final mean train loss: 1893.819095151808
INFO:root:final train perplexity: 4.453006744384766
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 24.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 24.00s/it]
INFO:root:eval mean loss: 2050.718055238115
INFO:root:eval perplexity: 5.251430034637451
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.55s/it]
INFO:root:eval mean loss: 2523.5488887272827
INFO:root:eval perplexity: 7.876058101654053
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [4:58:50<14:41:50, 352.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1876.591761997768
INFO:root:current train perplexity4.428909778594971
INFO:root:current mean train loss 1889.508903759438
INFO:root:current train perplexity4.415555953979492
INFO:root:current mean train loss 1892.0450557111258
INFO:root:current train perplexity4.433218479156494
INFO:root:current mean train loss 1889.1565483552338
INFO:root:current train perplexity4.429858207702637
INFO:root:current mean train loss 1888.5276525960467
INFO:root:current train perplexity4.4344162940979
INFO:root:current mean train loss 1886.892762898096
INFO:root:current train perplexity4.431243419647217
INFO:root:current mean train loss 1882.1487674095965
INFO:root:current train perplexity4.4157280921936035
INFO:root:current mean train loss 1883.136725106131
INFO:root:current train perplexity4.416443824768066
INFO:root:current mean train loss 1885.137994665139
INFO:root:current train perplexity4.417849540710449
INFO:root:current mean train loss 1885.8877302999867
INFO:root:current train perplexity4.418031215667725
INFO:root:current mean train loss 1887.1859884925748
INFO:root:current train perplexity4.420798301696777
INFO:root:current mean train loss 1888.8272232307986
INFO:root:current train perplexity4.423203468322754
INFO:root:current mean train loss 1888.6640684618008
INFO:root:current train perplexity4.425987720489502
INFO:root:current mean train loss 1889.341406050923
INFO:root:current train perplexity4.429289817810059
INFO:root:current mean train loss 1890.18697557785
INFO:root:current train perplexity4.431547164916992
INFO:root:current mean train loss 1890.509953261807
INFO:root:current train perplexity4.434217929840088
INFO:root:current mean train loss 1890.7710613114245
INFO:root:current train perplexity4.4341278076171875
INFO:root:current mean train loss 1890.5883250250142
INFO:root:current train perplexity4.436315059661865
INFO:root:current mean train loss 1889.9249444510758
INFO:root:current train perplexity4.435297012329102
INFO:root:current mean train loss 1889.0163849174457
INFO:root:current train perplexity4.433954238891602

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.04s/it]
INFO:root:final mean train loss: 1888.7593327155332
INFO:root:final train perplexity: 4.435273170471191
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.13s/it]
INFO:root:eval mean loss: 2048.172882729388
INFO:root:eval perplexity: 5.240631103515625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.33s/it]
INFO:root:eval mean loss: 2520.504962028341
INFO:root:eval perplexity: 7.856476306915283
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [5:04:36<14:31:20, 350.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1853.136054761482
INFO:root:current train perplexity4.373680114746094
INFO:root:current mean train loss 1856.6590193782945
INFO:root:current train perplexity4.385619640350342
INFO:root:current mean train loss 1870.4721000499296
INFO:root:current train perplexity4.401852607727051
INFO:root:current mean train loss 1875.273550898651
INFO:root:current train perplexity4.401391506195068
INFO:root:current mean train loss 1874.6265353092308
INFO:root:current train perplexity4.406022548675537
INFO:root:current mean train loss 1875.2687054421792
INFO:root:current train perplexity4.403405666351318
INFO:root:current mean train loss 1877.2865256003074
INFO:root:current train perplexity4.4049506187438965
INFO:root:current mean train loss 1877.719321786268
INFO:root:current train perplexity4.401506423950195
INFO:root:current mean train loss 1878.8915637855441
INFO:root:current train perplexity4.404462814331055
INFO:root:current mean train loss 1880.4080976087362
INFO:root:current train perplexity4.408031463623047
INFO:root:current mean train loss 1880.4397965479523
INFO:root:current train perplexity4.407711029052734
INFO:root:current mean train loss 1881.0222985609523
INFO:root:current train perplexity4.409034729003906
INFO:root:current mean train loss 1881.593090376771
INFO:root:current train perplexity4.413628578186035
INFO:root:current mean train loss 1883.9982189887787
INFO:root:current train perplexity4.417178153991699
INFO:root:current mean train loss 1883.4568787870107
INFO:root:current train perplexity4.417212009429932
INFO:root:current mean train loss 1883.1230639461357
INFO:root:current train perplexity4.418097496032715
INFO:root:current mean train loss 1884.0372371604892
INFO:root:current train perplexity4.4180073738098145
INFO:root:current mean train loss 1884.136219270907
INFO:root:current train perplexity4.4197998046875
INFO:root:current mean train loss 1883.4810756998174
INFO:root:current train perplexity4.418342113494873
INFO:root:current mean train loss 1884.4841792901195
INFO:root:current train perplexity4.4194865226745605

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.95s/it]
INFO:root:final mean train loss: 1884.252611861467
INFO:root:final train perplexity: 4.41953706741333
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.77s/it]
INFO:root:eval mean loss: 2048.438558808455
INFO:root:eval perplexity: 5.241757392883301
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.89s/it]
INFO:root:eval mean loss: 2522.1478262826904
INFO:root:eval perplexity: 7.867040157318115
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [5:10:25<14:23:50, 350.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1859.4327848503387
INFO:root:current train perplexity4.326081275939941
INFO:root:current mean train loss 1855.0590293342298
INFO:root:current train perplexity4.326424598693848
INFO:root:current mean train loss 1862.6266982007785
INFO:root:current train perplexity4.358320236206055
INFO:root:current mean train loss 1863.781571908657
INFO:root:current train perplexity4.356682777404785
INFO:root:current mean train loss 1866.099182255273
INFO:root:current train perplexity4.368594169616699
INFO:root:current mean train loss 1864.575055444629
INFO:root:current train perplexity4.366939067840576
INFO:root:current mean train loss 1861.9862925583936
INFO:root:current train perplexity4.36256217956543
INFO:root:current mean train loss 1865.456538759429
INFO:root:current train perplexity4.3742475509643555
INFO:root:current mean train loss 1867.1840545205
INFO:root:current train perplexity4.382071495056152
INFO:root:current mean train loss 1871.3194088319797
INFO:root:current train perplexity4.386080265045166
INFO:root:current mean train loss 1870.7214296856966
INFO:root:current train perplexity4.386350631713867
INFO:root:current mean train loss 1873.7293552582485
INFO:root:current train perplexity4.391242980957031
INFO:root:current mean train loss 1874.984885069326
INFO:root:current train perplexity4.392202377319336
INFO:root:current mean train loss 1874.9236116995435
INFO:root:current train perplexity4.391488075256348
INFO:root:current mean train loss 1876.59448522052
INFO:root:current train perplexity4.393604755401611
INFO:root:current mean train loss 1878.1634307880606
INFO:root:current train perplexity4.394961357116699
INFO:root:current mean train loss 1877.8926825701872
INFO:root:current train perplexity4.394369125366211
INFO:root:current mean train loss 1878.5400897939087
INFO:root:current train perplexity4.395769119262695
INFO:root:current mean train loss 1879.007602653159
INFO:root:current train perplexity4.399630069732666
INFO:root:current mean train loss 1878.9768163052943
INFO:root:current train perplexity4.401186466217041

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:07<00:00, 307.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:07<00:00, 307.87s/it]
INFO:root:final mean train loss: 1878.9768163052943
INFO:root:final train perplexity: 4.401186466217041
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.14s/it]
INFO:root:eval mean loss: 2046.585969532635
INFO:root:eval perplexity: 5.233910083770752
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.20s/it]
INFO:root:eval mean loss: 2521.2978368448025
INFO:root:eval perplexity: 7.861568927764893
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [5:16:22<14:23:12, 352.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1863.5245129394532
INFO:root:current train perplexity4.344519138336182
INFO:root:current mean train loss 1866.5567211914063
INFO:root:current train perplexity4.339975833892822
INFO:root:current mean train loss 1873.416349283854
INFO:root:current train perplexity4.360185146331787
INFO:root:current mean train loss 1870.6903115844727
INFO:root:current train perplexity4.361185550689697
INFO:root:current mean train loss 1867.5067912597656
INFO:root:current train perplexity4.361964702606201
INFO:root:current mean train loss 1866.654306640625
INFO:root:current train perplexity4.368481636047363
INFO:root:current mean train loss 1865.72962890625
INFO:root:current train perplexity4.364312648773193
INFO:root:current mean train loss 1867.0967826843262
INFO:root:current train perplexity4.364500522613525
INFO:root:current mean train loss 1867.9502380371093
INFO:root:current train perplexity4.365902423858643
INFO:root:current mean train loss 1869.2355184326173
INFO:root:current train perplexity4.368699073791504
INFO:root:current mean train loss 1869.6982729270242
INFO:root:current train perplexity4.371943473815918
INFO:root:current mean train loss 1869.48103708903
INFO:root:current train perplexity4.37049674987793
INFO:root:current mean train loss 1869.4318563138522
INFO:root:current train perplexity4.369180679321289
INFO:root:current mean train loss 1870.1712887137278
INFO:root:current train perplexity4.373034477233887
INFO:root:current mean train loss 1872.6492202148438
INFO:root:current train perplexity4.377248287200928
INFO:root:current mean train loss 1874.003355178833
INFO:root:current train perplexity4.381324768066406
INFO:root:current mean train loss 1873.909258961397
INFO:root:current train perplexity4.381384372711182
INFO:root:current mean train loss 1874.0205282931859
INFO:root:current train perplexity4.382373332977295
INFO:root:current mean train loss 1874.6968161492598
INFO:root:current train perplexity4.382462024688721

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.34s/it]
INFO:root:final mean train loss: 1874.0551188397276
INFO:root:final train perplexity: 4.384136199951172
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.88s/it]
INFO:root:eval mean loss: 2046.7423078388188
INFO:root:eval perplexity: 5.23457145690918
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.09s/it]
INFO:root:eval mean loss: 2521.8244758768283
INFO:root:eval perplexity: 7.864958763122559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [5:22:16<14:18:07, 352.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1879.1457591337316
INFO:root:current train perplexity4.406787395477295
INFO:root:current mean train loss 1870.9918984959268
INFO:root:current train perplexity4.378256320953369
INFO:root:current mean train loss 1868.963382281466
INFO:root:current train perplexity4.362155437469482
INFO:root:current mean train loss 1866.2070593608291
INFO:root:current train perplexity4.350435733795166
INFO:root:current mean train loss 1862.4484699349896
INFO:root:current train perplexity4.349806785583496
INFO:root:current mean train loss 1863.637913480718
INFO:root:current train perplexity4.354595184326172
INFO:root:current mean train loss 1863.2216312154958
INFO:root:current train perplexity4.355434894561768
INFO:root:current mean train loss 1865.8119523009827
INFO:root:current train perplexity4.362718105316162
INFO:root:current mean train loss 1864.7321353011207
INFO:root:current train perplexity4.358277320861816
INFO:root:current mean train loss 1864.51038649298
INFO:root:current train perplexity4.3550896644592285
INFO:root:current mean train loss 1865.424970928781
INFO:root:current train perplexity4.3612799644470215
INFO:root:current mean train loss 1866.5754230605137
INFO:root:current train perplexity4.362517833709717
INFO:root:current mean train loss 1865.6325214169706
INFO:root:current train perplexity4.360297679901123
INFO:root:current mean train loss 1868.4091068346029
INFO:root:current train perplexity4.362747669219971
INFO:root:current mean train loss 1868.498281022572
INFO:root:current train perplexity4.365018844604492
INFO:root:current mean train loss 1869.232471845774
INFO:root:current train perplexity4.367226600646973
INFO:root:current mean train loss 1870.172455003841
INFO:root:current train perplexity4.3693389892578125
INFO:root:current mean train loss 1871.0646974789104
INFO:root:current train perplexity4.370352268218994
INFO:root:current mean train loss 1871.5235721334102
INFO:root:current train perplexity4.370790481567383
INFO:root:current mean train loss 1870.6102014102846
INFO:root:current train perplexity4.369379043579102

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.84s/it]
INFO:root:final mean train loss: 1869.5645199158669
INFO:root:final train perplexity: 4.3686370849609375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.25s/it]
INFO:root:eval mean loss: 2046.2992289658134
INFO:root:eval perplexity: 5.232696056365967
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.38s/it]
INFO:root:eval mean loss: 2524.658640327183
INFO:root:eval perplexity: 7.883210182189941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [5:28:11<14:14:21, 353.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1885.8315106560203
INFO:root:current train perplexity4.363341331481934
INFO:root:current mean train loss 1883.1668792269122
INFO:root:current train perplexity4.357440948486328
INFO:root:current mean train loss 1870.3440311790532
INFO:root:current train perplexity4.345335960388184
INFO:root:current mean train loss 1864.013752280595
INFO:root:current train perplexity4.3393025398254395
INFO:root:current mean train loss 1866.9171887938328
INFO:root:current train perplexity4.343329906463623
INFO:root:current mean train loss 1866.014933039633
INFO:root:current train perplexity4.346450328826904
INFO:root:current mean train loss 1863.8149013579455
INFO:root:current train perplexity4.342823028564453
INFO:root:current mean train loss 1863.058261299653
INFO:root:current train perplexity4.34080696105957
INFO:root:current mean train loss 1863.8569277390588
INFO:root:current train perplexity4.347443580627441
INFO:root:current mean train loss 1864.0977346677596
INFO:root:current train perplexity4.351198196411133
INFO:root:current mean train loss 1863.3391537103707
INFO:root:current train perplexity4.349451541900635
INFO:root:current mean train loss 1864.0358135351219
INFO:root:current train perplexity4.346766471862793
INFO:root:current mean train loss 1863.2039719740808
INFO:root:current train perplexity4.344194412231445
INFO:root:current mean train loss 1865.5642865822947
INFO:root:current train perplexity4.347585201263428
INFO:root:current mean train loss 1864.872915440856
INFO:root:current train perplexity4.347806930541992
INFO:root:current mean train loss 1864.8349166134035
INFO:root:current train perplexity4.347607135772705
INFO:root:current mean train loss 1865.0341911922908
INFO:root:current train perplexity4.348233699798584
INFO:root:current mean train loss 1865.004502803534
INFO:root:current train perplexity4.350883960723877
INFO:root:current mean train loss 1866.159543302613
INFO:root:current train perplexity4.354264736175537
INFO:root:current mean train loss 1865.9387634971642
INFO:root:current train perplexity4.354199409484863

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:11<00:00, 311.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:11<00:00, 311.64s/it]
INFO:root:final mean train loss: 1865.5521075565648
INFO:root:final train perplexity: 4.35483455657959
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.49s/it]
INFO:root:eval mean loss: 2048.227908736425
INFO:root:eval perplexity: 5.240864276885986
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.37s/it]
INFO:root:eval mean loss: 2527.8568686627327
INFO:root:eval perplexity: 7.9038567543029785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [5:34:13<14:14:16, 355.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1837.3370816099878
INFO:root:current train perplexity4.292001247406006
INFO:root:current mean train loss 1829.4435703707056
INFO:root:current train perplexity4.26257848739624
INFO:root:current mean train loss 1846.6879226259027
INFO:root:current train perplexity4.301955223083496
INFO:root:current mean train loss 1848.8349508519186
INFO:root:current train perplexity4.306895732879639
INFO:root:current mean train loss 1849.176979217191
INFO:root:current train perplexity4.311220645904541
INFO:root:current mean train loss 1852.144679240869
INFO:root:current train perplexity4.320537090301514
INFO:root:current mean train loss 1854.6495665097566
INFO:root:current train perplexity4.325713634490967
INFO:root:current mean train loss 1855.526566953697
INFO:root:current train perplexity4.324079990386963
INFO:root:current mean train loss 1856.1437316966253
INFO:root:current train perplexity4.324203014373779
INFO:root:current mean train loss 1857.8721360327945
INFO:root:current train perplexity4.327552318572998
INFO:root:current mean train loss 1857.9237947908614
INFO:root:current train perplexity4.327404975891113
INFO:root:current mean train loss 1857.4712073146313
INFO:root:current train perplexity4.32513427734375
INFO:root:current mean train loss 1858.9580350368144
INFO:root:current train perplexity4.329803466796875
INFO:root:current mean train loss 1859.521144999653
INFO:root:current train perplexity4.330688953399658
INFO:root:current mean train loss 1860.2408506996792
INFO:root:current train perplexity4.330159664154053
INFO:root:current mean train loss 1861.6616654829545
INFO:root:current train perplexity4.333235740661621
INFO:root:current mean train loss 1862.0636954166037
INFO:root:current train perplexity4.334868431091309
INFO:root:current mean train loss 1860.4415180722622
INFO:root:current train perplexity4.335605144500732
INFO:root:current mean train loss 1860.207987698267
INFO:root:current train perplexity4.334929943084717
INFO:root:current mean train loss 1860.817582029248
INFO:root:current train perplexity4.3380351066589355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.91s/it]
INFO:root:final mean train loss: 1860.9445911586374
INFO:root:final train perplexity: 4.339039325714111
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.95s/it]
INFO:root:eval mean loss: 2050.5792180054577
INFO:root:eval perplexity: 5.250839710235596
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.64s/it]
INFO:root:eval mean loss: 2529.9316020992633
INFO:root:eval perplexity: 7.9172797203063965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [5:40:07<14:07:21, 355.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1875.1887943043428
INFO:root:current train perplexity4.312995910644531
INFO:root:current mean train loss 1856.6942894345239
INFO:root:current train perplexity4.302138805389404
INFO:root:current mean train loss 1854.5490084975513
INFO:root:current train perplexity4.2915215492248535
INFO:root:current mean train loss 1855.3853096340013
INFO:root:current train perplexity4.304276466369629
INFO:root:current mean train loss 1855.782919859275
INFO:root:current train perplexity4.309443950653076
INFO:root:current mean train loss 1857.2909447038678
INFO:root:current train perplexity4.310266971588135
INFO:root:current mean train loss 1854.7638637519883
INFO:root:current train perplexity4.305603981018066
INFO:root:current mean train loss 1854.282597064972
INFO:root:current train perplexity4.303978443145752
INFO:root:current mean train loss 1853.755867531772
INFO:root:current train perplexity4.3050127029418945
INFO:root:current mean train loss 1854.440667144523
INFO:root:current train perplexity4.308894634246826
INFO:root:current mean train loss 1854.9956941640332
INFO:root:current train perplexity4.3118720054626465
INFO:root:current mean train loss 1857.19144659173
INFO:root:current train perplexity4.31687593460083
INFO:root:current mean train loss 1858.5266048780375
INFO:root:current train perplexity4.319645881652832
INFO:root:current mean train loss 1856.9313339322632
INFO:root:current train perplexity4.32090425491333
INFO:root:current mean train loss 1857.3903159991273
INFO:root:current train perplexity4.320780277252197
INFO:root:current mean train loss 1857.5195525811644
INFO:root:current train perplexity4.321407794952393
INFO:root:current mean train loss 1857.1051805528234
INFO:root:current train perplexity4.320265293121338
INFO:root:current mean train loss 1856.9671873204848
INFO:root:current train perplexity4.3201775550842285
INFO:root:current mean train loss 1857.5019851455852
INFO:root:current train perplexity4.324033737182617
INFO:root:current mean train loss 1857.0809166760948
INFO:root:current train perplexity4.323701858520508

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.45s/it]
INFO:root:final mean train loss: 1856.5422805270582
INFO:root:final train perplexity: 4.324000358581543
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.25s/it]
INFO:root:eval mean loss: 2049.6351617042055
INFO:root:eval perplexity: 5.246832847595215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.56s/it]
INFO:root:eval mean loss: 2532.2821226728724
INFO:root:eval perplexity: 7.932512283325195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [5:46:01<13:59:51, 354.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1841.4937873391543
INFO:root:current train perplexity4.244579315185547
INFO:root:current mean train loss 1845.7686008762669
INFO:root:current train perplexity4.276092052459717
INFO:root:current mean train loss 1850.5976648163378
INFO:root:current train perplexity4.2740092277526855
INFO:root:current mean train loss 1847.0073296088676
INFO:root:current train perplexity4.281846046447754
INFO:root:current mean train loss 1848.459222978415
INFO:root:current train perplexity4.290402412414551
INFO:root:current mean train loss 1842.7404374081864
INFO:root:current train perplexity4.2817559242248535
INFO:root:current mean train loss 1842.5461755460196
INFO:root:current train perplexity4.282766819000244
INFO:root:current mean train loss 1845.0277318869428
INFO:root:current train perplexity4.287387847900391
INFO:root:current mean train loss 1845.2946872517214
INFO:root:current train perplexity4.28953742980957
INFO:root:current mean train loss 1847.2735454423778
INFO:root:current train perplexity4.292861461639404
INFO:root:current mean train loss 1848.7388472737255
INFO:root:current train perplexity4.297812461853027
INFO:root:current mean train loss 1848.8755453504089
INFO:root:current train perplexity4.297084808349609
INFO:root:current mean train loss 1849.4524215520123
INFO:root:current train perplexity4.297050476074219
INFO:root:current mean train loss 1849.9322307930956
INFO:root:current train perplexity4.301220893859863
INFO:root:current mean train loss 1850.2772558758154
INFO:root:current train perplexity4.302185535430908
INFO:root:current mean train loss 1849.9375789413693
INFO:root:current train perplexity4.303797721862793
INFO:root:current mean train loss 1850.072794475612
INFO:root:current train perplexity4.304012775421143
INFO:root:current mean train loss 1851.5401221523766
INFO:root:current train perplexity4.305265426635742
INFO:root:current mean train loss 1850.8086523567017
INFO:root:current train perplexity4.305461406707764

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:10<00:00, 310.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:10<00:00, 310.73s/it]
INFO:root:final mean train loss: 1851.5970482376567
INFO:root:final train perplexity: 4.307169437408447
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.82s/it]
INFO:root:eval mean loss: 2046.3795118399546
INFO:root:eval perplexity: 5.233035564422607
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.31s/it]
INFO:root:eval mean loss: 2528.1715100876827
INFO:root:eval perplexity: 7.905890464782715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [5:52:02<13:58:15, 356.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1807.0083618164062
INFO:root:current train perplexity4.335025310516357
INFO:root:current mean train loss 1829.7787008846508
INFO:root:current train perplexity4.258676528930664
INFO:root:current mean train loss 1838.2933675935953
INFO:root:current train perplexity4.293622970581055
INFO:root:current mean train loss 1841.6615932035131
INFO:root:current train perplexity4.2909626960754395
INFO:root:current mean train loss 1842.3139590742576
INFO:root:current train perplexity4.2823710441589355
INFO:root:current mean train loss 1840.3352179660264
INFO:root:current train perplexity4.276257514953613
INFO:root:current mean train loss 1840.4340652009578
INFO:root:current train perplexity4.2772417068481445
INFO:root:current mean train loss 1840.7262670620214
INFO:root:current train perplexity4.277834415435791
INFO:root:current mean train loss 1844.6821206870518
INFO:root:current train perplexity4.28181791305542
INFO:root:current mean train loss 1842.492112119552
INFO:root:current train perplexity4.277524948120117
INFO:root:current mean train loss 1842.897579962146
INFO:root:current train perplexity4.28190803527832
INFO:root:current mean train loss 1844.6494949257742
INFO:root:current train perplexity4.286428928375244
INFO:root:current mean train loss 1845.1836421922121
INFO:root:current train perplexity4.286555290222168
INFO:root:current mean train loss 1845.987043202015
INFO:root:current train perplexity4.2894721031188965
INFO:root:current mean train loss 1845.6352205589392
INFO:root:current train perplexity4.2868757247924805
INFO:root:current mean train loss 1845.719829859016
INFO:root:current train perplexity4.290057182312012
INFO:root:current mean train loss 1846.9754465700832
INFO:root:current train perplexity4.292025566101074
INFO:root:current mean train loss 1847.8377334827821
INFO:root:current train perplexity4.29304838180542
INFO:root:current mean train loss 1847.7311622882128
INFO:root:current train perplexity4.292685031890869
INFO:root:current mean train loss 1847.2425413242024
INFO:root:current train perplexity4.290749549865723

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.60s/it]
INFO:root:final mean train loss: 1847.0214359593162
INFO:root:final train perplexity: 4.291654109954834
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.15s/it]
INFO:root:eval mean loss: 2051.2025423523382
INFO:root:eval perplexity: 5.253487586975098
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.82s/it]
INFO:root:eval mean loss: 2534.3330736092644
INFO:root:eval perplexity: 7.945830345153809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [5:57:57<13:51:35, 356.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1858.423892372533
INFO:root:current train perplexity4.35175085067749
INFO:root:current mean train loss 1829.5538473690258
INFO:root:current train perplexity4.267838478088379
INFO:root:current mean train loss 1829.9607346068778
INFO:root:current train perplexity4.263967990875244
INFO:root:current mean train loss 1831.5874750502057
INFO:root:current train perplexity4.261202335357666
INFO:root:current mean train loss 1834.7719886797993
INFO:root:current train perplexity4.261888027191162
INFO:root:current mean train loss 1838.8456944224922
INFO:root:current train perplexity4.265839576721191
INFO:root:current mean train loss 1837.7650304248914
INFO:root:current train perplexity4.267726421356201
INFO:root:current mean train loss 1836.0882028465642
INFO:root:current train perplexity4.259400844573975
INFO:root:current mean train loss 1837.1756645454154
INFO:root:current train perplexity4.2641425132751465
INFO:root:current mean train loss 1839.0724056272952
INFO:root:current train perplexity4.266316890716553
INFO:root:current mean train loss 1838.9709579273108
INFO:root:current train perplexity4.267456531524658
INFO:root:current mean train loss 1840.0751158958892
INFO:root:current train perplexity4.268041610717773
INFO:root:current mean train loss 1841.7693456911081
INFO:root:current train perplexity4.271174907684326
INFO:root:current mean train loss 1842.0535959008066
INFO:root:current train perplexity4.270887851715088
INFO:root:current mean train loss 1842.5524600393928
INFO:root:current train perplexity4.271040916442871
INFO:root:current mean train loss 1842.6646663422173
INFO:root:current train perplexity4.27230978012085
INFO:root:current mean train loss 1842.6369074726636
INFO:root:current train perplexity4.272937297821045
INFO:root:current mean train loss 1842.8908709869474
INFO:root:current train perplexity4.273437023162842
INFO:root:current mean train loss 1843.8631462277522
INFO:root:current train perplexity4.277760982513428
INFO:root:current mean train loss 1843.7842730690627
INFO:root:current train perplexity4.279036045074463

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:13<00:00, 313.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:13<00:00, 313.05s/it]
INFO:root:final mean train loss: 1843.1588010417652
INFO:root:final train perplexity: 4.278600215911865
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.42s/it]
INFO:root:eval mean loss: 2047.1961972933289
INFO:root:eval perplexity: 5.236493110656738
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.33s/it]
INFO:root:eval mean loss: 2532.104585688165
INFO:root:eval perplexity: 7.931360721588135
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [6:04:00<13:50:08, 358.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1821.6958719889324
INFO:root:current train perplexity4.228640556335449
INFO:root:current mean train loss 1832.8866756663604
INFO:root:current train perplexity4.251256465911865
INFO:root:current mean train loss 1821.2652934446173
INFO:root:current train perplexity4.220820903778076
INFO:root:current mean train loss 1825.4499729701452
INFO:root:current train perplexity4.229024887084961
INFO:root:current mean train loss 1826.571165032343
INFO:root:current train perplexity4.230284214019775
INFO:root:current mean train loss 1825.7454874978137
INFO:root:current train perplexity4.234378814697266
INFO:root:current mean train loss 1830.5995606236488
INFO:root:current train perplexity4.239762306213379
INFO:root:current mean train loss 1831.587469018024
INFO:root:current train perplexity4.242110729217529
INFO:root:current mean train loss 1833.278149034418
INFO:root:current train perplexity4.244929313659668
INFO:root:current mean train loss 1833.2762918064736
INFO:root:current train perplexity4.245956897735596
INFO:root:current mean train loss 1836.3354427381832
INFO:root:current train perplexity4.25106143951416
INFO:root:current mean train loss 1837.3786625392001
INFO:root:current train perplexity4.251233100891113
INFO:root:current mean train loss 1837.0318753634456
INFO:root:current train perplexity4.249481201171875
INFO:root:current mean train loss 1836.9681848765847
INFO:root:current train perplexity4.251017093658447
INFO:root:current mean train loss 1837.0791518017443
INFO:root:current train perplexity4.252284526824951
INFO:root:current mean train loss 1836.975313981374
INFO:root:current train perplexity4.2548136711120605
INFO:root:current mean train loss 1837.9949701957423
INFO:root:current train perplexity4.257669448852539
INFO:root:current mean train loss 1838.4383684149536
INFO:root:current train perplexity4.258880138397217
INFO:root:current mean train loss 1838.7884658447797
INFO:root:current train perplexity4.260301113128662
INFO:root:current mean train loss 1839.228300425632
INFO:root:current train perplexity4.262097358703613

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.75s/it]
INFO:root:final mean train loss: 1838.710298185209
INFO:root:final train perplexity: 4.263615608215332
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.46s/it]
INFO:root:eval mean loss: 2046.4261162940493
INFO:root:eval perplexity: 5.233232498168945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.50s/it]
INFO:root:eval mean loss: 2532.070581747285
INFO:root:eval perplexity: 7.9311394691467285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [6:09:47<13:36:11, 354.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1812.9509668890034
INFO:root:current train perplexity4.2133026123046875
INFO:root:current mean train loss 1809.228076012306
INFO:root:current train perplexity4.20569372177124
INFO:root:current mean train loss 1818.962717410604
INFO:root:current train perplexity4.214386463165283
INFO:root:current mean train loss 1818.1041235559048
INFO:root:current train perplexity4.222592830657959
INFO:root:current mean train loss 1819.2418107796977
INFO:root:current train perplexity4.2248969078063965
INFO:root:current mean train loss 1822.7737939982906
INFO:root:current train perplexity4.228394508361816
INFO:root:current mean train loss 1822.2244132773617
INFO:root:current train perplexity4.227609634399414
INFO:root:current mean train loss 1824.6743305099913
INFO:root:current train perplexity4.22947359085083
INFO:root:current mean train loss 1824.406771052764
INFO:root:current train perplexity4.233471393585205
INFO:root:current mean train loss 1826.4619540267577
INFO:root:current train perplexity4.235756874084473
INFO:root:current mean train loss 1827.0284924629407
INFO:root:current train perplexity4.237120151519775
INFO:root:current mean train loss 1828.5029712951607
INFO:root:current train perplexity4.237124443054199
INFO:root:current mean train loss 1828.9246910929394
INFO:root:current train perplexity4.237551212310791
INFO:root:current mean train loss 1830.3967881523408
INFO:root:current train perplexity4.241303443908691
INFO:root:current mean train loss 1831.7388193507238
INFO:root:current train perplexity4.2428107261657715
INFO:root:current mean train loss 1833.3876291288534
INFO:root:current train perplexity4.246255874633789
INFO:root:current mean train loss 1833.5685278955402
INFO:root:current train perplexity4.243828773498535
INFO:root:current mean train loss 1833.7290800174032
INFO:root:current train perplexity4.244361877441406
INFO:root:current mean train loss 1834.3858826375304
INFO:root:current train perplexity4.246039390563965
INFO:root:current mean train loss 1834.2909455580157
INFO:root:current train perplexity4.248195171356201

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.35s/it]
INFO:root:final mean train loss: 1834.3101901132773
INFO:root:final train perplexity: 4.24884557723999
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.60s/it]
INFO:root:eval mean loss: 2050.101362512467
INFO:root:eval perplexity: 5.248812198638916
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.94s/it]
INFO:root:eval mean loss: 2537.093048745013
INFO:root:eval perplexity: 7.9637837409973145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [6:15:36<13:26:14, 353.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1815.8583949497768
INFO:root:current train perplexity4.197228908538818
INFO:root:current mean train loss 1824.733101160386
INFO:root:current train perplexity4.2177886962890625
INFO:root:current mean train loss 1830.1364348234954
INFO:root:current train perplexity4.2269158363342285
INFO:root:current mean train loss 1827.1684801256336
INFO:root:current train perplexity4.218067169189453
INFO:root:current mean train loss 1825.615223206865
INFO:root:current train perplexity4.221997261047363
INFO:root:current mean train loss 1826.944764682703
INFO:root:current train perplexity4.217787265777588
INFO:root:current mean train loss 1825.2698402518656
INFO:root:current train perplexity4.218618392944336
INFO:root:current mean train loss 1823.491992346033
INFO:root:current train perplexity4.217362403869629
INFO:root:current mean train loss 1823.125718250494
INFO:root:current train perplexity4.214981555938721
INFO:root:current mean train loss 1822.2387428519653
INFO:root:current train perplexity4.216370105743408
INFO:root:current mean train loss 1824.4596299786433
INFO:root:current train perplexity4.220466613769531
INFO:root:current mean train loss 1824.4059582832533
INFO:root:current train perplexity4.222508430480957
INFO:root:current mean train loss 1826.7211989996001
INFO:root:current train perplexity4.224142074584961
INFO:root:current mean train loss 1827.5254808857494
INFO:root:current train perplexity4.224508762359619
INFO:root:current mean train loss 1829.3556389010682
INFO:root:current train perplexity4.229116916656494
INFO:root:current mean train loss 1830.2504518156597
INFO:root:current train perplexity4.232532978057861
INFO:root:current mean train loss 1830.2676019542946
INFO:root:current train perplexity4.2332563400268555
INFO:root:current mean train loss 1831.9254113148834
INFO:root:current train perplexity4.237708568572998
INFO:root:current mean train loss 1832.1206112132354
INFO:root:current train perplexity4.239675521850586
INFO:root:current mean train loss 1831.8980056065593
INFO:root:current train perplexity4.23897647857666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.89s/it]
INFO:root:final mean train loss: 1831.2297273713775
INFO:root:final train perplexity: 4.2385358810424805
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.48s/it]
INFO:root:eval mean loss: 2049.3626098632812
INFO:root:eval perplexity: 5.245676517486572
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.40s/it]
INFO:root:eval mean loss: 2537.2034206525655
INFO:root:eval perplexity: 7.964505195617676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [6:21:33<13:22:55, 354.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1819.1165434738684
INFO:root:current train perplexity4.222076416015625
INFO:root:current mean train loss 1819.9253895805482
INFO:root:current train perplexity4.207284927368164
INFO:root:current mean train loss 1824.4767696367323
INFO:root:current train perplexity4.204613208770752
INFO:root:current mean train loss 1823.173249316154
INFO:root:current train perplexity4.199363708496094
INFO:root:current mean train loss 1825.795091820938
INFO:root:current train perplexity4.208598613739014
INFO:root:current mean train loss 1825.3421354277577
INFO:root:current train perplexity4.208992004394531
INFO:root:current mean train loss 1825.3032738298307
INFO:root:current train perplexity4.206693649291992
INFO:root:current mean train loss 1824.6582592742416
INFO:root:current train perplexity4.208230018615723
INFO:root:current mean train loss 1823.8235693139181
INFO:root:current train perplexity4.2122483253479
INFO:root:current mean train loss 1824.6609544686391
INFO:root:current train perplexity4.215198516845703
INFO:root:current mean train loss 1823.9406486728813
INFO:root:current train perplexity4.213632583618164
INFO:root:current mean train loss 1824.390734421072
INFO:root:current train perplexity4.213128089904785
INFO:root:current mean train loss 1823.814999263974
INFO:root:current train perplexity4.212265491485596
INFO:root:current mean train loss 1822.9966045618917
INFO:root:current train perplexity4.210690498352051
INFO:root:current mean train loss 1823.8001141730938
INFO:root:current train perplexity4.213475227355957
INFO:root:current mean train loss 1825.1340763546343
INFO:root:current train perplexity4.2170209884643555
INFO:root:current mean train loss 1825.2971331059898
INFO:root:current train perplexity4.218267917633057
INFO:root:current mean train loss 1824.881022226497
INFO:root:current train perplexity4.2186408042907715
INFO:root:current mean train loss 1825.300829120711
INFO:root:current train perplexity4.219102382659912

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.03s/it]
INFO:root:final mean train loss: 1826.340574940707
INFO:root:final train perplexity: 4.22222375869751
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.11s/it]
INFO:root:eval mean loss: 2047.4885868586548
INFO:root:eval perplexity: 5.237732410430908
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.85s/it]
INFO:root:eval mean loss: 2534.069769243822
INFO:root:eval perplexity: 7.944119930267334
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [6:27:24<13:14:53, 353.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1810.5194396972656
INFO:root:current train perplexity4.244077682495117
INFO:root:current mean train loss 1814.3579817551833
INFO:root:current train perplexity4.200723648071289
INFO:root:current mean train loss 1812.65005792356
INFO:root:current train perplexity4.200132369995117
INFO:root:current mean train loss 1810.274822837428
INFO:root:current train perplexity4.176661491394043
INFO:root:current mean train loss 1809.7879327453009
INFO:root:current train perplexity4.18046236038208
INFO:root:current mean train loss 1812.9237060546875
INFO:root:current train perplexity4.195477485656738
INFO:root:current mean train loss 1814.7409762957238
INFO:root:current train perplexity4.195178508758545
INFO:root:current mean train loss 1813.7939543290572
INFO:root:current train perplexity4.198050022125244
INFO:root:current mean train loss 1816.6609943446829
INFO:root:current train perplexity4.199050426483154
INFO:root:current mean train loss 1816.7560769140193
INFO:root:current train perplexity4.2020111083984375
INFO:root:current mean train loss 1816.7814617992872
INFO:root:current train perplexity4.202757835388184
INFO:root:current mean train loss 1816.4511476599653
INFO:root:current train perplexity4.2061767578125
INFO:root:current mean train loss 1820.5037885393415
INFO:root:current train perplexity4.211871147155762
INFO:root:current mean train loss 1821.3353464325512
INFO:root:current train perplexity4.211101531982422
INFO:root:current mean train loss 1820.3272640739071
INFO:root:current train perplexity4.20954704284668
INFO:root:current mean train loss 1821.6106162375593
INFO:root:current train perplexity4.210655689239502
INFO:root:current mean train loss 1821.8138669744096
INFO:root:current train perplexity4.212455749511719
INFO:root:current mean train loss 1822.4900948251357
INFO:root:current train perplexity4.211902618408203
INFO:root:current mean train loss 1823.1439315220734
INFO:root:current train perplexity4.2126145362854
INFO:root:current mean train loss 1823.0678198678154
INFO:root:current train perplexity4.212201118469238

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:08<00:00, 308.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:08<00:00, 308.99s/it]
INFO:root:final mean train loss: 1823.3299991455694
INFO:root:final train perplexity: 4.212211608886719
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it]
INFO:root:eval mean loss: 2050.2253625748003
INFO:root:eval perplexity: 5.249337673187256
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.65s/it]
INFO:root:eval mean loss: 2541.0272359645114
INFO:root:eval perplexity: 7.989449977874756
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [6:33:27<13:15:44, 356.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1795.2225167410713
INFO:root:current train perplexity4.192673683166504
INFO:root:current mean train loss 1809.4527668598269
INFO:root:current train perplexity4.168564319610596
INFO:root:current mean train loss 1808.5960975060095
INFO:root:current train perplexity4.143638610839844
INFO:root:current mean train loss 1806.8475083205558
INFO:root:current train perplexity4.149466514587402
INFO:root:current mean train loss 1808.481881982074
INFO:root:current train perplexity4.162191390991211
INFO:root:current mean train loss 1810.4426292961252
INFO:root:current train perplexity4.165737152099609
INFO:root:current mean train loss 1809.8998172287013
INFO:root:current train perplexity4.170094966888428
INFO:root:current mean train loss 1814.0477714803117
INFO:root:current train perplexity4.1738409996032715
INFO:root:current mean train loss 1815.159501441649
INFO:root:current train perplexity4.172135353088379
INFO:root:current mean train loss 1814.3958814457367
INFO:root:current train perplexity4.172250270843506
INFO:root:current mean train loss 1816.3880837615159
INFO:root:current train perplexity4.1790385246276855
INFO:root:current mean train loss 1816.0274369633698
INFO:root:current train perplexity4.182254314422607
INFO:root:current mean train loss 1816.1350395583795
INFO:root:current train perplexity4.179466247558594
INFO:root:current mean train loss 1815.161693910863
INFO:root:current train perplexity4.18136739730835
INFO:root:current mean train loss 1816.4225783002453
INFO:root:current train perplexity4.184447765350342
INFO:root:current mean train loss 1816.5730791863134
INFO:root:current train perplexity4.1869049072265625
INFO:root:current mean train loss 1816.927199027775
INFO:root:current train perplexity4.187348365783691
INFO:root:current mean train loss 1817.4356134781513
INFO:root:current train perplexity4.190122127532959
INFO:root:current mean train loss 1818.3939955751691
INFO:root:current train perplexity4.1921234130859375
INFO:root:current mean train loss 1818.579327084384
INFO:root:current train perplexity4.194028377532959

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.65s/it]
INFO:root:final mean train loss: 1818.1965665677792
INFO:root:final train perplexity: 4.195192337036133
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.75s/it]
INFO:root:eval mean loss: 2046.0870889433731
INFO:root:eval perplexity: 5.23179817199707
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.08s/it]
INFO:root:eval mean loss: 2535.399250003463
INFO:root:eval perplexity: 7.952761650085449
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [6:39:24<13:09:58, 356.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1820.090386641653
INFO:root:current train perplexity4.200459957122803
INFO:root:current mean train loss 1803.665793598562
INFO:root:current train perplexity4.158970832824707
INFO:root:current mean train loss 1805.1604603999804
INFO:root:current train perplexity4.159715175628662
INFO:root:current mean train loss 1805.8642235027967
INFO:root:current train perplexity4.157792568206787
INFO:root:current mean train loss 1807.0168033408247
INFO:root:current train perplexity4.164290904998779
INFO:root:current mean train loss 1807.4003824567262
INFO:root:current train perplexity4.165087699890137
INFO:root:current mean train loss 1809.549485544426
INFO:root:current train perplexity4.1671576499938965
INFO:root:current mean train loss 1809.215512324801
INFO:root:current train perplexity4.168578624725342
INFO:root:current mean train loss 1807.648740345083
INFO:root:current train perplexity4.165652751922607
INFO:root:current mean train loss 1808.137024446337
INFO:root:current train perplexity4.169477462768555
INFO:root:current mean train loss 1807.838768402276
INFO:root:current train perplexity4.16937255859375
INFO:root:current mean train loss 1809.6407133883458
INFO:root:current train perplexity4.172629356384277
INFO:root:current mean train loss 1809.8069385041713
INFO:root:current train perplexity4.17130708694458
INFO:root:current mean train loss 1810.5998008739432
INFO:root:current train perplexity4.170726776123047
INFO:root:current mean train loss 1811.8772713736798
INFO:root:current train perplexity4.173713684082031
INFO:root:current mean train loss 1812.3906143644851
INFO:root:current train perplexity4.173757553100586
INFO:root:current mean train loss 1813.3669859871031
INFO:root:current train perplexity4.176835060119629
INFO:root:current mean train loss 1814.3651793801469
INFO:root:current train perplexity4.17832088470459
INFO:root:current mean train loss 1815.095688181681
INFO:root:current train perplexity4.181513786315918
INFO:root:current mean train loss 1814.5744939435992
INFO:root:current train perplexity4.183316230773926

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.63s/it]
INFO:root:final mean train loss: 1814.5606617122003
INFO:root:final train perplexity: 4.183180332183838
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.01s/it]
INFO:root:eval mean loss: 2050.56045900169
INFO:root:eval perplexity: 5.250761032104492
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.21s/it]
INFO:root:eval mean loss: 2542.0053503158247
INFO:root:eval perplexity: 7.995842933654785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [6:45:21<13:04:21, 356.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1793.2921963778408
INFO:root:current train perplexity4.113475322723389
INFO:root:current mean train loss 1802.5584968813005
INFO:root:current train perplexity4.1379313468933105
INFO:root:current mean train loss 1805.5248611749387
INFO:root:current train perplexity4.160407066345215
INFO:root:current mean train loss 1805.302060409331
INFO:root:current train perplexity4.152739524841309
INFO:root:current mean train loss 1805.662449830443
INFO:root:current train perplexity4.151905536651611
INFO:root:current mean train loss 1809.6954992345861
INFO:root:current train perplexity4.165286064147949
INFO:root:current mean train loss 1809.3986930090052
INFO:root:current train perplexity4.166431427001953
INFO:root:current mean train loss 1808.7731259377588
INFO:root:current train perplexity4.170357704162598
INFO:root:current mean train loss 1807.382711988304
INFO:root:current train perplexity4.165873050689697
INFO:root:current mean train loss 1808.9236766555546
INFO:root:current train perplexity4.166658878326416
INFO:root:current mean train loss 1807.2646911331829
INFO:root:current train perplexity4.1657891273498535
INFO:root:current mean train loss 1806.1601325757576
INFO:root:current train perplexity4.161952018737793
INFO:root:current mean train loss 1806.699458610869
INFO:root:current train perplexity4.1626057624816895
INFO:root:current mean train loss 1807.8326443042263
INFO:root:current train perplexity4.166467666625977
INFO:root:current mean train loss 1807.6813204735824
INFO:root:current train perplexity4.166374683380127
INFO:root:current mean train loss 1807.9593597706491
INFO:root:current train perplexity4.168059825897217
INFO:root:current mean train loss 1809.0674996459593
INFO:root:current train perplexity4.168637275695801
INFO:root:current mean train loss 1810.0479501229745
INFO:root:current train perplexity4.17087459564209
INFO:root:current mean train loss 1810.6673885376306
INFO:root:current train perplexity4.172474384307861
INFO:root:current mean train loss 1811.461426905171
INFO:root:current train perplexity4.1725850105285645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.19s/it]
INFO:root:final mean train loss: 1811.155150043682
INFO:root:final train perplexity: 4.171959400177002
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.90s/it]
INFO:root:eval mean loss: 2056.561606982076
INFO:root:eval perplexity: 5.27630615234375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.96s/it]
INFO:root:eval mean loss: 2551.351277669271
INFO:root:eval perplexity: 8.0571928024292
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [6:51:11<12:54:12, 354.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1794.721193101671
INFO:root:current train perplexity4.134536266326904
INFO:root:current mean train loss 1783.7037041242731
INFO:root:current train perplexity4.107395172119141
INFO:root:current mean train loss 1788.6950921451344
INFO:root:current train perplexity4.120165824890137
INFO:root:current mean train loss 1795.0315299085391
INFO:root:current train perplexity4.130072593688965
INFO:root:current mean train loss 1796.9382926811606
INFO:root:current train perplexity4.133476734161377
INFO:root:current mean train loss 1795.518997725907
INFO:root:current train perplexity4.136896133422852
INFO:root:current mean train loss 1798.7813967750185
INFO:root:current train perplexity4.143982887268066
INFO:root:current mean train loss 1798.386318700919
INFO:root:current train perplexity4.145548343658447
INFO:root:current mean train loss 1796.4733468151967
INFO:root:current train perplexity4.140774250030518
INFO:root:current mean train loss 1799.8574540252057
INFO:root:current train perplexity4.1444315910339355
INFO:root:current mean train loss 1802.9460634829393
INFO:root:current train perplexity4.146187782287598
INFO:root:current mean train loss 1802.8523330428088
INFO:root:current train perplexity4.147821426391602
INFO:root:current mean train loss 1804.0681259827045
INFO:root:current train perplexity4.151897430419922
INFO:root:current mean train loss 1805.823164781398
INFO:root:current train perplexity4.154834747314453
INFO:root:current mean train loss 1806.5749801967454
INFO:root:current train perplexity4.156839847564697
INFO:root:current mean train loss 1806.5373093311416
INFO:root:current train perplexity4.156125068664551
INFO:root:current mean train loss 1807.575219697359
INFO:root:current train perplexity4.1580705642700195
INFO:root:current mean train loss 1807.8245305390712
INFO:root:current train perplexity4.157529830932617
INFO:root:current mean train loss 1807.5695754483215
INFO:root:current train perplexity4.157554626464844
INFO:root:current mean train loss 1807.9224502532525
INFO:root:current train perplexity4.15985107421875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.36s/it]
INFO:root:final mean train loss: 1807.5482132181157
INFO:root:final train perplexity: 4.160109043121338
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.77s/it]
INFO:root:eval mean loss: 2052.2917683919272
INFO:root:eval perplexity: 5.258118152618408
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.84s/it]
INFO:root:eval mean loss: 2544.4951414284133
INFO:root:eval perplexity: 8.012142181396484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [6:57:07<12:49:15, 355.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1782.2966198867625
INFO:root:current train perplexity4.090295791625977
INFO:root:current mean train loss 1796.7733199508102
INFO:root:current train perplexity4.126492500305176
INFO:root:current mean train loss 1801.8586079422578
INFO:root:current train perplexity4.135443687438965
INFO:root:current mean train loss 1803.671278769682
INFO:root:current train perplexity4.139158248901367
INFO:root:current mean train loss 1802.004644163791
INFO:root:current train perplexity4.142614841461182
INFO:root:current mean train loss 1801.1633209591203
INFO:root:current train perplexity4.144956111907959
INFO:root:current mean train loss 1804.3766457345905
INFO:root:current train perplexity4.144233703613281
INFO:root:current mean train loss 1803.9679932878346
INFO:root:current train perplexity4.144636154174805
INFO:root:current mean train loss 1803.9227732946956
INFO:root:current train perplexity4.146133899688721
INFO:root:current mean train loss 1805.107035298439
INFO:root:current train perplexity4.147012710571289
INFO:root:current mean train loss 1804.547735433167
INFO:root:current train perplexity4.1479716300964355
INFO:root:current mean train loss 1805.842248709689
INFO:root:current train perplexity4.1492109298706055
INFO:root:current mean train loss 1804.7083137932445
INFO:root:current train perplexity4.146266460418701
INFO:root:current mean train loss 1804.0216022269
INFO:root:current train perplexity4.14662504196167
INFO:root:current mean train loss 1804.2066191294755
INFO:root:current train perplexity4.148707389831543
INFO:root:current mean train loss 1805.5238236846828
INFO:root:current train perplexity4.148552417755127
INFO:root:current mean train loss 1804.9603820764644
INFO:root:current train perplexity4.147690296173096
INFO:root:current mean train loss 1803.831150078387
INFO:root:current train perplexity4.144665241241455
INFO:root:current mean train loss 1804.3504201829464
INFO:root:current train perplexity4.145782947540283

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.40s/it]
INFO:root:final mean train loss: 1803.5982535819603
INFO:root:final train perplexity: 4.147169589996338
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.17s/it]
INFO:root:eval mean loss: 2048.0236080521386
INFO:root:eval perplexity: 5.239998817443848
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.77s/it]
INFO:root:eval mean loss: 2539.563244109458
INFO:root:eval perplexity: 7.979891300201416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [7:02:58<12:41:00, 353.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1790.132568359375
INFO:root:current train perplexity4.023677825927734
INFO:root:current mean train loss 1780.0609672114533
INFO:root:current train perplexity4.072817802429199
INFO:root:current mean train loss 1779.6180870278367
INFO:root:current train perplexity4.095887660980225
INFO:root:current mean train loss 1778.8120563980801
INFO:root:current train perplexity4.094670295715332
INFO:root:current mean train loss 1778.5813899298607
INFO:root:current train perplexity4.104610443115234
INFO:root:current mean train loss 1784.1003630264945
INFO:root:current train perplexity4.107173919677734
INFO:root:current mean train loss 1785.724607964947
INFO:root:current train perplexity4.109104633331299
INFO:root:current mean train loss 1790.221700435995
INFO:root:current train perplexity4.115567684173584
INFO:root:current mean train loss 1792.1484697592762
INFO:root:current train perplexity4.117759704589844
INFO:root:current mean train loss 1794.611754832152
INFO:root:current train perplexity4.121887683868408
INFO:root:current mean train loss 1793.68612701234
INFO:root:current train perplexity4.120778560638428
INFO:root:current mean train loss 1796.3780058434816
INFO:root:current train perplexity4.127439498901367
INFO:root:current mean train loss 1797.8323421952737
INFO:root:current train perplexity4.127403736114502
INFO:root:current mean train loss 1797.6033540173657
INFO:root:current train perplexity4.128212928771973
INFO:root:current mean train loss 1797.4737484580592
INFO:root:current train perplexity4.128283977508545
INFO:root:current mean train loss 1797.958251304677
INFO:root:current train perplexity4.130800247192383
INFO:root:current mean train loss 1798.4530208677907
INFO:root:current train perplexity4.132174015045166
INFO:root:current mean train loss 1799.8749117745044
INFO:root:current train perplexity4.133486747741699
INFO:root:current mean train loss 1799.2225674347228
INFO:root:current train perplexity4.132255554199219
INFO:root:current mean train loss 1799.7967223800867
INFO:root:current train perplexity4.134706974029541

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.61s/it]
INFO:root:final mean train loss: 1800.415397547858
INFO:root:final train perplexity: 4.136772155761719
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.69s/it]
INFO:root:eval mean loss: 2050.045198914007
INFO:root:eval perplexity: 5.248573303222656
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.09s/it]
INFO:root:eval mean loss: 2541.781746072972
INFO:root:eval perplexity: 7.994382858276367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [7:08:46<12:30:58, 352.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1793.9667650305707
INFO:root:current train perplexity4.04355001449585
INFO:root:current mean train loss 1790.530006470719
INFO:root:current train perplexity4.095887660980225
INFO:root:current mean train loss 1791.2955398901695
INFO:root:current train perplexity4.11611795425415
INFO:root:current mean train loss 1793.804117208664
INFO:root:current train perplexity4.11909294128418
INFO:root:current mean train loss 1788.0025325982565
INFO:root:current train perplexity4.102933406829834
INFO:root:current mean train loss 1787.1072661945059
INFO:root:current train perplexity4.1018757820129395
INFO:root:current mean train loss 1788.9526794335625
INFO:root:current train perplexity4.099948883056641
INFO:root:current mean train loss 1786.5286659251276
INFO:root:current train perplexity4.092422008514404
INFO:root:current mean train loss 1788.8307025673032
INFO:root:current train perplexity4.0984625816345215
INFO:root:current mean train loss 1790.0165009173127
INFO:root:current train perplexity4.101442813873291
INFO:root:current mean train loss 1789.9215233468124
INFO:root:current train perplexity4.100788593292236
INFO:root:current mean train loss 1788.5798293102669
INFO:root:current train perplexity4.100808620452881
INFO:root:current mean train loss 1788.9259752849039
INFO:root:current train perplexity4.100260257720947
INFO:root:current mean train loss 1790.3430621434773
INFO:root:current train perplexity4.1060309410095215
INFO:root:current mean train loss 1790.7569294418154
INFO:root:current train perplexity4.1086745262146
INFO:root:current mean train loss 1792.3059687172984
INFO:root:current train perplexity4.109858989715576
INFO:root:current mean train loss 1793.4614985119906
INFO:root:current train perplexity4.114182949066162
INFO:root:current mean train loss 1794.5125546092843
INFO:root:current train perplexity4.116590976715088
INFO:root:current mean train loss 1795.875638810083
INFO:root:current train perplexity4.118546962738037
INFO:root:current mean train loss 1796.4809164046248
INFO:root:current train perplexity4.122489929199219

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.46s/it]
INFO:root:final mean train loss: 1796.4324271874902
INFO:root:final train perplexity: 4.123798370361328
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.12s/it]
INFO:root:eval mean loss: 2056.611683081228
INFO:root:eval perplexity: 5.276519775390625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.47s/it]
INFO:root:eval mean loss: 2550.193212630901
INFO:root:eval perplexity: 8.049566268920898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [7:14:35<12:23:14, 351.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1785.252621459961
INFO:root:current train perplexity4.069869518280029
INFO:root:current mean train loss 1779.02299281529
INFO:root:current train perplexity4.06644868850708
INFO:root:current mean train loss 1784.4933975219726
INFO:root:current train perplexity4.076268672943115
INFO:root:current mean train loss 1789.5328893324909
INFO:root:current train perplexity4.0784406661987305
INFO:root:current mean train loss 1786.1177520751953
INFO:root:current train perplexity4.077940464019775
INFO:root:current mean train loss 1789.0512539333768
INFO:root:current train perplexity4.077917098999023
INFO:root:current mean train loss 1792.294201850891
INFO:root:current train perplexity4.085718154907227
INFO:root:current mean train loss 1790.9025803024704
INFO:root:current train perplexity4.091876029968262
INFO:root:current mean train loss 1790.7694863455636
INFO:root:current train perplexity4.095843315124512
INFO:root:current mean train loss 1792.2506452844498
INFO:root:current train perplexity4.097787380218506
INFO:root:current mean train loss 1791.7087952833908
INFO:root:current train perplexity4.098526954650879
INFO:root:current mean train loss 1790.0188827782347
INFO:root:current train perplexity4.099935531616211
INFO:root:current mean train loss 1791.0863911290323
INFO:root:current train perplexity4.101051330566406
INFO:root:current mean train loss 1791.851423394502
INFO:root:current train perplexity4.105642795562744
INFO:root:current mean train loss 1791.3691434224447
INFO:root:current train perplexity4.105161190032959
INFO:root:current mean train loss 1792.0191057477678
INFO:root:current train perplexity4.107965469360352
INFO:root:current mean train loss 1792.8618618104515
INFO:root:current train perplexity4.110070705413818
INFO:root:current mean train loss 1792.2594129540455
INFO:root:current train perplexity4.110163688659668
INFO:root:current mean train loss 1792.8051196554434
INFO:root:current train perplexity4.11100435256958
INFO:root:current mean train loss 1792.7937985764336
INFO:root:current train perplexity4.111204147338867

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.85s/it]
INFO:root:final mean train loss: 1793.1435208611576
INFO:root:final train perplexity: 4.113115310668945
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.58s/it]
INFO:root:eval mean loss: 2051.949034345911
INFO:root:eval perplexity: 5.256660461425781
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.30s/it]
INFO:root:eval mean loss: 2547.2570562700853
INFO:root:eval perplexity: 8.03026008605957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [7:20:25<12:16:35, 350.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1795.6810559724506
INFO:root:current train perplexity4.085435390472412
INFO:root:current mean train loss 1801.5096855406548
INFO:root:current train perplexity4.100384712219238
INFO:root:current mean train loss 1793.7339988144456
INFO:root:current train perplexity4.090241432189941
INFO:root:current mean train loss 1791.8151852049414
INFO:root:current train perplexity4.087071418762207
INFO:root:current mean train loss 1791.5432179657582
INFO:root:current train perplexity4.0914788246154785
INFO:root:current mean train loss 1791.0372669487067
INFO:root:current train perplexity4.087001800537109
INFO:root:current mean train loss 1790.8505281538362
INFO:root:current train perplexity4.090304374694824
INFO:root:current mean train loss 1788.9464833752168
INFO:root:current train perplexity4.085217475891113
INFO:root:current mean train loss 1788.1052211908366
INFO:root:current train perplexity4.083845615386963
INFO:root:current mean train loss 1787.4894766971984
INFO:root:current train perplexity4.085472106933594
INFO:root:current mean train loss 1789.6765938202163
INFO:root:current train perplexity4.0901055335998535
INFO:root:current mean train loss 1789.800784098659
INFO:root:current train perplexity4.088540077209473
INFO:root:current mean train loss 1790.026975791039
INFO:root:current train perplexity4.092820644378662
INFO:root:current mean train loss 1790.2318069356807
INFO:root:current train perplexity4.09402322769165
INFO:root:current mean train loss 1790.6886004760156
INFO:root:current train perplexity4.0974016189575195
INFO:root:current mean train loss 1791.0375074167318
INFO:root:current train perplexity4.098479270935059
INFO:root:current mean train loss 1790.7692101247785
INFO:root:current train perplexity4.097183704376221
INFO:root:current mean train loss 1789.73373755258
INFO:root:current train perplexity4.096465110778809
INFO:root:current mean train loss 1789.8455905862952
INFO:root:current train perplexity4.099019527435303
INFO:root:current mean train loss 1789.4740805491904
INFO:root:current train perplexity4.098833084106445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.16s/it]
INFO:root:final mean train loss: 1789.3153370113248
INFO:root:final train perplexity: 4.100715637207031
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.14s/it]
INFO:root:eval mean loss: 2051.6392869881706
INFO:root:eval perplexity: 5.255344390869141
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.67s/it]
INFO:root:eval mean loss: 2547.642531807541
INFO:root:eval perplexity: 8.032791137695312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [7:26:14<12:09:40, 350.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1779.2897800754856
INFO:root:current train perplexity4.054004192352295
INFO:root:current mean train loss 1783.613162687455
INFO:root:current train perplexity4.056523323059082
INFO:root:current mean train loss 1781.146065593636
INFO:root:current train perplexity4.0641279220581055
INFO:root:current mean train loss 1779.363460112383
INFO:root:current train perplexity4.05711555480957
INFO:root:current mean train loss 1778.629809415793
INFO:root:current train perplexity4.066829204559326
INFO:root:current mean train loss 1776.5557274369828
INFO:root:current train perplexity4.070191860198975
INFO:root:current mean train loss 1779.6027922587862
INFO:root:current train perplexity4.071899890899658
INFO:root:current mean train loss 1780.137912641816
INFO:root:current train perplexity4.071273326873779
INFO:root:current mean train loss 1780.5823710635816
INFO:root:current train perplexity4.072284698486328
INFO:root:current mean train loss 1783.8985309953318
INFO:root:current train perplexity4.0833611488342285
INFO:root:current mean train loss 1784.1612780693522
INFO:root:current train perplexity4.083934783935547
INFO:root:current mean train loss 1782.8123689875692
INFO:root:current train perplexity4.080246925354004
INFO:root:current mean train loss 1783.945007707485
INFO:root:current train perplexity4.081913471221924
INFO:root:current mean train loss 1784.5813009603576
INFO:root:current train perplexity4.082895755767822
INFO:root:current mean train loss 1785.2372248531844
INFO:root:current train perplexity4.0852179527282715
INFO:root:current mean train loss 1785.2239545848802
INFO:root:current train perplexity4.087707996368408
INFO:root:current mean train loss 1785.581996904052
INFO:root:current train perplexity4.087703704833984
INFO:root:current mean train loss 1785.3412993042955
INFO:root:current train perplexity4.089409351348877
INFO:root:current mean train loss 1786.3429910665898
INFO:root:current train perplexity4.09094762802124
INFO:root:current mean train loss 1786.556505692162
INFO:root:current train perplexity4.090059280395508

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.41s/it]
INFO:root:final mean train loss: 1786.0792131063256
INFO:root:final train perplexity: 4.090263843536377
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.61s/it]
INFO:root:eval mean loss: 2058.2151199232603
INFO:root:eval perplexity: 5.2833662033081055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.45s/it]
INFO:root:eval mean loss: 2555.760569470994
INFO:root:eval perplexity: 8.086298942565918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [7:32:09<12:07:05, 351.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1771.9995653760302
INFO:root:current train perplexity4.041111946105957
INFO:root:current mean train loss 1769.1409650073626
INFO:root:current train perplexity4.04176139831543
INFO:root:current mean train loss 1770.6938484952211
INFO:root:current train perplexity4.042911052703857
INFO:root:current mean train loss 1772.3198139161404
INFO:root:current train perplexity4.052536487579346
INFO:root:current mean train loss 1774.8086131420253
INFO:root:current train perplexity4.054541110992432
INFO:root:current mean train loss 1771.3973120158498
INFO:root:current train perplexity4.047040939331055
INFO:root:current mean train loss 1773.218319839058
INFO:root:current train perplexity4.051130771636963
INFO:root:current mean train loss 1773.1214446828578
INFO:root:current train perplexity4.05163049697876
INFO:root:current mean train loss 1774.8958562129542
INFO:root:current train perplexity4.05893087387085
INFO:root:current mean train loss 1777.187621331239
INFO:root:current train perplexity4.0634565353393555
INFO:root:current mean train loss 1775.6197688787165
INFO:root:current train perplexity4.06185245513916
INFO:root:current mean train loss 1776.9473000629723
INFO:root:current train perplexity4.063529968261719
INFO:root:current mean train loss 1777.3979757886632
INFO:root:current train perplexity4.063505172729492
INFO:root:current mean train loss 1777.712274130431
INFO:root:current train perplexity4.065659999847412
INFO:root:current mean train loss 1779.006215352008
INFO:root:current train perplexity4.069181442260742
INFO:root:current mean train loss 1780.4761238601657
INFO:root:current train perplexity4.071604251861572
INFO:root:current mean train loss 1779.8922656221125
INFO:root:current train perplexity4.073074817657471
INFO:root:current mean train loss 1780.8452685519612
INFO:root:current train perplexity4.07601261138916
INFO:root:current mean train loss 1781.4790083604285
INFO:root:current train perplexity4.076046943664551

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.53s/it]
INFO:root:final mean train loss: 1782.4262405988006
INFO:root:final train perplexity: 4.078496932983398
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.24s/it]
INFO:root:eval mean loss: 2052.890832779255
INFO:root:eval perplexity: 5.260666370391846
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.44s/it]
INFO:root:eval mean loss: 2551.9491317424367
INFO:root:eval perplexity: 8.061132431030273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [7:38:00<12:00:53, 351.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1706.4408264160156
INFO:root:current train perplexity3.9640748500823975
INFO:root:current mean train loss 1783.9839059335213
INFO:root:current train perplexity4.073100566864014
INFO:root:current mean train loss 1777.9419373732346
INFO:root:current train perplexity4.064237594604492
INFO:root:current mean train loss 1779.2010196834415
INFO:root:current train perplexity4.056581020355225
INFO:root:current mean train loss 1779.512804816751
INFO:root:current train perplexity4.054815769195557
INFO:root:current mean train loss 1780.3304414523868
INFO:root:current train perplexity4.051904201507568
INFO:root:current mean train loss 1777.5626315066688
INFO:root:current train perplexity4.051857948303223
INFO:root:current mean train loss 1778.6963633736648
INFO:root:current train perplexity4.057417869567871
INFO:root:current mean train loss 1777.9221983050356
INFO:root:current train perplexity4.056700706481934
INFO:root:current mean train loss 1777.950583705818
INFO:root:current train perplexity4.059553146362305
INFO:root:current mean train loss 1778.4075765458365
INFO:root:current train perplexity4.06101131439209
INFO:root:current mean train loss 1778.514938409578
INFO:root:current train perplexity4.0640387535095215
INFO:root:current mean train loss 1778.2145151302514
INFO:root:current train perplexity4.064568996429443
INFO:root:current mean train loss 1777.6364903814567
INFO:root:current train perplexity4.064927101135254
INFO:root:current mean train loss 1777.916833790866
INFO:root:current train perplexity4.06586217880249
INFO:root:current mean train loss 1778.0107534393392
INFO:root:current train perplexity4.065898895263672
INFO:root:current mean train loss 1778.5521390544834
INFO:root:current train perplexity4.068063735961914
INFO:root:current mean train loss 1778.5296904588472
INFO:root:current train perplexity4.068160533905029
INFO:root:current mean train loss 1779.169995400758
INFO:root:current train perplexity4.067974090576172
INFO:root:current mean train loss 1779.6216205460971
INFO:root:current train perplexity4.0690016746521

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:08<00:00, 308.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:08<00:00, 308.40s/it]
INFO:root:final mean train loss: 1779.5392994998504
INFO:root:final train perplexity: 4.0692219734191895
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.56s/it]
INFO:root:eval mean loss: 2054.2693819086603
INFO:root:eval perplexity: 5.266534328460693
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:23<00:00, 23.82s/it]
INFO:root:eval mean loss: 2554.3313620276485
INFO:root:eval perplexity: 8.076855659484863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [7:43:59<11:58:57, 353.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1768.4684521484376
INFO:root:current train perplexity4.024526119232178
INFO:root:current mean train loss 1781.2337021484375
INFO:root:current train perplexity4.03786039352417
INFO:root:current mean train loss 1778.067980143229
INFO:root:current train perplexity4.043221473693848
INFO:root:current mean train loss 1776.6529642427884
INFO:root:current train perplexity4.043216228485107
INFO:root:current mean train loss 1774.5564536420036
INFO:root:current train perplexity4.04758358001709
INFO:root:current mean train loss 1774.9129029482888
INFO:root:current train perplexity4.049191474914551
INFO:root:current mean train loss 1773.759875390625
INFO:root:current train perplexity4.048996448516846
INFO:root:current mean train loss 1772.9996683054958
INFO:root:current train perplexity4.047166347503662
INFO:root:current mean train loss 1772.3076683830493
INFO:root:current train perplexity4.044036865234375
INFO:root:current mean train loss 1775.242141443201
INFO:root:current train perplexity4.045271873474121
INFO:root:current mean train loss 1777.2232831554877
INFO:root:current train perplexity4.047947883605957
INFO:root:current mean train loss 1776.483683810764
INFO:root:current train perplexity4.046942234039307
INFO:root:current mean train loss 1776.4331609733738
INFO:root:current train perplexity4.049642562866211
INFO:root:current mean train loss 1776.9412933925412
INFO:root:current train perplexity4.0531792640686035
INFO:root:current mean train loss 1776.8064224403784
INFO:root:current train perplexity4.055891036987305
INFO:root:current mean train loss 1777.017661452997
INFO:root:current train perplexity4.057971000671387
INFO:root:current mean train loss 1777.5751047926683
INFO:root:current train perplexity4.056743621826172
INFO:root:current mean train loss 1777.940128226902
INFO:root:current train perplexity4.057620048522949
INFO:root:current mean train loss 1776.8617939988228
INFO:root:current train perplexity4.056596279144287
INFO:root:current mean train loss 1777.0128703327923
INFO:root:current train perplexity4.057889938354492

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.52s/it]
INFO:root:final mean train loss: 1775.940136761841
INFO:root:final train perplexity: 4.057687282562256
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.44s/it]
INFO:root:eval mean loss: 2055.368963146886
INFO:root:eval perplexity: 5.271218776702881
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.29s/it]
INFO:root:eval mean loss: 2553.662519306156
INFO:root:eval perplexity: 8.072437286376953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [7:50:12<12:04:52, 359.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1760.239510672433
INFO:root:current train perplexity4.056618690490723
INFO:root:current mean train loss 1748.579484106789
INFO:root:current train perplexity4.012566566467285
INFO:root:current mean train loss 1761.4122390116543
INFO:root:current train perplexity4.023775577545166
INFO:root:current mean train loss 1762.1064456694307
INFO:root:current train perplexity4.028697490692139
INFO:root:current mean train loss 1765.4096560931314
INFO:root:current train perplexity4.037096977233887
INFO:root:current mean train loss 1765.0917365155096
INFO:root:current train perplexity4.031825065612793
INFO:root:current mean train loss 1765.6818073783709
INFO:root:current train perplexity4.036675453186035
INFO:root:current mean train loss 1764.8117197041884
INFO:root:current train perplexity4.032408237457275
INFO:root:current mean train loss 1767.0669464328794
INFO:root:current train perplexity4.036810398101807
INFO:root:current mean train loss 1767.580605411732
INFO:root:current train perplexity4.037367820739746
INFO:root:current mean train loss 1767.8994057448492
INFO:root:current train perplexity4.039595127105713
INFO:root:current mean train loss 1770.0659010798627
INFO:root:current train perplexity4.041966915130615
INFO:root:current mean train loss 1769.0208711731646
INFO:root:current train perplexity4.037998199462891
INFO:root:current mean train loss 1770.194780466276
INFO:root:current train perplexity4.039283752441406
INFO:root:current mean train loss 1770.50144317246
INFO:root:current train perplexity4.039670467376709
INFO:root:current mean train loss 1770.2123212010326
INFO:root:current train perplexity4.040249824523926
INFO:root:current mean train loss 1771.175402103475
INFO:root:current train perplexity4.043014049530029
INFO:root:current mean train loss 1771.3509416372165
INFO:root:current train perplexity4.0431952476501465
INFO:root:current mean train loss 1771.1696595099797
INFO:root:current train perplexity4.043136119842529
INFO:root:current mean train loss 1772.9099576185956
INFO:root:current train perplexity4.045619964599609

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.33s/it]
INFO:root:final mean train loss: 1772.5722242577533
INFO:root:final train perplexity: 4.046924114227295
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.48s/it]
INFO:root:eval mean loss: 2054.083329004599
INFO:root:eval perplexity: 5.265741348266602
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.93s/it]
INFO:root:eval mean loss: 2554.6226023139684
INFO:root:eval perplexity: 8.078775405883789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_multiqa_not_cross/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [7:56:03<11:54:19, 357.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1749.1020880230403
INFO:root:current train perplexity3.9993977546691895
INFO:root:current mean train loss 1753.762289946934
INFO:root:current train perplexity4.0146894454956055
INFO:root:current mean train loss 1760.0647132902993
INFO:root:current train perplexity4.012477874755859
INFO:root:current mean train loss 1762.664471554557
INFO:root:current train perplexity4.01218318939209
INFO:root:current mean train loss 1760.5540532130822
INFO:root:current train perplexity4.013639450073242
INFO:root:current mean train loss 1761.843245995919
INFO:root:current train perplexity4.020047187805176
INFO:root:current mean train loss 1761.5545324577367
INFO:root:current train perplexity4.024925708770752
INFO:root:current mean train loss 1763.045675687325
INFO:root:current train perplexity4.028220176696777
INFO:root:current mean train loss 1765.5516947167855
INFO:root:current train perplexity4.028327941894531
INFO:root:current mean train loss 1765.6347224739718
INFO:root:current train perplexity4.028641700744629
INFO:root:current mean train loss 1765.931977903314
INFO:root:current train perplexity4.03181266784668
INFO:root:current mean train loss 1766.801793095981
INFO:root:current train perplexity4.030903339385986
INFO:root:current mean train loss 1767.4425318371786
INFO:root:current train perplexity4.032888889312744
INFO:root:current mean train loss 1768.2711384642027
INFO:root:current train perplexity4.034577369689941
INFO:root:current mean train loss 1768.8565145051994
INFO:root:current train perplexity4.035398483276367
INFO:root:current mean train loss 1768.0237704332706
INFO:root:current train perplexity4.036278247833252
INFO:root:current mean train loss 1768.5261618974628
INFO:root:current train perplexity4.036219120025635
INFO:root:current mean train loss 1769.4919512012996
INFO:root:current train perplexity4.03685998916626
INFO:root:current mean train loss 1770.4265625919304
INFO:root:current train perplexity4.037109851837158
slurmstepd: error: *** JOB 26292819 ON gv007 CANCELLED AT 2022-10-26T12:45:25 ***
