INFO:root:Output: small_window_8
INFO:root:Steps per epochs:248
INFO:root:Total steps:49600
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'cls.predictions.decoder.weight', 'encoder.layer.4.crossattention.self.key.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.3.crossattention.self.key.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.value.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/200 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
INFO:root:current mean train loss 97829.64883207071
INFO:root:current train perplexity15173.474609375
INFO:root:current mean train loss 81425.30382380653
INFO:root:current train perplexity3045.447998046875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.11s/it]
INFO:root:final mean train loss: 75056.03331338205
INFO:root:final train perplexity: 1640.8079833984375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.44s/it]
INFO:root:eval mean loss: 44182.159877232145
INFO:root:eval perplexity: 96.80158233642578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/1

  0%|          | 1/200 [05:41<18:53:16, 341.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 42896.23920036765
INFO:root:current train perplexity69.47515106201172
INFO:root:current mean train loss 39104.42192673841
INFO:root:current train perplexity47.21715545654297


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.07s/it]
INFO:root:final mean train loss: 36513.20865360383
INFO:root:final train perplexity: 36.64875411987305
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.74s/it]
INFO:root:eval mean loss: 31760.1689453125
INFO:root:eval perplexity: 26.763545989990234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/2

  1%|          | 2/200 [11:22<18:45:24, 341.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 31230.082682291668
INFO:root:current train perplexity22.09511375427246
INFO:root:current mean train loss 29691.188675667476
INFO:root:current train perplexity18.654205322265625
INFO:root:current mean train loss 28788.040794334975
INFO:root:current train perplexity17.06601905822754


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.32s/it]
INFO:root:final mean train loss: 28402.849759009576
INFO:root:final train perplexity: 16.46828842163086
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.30s/it]
INFO:root:eval mean loss: 28525.83533296131
INFO:root:eval perplexity: 19.149967193603516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/3

  2%|â–         | 3/200 [16:58<18:32:26, 338.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 26366.991974431818
INFO:root:current train perplexity13.398015975952148
INFO:root:current mean train loss 25886.28685735887
INFO:root:current train perplexity12.817510604858398


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.43s/it]
INFO:root:final mean train loss: 25521.52411479335
INFO:root:final train perplexity: 12.394400596618652
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.65s/it]
INFO:root:eval mean loss: 27112.44066220238
INFO:root:eval perplexity: 16.543954849243164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/4

  2%|â–         | 4/200 [22:44<18:36:12, 341.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24889.899274553572
INFO:root:current train perplexity11.328659057617188
INFO:root:current mean train loss 24373.450423481307
INFO:root:current train perplexity11.01302433013916
INFO:root:current mean train loss 24090.189056838768
INFO:root:current train perplexity10.754289627075195


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.48s/it]
INFO:root:final mean train loss: 23976.40106004284
INFO:root:final train perplexity: 10.642399787902832
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.33s/it]
INFO:root:eval mean loss: 26302.044828869046
INFO:root:eval perplexity: 15.212966918945312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/5

  2%|â–Ž         | 5/200 [28:44<18:51:39, 348.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 23344.412970074154
INFO:root:current train perplexity9.992867469787598
INFO:root:current mean train loss 23112.144261006288
INFO:root:current train perplexity9.757780075073242


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.18s/it]
INFO:root:final mean train loss: 22962.28155714466
INFO:root:final train perplexity: 9.629404067993164
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.79s/it]
INFO:root:eval mean loss: 25743.77218191964
INFO:root:eval perplexity: 14.358891487121582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/6

  3%|â–Ž         | 6/200 [34:37<18:51:12, 349.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 22340.541903409092
INFO:root:current train perplexity9.109789848327637
INFO:root:current mean train loss 22390.90477195946
INFO:root:current train perplexity9.093735694885254
INFO:root:current mean train loss 22267.81738744076
INFO:root:current train perplexity8.9810152053833


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.35s/it]
INFO:root:final mean train loss: 22218.771681262602
INFO:root:final train perplexity: 8.94851016998291
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.04s/it]
INFO:root:eval mean loss: 25303.521484375
INFO:root:eval perplexity: 13.719325065612793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/7

  4%|â–Ž         | 7/200 [40:23<18:41:42, 348.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 21863.828280009922
INFO:root:current train perplexity8.627034187316895
INFO:root:current mean train loss 21769.126653565952
INFO:root:current train perplexity8.531416893005371


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.97s/it]
INFO:root:final mean train loss: 21649.204322076614
INFO:root:final train perplexity: 8.459662437438965
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.74s/it]
INFO:root:eval mean loss: 25005.123395647322
INFO:root:eval perplexity: 13.302105903625488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/8

  4%|â–         | 8/200 [46:17<18:40:53, 350.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 21413.838671875
INFO:root:current train perplexity8.18932819366455
INFO:root:current mean train loss 21330.010394021738
INFO:root:current train perplexity8.165963172912598
INFO:root:current mean train loss 21219.617596293603
INFO:root:current train perplexity8.095909118652344


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.39s/it]
INFO:root:final mean train loss: 21184.792700982864
INFO:root:final train perplexity: 8.080900192260742
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.42s/it]
INFO:root:eval mean loss: 24713.159621465773
INFO:root:eval perplexity: 12.906168937683105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/9

  4%|â–         | 9/200 [52:17<18:44:57, 353.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20957.44671175373
INFO:root:current train perplexity7.862667560577393
INFO:root:current mean train loss 20891.76371865644
INFO:root:current train perplexity7.829254627227783


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.95s/it]
INFO:root:final mean train loss: 20797.48478452621
INFO:root:final train perplexity: 7.778024673461914
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.77s/it]
INFO:root:eval mean loss: 24495.916085379464
INFO:root:eval perplexity: 12.619233131408691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/10

  5%|â–Œ         | 10/200 [58:03<18:31:18, 350.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20784.176706414473
INFO:root:current train perplexity7.635256767272949
INFO:root:current mean train loss 20588.733734900212
INFO:root:current train perplexity7.572308540344238
INFO:root:current mean train loss 20502.967653039384
INFO:root:current train perplexity7.54335355758667


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.09s/it]
INFO:root:final mean train loss: 20475.50451266381
INFO:root:final train perplexity: 7.534892559051514
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.94s/it]
INFO:root:eval mean loss: 24276.877976190477
INFO:root:eval perplexity: 12.33637523651123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/11

  6%|â–Œ         | 11/200 [1:03:57<18:28:33, 351.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20289.859430017605
INFO:root:current train perplexity7.35044002532959
INFO:root:current mean train loss 20233.846902412282
INFO:root:current train perplexity7.3430962562561035


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.68s/it]
INFO:root:final mean train loss: 20183.20287298387
INFO:root:final train perplexity: 7.3207621574401855
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.19s/it]
INFO:root:eval mean loss: 24110.21314639137
INFO:root:eval perplexity: 12.125406265258789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/12

  6%|â–Œ         | 12/200 [1:09:47<18:20:47, 351.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 20059.617866847828
INFO:root:current train perplexity7.202762603759766
INFO:root:current mean train loss 19963.735438897358
INFO:root:current train perplexity7.168951988220215
INFO:root:current mean train loss 19935.295850266255
INFO:root:current train perplexity7.140656471252441


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.83s/it]
INFO:root:final mean train loss: 19930.732035975303
INFO:root:final train perplexity: 7.140712738037109
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.10s/it]
INFO:root:eval mean loss: 23962.287179129464
INFO:root:eval perplexity: 11.941184997558594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/13

  6%|â–‹         | 13/200 [1:15:48<18:24:02, 354.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19814.372916666667
INFO:root:current train perplexity7.014764308929443
INFO:root:current mean train loss 19743.855167410715
INFO:root:current train perplexity7.000770568847656


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.25s/it]
INFO:root:final mean train loss: 19709.70865360383
INFO:root:final train perplexity: 6.986730098724365
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.87s/it]
INFO:root:eval mean loss: 23836.838448660714
INFO:root:eval perplexity: 11.787150382995605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/14

  7%|â–‹         | 14/200 [1:21:45<18:21:27, 355.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19508.823784722223
INFO:root:current train perplexity6.877467155456543
INFO:root:current mean train loss 19475.78973917323
INFO:root:current train perplexity6.856362819671631
INFO:root:current mean train loss 19519.16816664372
INFO:root:current train perplexity6.849161624908447


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.93s/it]
INFO:root:final mean train loss: 19497.108414188508
INFO:root:final train perplexity: 6.8417487144470215
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.12s/it]
INFO:root:eval mean loss: 23722.056687127977
INFO:root:eval perplexity: 11.647953987121582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/15

  8%|â–Š         | 15/200 [1:27:41<18:16:18, 355.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19326.005933544304
INFO:root:current train perplexity6.734854221343994
INFO:root:current mean train loss 19327.488073935056
INFO:root:current train perplexity6.72581148147583


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.15s/it]
INFO:root:final mean train loss: 19310.286652595765
INFO:root:final train perplexity: 6.716832637786865
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.59s/it]
INFO:root:eval mean loss: 23622.43896484375
INFO:root:eval perplexity: 11.528481483459473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/16

  8%|â–Š         | 16/200 [1:33:32<18:06:03, 354.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 19107.231980846773
INFO:root:current train perplexity6.6467108726501465
INFO:root:current mean train loss 19147.167163645037
INFO:root:current train perplexity6.6064677238464355
INFO:root:current mean train loss 19144.784792681276
INFO:root:current train perplexity6.603900909423828


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.32s/it]
INFO:root:final mean train loss: 19142.2258812689
INFO:root:final train perplexity: 6.606410980224609
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.07s/it]
INFO:root:eval mean loss: 23503.62527901786
INFO:root:eval perplexity: 11.387587547302246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/17

  8%|â–Š         | 17/200 [1:39:18<17:52:08, 351.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18984.102009600905
INFO:root:current train perplexity6.501713752746582
INFO:root:current mean train loss 18994.80971439549
INFO:root:current train perplexity6.494296073913574


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.94s/it]
INFO:root:final mean train loss: 18977.404643397178
INFO:root:final train perplexity: 6.499879360198975
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.58s/it]
INFO:root:eval mean loss: 23442.665852864582
INFO:root:eval perplexity: 11.315966606140137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/18

  9%|â–‰         | 18/200 [1:45:11<17:48:12, 352.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18905.652120535713
INFO:root:current train perplexity6.44413948059082
INFO:root:current mean train loss 18909.20462962963
INFO:root:current train perplexity6.438653945922852
INFO:root:current mean train loss 18835.358735039892
INFO:root:current train perplexity6.4053449630737305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.52s/it]
INFO:root:final mean train loss: 18834.423367408013
INFO:root:final train perplexity: 6.408859729766846
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.01s/it]
INFO:root:eval mean loss: 23361.526064918155
INFO:root:eval perplexity: 11.22133731842041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/19

 10%|â–‰         | 19/200 [1:50:55<17:34:43, 349.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18702.417856501437
INFO:root:current train perplexity6.3110785484313965
INFO:root:current mean train loss 18735.385319184494
INFO:root:current train perplexity6.326963901519775


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.37s/it]
INFO:root:final mean train loss: 18704.18691327495
INFO:root:final train perplexity: 6.327060699462891
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.84s/it]
INFO:root:eval mean loss: 23267.03294735863
INFO:root:eval perplexity: 11.112133979797363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/20

 10%|â–ˆ         | 20/200 [1:57:00<17:42:09, 354.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18710.76647636218
INFO:root:current train perplexity6.264453887939453
INFO:root:current mean train loss 18603.96974763939
INFO:root:current train perplexity6.25049352645874
INFO:root:current mean train loss 18593.736213716005
INFO:root:current train perplexity6.247689723968506


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.61s/it]
INFO:root:final mean train loss: 18572.174442414314
INFO:root:final train perplexity: 6.245212078094482
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.54s/it]
INFO:root:eval mean loss: 23212.709519159227
INFO:root:eval perplexity: 11.049835205078125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/21

 10%|â–ˆ         | 21/200 [2:02:53<17:35:38, 353.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18450.855425824175
INFO:root:current train perplexity6.173670291900635
INFO:root:current mean train loss 18464.74122627618
INFO:root:current train perplexity6.165547847747803


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:08<00:00, 308.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:08<00:00, 308.02s/it]
INFO:root:final mean train loss: 18450.794350900956
INFO:root:final train perplexity: 6.170889854431152
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.80s/it]
INFO:root:eval mean loss: 23145.942685081845
INFO:root:eval perplexity: 10.973743438720703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/22

 11%|â–ˆ         | 22/200 [2:08:59<17:40:28, 357.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18396.64734738372
INFO:root:current train perplexity6.130059719085693
INFO:root:current mean train loss 18366.234211101397
INFO:root:current train perplexity6.113137722015381
INFO:root:current mean train loss 18370.06786104681
INFO:root:current train perplexity6.110055923461914


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 295.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 295.00s/it]
INFO:root:final mean train loss: 18347.375637915826
INFO:root:final train perplexity: 6.1082634925842285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.42s/it]
INFO:root:eval mean loss: 23117.293550037204
INFO:root:eval perplexity: 10.941254615783691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/23

 12%|â–ˆâ–        | 23/200 [2:14:52<17:30:54, 356.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18287.008470394736
INFO:root:current train perplexity6.0418701171875
INFO:root:current mean train loss 18253.732211538463
INFO:root:current train perplexity6.03709602355957


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.89s/it]
INFO:root:final mean train loss: 18232.23152406754
INFO:root:final train perplexity: 6.039285659790039
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.95s/it]
INFO:root:eval mean loss: 23027.184128534227
INFO:root:eval perplexity: 10.839688301086426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/24

 12%|â–ˆâ–        | 24/200 [2:20:42<17:19:25, 354.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18081.541015625
INFO:root:current train perplexity5.968903541564941
INFO:root:current mean train loss 18142.155492665817
INFO:root:current train perplexity5.98535680770874
INFO:root:current mean train loss 18150.32765846407
INFO:root:current train perplexity5.983458995819092


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.20s/it]
INFO:root:final mean train loss: 18137.088465536795
INFO:root:final train perplexity: 5.982875823974609
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.29s/it]
INFO:root:eval mean loss: 23036.33728608631
INFO:root:eval perplexity: 10.849963188171387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/25

 12%|â–ˆâ–Ž        | 25/200 [2:26:25<17:03:21, 350.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18089.90946575126
INFO:root:current train perplexity5.943308353424072
INFO:root:current mean train loss 18075.786412531408
INFO:root:current train perplexity5.928610801696777


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.38s/it]
INFO:root:final mean train loss: 18045.11855389995
INFO:root:final train perplexity: 5.9288506507873535
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.03s/it]
INFO:root:eval mean loss: 22962.73172433036
INFO:root:eval perplexity: 10.767622947692871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/26

 13%|â–ˆâ–Ž        | 26/200 [2:32:27<17:07:31, 354.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17967.14292279412
INFO:root:current train perplexity5.893290996551514
INFO:root:current mean train loss 17988.92788959023
INFO:root:current train perplexity5.888498783111572


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.02s/it]
INFO:root:final mean train loss: 17957.954463835686
INFO:root:final train perplexity: 5.878098487854004
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.18s/it]
INFO:root:eval mean loss: 22922.339704241072
INFO:root:eval perplexity: 10.72270393371582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/27

 14%|â–ˆâ–Ž        | 27/200 [2:38:33<17:11:07, 357.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 18044.05859375
INFO:root:current train perplexity5.829091548919678
INFO:root:current mean train loss 17896.53318416262
INFO:root:current train perplexity5.83866024017334
INFO:root:current mean train loss 17894.958195427957
INFO:root:current train perplexity5.827310085296631


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.12s/it]
INFO:root:final mean train loss: 17868.75283518145
INFO:root:final train perplexity: 5.826608180999756
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.43s/it]
INFO:root:eval mean loss: 22872.74588448661
INFO:root:eval perplexity: 10.667808532714844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/28

 14%|â–ˆâ–        | 28/200 [2:44:29<17:04:15, 357.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17863.66541193182
INFO:root:current train perplexity5.807559490203857
INFO:root:current mean train loss 17832.17644909274
INFO:root:current train perplexity5.791486740112305


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.70s/it]
INFO:root:final mean train loss: 17794.001961000504
INFO:root:final train perplexity: 5.783806800842285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.83s/it]
INFO:root:eval mean loss: 22845.294875372023
INFO:root:eval perplexity: 10.637541770935059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/29

 14%|â–ˆâ–        | 29/200 [2:50:23<16:55:10, 356.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17830.971819196428
INFO:root:current train perplexity5.746269702911377
INFO:root:current mean train loss 17820.65020808995
INFO:root:current train perplexity5.746181964874268
INFO:root:current mean train loss 17758.36713088768
INFO:root:current train perplexity5.739195823669434


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:13<00:00, 313.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:13<00:00, 313.55s/it]
INFO:root:final mean train loss: 17711.857193485383
INFO:root:final train perplexity: 5.737135410308838
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.15s/it]
INFO:root:eval mean loss: 22802.950009300595
INFO:root:eval perplexity: 10.591026306152344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/30

 15%|â–ˆâ–Œ        | 30/200 [2:56:35<17:02:28, 360.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17657.979111493645
INFO:root:current train perplexity5.6983962059021
INFO:root:current mean train loss 17655.894961183178
INFO:root:current train perplexity5.696996212005615


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.43s/it]
INFO:root:final mean train loss: 17637.616041614165
INFO:root:final train perplexity: 5.695277690887451
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.50s/it]
INFO:root:eval mean loss: 22773.44019717262
INFO:root:eval perplexity: 10.55872917175293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/31

 16%|â–ˆâ–Œ        | 31/200 [3:02:23<16:45:34, 357.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17501.805930397728
INFO:root:current train perplexity5.628420352935791
INFO:root:current mean train loss 17580.064893018018
INFO:root:current train perplexity5.64263916015625
INFO:root:current mean train loss 17579.375879369076
INFO:root:current train perplexity5.658226013183594


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.90s/it]
INFO:root:final mean train loss: 17565.72579857611
INFO:root:final train perplexity: 5.655037879943848
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.48s/it]
INFO:root:eval mean loss: 22754.378580729168
INFO:root:eval perplexity: 10.537920951843262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/32

 16%|â–ˆâ–Œ        | 32/200 [3:08:10<16:31:36, 354.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17505.639539930555
INFO:root:current train perplexity5.603548049926758
INFO:root:current mean train loss 17520.04639570552
INFO:root:current train perplexity5.620396137237549


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.64s/it]
INFO:root:final mean train loss: 17498.907124180947
INFO:root:final train perplexity: 5.61789083480835
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.47s/it]
INFO:root:eval mean loss: 22736.18824404762
INFO:root:eval perplexity: 10.51810073852539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/33

 16%|â–ˆâ–‹        | 33/200 [3:14:04<16:25:47, 354.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17275.865885416668
INFO:root:current train perplexity5.532436847686768
INFO:root:current mean train loss 17426.152564538042
INFO:root:current train perplexity5.577840805053711
INFO:root:current mean train loss 17409.936537063953
INFO:root:current train perplexity5.566530227661133


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.26s/it]
INFO:root:final mean train loss: 17426.35924111643
INFO:root:final train perplexity: 5.577834606170654
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.18s/it]
INFO:root:eval mean loss: 22674.708937872023
INFO:root:eval perplexity: 10.451385498046875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/34

 17%|â–ˆâ–‹        | 34/200 [3:19:56<16:17:45, 353.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17364.566697761195
INFO:root:current train perplexity5.54221248626709
INFO:root:current mean train loss 17382.886297717065
INFO:root:current train perplexity5.542821407318115


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.10s/it]
INFO:root:final mean train loss: 17366.412940240676
INFO:root:final train perplexity: 5.544954299926758
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.87s/it]
INFO:root:eval mean loss: 22659.1513671875
INFO:root:eval perplexity: 10.434571266174316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/35

 18%|â–ˆâ–Š        | 35/200 [3:25:52<16:13:58, 354.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17508.538137335527
INFO:root:current train perplexity5.573244094848633
INFO:root:current mean train loss 17356.18016347164
INFO:root:current train perplexity5.52752685546875
INFO:root:current mean train loss 17329.1402861016
INFO:root:current train perplexity5.514340400695801


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.75s/it]
INFO:root:final mean train loss: 17311.369908486642
INFO:root:final train perplexity: 5.514930248260498
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.59s/it]
INFO:root:eval mean loss: 22663.314918154763
INFO:root:eval perplexity: 10.439067840576172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/36

 18%|â–ˆâ–Š        | 36/200 [3:31:43<16:05:25, 353.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17216.763988226234
INFO:root:current train perplexity5.462830543518066
INFO:root:current mean train loss 17241.998058296784
INFO:root:current train perplexity5.480469703674316


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.21s/it]
INFO:root:final mean train loss: 17248.09170236895
INFO:root:final train perplexity: 5.480618000030518
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.26s/it]
INFO:root:eval mean loss: 22615.374837239582
INFO:root:eval perplexity: 10.38740062713623
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/37

 18%|â–ˆâ–Š        | 37/200 [3:37:34<15:57:44, 352.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17136.804050611412
INFO:root:current train perplexity5.422143459320068
INFO:root:current mean train loss 17140.380454458842
INFO:root:current train perplexity5.438940048217773
INFO:root:current mean train loss 17207.055015940303
INFO:root:current train perplexity5.451488018035889


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.57s/it]
INFO:root:final mean train loss: 17191.294555664062
INFO:root:final train perplexity: 5.450000762939453
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.33s/it]
INFO:root:eval mean loss: 22604.161923363095
INFO:root:eval perplexity: 10.375356674194336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/38

 19%|â–ˆâ–‰        | 38/200 [3:43:20<15:46:36, 350.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17160.623307291666
INFO:root:current train perplexity5.415552616119385
INFO:root:current mean train loss 17144.346512276785
INFO:root:current train perplexity5.417181015014648


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.21s/it]
INFO:root:final mean train loss: 17140.805786132812
INFO:root:final train perplexity: 5.422928810119629
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.51s/it]
INFO:root:eval mean loss: 22583.901460193454
INFO:root:eval perplexity: 10.353623390197754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/39

 20%|â–ˆâ–‰        | 39/200 [3:49:05<15:36:07, 348.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17007.09736689815
INFO:root:current train perplexity5.357106685638428
INFO:root:current mean train loss 17094.78309547244
INFO:root:current train perplexity5.395587921142578
INFO:root:current mean train loss 17097.358256470263
INFO:root:current train perplexity5.393420696258545


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.32s/it]
INFO:root:final mean train loss: 17088.07912125126
INFO:root:final train perplexity: 5.39479923248291
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.66s/it]
INFO:root:eval mean loss: 22567.774553571428
INFO:root:eval perplexity: 10.336356163024902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/40

 20%|â–ˆâ–ˆ        | 40/200 [3:54:51<15:28:06, 348.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17079.840313488923
INFO:root:current train perplexity5.37667179107666
INFO:root:current mean train loss 17089.310972416202
INFO:root:current train perplexity5.380210876464844


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.49s/it]
INFO:root:final mean train loss: 17034.490600585938
INFO:root:final train perplexity: 5.366361141204834
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.28s/it]
INFO:root:eval mean loss: 22559.35205078125
INFO:root:eval perplexity: 10.327349662780762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/41

 20%|â–ˆâ–ˆ        | 41/200 [4:00:32<15:16:40, 345.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16910.530903477822
INFO:root:current train perplexity5.30974006652832
INFO:root:current mean train loss 16962.226704138837
INFO:root:current train perplexity5.3248209953308105
INFO:root:current mean train loss 17005.878724465638
INFO:root:current train perplexity5.340383052825928


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.27s/it]
INFO:root:final mean train loss: 16986.306569745462
INFO:root:final train perplexity: 5.340917110443115
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.24s/it]
INFO:root:eval mean loss: 22520.54757254464
INFO:root:eval perplexity: 10.285957336425781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/42

 21%|â–ˆâ–ˆ        | 42/200 [4:06:12<15:06:39, 344.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16929.67262801205
INFO:root:current train perplexity5.31341028213501
INFO:root:current mean train loss 16962.10521260246
INFO:root:current train perplexity5.316618919372559


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.33s/it]
INFO:root:final mean train loss: 16937.19720655872
INFO:root:final train perplexity: 5.315109729766846
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.34s/it]
INFO:root:eval mean loss: 22548.803245907737
INFO:root:eval perplexity: 10.316082000732422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/43

 22%|â–ˆâ–ˆâ–       | 43/200 [4:12:03<15:05:52, 346.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 17017.703515625
INFO:root:current train perplexity5.325598239898682
INFO:root:current mean train loss 16935.032277199072
INFO:root:current train perplexity5.291927814483643
INFO:root:current mean train loss 16907.047419381648
INFO:root:current train perplexity5.292025089263916


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.86s/it]
INFO:root:final mean train loss: 16891.952270507812
INFO:root:final train perplexity: 5.29144287109375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.33s/it]
INFO:root:eval mean loss: 22524.362723214286
INFO:root:eval perplexity: 10.290020942687988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/44

 22%|â–ˆâ–ˆâ–       | 44/200 [4:17:48<14:59:23, 345.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16836.068965517243
INFO:root:current train perplexity5.25615930557251
INFO:root:current mean train loss 16855.844606450533
INFO:root:current train perplexity5.2632646560668945


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.33s/it]
INFO:root:final mean train loss: 16846.556865076866
INFO:root:final train perplexity: 5.2678046226501465
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.88s/it]
INFO:root:eval mean loss: 22501.259137834822
INFO:root:eval perplexity: 10.265445709228516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/45

 22%|â–ˆâ–ˆâ–Ž       | 45/200 [4:23:29<14:49:59, 344.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16836.167392828527
INFO:root:current train perplexity5.254140853881836
INFO:root:current mean train loss 16803.73690422662
INFO:root:current train perplexity5.244101524353027
INFO:root:current mean train loss 16818.669921875
INFO:root:current train perplexity5.2459845542907715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.48s/it]
INFO:root:final mean train loss: 16802.84835716986
INFO:root:final train perplexity: 5.245142459869385
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.73s/it]
INFO:root:eval mean loss: 22493.281715029763
INFO:root:eval perplexity: 10.25697135925293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/46

 23%|â–ˆâ–ˆâ–Ž       | 46/200 [4:29:17<14:46:21, 345.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16798.84234417926
INFO:root:current train perplexity5.220200538635254
INFO:root:current mean train loss 16792.349231020944
INFO:root:current train perplexity5.227652072906494


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.43s/it]
INFO:root:final mean train loss: 16760.401355374244
INFO:root:final train perplexity: 5.223228931427002
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.11s/it]
INFO:root:eval mean loss: 22478.758370535714
INFO:root:eval perplexity: 10.24156665802002
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/47

 24%|â–ˆâ–ˆâ–Ž       | 47/200 [4:35:02<14:40:49, 345.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16730.63015534157
INFO:root:current train perplexity5.203364849090576
INFO:root:current mean train loss 16733.702885981205
INFO:root:current train perplexity5.201880931854248
INFO:root:current mean train loss 16727.767208397632
INFO:root:current train perplexity5.201364517211914


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:06<00:00, 306.88s/it]
INFO:root:final mean train loss: 16717.211709299394
INFO:root:final train perplexity: 5.20102596282959
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.90s/it]
INFO:root:eval mean loss: 22476.166015625
INFO:root:eval perplexity: 10.23882007598877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/48

 24%|â–ˆâ–ˆâ–       | 48/200 [4:40:58<14:43:02, 348.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16664.330067845396
INFO:root:current train perplexity5.1658244132995605
INFO:root:current mean train loss 16679.86402744391
INFO:root:current train perplexity5.173437118530273


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.37s/it]
INFO:root:final mean train loss: 16681.03152170489
INFO:root:final train perplexity: 5.182498931884766
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.24s/it]
INFO:root:eval mean loss: 22449.49865141369
INFO:root:eval perplexity: 10.210600852966309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/49

 24%|â–ˆâ–ˆâ–       | 49/200 [4:46:39<14:31:09, 346.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16659.03455369016
INFO:root:current train perplexity5.136993408203125
INFO:root:current mean train loss 16647.020833333332
INFO:root:current train perplexity5.15800142288208
INFO:root:current mean train loss 16650.346031281628
INFO:root:current train perplexity5.161014556884766


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.60s/it]
INFO:root:final mean train loss: 16639.645661384828
INFO:root:final train perplexity: 5.161386966705322
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.41s/it]
INFO:root:eval mean loss: 22450.326171875
INFO:root:eval perplexity: 10.211474418640137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/50

 25%|â–ˆâ–ˆâ–Œ       | 50/200 [4:52:22<14:23:03, 345.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16615.72074258207
INFO:root:current train perplexity5.128253936767578
INFO:root:current mean train loss 16592.590844849245
INFO:root:current train perplexity5.141295909881592


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.37s/it]
INFO:root:final mean train loss: 16605.53654233871
INFO:root:final train perplexity: 5.144052028656006
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.77s/it]
INFO:root:eval mean loss: 22433.15062313988
INFO:root:eval perplexity: 10.193338394165039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/51

 26%|â–ˆâ–ˆâ–Œ       | 51/200 [4:57:58<14:10:30, 342.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16577.636833639706
INFO:root:current train perplexity5.119320392608643
INFO:root:current mean train loss 16588.71440397351
INFO:root:current train perplexity5.123692512512207


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.73s/it]
INFO:root:final mean train loss: 16567.038018995714
INFO:root:final train perplexity: 5.124556064605713
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.34s/it]
INFO:root:eval mean loss: 22435.929780505954
INFO:root:eval perplexity: 10.196271896362305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/52

 26%|â–ˆâ–ˆâ–Œ       | 52/200 [5:03:49<14:11:28, 345.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16651.7587890625
INFO:root:current train perplexity5.2320637702941895
INFO:root:current mean train loss 16495.11955779733
INFO:root:current train perplexity5.087337493896484
INFO:root:current mean train loss 16536.49402035868
INFO:root:current train perplexity5.103462219238281


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.44s/it]
INFO:root:final mean train loss: 16531.29536684098
INFO:root:final train perplexity: 5.106522083282471
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.05s/it]
INFO:root:eval mean loss: 22420.633649553572
INFO:root:eval perplexity: 10.180143356323242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/53

 26%|â–ˆâ–ˆâ–‹       | 53/200 [5:09:34<14:05:11, 344.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16482.754669744318
INFO:root:current train perplexity5.093138217926025
INFO:root:current mean train loss 16539.71214717742
INFO:root:current train perplexity5.102688312530518


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.19s/it]
INFO:root:final mean train loss: 16495.578278572328
INFO:root:final train perplexity: 5.088564872741699
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.37s/it]
INFO:root:eval mean loss: 22397.451241629464
INFO:root:eval perplexity: 10.155743598937988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/54

 27%|â–ˆâ–ˆâ–‹       | 54/200 [5:15:15<13:56:50, 343.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16361.1357421875
INFO:root:current train perplexity5.0857768058776855
INFO:root:current mean train loss 16458.25324912383
INFO:root:current train perplexity5.072841644287109
INFO:root:current mean train loss 16461.175417987622
INFO:root:current train perplexity5.074191093444824


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.40s/it]
INFO:root:final mean train loss: 16460.49386892011
INFO:root:final train perplexity: 5.070985794067383
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.45s/it]
INFO:root:eval mean loss: 22400.103422619046
INFO:root:eval perplexity: 10.158533096313477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/55

 28%|â–ˆâ–ˆâ–Š       | 55/200 [5:20:52<13:46:16, 341.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16449.749039989405
INFO:root:current train perplexity5.044767379760742
INFO:root:current mean train loss 16404.909241106525
INFO:root:current train perplexity5.045585632324219


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.94s/it]
INFO:root:final mean train loss: 16426.131576045867
INFO:root:final train perplexity: 5.053828239440918
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.48s/it]
INFO:root:eval mean loss: 22407.587100074405
INFO:root:eval perplexity: 10.16640567779541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/56

 28%|â–ˆâ–ˆâ–Š       | 56/200 [5:26:36<13:41:45, 342.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16523.96306818182
INFO:root:current train perplexity5.07285737991333
INFO:root:current mean train loss 16381.174259220157
INFO:root:current train perplexity5.029971122741699
INFO:root:current mean train loss 16416.26082549615
INFO:root:current train perplexity5.038692951202393


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.41s/it]
INFO:root:final mean train loss: 16387.822875976562
INFO:root:final train perplexity: 5.034768581390381
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.36s/it]
INFO:root:eval mean loss: 22395.963239397322
INFO:root:eval perplexity: 10.154184341430664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/57

 28%|â–ˆâ–ˆâ–Š       | 57/200 [5:32:28<13:43:10, 345.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16321.761827256945
INFO:root:current train perplexity4.99211311340332
INFO:root:current mean train loss 16353.881740078605
INFO:root:current train perplexity5.013972282409668


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.94s/it]
INFO:root:final mean train loss: 16354.286613218246
INFO:root:final train perplexity: 5.018142223358154
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:03<00:00, 63.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:03<00:00, 63.35s/it]
INFO:root:eval mean loss: 22392.396530877977
INFO:root:eval perplexity: 10.150435447692871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/58

 29%|â–ˆâ–ˆâ–‰       | 58/200 [5:38:25<13:45:33, 348.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16321.365755208333
INFO:root:current train perplexity5.008242130279541
INFO:root:current mean train loss 16274.883211616849
INFO:root:current train perplexity4.979971408843994
INFO:root:current mean train loss 16307.718677325582
INFO:root:current train perplexity4.996838092803955


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.73s/it]
INFO:root:final mean train loss: 16323.333133820564
INFO:root:final train perplexity: 5.00284481048584
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.74s/it]
INFO:root:eval mean loss: 22368.351539248513
INFO:root:eval perplexity: 10.125205993652344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/59

 30%|â–ˆâ–ˆâ–‰       | 59/200 [5:44:28<13:49:25, 352.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16294.84767082556
INFO:root:current train perplexity4.9678635597229
INFO:root:current mean train loss 16296.483766841317
INFO:root:current train perplexity4.988361835479736


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.36s/it]
INFO:root:final mean train loss: 16292.736800655242
INFO:root:final train perplexity: 4.9877705574035645
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.17s/it]
INFO:root:eval mean loss: 22374.604817708332
INFO:root:eval perplexity: 10.131759643554688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/60

 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [5:50:29<13:49:29, 355.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16256.963096217105
INFO:root:current train perplexity4.978483200073242
INFO:root:current mean train loss 16242.220325630253
INFO:root:current train perplexity4.968999862670898
INFO:root:current mean train loss 16262.346684146689
INFO:root:current train perplexity4.970090389251709


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.23s/it]
INFO:root:final mean train loss: 16262.350534746723
INFO:root:final train perplexity: 4.972843647003174
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.81s/it]
INFO:root:eval mean loss: 22351.51232328869
INFO:root:eval perplexity: 10.107574462890625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/61

 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [5:56:20<13:40:26, 354.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16262.405796104753
INFO:root:current train perplexity4.962741851806641
INFO:root:current mean train loss 16264.859774762426
INFO:root:current train perplexity4.962892055511475


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.46s/it]
INFO:root:final mean train loss: 16235.576475081905
INFO:root:final train perplexity: 4.959729194641113
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.73s/it]
INFO:root:eval mean loss: 22365.310593377977
INFO:root:eval perplexity: 10.12201976776123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/62

 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [6:02:06<13:29:04, 351.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16129.957201086956
INFO:root:current train perplexity4.911495685577393
INFO:root:current mean train loss 16217.461961699695
INFO:root:current train perplexity4.937276840209961
INFO:root:current mean train loss 16221.34572502102
INFO:root:current train perplexity4.947301864624023


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.08s/it]
INFO:root:final mean train loss: 16207.188996345767
INFO:root:final train perplexity: 4.945861339569092
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 48.00s/it]
INFO:root:eval mean loss: 22360.672712053572
INFO:root:eval perplexity: 10.11716079711914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/63

 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [6:07:48<13:16:26, 348.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16165.44765625
INFO:root:current train perplexity4.932343006134033
INFO:root:current mean train loss 16203.559966517858
INFO:root:current train perplexity4.929840564727783


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.04s/it]
INFO:root:final mean train loss: 16179.027335874496
INFO:root:final train perplexity: 4.93214225769043
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.30s/it]
INFO:root:eval mean loss: 22344.454659598214
INFO:root:eval perplexity: 10.10019588470459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/64

 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [6:13:29<13:05:27, 346.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16262.437897858796
INFO:root:current train perplexity4.9314985275268555
INFO:root:current mean train loss 16139.392032172736
INFO:root:current train perplexity4.90974760055542
INFO:root:current mean train loss 16161.635978799559
INFO:root:current train perplexity4.918674945831299


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.63s/it]
INFO:root:final mean train loss: 16154.54576061618
INFO:root:final train perplexity: 4.920248508453369
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.01s/it]
INFO:root:eval mean loss: 22363.50818452381
INFO:root:eval perplexity: 10.120132446289062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/65

 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [6:19:24<13:05:11, 348.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16144.691480419304
INFO:root:current train perplexity4.901201248168945
INFO:root:current mean train loss 16136.851398830308
INFO:root:current train perplexity4.90397834777832


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.63s/it]
INFO:root:final mean train loss: 16124.307451801915
INFO:root:final train perplexity: 4.905594825744629
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.17s/it]
INFO:root:eval mean loss: 22354.7021484375
INFO:root:eval perplexity: 10.110915184020996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/66

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [6:25:03<12:52:27, 345.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16050.521799395161
INFO:root:current train perplexity4.861428737640381
INFO:root:current mean train loss 16107.741166209447
INFO:root:current train perplexity4.884748458862305
INFO:root:current mean train loss 16102.596256933171
INFO:root:current train perplexity4.889557361602783


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.20s/it]
INFO:root:final mean train loss: 16093.14488170993
INFO:root:final train perplexity: 4.890540599822998
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.42s/it]
INFO:root:eval mean loss: 22344.758765811013
INFO:root:eval perplexity: 10.100513458251953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/67

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [6:30:51<12:47:59, 346.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16082.973609280874
INFO:root:current train perplexity4.8759684562683105
INFO:root:current mean train loss 16088.392620816257
INFO:root:current train perplexity4.876745223999023


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.04s/it]
INFO:root:final mean train loss: 16071.734890845513
INFO:root:final train perplexity: 4.880224227905273
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 46.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 46.00s/it]
INFO:root:eval mean loss: 22340.975725446428
INFO:root:eval perplexity: 10.096558570861816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/68

 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [6:36:26<12:34:45, 343.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16130.866768973214
INFO:root:current train perplexity4.888126373291016
INFO:root:current mean train loss 16058.882349537036
INFO:root:current train perplexity4.862586975097656
INFO:root:current mean train loss 16058.463356050532
INFO:root:current train perplexity4.865113735198975


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.10s/it]
INFO:root:final mean train loss: 16042.293244392642
INFO:root:final train perplexity: 4.866073131561279
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.31s/it]
INFO:root:eval mean loss: 22336.761788504464
INFO:root:eval perplexity: 10.092156410217285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/69

 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [6:42:06<12:27:13, 342.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 16019.046302532328
INFO:root:current train perplexity4.859172344207764
INFO:root:current mean train loss 16002.556499623997
INFO:root:current train perplexity4.853172779083252


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.19s/it]
INFO:root:final mean train loss: 16024.29673717868
INFO:root:final train perplexity: 4.857442855834961
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.46s/it]
INFO:root:eval mean loss: 22356.0380859375
INFO:root:eval perplexity: 10.112311363220215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/70

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [6:47:42<12:17:13, 340.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15905.893604767629
INFO:root:current train perplexity4.838428974151611
INFO:root:current mean train loss 15959.369309240108
INFO:root:current train perplexity4.828882694244385
INFO:root:current mean train loss 16002.080008662395
INFO:root:current train perplexity4.8405022621154785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.32s/it]
INFO:root:final mean train loss: 15995.680927891884
INFO:root:final train perplexity: 4.843752861022949
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.20s/it]
INFO:root:eval mean loss: 22315.580915178572
INFO:root:eval perplexity: 10.070060729980469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/71

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [6:53:18<12:09:12, 339.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15945.22816148695
INFO:root:current train perplexity4.815631866455078
INFO:root:current mean train loss 15962.703477789595
INFO:root:current train perplexity4.824436664581299


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.22s/it]
INFO:root:final mean train loss: 15970.181156281502
INFO:root:final train perplexity: 4.83158540725708
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.44s/it]
INFO:root:eval mean loss: 22320.539597284227
INFO:root:eval perplexity: 10.075226783752441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/72

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [6:58:54<12:01:19, 338.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15957.353833575582
INFO:root:current train perplexity4.800640106201172
INFO:root:current mean train loss 15952.018609320367
INFO:root:current train perplexity4.816223621368408
INFO:root:current mean train loss 15962.667285558127
INFO:root:current train perplexity4.821439743041992


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.98s/it]
INFO:root:final mean train loss: 15948.845384167087
INFO:root:final train perplexity: 4.8214287757873535
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.05s/it]
INFO:root:eval mean loss: 22320.269484747023
INFO:root:eval perplexity: 10.074947357177734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/73

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [7:04:30<11:54:17, 337.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15920.972615131579
INFO:root:current train perplexity4.804588317871094
INFO:root:current mean train loss 15931.718149038461
INFO:root:current train perplexity4.810527324676514


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.35s/it]
INFO:root:final mean train loss: 15927.313193044354
INFO:root:final train perplexity: 4.81119966506958
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.75s/it]
INFO:root:eval mean loss: 22323.788504464286
INFO:root:eval perplexity: 10.07861614227295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/74

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [7:10:12<11:51:27, 338.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15890.97032912234
INFO:root:current train perplexity4.782954692840576
INFO:root:current mean train loss 15890.589969972363
INFO:root:current train perplexity4.782366752624512
INFO:root:current mean train loss 15914.23214907009
INFO:root:current train perplexity4.798618793487549


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.43s/it]
INFO:root:final mean train loss: 15901.43150280368
INFO:root:final train perplexity: 4.798933506011963
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 47.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 47.00s/it]
INFO:root:eval mean loss: 22327.344052269345
INFO:root:eval perplexity: 10.082326889038086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/75

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [7:15:45<11:42:23, 337.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15878.842112531565
INFO:root:current train perplexity4.781946182250977
INFO:root:current mean train loss 15885.089034037373
INFO:root:current train perplexity4.785301208496094


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.99s/it]
INFO:root:final mean train loss: 15875.476660943801
INFO:root:final train perplexity: 4.786664009094238
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.34s/it]
INFO:root:eval mean loss: 22325.873697916668
INFO:root:eval perplexity: 10.080788612365723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/76

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [7:21:21<11:36:10, 336.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15847.142367493872
INFO:root:current train perplexity4.776182651519775
INFO:root:current mean train loss 15872.086694174255
INFO:root:current train perplexity4.7759222984313965


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.49s/it]
INFO:root:final mean train loss: 15852.371904926915
INFO:root:final train perplexity: 4.775768756866455
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.70s/it]
INFO:root:eval mean loss: 22321.32105654762
INFO:root:eval perplexity: 10.076043128967285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/77

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [7:27:04<11:34:19, 338.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15407.556315104166
INFO:root:current train perplexity4.630821228027344
INFO:root:current mean train loss 15842.22782349818
INFO:root:current train perplexity4.7602715492248535
INFO:root:current mean train loss 15835.524038831589
INFO:root:current train perplexity4.76302433013916


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.22s/it]
INFO:root:final mean train loss: 15833.848368983116
INFO:root:final train perplexity: 4.7670512199401855
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.82s/it]
INFO:root:eval mean loss: 22316.27074032738
INFO:root:eval perplexity: 10.070775985717773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/78

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [7:32:38<11:25:44, 337.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15783.945632102274
INFO:root:current train perplexity4.759385108947754
INFO:root:current mean train loss 15810.993510584678
INFO:root:current train perplexity4.756002426147461


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.79s/it]
INFO:root:final mean train loss: 15814.757808562248
INFO:root:final train perplexity: 4.758082866668701
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.78s/it]
INFO:root:eval mean loss: 22326.448195684523
INFO:root:eval perplexity: 10.081389427185059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/79

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [7:38:11<11:17:10, 335.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15726.310128348214
INFO:root:current train perplexity4.712811470031738
INFO:root:current mean train loss 15822.006370473131
INFO:root:current train perplexity4.749077320098877
INFO:root:current mean train loss 15821.65052272041
INFO:root:current train perplexity4.753557205200195


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 295.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 295.00s/it]
INFO:root:final mean train loss: 15793.266471616684
INFO:root:final train perplexity: 4.748007774353027
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.58s/it]
INFO:root:eval mean loss: 22313.788922991072
INFO:root:eval perplexity: 10.068190574645996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/80

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [7:43:59<11:19:13, 339.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15719.027095471398
INFO:root:current train perplexity4.71425724029541
INFO:root:current mean train loss 15757.233539701258
INFO:root:current train perplexity4.727421760559082


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.90s/it]
INFO:root:final mean train loss: 15768.85701234879
INFO:root:final train perplexity: 4.73659086227417
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.84s/it]
INFO:root:eval mean loss: 22317.408830915178
INFO:root:eval perplexity: 10.071962356567383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/81

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [7:49:44<11:16:28, 341.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15857.822531960228
INFO:root:current train perplexity4.808398723602295
INFO:root:current mean train loss 15772.21411352759
INFO:root:current train perplexity4.7227253913879395
INFO:root:current mean train loss 15774.81518438981
INFO:root:current train perplexity4.725595474243164


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.26s/it]
INFO:root:final mean train loss: 15745.63543110509
INFO:root:final train perplexity: 4.725754737854004
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.46s/it]
INFO:root:eval mean loss: 22316.361490885418
INFO:root:eval perplexity: 10.07087230682373
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/82

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [7:55:23<11:09:50, 340.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15726.255952380952
INFO:root:current train perplexity4.7162766456604
INFO:root:current mean train loss 15726.320036905674
INFO:root:current train perplexity4.721625328063965


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.28s/it]
INFO:root:final mean train loss: 15729.417496219758
INFO:root:final train perplexity: 4.718201160430908
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.81s/it]
INFO:root:eval mean loss: 22309.14208984375
INFO:root:eval perplexity: 10.063347816467285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/83

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [8:00:57<11:00:15, 338.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15724.376627604166
INFO:root:current train perplexity4.683462619781494
INFO:root:current mean train loss 15694.710810122282
INFO:root:current train perplexity4.704416275024414
INFO:root:current mean train loss 15719.347492732559
INFO:root:current train perplexity4.708621025085449


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.31s/it]
INFO:root:final mean train loss: 15706.049828314011
INFO:root:final train perplexity: 4.707339286804199
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.58s/it]
INFO:root:eval mean loss: 22322.793596540178
INFO:root:eval perplexity: 10.0775785446167
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/84

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [8:06:48<11:01:39, 342.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15651.571041277984
INFO:root:current train perplexity4.688732147216797
INFO:root:current mean train loss 15698.553149560254
INFO:root:current train perplexity4.6990838050842285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.33s/it]
INFO:root:final mean train loss: 15694.32008017263
INFO:root:final train perplexity: 4.701895713806152
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.33s/it]
INFO:root:eval mean loss: 22314.63746279762
INFO:root:eval perplexity: 10.069073677062988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/85

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [8:12:24<10:52:36, 340.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15468.910053453947
INFO:root:current train perplexity4.685290813446045
INFO:root:current mean train loss 15684.641117384454
INFO:root:current train perplexity4.686830997467041
INFO:root:current mean train loss 15679.217969641837
INFO:root:current train perplexity4.687877655029297


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.94s/it]
INFO:root:final mean train loss: 15666.502504410282
INFO:root:final train perplexity: 4.68901252746582
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.65s/it]
INFO:root:eval mean loss: 22318.770531063987
INFO:root:eval perplexity: 10.073384284973145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/86

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [8:18:08<10:48:33, 341.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15599.8857421875
INFO:root:current train perplexity4.682583332061768
INFO:root:current mean train loss 15647.261073419226
INFO:root:current train perplexity4.679515361785889


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.97s/it]
INFO:root:final mean train loss: 15653.355756205898
INFO:root:final train perplexity: 4.682937145233154
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.62s/it]
INFO:root:eval mean loss: 22319.596865699405
INFO:root:eval perplexity: 10.074243545532227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/87

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [8:23:58<10:47:58, 344.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15672.004288383152
INFO:root:current train perplexity4.6677045822143555
INFO:root:current mean train loss 15641.49558561992
INFO:root:current train perplexity4.671988010406494
INFO:root:current mean train loss 15645.621098129204
INFO:root:current train perplexity4.674248695373535


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.30s/it]
INFO:root:final mean train loss: 15635.030769594254
INFO:root:final train perplexity: 4.67448091506958
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.32s/it]
INFO:root:eval mean loss: 22324.84791201637
INFO:root:eval perplexity: 10.079721450805664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/88

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [8:29:40<10:41:19, 343.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15619.101770833333
INFO:root:current train perplexity4.654271602630615
INFO:root:current mean train loss 15610.795658482142
INFO:root:current train perplexity4.661063194274902


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.81s/it]
INFO:root:final mean train loss: 15615.109670331402
INFO:root:final train perplexity: 4.665305137634277
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.13s/it]
INFO:root:eval mean loss: 22306.241187686013
INFO:root:eval perplexity: 10.060327529907227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/89

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [8:35:21<10:33:45, 342.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15578.599175347223
INFO:root:current train perplexity4.65101957321167
INFO:root:current mean train loss 15555.061446542815
INFO:root:current train perplexity4.638437747955322
INFO:root:current mean train loss 15595.296646992016
INFO:root:current train perplexity4.652505874633789


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.77s/it]
INFO:root:final mean train loss: 15596.60533092868
INFO:root:final train perplexity: 4.656797409057617
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.56s/it]
INFO:root:eval mean loss: 22313.081380208332
INFO:root:eval perplexity: 10.067451477050781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/90

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [8:41:17<10:35:28, 346.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15643.625259592563
INFO:root:current train perplexity4.653990268707275
INFO:root:current mean train loss 15585.16723769204
INFO:root:current train perplexity4.64825439453125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.71s/it]
INFO:root:final mean train loss: 15583.46469017767
INFO:root:final train perplexity: 4.650765895843506
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.80s/it]
INFO:root:eval mean loss: 22297.67940848214
INFO:root:eval perplexity: 10.05141830444336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/91
##########################best#################
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [8:47:06<10:31:16, 347.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15576.58634702621
INFO:root:current train perplexity4.647563934326172
INFO:root:current mean train loss 15563.799730140745
INFO:root:current train perplexity4.645298957824707
INFO:root:current mean train loss 15574.418319636094
INFO:root:current train perplexity4.643315315246582


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.03s/it]
INFO:root:final mean train loss: 15565.32609311996
INFO:root:final train perplexity: 4.642451763153076
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.08s/it]
INFO:root:eval mean loss: 22320.99586123512
INFO:root:eval perplexity: 10.075701713562012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/92

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [8:52:49<10:23:03, 346.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15580.027873211597
INFO:root:current train perplexity4.642180442810059
INFO:root:current mean train loss 15556.67569053108
INFO:root:current train perplexity4.6330389976501465


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.76s/it]
INFO:root:final mean train loss: 15547.047241210938
INFO:root:final train perplexity: 4.634089469909668
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.29s/it]
INFO:root:eval mean loss: 22313.89285714286
INFO:root:eval perplexity: 10.06829833984375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/93

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [8:58:36<10:17:39, 346.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15524.291964285714
INFO:root:current train perplexity4.598790645599365
INFO:root:current mean train loss 15511.383991608796
INFO:root:current train perplexity4.618288040161133
INFO:root:current mean train loss 15536.296488530585
INFO:root:current train perplexity4.623632431030273


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.39s/it]
INFO:root:final mean train loss: 15525.62091655116
INFO:root:final train perplexity: 4.624307155609131
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.18s/it]
INFO:root:eval mean loss: 22324.02001953125
INFO:root:eval perplexity: 10.078856468200684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/94

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [9:04:13<10:07:10, 343.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15544.181337553879
INFO:root:current train perplexity4.612452030181885
INFO:root:current mean train loss 15531.842883104946
INFO:root:current train perplexity4.619887351989746


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.30s/it]
INFO:root:final mean train loss: 15512.195513325352
INFO:root:final train perplexity: 4.618188858032227
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.63s/it]
INFO:root:eval mean loss: 22318.87379092262
INFO:root:eval perplexity: 10.073490142822266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/95

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [9:09:50<9:57:48, 341.61s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15436.558794070514
INFO:root:current train perplexity4.563989162445068
INFO:root:current mean train loss 15501.056661701889
INFO:root:current train perplexity4.5962066650390625
INFO:root:current mean train loss 15520.34641409519
INFO:root:current train perplexity4.611839294433594


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:12<00:00, 312.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:12<00:00, 312.14s/it]
INFO:root:final mean train loss: 15497.062669323337
INFO:root:final train perplexity: 4.611299991607666
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.61s/it]
INFO:root:eval mean loss: 22318.943777901786
INFO:root:eval perplexity: 10.073561668395996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/96

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [9:15:50<10:01:38, 347.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15523.206537603022
INFO:root:current train perplexity4.609179496765137
INFO:root:current mean train loss 15478.92292825589
INFO:root:current train perplexity4.602740287780762


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.60s/it]
INFO:root:final mean train loss: 15478.231657951108
INFO:root:final train perplexity: 4.602743625640869
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.51s/it]
INFO:root:eval mean loss: 22331.324311755954
INFO:root:eval perplexity: 10.086482048034668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/97

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [9:21:29<9:51:36, 344.62s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15474.343136809593
INFO:root:current train perplexity4.608967304229736
INFO:root:current mean train loss 15485.487905649039
INFO:root:current train perplexity4.603877544403076
INFO:root:current mean train loss 15476.708739229682
INFO:root:current train perplexity4.598299026489258


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.55s/it]
INFO:root:final mean train loss: 15467.931821761593
INFO:root:final train perplexity: 4.59807014465332
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.11s/it]
INFO:root:eval mean loss: 22319.117606026786
INFO:root:eval perplexity: 10.073746681213379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/98

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [9:27:16<9:46:50, 345.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15489.9287109375
INFO:root:current train perplexity4.5871381759643555
INFO:root:current mean train loss 15465.406475360576
INFO:root:current train perplexity4.590145587921143


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.35s/it]
INFO:root:final mean train loss: 15450.800596175655
INFO:root:final train perplexity: 4.590307235717773
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.28s/it]
INFO:root:eval mean loss: 22311.183733258928
INFO:root:eval perplexity: 10.065476417541504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/99

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [9:33:04<9:42:46, 346.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15363.218043550532
INFO:root:current train perplexity4.536372184753418
INFO:root:current mean train loss 15422.214644451531
INFO:root:current train perplexity4.5687031745910645
INFO:root:current mean train loss 15435.773307028086
INFO:root:current train perplexity4.578008651733398


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.83s/it]
INFO:root:final mean train loss: 15425.104704826108
INFO:root:final train perplexity: 4.578688621520996
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.20s/it]
INFO:root:eval mean loss: 22321.188802083332
INFO:root:eval perplexity: 10.075905799865723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/100

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [9:38:57<9:40:24, 348.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15372.65849905303
INFO:root:current train perplexity4.559463024139404
INFO:root:current mean train loss 15439.575946136934
INFO:root:current train perplexity4.576246738433838


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.52s/it]
INFO:root:final mean train loss: 15419.577215379284
INFO:root:final train perplexity: 4.5761919021606445
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.51s/it]
INFO:root:eval mean loss: 22314.427176339286
INFO:root:eval perplexity: 10.068853378295898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/101

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [9:44:45<9:34:35, 348.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15446.15682444853
INFO:root:current train perplexity4.560049057006836
INFO:root:current mean train loss 15428.213757243377
INFO:root:current train perplexity4.570146083831787


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.26s/it]
INFO:root:final mean train loss: 15404.861745526714
INFO:root:final train perplexity: 4.569555759429932
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.01s/it]
INFO:root:eval mean loss: 22310.465355282737
INFO:root:eval perplexity: 10.064724922180176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/102

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [9:50:33<9:28:45, 348.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15456.819986979166
INFO:root:current train perplexity4.5006232261657715
INFO:root:current mean train loss 15414.363395024271
INFO:root:current train perplexity4.552417755126953
INFO:root:current mean train loss 15382.837847329125
INFO:root:current train perplexity4.5546875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.73s/it]
INFO:root:final mean train loss: 15383.70164046749
INFO:root:final train perplexity: 4.56002950668335
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.53s/it]
INFO:root:eval mean loss: 22312.161528087796
INFO:root:eval perplexity: 10.066495895385742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/103

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [9:56:19<9:21:27, 347.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15352.487127130682
INFO:root:current train perplexity4.530787944793701
INFO:root:current mean train loss 15371.994449344758
INFO:root:current train perplexity4.554015636444092


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.06s/it]
INFO:root:final mean train loss: 15373.358248802924
INFO:root:final train perplexity: 4.5553789138793945
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.40s/it]
INFO:root:eval mean loss: 22314.34509858631
INFO:root:eval perplexity: 10.068769454956055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/104

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [10:02:02<9:13:48, 346.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15190.272181919643
INFO:root:current train perplexity4.4978718757629395
INFO:root:current mean train loss 15284.669173481308
INFO:root:current train perplexity4.532955646514893
INFO:root:current mean train loss 15371.007251094505
INFO:root:current train perplexity4.551815032958984


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.54s/it]
INFO:root:final mean train loss: 15363.309633316532
INFO:root:final train perplexity: 4.55086612701416
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.17s/it]
INFO:root:eval mean loss: 22320.97047061012
INFO:root:eval perplexity: 10.075677871704102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/105

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [10:07:43<9:05:49, 344.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15348.0419921875
INFO:root:current train perplexity4.541544437408447
INFO:root:current mean train loss 15380.817450373428
INFO:root:current train perplexity4.544753074645996


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.15s/it]
INFO:root:final mean train loss: 15342.939965032761
INFO:root:final train perplexity: 4.541731834411621
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.61s/it]
INFO:root:eval mean loss: 22326.481352306546
INFO:root:eval perplexity: 10.081425666809082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/106

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [10:13:36<9:03:49, 347.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15057.127219460228
INFO:root:current train perplexity4.491206169128418
INFO:root:current mean train loss 15294.563177435248
INFO:root:current train perplexity4.519106864929199
INFO:root:current mean train loss 15337.44050836789
INFO:root:current train perplexity4.533237934112549


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.43s/it]
INFO:root:final mean train loss: 15328.46361123362
INFO:root:final train perplexity: 4.535252571105957
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.13s/it]
INFO:root:eval mean loss: 22327.453776041668
INFO:root:eval perplexity: 10.082440376281738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/107

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [10:19:16<8:54:26, 344.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15282.172309027777
INFO:root:current train perplexity4.520027160644531
INFO:root:current mean train loss 15322.095547354294
INFO:root:current train perplexity4.528378486633301


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.56s/it]
INFO:root:final mean train loss: 15320.155490013862
INFO:root:final train perplexity: 4.53153657913208
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.11s/it]
INFO:root:eval mean loss: 22331.177641369046
INFO:root:eval perplexity: 10.086325645446777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/108

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [10:24:58<8:47:39, 344.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15047.3794921875
INFO:root:current train perplexity4.499904155731201
INFO:root:current mean train loss 15280.115760869565
INFO:root:current train perplexity4.5132527351379395
INFO:root:current mean train loss 15306.785092659884
INFO:root:current train perplexity4.5198187828063965


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.04s/it]
INFO:root:final mean train loss: 15301.971179592994
INFO:root:final train perplexity: 4.523416519165039
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.50s/it]
INFO:root:eval mean loss: 22344.928199404763
INFO:root:eval perplexity: 10.100689888000488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/109

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [10:30:51<8:45:53, 346.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15223.579028684702
INFO:root:current train perplexity4.501588821411133
INFO:root:current mean train loss 15277.17740105726
INFO:root:current train perplexity4.51447868347168


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.52s/it]
INFO:root:final mean train loss: 15286.450490643902
INFO:root:final train perplexity: 4.5164971351623535
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.11s/it]
INFO:root:eval mean loss: 22340.370954241072
INFO:root:eval perplexity: 10.095927238464355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/110

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [10:36:35<8:39:06, 346.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15278.41267475329
INFO:root:current train perplexity4.496984004974365
INFO:root:current mean train loss 15326.83331144958
INFO:root:current train perplexity4.513873100280762
INFO:root:current mean train loss 15286.673181542523
INFO:root:current train perplexity4.511678695678711


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.79s/it]
INFO:root:final mean train loss: 15280.920792118195
INFO:root:final train perplexity: 4.514033794403076
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.43s/it]
INFO:root:eval mean loss: 22345.55689639137
INFO:root:eval perplexity: 10.101346969604492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/111

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [10:42:21<8:32:53, 345.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15300.232188050177
INFO:root:current train perplexity4.51370096206665
INFO:root:current mean train loss 15283.599261010599
INFO:root:current train perplexity4.511157512664795


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.73s/it]
INFO:root:final mean train loss: 15264.690457251763
INFO:root:final train perplexity: 4.506814002990723
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.96s/it]
INFO:root:eval mean loss: 22343.78097098214
INFO:root:eval perplexity: 10.09949016571045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/112

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [10:48:02<8:25:12, 344.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15189.584833559782
INFO:root:current train perplexity4.482785701751709
INFO:root:current mean train loss 15242.039681783537
INFO:root:current train perplexity4.501673698425293
INFO:root:current mean train loss 15259.459360986548
INFO:root:current train perplexity4.503389835357666


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.48s/it]
INFO:root:final mean train loss: 15253.614383820564
INFO:root:final train perplexity: 4.501892566680908
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.19s/it]
INFO:root:eval mean loss: 22344.854585193454
INFO:root:eval perplexity: 10.100615501403809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/113

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [10:53:40<8:16:51, 342.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15238.065234375
INFO:root:current train perplexity4.496653079986572
INFO:root:current mean train loss 15260.491383928571
INFO:root:current train perplexity4.502171039581299


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.91s/it]
INFO:root:final mean train loss: 15245.909723097278
INFO:root:final train perplexity: 4.498473167419434
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.92s/it]
INFO:root:eval mean loss: 22336.102864583332
INFO:root:eval perplexity: 10.091470718383789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/114

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [10:59:23<8:11:18, 342.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15205.433051215277
INFO:root:current train perplexity4.511585712432861
INFO:root:current mean train loss 15225.785609928642
INFO:root:current train perplexity4.493707180023193
INFO:root:current mean train loss 15238.502262871696
INFO:root:current train perplexity4.489606857299805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.92s/it]
INFO:root:final mean train loss: 15233.202782415574
INFO:root:final train perplexity: 4.4928388595581055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.62s/it]
INFO:root:eval mean loss: 22331.959542410714
INFO:root:eval perplexity: 10.087142944335938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/115

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [11:05:03<8:04:05, 341.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15197.301485858387
INFO:root:current train perplexity4.47846794128418
INFO:root:current mean train loss 15228.208155115224
INFO:root:current train perplexity4.480128765106201


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.73s/it]
INFO:root:final mean train loss: 15214.661770728326
INFO:root:final train perplexity: 4.484630107879639
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.04s/it]
INFO:root:eval mean loss: 22337.680106026786
INFO:root:eval perplexity: 10.093113899230957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/116

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [11:10:38<7:55:39, 339.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15265.398311491936
INFO:root:current train perplexity4.490485668182373
INFO:root:current mean train loss 15239.235008647423
INFO:root:current train perplexity4.482836723327637
INFO:root:current mean train loss 15220.164734679383
INFO:root:current train perplexity4.481466293334961


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.90s/it]
INFO:root:final mean train loss: 15203.092710433468
INFO:root:final train perplexity: 4.479515552520752
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.50s/it]
INFO:root:eval mean loss: 22347.592308407737
INFO:root:eval perplexity: 10.103476524353027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/117

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [11:16:12<7:47:42, 338.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15204.432970161897
INFO:root:current train perplexity4.469033718109131
INFO:root:current mean train loss 15221.094790599385
INFO:root:current train perplexity4.4762139320373535


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.74s/it]
INFO:root:final mean train loss: 15194.2177734375
INFO:root:final train perplexity: 4.4755964279174805
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.34s/it]
INFO:root:eval mean loss: 22357.017903645832
INFO:root:eval perplexity: 10.113333702087402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/118

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [11:21:53<7:43:10, 338.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15138.652957589286
INFO:root:current train perplexity4.444769859313965
INFO:root:current mean train loss 15198.258362268518
INFO:root:current train perplexity4.46248722076416
INFO:root:current mean train loss 15193.889016788564
INFO:root:current train perplexity4.4709391593933105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.80s/it]
INFO:root:final mean train loss: 15183.560558688256
INFO:root:final train perplexity: 4.4708943367004395
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.34s/it]
INFO:root:eval mean loss: 22344.145112537204
INFO:root:eval perplexity: 10.099870681762695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/119

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [11:27:26<7:35:05, 337.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15131.434312140804
INFO:root:current train perplexity4.463614463806152
INFO:root:current mean train loss 15175.004010695187
INFO:root:current train perplexity4.463810920715332


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.70s/it]
INFO:root:final mean train loss: 15171.884190713206
INFO:root:final train perplexity: 4.4657487869262695
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.47s/it]
INFO:root:eval mean loss: 22353.298525855655
INFO:root:eval perplexity: 10.109442710876465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/120

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [11:33:06<7:30:36, 337.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15113.375901442309
INFO:root:current train perplexity4.438600063323975
INFO:root:current mean train loss 15132.724244042267
INFO:root:current train perplexity4.4528422355651855
INFO:root:current mean train loss 15162.720106563807
INFO:root:current train perplexity4.457190990447998


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.35s/it]
INFO:root:final mean train loss: 15153.633600050403
INFO:root:final train perplexity: 4.45771598815918
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.78s/it]
INFO:root:eval mean loss: 22349.110374813987
INFO:root:eval perplexity: 10.105064392089844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/121

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [11:38:41<7:23:54, 337.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15126.528427627061
INFO:root:current train perplexity4.447227478027344
INFO:root:current mean train loss 15140.417268283703
INFO:root:current train perplexity4.444695472717285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.00s/it]
INFO:root:final mean train loss: 15147.76390420237
INFO:root:final train perplexity: 4.455136775970459
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.51s/it]
INFO:root:eval mean loss: 22348.71363467262
INFO:root:eval perplexity: 10.104649543762207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/122

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [11:44:27<7:21:49, 339.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15117.511423510174
INFO:root:current train perplexity4.462667942047119
INFO:root:current mean train loss 15164.71119700612
INFO:root:current train perplexity4.4559783935546875
INFO:root:current mean train loss 15151.071594489455
INFO:root:current train perplexity4.451525688171387


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.76s/it]
INFO:root:final mean train loss: 15139.32339575983
INFO:root:final train perplexity: 4.451430320739746
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.79s/it]
INFO:root:eval mean loss: 22354.69505673363
INFO:root:eval perplexity: 10.110905647277832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/123

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [11:50:03<7:14:24, 338.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15105.404009046053
INFO:root:current train perplexity4.4416680335998535
INFO:root:current mean train loss 15145.970853365385
INFO:root:current train perplexity4.444623947143555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.20s/it]
INFO:root:final mean train loss: 15128.843210527973
INFO:root:final train perplexity: 4.446831226348877
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:48<00:00, 48.08s/it]
INFO:root:eval mean loss: 22359.3046875
INFO:root:eval perplexity: 10.115728378295898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/124

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [11:55:44<7:09:54, 339.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15111.02775930851
INFO:root:current train perplexity4.42849588394165
INFO:root:current mean train loss 15129.891641422193
INFO:root:current train perplexity4.4378862380981445
INFO:root:current mean train loss 15131.147346280364
INFO:root:current train perplexity4.442141532897949


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.41s/it]
INFO:root:final mean train loss: 15117.371771043347
INFO:root:final train perplexity: 4.441802024841309
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.62s/it]
INFO:root:eval mean loss: 22351.65352957589
INFO:root:eval perplexity: 10.1077241897583
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/125

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [12:01:28<7:06:01, 340.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15095.43549755366
INFO:root:current train perplexity4.431706428527832
INFO:root:current mean train loss 15112.904910293655
INFO:root:current train perplexity4.433371067047119


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.73s/it]
INFO:root:final mean train loss: 15105.067410376763
INFO:root:final train perplexity: 4.43641471862793
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.05s/it]
INFO:root:eval mean loss: 22341.527808779763
INFO:root:eval perplexity: 10.097135543823242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/126

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [12:07:04<6:58:22, 339.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15100.401845894608
INFO:root:current train perplexity4.4273786544799805
INFO:root:current mean train loss 15087.657795685016
INFO:root:current train perplexity4.427988052368164


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.52s/it]
INFO:root:final mean train loss: 15099.491648027973
INFO:root:final train perplexity: 4.4339752197265625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.72s/it]
INFO:root:eval mean loss: 22355.652971540178
INFO:root:eval perplexity: 10.111908912658691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/127

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [12:12:44<6:52:59, 339.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14924.1337890625
INFO:root:current train perplexity4.438325881958008
INFO:root:current mean train loss 15081.775201001214
INFO:root:current train perplexity4.4286274909973145
INFO:root:current mean train loss 15081.492336630234
INFO:root:current train perplexity4.422661304473877


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.33s/it]
INFO:root:final mean train loss: 15083.489056987148
INFO:root:final train perplexity: 4.426982402801514
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.48s/it]
INFO:root:eval mean loss: 22351.232491629464
INFO:root:eval perplexity: 10.107282638549805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/128

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [12:18:22<6:46:52, 339.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15101.378888494319
INFO:root:current train perplexity4.427541732788086
INFO:root:current mean train loss 15086.090517893144
INFO:root:current train perplexity4.426828861236572


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.85s/it]
INFO:root:final mean train loss: 15079.178529800907
INFO:root:final train perplexity: 4.425101280212402
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.02s/it]
INFO:root:eval mean loss: 22357.74744233631
INFO:root:eval perplexity: 10.114100456237793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/129

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [12:24:13<6:45:23, 342.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15108.176060267857
INFO:root:current train perplexity4.381299018859863
INFO:root:current mean train loss 15097.332213785046
INFO:root:current train perplexity4.431206703186035
INFO:root:current mean train loss 15080.632411496075
INFO:root:current train perplexity4.421826362609863


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:03<00:00, 303.56s/it]
INFO:root:final mean train loss: 15068.851078156502
INFO:root:final train perplexity: 4.420595169067383
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.03s/it]
INFO:root:eval mean loss: 22383.492350260418
INFO:root:eval perplexity: 10.141083717346191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/130

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [12:30:04<6:42:44, 345.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15102.452065677966
INFO:root:current train perplexity4.427750110626221
INFO:root:current mean train loss 15053.420701896619
INFO:root:current train perplexity4.417291164398193


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.35s/it]
INFO:root:final mean train loss: 15061.42218608241
INFO:root:final train perplexity: 4.417357444763184
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.62s/it]
INFO:root:eval mean loss: 22360.637044270832
INFO:root:eval perplexity: 10.117124557495117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/131

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [12:35:51<6:37:33, 345.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14977.49502840909
INFO:root:current train perplexity4.437460899353027
INFO:root:current mean train loss 15056.692356418918
INFO:root:current train perplexity4.408944606781006
INFO:root:current mean train loss 15049.661965898993
INFO:root:current train perplexity4.409520626068115


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.69s/it]
INFO:root:final mean train loss: 15047.83999732233
INFO:root:final train perplexity: 4.411443710327148
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.42s/it]
INFO:root:eval mean loss: 22364.000511532737
INFO:root:eval perplexity: 10.120646476745605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/132

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [12:41:45<6:34:36, 348.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14937.068002852182
INFO:root:current train perplexity4.393709182739258
INFO:root:current mean train loss 15004.464675996933
INFO:root:current train perplexity4.397762298583984


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.82s/it]
INFO:root:final mean train loss: 15035.837512600807
INFO:root:final train perplexity: 4.406224250793457
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.90s/it]
INFO:root:eval mean loss: 22362.7412109375
INFO:root:eval perplexity: 10.119329452514648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/133

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [12:47:31<6:28:15, 347.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15013.136979166668
INFO:root:current train perplexity4.420023441314697
INFO:root:current mean train loss 15044.971875
INFO:root:current train perplexity4.410130977630615
INFO:root:current mean train loss 15033.636845930232
INFO:root:current train perplexity4.3997111320495605


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.89s/it]
INFO:root:final mean train loss: 15025.778103736138
INFO:root:final train perplexity: 4.40185546875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.63s/it]
INFO:root:eval mean loss: 22378.86072358631
INFO:root:eval perplexity: 10.136224746704102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/134

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [12:53:11<6:19:41, 345.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14977.035418610074
INFO:root:current train perplexity4.381811618804932
INFO:root:current mean train loss 15058.044711358532
INFO:root:current train perplexity4.407088756561279


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.39s/it]
INFO:root:final mean train loss: 15024.362836284023
INFO:root:final train perplexity: 4.401240348815918
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.99s/it]
INFO:root:eval mean loss: 22374.26490420387
INFO:root:eval perplexity: 10.131406784057617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/135

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [12:58:55<6:13:39, 344.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15071.174136513158
INFO:root:current train perplexity4.401847839355469
INFO:root:current mean train loss 15041.917377888656
INFO:root:current train perplexity4.403995037078857
INFO:root:current mean train loss 15042.565585759132
INFO:root:current train perplexity4.397768974304199


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.72s/it]
INFO:root:final mean train loss: 15009.552612304688
INFO:root:final train perplexity: 4.3948163986206055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.52s/it]
INFO:root:eval mean loss: 22382.566243489582
INFO:root:eval perplexity: 10.140111923217773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/136

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [13:04:52<6:11:48, 348.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14997.638506822183
INFO:root:current train perplexity4.385984897613525
INFO:root:current mean train loss 15035.175381487574
INFO:root:current train perplexity4.394624710083008


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.33s/it]
INFO:root:final mean train loss: 15007.38966812626
INFO:root:final train perplexity: 4.393878936767578
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.65s/it]
INFO:root:eval mean loss: 22377.762067522322
INFO:root:eval perplexity: 10.135074615478516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/137

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [13:10:32<6:03:16, 345.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14902.616550611414
INFO:root:current train perplexity4.360902786254883
INFO:root:current mean train loss 14982.686968051321
INFO:root:current train perplexity4.385165691375732
INFO:root:current mean train loss 14995.125341577916
INFO:root:current train perplexity4.386467456817627


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.23s/it]
INFO:root:final mean train loss: 14987.979330739667
INFO:root:final train perplexity: 4.385475158691406
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.31s/it]
INFO:root:eval mean loss: 22384.262765066964
INFO:root:eval perplexity: 10.14189338684082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/138

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [13:16:16<5:56:59, 345.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14931.5510546875
INFO:root:current train perplexity4.364553928375244
INFO:root:current mean train loss 14981.903995535715
INFO:root:current train perplexity4.373899459838867


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.86s/it]
INFO:root:final mean train loss: 14984.91830345892
INFO:root:final train perplexity: 4.384151458740234
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.45s/it]
INFO:root:eval mean loss: 22374.55689639137
INFO:root:eval perplexity: 10.13171100616455
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/139

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [13:22:10<5:53:38, 347.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14991.310402199075
INFO:root:current train perplexity4.384243965148926
INFO:root:current mean train loss 14955.893262487696
INFO:root:current train perplexity4.374471664428711
INFO:root:current mean train loss 14992.447984065253
INFO:root:current train perplexity4.381030559539795


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.03s/it]
INFO:root:final mean train loss: 14980.336461221019
INFO:root:final train perplexity: 4.3821702003479
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.06s/it]
INFO:root:eval mean loss: 22380.907877604168
INFO:root:eval perplexity: 10.138373374938965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/140

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [13:28:07<5:50:51, 350.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14926.309360166139
INFO:root:current train perplexity4.372552871704102
INFO:root:current mean train loss 14954.786285570879
INFO:root:current train perplexity4.371682167053223


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.40s/it]
INFO:root:final mean train loss: 14963.908403950352
INFO:root:final train perplexity: 4.37507438659668
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.18s/it]
INFO:root:eval mean loss: 22383.346609933036
INFO:root:eval perplexity: 10.140931129455566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/141

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [13:33:44<5:40:46, 346.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14944.105972782258
INFO:root:current train perplexity4.375979900360107
INFO:root:current mean train loss 14972.66418177481
INFO:root:current train perplexity4.377941131591797
INFO:root:current mean train loss 14968.046135179924
INFO:root:current train perplexity4.37425422668457


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.75s/it]
INFO:root:final mean train loss: 14956.982918031754
INFO:root:final train perplexity: 4.372087478637695
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.93s/it]
INFO:root:eval mean loss: 22408.178571428572
INFO:root:eval perplexity: 10.167028427124023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/142

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [13:39:26<5:33:48, 345.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15019.652767319278
INFO:root:current train perplexity4.363959789276123
INFO:root:current mean train loss 14970.754471909153
INFO:root:current train perplexity4.364488124847412


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.24s/it]
INFO:root:final mean train loss: 14955.319442256805
INFO:root:final train perplexity: 4.371370315551758
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.48s/it]
INFO:root:eval mean loss: 22382.01243954613
INFO:root:eval perplexity: 10.139531135559082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/143

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [13:45:01<5:24:59, 342.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14902.410435267857
INFO:root:current train perplexity4.340539932250977
INFO:root:current mean train loss 14938.783680555556
INFO:root:current train perplexity4.356786251068115
INFO:root:current mean train loss 14950.926969747341
INFO:root:current train perplexity4.368558406829834


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.51s/it]
INFO:root:final mean train loss: 14948.735824092742
INFO:root:final train perplexity: 4.368532180786133
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.09s/it]
INFO:root:eval mean loss: 22392.380952380954
INFO:root:eval perplexity: 10.150415420532227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/144

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [13:50:40<5:18:18, 341.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14919.717728538075
INFO:root:current train perplexity4.353509426116943
INFO:root:current mean train loss 14961.825451203209
INFO:root:current train perplexity4.367273807525635


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.20s/it]
INFO:root:final mean train loss: 14940.618896484375
INFO:root:final train perplexity: 4.365036964416504
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.12s/it]
INFO:root:eval mean loss: 22395.37293061756
INFO:root:eval perplexity: 10.153562545776367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/145

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [13:56:32<5:15:47, 344.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14946.094401041666
INFO:root:current train perplexity4.355130195617676
INFO:root:current mean train loss 14933.95481115108
INFO:root:current train perplexity4.3593926429748535
INFO:root:current mean train loss 14939.65846871731
INFO:root:current train perplexity4.359930992126465


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.37s/it]
INFO:root:final mean train loss: 14929.945635395665
INFO:root:final train perplexity: 4.360443592071533
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.24s/it]
INFO:root:eval mean loss: 22389.347958519345
INFO:root:eval perplexity: 10.147233963012695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/146

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [14:02:15<5:09:31, 343.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14978.485169127747
INFO:root:current train perplexity4.3542866706848145
INFO:root:current mean train loss 14932.590196539595
INFO:root:current train perplexity4.350553512573242


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.77s/it]
INFO:root:final mean train loss: 14926.489037298386
INFO:root:final train perplexity: 4.358957767486572
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.95s/it]
INFO:root:eval mean loss: 22396.790225074405
INFO:root:eval perplexity: 10.155048370361328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/147

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [14:08:43<5:15:37, 357.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14923.809456758721
INFO:root:current train perplexity4.357834815979004
INFO:root:current mean train loss 14914.16567416958
INFO:root:current train perplexity4.348133087158203
INFO:root:current mean train loss 14932.754637667182
INFO:root:current train perplexity4.355003833770752


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.66s/it]
INFO:root:final mean train loss: 14917.736477759576
INFO:root:final train perplexity: 4.355195999145508
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.06s/it]
INFO:root:eval mean loss: 22396.674479166668
INFO:root:eval perplexity: 10.154927253723145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/148

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [14:14:24<5:05:17, 352.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14929.787705592105
INFO:root:current train perplexity4.352015018463135
INFO:root:current mean train loss 14912.496724759616
INFO:root:current train perplexity4.349699020385742


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.50s/it]
INFO:root:final mean train loss: 14913.449955109627
INFO:root:final train perplexity: 4.353355884552002
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.66s/it]
INFO:root:eval mean loss: 22392.11158389137
INFO:root:eval perplexity: 10.150136947631836
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/149

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [14:20:08<4:57:29, 349.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14894.363821476063
INFO:root:current train perplexity4.339184761047363
INFO:root:current mean train loss 14886.355980282739
INFO:root:current train perplexity4.340475559234619
INFO:root:current mean train loss 14916.905767649292
INFO:root:current train perplexity4.350268840789795


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.39s/it]
INFO:root:final mean train loss: 14905.93519641507
INFO:root:final train perplexity: 4.3501296043396
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.67s/it]
INFO:root:eval mean loss: 22397.553896949405
INFO:root:eval perplexity: 10.155855178833008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/150

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [14:26:02<4:52:27, 350.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14884.43027935606
INFO:root:current train perplexity4.336699485778809
INFO:root:current mean train loss 14879.108418066897
INFO:root:current train perplexity4.342944145202637


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.32s/it]
INFO:root:final mean train loss: 14896.85570107737
INFO:root:final train perplexity: 4.346235752105713
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.92s/it]
INFO:root:eval mean loss: 22407.255905877977
INFO:root:eval perplexity: 10.166058540344238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/151

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [14:32:08<4:50:22, 355.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14880.525352328432
INFO:root:current train perplexity4.342599391937256
INFO:root:current mean train loss 14875.428297030216
INFO:root:current train perplexity4.337512016296387


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.15s/it]
INFO:root:final mean train loss: 14889.22627110635
INFO:root:final train perplexity: 4.342966079711914
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.05s/it]
INFO:root:eval mean loss: 22401.517531622023
INFO:root:eval perplexity: 10.16002082824707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/152

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [14:38:15<4:47:17, 359.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14920.394856770834
INFO:root:current train perplexity4.335592746734619
INFO:root:current mean train loss 14869.203779202064
INFO:root:current train perplexity4.331079006195068
INFO:root:current mean train loss 14893.639431958129
INFO:root:current train perplexity4.339820384979248


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.02s/it]
INFO:root:final mean train loss: 14882.644928962955
INFO:root:final train perplexity: 4.340148448944092
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.47s/it]
INFO:root:eval mean loss: 22414.629464285714
INFO:root:eval perplexity: 10.17381763458252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/153

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [14:44:19<4:42:16, 360.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14842.122407670455
INFO:root:current train perplexity4.3178277015686035
INFO:root:current mean train loss 14863.50255796371
INFO:root:current train perplexity4.329261779785156


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.82s/it]
INFO:root:final mean train loss: 14876.76990139869
INFO:root:final train perplexity: 4.337634086608887
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.84s/it]
INFO:root:eval mean loss: 22406.282319568454
INFO:root:eval perplexity: 10.165031433105469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/154

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [14:50:47<4:42:47, 368.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14953.487862723214
INFO:root:current train perplexity4.377287864685059
INFO:root:current mean train loss 14841.210134345794
INFO:root:current train perplexity4.330280303955078
INFO:root:current mean train loss 14883.851656853865
INFO:root:current train perplexity4.3351569175720215


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.60s/it]
INFO:root:final mean train loss: 14867.840335969002
INFO:root:final train perplexity: 4.333815574645996
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.54s/it]
INFO:root:eval mean loss: 22410.89501953125
INFO:root:eval perplexity: 10.169886589050293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/155

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [14:56:24<4:29:28, 359.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14884.055399231991
INFO:root:current train perplexity4.326286315917969
INFO:root:current mean train loss 14850.795493071933
INFO:root:current train perplexity4.32592248916626


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.59s/it]
INFO:root:final mean train loss: 14857.71724577873
INFO:root:final train perplexity: 4.329490661621094
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.31s/it]
INFO:root:eval mean loss: 22404.268019903273
INFO:root:eval perplexity: 10.16291332244873
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/156

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [15:01:59<4:18:03, 351.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14834.589044744318
INFO:root:current train perplexity4.2816243171691895
INFO:root:current mean train loss 14862.002041103604
INFO:root:current train perplexity4.3216471672058105
INFO:root:current mean train loss 14868.224868557465
INFO:root:current train perplexity4.327091693878174


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.81s/it]
INFO:root:final mean train loss: 14858.521712764617
INFO:root:final train perplexity: 4.329833507537842
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.36s/it]
INFO:root:eval mean loss: 22409.88399832589
INFO:root:eval perplexity: 10.168822288513184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/157

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [15:07:39<4:09:38, 348.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14791.960968501984
INFO:root:current train perplexity4.318007946014404
INFO:root:current mean train loss 14867.009352233512
INFO:root:current train perplexity4.3306427001953125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.80s/it]
INFO:root:final mean train loss: 14857.05752268145
INFO:root:final train perplexity: 4.329208850860596
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.42s/it]
INFO:root:eval mean loss: 22412.60472470238
INFO:root:eval perplexity: 10.171686172485352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/158

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [15:13:11<4:00:23, 343.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14921.0478515625
INFO:root:current train perplexity4.3244428634643555
INFO:root:current mean train loss 14868.654517663044
INFO:root:current train perplexity4.333593368530273
INFO:root:current mean train loss 14861.39589389535
INFO:root:current train perplexity4.326519966125488


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.90s/it]
INFO:root:final mean train loss: 14847.260068831905
INFO:root:final train perplexity: 4.325026988983154
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.25s/it]
INFO:root:eval mean loss: 22414.02074032738
INFO:root:eval perplexity: 10.173177719116211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/159

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [15:18:44<3:52:30, 340.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14827.09615496735
INFO:root:current train perplexity4.309821605682373
INFO:root:current mean train loss 14836.827739053144
INFO:root:current train perplexity4.317584991455078


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.32s/it]
INFO:root:final mean train loss: 14844.35412203881
INFO:root:final train perplexity: 4.323787212371826
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.50s/it]
INFO:root:eval mean loss: 22405.623093377977
INFO:root:eval perplexity: 10.164335250854492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/160

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [15:24:25<3:46:55, 340.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14826.3125
INFO:root:current train perplexity4.303652763366699
INFO:root:current mean train loss 14857.06166294643
INFO:root:current train perplexity4.3215556144714355
INFO:root:current mean train loss 14839.371379138129
INFO:root:current train perplexity4.321553707122803


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.95s/it]
INFO:root:final mean train loss: 14839.413877425655
INFO:root:final train perplexity: 4.321681976318359
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.46s/it]
INFO:root:eval mean loss: 22418.693382626487
INFO:root:eval perplexity: 10.178099632263184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/161

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [15:30:11<3:42:23, 342.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14840.312073613557
INFO:root:current train perplexity4.306477069854736
INFO:root:current mean train loss 14838.571871573466
INFO:root:current train perplexity4.312196731567383


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.27s/it]
INFO:root:final mean train loss: 14833.372145129788
INFO:root:final train perplexity: 4.319106578826904
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.26s/it]
INFO:root:eval mean loss: 22412.487467447918
INFO:root:eval perplexity: 10.171562194824219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/162

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [15:35:59<3:37:52, 344.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14828.910453464674
INFO:root:current train perplexity4.329828262329102
INFO:root:current mean train loss 14872.615440802845
INFO:root:current train perplexity4.320310592651367
INFO:root:current mean train loss 14834.821109515135
INFO:root:current train perplexity4.312609672546387


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.70s/it]
INFO:root:final mean train loss: 14822.591332220261
INFO:root:final train perplexity: 4.314516544342041
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.97s/it]
INFO:root:eval mean loss: 22406.57654389881
INFO:root:eval perplexity: 10.1653413772583
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/163

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [15:41:42<3:31:51, 343.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14803.994375
INFO:root:current train perplexity4.321343898773193
INFO:root:current mean train loss 14813.549642857142
INFO:root:current train perplexity4.312161922454834


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.78s/it]
INFO:root:final mean train loss: 14820.9097624748
INFO:root:final train perplexity: 4.31380033493042
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.84s/it]
INFO:root:eval mean loss: 22417.961890811013
INFO:root:eval perplexity: 10.177326202392578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/164

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [15:47:25<3:26:08, 343.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14865.633391203704
INFO:root:current train perplexity4.307868003845215
INFO:root:current mean train loss 14861.973871186023
INFO:root:current train perplexity4.328950881958008
INFO:root:current mean train loss 14839.088325130782
INFO:root:current train perplexity4.317007541656494


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.76s/it]
INFO:root:final mean train loss: 14820.626807428176
INFO:root:final train perplexity: 4.313680648803711
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.84s/it]
INFO:root:eval mean loss: 22416.189267113095
INFO:root:eval perplexity: 10.175459861755371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/165

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [15:53:11<3:20:51, 344.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14847.489233089398
INFO:root:current train perplexity4.318078994750977
INFO:root:current mean train loss 14839.334780900837
INFO:root:current train perplexity4.314136505126953


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.50s/it]
INFO:root:final mean train loss: 14813.87142845892
INFO:root:final train perplexity: 4.310807704925537
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.92s/it]
INFO:root:eval mean loss: 22425.750465029763
INFO:root:eval perplexity: 10.18553352355957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/166

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [15:58:56<3:15:09, 344.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14833.637222782258
INFO:root:current train perplexity4.306654453277588
INFO:root:current mean train loss 14832.982928792939
INFO:root:current train perplexity4.305339336395264
INFO:root:current mean train loss 14821.31159953328
INFO:root:current train perplexity4.30885124206543


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.10s/it]
INFO:root:final mean train loss: 14807.285380701866
INFO:root:final train perplexity: 4.308007717132568
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.58s/it]
INFO:root:eval mean loss: 22420.550130208332
INFO:root:eval perplexity: 10.1800537109375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/167

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [16:04:44<3:09:58, 345.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14796.954431005272
INFO:root:current train perplexity4.2993035316467285
INFO:root:current mean train loss 14823.52656997097
INFO:root:current train perplexity4.304983139038086


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.12s/it]
INFO:root:final mean train loss: 14800.802706810737
INFO:root:final train perplexity: 4.3052544593811035
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.41s/it]
INFO:root:eval mean loss: 22417.779482886905
INFO:root:eval perplexity: 10.17713451385498
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/168

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [16:10:31<3:04:30, 345.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14948.91875
INFO:root:current train perplexity4.340216159820557
INFO:root:current mean train loss 14795.949768518518
INFO:root:current train perplexity4.298555850982666
INFO:root:current mean train loss 14815.494348404256
INFO:root:current train perplexity4.305481910705566


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.19s/it]
INFO:root:final mean train loss: 14797.546713552167
INFO:root:final train perplexity: 4.303872108459473
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.99s/it]
INFO:root:eval mean loss: 22423.368698846727
INFO:root:eval perplexity: 10.183024406433105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/169

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [16:16:19<2:59:03, 346.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14808.061197916666
INFO:root:current train perplexity4.309469699859619
INFO:root:current mean train loss 14803.576620989305
INFO:root:current train perplexity4.30552339553833


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.72s/it]
INFO:root:final mean train loss: 14803.398508379536
INFO:root:final train perplexity: 4.306356430053711
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.61s/it]
INFO:root:eval mean loss: 22432.45837983631
INFO:root:eval perplexity: 10.192606925964355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/170

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [16:22:09<2:53:49, 347.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14717.166716746795
INFO:root:current train perplexity4.270705223083496
INFO:root:current mean train loss 14772.716017030127
INFO:root:current train perplexity4.300418853759766
INFO:root:current mean train loss 14802.695357446391
INFO:root:current train perplexity4.303921222686768


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.36s/it]
INFO:root:final mean train loss: 14793.389498802924
INFO:root:final train perplexity: 4.302107334136963
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.10s/it]
INFO:root:eval mean loss: 22428.107863653273
INFO:root:eval perplexity: 10.188019752502441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/171

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [16:27:50<2:47:05, 345.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14834.15296617445
INFO:root:current train perplexity4.318599700927734
INFO:root:current mean train loss 14783.508870868784
INFO:root:current train perplexity4.298486232757568


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.33s/it]
INFO:root:final mean train loss: 14785.903910975303
INFO:root:final train perplexity: 4.298933029174805
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.69s/it]
INFO:root:eval mean loss: 22422.63502139137
INFO:root:eval perplexity: 10.182250022888184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/172

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [16:33:39<2:41:48, 346.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14744.41796875
INFO:root:current train perplexity4.2883172035217285
INFO:root:current mean train loss 14796.695305670892
INFO:root:current train perplexity4.2973151206970215
INFO:root:current mean train loss 14791.318853684414
INFO:root:current train perplexity4.295090198516846


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.48s/it]
INFO:root:final mean train loss: 14777.93572407384
INFO:root:final train perplexity: 4.295555114746094
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.32s/it]
INFO:root:eval mean loss: 22431.888811383928
INFO:root:eval perplexity: 10.192007064819336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/173

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [16:39:17<2:34:46, 343.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14811.669901315789
INFO:root:current train perplexity4.297239780426025
INFO:root:current mean train loss 14800.577554086538
INFO:root:current train perplexity4.2967329025268555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.65s/it]
INFO:root:final mean train loss: 14782.016703944053
INFO:root:final train perplexity: 4.297284126281738
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.29s/it]
INFO:root:eval mean loss: 22429.598237537204
INFO:root:eval perplexity: 10.189591407775879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/174

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [16:45:02<2:29:10, 344.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14711.999127327128
INFO:root:current train perplexity4.275859355926514
INFO:root:current mean train loss 14767.173788265307
INFO:root:current train perplexity4.285094738006592
INFO:root:current mean train loss 14789.198471501772
INFO:root:current train perplexity4.295639514923096


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.28s/it]
INFO:root:final mean train loss: 14777.304407919606
INFO:root:final train perplexity: 4.295288562774658
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.99s/it]
INFO:root:eval mean loss: 22426.36837332589
INFO:root:eval perplexity: 10.186186790466309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/175

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [16:51:22<2:27:57, 355.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14769.200984453913
INFO:root:current train perplexity4.287871837615967
INFO:root:current mean train loss 14774.056733864636
INFO:root:current train perplexity4.289241790771484


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.17s/it]
INFO:root:final mean train loss: 14770.753382528981
INFO:root:final train perplexity: 4.292512893676758
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.24s/it]
INFO:root:eval mean loss: 22425.60779389881
INFO:root:eval perplexity: 10.185382843017578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/176

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [16:56:59<2:19:49, 349.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14788.30330882353
INFO:root:current train perplexity4.280853748321533
INFO:root:current mean train loss 14768.064511330713
INFO:root:current train perplexity4.284226417541504


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:02<00:00, 302.95s/it]
INFO:root:final mean train loss: 14769.095651934223
INFO:root:final train perplexity: 4.291810989379883
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.48s/it]
INFO:root:eval mean loss: 22432.58028738839
INFO:root:eval perplexity: 10.19273853302002
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/177

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [17:02:50<2:14:10, 350.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14800.427083333334
INFO:root:current train perplexity4.276400566101074
INFO:root:current mean train loss 14764.634689775485
INFO:root:current train perplexity4.2892022132873535
INFO:root:current mean train loss 14790.934613608375
INFO:root:current train perplexity4.291921138763428


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.03s/it]
INFO:root:final mean train loss: 14768.032431325604
INFO:root:final train perplexity: 4.291361331939697
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.65s/it]
INFO:root:eval mean loss: 22435.731026785714
INFO:root:eval perplexity: 10.19605827331543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/178

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [17:09:08<2:11:22, 358.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14828.156764914773
INFO:root:current train perplexity4.283688068389893
INFO:root:current mean train loss 14797.757711693548
INFO:root:current train perplexity4.290390968322754


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.73s/it]
INFO:root:final mean train loss: 14763.95238076487
INFO:root:final train perplexity: 4.289634704589844
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.09s/it]
INFO:root:eval mean loss: 22438.267624627977
INFO:root:eval perplexity: 10.198738098144531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/179

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [17:15:06<2:05:22, 358.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14683.277064732143
INFO:root:current train perplexity4.269473075866699
INFO:root:current mean train loss 14741.886527088202
INFO:root:current train perplexity4.286561489105225
INFO:root:current mean train loss 14769.865739168175
INFO:root:current train perplexity4.287369728088379


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.93s/it]
INFO:root:final mean train loss: 14761.267999464466
INFO:root:final train perplexity: 4.288498878479004
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:47<00:00, 47.22s/it]
INFO:root:eval mean loss: 22433.140764508928
INFO:root:eval perplexity: 10.193325996398926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/180

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [17:21:31<2:02:06, 366.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14730.350668697034
INFO:root:current train perplexity4.283608913421631
INFO:root:current mean train loss 14742.09113969143
INFO:root:current train perplexity4.278219223022461


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:52<00:00, 292.55s/it]
INFO:root:final mean train loss: 14758.944773027973
INFO:root:final train perplexity: 4.2875165939331055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.25s/it]
INFO:root:eval mean loss: 22436.95665922619
INFO:root:eval perplexity: 10.197354316711426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/181

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [17:27:59<1:58:07, 373.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14852.364524147728
INFO:root:current train perplexity4.271313667297363
INFO:root:current mean train loss 14784.695954743805
INFO:root:current train perplexity4.289772987365723
INFO:root:current mean train loss 14770.56982190462
INFO:root:current train perplexity4.287281036376953


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.40s/it]
INFO:root:final mean train loss: 14753.90867171749
INFO:root:final train perplexity: 4.28538703918457
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.96s/it]
INFO:root:eval mean loss: 22437.251813616072
INFO:root:eval perplexity: 10.197663307189941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/182

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [17:34:30<1:53:30, 378.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14707.015423487102
INFO:root:current train perplexity4.27595329284668
INFO:root:current mean train loss 14745.860069976994
INFO:root:current train perplexity4.277322769165039


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.78s/it]
INFO:root:final mean train loss: 14753.385064894153
INFO:root:final train perplexity: 4.285166263580322
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.32s/it]
INFO:root:eval mean loss: 22435.83077566964
INFO:root:eval perplexity: 10.196165084838867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/183

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [17:40:15<1:44:21, 368.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14726.522526041666
INFO:root:current train perplexity4.2968363761901855
INFO:root:current mean train loss 14759.776936141305
INFO:root:current train perplexity4.286377429962158
INFO:root:current mean train loss 14755.09300962936
INFO:root:current train perplexity4.281248569488525


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.83s/it]
INFO:root:final mean train loss: 14743.73380796371
INFO:root:final train perplexity: 4.281088829040527
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.69s/it]
INFO:root:eval mean loss: 22432.57496279762
INFO:root:eval perplexity: 10.192730903625488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/184

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [17:46:41<1:39:39, 373.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14774.825107859142
INFO:root:current train perplexity4.27388334274292
INFO:root:current mean train loss 14751.942341878743
INFO:root:current train perplexity4.277238368988037


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.74s/it]
INFO:root:final mean train loss: 14746.007977885585
INFO:root:final train perplexity: 4.282049179077148
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.86s/it]
INFO:root:eval mean loss: 22437.139950706845
INFO:root:eval perplexity: 10.197548866271973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/185

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [17:53:08<1:34:22, 377.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14690.078279194078
INFO:root:current train perplexity4.261691570281982
INFO:root:current mean train loss 14742.95807346376
INFO:root:current train perplexity4.282853126525879
INFO:root:current mean train loss 14767.265500142694
INFO:root:current train perplexity4.2846598625183105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.56s/it]
INFO:root:final mean train loss: 14743.966749621975
INFO:root:final train perplexity: 4.281187534332275
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.84s/it]
INFO:root:eval mean loss: 22434.444266183036
INFO:root:eval perplexity: 10.1947021484375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/186

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [17:59:39<1:29:04, 381.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14773.77782515405
INFO:root:current train perplexity4.281863212585449
INFO:root:current mean train loss 14782.64916278326
INFO:root:current train perplexity4.285862922668457


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.71s/it]
INFO:root:final mean train loss: 14748.939756331905
INFO:root:final train perplexity: 4.283287525177002
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:49<00:00, 49.92s/it]
INFO:root:eval mean loss: 22437.870256696428
INFO:root:eval perplexity: 10.19831657409668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/187

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [18:05:32<1:20:50, 373.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14790.231827445652
INFO:root:current train perplexity4.26553201675415
INFO:root:current mean train loss 14735.032917301829
INFO:root:current train perplexity4.27418851852417
INFO:root:current mean train loss 14755.470720641817
INFO:root:current train perplexity4.281262397766113


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.47s/it]
INFO:root:final mean train loss: 14742.422123078377
INFO:root:final train perplexity: 4.280534744262695
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.64s/it]
INFO:root:eval mean loss: 22443.14122953869
INFO:root:eval perplexity: 10.203882217407227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/188

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [18:11:13<1:12:41, 363.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14761.6691015625
INFO:root:current train perplexity4.2827534675598145
INFO:root:current mean train loss 14730.490189732143
INFO:root:current train perplexity4.274485111236572

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.08s/it]
INFO:root:final mean train loss: 14735.82005654612
INFO:root:final train perplexity: 4.2777485847473145
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.24s/it]
INFO:root:eval mean loss: 22437.703218005954
INFO:root:eval perplexity: 10.198142051696777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/189
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [18:17:36<1:07:40, 369.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14692.083586516204
INFO:root:current train perplexity4.265934467315674
INFO:root:current mean train loss 14722.964436208169
INFO:root:current train perplexity4.2762908935546875
INFO:root:current mean train loss 14740.917474015694
INFO:root:current train perplexity4.276841640472412

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.25s/it]
INFO:root:final mean train loss: 14738.955688476562
INFO:root:final train perplexity: 4.279071807861328
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.72s/it]
INFO:root:eval mean loss: 22439.96512276786
INFO:root:eval perplexity: 10.200530052185059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/190
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [18:24:06<1:02:35, 375.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14807.37071054193
INFO:root:current train perplexity4.285376071929932
INFO:root:current mean train loss 14747.46302701641
INFO:root:current train perplexity4.277647495269775

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.67s/it]
INFO:root:final mean train loss: 14738.159912109375
INFO:root:final train perplexity: 4.278735637664795
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.80s/it]
INFO:root:eval mean loss: 22438.394717261905
INFO:root:eval perplexity: 10.198871612548828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/191
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [18:30:35<56:54, 379.40s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14853.145318800403
INFO:root:current train perplexity4.2853851318359375
INFO:root:current mean train loss 14787.690780057252
INFO:root:current train perplexity4.282187461853027
INFO:root:current mean train loss 14741.951374797078
INFO:root:current train perplexity4.276682376861572

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.65s/it]
INFO:root:final mean train loss: 14735.84093844506
INFO:root:final train perplexity: 4.27775764465332
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.65s/it]
INFO:root:eval mean loss: 22440.093563988095
INFO:root:eval perplexity: 10.200666427612305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/192
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [18:36:27<49:30, 371.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14735.292345161897
INFO:root:current train perplexity4.278707027435303
INFO:root:current mean train loss 14733.516788336749
INFO:root:current train perplexity4.275347709655762

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.22s/it]
INFO:root:final mean train loss: 14734.345395980343
INFO:root:final train perplexity: 4.277125835418701
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.63s/it]
INFO:root:eval mean loss: 22440.997488839286
INFO:root:eval perplexity: 10.201619148254395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/193
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [18:42:06<42:10, 361.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14737.659654017858
INFO:root:current train perplexity4.29591703414917
INFO:root:current mean train loss 14744.473734085648
INFO:root:current train perplexity4.275823593139648
INFO:root:current mean train loss 14745.403893783245
INFO:root:current train perplexity4.27437162399292

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.74s/it]
INFO:root:final mean train loss: 14729.313504126763
INFO:root:final train perplexity: 4.2750043869018555
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:50<00:00, 50.21s/it]
INFO:root:eval mean loss: 22436.23902529762
INFO:root:eval perplexity: 10.196596145629883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/194
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [18:48:18<36:28, 364.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14702.085499730603
INFO:root:current train perplexity4.270045757293701
INFO:root:current mean train loss 14727.232150317514
INFO:root:current train perplexity4.273235321044922

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.73s/it]
INFO:root:final mean train loss: 14726.8474593624
INFO:root:final train perplexity: 4.273964881896973
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.61s/it]
INFO:root:eval mean loss: 22439.203311011905
INFO:root:eval perplexity: 10.199725151062012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/195
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [18:54:56<31:13, 374.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14807.178485576924
INFO:root:current train perplexity4.293638706207275
INFO:root:current mean train loss 14736.372154620054
INFO:root:current train perplexity4.274986267089844
INFO:root:current mean train loss 14740.358378007322
INFO:root:current train perplexity4.274919509887695

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.82s/it]
INFO:root:final mean train loss: 14728.686499810989
INFO:root:final train perplexity: 4.274739742279053
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.29s/it]
INFO:root:eval mean loss: 22441.92261904762
INFO:root:eval perplexity: 10.202594757080078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/196
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [19:00:58<24:43, 370.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14765.218009529533
INFO:root:current train perplexity4.27906608581543
INFO:root:current mean train loss 14753.21291107657
INFO:root:current train perplexity4.2795844078063965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.85s/it]
INFO:root:final mean train loss: 14728.178801505795
INFO:root:final train perplexity: 4.274525165557861
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.97s/it]
INFO:root:eval mean loss: 22439.060244605655
INFO:root:eval perplexity: 10.19957447052002
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/197
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [19:06:41<18:07, 362.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14734.088117732557
INFO:root:current train perplexity4.267065048217773
INFO:root:current mean train loss 14730.537382539336
INFO:root:current train perplexity4.265677452087402
INFO:root:current mean train loss 14735.349846482768
INFO:root:current train perplexity4.272677898406982

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:01<00:00, 301.66s/it]
INFO:root:final mean train loss: 14722.600022838962
INFO:root:final train perplexity: 4.272174835205078
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.87s/it]
INFO:root:eval mean loss: 22439.08117094494
INFO:root:eval perplexity: 10.19959831237793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/198
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [19:12:43<12:04, 362.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14749.955684621711
INFO:root:current train perplexity4.279993534088135
INFO:root:current mean train loss 14737.351302083332
INFO:root:current train perplexity4.273250579833984

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.94s/it]
INFO:root:final mean train loss: 14718.756528792843
INFO:root:final train perplexity: 4.270555019378662
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.22s/it]
INFO:root:eval mean loss: 22440.214169456845
INFO:root:eval perplexity: 10.20079231262207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/199
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [19:19:05<06:08, 368.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 14713.135347406915
INFO:root:current train perplexity4.263575077056885
INFO:root:current mean train loss 14725.20014216624
INFO:root:current train perplexity4.272719860076904
INFO:root:current mean train loss 14736.407218655111
INFO:root:current train perplexity4.273221015930176

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.95s/it]
INFO:root:final mean train loss: 14724.598955708165
INFO:root:final train perplexity: 4.273016929626465
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.90s/it]
INFO:root:eval mean loss: 22440.250581287204
INFO:root:eval perplexity: 10.200831413269043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_window_8/200
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [19:24:53<00:00, 362.22s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [19:24:53<00:00, 349.47s/it]
INFO:root:evaluating final model
INFO:root:start evaluating
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.64s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:44<00:00, 44.64s/it]
INFO:root:eval mean loss: 22440.250581287204
INFO:root:eval perplexity: 10.200831413269043
INFO:root:evalaution complete
INFO:root:save model final: small_window_8/final
