INFO:root:Output: std_24
INFO:root:Steps per epochs:1983
INFO:root:Total steps:198300
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.value.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.key.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.4.crossattention.output.dense.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
INFO:root:current mean train loss 12233.996034564394
INFO:root:current train perplexity16645.296875
INFO:root:current mean train loss 10556.768201358354
INFO:root:current train perplexity4153.33935546875
INFO:root:current mean train loss 9183.089889475334
INFO:root:current train perplexity1394.477294921875
INFO:root:current mean train loss 8234.04138275376
INFO:root:current train perplexity659.0493774414062
INFO:root:current mean train loss 7541.353360529653
INFO:root:current train perplexity382.4305419921875
INFO:root:current mean train loss 7015.903111223784
INFO:root:current train perplexity252.64076232910156
INFO:root:current mean train loss 6606.168340025371
INFO:root:current train perplexity182.30226135253906
INFO:root:current mean train loss 6280.677066120248
INFO:root:current train perplexity140.57440185546875
INFO:root:current mean train loss 6003.528543270735
INFO:root:current train perplexity113.54402160644531
INFO:root:current mean train loss 5779.561343814517
INFO:root:current train perplexity94.66704559326172
INFO:root:current mean train loss 5580.0193961840305
INFO:root:current train perplexity81.072265625
INFO:root:current mean train loss 5410.467772623019
INFO:root:current train perplexity70.9686050415039
INFO:root:current mean train loss 5263.929425504595
INFO:root:current train perplexity63.05072021484375
INFO:root:current mean train loss 5128.249730555307
INFO:root:current train perplexity56.7990608215332
INFO:root:current mean train loss 5009.453267998979
INFO:root:current train perplexity51.79373550415039
INFO:root:current mean train loss 4902.716970475933
INFO:root:current train perplexity47.6391487121582
INFO:root:current mean train loss 4807.124024587073
INFO:root:current train perplexity44.14892578125
INFO:root:current mean train loss 4718.543515521861
INFO:root:current train perplexity41.21760177612305
INFO:root:current mean train loss 4636.032411821395
INFO:root:current train perplexity38.680816650390625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.90s/it]
INFO:root:final mean train loss: 4571.8758802236
INFO:root:final train perplexity: 36.805816650390625
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.39s/it]
INFO:root:eval mean loss: 3474.2402167792793
INFO:root:eval perplexity: 17.30278968811035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/1
  1%|          | 1/100 [08:36<14:11:52, 516.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3098.5182342529297
INFO:root:current train perplexity11.432051658630371
INFO:root:current mean train loss 3095.3429397056843
INFO:root:current train perplexity11.508647918701172
INFO:root:current mean train loss 3077.502918384693
INFO:root:current train perplexity11.445938110351562
INFO:root:current mean train loss 3077.5060100313985
INFO:root:current train perplexity11.43754768371582
INFO:root:current mean train loss 3070.782782334548
INFO:root:current train perplexity11.345025062561035
INFO:root:current mean train loss 3061.356970498728
INFO:root:current train perplexity11.210612297058105
INFO:root:current mean train loss 3043.2432361949573
INFO:root:current train perplexity11.078469276428223
INFO:root:current mean train loss 3032.268536615638
INFO:root:current train perplexity10.977139472961426
INFO:root:current mean train loss 3022.9168123731424
INFO:root:current train perplexity10.895428657531738
INFO:root:current mean train loss 3016.8943286879094
INFO:root:current train perplexity10.818695068359375
INFO:root:current mean train loss 3004.146983709861
INFO:root:current train perplexity10.73059368133545
INFO:root:current mean train loss 2995.935842425165
INFO:root:current train perplexity10.640052795410156
INFO:root:current mean train loss 2989.1673792788856
INFO:root:current train perplexity10.567858695983887
INFO:root:current mean train loss 2980.6112689450156
INFO:root:current train perplexity10.48901653289795
INFO:root:current mean train loss 2971.810908947961
INFO:root:current train perplexity10.419004440307617
INFO:root:current mean train loss 2963.8592728989734
INFO:root:current train perplexity10.347049713134766
INFO:root:current mean train loss 2954.968570520382
INFO:root:current train perplexity10.277222633361816
INFO:root:current mean train loss 2947.6869280621722
INFO:root:current train perplexity10.216264724731445
INFO:root:current mean train loss 2937.7422389900107
INFO:root:current train perplexity10.147475242614746
INFO:root:current mean train loss 2929.8350565040287
INFO:root:current train perplexity10.077510833740234

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:07<00:00, 427.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:07<00:00, 427.35s/it]
INFO:root:final mean train loss: 2924.1904487706047
INFO:root:final train perplexity: 10.036138534545898
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.10s/it]
INFO:root:eval mean loss: 3221.7176172754785
INFO:root:eval perplexity: 14.064509391784668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/2
  2%|â–         | 2/100 [17:04<13:55:40, 511.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2811.11757960464
INFO:root:current train perplexity9.154733657836914
INFO:root:current mean train loss 2754.9584520382987
INFO:root:current train perplexity8.85615348815918
INFO:root:current mean train loss 2753.1517360179723
INFO:root:current train perplexity8.823223114013672
INFO:root:current mean train loss 2740.188701641094
INFO:root:current train perplexity8.747541427612305
INFO:root:current mean train loss 2743.376054371752
INFO:root:current train perplexity8.71773910522461
INFO:root:current mean train loss 2738.6522301536115
INFO:root:current train perplexity8.67010498046875
INFO:root:current mean train loss 2734.5412084690956
INFO:root:current train perplexity8.632123947143555
INFO:root:current mean train loss 2728.5435972539008
INFO:root:current train perplexity8.595365524291992
INFO:root:current mean train loss 2724.162826263318
INFO:root:current train perplexity8.565065383911133
INFO:root:current mean train loss 2717.7107150782085
INFO:root:current train perplexity8.530912399291992
INFO:root:current mean train loss 2713.0379573678
INFO:root:current train perplexity8.500304222106934
INFO:root:current mean train loss 2707.8765376765227
INFO:root:current train perplexity8.47512149810791
INFO:root:current mean train loss 2702.5636001178527
INFO:root:current train perplexity8.443819999694824
INFO:root:current mean train loss 2696.277295214917
INFO:root:current train perplexity8.405990600585938
INFO:root:current mean train loss 2695.2969830147636
INFO:root:current train perplexity8.388622283935547
INFO:root:current mean train loss 2694.013260355512
INFO:root:current train perplexity8.364381790161133
INFO:root:current mean train loss 2689.979374378062
INFO:root:current train perplexity8.337881088256836
INFO:root:current mean train loss 2686.4884393145016
INFO:root:current train perplexity8.309561729431152
INFO:root:current mean train loss 2682.256473122954
INFO:root:current train perplexity8.277544975280762
INFO:root:current mean train loss 2677.621333596377
INFO:root:current train perplexity8.252263069152832

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.76s/it]
INFO:root:final mean train loss: 2673.721010855455
INFO:root:final train perplexity: 8.237174034118652
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.28s/it]
INFO:root:eval mean loss: 3104.6205695441536
INFO:root:eval perplexity: 12.775992393493652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/3
  3%|â–Ž         | 3/100 [25:50<13:57:52, 518.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2604.9123095703126
INFO:root:current train perplexity7.756750583648682
INFO:root:current mean train loss 2591.6319905598957
INFO:root:current train perplexity7.7137451171875
INFO:root:current mean train loss 2583.4875595703124
INFO:root:current train perplexity7.682977676391602
INFO:root:current mean train loss 2576.4713832310267
INFO:root:current train perplexity7.628664493560791
INFO:root:current mean train loss 2581.246275499132
INFO:root:current train perplexity7.624702453613281
INFO:root:current mean train loss 2573.5585369318183
INFO:root:current train perplexity7.587040424346924
INFO:root:current mean train loss 2569.7215963040867
INFO:root:current train perplexity7.570847988128662
INFO:root:current mean train loss 2566.6280445963544
INFO:root:current train perplexity7.555428981781006
INFO:root:current mean train loss 2564.0360607192097
INFO:root:current train perplexity7.549492359161377
INFO:root:current mean train loss 2561.108275082237
INFO:root:current train perplexity7.529796123504639
INFO:root:current mean train loss 2557.4914562406993
INFO:root:current train perplexity7.509936332702637
INFO:root:current mean train loss 2556.8107837975544
INFO:root:current train perplexity7.501588344573975
INFO:root:current mean train loss 2553.5559095703125
INFO:root:current train perplexity7.487163543701172
INFO:root:current mean train loss 2551.286256962529
INFO:root:current train perplexity7.472534656524658
INFO:root:current mean train loss 2550.663355586611
INFO:root:current train perplexity7.4668965339660645
INFO:root:current mean train loss 2547.880859453755
INFO:root:current train perplexity7.4534711837768555
INFO:root:current mean train loss 2546.532693314986
INFO:root:current train perplexity7.443487644195557
INFO:root:current mean train loss 2543.8626208844867
INFO:root:current train perplexity7.426965713500977
INFO:root:current mean train loss 2542.587329959354
INFO:root:current train perplexity7.419417381286621
INFO:root:current mean train loss 2540.3768895858375
INFO:root:current train perplexity7.409136772155762

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.83s/it]
INFO:root:final mean train loss: 2538.8426559225095
INFO:root:final train perplexity: 7.405952453613281
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.90s/it]
INFO:root:eval mean loss: 3039.3739647850975
INFO:root:eval perplexity: 12.109957695007324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/4
  4%|â–         | 4/100 [34:21<13:44:27, 515.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2516.7771888846783
INFO:root:current train perplexity7.1286725997924805
INFO:root:current mean train loss 2480.7500387408777
INFO:root:current train perplexity7.042261123657227
INFO:root:current mean train loss 2478.578536015771
INFO:root:current train perplexity7.051685810089111
INFO:root:current mean train loss 2479.423222430071
INFO:root:current train perplexity7.063732624053955
INFO:root:current mean train loss 2479.824410350726
INFO:root:current train perplexity7.071369647979736
INFO:root:current mean train loss 2474.901007865892
INFO:root:current train perplexity7.03809118270874
INFO:root:current mean train loss 2476.4208810511736
INFO:root:current train perplexity7.038894176483154
INFO:root:current mean train loss 2472.9056377386023
INFO:root:current train perplexity7.021596908569336
INFO:root:current mean train loss 2473.0561899363374
INFO:root:current train perplexity7.010249137878418
INFO:root:current mean train loss 2469.438070713426
INFO:root:current train perplexity6.99431848526001
INFO:root:current mean train loss 2468.7468292608146
INFO:root:current train perplexity6.988977432250977
INFO:root:current mean train loss 2467.922682421373
INFO:root:current train perplexity6.980679988861084
INFO:root:current mean train loss 2464.9145235153474
INFO:root:current train perplexity6.969332695007324
INFO:root:current mean train loss 2464.507385030661
INFO:root:current train perplexity6.964529037475586
INFO:root:current mean train loss 2461.7854001409924
INFO:root:current train perplexity6.9585089683532715
INFO:root:current mean train loss 2459.290178115153
INFO:root:current train perplexity6.952396869659424
INFO:root:current mean train loss 2455.849034319113
INFO:root:current train perplexity6.937386989593506
INFO:root:current mean train loss 2454.3735948442804
INFO:root:current train perplexity6.925644397735596
INFO:root:current mean train loss 2452.638157898178
INFO:root:current train perplexity6.916928768157959
INFO:root:current mean train loss 2450.8749571171397
INFO:root:current train perplexity6.90540885925293

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:18<00:00, 438.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:18<00:00, 438.77s/it]
INFO:root:final mean train loss: 2449.850564822968
INFO:root:final train perplexity: 6.903991222381592
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.81s/it]
INFO:root:eval mean loss: 2998.6206677869277
INFO:root:eval perplexity: 11.711684226989746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/5
  5%|â–Œ         | 5/100 [42:39<13:25:43, 508.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2405.2493576776415
INFO:root:current train perplexity6.606167793273926
INFO:root:current mean train loss 2402.305563221807
INFO:root:current train perplexity6.633212089538574
INFO:root:current mean train loss 2400.88227478887
INFO:root:current train perplexity6.6587066650390625
INFO:root:current mean train loss 2402.9873746236167
INFO:root:current train perplexity6.666399002075195
INFO:root:current mean train loss 2408.904678218621
INFO:root:current train perplexity6.679003715515137
INFO:root:current mean train loss 2402.45274060393
INFO:root:current train perplexity6.64563512802124
INFO:root:current mean train loss 2401.280104787726
INFO:root:current train perplexity6.62877893447876
INFO:root:current mean train loss 2401.199413688815
INFO:root:current train perplexity6.634603023529053
INFO:root:current mean train loss 2399.2868360976827
INFO:root:current train perplexity6.621488571166992
INFO:root:current mean train loss 2395.4549909141974
INFO:root:current train perplexity6.605530738830566
INFO:root:current mean train loss 2394.612971907612
INFO:root:current train perplexity6.60434627532959
INFO:root:current mean train loss 2393.009588396227
INFO:root:current train perplexity6.5971455574035645
INFO:root:current mean train loss 2391.843861517505
INFO:root:current train perplexity6.591971397399902
INFO:root:current mean train loss 2391.727284425945
INFO:root:current train perplexity6.588214874267578
INFO:root:current mean train loss 2392.0472459818798
INFO:root:current train perplexity6.589836597442627
INFO:root:current mean train loss 2391.249015731041
INFO:root:current train perplexity6.581474304199219
INFO:root:current mean train loss 2390.5431628012034
INFO:root:current train perplexity6.576511859893799
INFO:root:current mean train loss 2387.489876169795
INFO:root:current train perplexity6.570245265960693
INFO:root:current mean train loss 2386.844681790427
INFO:root:current train perplexity6.563331604003906

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:10<00:00, 430.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:10<00:00, 430.43s/it]
INFO:root:final mean train loss: 2384.386202275002
INFO:root:final train perplexity: 6.556589126586914
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.07s/it]
INFO:root:eval mean loss: 2967.4712097351257
INFO:root:eval perplexity: 11.416122436523438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/6
  6%|â–Œ         | 6/100 [50:43<13:04:07, 500.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2480.71923828125
INFO:root:current train perplexity6.163896560668945
INFO:root:current mean train loss 2327.174237846148
INFO:root:current train perplexity6.285189151763916
INFO:root:current mean train loss 2338.9212130266637
INFO:root:current train perplexity6.342167854309082
INFO:root:current mean train loss 2346.994077359323
INFO:root:current train perplexity6.350844383239746
INFO:root:current mean train loss 2344.76713733245
INFO:root:current train perplexity6.3510613441467285
INFO:root:current mean train loss 2341.83241086187
INFO:root:current train perplexity6.350585460662842
INFO:root:current mean train loss 2339.4331613245504
INFO:root:current train perplexity6.342831134796143
INFO:root:current mean train loss 2341.441984908557
INFO:root:current train perplexity6.34480094909668
INFO:root:current mean train loss 2341.6047168212585
INFO:root:current train perplexity6.343529224395752
INFO:root:current mean train loss 2340.8208793614735
INFO:root:current train perplexity6.336573600769043
INFO:root:current mean train loss 2337.9854655842205
INFO:root:current train perplexity6.326719760894775
INFO:root:current mean train loss 2336.831364464478
INFO:root:current train perplexity6.318264007568359
INFO:root:current mean train loss 2336.6546538366465
INFO:root:current train perplexity6.3159708976745605
INFO:root:current mean train loss 2336.6018492385665
INFO:root:current train perplexity6.316873073577881
INFO:root:current mean train loss 2336.3774288594086
INFO:root:current train perplexity6.31644344329834
INFO:root:current mean train loss 2336.681035966257
INFO:root:current train perplexity6.312222957611084
INFO:root:current mean train loss 2335.3630076783065
INFO:root:current train perplexity6.305792808532715
INFO:root:current mean train loss 2335.380897768661
INFO:root:current train perplexity6.3067626953125
INFO:root:current mean train loss 2335.2098389349667
INFO:root:current train perplexity6.302863121032715
INFO:root:current mean train loss 2334.8449158003805
INFO:root:current train perplexity6.300889015197754

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.01s/it]
INFO:root:final mean train loss: 2333.586626092292
INFO:root:final train perplexity: 6.299099445343018
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.17s/it]
INFO:root:eval mean loss: 2945.723340283643
INFO:root:eval perplexity: 11.214201927185059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/7
  7%|â–‹         | 7/100 [58:48<12:47:54, 495.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2295.0665283203125
INFO:root:current train perplexity6.093954563140869
INFO:root:current mean train loss 2284.3098775572694
INFO:root:current train perplexity6.130782604217529
INFO:root:current mean train loss 2299.514473171409
INFO:root:current train perplexity6.170079231262207
INFO:root:current mean train loss 2303.0088001946983
INFO:root:current train perplexity6.169676780700684
INFO:root:current mean train loss 2302.5421165940866
INFO:root:current train perplexity6.146724224090576
INFO:root:current mean train loss 2302.815438406808
INFO:root:current train perplexity6.144949913024902
INFO:root:current mean train loss 2302.461710809504
INFO:root:current train perplexity6.137875080108643
INFO:root:current mean train loss 2303.5695935092594
INFO:root:current train perplexity6.141851902008057
INFO:root:current mean train loss 2302.608757783848
INFO:root:current train perplexity6.1327080726623535
INFO:root:current mean train loss 2300.905666908148
INFO:root:current train perplexity6.128021240234375
INFO:root:current mean train loss 2298.024279641262
INFO:root:current train perplexity6.118579387664795
INFO:root:current mean train loss 2298.5604581065168
INFO:root:current train perplexity6.114187240600586
INFO:root:current mean train loss 2298.25368936974
INFO:root:current train perplexity6.109981060028076
INFO:root:current mean train loss 2298.8246029287984
INFO:root:current train perplexity6.11635160446167
INFO:root:current mean train loss 2299.120770237846
INFO:root:current train perplexity6.114451885223389
INFO:root:current mean train loss 2299.2948678359685
INFO:root:current train perplexity6.111186504364014
INFO:root:current mean train loss 2297.285758302592
INFO:root:current train perplexity6.104613780975342
INFO:root:current mean train loss 2295.571828644545
INFO:root:current train perplexity6.098426818847656
INFO:root:current mean train loss 2294.7681649756773
INFO:root:current train perplexity6.098876953125
INFO:root:current mean train loss 2292.5545185872734
INFO:root:current train perplexity6.095393657684326

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.65s/it]
INFO:root:final mean train loss: 2291.9934847509985
INFO:root:final train perplexity: 6.095824241638184
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.51s/it]
INFO:root:eval mean loss: 2924.30505481067
INFO:root:eval perplexity: 11.018831253051758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/8
  8%|â–Š         | 8/100 [1:06:55<12:35:30, 492.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2261.413326590402
INFO:root:current train perplexity5.921321868896484
INFO:root:current mean train loss 2267.3469012225114
INFO:root:current train perplexity5.930943489074707
INFO:root:current mean train loss 2259.5671636053858
INFO:root:current train perplexity5.936183452606201
INFO:root:current mean train loss 2261.497362188083
INFO:root:current train perplexity5.950688362121582
INFO:root:current mean train loss 2258.721534606232
INFO:root:current train perplexity5.9554033279418945
INFO:root:current mean train loss 2257.9234904351633
INFO:root:current train perplexity5.944366931915283
INFO:root:current mean train loss 2260.5028852808196
INFO:root:current train perplexity5.93986701965332
INFO:root:current mean train loss 2263.1954770873194
INFO:root:current train perplexity5.945597171783447
INFO:root:current mean train loss 2263.7018199440963
INFO:root:current train perplexity5.949978351593018
INFO:root:current mean train loss 2265.6582635726522
INFO:root:current train perplexity5.953976154327393
INFO:root:current mean train loss 2264.473997018418
INFO:root:current train perplexity5.953657627105713
INFO:root:current mean train loss 2261.778421087727
INFO:root:current train perplexity5.946780204772949
INFO:root:current mean train loss 2259.9523885255885
INFO:root:current train perplexity5.943349838256836
INFO:root:current mean train loss 2260.941832353113
INFO:root:current train perplexity5.946321964263916
INFO:root:current mean train loss 2260.4426641271507
INFO:root:current train perplexity5.944421768188477
INFO:root:current mean train loss 2261.2163217153147
INFO:root:current train perplexity5.943364143371582
INFO:root:current mean train loss 2260.4163090417146
INFO:root:current train perplexity5.942428112030029
INFO:root:current mean train loss 2259.1073824747837
INFO:root:current train perplexity5.937509059906006
INFO:root:current mean train loss 2257.668402947782
INFO:root:current train perplexity5.931974411010742
INFO:root:current mean train loss 2257.65334434805
INFO:root:current train perplexity5.931446075439453

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:18<00:00, 438.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:18<00:00, 438.70s/it]
INFO:root:final mean train loss: 2257.7996429120176
INFO:root:final train perplexity: 5.933633804321289
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.51s/it]
INFO:root:eval mean loss: 2911.1189529373123
INFO:root:eval perplexity: 10.900248527526855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/9
  9%|â–‰         | 9/100 [1:15:10<12:28:28, 493.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2213.2344712477466
INFO:root:current train perplexity5.769294261932373
INFO:root:current mean train loss 2220.8535935251334
INFO:root:current train perplexity5.726970672607422
INFO:root:current mean train loss 2231.042189825149
INFO:root:current train perplexity5.77872371673584
INFO:root:current mean train loss 2227.4824624495072
INFO:root:current train perplexity5.790835857391357
INFO:root:current mean train loss 2234.0747578038577
INFO:root:current train perplexity5.808411121368408
INFO:root:current mean train loss 2235.5312504422836
INFO:root:current train perplexity5.812860012054443
INFO:root:current mean train loss 2238.3595030614933
INFO:root:current train perplexity5.820671081542969
INFO:root:current mean train loss 2235.102365209701
INFO:root:current train perplexity5.812355041503906
INFO:root:current mean train loss 2234.7251712996076
INFO:root:current train perplexity5.814870834350586
INFO:root:current mean train loss 2231.5109694024095
INFO:root:current train perplexity5.807734489440918
INFO:root:current mean train loss 2232.7237033626425
INFO:root:current train perplexity5.811500549316406
INFO:root:current mean train loss 2231.9807679918076
INFO:root:current train perplexity5.803524017333984
INFO:root:current mean train loss 2231.3390594579923
INFO:root:current train perplexity5.802072048187256
INFO:root:current mean train loss 2232.1980630547337
INFO:root:current train perplexity5.809271812438965
INFO:root:current mean train loss 2230.7834564293053
INFO:root:current train perplexity5.804337024688721
INFO:root:current mean train loss 2228.2991497393737
INFO:root:current train perplexity5.796961307525635
INFO:root:current mean train loss 2228.342004512759
INFO:root:current train perplexity5.793967247009277
INFO:root:current mean train loss 2229.660890344071
INFO:root:current train perplexity5.796862602233887
INFO:root:current mean train loss 2228.1052255980653
INFO:root:current train perplexity5.792888164520264
INFO:root:current mean train loss 2228.284552652328
INFO:root:current train perplexity5.793381214141846

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.46s/it]
INFO:root:final mean train loss: 2227.4607593499827
INFO:root:final train perplexity: 5.793342590332031
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.03s/it]
INFO:root:eval mean loss: 2898.595330682245
INFO:root:eval perplexity: 10.78880500793457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/10
 10%|â–ˆ         | 10/100 [1:23:34<12:25:14, 496.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2220.1907445935235
INFO:root:current train perplexity5.703662872314453
INFO:root:current mean train loss 2221.6518142971063
INFO:root:current train perplexity5.688498020172119
INFO:root:current mean train loss 2203.6142319463
INFO:root:current train perplexity5.651496410369873
INFO:root:current mean train loss 2202.3555799034552
INFO:root:current train perplexity5.65538215637207
INFO:root:current mean train loss 2203.552588098847
INFO:root:current train perplexity5.65755558013916
INFO:root:current mean train loss 2207.141611431102
INFO:root:current train perplexity5.669548988342285
INFO:root:current mean train loss 2203.4300912991057
INFO:root:current train perplexity5.663577556610107
INFO:root:current mean train loss 2205.1205013359477
INFO:root:current train perplexity5.676238059997559
INFO:root:current mean train loss 2206.437744140625
INFO:root:current train perplexity5.672030448913574
INFO:root:current mean train loss 2205.4851152323595
INFO:root:current train perplexity5.673168182373047
INFO:root:current mean train loss 2204.049710708204
INFO:root:current train perplexity5.675051212310791
INFO:root:current mean train loss 2203.591074477719
INFO:root:current train perplexity5.673508644104004
INFO:root:current mean train loss 2203.001014847752
INFO:root:current train perplexity5.670482635498047
INFO:root:current mean train loss 2203.7209694683334
INFO:root:current train perplexity5.673687934875488
INFO:root:current mean train loss 2204.5018398630286
INFO:root:current train perplexity5.675166606903076
INFO:root:current mean train loss 2202.792948288246
INFO:root:current train perplexity5.672464847564697
INFO:root:current mean train loss 2201.977922315009
INFO:root:current train perplexity5.671631813049316
INFO:root:current mean train loss 2200.935768657919
INFO:root:current train perplexity5.670749664306641
INFO:root:current mean train loss 2200.1711464316018
INFO:root:current train perplexity5.670389175415039
INFO:root:current mean train loss 2201.534024821253
INFO:root:current train perplexity5.6739397048950195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:17<00:00, 437.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:17<00:00, 437.54s/it]
INFO:root:final mean train loss: 2201.07685092574
INFO:root:final train perplexity: 5.674041748046875
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.76s/it]
INFO:root:eval mean loss: 2881.975365990991
INFO:root:eval perplexity: 10.64266586303711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/11
 11%|â–ˆ         | 11/100 [1:31:47<12:15:18, 495.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2204.889583144077
INFO:root:current train perplexity5.610666751861572
INFO:root:current mean train loss 2173.508592831191
INFO:root:current train perplexity5.549427032470703
INFO:root:current mean train loss 2175.0683090103257
INFO:root:current train perplexity5.550292491912842
INFO:root:current mean train loss 2184.783976342394
INFO:root:current train perplexity5.58135986328125
INFO:root:current mean train loss 2179.9090510866768
INFO:root:current train perplexity5.561505317687988
INFO:root:current mean train loss 2179.1833579418194
INFO:root:current train perplexity5.555347919464111
INFO:root:current mean train loss 2180.2821644596734
INFO:root:current train perplexity5.559287071228027
INFO:root:current mean train loss 2180.4384498499126
INFO:root:current train perplexity5.567690372467041
INFO:root:current mean train loss 2178.3082699743404
INFO:root:current train perplexity5.565228462219238
INFO:root:current mean train loss 2178.2264958936835
INFO:root:current train perplexity5.568285942077637
INFO:root:current mean train loss 2175.0761369174797
INFO:root:current train perplexity5.560489654541016
INFO:root:current mean train loss 2178.2772102548943
INFO:root:current train perplexity5.566214561462402
INFO:root:current mean train loss 2177.2344404015903
INFO:root:current train perplexity5.56521463394165
INFO:root:current mean train loss 2177.275077610649
INFO:root:current train perplexity5.5662841796875
INFO:root:current mean train loss 2177.0390713718666
INFO:root:current train perplexity5.565319061279297
INFO:root:current mean train loss 2176.733232341829
INFO:root:current train perplexity5.563000202178955
INFO:root:current mean train loss 2176.7724931565326
INFO:root:current train perplexity5.562963008880615
INFO:root:current mean train loss 2176.9543205508994
INFO:root:current train perplexity5.564711093902588
INFO:root:current mean train loss 2176.999871780865
INFO:root:current train perplexity5.564717769622803

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.22s/it]
INFO:root:final mean train loss: 2176.7060456999734
INFO:root:final train perplexity: 5.56602668762207
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.15s/it]
INFO:root:eval mean loss: 2873.077032599005
INFO:root:eval perplexity: 10.565240859985352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/12
 12%|â–ˆâ–        | 12/100 [1:40:05<12:07:43, 496.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2028.5974527994792
INFO:root:current train perplexity5.032833576202393
INFO:root:current mean train loss 2155.6576259576
INFO:root:current train perplexity5.463956356048584
INFO:root:current mean train loss 2161.233130844943
INFO:root:current train perplexity5.488798141479492
INFO:root:current mean train loss 2156.80264574309
INFO:root:current train perplexity5.482515811920166
INFO:root:current mean train loss 2153.166203425481
INFO:root:current train perplexity5.481964588165283
INFO:root:current mean train loss 2157.3397301736454
INFO:root:current train perplexity5.4960527420043945
INFO:root:current mean train loss 2154.963453403555
INFO:root:current train perplexity5.492044448852539
INFO:root:current mean train loss 2153.174948289418
INFO:root:current train perplexity5.486469268798828
INFO:root:current mean train loss 2152.5486976937073
INFO:root:current train perplexity5.479671001434326
INFO:root:current mean train loss 2155.923131121089
INFO:root:current train perplexity5.484572410583496
INFO:root:current mean train loss 2155.512191209574
INFO:root:current train perplexity5.481614589691162
INFO:root:current mean train loss 2154.1942314639055
INFO:root:current train perplexity5.4774250984191895
INFO:root:current mean train loss 2152.8919061801876
INFO:root:current train perplexity5.478506088256836
INFO:root:current mean train loss 2152.1813629454864
INFO:root:current train perplexity5.477011680603027
INFO:root:current mean train loss 2152.2010147410124
INFO:root:current train perplexity5.475025653839111
INFO:root:current mean train loss 2152.8327494587647
INFO:root:current train perplexity5.471321105957031
INFO:root:current mean train loss 2155.0776827902027
INFO:root:current train perplexity5.473684787750244
INFO:root:current mean train loss 2154.074907519015
INFO:root:current train perplexity5.472447872161865
INFO:root:current mean train loss 2155.2174244233784
INFO:root:current train perplexity5.475455284118652
INFO:root:current mean train loss 2156.265477527773
INFO:root:current train perplexity5.477569103240967

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.21s/it]
INFO:root:final mean train loss: 2156.6843607676974
INFO:root:final train perplexity: 5.478826999664307
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.67s/it]
INFO:root:eval mean loss: 2872.310916385135
INFO:root:eval perplexity: 10.558597564697266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/13
 13%|â–ˆâ–Ž        | 13/100 [1:48:26<12:01:54, 497.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2206.920379638672
INFO:root:current train perplexity5.475656986236572
INFO:root:current mean train loss 2140.418932088216
INFO:root:current train perplexity5.36614990234375
INFO:root:current mean train loss 2145.5121532093394
INFO:root:current train perplexity5.389637470245361
INFO:root:current mean train loss 2136.557139587402
INFO:root:current train perplexity5.37488317489624
INFO:root:current mean train loss 2139.832035609654
INFO:root:current train perplexity5.37617826461792
INFO:root:current mean train loss 2140.9458186222955
INFO:root:current train perplexity5.393101692199707
INFO:root:current mean train loss 2140.245614919355
INFO:root:current train perplexity5.389773845672607
INFO:root:current mean train loss 2141.0999384562174
INFO:root:current train perplexity5.391332626342773
INFO:root:current mean train loss 2141.7730041503905
INFO:root:current train perplexity5.39436149597168
INFO:root:current mean train loss 2142.4220719047216
INFO:root:current train perplexity5.395635604858398
INFO:root:current mean train loss 2140.509573065066
INFO:root:current train perplexity5.39634370803833
INFO:root:current mean train loss 2141.0130114964077
INFO:root:current train perplexity5.398777008056641
INFO:root:current mean train loss 2138.3873460113027
INFO:root:current train perplexity5.398019313812256
INFO:root:current mean train loss 2137.2870811693597
INFO:root:current train perplexity5.397350788116455
INFO:root:current mean train loss 2136.824131065691
INFO:root:current train perplexity5.391703128814697
INFO:root:current mean train loss 2135.9316031205026
INFO:root:current train perplexity5.390509128570557
INFO:root:current mean train loss 2136.0602780942563
INFO:root:current train perplexity5.38918924331665
INFO:root:current mean train loss 2135.8700055499407
INFO:root:current train perplexity5.3879923820495605
INFO:root:current mean train loss 2136.421914907602
INFO:root:current train perplexity5.390888690948486
INFO:root:current mean train loss 2137.3954352696737
INFO:root:current train perplexity5.39203405380249

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.10s/it]
INFO:root:final mean train loss: 2136.3218470894203
INFO:root:final train perplexity: 5.391544818878174
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.37s/it]
INFO:root:eval mean loss: 2858.859005489865
INFO:root:eval perplexity: 10.442689895629883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/14
 14%|â–ˆâ–        | 14/100 [1:56:47<11:54:40, 498.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2092.336768897804
INFO:root:current train perplexity5.2381439208984375
INFO:root:current mean train loss 2094.207010756444
INFO:root:current train perplexity5.274470329284668
INFO:root:current mean train loss 2111.348115687632
INFO:root:current train perplexity5.305233001708984
INFO:root:current mean train loss 2108.4601040169464
INFO:root:current train perplexity5.302174091339111
INFO:root:current mean train loss 2107.3551276794014
INFO:root:current train perplexity5.310408592224121
INFO:root:current mean train loss 2111.385407346587
INFO:root:current train perplexity5.3156914710998535
INFO:root:current mean train loss 2110.6426490292633
INFO:root:current train perplexity5.305965900421143
INFO:root:current mean train loss 2108.2333270503837
INFO:root:current train perplexity5.304818153381348
INFO:root:current mean train loss 2109.3320731068457
INFO:root:current train perplexity5.305431842803955
INFO:root:current mean train loss 2110.838154958686
INFO:root:current train perplexity5.310688495635986
INFO:root:current mean train loss 2111.585545156363
INFO:root:current train perplexity5.313217639923096
INFO:root:current mean train loss 2114.014720477236
INFO:root:current train perplexity5.314858913421631
INFO:root:current mean train loss 2116.227048412869
INFO:root:current train perplexity5.320466041564941
INFO:root:current mean train loss 2116.384673045122
INFO:root:current train perplexity5.320512294769287
INFO:root:current mean train loss 2116.8898772025323
INFO:root:current train perplexity5.316897392272949
INFO:root:current mean train loss 2118.255406833269
INFO:root:current train perplexity5.323730945587158
INFO:root:current mean train loss 2118.2628359506243
INFO:root:current train perplexity5.322421550750732
INFO:root:current mean train loss 2118.94719295908
INFO:root:current train perplexity5.31897497177124
INFO:root:current mean train loss 2118.7752644347315
INFO:root:current train perplexity5.31622314453125
INFO:root:current mean train loss 2119.691620771086
INFO:root:current train perplexity5.317298889160156

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.71s/it]
INFO:root:final mean train loss: 2118.4875902877093
INFO:root:final train perplexity: 5.31624174118042
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.93s/it]
INFO:root:eval mean loss: 2859.2685429570197
INFO:root:eval perplexity: 10.44620132446289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/15
 15%|â–ˆâ–Œ        | 15/100 [2:05:06<11:46:44, 498.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2107.7472262912324
INFO:root:current train perplexity5.212942600250244
INFO:root:current mean train loss 2100.184596470424
INFO:root:current train perplexity5.184176921844482
INFO:root:current mean train loss 2098.2578206700605
INFO:root:current train perplexity5.220786094665527
INFO:root:current mean train loss 2095.18470169326
INFO:root:current train perplexity5.231385707855225
INFO:root:current mean train loss 2095.33501148644
INFO:root:current train perplexity5.228230953216553
INFO:root:current mean train loss 2093.9152990678585
INFO:root:current train perplexity5.227351665496826
INFO:root:current mean train loss 2095.983091768504
INFO:root:current train perplexity5.22865629196167
INFO:root:current mean train loss 2097.688576452928
INFO:root:current train perplexity5.236917972564697
INFO:root:current mean train loss 2098.950140280802
INFO:root:current train perplexity5.236837863922119
INFO:root:current mean train loss 2097.6661817122804
INFO:root:current train perplexity5.235805511474609
INFO:root:current mean train loss 2098.307508436055
INFO:root:current train perplexity5.236212253570557
INFO:root:current mean train loss 2097.735334531893
INFO:root:current train perplexity5.238230228424072
INFO:root:current mean train loss 2099.8218953255832
INFO:root:current train perplexity5.243456840515137
INFO:root:current mean train loss 2102.0077982554585
INFO:root:current train perplexity5.249387741088867
INFO:root:current mean train loss 2101.2791783307903
INFO:root:current train perplexity5.244699001312256
INFO:root:current mean train loss 2101.5607254244337
INFO:root:current train perplexity5.246665000915527
INFO:root:current mean train loss 2101.010874368836
INFO:root:current train perplexity5.245588302612305
INFO:root:current mean train loss 2101.1661067253644
INFO:root:current train perplexity5.245325565338135
INFO:root:current mean train loss 2101.1438150909985
INFO:root:current train perplexity5.246022701263428
INFO:root:current mean train loss 2102.7201559326422
INFO:root:current train perplexity5.248281002044678

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:18<00:00, 438.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:18<00:00, 438.27s/it]
INFO:root:final mean train loss: 2102.4344563063382
INFO:root:final train perplexity: 5.249361038208008
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.93s/it]
INFO:root:eval mean loss: 2850.1662736955705
INFO:root:eval perplexity: 10.36846923828125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/16
 16%|â–ˆâ–Œ        | 16/100 [2:13:19<11:35:56, 497.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2102.7339417363555
INFO:root:current train perplexity5.261078357696533
INFO:root:current mean train loss 2079.5026527092473
INFO:root:current train perplexity5.1876091957092285
INFO:root:current mean train loss 2076.9729368765857
INFO:root:current train perplexity5.189117431640625
INFO:root:current mean train loss 2079.5430440979826
INFO:root:current train perplexity5.186691761016846
INFO:root:current mean train loss 2080.819105273852
INFO:root:current train perplexity5.181177139282227
INFO:root:current mean train loss 2082.041695242379
INFO:root:current train perplexity5.176233291625977
INFO:root:current mean train loss 2081.338582478053
INFO:root:current train perplexity5.176163673400879
INFO:root:current mean train loss 2083.7615124495887
INFO:root:current train perplexity5.1753926277160645
INFO:root:current mean train loss 2082.836941531824
INFO:root:current train perplexity5.177336692810059
INFO:root:current mean train loss 2084.030012073772
INFO:root:current train perplexity5.177511692047119
INFO:root:current mean train loss 2083.7311022390727
INFO:root:current train perplexity5.1741156578063965
INFO:root:current mean train loss 2084.841205287448
INFO:root:current train perplexity5.174149990081787
INFO:root:current mean train loss 2083.9199453094266
INFO:root:current train perplexity5.174752235412598
INFO:root:current mean train loss 2084.185516869387
INFO:root:current train perplexity5.178291320800781
INFO:root:current mean train loss 2084.1256776520545
INFO:root:current train perplexity5.1795654296875
INFO:root:current mean train loss 2085.0335724440297
INFO:root:current train perplexity5.182661533355713
INFO:root:current mean train loss 2084.926708575282
INFO:root:current train perplexity5.178604602813721
INFO:root:current mean train loss 2086.170934279715
INFO:root:current train perplexity5.183480739593506
INFO:root:current mean train loss 2086.3288134478553
INFO:root:current train perplexity5.185442924499512
INFO:root:current mean train loss 2087.8331091971277
INFO:root:current train perplexity5.18781042098999

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:23<00:00, 443.26s/it]
INFO:root:final mean train loss: 2087.72449644611
INFO:root:final train perplexity: 5.18881368637085
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.05s/it]
INFO:root:eval mean loss: 2847.3341156097504
INFO:root:eval perplexity: 10.344402313232422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/17
 17%|â–ˆâ–‹        | 17/100 [2:21:36<11:27:40, 497.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2054.231015292081
INFO:root:current train perplexity5.071938991546631
INFO:root:current mean train loss 2062.6463798360624
INFO:root:current train perplexity5.0927581787109375
INFO:root:current mean train loss 2069.851700252957
INFO:root:current train perplexity5.103058338165283
INFO:root:current mean train loss 2062.688833020397
INFO:root:current train perplexity5.096800327301025
INFO:root:current mean train loss 2066.7699279785156
INFO:root:current train perplexity5.115223407745361
INFO:root:current mean train loss 2069.0592439612565
INFO:root:current train perplexity5.117620944976807
INFO:root:current mean train loss 2069.871105815089
INFO:root:current train perplexity5.122368335723877
INFO:root:current mean train loss 2068.078722338991
INFO:root:current train perplexity5.121020317077637
INFO:root:current mean train loss 2069.0674126427452
INFO:root:current train perplexity5.121882915496826
INFO:root:current mean train loss 2072.765056038675
INFO:root:current train perplexity5.125545978546143
INFO:root:current mean train loss 2074.3810532513785
INFO:root:current train perplexity5.12573766708374
INFO:root:current mean train loss 2074.1550246729994
INFO:root:current train perplexity5.1213226318359375
INFO:root:current mean train loss 2072.0304096293007
INFO:root:current train perplexity5.119319915771484
INFO:root:current mean train loss 2071.178240157685
INFO:root:current train perplexity5.11667013168335
INFO:root:current mean train loss 2071.5633107667327
INFO:root:current train perplexity5.117210388183594
INFO:root:current mean train loss 2071.80306368811
INFO:root:current train perplexity5.121252536773682
INFO:root:current mean train loss 2072.907645781458
INFO:root:current train perplexity5.125463485717773
INFO:root:current mean train loss 2073.0052867778463
INFO:root:current train perplexity5.128315448760986
INFO:root:current mean train loss 2073.2119410240043
INFO:root:current train perplexity5.129678249359131

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:17<00:00, 437.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:17<00:00, 437.51s/it]
INFO:root:final mean train loss: 2073.2390736913176
INFO:root:final train perplexity: 5.129874229431152
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.30s/it]
INFO:root:eval mean loss: 2845.892323720205
INFO:root:eval perplexity: 10.332172393798828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/18
 18%|â–ˆâ–Š        | 18/100 [2:29:48<11:17:05, 495.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2078.184228515625
INFO:root:current train perplexity5.140441417694092
INFO:root:current mean train loss 2056.3591180710564
INFO:root:current train perplexity5.072305202484131
INFO:root:current mean train loss 2059.6902671255716
INFO:root:current train perplexity5.07020378112793
INFO:root:current mean train loss 2063.2415275198514
INFO:root:current train perplexity5.082269668579102
INFO:root:current mean train loss 2059.4149555724343
INFO:root:current train perplexity5.077784538269043
INFO:root:current mean train loss 2057.5826585222
INFO:root:current train perplexity5.0718512535095215
INFO:root:current mean train loss 2061.696715198864
INFO:root:current train perplexity5.080360412597656
INFO:root:current mean train loss 2061.1332211325353
INFO:root:current train perplexity5.083257675170898
INFO:root:current mean train loss 2061.20762810559
INFO:root:current train perplexity5.077582836151123
INFO:root:current mean train loss 2062.5256842681715
INFO:root:current train perplexity5.082087993621826
INFO:root:current mean train loss 2064.6948408591807
INFO:root:current train perplexity5.086345672607422
INFO:root:current mean train loss 2062.8982984171735
INFO:root:current train perplexity5.080041885375977
INFO:root:current mean train loss 2062.1684028340574
INFO:root:current train perplexity5.076910018920898
INFO:root:current mean train loss 2061.073739635716
INFO:root:current train perplexity5.075502872467041
INFO:root:current mean train loss 2060.8600148048267
INFO:root:current train perplexity5.074056625366211
INFO:root:current mean train loss 2059.2973954007475
INFO:root:current train perplexity5.072512626647949
INFO:root:current mean train loss 2058.261994453977
INFO:root:current train perplexity5.070672988891602
INFO:root:current mean train loss 2058.9919424286336
INFO:root:current train perplexity5.072169303894043
INFO:root:current mean train loss 2058.236293093187
INFO:root:current train perplexity5.070374965667725
INFO:root:current mean train loss 2058.630019300566
INFO:root:current train perplexity5.072022914886475

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.48s/it]
INFO:root:final mean train loss: 2059.53177644746
INFO:root:final train perplexity: 5.074716567993164
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.11s/it]
INFO:root:eval mean loss: 2841.74353137317
INFO:root:eval perplexity: 10.2970552444458
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/19
 19%|â–ˆâ–‰        | 19/100 [2:38:03<11:08:38, 495.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2003.7829312411222
INFO:root:current train perplexity4.919356346130371
INFO:root:current mean train loss 2032.4701227907274
INFO:root:current train perplexity4.947202205657959
INFO:root:current mean train loss 2030.5891828107403
INFO:root:current train perplexity4.961240291595459
INFO:root:current mean train loss 2031.28185769786
INFO:root:current train perplexity4.9625420570373535
INFO:root:current mean train loss 2040.3106408864967
INFO:root:current train perplexity4.970535755157471
INFO:root:current mean train loss 2041.8236799568965
INFO:root:current train perplexity4.982059955596924
INFO:root:current mean train loss 2042.1728431235556
INFO:root:current train perplexity4.9913105964660645
INFO:root:current mean train loss 2040.8693146005562
INFO:root:current train perplexity4.995501518249512
INFO:root:current mean train loss 2043.5857064277295
INFO:root:current train perplexity4.998115062713623
INFO:root:current mean train loss 2044.4670191700702
INFO:root:current train perplexity4.999370574951172
INFO:root:current mean train loss 2043.7475858266573
INFO:root:current train perplexity5.00352144241333
INFO:root:current mean train loss 2043.870392444087
INFO:root:current train perplexity5.006806373596191
INFO:root:current mean train loss 2045.0147173642722
INFO:root:current train perplexity5.010295391082764
INFO:root:current mean train loss 2046.9836591988937
INFO:root:current train perplexity5.01690673828125
INFO:root:current mean train loss 2047.0149742158655
INFO:root:current train perplexity5.015601634979248
INFO:root:current mean train loss 2047.7726378672696
INFO:root:current train perplexity5.018789768218994
INFO:root:current mean train loss 2047.625431385346
INFO:root:current train perplexity5.01869010925293
INFO:root:current mean train loss 2047.7754648454513
INFO:root:current train perplexity5.022652626037598
INFO:root:current mean train loss 2048.4902496505388
INFO:root:current train perplexity5.025777816772461
INFO:root:current mean train loss 2048.909205727473
INFO:root:current train perplexity5.0271501541137695

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.20s/it]
INFO:root:final mean train loss: 2047.0695572707368
INFO:root:final train perplexity: 5.025083541870117
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.03s/it]
INFO:root:eval mean loss: 2837.5818025056305
INFO:root:eval perplexity: 10.26194953918457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/20
 20%|â–ˆâ–ˆ        | 20/100 [2:46:15<10:58:58, 494.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2017.7639379256811
INFO:root:current train perplexity4.947559833526611
INFO:root:current mean train loss 2047.0890911294402
INFO:root:current train perplexity4.96724271774292
INFO:root:current mean train loss 2042.7021183029876
INFO:root:current train perplexity4.963044166564941
INFO:root:current mean train loss 2041.598761364422
INFO:root:current train perplexity4.963827133178711
INFO:root:current mean train loss 2038.8876516563746
INFO:root:current train perplexity4.9632110595703125
INFO:root:current mean train loss 2038.4592744901584
INFO:root:current train perplexity4.96904993057251
INFO:root:current mean train loss 2036.3658334555946
INFO:root:current train perplexity4.973508358001709
INFO:root:current mean train loss 2037.8708695965304
INFO:root:current train perplexity4.975513935089111
INFO:root:current mean train loss 2036.5499458176587
INFO:root:current train perplexity4.976517677307129
INFO:root:current mean train loss 2036.8235146681975
INFO:root:current train perplexity4.97475004196167
INFO:root:current mean train loss 2036.1039753566004
INFO:root:current train perplexity4.97307014465332
INFO:root:current mean train loss 2037.1370503439832
INFO:root:current train perplexity4.9762749671936035
INFO:root:current mean train loss 2035.6711469131483
INFO:root:current train perplexity4.97273063659668
INFO:root:current mean train loss 2037.1694284884943
INFO:root:current train perplexity4.976431369781494
INFO:root:current mean train loss 2037.803736471318
INFO:root:current train perplexity4.981269836425781
INFO:root:current mean train loss 2038.8167603252923
INFO:root:current train perplexity4.984935283660889
INFO:root:current mean train loss 2037.6462824637022
INFO:root:current train perplexity4.983108997344971
INFO:root:current mean train loss 2037.8551302663618
INFO:root:current train perplexity4.984872341156006
INFO:root:current mean train loss 2037.7379356828185
INFO:root:current train perplexity4.983576774597168
INFO:root:current mean train loss 2036.8366381294522
INFO:root:current train perplexity4.982821941375732

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.38s/it]
INFO:root:final mean train loss: 2035.8373821833732
INFO:root:final train perplexity: 4.980766296386719
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.75s/it]
INFO:root:eval mean loss: 2844.124808646537
INFO:root:eval perplexity: 10.317193031311035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/21
 21%|â–ˆâ–ˆ        | 21/100 [2:54:36<10:53:40, 496.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2000.474888392857
INFO:root:current train perplexity4.928229331970215
INFO:root:current mean train loss 2009.390862880609
INFO:root:current train perplexity4.923165798187256
INFO:root:current mean train loss 2014.7040090560913
INFO:root:current train perplexity4.932980537414551
INFO:root:current mean train loss 2020.0719854804906
INFO:root:current train perplexity4.942812919616699
INFO:root:current mean train loss 2021.562963920727
INFO:root:current train perplexity4.943349361419678
INFO:root:current mean train loss 2020.98117855813
INFO:root:current train perplexity4.929014682769775
INFO:root:current mean train loss 2019.0868052040657
INFO:root:current train perplexity4.926292419433594
INFO:root:current mean train loss 2019.9846911556506
INFO:root:current train perplexity4.923577308654785
INFO:root:current mean train loss 2020.2806346572447
INFO:root:current train perplexity4.9260711669921875
INFO:root:current mean train loss 2022.2425832070066
INFO:root:current train perplexity4.927639484405518
INFO:root:current mean train loss 2021.960588050611
INFO:root:current train perplexity4.927573204040527
INFO:root:current mean train loss 2022.322011980631
INFO:root:current train perplexity4.9271979331970215
INFO:root:current mean train loss 2021.823252586802
INFO:root:current train perplexity4.923848628997803
INFO:root:current mean train loss 2022.8575650105433
INFO:root:current train perplexity4.927496910095215
INFO:root:current mean train loss 2023.498667874179
INFO:root:current train perplexity4.9274444580078125
INFO:root:current mean train loss 2023.9566863778318
INFO:root:current train perplexity4.928934574127197
INFO:root:current mean train loss 2024.868135019201
INFO:root:current train perplexity4.929627895355225
INFO:root:current mean train loss 2025.0037709716241
INFO:root:current train perplexity4.931124687194824
INFO:root:current mean train loss 2025.6081573880952
INFO:root:current train perplexity4.933828830718994
INFO:root:current mean train loss 2025.1215523249775
INFO:root:current train perplexity4.9359130859375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:10<00:00, 430.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:10<00:00, 430.34s/it]
INFO:root:final mean train loss: 2024.6892446882487
INFO:root:final train perplexity: 4.937168121337891
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.88s/it]
INFO:root:eval mean loss: 2834.3276726433464
INFO:root:eval perplexity: 10.234585762023926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/22
 22%|â–ˆâ–ˆâ–       | 22/100 [3:02:46<10:42:57, 494.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2004.5789226375214
INFO:root:current train perplexity4.883941173553467
INFO:root:current mean train loss 2012.5651121635658
INFO:root:current train perplexity4.880980968475342
INFO:root:current mean train loss 2011.0943129542984
INFO:root:current train perplexity4.879232883453369
INFO:root:current mean train loss 2009.418905386017
INFO:root:current train perplexity4.884121894836426
INFO:root:current mean train loss 2007.1215453843486
INFO:root:current train perplexity4.866644859313965
INFO:root:current mean train loss 2009.614628923293
INFO:root:current train perplexity4.875889301300049
INFO:root:current mean train loss 2009.9260304693305
INFO:root:current train perplexity4.879391193389893
INFO:root:current mean train loss 2008.5270901343183
INFO:root:current train perplexity4.879663467407227
INFO:root:current mean train loss 2009.1846476376809
INFO:root:current train perplexity4.8823137283325195
INFO:root:current mean train loss 2011.5222726255379
INFO:root:current train perplexity4.885836601257324
INFO:root:current mean train loss 2013.9108935637887
INFO:root:current train perplexity4.892556667327881
INFO:root:current mean train loss 2013.787170358123
INFO:root:current train perplexity4.89220666885376
INFO:root:current mean train loss 2013.546515693275
INFO:root:current train perplexity4.8937201499938965
INFO:root:current mean train loss 2012.76303831852
INFO:root:current train perplexity4.892862796783447
INFO:root:current mean train loss 2013.4709983975888
INFO:root:current train perplexity4.891269683837891
INFO:root:current mean train loss 2014.9841285312698
INFO:root:current train perplexity4.898012638092041
INFO:root:current mean train loss 2015.3111478870526
INFO:root:current train perplexity4.896942615509033
INFO:root:current mean train loss 2014.4129682047112
INFO:root:current train perplexity4.8942670822143555
INFO:root:current mean train loss 2014.4708196555493
INFO:root:current train perplexity4.894337177276611
INFO:root:current mean train loss 2015.0072663699198
INFO:root:current train perplexity4.896843910217285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:12<00:00, 432.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:12<00:00, 432.58s/it]
INFO:root:final mean train loss: 2014.08639841854
INFO:root:final train perplexity: 4.896055221557617
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.94s/it]
INFO:root:eval mean loss: 2834.64928869299
INFO:root:eval perplexity: 10.237287521362305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/23
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [3:10:58<10:33:34, 493.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2014.1271647135416
INFO:root:current train perplexity4.829154014587402
INFO:root:current mean train loss 2000.2368999280427
INFO:root:current train perplexity4.809264659881592
INFO:root:current mean train loss 2001.654548592403
INFO:root:current train perplexity4.824837684631348
INFO:root:current mean train loss 2007.103518755008
INFO:root:current train perplexity4.840916633605957
INFO:root:current mean train loss 1998.6843588069994
INFO:root:current train perplexity4.827329158782959
INFO:root:current mean train loss 2001.181640418101
INFO:root:current train perplexity4.834550380706787
INFO:root:current mean train loss 2003.5888666567596
INFO:root:current train perplexity4.84327507019043
INFO:root:current mean train loss 2005.2315364789358
INFO:root:current train perplexity4.843805313110352
INFO:root:current mean train loss 2004.6361540719365
INFO:root:current train perplexity4.845329284667969
INFO:root:current mean train loss 2006.703383073903
INFO:root:current train perplexity4.853972434997559
INFO:root:current mean train loss 2004.5050574066443
INFO:root:current train perplexity4.852836608886719
INFO:root:current mean train loss 2003.211324842437
INFO:root:current train perplexity4.845746994018555
INFO:root:current mean train loss 2002.008496756147
INFO:root:current train perplexity4.840630054473877
INFO:root:current mean train loss 2001.739771122555
INFO:root:current train perplexity4.842994213104248
INFO:root:current mean train loss 2002.2901445017565
INFO:root:current train perplexity4.8467278480529785
INFO:root:current mean train loss 2004.054626771939
INFO:root:current train perplexity4.852475166320801
INFO:root:current mean train loss 2003.548399939904
INFO:root:current train perplexity4.854436874389648
INFO:root:current mean train loss 2003.9390644094797
INFO:root:current train perplexity4.856160640716553
INFO:root:current mean train loss 2004.431016387132
INFO:root:current train perplexity4.857565879821777

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.70s/it]
INFO:root:final mean train loss: 2004.0234628005035
INFO:root:final train perplexity: 4.8573527336120605
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.73s/it]
INFO:root:eval mean loss: 2837.394553977806
INFO:root:eval perplexity: 10.2603759765625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/24
 24%|â–ˆâ–ˆâ–       | 24/100 [3:19:36<10:34:22, 500.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1916.2141287667412
INFO:root:current train perplexity4.674564361572266
INFO:root:current mean train loss 1965.1074355651285
INFO:root:current train perplexity4.746860504150391
INFO:root:current mean train loss 1976.3368828077823
INFO:root:current train perplexity4.772617340087891
INFO:root:current mean train loss 1981.202902331026
INFO:root:current train perplexity4.7879958152771
INFO:root:current mean train loss 1982.8014962761056
INFO:root:current train perplexity4.789130210876465
INFO:root:current mean train loss 1983.0560018625956
INFO:root:current train perplexity4.787224769592285
INFO:root:current mean train loss 1985.0730322346067
INFO:root:current train perplexity4.79697847366333
INFO:root:current mean train loss 1988.276237002188
INFO:root:current train perplexity4.806096076965332
INFO:root:current mean train loss 1987.7017315530127
INFO:root:current train perplexity4.804676532745361
INFO:root:current mean train loss 1988.9127104400668
INFO:root:current train perplexity4.8071465492248535
INFO:root:current mean train loss 1989.1943224818847
INFO:root:current train perplexity4.810892105102539
INFO:root:current mean train loss 1990.4735944380927
INFO:root:current train perplexity4.811439514160156
INFO:root:current mean train loss 1993.5119935346222
INFO:root:current train perplexity4.820875644683838
INFO:root:current mean train loss 1993.1204712567844
INFO:root:current train perplexity4.81894588470459
INFO:root:current mean train loss 1993.0977099539969
INFO:root:current train perplexity4.818910598754883
INFO:root:current mean train loss 1994.2768318971105
INFO:root:current train perplexity4.820017337799072
INFO:root:current mean train loss 1996.2622823851702
INFO:root:current train perplexity4.823225021362305
INFO:root:current mean train loss 1995.3820024165202
INFO:root:current train perplexity4.822777271270752
INFO:root:current mean train loss 1995.4676496783343
INFO:root:current train perplexity4.823447227478027
INFO:root:current mean train loss 1995.0100534856163
INFO:root:current train perplexity4.822363376617432

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:16<00:00, 436.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:16<00:00, 436.72s/it]
INFO:root:final mean train loss: 1994.5352684094096
INFO:root:final train perplexity: 4.821140766143799
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.59s/it]
INFO:root:eval mean loss: 2837.6652450790634
INFO:root:eval perplexity: 10.262654304504395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/25
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [3:28:17<10:33:55, 507.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1961.832066853841
INFO:root:current train perplexity4.72201681137085
INFO:root:current mean train loss 1957.0643113659273
INFO:root:current train perplexity4.76161527633667
INFO:root:current mean train loss 1969.6553519112724
INFO:root:current train perplexity4.776251792907715
INFO:root:current mean train loss 1976.2817439326534
INFO:root:current train perplexity4.765152931213379
INFO:root:current mean train loss 1974.888797975936
INFO:root:current train perplexity4.759757041931152
INFO:root:current mean train loss 1977.164629987178
INFO:root:current train perplexity4.761276721954346
INFO:root:current mean train loss 1980.4748188899114
INFO:root:current train perplexity4.769766330718994
INFO:root:current mean train loss 1983.204306418066
INFO:root:current train perplexity4.7787184715271
INFO:root:current mean train loss 1983.855939994738
INFO:root:current train perplexity4.777200222015381
INFO:root:current mean train loss 1982.856548226757
INFO:root:current train perplexity4.771872043609619
INFO:root:current mean train loss 1983.5579750537872
INFO:root:current train perplexity4.778347969055176
INFO:root:current mean train loss 1984.258883221718
INFO:root:current train perplexity4.775472164154053
INFO:root:current mean train loss 1983.3213537876902
INFO:root:current train perplexity4.771767616271973
INFO:root:current mean train loss 1983.4903345943578
INFO:root:current train perplexity4.774899005889893
INFO:root:current mean train loss 1984.271957740355
INFO:root:current train perplexity4.776132583618164
INFO:root:current mean train loss 1984.9038609782542
INFO:root:current train perplexity4.778162479400635
INFO:root:current mean train loss 1985.7549701559133
INFO:root:current train perplexity4.779391288757324
INFO:root:current mean train loss 1986.9032206170243
INFO:root:current train perplexity4.782898902893066
INFO:root:current mean train loss 1986.0271234345018
INFO:root:current train perplexity4.784584045410156
INFO:root:current mean train loss 1986.1844090324926
INFO:root:current train perplexity4.784241676330566

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:12<00:00, 432.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:12<00:00, 432.68s/it]
INFO:root:final mean train loss: 1984.7072496284334
INFO:root:final train perplexity: 4.783916473388672
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.44s/it]
INFO:root:eval mean loss: 2836.0529865803305
INFO:root:eval perplexity: 10.249085426330566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/26
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [3:36:22<10:17:13, 500.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1984.6112447599085
INFO:root:current train perplexity4.739505290985107
INFO:root:current mean train loss 1966.591040212212
INFO:root:current train perplexity4.730801582336426
INFO:root:current mean train loss 1968.1091592242608
INFO:root:current train perplexity4.740265369415283
INFO:root:current mean train loss 1979.0599161187224
INFO:root:current train perplexity4.756132125854492
INFO:root:current mean train loss 1972.54564986802
INFO:root:current train perplexity4.751093864440918
INFO:root:current mean train loss 1974.3032799683745
INFO:root:current train perplexity4.7511067390441895
INFO:root:current mean train loss 1974.232100416829
INFO:root:current train perplexity4.752049922943115
INFO:root:current mean train loss 1974.3852102508752
INFO:root:current train perplexity4.755190849304199
INFO:root:current mean train loss 1978.2048773839272
INFO:root:current train perplexity4.761533260345459
INFO:root:current mean train loss 1976.507602087623
INFO:root:current train perplexity4.755203723907471
INFO:root:current mean train loss 1974.5723780797834
INFO:root:current train perplexity4.750988960266113
INFO:root:current mean train loss 1976.1091297895211
INFO:root:current train perplexity4.750064849853516
INFO:root:current mean train loss 1976.07339278351
INFO:root:current train perplexity4.747920513153076
INFO:root:current mean train loss 1976.3245112271918
INFO:root:current train perplexity4.749638080596924
INFO:root:current mean train loss 1976.8133649117908
INFO:root:current train perplexity4.752475261688232
INFO:root:current mean train loss 1976.711132844186
INFO:root:current train perplexity4.75315523147583
INFO:root:current mean train loss 1976.1893152844825
INFO:root:current train perplexity4.752033233642578
INFO:root:current mean train loss 1976.2967349101182
INFO:root:current train perplexity4.752133846282959
INFO:root:current mean train loss 1976.3428626860825
INFO:root:current train perplexity4.751091480255127
INFO:root:current mean train loss 1976.4079442680159
INFO:root:current train perplexity4.751193523406982

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.52s/it]
INFO:root:final mean train loss: 1976.113027937173
INFO:root:final train perplexity: 4.751600742340088
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.55s/it]
INFO:root:eval mean loss: 2833.2626395927177
INFO:root:eval perplexity: 10.2256441116333
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/27
 27%|â–ˆâ–ˆâ–‹       | 27/100 [3:44:29<10:03:53, 496.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1980.890591325431
INFO:root:current train perplexity4.685492038726807
INFO:root:current mean train loss 1959.4498816381526
INFO:root:current train perplexity4.671980857849121
INFO:root:current mean train loss 1951.1866615945978
INFO:root:current train perplexity4.688688278198242
INFO:root:current mean train loss 1951.5253483436627
INFO:root:current train perplexity4.685555934906006
INFO:root:current mean train loss 1955.5903245684362
INFO:root:current train perplexity4.697771072387695
INFO:root:current mean train loss 1961.1089365969422
INFO:root:current train perplexity4.7064409255981445
INFO:root:current mean train loss 1962.8579353865882
INFO:root:current train perplexity4.709165096282959
INFO:root:current mean train loss 1964.3776058307737
INFO:root:current train perplexity4.712162017822266
INFO:root:current mean train loss 1965.4250337471774
INFO:root:current train perplexity4.716374397277832
INFO:root:current mean train loss 1965.0130945257454
INFO:root:current train perplexity4.713508605957031
INFO:root:current mean train loss 1964.436132881727
INFO:root:current train perplexity4.712494373321533
INFO:root:current mean train loss 1965.702508218136
INFO:root:current train perplexity4.713300704956055
INFO:root:current mean train loss 1967.1015172815853
INFO:root:current train perplexity4.715498924255371
INFO:root:current mean train loss 1966.9379968207784
INFO:root:current train perplexity4.713681221008301
INFO:root:current mean train loss 1967.0069073544935
INFO:root:current train perplexity4.714192867279053
INFO:root:current mean train loss 1967.9899125105303
INFO:root:current train perplexity4.716887474060059
INFO:root:current mean train loss 1967.8441129714358
INFO:root:current train perplexity4.71661901473999
INFO:root:current mean train loss 1967.1840562006719
INFO:root:current train perplexity4.714694976806641
INFO:root:current mean train loss 1967.8101551725226
INFO:root:current train perplexity4.718839168548584
INFO:root:current mean train loss 1967.9550826761404
INFO:root:current train perplexity4.718994140625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.91s/it]
INFO:root:final mean train loss: 1967.7362422510282
INFO:root:final train perplexity: 4.72031307220459
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.59s/it]
INFO:root:eval mean loss: 2835.2342379000092
INFO:root:eval perplexity: 10.242201805114746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/28
 28%|â–ˆâ–ˆâ–Š       | 28/100 [3:52:35<9:51:57, 493.30s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1980.4528108723957
INFO:root:current train perplexity4.730868816375732
INFO:root:current mean train loss 1967.2624839564733
INFO:root:current train perplexity4.681678771972656
INFO:root:current mean train loss 1961.8200714666193
INFO:root:current train perplexity4.6795525550842285
INFO:root:current mean train loss 1962.4083763020833
INFO:root:current train perplexity4.687511920928955
INFO:root:current mean train loss 1962.7700495990955
INFO:root:current train perplexity4.692305088043213
INFO:root:current mean train loss 1958.344444420856
INFO:root:current train perplexity4.681143283843994
INFO:root:current mean train loss 1957.3642961516205
INFO:root:current train perplexity4.679470539093018
INFO:root:current mean train loss 1960.7390569871473
INFO:root:current train perplexity4.68637752532959
INFO:root:current mean train loss 1961.384548828125
INFO:root:current train perplexity4.686684608459473
INFO:root:current mean train loss 1962.449633914263
INFO:root:current train perplexity4.686248302459717
INFO:root:current mean train loss 1963.2374477652615
INFO:root:current train perplexity4.68767786026001
INFO:root:current mean train loss 1961.3940370470411
INFO:root:current train perplexity4.6875152587890625
INFO:root:current mean train loss 1959.6028475413602
INFO:root:current train perplexity4.684727191925049
INFO:root:current mean train loss 1958.607745205966
INFO:root:current train perplexity4.686225414276123
INFO:root:current mean train loss 1958.6557320080774
INFO:root:current train perplexity4.684798240661621
INFO:root:current mean train loss 1960.0992514570933
INFO:root:current train perplexity4.686429023742676
INFO:root:current mean train loss 1960.4723436771221
INFO:root:current train perplexity4.688019275665283
INFO:root:current mean train loss 1959.8321325511663
INFO:root:current train perplexity4.687714576721191
INFO:root:current mean train loss 1959.9833252604167
INFO:root:current train perplexity4.689018249511719
INFO:root:current mean train loss 1959.4772032609771
INFO:root:current train perplexity4.688299655914307

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.50s/it]
INFO:root:final mean train loss: 1959.1736506829043
INFO:root:final train perplexity: 4.688544273376465
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.20s/it]
INFO:root:eval mean loss: 2838.0764548728416
INFO:root:eval perplexity: 10.266117095947266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/29
 29%|â–ˆâ–ˆâ–‰       | 29/100 [4:00:43<9:41:39, 491.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1947.7224333389945
INFO:root:current train perplexity4.639644622802734
INFO:root:current mean train loss 1945.2166442871094
INFO:root:current train perplexity4.643830299377441
INFO:root:current mean train loss 1952.051678801236
INFO:root:current train perplexity4.643549919128418
INFO:root:current mean train loss 1953.5374042744538
INFO:root:current train perplexity4.647558689117432
INFO:root:current mean train loss 1960.8837456431816
INFO:root:current train perplexity4.6581926345825195
INFO:root:current mean train loss 1960.3889092110298
INFO:root:current train perplexity4.663285255432129
INFO:root:current mean train loss 1959.499002622042
INFO:root:current train perplexity4.656214237213135
INFO:root:current mean train loss 1957.0863729149405
INFO:root:current train perplexity4.654314994812012
INFO:root:current mean train loss 1958.2533208051605
INFO:root:current train perplexity4.655093669891357
INFO:root:current mean train loss 1957.443450066351
INFO:root:current train perplexity4.655685901641846
INFO:root:current mean train loss 1956.1492414649153
INFO:root:current train perplexity4.652130603790283
INFO:root:current mean train loss 1955.556837555546
INFO:root:current train perplexity4.653453350067139
INFO:root:current mean train loss 1954.9734994988692
INFO:root:current train perplexity4.6530632972717285
INFO:root:current mean train loss 1954.6455006215765
INFO:root:current train perplexity4.655946254730225
INFO:root:current mean train loss 1955.6301293258052
INFO:root:current train perplexity4.658261775970459
INFO:root:current mean train loss 1954.8929605148546
INFO:root:current train perplexity4.657660961151123
INFO:root:current mean train loss 1953.8290731371435
INFO:root:current train perplexity4.65693998336792
INFO:root:current mean train loss 1951.8423656054906
INFO:root:current train perplexity4.6572771072387695
INFO:root:current mean train loss 1951.8172082235646
INFO:root:current train perplexity4.659396171569824

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:09<00:00, 429.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:09<00:00, 429.60s/it]
INFO:root:final mean train loss: 1951.4408054399898
INFO:root:final train perplexity: 4.660037517547607
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.71s/it]
INFO:root:eval mean loss: 2833.1556803385415
INFO:root:eval perplexity: 10.224747657775879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/30
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [4:08:48<9:31:10, 489.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1898.6304117838542
INFO:root:current train perplexity4.676206588745117
INFO:root:current mean train loss 1928.7954146358945
INFO:root:current train perplexity4.621723651885986
INFO:root:current mean train loss 1938.2806939668062
INFO:root:current train perplexity4.622575759887695
INFO:root:current mean train loss 1939.6623025542324
INFO:root:current train perplexity4.633108615875244
INFO:root:current mean train loss 1943.631250656613
INFO:root:current train perplexity4.627063274383545
INFO:root:current mean train loss 1938.8549435358852
INFO:root:current train perplexity4.611110210418701
INFO:root:current mean train loss 1939.765959741251
INFO:root:current train perplexity4.61245584487915
INFO:root:current mean train loss 1938.8936908759586
INFO:root:current train perplexity4.613109111785889
INFO:root:current mean train loss 1940.5480886112775
INFO:root:current train perplexity4.614363670349121
INFO:root:current mean train loss 1941.1975129886036
INFO:root:current train perplexity4.617722034454346
INFO:root:current mean train loss 1942.6138698248963
INFO:root:current train perplexity4.621120929718018
INFO:root:current mean train loss 1942.4836158305272
INFO:root:current train perplexity4.622156143188477
INFO:root:current mean train loss 1942.9376631642888
INFO:root:current train perplexity4.6260881423950195
INFO:root:current mean train loss 1943.7014334542412
INFO:root:current train perplexity4.627591609954834
INFO:root:current mean train loss 1944.247390866195
INFO:root:current train perplexity4.627042770385742
INFO:root:current mean train loss 1944.0939027294567
INFO:root:current train perplexity4.628236770629883
INFO:root:current mean train loss 1944.2069080416795
INFO:root:current train perplexity4.6285481452941895
INFO:root:current mean train loss 1944.4240236232126
INFO:root:current train perplexity4.631448268890381
INFO:root:current mean train loss 1944.1820986079802
INFO:root:current train perplexity4.631800174713135
INFO:root:current mean train loss 1944.025985374071
INFO:root:current train perplexity4.631740093231201

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.63s/it]
INFO:root:final mean train loss: 1943.7366919043807
INFO:root:final train perplexity: 4.631810188293457
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.14s/it]
INFO:root:eval mean loss: 2834.6825394730668
INFO:root:eval perplexity: 10.237565994262695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/31
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [4:16:53<9:21:36, 488.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1929.4080763596755
INFO:root:current train perplexity4.597877502441406
INFO:root:current mean train loss 1929.0248325892858
INFO:root:current train perplexity4.57448673248291
INFO:root:current mean train loss 1931.1685499343198
INFO:root:current train perplexity4.5738301277160645
INFO:root:current mean train loss 1923.1134576153902
INFO:root:current train perplexity4.553530693054199
INFO:root:current mean train loss 1922.9494282180715
INFO:root:current train perplexity4.554686546325684
INFO:root:current mean train loss 1926.3875920400874
INFO:root:current train perplexity4.564717769622803
INFO:root:current mean train loss 1928.267671140238
INFO:root:current train perplexity4.571671962738037
INFO:root:current mean train loss 1931.2998399970945
INFO:root:current train perplexity4.575435638427734
INFO:root:current mean train loss 1934.8159133874187
INFO:root:current train perplexity4.582136631011963
INFO:root:current mean train loss 1933.1471378334654
INFO:root:current train perplexity4.5816569328308105
INFO:root:current mean train loss 1933.0599360475298
INFO:root:current train perplexity4.586087226867676
INFO:root:current mean train loss 1935.3918027725356
INFO:root:current train perplexity4.595104694366455
INFO:root:current mean train loss 1935.7930243089188
INFO:root:current train perplexity4.598670959472656
INFO:root:current mean train loss 1936.6368968842796
INFO:root:current train perplexity4.598752975463867
INFO:root:current mean train loss 1935.7570176733159
INFO:root:current train perplexity4.600386619567871
INFO:root:current mean train loss 1934.4139344301636
INFO:root:current train perplexity4.6001763343811035
INFO:root:current mean train loss 1935.6658421290024
INFO:root:current train perplexity4.602964878082275
INFO:root:current mean train loss 1936.4631523760004
INFO:root:current train perplexity4.605125427246094
INFO:root:current mean train loss 1936.2252503444174
INFO:root:current train perplexity4.603930473327637
INFO:root:current mean train loss 1936.5158795349819
INFO:root:current train perplexity4.606215000152588

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:07<00:00, 427.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:07<00:00, 427.72s/it]
INFO:root:final mean train loss: 1936.738132986587
INFO:root:final train perplexity: 4.606315612792969
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.97s/it]
INFO:root:eval mean loss: 2835.9725638724663
INFO:root:eval perplexity: 10.248408317565918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/32
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [4:24:56<9:11:26, 486.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1907.8866818450217
INFO:root:current train perplexity4.473073959350586
INFO:root:current mean train loss 1924.0451933320585
INFO:root:current train perplexity4.520509719848633
INFO:root:current mean train loss 1930.7783283500514
INFO:root:current train perplexity4.54953670501709
INFO:root:current mean train loss 1930.4132685091336
INFO:root:current train perplexity4.558109283447266
INFO:root:current mean train loss 1925.40342970734
INFO:root:current train perplexity4.552995681762695
INFO:root:current mean train loss 1921.8918897653373
INFO:root:current train perplexity4.549705982208252
INFO:root:current mean train loss 1919.9103039493828
INFO:root:current train perplexity4.553951740264893
INFO:root:current mean train loss 1921.606817766603
INFO:root:current train perplexity4.558796405792236
INFO:root:current mean train loss 1922.315967636742
INFO:root:current train perplexity4.562455654144287
INFO:root:current mean train loss 1925.7326326178088
INFO:root:current train perplexity4.568078994750977
INFO:root:current mean train loss 1926.5585506801294
INFO:root:current train perplexity4.571442127227783
INFO:root:current mean train loss 1926.9807095798817
INFO:root:current train perplexity4.572944164276123
INFO:root:current mean train loss 1928.7904720536567
INFO:root:current train perplexity4.575469970703125
INFO:root:current mean train loss 1929.094902532809
INFO:root:current train perplexity4.5746073722839355
INFO:root:current mean train loss 1929.104429925719
INFO:root:current train perplexity4.5749664306640625
INFO:root:current mean train loss 1930.2247929155865
INFO:root:current train perplexity4.575697898864746
INFO:root:current mean train loss 1930.8446261869722
INFO:root:current train perplexity4.576253890991211
INFO:root:current mean train loss 1930.1479934105844
INFO:root:current train perplexity4.576807975769043
INFO:root:current mean train loss 1929.6972383363573
INFO:root:current train perplexity4.5788774490356445
INFO:root:current mean train loss 1929.9783698065773
INFO:root:current train perplexity4.579638957977295

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:10<00:00, 430.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:10<00:00, 430.41s/it]
INFO:root:final mean train loss: 1929.041835028898
INFO:root:final train perplexity: 4.5784406661987305
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.08s/it]
INFO:root:eval mean loss: 2837.247389968093
INFO:root:eval perplexity: 10.259133338928223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/33
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [4:33:00<9:02:35, 485.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1891.3975179036458
INFO:root:current train perplexity4.477508544921875
INFO:root:current mean train loss 1902.2774940490722
INFO:root:current train perplexity4.524284362792969
INFO:root:current mean train loss 1906.5619901216946
INFO:root:current train perplexity4.536900997161865
INFO:root:current mean train loss 1908.4996205647788
INFO:root:current train perplexity4.538854598999023
INFO:root:current mean train loss 1907.0247683317764
INFO:root:current train perplexity4.538472652435303
INFO:root:current mean train loss 1909.0198684692382
INFO:root:current train perplexity4.534856796264648
INFO:root:current mean train loss 1911.8555257161458
INFO:root:current train perplexity4.541596412658691
INFO:root:current mean train loss 1914.9064271625718
INFO:root:current train perplexity4.5420026779174805
INFO:root:current mean train loss 1918.0022783146349
INFO:root:current train perplexity4.5444254875183105
INFO:root:current mean train loss 1918.8246573130289
INFO:root:current train perplexity4.540778160095215
INFO:root:current mean train loss 1918.7197784999632
INFO:root:current train perplexity4.540767192840576
INFO:root:current mean train loss 1918.1748875058931
INFO:root:current train perplexity4.541093349456787
INFO:root:current mean train loss 1918.8552852570065
INFO:root:current train perplexity4.543567180633545
INFO:root:current mean train loss 1918.3562488331513
INFO:root:current train perplexity4.543389797210693
INFO:root:current mean train loss 1918.4237267063088
INFO:root:current train perplexity4.543074607849121
INFO:root:current mean train loss 1918.0755719307142
INFO:root:current train perplexity4.544023513793945
INFO:root:current mean train loss 1918.6299566429782
INFO:root:current train perplexity4.5452985763549805
INFO:root:current mean train loss 1920.5896079323509
INFO:root:current train perplexity4.548182964324951
INFO:root:current mean train loss 1921.850297825311
INFO:root:current train perplexity4.551655292510986
INFO:root:current mean train loss 1923.283569211376
INFO:root:current train perplexity4.555995464324951

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.30s/it]
INFO:root:final mean train loss: 1922.4266559333437
INFO:root:final train perplexity: 4.554616451263428
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.03s/it]
INFO:root:eval mean loss: 2835.1549963048988
INFO:root:eval perplexity: 10.241538047790527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/34
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [4:41:09<8:55:31, 486.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1931.9216498833198
INFO:root:current train perplexity4.49884557723999
INFO:root:current mean train loss 1926.1289559057204
INFO:root:current train perplexity4.517640113830566
INFO:root:current mean train loss 1916.1934906997406
INFO:root:current train perplexity4.509475231170654
INFO:root:current mean train loss 1914.1108220350836
INFO:root:current train perplexity4.511783599853516
INFO:root:current mean train loss 1911.817061642181
INFO:root:current train perplexity4.518064975738525
INFO:root:current mean train loss 1913.3724504864194
INFO:root:current train perplexity4.5213847160339355
INFO:root:current mean train loss 1912.010097216292
INFO:root:current train perplexity4.516503810882568
INFO:root:current mean train loss 1912.72757488236
INFO:root:current train perplexity4.512589931488037
INFO:root:current mean train loss 1911.7632477606987
INFO:root:current train perplexity4.511137962341309
INFO:root:current mean train loss 1912.7048018737605
INFO:root:current train perplexity4.515160083770752
INFO:root:current mean train loss 1913.241727781163
INFO:root:current train perplexity4.518319606781006
INFO:root:current mean train loss 1914.6989544890346
INFO:root:current train perplexity4.522154808044434
INFO:root:current mean train loss 1916.0481879488975
INFO:root:current train perplexity4.52742338180542
INFO:root:current mean train loss 1916.1566539756093
INFO:root:current train perplexity4.527801513671875
INFO:root:current mean train loss 1915.278386513123
INFO:root:current train perplexity4.526838302612305
INFO:root:current mean train loss 1915.162241508179
INFO:root:current train perplexity4.525961399078369
INFO:root:current mean train loss 1916.027714037227
INFO:root:current train perplexity4.528095245361328
INFO:root:current mean train loss 1916.3554381809008
INFO:root:current train perplexity4.529538631439209
INFO:root:current mean train loss 1916.7792023144063
INFO:root:current train perplexity4.5316667556762695
INFO:root:current mean train loss 1916.3639161761625
INFO:root:current train perplexity4.531306743621826

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:12<00:00, 432.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:12<00:00, 432.80s/it]
INFO:root:final mean train loss: 1915.8306292881584
INFO:root:final train perplexity: 4.530984401702881
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.78s/it]
INFO:root:eval mean loss: 2835.1976908549173
INFO:root:eval perplexity: 10.241894721984863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/35
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [4:49:16<8:47:33, 486.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1929.0363250083112
INFO:root:current train perplexity4.5399065017700195
INFO:root:current mean train loss 1916.1392293713757
INFO:root:current train perplexity4.511449813842773
INFO:root:current mean train loss 1914.67231968471
INFO:root:current train perplexity4.500622272491455
INFO:root:current mean train loss 1910.9871844761262
INFO:root:current train perplexity4.492778301239014
INFO:root:current mean train loss 1909.1592273789379
INFO:root:current train perplexity4.499744415283203
INFO:root:current mean train loss 1910.4689668083834
INFO:root:current train perplexity4.500707149505615
INFO:root:current mean train loss 1909.6895783614013
INFO:root:current train perplexity4.503724575042725
INFO:root:current mean train loss 1910.2688241953813
INFO:root:current train perplexity4.500797748565674
INFO:root:current mean train loss 1910.0697907654765
INFO:root:current train perplexity4.503332614898682
INFO:root:current mean train loss 1908.3580912968043
INFO:root:current train perplexity4.500697612762451
INFO:root:current mean train loss 1910.105720589758
INFO:root:current train perplexity4.503312110900879
INFO:root:current mean train loss 1910.969590485795
INFO:root:current train perplexity4.502432823181152
INFO:root:current mean train loss 1910.5548357956193
INFO:root:current train perplexity4.505992412567139
INFO:root:current mean train loss 1910.952772274592
INFO:root:current train perplexity4.506556987762451
INFO:root:current mean train loss 1910.9494537394369
INFO:root:current train perplexity4.5058817863464355
INFO:root:current mean train loss 1909.5560651944302
INFO:root:current train perplexity4.503775119781494
INFO:root:current mean train loss 1909.0425246417733
INFO:root:current train perplexity4.503310680389404
INFO:root:current mean train loss 1909.8687286206844
INFO:root:current train perplexity4.505730152130127
INFO:root:current mean train loss 1909.9629711888283
INFO:root:current train perplexity4.5075225830078125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.44s/it]
INFO:root:final mean train loss: 1909.211396756463
INFO:root:final train perplexity: 4.5073933601379395
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.24s/it]
INFO:root:eval mean loss: 2842.8270890519425
INFO:root:eval perplexity: 10.3062162399292
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/36
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [4:57:23<8:39:14, 486.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1931.7282825816762
INFO:root:current train perplexity4.586000919342041
INFO:root:current mean train loss 1887.3334543039132
INFO:root:current train perplexity4.472550392150879
INFO:root:current mean train loss 1883.05840399141
INFO:root:current train perplexity4.447020530700684
INFO:root:current mean train loss 1889.78542708124
INFO:root:current train perplexity4.461812973022461
INFO:root:current mean train loss 1892.0199619116863
INFO:root:current train perplexity4.451474189758301
INFO:root:current mean train loss 1894.4270404136344
INFO:root:current train perplexity4.460701942443848
INFO:root:current mean train loss 1897.9059261440646
INFO:root:current train perplexity4.4693145751953125
INFO:root:current mean train loss 1898.2979696839839
INFO:root:current train perplexity4.46881628036499
INFO:root:current mean train loss 1896.518702195399
INFO:root:current train perplexity4.469438552856445
INFO:root:current mean train loss 1895.816423535478
INFO:root:current train perplexity4.47162389755249
INFO:root:current mean train loss 1896.4430080153468
INFO:root:current train perplexity4.473342418670654
INFO:root:current mean train loss 1896.254534401194
INFO:root:current train perplexity4.47383975982666
INFO:root:current mean train loss 1897.9862162356137
INFO:root:current train perplexity4.4754319190979
INFO:root:current mean train loss 1897.5035503745353
INFO:root:current train perplexity4.475687503814697
INFO:root:current mean train loss 1900.4793572267008
INFO:root:current train perplexity4.477232933044434
INFO:root:current mean train loss 1900.7624657944605
INFO:root:current train perplexity4.480020523071289
INFO:root:current mean train loss 1901.6873508787244
INFO:root:current train perplexity4.4817891120910645
INFO:root:current mean train loss 1902.626447221677
INFO:root:current train perplexity4.4816718101501465
INFO:root:current mean train loss 1902.8059470283597
INFO:root:current train perplexity4.483038902282715
INFO:root:current mean train loss 1902.582112694086
INFO:root:current train perplexity4.482800483703613

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:10<00:00, 430.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:10<00:00, 430.34s/it]
INFO:root:final mean train loss: 1903.080298996549
INFO:root:final train perplexity: 4.485650062561035
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.82s/it]
INFO:root:eval mean loss: 2842.682723494979
INFO:root:eval perplexity: 10.304994583129883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/37
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [5:05:25<8:29:54, 485.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1889.3172694614955
INFO:root:current train perplexity4.427427291870117
INFO:root:current mean train loss 1890.367805480957
INFO:root:current train perplexity4.440845966339111
INFO:root:current mean train loss 1888.9045581483003
INFO:root:current train perplexity4.428455829620361
INFO:root:current mean train loss 1882.8492059475038
INFO:root:current train perplexity4.42408561706543
INFO:root:current mean train loss 1882.8061340902452
INFO:root:current train perplexity4.430103302001953
INFO:root:current mean train loss 1885.4476029367158
INFO:root:current train perplexity4.438667297363281
INFO:root:current mean train loss 1886.226870008335
INFO:root:current train perplexity4.43902063369751
INFO:root:current mean train loss 1885.411176576719
INFO:root:current train perplexity4.440099239349365
INFO:root:current mean train loss 1885.9107685181255
INFO:root:current train perplexity4.444461822509766
INFO:root:current mean train loss 1886.233350424931
INFO:root:current train perplexity4.446027755737305
INFO:root:current mean train loss 1888.7390858691026
INFO:root:current train perplexity4.448490142822266
INFO:root:current mean train loss 1889.920964450701
INFO:root:current train perplexity4.448101997375488
INFO:root:current mean train loss 1889.6996192559357
INFO:root:current train perplexity4.450479507446289
INFO:root:current mean train loss 1890.6677418904133
INFO:root:current train perplexity4.451003551483154
INFO:root:current mean train loss 1890.0743491976868
INFO:root:current train perplexity4.450408935546875
INFO:root:current mean train loss 1892.377812969747
INFO:root:current train perplexity4.455020904541016
INFO:root:current mean train loss 1895.2642338633245
INFO:root:current train perplexity4.460067272186279
INFO:root:current mean train loss 1896.8145371896248
INFO:root:current train perplexity4.461568832397461
INFO:root:current mean train loss 1897.6454029041515
INFO:root:current train perplexity4.46394681930542
INFO:root:current mean train loss 1897.4151834195086
INFO:root:current train perplexity4.463344573974609

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:18<00:00, 438.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:18<00:00, 438.02s/it]
INFO:root:final mean train loss: 1896.713933547458
INFO:root:final train perplexity: 4.4631853103637695
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.94s/it]
INFO:root:eval mean loss: 2846.8356860278245
INFO:root:eval perplexity: 10.340168952941895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/38
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [5:13:39<8:24:18, 488.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1865.9504503038195
INFO:root:current train perplexity4.40294075012207
INFO:root:current mean train loss 1888.1962065598061
INFO:root:current train perplexity4.412524700164795
INFO:root:current mean train loss 1892.7496322943239
INFO:root:current train perplexity4.426502227783203
INFO:root:current mean train loss 1886.1438784391983
INFO:root:current train perplexity4.420989990234375
INFO:root:current mean train loss 1887.7195221975949
INFO:root:current train perplexity4.423214912414551
INFO:root:current mean train loss 1886.706784197606
INFO:root:current train perplexity4.423380374908447
INFO:root:current mean train loss 1886.9022065391837
INFO:root:current train perplexity4.42054557800293
INFO:root:current mean train loss 1885.3480544122274
INFO:root:current train perplexity4.417198657989502
INFO:root:current mean train loss 1886.9989207250833
INFO:root:current train perplexity4.419200420379639
INFO:root:current mean train loss 1887.1436219876405
INFO:root:current train perplexity4.419576644897461
INFO:root:current mean train loss 1887.6667091479142
INFO:root:current train perplexity4.42331075668335
INFO:root:current mean train loss 1889.186288998533
INFO:root:current train perplexity4.427883625030518
INFO:root:current mean train loss 1889.7377201187562
INFO:root:current train perplexity4.43057918548584
INFO:root:current mean train loss 1888.198603769749
INFO:root:current train perplexity4.432260036468506
INFO:root:current mean train loss 1889.677675662981
INFO:root:current train perplexity4.4333109855651855
INFO:root:current mean train loss 1889.710410898943
INFO:root:current train perplexity4.433286666870117
INFO:root:current mean train loss 1890.2207868303572
INFO:root:current train perplexity4.434824466705322
INFO:root:current mean train loss 1890.9446692699007
INFO:root:current train perplexity4.436888217926025
INFO:root:current mean train loss 1891.22733706756
INFO:root:current train perplexity4.4389142990112305
INFO:root:current mean train loss 1891.0516184201276
INFO:root:current train perplexity4.43979024887085

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.52s/it]
INFO:root:final mean train loss: 1890.5914206300429
INFO:root:final train perplexity: 4.441686630249023
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.02s/it]
INFO:root:eval mean loss: 2841.8566953183654
INFO:root:eval perplexity: 10.298009872436523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/39
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [5:21:47<8:16:14, 488.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1871.9112135364164
INFO:root:current train perplexity4.3904523849487305
INFO:root:current mean train loss 1873.8148276246625
INFO:root:current train perplexity4.3868303298950195
INFO:root:current mean train loss 1880.1488470412394
INFO:root:current train perplexity4.388851642608643
INFO:root:current mean train loss 1880.6374663463614
INFO:root:current train perplexity4.392885684967041
INFO:root:current mean train loss 1877.134560324929
INFO:root:current train perplexity4.396247863769531
INFO:root:current mean train loss 1880.0759498894852
INFO:root:current train perplexity4.410197734832764
INFO:root:current mean train loss 1880.0241693686862
INFO:root:current train perplexity4.411865234375
INFO:root:current mean train loss 1879.9719794165744
INFO:root:current train perplexity4.411201000213623
INFO:root:current mean train loss 1882.5920898720726
INFO:root:current train perplexity4.418291091918945
INFO:root:current mean train loss 1882.1521419913754
INFO:root:current train perplexity4.419060230255127
INFO:root:current mean train loss 1883.5078846847045
INFO:root:current train perplexity4.417476177215576
INFO:root:current mean train loss 1883.7021858359778
INFO:root:current train perplexity4.415276527404785
INFO:root:current mean train loss 1882.6446511923039
INFO:root:current train perplexity4.4137773513793945
INFO:root:current mean train loss 1883.7401082715273
INFO:root:current train perplexity4.417293548583984
INFO:root:current mean train loss 1883.3736919606597
INFO:root:current train perplexity4.4195942878723145
INFO:root:current mean train loss 1884.262462034726
INFO:root:current train perplexity4.420647621154785
INFO:root:current mean train loss 1885.1355413811013
INFO:root:current train perplexity4.421273708343506
INFO:root:current mean train loss 1885.4492021229428
INFO:root:current train perplexity4.422746181488037
INFO:root:current mean train loss 1885.9560147622474
INFO:root:current train perplexity4.423032283782959
INFO:root:current mean train loss 1886.024279859817
INFO:root:current train perplexity4.4226298332214355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:15<00:00, 435.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:15<00:00, 435.64s/it]
INFO:root:final mean train loss: 1885.3978168989634
INFO:root:final train perplexity: 4.4235310554504395
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.62s/it]
INFO:root:eval mean loss: 2845.2978647592904
INFO:root:eval perplexity: 10.327128410339355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/40
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [5:29:57<8:08:40, 488.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1875.1193924915942
INFO:root:current train perplexity4.39996337890625
INFO:root:current mean train loss 1880.5316407613914
INFO:root:current train perplexity4.393136501312256
INFO:root:current mean train loss 1878.0583885493672
INFO:root:current train perplexity4.394900798797607
INFO:root:current mean train loss 1877.5962249031168
INFO:root:current train perplexity4.398740291595459
INFO:root:current mean train loss 1876.2404846318827
INFO:root:current train perplexity4.398690223693848
INFO:root:current mean train loss 1878.545766669028
INFO:root:current train perplexity4.392827033996582
INFO:root:current mean train loss 1879.2897332574903
INFO:root:current train perplexity4.394186973571777
INFO:root:current mean train loss 1881.3253394776957
INFO:root:current train perplexity4.400142669677734
INFO:root:current mean train loss 1880.3639092385702
INFO:root:current train perplexity4.399856090545654
INFO:root:current mean train loss 1881.1335957948959
INFO:root:current train perplexity4.401416301727295
INFO:root:current mean train loss 1881.1155088352207
INFO:root:current train perplexity4.399955749511719
INFO:root:current mean train loss 1880.930103615849
INFO:root:current train perplexity4.4030022621154785
INFO:root:current mean train loss 1881.67254118513
INFO:root:current train perplexity4.401398181915283
INFO:root:current mean train loss 1882.8595409766758
INFO:root:current train perplexity4.406599998474121
INFO:root:current mean train loss 1883.1966091359766
INFO:root:current train perplexity4.407234191894531
INFO:root:current mean train loss 1882.053622032586
INFO:root:current train perplexity4.4070725440979
INFO:root:current mean train loss 1881.3326341857364
INFO:root:current train perplexity4.404111862182617
INFO:root:current mean train loss 1880.291947517588
INFO:root:current train perplexity4.403534889221191
INFO:root:current mean train loss 1880.0113672862476
INFO:root:current train perplexity4.4041972160339355
INFO:root:current mean train loss 1880.0825338416655
INFO:root:current train perplexity4.403221607208252

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.89s/it]
INFO:root:final mean train loss: 1879.5477362020533
INFO:root:final train perplexity: 4.403168201446533
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.81s/it]
INFO:root:eval mean loss: 2847.6119806329766
INFO:root:eval perplexity: 10.346757888793945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/41
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [5:38:06<8:00:26, 488.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1859.1089515686035
INFO:root:current train perplexity4.344616889953613
INFO:root:current mean train loss 1859.7268714126276
INFO:root:current train perplexity4.346776962280273
INFO:root:current mean train loss 1865.7221432247677
INFO:root:current train perplexity4.363668441772461
INFO:root:current mean train loss 1867.649035521228
INFO:root:current train perplexity4.3662109375
INFO:root:current mean train loss 1866.5782689740581
INFO:root:current train perplexity4.370855808258057
INFO:root:current mean train loss 1869.2657882383205
INFO:root:current train perplexity4.36532735824585
INFO:root:current mean train loss 1865.90496054463
INFO:root:current train perplexity4.360871315002441
INFO:root:current mean train loss 1867.392150572197
INFO:root:current train perplexity4.3655595779418945
INFO:root:current mean train loss 1868.6689044407435
INFO:root:current train perplexity4.367649078369141
INFO:root:current mean train loss 1868.7527073626538
INFO:root:current train perplexity4.369831562042236
INFO:root:current mean train loss 1868.8939936282861
INFO:root:current train perplexity4.36542272567749
INFO:root:current mean train loss 1869.8884370223336
INFO:root:current train perplexity4.367112636566162
INFO:root:current mean train loss 1871.6197936446579
INFO:root:current train perplexity4.370262622833252
INFO:root:current mean train loss 1871.6658114457882
INFO:root:current train perplexity4.37311315536499
INFO:root:current mean train loss 1872.5185692935067
INFO:root:current train perplexity4.376465797424316
INFO:root:current mean train loss 1874.909573739035
INFO:root:current train perplexity4.3803253173828125
INFO:root:current mean train loss 1875.0733466238346
INFO:root:current train perplexity4.381890773773193
INFO:root:current mean train loss 1875.0041619451647
INFO:root:current train perplexity4.383107662200928
INFO:root:current mean train loss 1875.3717379026775
INFO:root:current train perplexity4.384605884552002

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:12<00:00, 432.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:12<00:00, 432.46s/it]
INFO:root:final mean train loss: 1874.5580593922855
INFO:root:final train perplexity: 4.3858747482299805
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.83s/it]
INFO:root:eval mean loss: 2845.6201648425767
INFO:root:eval perplexity: 10.329864501953125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/42
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [5:46:11<7:51:16, 487.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1877.6212252103364
INFO:root:current train perplexity4.444751262664795
INFO:root:current mean train loss 1853.063550020741
INFO:root:current train perplexity4.370968818664551
INFO:root:current mean train loss 1852.1050417904562
INFO:root:current train perplexity4.356210708618164
INFO:root:current mean train loss 1856.8031243759983
INFO:root:current train perplexity4.343166828155518
INFO:root:current mean train loss 1855.930304945237
INFO:root:current train perplexity4.3421854972839355
INFO:root:current mean train loss 1859.4698298344604
INFO:root:current train perplexity4.3411736488342285
INFO:root:current mean train loss 1860.9666146656427
INFO:root:current train perplexity4.3494062423706055
INFO:root:current mean train loss 1864.4099386463995
INFO:root:current train perplexity4.350636959075928
INFO:root:current mean train loss 1864.242029244023
INFO:root:current train perplexity4.354954719543457
INFO:root:current mean train loss 1866.2790711853095
INFO:root:current train perplexity4.354909896850586
INFO:root:current mean train loss 1867.6510407428045
INFO:root:current train perplexity4.357008457183838
INFO:root:current mean train loss 1867.836293072285
INFO:root:current train perplexity4.359776020050049
INFO:root:current mean train loss 1868.090998637804
INFO:root:current train perplexity4.362420558929443
INFO:root:current mean train loss 1868.0020830048375
INFO:root:current train perplexity4.361586093902588
INFO:root:current mean train loss 1869.8276873438053
INFO:root:current train perplexity4.365323543548584
INFO:root:current mean train loss 1869.5879918796213
INFO:root:current train perplexity4.365824222564697
INFO:root:current mean train loss 1868.1149550436153
INFO:root:current train perplexity4.361238479614258
INFO:root:current mean train loss 1868.5891010665225
INFO:root:current train perplexity4.363300800323486
INFO:root:current mean train loss 1868.1077456676821
INFO:root:current train perplexity4.362554550170898
INFO:root:current mean train loss 1869.1983710855823
INFO:root:current train perplexity4.3654069900512695

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.07s/it]
INFO:root:final mean train loss: 1869.2443555869422
INFO:root:final train perplexity: 4.367534160614014
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.00s/it]
INFO:root:eval mean loss: 2848.549540018534
INFO:root:eval perplexity: 10.354723930358887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/43
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [5:54:32<7:46:56, 491.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1880.9308675130208
INFO:root:current train perplexity4.399090766906738
INFO:root:current mean train loss 1868.0799081655648
INFO:root:current train perplexity4.348707675933838
INFO:root:current mean train loss 1874.4560217815897
INFO:root:current train perplexity4.359689712524414
INFO:root:current mean train loss 1870.5285344904119
INFO:root:current train perplexity4.342010498046875
INFO:root:current mean train loss 1865.9849617891534
INFO:root:current train perplexity4.3402419090271
INFO:root:current mean train loss 1865.826560427108
INFO:root:current train perplexity4.334270477294922
INFO:root:current mean train loss 1862.6806160094245
INFO:root:current train perplexity4.331387519836426
INFO:root:current mean train loss 1863.8754943011559
INFO:root:current train perplexity4.335794448852539
INFO:root:current mean train loss 1865.315096714985
INFO:root:current train perplexity4.335543155670166
INFO:root:current mean train loss 1865.4295667422716
INFO:root:current train perplexity4.337531566619873
INFO:root:current mean train loss 1864.609478937538
INFO:root:current train perplexity4.339260578155518
INFO:root:current mean train loss 1864.5720400649889
INFO:root:current train perplexity4.339658260345459
INFO:root:current mean train loss 1864.9949944224784
INFO:root:current train perplexity4.342654705047607
INFO:root:current mean train loss 1864.5669391373942
INFO:root:current train perplexity4.341709613800049
INFO:root:current mean train loss 1864.7925933197662
INFO:root:current train perplexity4.344257831573486
INFO:root:current mean train loss 1863.5248047672844
INFO:root:current train perplexity4.343558311462402
INFO:root:current mean train loss 1863.7077776013707
INFO:root:current train perplexity4.3473219871521
INFO:root:current mean train loss 1864.6974156374188
INFO:root:current train perplexity4.348137378692627
INFO:root:current mean train loss 1864.5547914265283
INFO:root:current train perplexity4.349438190460205
INFO:root:current mean train loss 1863.7235923332255
INFO:root:current train perplexity4.346944332122803

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:19<00:00, 439.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:19<00:00, 439.55s/it]
INFO:root:final mean train loss: 1863.586662750321
INFO:root:final train perplexity: 4.348089218139648
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.36s/it]
INFO:root:eval mean loss: 2849.465916355809
INFO:root:eval perplexity: 10.36251163482666
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/44
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [6:02:47<7:39:53, 492.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1848.4634308510638
INFO:root:current train perplexity4.314572334289551
INFO:root:current mean train loss 1832.9161252391582
INFO:root:current train perplexity4.280824661254883
INFO:root:current mean train loss 1845.0920899425923
INFO:root:current train perplexity4.283683776855469
INFO:root:current mean train loss 1853.215930070245
INFO:root:current train perplexity4.312394618988037
INFO:root:current mean train loss 1854.4286677896043
INFO:root:current train perplexity4.315051078796387
INFO:root:current mean train loss 1855.181557608261
INFO:root:current train perplexity4.318436622619629
INFO:root:current mean train loss 1854.4914347016277
INFO:root:current train perplexity4.318218231201172
INFO:root:current mean train loss 1854.6375271594188
INFO:root:current train perplexity4.3100175857543945
INFO:root:current mean train loss 1857.5335807214801
INFO:root:current train perplexity4.31782865524292
INFO:root:current mean train loss 1857.7361428926463
INFO:root:current train perplexity4.315866470336914
INFO:root:current mean train loss 1857.2429448722542
INFO:root:current train perplexity4.320195198059082
INFO:root:current mean train loss 1858.8656896642738
INFO:root:current train perplexity4.322828769683838
INFO:root:current mean train loss 1857.0647559024471
INFO:root:current train perplexity4.321259021759033
INFO:root:current mean train loss 1856.1294758208344
INFO:root:current train perplexity4.321048736572266
INFO:root:current mean train loss 1856.9678635350078
INFO:root:current train perplexity4.322192668914795
INFO:root:current mean train loss 1858.372878012383
INFO:root:current train perplexity4.328829765319824
INFO:root:current mean train loss 1857.7702483297046
INFO:root:current train perplexity4.328347682952881
INFO:root:current mean train loss 1857.7167890490841
INFO:root:current train perplexity4.327303886413574
INFO:root:current mean train loss 1858.1860986037325
INFO:root:current train perplexity4.328907489776611
INFO:root:current mean train loss 1859.5702798977593
INFO:root:current train perplexity4.3323493003845215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.83s/it]
INFO:root:final mean train loss: 1858.9283068373657
INFO:root:final train perplexity: 4.332144737243652
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:55<00:00, 55.03s/it]
INFO:root:eval mean loss: 2848.6183803432336
INFO:root:eval perplexity: 10.35530948638916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/45
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [6:11:05<7:33:01, 494.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1844.1694202423096
INFO:root:current train perplexity4.280116558074951
INFO:root:current mean train loss 1852.7909709651296
INFO:root:current train perplexity4.29381799697876
INFO:root:current mean train loss 1853.2317777691464
INFO:root:current train perplexity4.304851531982422
INFO:root:current mean train loss 1855.4817639026014
INFO:root:current train perplexity4.326096057891846
INFO:root:current mean train loss 1854.675647867137
INFO:root:current train perplexity4.317988872528076
INFO:root:current mean train loss 1853.3534277516899
INFO:root:current train perplexity4.314390659332275
INFO:root:current mean train loss 1850.9368560055652
INFO:root:current train perplexity4.30947208404541
INFO:root:current mean train loss 1850.7212631465252
INFO:root:current train perplexity4.311633110046387
INFO:root:current mean train loss 1852.9212595621746
INFO:root:current train perplexity4.3148698806762695
INFO:root:current mean train loss 1853.9262157139442
INFO:root:current train perplexity4.3164777755737305
INFO:root:current mean train loss 1852.4004241254993
INFO:root:current train perplexity4.315309047698975
INFO:root:current mean train loss 1853.6125982225556
INFO:root:current train perplexity4.314541339874268
INFO:root:current mean train loss 1854.8404445406757
INFO:root:current train perplexity4.315810203552246
INFO:root:current mean train loss 1855.886303764634
INFO:root:current train perplexity4.315624237060547
INFO:root:current mean train loss 1856.603435495512
INFO:root:current train perplexity4.3150529861450195
INFO:root:current mean train loss 1856.1578251285016
INFO:root:current train perplexity4.314272880554199
INFO:root:current mean train loss 1854.9902476530808
INFO:root:current train perplexity4.315510272979736
INFO:root:current mean train loss 1854.9338132551197
INFO:root:current train perplexity4.3149824142456055
INFO:root:current mean train loss 1854.5518807996496
INFO:root:current train perplexity4.315608024597168
INFO:root:current mean train loss 1854.7677809954175
INFO:root:current train perplexity4.315728664398193

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.86s/it]
INFO:root:final mean train loss: 1854.0566014122976
INFO:root:final train perplexity: 4.315531253814697
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.98s/it]
INFO:root:eval mean loss: 2851.401830541479
INFO:root:eval perplexity: 10.378986358642578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/46
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [6:19:14<7:23:32, 492.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1857.8633038556134
INFO:root:current train perplexity4.307316780090332
INFO:root:current mean train loss 1855.4885044835548
INFO:root:current train perplexity4.289411544799805
INFO:root:current mean train loss 1854.1236216046207
INFO:root:current train perplexity4.285591125488281
INFO:root:current mean train loss 1853.3949669865485
INFO:root:current train perplexity4.282659530639648
INFO:root:current mean train loss 1849.009059596706
INFO:root:current train perplexity4.282039165496826
INFO:root:current mean train loss 1850.003848261349
INFO:root:current train perplexity4.286139011383057
INFO:root:current mean train loss 1851.0714629365134
INFO:root:current train perplexity4.2948737144470215
INFO:root:current mean train loss 1852.7334745556077
INFO:root:current train perplexity4.296718120574951
INFO:root:current mean train loss 1855.3021231920845
INFO:root:current train perplexity4.298809051513672
INFO:root:current mean train loss 1852.485372965246
INFO:root:current train perplexity4.296865463256836
INFO:root:current mean train loss 1852.2838900387012
INFO:root:current train perplexity4.296930313110352
INFO:root:current mean train loss 1852.3499479883308
INFO:root:current train perplexity4.2972002029418945
INFO:root:current mean train loss 1852.761938209742
INFO:root:current train perplexity4.301082611083984
INFO:root:current mean train loss 1852.2284194537474
INFO:root:current train perplexity4.301078796386719
INFO:root:current mean train loss 1851.620931786351
INFO:root:current train perplexity4.3015899658203125
INFO:root:current mean train loss 1850.4736755872964
INFO:root:current train perplexity4.299736022949219
INFO:root:current mean train loss 1850.9257871320317
INFO:root:current train perplexity4.2992753982543945
INFO:root:current mean train loss 1850.6924212636204
INFO:root:current train perplexity4.299821853637695
INFO:root:current mean train loss 1849.517867109105
INFO:root:current train perplexity4.298796653747559
INFO:root:current mean train loss 1850.1405394706746
INFO:root:current train perplexity4.300300121307373

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.73s/it]
INFO:root:final mean train loss: 1849.5436323803601
INFO:root:final train perplexity: 4.300199031829834
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.14s/it]
INFO:root:eval mean loss: 2854.0871457394896
INFO:root:eval perplexity: 10.401883125305176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/47
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [6:27:38<7:18:15, 496.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1844.7848847058356
INFO:root:current train perplexity4.248548984527588
INFO:root:current mean train loss 1840.704121907552
INFO:root:current train perplexity4.245185375213623
INFO:root:current mean train loss 1839.7098134700084
INFO:root:current train perplexity4.265045642852783
INFO:root:current mean train loss 1837.5316070096576
INFO:root:current train perplexity4.26449728012085
INFO:root:current mean train loss 1838.930363789141
INFO:root:current train perplexity4.263960838317871
INFO:root:current mean train loss 1838.8450919569136
INFO:root:current train perplexity4.263579845428467
INFO:root:current mean train loss 1842.5753457143178
INFO:root:current train perplexity4.273021221160889
INFO:root:current mean train loss 1842.8174426238936
INFO:root:current train perplexity4.276592254638672
INFO:root:current mean train loss 1843.7337476564676
INFO:root:current train perplexity4.279825210571289
INFO:root:current mean train loss 1842.3787770854208
INFO:root:current train perplexity4.277360439300537
INFO:root:current mean train loss 1844.3450615332208
INFO:root:current train perplexity4.27708101272583
INFO:root:current mean train loss 1844.7966615297958
INFO:root:current train perplexity4.279196739196777
INFO:root:current mean train loss 1842.986103827854
INFO:root:current train perplexity4.276821613311768
INFO:root:current mean train loss 1843.7043512041478
INFO:root:current train perplexity4.280036926269531
INFO:root:current mean train loss 1843.5643865486013
INFO:root:current train perplexity4.281125545501709
INFO:root:current mean train loss 1844.1768943968045
INFO:root:current train perplexity4.28422212600708
INFO:root:current mean train loss 1844.5086963954607
INFO:root:current train perplexity4.284768581390381
INFO:root:current mean train loss 1844.547984359792
INFO:root:current train perplexity4.283960342407227
INFO:root:current mean train loss 1844.5674300841963
INFO:root:current train perplexity4.283090114593506

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:19<00:00, 439.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:19<00:00, 439.09s/it]
INFO:root:final mean train loss: 1844.5872249632127
INFO:root:final train perplexity: 4.283422946929932
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.56s/it]
INFO:root:eval mean loss: 2854.1674621398743
INFO:root:eval perplexity: 10.402567863464355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/48
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [6:35:52<7:09:16, 495.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1777.1837239583333
INFO:root:current train perplexity4.041616439819336
INFO:root:current mean train loss 1837.036908755095
INFO:root:current train perplexity4.252793312072754
INFO:root:current mean train loss 1840.0353697311045
INFO:root:current train perplexity4.240238189697266
INFO:root:current mean train loss 1838.691632564484
INFO:root:current train perplexity4.23807954788208
INFO:root:current mean train loss 1841.108606104104
INFO:root:current train perplexity4.245232105255127
INFO:root:current mean train loss 1837.5135659227094
INFO:root:current train perplexity4.238676071166992
INFO:root:current mean train loss 1834.1362880303607
INFO:root:current train perplexity4.237668037414551
INFO:root:current mean train loss 1835.8317331594187
INFO:root:current train perplexity4.245900630950928
INFO:root:current mean train loss 1835.1791568311446
INFO:root:current train perplexity4.2490763664245605
INFO:root:current mean train loss 1834.1619423454576
INFO:root:current train perplexity4.250349998474121
INFO:root:current mean train loss 1836.2639658058806
INFO:root:current train perplexity4.254511833190918
INFO:root:current mean train loss 1837.5378130036086
INFO:root:current train perplexity4.252842426300049
INFO:root:current mean train loss 1838.6113753456148
INFO:root:current train perplexity4.253077983856201
INFO:root:current mean train loss 1838.8146591128504
INFO:root:current train perplexity4.2546706199646
INFO:root:current mean train loss 1838.4248392812776
INFO:root:current train perplexity4.25730037689209
INFO:root:current mean train loss 1837.9042620668317
INFO:root:current train perplexity4.259599685668945
INFO:root:current mean train loss 1838.879931187113
INFO:root:current train perplexity4.261273384094238
INFO:root:current mean train loss 1838.4850219370671
INFO:root:current train perplexity4.261991500854492
INFO:root:current mean train loss 1839.4416025713456
INFO:root:current train perplexity4.263649940490723
INFO:root:current mean train loss 1839.5758235124633
INFO:root:current train perplexity4.266284465789795

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.70s/it]
INFO:root:final mean train loss: 1840.1430736701416
INFO:root:final train perplexity: 4.268436431884766
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.40s/it]
INFO:root:eval mean loss: 2854.7912465688346
INFO:root:eval perplexity: 10.407894134521484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/49
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [6:44:13<7:02:24, 496.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1858.5160064697266
INFO:root:current train perplexity4.300349712371826
INFO:root:current mean train loss 1833.9195926550663
INFO:root:current train perplexity4.208133697509766
INFO:root:current mean train loss 1829.6727668499125
INFO:root:current train perplexity4.205475330352783
INFO:root:current mean train loss 1831.5809348232774
INFO:root:current train perplexity4.21819543838501
INFO:root:current mean train loss 1832.8233947753906
INFO:root:current train perplexity4.225067615509033
INFO:root:current mean train loss 1830.438421034275
INFO:root:current train perplexity4.2304768562316895
INFO:root:current mean train loss 1831.0362094927439
INFO:root:current train perplexity4.235494136810303
INFO:root:current mean train loss 1832.0682378049758
INFO:root:current train perplexity4.238295078277588
INFO:root:current mean train loss 1831.9719949869009
INFO:root:current train perplexity4.239768028259277
INFO:root:current mean train loss 1832.3371702529842
INFO:root:current train perplexity4.24187707901001
INFO:root:current mean train loss 1831.6479151526162
INFO:root:current train perplexity4.240811347961426
INFO:root:current mean train loss 1833.622069988992
INFO:root:current train perplexity4.243504047393799
INFO:root:current mean train loss 1834.2271019081018
INFO:root:current train perplexity4.244449138641357
INFO:root:current mean train loss 1833.609015204169
INFO:root:current train perplexity4.244100093841553
INFO:root:current mean train loss 1833.0255673371214
INFO:root:current train perplexity4.243772029876709
INFO:root:current mean train loss 1833.2276754752775
INFO:root:current train perplexity4.243858814239502
INFO:root:current mean train loss 1834.237065034754
INFO:root:current train perplexity4.24563455581665
INFO:root:current mean train loss 1833.5798295441732
INFO:root:current train perplexity4.245976448059082
INFO:root:current mean train loss 1835.0190510312543
INFO:root:current train perplexity4.248877048492432
INFO:root:current mean train loss 1835.1522063893067
INFO:root:current train perplexity4.251246929168701

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.50s/it]
INFO:root:final mean train loss: 1835.6132059948527
INFO:root:final train perplexity: 4.253214359283447
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.44s/it]
INFO:root:eval mean loss: 2855.54845788171
INFO:root:eval perplexity: 10.414362907409668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/50
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [6:52:21<6:52:02, 494.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1808.9007393973213
INFO:root:current train perplexity4.193833827972412
INFO:root:current mean train loss 1820.2462125432571
INFO:root:current train perplexity4.176054954528809
INFO:root:current mean train loss 1820.9711438527547
INFO:root:current train perplexity4.196413040161133
INFO:root:current mean train loss 1823.1683265664174
INFO:root:current train perplexity4.207568645477295
INFO:root:current mean train loss 1828.0013019927094
INFO:root:current train perplexity4.209990501403809
INFO:root:current mean train loss 1828.4575646683602
INFO:root:current train perplexity4.213417053222656
INFO:root:current mean train loss 1826.789774984351
INFO:root:current train perplexity4.215970516204834
INFO:root:current mean train loss 1828.7785119742991
INFO:root:current train perplexity4.220796585083008
INFO:root:current mean train loss 1828.2324328023778
INFO:root:current train perplexity4.219581604003906
INFO:root:current mean train loss 1830.6626557972209
INFO:root:current train perplexity4.227052688598633
INFO:root:current mean train loss 1831.5380378774055
INFO:root:current train perplexity4.23279333114624
INFO:root:current mean train loss 1831.1380615234375
INFO:root:current train perplexity4.23541784286499
INFO:root:current mean train loss 1831.1478736700299
INFO:root:current train perplexity4.23799467086792
INFO:root:current mean train loss 1829.656867409742
INFO:root:current train perplexity4.235836029052734
INFO:root:current mean train loss 1829.2729367505608
INFO:root:current train perplexity4.235427379608154
INFO:root:current mean train loss 1829.0185273418588
INFO:root:current train perplexity4.234870910644531
INFO:root:current mean train loss 1829.2651000754481
INFO:root:current train perplexity4.235367298126221
INFO:root:current mean train loss 1829.497623013932
INFO:root:current train perplexity4.236138343811035
INFO:root:current mean train loss 1830.0971927921344
INFO:root:current train perplexity4.236203670501709
INFO:root:current mean train loss 1831.7588750566197
INFO:root:current train perplexity4.238734245300293

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:12<00:00, 432.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:12<00:00, 432.56s/it]
INFO:root:final mean train loss: 1831.070202433576
INFO:root:final train perplexity: 4.238002777099609
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.10s/it]
INFO:root:eval mean loss: 2854.4103432045326
INFO:root:eval perplexity: 10.404641151428223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/51
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [7:00:28<6:41:49, 492.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1826.7666718454072
INFO:root:current train perplexity4.191096782684326
INFO:root:current mean train loss 1819.8919383589043
INFO:root:current train perplexity4.204004287719727
INFO:root:current mean train loss 1823.463931893944
INFO:root:current train perplexity4.193947792053223
INFO:root:current mean train loss 1823.5993295471526
INFO:root:current train perplexity4.210708141326904
INFO:root:current mean train loss 1823.3742261894783
INFO:root:current train perplexity4.207613468170166
INFO:root:current mean train loss 1829.2687966714057
INFO:root:current train perplexity4.211516380310059
INFO:root:current mean train loss 1829.6627686646607
INFO:root:current train perplexity4.2120842933654785
INFO:root:current mean train loss 1826.5271284536655
INFO:root:current train perplexity4.209229946136475
INFO:root:current mean train loss 1828.4350364632198
INFO:root:current train perplexity4.21434211730957
INFO:root:current mean train loss 1826.90763902368
INFO:root:current train perplexity4.212169170379639
INFO:root:current mean train loss 1826.5722483336142
INFO:root:current train perplexity4.217160701751709
INFO:root:current mean train loss 1825.430933957239
INFO:root:current train perplexity4.214849948883057
INFO:root:current mean train loss 1826.1266619304156
INFO:root:current train perplexity4.215957164764404
INFO:root:current mean train loss 1825.551668895984
INFO:root:current train perplexity4.218512535095215
INFO:root:current mean train loss 1825.1541205142075
INFO:root:current train perplexity4.219313621520996
INFO:root:current mean train loss 1826.5202273469927
INFO:root:current train perplexity4.222378730773926
INFO:root:current mean train loss 1826.1293047736672
INFO:root:current train perplexity4.2213640213012695
INFO:root:current mean train loss 1827.0139299783675
INFO:root:current train perplexity4.22205114364624
INFO:root:current mean train loss 1826.722362784072
INFO:root:current train perplexity4.22213077545166
INFO:root:current mean train loss 1827.039754190377
INFO:root:current train perplexity4.222938060760498

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.39s/it]
INFO:root:final mean train loss: 1826.8132756358737
INFO:root:final train perplexity: 4.2237982749938965
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.31s/it]
INFO:root:eval mean loss: 2859.611617721237
INFO:root:eval perplexity: 10.449142456054688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/52
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [7:08:37<6:32:59, 491.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1817.6026655449925
INFO:root:current train perplexity4.203640937805176
INFO:root:current mean train loss 1816.4214914457393
INFO:root:current train perplexity4.199624061584473
INFO:root:current mean train loss 1811.6806386132123
INFO:root:current train perplexity4.18388032913208
INFO:root:current mean train loss 1814.0297083443822
INFO:root:current train perplexity4.1934027671813965
INFO:root:current mean train loss 1813.6270003861769
INFO:root:current train perplexity4.190441131591797
INFO:root:current mean train loss 1813.689702081435
INFO:root:current train perplexity4.196122169494629
INFO:root:current mean train loss 1816.4437311264642
INFO:root:current train perplexity4.19855260848999
INFO:root:current mean train loss 1816.2064336823016
INFO:root:current train perplexity4.193926811218262
INFO:root:current mean train loss 1818.0575183423432
INFO:root:current train perplexity4.195497512817383
INFO:root:current mean train loss 1818.4417638924212
INFO:root:current train perplexity4.197919845581055
INFO:root:current mean train loss 1818.097469030435
INFO:root:current train perplexity4.196801662445068
INFO:root:current mean train loss 1819.039022566601
INFO:root:current train perplexity4.202517032623291
INFO:root:current mean train loss 1818.1016429921935
INFO:root:current train perplexity4.20384407043457
INFO:root:current mean train loss 1819.3454994979495
INFO:root:current train perplexity4.206256866455078
INFO:root:current mean train loss 1821.0152895741583
INFO:root:current train perplexity4.207653999328613
INFO:root:current mean train loss 1822.2358861888276
INFO:root:current train perplexity4.2085747718811035
INFO:root:current mean train loss 1822.4135112615122
INFO:root:current train perplexity4.20773983001709
INFO:root:current mean train loss 1823.2604495747598
INFO:root:current train perplexity4.209702968597412
INFO:root:current mean train loss 1823.47957912127
INFO:root:current train perplexity4.210954666137695
INFO:root:current mean train loss 1823.0088422797392
INFO:root:current train perplexity4.21114444732666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.49s/it]
INFO:root:final mean train loss: 1823.0088422797392
INFO:root:final train perplexity: 4.21114444732666
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.86s/it]
INFO:root:eval mean loss: 2863.203985724005
INFO:root:eval perplexity: 10.479990005493164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/53
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [7:16:44<6:23:48, 489.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1813.4444641113282
INFO:root:current train perplexity4.252427577972412
INFO:root:current mean train loss 1827.4587127685547
INFO:root:current train perplexity4.227166175842285
INFO:root:current mean train loss 1815.6942240397136
INFO:root:current train perplexity4.205937385559082
INFO:root:current mean train loss 1815.559039001465
INFO:root:current train perplexity4.199528217315674
INFO:root:current mean train loss 1814.5852939453125
INFO:root:current train perplexity4.194901466369629
INFO:root:current mean train loss 1819.7428991699219
INFO:root:current train perplexity4.202555179595947
INFO:root:current mean train loss 1817.6197040666852
INFO:root:current train perplexity4.19459342956543
INFO:root:current mean train loss 1817.500493927002
INFO:root:current train perplexity4.197301864624023
INFO:root:current mean train loss 1818.3902559407552
INFO:root:current train perplexity4.1981072425842285
INFO:root:current mean train loss 1818.2259458007813
INFO:root:current train perplexity4.198847770690918
INFO:root:current mean train loss 1820.8440524014559
INFO:root:current train perplexity4.202453136444092
INFO:root:current mean train loss 1821.270127360026
INFO:root:current train perplexity4.20296573638916
INFO:root:current mean train loss 1821.7496362304687
INFO:root:current train perplexity4.202007293701172
INFO:root:current mean train loss 1819.4831427873885
INFO:root:current train perplexity4.199249267578125
INFO:root:current mean train loss 1819.4198745117187
INFO:root:current train perplexity4.1992411613464355
INFO:root:current mean train loss 1819.9131233215332
INFO:root:current train perplexity4.200199127197266
INFO:root:current mean train loss 1820.4931536506203
INFO:root:current train perplexity4.199714183807373
INFO:root:current mean train loss 1821.833202311198
INFO:root:current train perplexity4.202091693878174
INFO:root:current mean train loss 1820.4305315198396
INFO:root:current train perplexity4.200462818145752

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.38s/it]
INFO:root:final mean train loss: 1819.401315693896
INFO:root:final train perplexity: 4.199179649353027
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.98s/it]
INFO:root:eval mean loss: 2863.9155097480293
INFO:root:eval perplexity: 10.486113548278809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/54
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [7:24:48<6:14:16, 488.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1813.2451674517463
INFO:root:current train perplexity4.235913276672363
INFO:root:current mean train loss 1807.4830322265625
INFO:root:current train perplexity4.181853294372559
INFO:root:current mean train loss 1810.9252130886377
INFO:root:current train perplexity4.169411659240723
INFO:root:current mean train loss 1808.4324439015675
INFO:root:current train perplexity4.170376300811768
INFO:root:current mean train loss 1815.3014217532225
INFO:root:current train perplexity4.186699867248535
INFO:root:current mean train loss 1814.059301616145
INFO:root:current train perplexity4.181290626525879
INFO:root:current mean train loss 1812.4008824674584
INFO:root:current train perplexity4.177614212036133
INFO:root:current mean train loss 1812.5803944522534
INFO:root:current train perplexity4.183553695678711
INFO:root:current mean train loss 1812.9295957604995
INFO:root:current train perplexity4.184366226196289
INFO:root:current mean train loss 1813.729633959455
INFO:root:current train perplexity4.186402320861816
INFO:root:current mean train loss 1813.8353314695105
INFO:root:current train perplexity4.1869378089904785
INFO:root:current mean train loss 1814.281089680261
INFO:root:current train perplexity4.189544677734375
INFO:root:current mean train loss 1814.5566698135465
INFO:root:current train perplexity4.191146373748779
INFO:root:current mean train loss 1813.5452557377682
INFO:root:current train perplexity4.190495491027832
INFO:root:current mean train loss 1814.336723849903
INFO:root:current train perplexity4.190400123596191
INFO:root:current mean train loss 1814.1631189294762
INFO:root:current train perplexity4.187524318695068
INFO:root:current mean train loss 1814.687316554818
INFO:root:current train perplexity4.1889142990112305
INFO:root:current mean train loss 1814.7103410119848
INFO:root:current train perplexity4.188366889953613
INFO:root:current mean train loss 1815.045201151989
INFO:root:current train perplexity4.187407493591309
INFO:root:current mean train loss 1815.4854724229347
INFO:root:current train perplexity4.185969829559326

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.70s/it]
INFO:root:final mean train loss: 1815.5821043198239
INFO:root:final train perplexity: 4.186551570892334
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.99s/it]
INFO:root:eval mean loss: 2862.182057790212
INFO:root:eval perplexity: 10.471206665039062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/55
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [7:33:18<6:11:07, 494.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1786.279821059283
INFO:root:current train perplexity4.12413215637207
INFO:root:current mean train loss 1800.2700796554338
INFO:root:current train perplexity4.136693000793457
INFO:root:current mean train loss 1809.8908362755408
INFO:root:current train perplexity4.147663593292236
INFO:root:current mean train loss 1813.2834348393058
INFO:root:current train perplexity4.158697605133057
INFO:root:current mean train loss 1813.2869822418634
INFO:root:current train perplexity4.162845611572266
INFO:root:current mean train loss 1812.2757794669506
INFO:root:current train perplexity4.160262584686279
INFO:root:current mean train loss 1809.8780032377513
INFO:root:current train perplexity4.154718399047852
INFO:root:current mean train loss 1809.8112014645776
INFO:root:current train perplexity4.155688762664795
INFO:root:current mean train loss 1809.1557978714684
INFO:root:current train perplexity4.156846523284912
INFO:root:current mean train loss 1807.099828944727
INFO:root:current train perplexity4.157172679901123
INFO:root:current mean train loss 1806.8220903112533
INFO:root:current train perplexity4.161818981170654
INFO:root:current mean train loss 1806.8061509443548
INFO:root:current train perplexity4.160617828369141
INFO:root:current mean train loss 1807.73925177823
INFO:root:current train perplexity4.16434907913208
INFO:root:current mean train loss 1808.0766384690955
INFO:root:current train perplexity4.16616153717041
INFO:root:current mean train loss 1808.2603089826043
INFO:root:current train perplexity4.168302536010742
INFO:root:current mean train loss 1809.5955763596755
INFO:root:current train perplexity4.169793128967285
INFO:root:current mean train loss 1810.1469356765654
INFO:root:current train perplexity4.170880317687988
INFO:root:current mean train loss 1811.1930003446691
INFO:root:current train perplexity4.173753261566162
INFO:root:current mean train loss 1810.914431506441
INFO:root:current train perplexity4.172182559967041
INFO:root:current mean train loss 1811.9862257475197
INFO:root:current train perplexity4.173093795776367

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.84s/it]
INFO:root:final mean train loss: 1811.5434580777428
INFO:root:final train perplexity: 4.173237323760986
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.54s/it]
INFO:root:eval mean loss: 2866.690261794998
INFO:root:eval perplexity: 10.510014533996582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/56
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [7:41:47<6:05:52, 498.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1806.9718687768077
INFO:root:current train perplexity4.1523308753967285
INFO:root:current mean train loss 1806.7604649019556
INFO:root:current train perplexity4.148604869842529
INFO:root:current mean train loss 1804.837755909954
INFO:root:current train perplexity4.154651165008545
INFO:root:current mean train loss 1803.3617249404604
INFO:root:current train perplexity4.143875598907471
INFO:root:current mean train loss 1803.531197490819
INFO:root:current train perplexity4.1446614265441895
INFO:root:current mean train loss 1805.2057161694647
INFO:root:current train perplexity4.146149158477783
INFO:root:current mean train loss 1806.7479038033434
INFO:root:current train perplexity4.150940418243408
INFO:root:current mean train loss 1804.2911399709242
INFO:root:current train perplexity4.14915132522583
INFO:root:current mean train loss 1804.0559707444368
INFO:root:current train perplexity4.150386333465576
INFO:root:current mean train loss 1803.8365637681964
INFO:root:current train perplexity4.1517839431762695
INFO:root:current mean train loss 1805.1382595537732
INFO:root:current train perplexity4.155436992645264
INFO:root:current mean train loss 1806.4236703138574
INFO:root:current train perplexity4.155833721160889
INFO:root:current mean train loss 1807.900664917285
INFO:root:current train perplexity4.156867027282715
INFO:root:current mean train loss 1808.7281841105837
INFO:root:current train perplexity4.158628463745117
INFO:root:current mean train loss 1808.5321498373967
INFO:root:current train perplexity4.1590256690979
INFO:root:current mean train loss 1808.6728832016138
INFO:root:current train perplexity4.160525321960449
INFO:root:current mean train loss 1808.2635667363056
INFO:root:current train perplexity4.159744739532471
INFO:root:current mean train loss 1808.276413617442
INFO:root:current train perplexity4.160356521606445
INFO:root:current mean train loss 1809.1637364515802
INFO:root:current train perplexity4.162002086639404
INFO:root:current mean train loss 1808.4758484731387
INFO:root:current train perplexity4.161423206329346

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:08<00:00, 428.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:08<00:00, 428.10s/it]
INFO:root:final mean train loss: 1807.8866172709731
INFO:root:final train perplexity: 4.161219596862793
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.37s/it]
INFO:root:eval mean loss: 2869.774995454439
INFO:root:eval perplexity: 10.536651611328125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/57
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [7:49:49<5:53:54, 493.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1788.6737132352941
INFO:root:current train perplexity4.085561752319336
INFO:root:current mean train loss 1783.9031604585193
INFO:root:current train perplexity4.100476264953613
INFO:root:current mean train loss 1794.7012565954408
INFO:root:current train perplexity4.112774848937988
INFO:root:current mean train loss 1792.2514565509298
INFO:root:current train perplexity4.113340377807617
INFO:root:current mean train loss 1795.118908482739
INFO:root:current train perplexity4.117470741271973
INFO:root:current mean train loss 1796.431160940251
INFO:root:current train perplexity4.121968746185303
INFO:root:current mean train loss 1795.691486838335
INFO:root:current train perplexity4.120337009429932
INFO:root:current mean train loss 1796.7532960573833
INFO:root:current train perplexity4.1237287521362305
INFO:root:current mean train loss 1798.676507624613
INFO:root:current train perplexity4.126455307006836
INFO:root:current mean train loss 1801.4043186912852
INFO:root:current train perplexity4.1331281661987305
INFO:root:current mean train loss 1800.183027403185
INFO:root:current train perplexity4.133793830871582
INFO:root:current mean train loss 1800.4276637247165
INFO:root:current train perplexity4.137021541595459
INFO:root:current mean train loss 1801.9937044257997
INFO:root:current train perplexity4.1391520500183105
INFO:root:current mean train loss 1800.4847582543803
INFO:root:current train perplexity4.139565467834473
INFO:root:current mean train loss 1801.2054674527951
INFO:root:current train perplexity4.143436431884766
INFO:root:current mean train loss 1801.8788598508252
INFO:root:current train perplexity4.143928527832031
INFO:root:current mean train loss 1802.308315578982
INFO:root:current train perplexity4.144157409667969
INFO:root:current mean train loss 1802.9991155425887
INFO:root:current train perplexity4.144988536834717
INFO:root:current mean train loss 1803.4712887749681
INFO:root:current train perplexity4.146054744720459
INFO:root:current mean train loss 1804.2752962189961
INFO:root:current train perplexity4.148499011993408

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.06s/it]
INFO:root:final mean train loss: 1803.967640717584
INFO:root:final train perplexity: 4.148378372192383
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.59s/it]
INFO:root:eval mean loss: 2866.305227835257
INFO:root:eval perplexity: 10.506694793701172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/58
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [7:57:57<5:44:28, 492.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1800.144424977022
INFO:root:current train perplexity4.144503593444824
INFO:root:current mean train loss 1795.485946077914
INFO:root:current train perplexity4.118808269500732
INFO:root:current mean train loss 1789.967063288103
INFO:root:current train perplexity4.100860595703125
INFO:root:current mean train loss 1789.3539335176542
INFO:root:current train perplexity4.099486827850342
INFO:root:current mean train loss 1791.6005939916238
INFO:root:current train perplexity4.104079246520996
INFO:root:current mean train loss 1792.2413463625135
INFO:root:current train perplexity4.107704162597656
INFO:root:current mean train loss 1789.3959959155452
INFO:root:current train perplexity4.10747766494751
INFO:root:current mean train loss 1791.5765477271596
INFO:root:current train perplexity4.109155654907227
INFO:root:current mean train loss 1793.0928323347016
INFO:root:current train perplexity4.114587306976318
INFO:root:current mean train loss 1793.6241548025064
INFO:root:current train perplexity4.118592739105225
INFO:root:current mean train loss 1794.291585923999
INFO:root:current train perplexity4.11764669418335
INFO:root:current mean train loss 1795.545472376055
INFO:root:current train perplexity4.120648384094238
INFO:root:current mean train loss 1794.83297864862
INFO:root:current train perplexity4.121933460235596
INFO:root:current mean train loss 1796.233890773071
INFO:root:current train perplexity4.123119354248047
INFO:root:current mean train loss 1796.4266610604745
INFO:root:current train perplexity4.125265121459961
INFO:root:current mean train loss 1797.239257889516
INFO:root:current train perplexity4.130664825439453
INFO:root:current mean train loss 1797.5824662115172
INFO:root:current train perplexity4.132696151733398
INFO:root:current mean train loss 1799.3133064163164
INFO:root:current train perplexity4.134997367858887
INFO:root:current mean train loss 1799.752627004932
INFO:root:current train perplexity4.135528564453125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:15<00:00, 435.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:15<00:00, 435.20s/it]
INFO:root:final mean train loss: 1800.584349878016
INFO:root:final train perplexity: 4.13732385635376
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.73s/it]
INFO:root:eval mean loss: 2869.816357861768
INFO:root:eval perplexity: 10.537008285522461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/59
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [8:06:07<5:35:57, 491.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1841.1544189453125
INFO:root:current train perplexity4.2353949546813965
INFO:root:current mean train loss 1796.9367125268077
INFO:root:current train perplexity4.095385551452637
INFO:root:current mean train loss 1789.5075260577817
INFO:root:current train perplexity4.095846176147461
INFO:root:current mean train loss 1787.4465522008227
INFO:root:current train perplexity4.089332580566406
INFO:root:current mean train loss 1789.844986796972
INFO:root:current train perplexity4.09569787979126
INFO:root:current mean train loss 1793.9723126536821
INFO:root:current train perplexity4.1037774085998535
INFO:root:current mean train loss 1792.4482379292333
INFO:root:current train perplexity4.103832721710205
INFO:root:current mean train loss 1796.4381999045695
INFO:root:current train perplexity4.112155437469482
INFO:root:current mean train loss 1796.6860333297616
INFO:root:current train perplexity4.121514320373535
INFO:root:current mean train loss 1795.4150562497834
INFO:root:current train perplexity4.121730804443359
INFO:root:current mean train loss 1794.793335813724
INFO:root:current train perplexity4.121972560882568
INFO:root:current mean train loss 1795.3938105699156
INFO:root:current train perplexity4.121255397796631
INFO:root:current mean train loss 1794.8755783614224
INFO:root:current train perplexity4.121440410614014
INFO:root:current mean train loss 1795.0614534955237
INFO:root:current train perplexity4.122383117675781
INFO:root:current mean train loss 1795.29740002424
INFO:root:current train perplexity4.12343168258667
INFO:root:current mean train loss 1796.9790367400758
INFO:root:current train perplexity4.12339448928833
INFO:root:current mean train loss 1797.636211876268
INFO:root:current train perplexity4.12384557723999
INFO:root:current mean train loss 1797.48205853293
INFO:root:current train perplexity4.124846935272217
INFO:root:current mean train loss 1797.4831556517065
INFO:root:current train perplexity4.124836444854736
INFO:root:current mean train loss 1797.3034860508676
INFO:root:current train perplexity4.125818729400635

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.27s/it]
INFO:root:final mean train loss: 1797.3792588873098
INFO:root:final train perplexity: 4.1268792152404785
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.21s/it]
INFO:root:eval mean loss: 2870.1156376102667
INFO:root:eval perplexity: 10.539599418640137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/60
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [8:14:14<5:26:39, 489.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1751.1437795538652
INFO:root:current train perplexity4.072856426239014
INFO:root:current mean train loss 1780.7647540949974
INFO:root:current train perplexity4.1024041175842285
INFO:root:current mean train loss 1791.3961989868722
INFO:root:current train perplexity4.102509498596191
INFO:root:current mean train loss 1792.9703816859326
INFO:root:current train perplexity4.110477924346924
INFO:root:current mean train loss 1794.399672769988
INFO:root:current train perplexity4.115184783935547
INFO:root:current mean train loss 1792.3295714979226
INFO:root:current train perplexity4.116934776306152
INFO:root:current mean train loss 1791.6819794243488
INFO:root:current train perplexity4.114413261413574
INFO:root:current mean train loss 1788.7141595450496
INFO:root:current train perplexity4.110621929168701
INFO:root:current mean train loss 1788.5325280866052
INFO:root:current train perplexity4.110196590423584
INFO:root:current mean train loss 1788.1620070962833
INFO:root:current train perplexity4.106551647186279
INFO:root:current mean train loss 1791.042829189731
INFO:root:current train perplexity4.109752655029297
INFO:root:current mean train loss 1790.8818230650274
INFO:root:current train perplexity4.11124324798584
INFO:root:current mean train loss 1791.1064086613644
INFO:root:current train perplexity4.110128879547119
INFO:root:current mean train loss 1790.3559483317736
INFO:root:current train perplexity4.109016418457031
INFO:root:current mean train loss 1791.4054459188083
INFO:root:current train perplexity4.1116509437561035
INFO:root:current mean train loss 1791.534581740017
INFO:root:current train perplexity4.111974716186523
INFO:root:current mean train loss 1791.8086965936727
INFO:root:current train perplexity4.111595630645752
INFO:root:current mean train loss 1793.0788544393542
INFO:root:current train perplexity4.112746238708496
INFO:root:current mean train loss 1793.4258480900392
INFO:root:current train perplexity4.113598823547363
INFO:root:current mean train loss 1794.3524697260536
INFO:root:current train perplexity4.114880561828613

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:10<00:00, 430.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:10<00:00, 430.61s/it]
INFO:root:final mean train loss: 1793.99621360421
INFO:root:final train perplexity: 4.1158833503723145
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.88s/it]
INFO:root:eval mean loss: 2872.6539515589807
INFO:root:eval perplexity: 10.56157112121582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/61
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [8:22:22<5:18:15, 489.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1788.9924180772568
INFO:root:current train perplexity4.041760444641113
INFO:root:current mean train loss 1777.9285224465764
INFO:root:current train perplexity4.049196720123291
INFO:root:current mean train loss 1784.0402190644863
INFO:root:current train perplexity4.0725860595703125
INFO:root:current mean train loss 1787.0597450619653
INFO:root:current train perplexity4.094743251800537
INFO:root:current mean train loss 1788.9131900892346
INFO:root:current train perplexity4.097705364227295
INFO:root:current mean train loss 1789.9856132393452
INFO:root:current train perplexity4.098133563995361
INFO:root:current mean train loss 1788.1434986426395
INFO:root:current train perplexity4.095059394836426
INFO:root:current mean train loss 1789.5786333498747
INFO:root:current train perplexity4.098062515258789
INFO:root:current mean train loss 1791.7993605034203
INFO:root:current train perplexity4.105445861816406
INFO:root:current mean train loss 1792.0110198452942
INFO:root:current train perplexity4.105367183685303
INFO:root:current mean train loss 1790.8313041304068
INFO:root:current train perplexity4.101963520050049
INFO:root:current mean train loss 1790.786512348014
INFO:root:current train perplexity4.100290775299072
INFO:root:current mean train loss 1790.3816997441659
INFO:root:current train perplexity4.098883152008057
INFO:root:current mean train loss 1790.7541388780057
INFO:root:current train perplexity4.099510192871094
INFO:root:current mean train loss 1790.5807926103598
INFO:root:current train perplexity4.101982116699219
INFO:root:current mean train loss 1790.3702968756359
INFO:root:current train perplexity4.102871417999268
INFO:root:current mean train loss 1789.702270060122
INFO:root:current train perplexity4.1019606590271
INFO:root:current mean train loss 1789.7504549509918
INFO:root:current train perplexity4.101510047912598
INFO:root:current mean train loss 1789.9482634633714
INFO:root:current train perplexity4.1015448570251465
INFO:root:current mean train loss 1790.5303462635386
INFO:root:current train perplexity4.103057384490967

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:12<00:00, 432.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:12<00:00, 432.55s/it]
INFO:root:final mean train loss: 1790.1465459641818
INFO:root:final train perplexity: 4.103405952453613
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.57s/it]
INFO:root:eval mean loss: 2874.967913470111
INFO:root:eval perplexity: 10.581646919250488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/62
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [8:30:33<5:10:12, 489.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1790.0731477557488
INFO:root:current train perplexity4.065793991088867
INFO:root:current mean train loss 1777.1705346200981
INFO:root:current train perplexity4.074289798736572
INFO:root:current mean train loss 1778.8734024711277
INFO:root:current train perplexity4.072647571563721
INFO:root:current mean train loss 1783.303018629382
INFO:root:current train perplexity4.084727764129639
INFO:root:current mean train loss 1782.6646631506105
INFO:root:current train perplexity4.083662509918213
INFO:root:current mean train loss 1784.7132435914189
INFO:root:current train perplexity4.087831497192383
INFO:root:current mean train loss 1784.9539161203102
INFO:root:current train perplexity4.086160659790039
INFO:root:current mean train loss 1786.05173722428
INFO:root:current train perplexity4.088925838470459
INFO:root:current mean train loss 1788.2216367553854
INFO:root:current train perplexity4.091379165649414
INFO:root:current mean train loss 1787.8452458416677
INFO:root:current train perplexity4.0888285636901855
INFO:root:current mean train loss 1788.4621163537586
INFO:root:current train perplexity4.089747428894043
INFO:root:current mean train loss 1787.9573645347734
INFO:root:current train perplexity4.090510845184326
INFO:root:current mean train loss 1787.417481345552
INFO:root:current train perplexity4.091899394989014
INFO:root:current mean train loss 1787.558648785396
INFO:root:current train perplexity4.091791152954102
INFO:root:current mean train loss 1788.6776938809253
INFO:root:current train perplexity4.095125198364258
INFO:root:current mean train loss 1789.3381870365572
INFO:root:current train perplexity4.0976033210754395
INFO:root:current mean train loss 1789.146974354748
INFO:root:current train perplexity4.0984039306640625
INFO:root:current mean train loss 1788.8502146432008
INFO:root:current train perplexity4.097538471221924
INFO:root:current mean train loss 1788.6880128534176
INFO:root:current train perplexity4.097774505615234
INFO:root:current mean train loss 1788.8045721801195
INFO:root:current train perplexity4.0971856117248535

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:06<00:00, 426.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:06<00:00, 426.76s/it]
INFO:root:final mean train loss: 1788.0946306545086
INFO:root:final train perplexity: 4.096770763397217
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.49s/it]
INFO:root:eval mean loss: 2876.5774321684967
INFO:root:eval perplexity: 10.595630645751953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/63
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [8:38:34<5:00:35, 487.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1789.0272739955358
INFO:root:current train perplexity4.099467754364014
INFO:root:current mean train loss 1786.2227596507353
INFO:root:current train perplexity4.092451572418213
INFO:root:current mean train loss 1785.829881004051
INFO:root:current train perplexity4.083560943603516
INFO:root:current mean train loss 1780.7905227248732
INFO:root:current train perplexity4.0690388679504395
INFO:root:current mean train loss 1782.63363842254
INFO:root:current train perplexity4.080082893371582
INFO:root:current mean train loss 1781.5011502449972
INFO:root:current train perplexity4.083899974822998
INFO:root:current mean train loss 1782.6670078562267
INFO:root:current train perplexity4.078212738037109
INFO:root:current mean train loss 1783.8580815302862
INFO:root:current train perplexity4.080338954925537
INFO:root:current mean train loss 1785.9473749270385
INFO:root:current train perplexity4.08351993560791
INFO:root:current mean train loss 1787.2668650833602
INFO:root:current train perplexity4.084562301635742
INFO:root:current mean train loss 1787.0871558073525
INFO:root:current train perplexity4.083639144897461
INFO:root:current mean train loss 1786.6072002704327
INFO:root:current train perplexity4.08026647567749
INFO:root:current mean train loss 1786.651250403697
INFO:root:current train perplexity4.079080104827881
INFO:root:current mean train loss 1786.0616096886406
INFO:root:current train perplexity4.0796051025390625
INFO:root:current mean train loss 1785.6026867094495
INFO:root:current train perplexity4.080221652984619
INFO:root:current mean train loss 1785.0066578858978
INFO:root:current train perplexity4.07986307144165
INFO:root:current mean train loss 1785.2706623374345
INFO:root:current train perplexity4.081948757171631
INFO:root:current mean train loss 1785.3399558202022
INFO:root:current train perplexity4.081587791442871
INFO:root:current mean train loss 1784.9553216781208
INFO:root:current train perplexity4.082414150238037
INFO:root:current mean train loss 1784.9217555322018
INFO:root:current train perplexity4.0845627784729

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:09<00:00, 429.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:09<00:00, 429.11s/it]
INFO:root:final mean train loss: 1784.4543843002434
INFO:root:final train perplexity: 4.085025787353516
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.76s/it]
INFO:root:eval mean loss: 2876.943633574981
INFO:root:eval perplexity: 10.59881591796875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/64
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [8:46:38<4:51:45, 486.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1784.073556483477
INFO:root:current train perplexity4.062509536743164
INFO:root:current mean train loss 1785.7664683948863
INFO:root:current train perplexity4.076720237731934
INFO:root:current mean train loss 1784.3958693447844
INFO:root:current train perplexity4.066804885864258
INFO:root:current mean train loss 1776.6836912169938
INFO:root:current train perplexity4.06453275680542
INFO:root:current mean train loss 1775.5857580290683
INFO:root:current train perplexity4.065945148468018
INFO:root:current mean train loss 1773.7913966008305
INFO:root:current train perplexity4.062869071960449
INFO:root:current mean train loss 1774.3614157242198
INFO:root:current train perplexity4.062823295593262
INFO:root:current mean train loss 1773.591548081123
INFO:root:current train perplexity4.059445858001709
INFO:root:current mean train loss 1776.9503998181194
INFO:root:current train perplexity4.06271505355835
INFO:root:current mean train loss 1778.848988758153
INFO:root:current train perplexity4.066389560699463
INFO:root:current mean train loss 1778.0073703741305
INFO:root:current train perplexity4.064047336578369
INFO:root:current mean train loss 1779.4559773523063
INFO:root:current train perplexity4.069319248199463
INFO:root:current mean train loss 1779.4325689094976
INFO:root:current train perplexity4.06943416595459
INFO:root:current mean train loss 1780.3471229074667
INFO:root:current train perplexity4.071753025054932
INFO:root:current mean train loss 1781.4713194692545
INFO:root:current train perplexity4.073048114776611
INFO:root:current mean train loss 1782.3937940591525
INFO:root:current train perplexity4.075980186462402
INFO:root:current mean train loss 1781.9093330894339
INFO:root:current train perplexity4.077062606811523
INFO:root:current mean train loss 1781.5210109170616
INFO:root:current train perplexity4.075207710266113
INFO:root:current mean train loss 1781.428243874619
INFO:root:current train perplexity4.074837684631348

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.21s/it]
INFO:root:final mean train loss: 1781.850988160103
INFO:root:final train perplexity: 4.0766472816467285
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.56s/it]
INFO:root:eval mean loss: 2877.8209320160004
INFO:root:eval perplexity: 10.606450080871582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/65
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [8:54:45<4:43:51, 486.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1755.3831787109375
INFO:root:current train perplexity4.049978733062744
INFO:root:current mean train loss 1764.465084369366
INFO:root:current train perplexity4.033150672912598
INFO:root:current mean train loss 1780.0030206418505
INFO:root:current train perplexity4.065164089202881
INFO:root:current mean train loss 1777.107735884817
INFO:root:current train perplexity4.054394721984863
INFO:root:current mean train loss 1776.917884146813
INFO:root:current train perplexity4.056625843048096
INFO:root:current mean train loss 1776.6593790205698
INFO:root:current train perplexity4.053473472595215
INFO:root:current mean train loss 1776.6480345062862
INFO:root:current train perplexity4.051846027374268
INFO:root:current mean train loss 1776.5710000124845
INFO:root:current train perplexity4.054605484008789
INFO:root:current mean train loss 1778.9249838454214
INFO:root:current train perplexity4.0606842041015625
INFO:root:current mean train loss 1779.1507251030575
INFO:root:current train perplexity4.059187412261963
INFO:root:current mean train loss 1778.7098800841557
INFO:root:current train perplexity4.056910514831543
INFO:root:current mean train loss 1777.439046887384
INFO:root:current train perplexity4.05659294128418
INFO:root:current mean train loss 1778.0260341302105
INFO:root:current train perplexity4.058881759643555
INFO:root:current mean train loss 1778.3265935979737
INFO:root:current train perplexity4.060335636138916
INFO:root:current mean train loss 1778.1613546952901
INFO:root:current train perplexity4.0617289543151855
INFO:root:current mean train loss 1777.7236320008624
INFO:root:current train perplexity4.061111927032471
INFO:root:current mean train loss 1777.9220050611996
INFO:root:current train perplexity4.060348987579346
INFO:root:current mean train loss 1777.056823229006
INFO:root:current train perplexity4.061250686645508
INFO:root:current mean train loss 1777.323686891543
INFO:root:current train perplexity4.062719821929932
INFO:root:current mean train loss 1778.2497674637482
INFO:root:current train perplexity4.064523696899414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:12<00:00, 432.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:12<00:00, 432.09s/it]
INFO:root:final mean train loss: 1778.8278113599383
INFO:root:final train perplexity: 4.066939353942871
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.83s/it]
INFO:root:eval mean loss: 2875.998802024681
INFO:root:eval perplexity: 10.590601921081543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/66
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [9:02:50<4:35:23, 485.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1745.8685186476935
INFO:root:current train perplexity3.9762580394744873
INFO:root:current mean train loss 1773.2896728515625
INFO:root:current train perplexity4.010066509246826
INFO:root:current mean train loss 1766.918247136595
INFO:root:current train perplexity4.02773904800415
INFO:root:current mean train loss 1773.093391014408
INFO:root:current train perplexity4.045967102050781
INFO:root:current mean train loss 1776.8934746604068
INFO:root:current train perplexity4.056361198425293
INFO:root:current mean train loss 1776.3525317991994
INFO:root:current train perplexity4.057467937469482
INFO:root:current mean train loss 1776.2779114457528
INFO:root:current train perplexity4.056044578552246
INFO:root:current mean train loss 1775.1475325543408
INFO:root:current train perplexity4.047542572021484
INFO:root:current mean train loss 1776.0499185801423
INFO:root:current train perplexity4.049232482910156
INFO:root:current mean train loss 1776.6005794429882
INFO:root:current train perplexity4.049973011016846
INFO:root:current mean train loss 1775.1729805672671
INFO:root:current train perplexity4.049658298492432
INFO:root:current mean train loss 1775.061617739811
INFO:root:current train perplexity4.050159454345703
INFO:root:current mean train loss 1775.215712438735
INFO:root:current train perplexity4.050267219543457
INFO:root:current mean train loss 1773.295350368595
INFO:root:current train perplexity4.050966262817383
INFO:root:current mean train loss 1774.2438159918465
INFO:root:current train perplexity4.0533270835876465
INFO:root:current mean train loss 1773.923554530197
INFO:root:current train perplexity4.0540995597839355
INFO:root:current mean train loss 1774.8370023959217
INFO:root:current train perplexity4.054632663726807
INFO:root:current mean train loss 1774.8922419883288
INFO:root:current train perplexity4.056084156036377
INFO:root:current mean train loss 1775.947126058613
INFO:root:current train perplexity4.05633544921875
INFO:root:current mean train loss 1775.2927842783097
INFO:root:current train perplexity4.055205821990967

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:10<00:00, 430.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:10<00:00, 430.44s/it]
INFO:root:final mean train loss: 1775.8142893180905
INFO:root:final train perplexity: 4.057284355163574
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.80s/it]
INFO:root:eval mean loss: 2879.806884765625
INFO:root:eval perplexity: 10.623745918273926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/67
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [9:10:54<4:26:56, 485.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1763.5156057257402
INFO:root:current train perplexity4.0345540046691895
INFO:root:current mean train loss 1759.753862021626
INFO:root:current train perplexity4.0197882652282715
INFO:root:current mean train loss 1762.2659153016675
INFO:root:current train perplexity4.0220136642456055
INFO:root:current mean train loss 1762.5361205332379
INFO:root:current train perplexity4.028629779815674
INFO:root:current mean train loss 1764.7519940938034
INFO:root:current train perplexity4.031536102294922
INFO:root:current mean train loss 1768.9687388820719
INFO:root:current train perplexity4.035081386566162
INFO:root:current mean train loss 1772.238254463411
INFO:root:current train perplexity4.037594795227051
INFO:root:current mean train loss 1769.1501433416433
INFO:root:current train perplexity4.035537242889404
INFO:root:current mean train loss 1770.3765312686455
INFO:root:current train perplexity4.03670597076416
INFO:root:current mean train loss 1772.6267186146556
INFO:root:current train perplexity4.039584159851074
INFO:root:current mean train loss 1772.7535866092396
INFO:root:current train perplexity4.042292594909668
INFO:root:current mean train loss 1773.925190635641
INFO:root:current train perplexity4.041755676269531
INFO:root:current mean train loss 1773.6644248654268
INFO:root:current train perplexity4.041616439819336
INFO:root:current mean train loss 1772.7140065009285
INFO:root:current train perplexity4.041900157928467
INFO:root:current mean train loss 1773.0628867540638
INFO:root:current train perplexity4.0436177253723145
INFO:root:current mean train loss 1774.2502236632904
INFO:root:current train perplexity4.04605770111084
INFO:root:current mean train loss 1774.0423186771454
INFO:root:current train perplexity4.046602725982666
INFO:root:current mean train loss 1774.3729743913623
INFO:root:current train perplexity4.048346042633057
INFO:root:current mean train loss 1775.0204487697863
INFO:root:current train perplexity4.0499653816223145
INFO:root:current mean train loss 1773.8342606393915
INFO:root:current train perplexity4.049522399902344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.09s/it]
INFO:root:final mean train loss: 1773.5488868824953
INFO:root:final train perplexity: 4.050042629241943
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.98s/it]
INFO:root:eval mean loss: 2881.473514041385
INFO:root:eval perplexity: 10.638284683227539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/68
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [9:18:59<4:18:45, 485.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1756.4526788884943
INFO:root:current train perplexity4.020474910736084
INFO:root:current mean train loss 1776.2572360131048
INFO:root:current train perplexity4.029022216796875
INFO:root:current mean train loss 1772.8293203316482
INFO:root:current train perplexity4.034012317657471
INFO:root:current mean train loss 1776.6269300863776
INFO:root:current train perplexity4.04634952545166
INFO:root:current mean train loss 1775.110630580357
INFO:root:current train perplexity4.048364162445068
INFO:root:current mean train loss 1771.731529991906
INFO:root:current train perplexity4.038951873779297
INFO:root:current mean train loss 1771.1589635019084
INFO:root:current train perplexity4.0379180908203125
INFO:root:current mean train loss 1770.9583420102958
INFO:root:current train perplexity4.0323615074157715
INFO:root:current mean train loss 1769.7512084247076
INFO:root:current train perplexity4.0316267013549805
INFO:root:current mean train loss 1770.225281209097
INFO:root:current train perplexity4.032721519470215
INFO:root:current mean train loss 1769.7127012135293
INFO:root:current train perplexity4.0327839851379395
INFO:root:current mean train loss 1771.2352244191356
INFO:root:current train perplexity4.035529613494873
INFO:root:current mean train loss 1771.566066106667
INFO:root:current train perplexity4.036308288574219
INFO:root:current mean train loss 1771.029207867274
INFO:root:current train perplexity4.036215305328369
INFO:root:current mean train loss 1771.72044514135
INFO:root:current train perplexity4.037862777709961
INFO:root:current mean train loss 1772.232645055642
INFO:root:current train perplexity4.038601398468018
INFO:root:current mean train loss 1773.399463038142
INFO:root:current train perplexity4.041903495788574
INFO:root:current mean train loss 1772.303373592192
INFO:root:current train perplexity4.040701866149902
INFO:root:current mean train loss 1771.770533213654
INFO:root:current train perplexity4.040436267852783
INFO:root:current mean train loss 1771.1250841691976
INFO:root:current train perplexity4.040040969848633

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:18<00:00, 438.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:18<00:00, 438.14s/it]
INFO:root:final mean train loss: 1770.5932428818787
INFO:root:final train perplexity: 4.040612697601318
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.48s/it]
INFO:root:eval mean loss: 2882.365521038617
INFO:root:eval perplexity: 10.646071434020996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/69
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [9:27:11<4:11:47, 487.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1755.1444193522136
INFO:root:current train perplexity4.024389743804932
INFO:root:current mean train loss 1760.8767586641534
INFO:root:current train perplexity4.031315326690674
INFO:root:current mean train loss 1759.866980159984
INFO:root:current train perplexity4.028631210327148
INFO:root:current mean train loss 1759.3289227229293
INFO:root:current train perplexity4.023561000823975
INFO:root:current mean train loss 1763.2772527145128
INFO:root:current train perplexity4.022895812988281
INFO:root:current mean train loss 1766.0303912396198
INFO:root:current train perplexity4.0319905281066895
INFO:root:current mean train loss 1767.3272270929247
INFO:root:current train perplexity4.03634786605835
INFO:root:current mean train loss 1765.9932815472696
INFO:root:current train perplexity4.03280782699585
INFO:root:current mean train loss 1764.0883063920048
INFO:root:current train perplexity4.0318450927734375
INFO:root:current mean train loss 1764.2245669266815
INFO:root:current train perplexity4.031311511993408
INFO:root:current mean train loss 1763.9752598093517
INFO:root:current train perplexity4.03070068359375
INFO:root:current mean train loss 1765.2720091106949
INFO:root:current train perplexity4.03187894821167
INFO:root:current mean train loss 1765.5347518441063
INFO:root:current train perplexity4.031342029571533
INFO:root:current mean train loss 1764.8733946686236
INFO:root:current train perplexity4.031709671020508
INFO:root:current mean train loss 1765.581537246704
INFO:root:current train perplexity4.032495021820068
INFO:root:current mean train loss 1765.435146108535
INFO:root:current train perplexity4.0319318771362305
INFO:root:current mean train loss 1767.0138828697386
INFO:root:current train perplexity4.032787322998047
INFO:root:current mean train loss 1767.5246680541716
INFO:root:current train perplexity4.03253173828125
INFO:root:current mean train loss 1768.438343993619
INFO:root:current train perplexity4.032747268676758
INFO:root:current mean train loss 1768.6181357114842
INFO:root:current train perplexity4.033153057098389

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:16<00:00, 436.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:16<00:00, 436.03s/it]
INFO:root:final mean train loss: 1768.4431378878671
INFO:root:final train perplexity: 4.033766746520996
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.36s/it]
INFO:root:eval mean loss: 2885.406717019754
INFO:root:eval perplexity: 10.672675132751465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/70
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [9:35:21<4:04:04, 488.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1758.2509738193469
INFO:root:current train perplexity4.0512189865112305
INFO:root:current mean train loss 1749.9200846354167
INFO:root:current train perplexity4.017897129058838
INFO:root:current mean train loss 1757.068942271302
INFO:root:current train perplexity4.021104335784912
INFO:root:current mean train loss 1755.9565643075193
INFO:root:current train perplexity4.0173869132995605
INFO:root:current mean train loss 1760.4428673492619
INFO:root:current train perplexity4.022502422332764
INFO:root:current mean train loss 1759.7472325893332
INFO:root:current train perplexity4.021570205688477
INFO:root:current mean train loss 1760.3086155419426
INFO:root:current train perplexity4.018896102905273
INFO:root:current mean train loss 1759.4923494868406
INFO:root:current train perplexity4.013980388641357
INFO:root:current mean train loss 1761.2520659954127
INFO:root:current train perplexity4.016416549682617
INFO:root:current mean train loss 1763.4068187563196
INFO:root:current train perplexity4.016153812408447
INFO:root:current mean train loss 1761.3217860870782
INFO:root:current train perplexity4.01436185836792
INFO:root:current mean train loss 1760.8490777685424
INFO:root:current train perplexity4.015990257263184
INFO:root:current mean train loss 1761.073299860751
INFO:root:current train perplexity4.016283988952637
INFO:root:current mean train loss 1761.1866557023095
INFO:root:current train perplexity4.017470359802246
INFO:root:current mean train loss 1762.033698046744
INFO:root:current train perplexity4.019964218139648
INFO:root:current mean train loss 1762.0264345604792
INFO:root:current train perplexity4.020802974700928
INFO:root:current mean train loss 1763.1327660279983
INFO:root:current train perplexity4.0206499099731445
INFO:root:current mean train loss 1764.126986559574
INFO:root:current train perplexity4.020585536956787
INFO:root:current mean train loss 1765.3604407403884
INFO:root:current train perplexity4.021972179412842

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:16<00:00, 436.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:16<00:00, 436.27s/it]
INFO:root:final mean train loss: 1765.766964941751
INFO:root:final train perplexity: 4.025262355804443
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.52s/it]
INFO:root:eval mean loss: 2882.1217594547675
INFO:root:eval perplexity: 10.64394474029541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/71
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [9:43:31<3:56:16, 488.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1801.9358723958333
INFO:root:current train perplexity4.017823219299316
INFO:root:current mean train loss 1755.775912302845
INFO:root:current train perplexity3.9724204540252686
INFO:root:current mean train loss 1749.83241286787
INFO:root:current train perplexity3.97395396232605
INFO:root:current mean train loss 1750.5433672736672
INFO:root:current train perplexity3.9736859798431396
INFO:root:current mean train loss 1752.9518492750346
INFO:root:current train perplexity3.985128402709961
INFO:root:current mean train loss 1752.4552033315063
INFO:root:current train perplexity3.9860193729400635
INFO:root:current mean train loss 1755.09748160485
INFO:root:current train perplexity3.9932732582092285
INFO:root:current mean train loss 1757.089838389972
INFO:root:current train perplexity3.997347354888916
INFO:root:current mean train loss 1758.768781562597
INFO:root:current train perplexity3.999354839324951
INFO:root:current mean train loss 1758.8398539898938
INFO:root:current train perplexity3.999598503112793
INFO:root:current mean train loss 1759.9262440493756
INFO:root:current train perplexity4.004697799682617
INFO:root:current mean train loss 1755.988569870133
INFO:root:current train perplexity4.0010247230529785
INFO:root:current mean train loss 1758.2572474946232
INFO:root:current train perplexity4.003655433654785
INFO:root:current mean train loss 1760.0427853641247
INFO:root:current train perplexity4.0056304931640625
INFO:root:current mean train loss 1760.5925543881413
INFO:root:current train perplexity4.00889253616333
INFO:root:current mean train loss 1760.970729143971
INFO:root:current train perplexity4.008134365081787
INFO:root:current mean train loss 1760.7818123899392
INFO:root:current train perplexity4.01029109954834
INFO:root:current mean train loss 1759.767461421202
INFO:root:current train perplexity4.009115695953369
INFO:root:current mean train loss 1760.8490082158862
INFO:root:current train perplexity4.012083053588867
INFO:root:current mean train loss 1763.0486609027619
INFO:root:current train perplexity4.014556407928467

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:09<00:00, 429.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:09<00:00, 429.97s/it]
INFO:root:final mean train loss: 1762.9389252001388
INFO:root:final train perplexity: 4.016294479370117
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.01s/it]
INFO:root:eval mean loss: 2887.418267877252
INFO:root:eval perplexity: 10.690305709838867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/72
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [9:51:35<3:47:23, 487.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1779.6148097826087
INFO:root:current train perplexity3.996356248855591
INFO:root:current mean train loss 1768.898781877223
INFO:root:current train perplexity4.006474018096924
INFO:root:current mean train loss 1759.8513720046244
INFO:root:current train perplexity3.9933841228485107
INFO:root:current mean train loss 1758.3447942113728
INFO:root:current train perplexity3.9901487827301025
INFO:root:current mean train loss 1758.5150293661347
INFO:root:current train perplexity3.9937045574188232
INFO:root:current mean train loss 1760.1393909928447
INFO:root:current train perplexity3.9967093467712402
INFO:root:current mean train loss 1758.7125240221835
INFO:root:current train perplexity3.9931561946868896
INFO:root:current mean train loss 1758.0955297277512
INFO:root:current train perplexity3.9998788833618164
INFO:root:current mean train loss 1758.0001683472717
INFO:root:current train perplexity4.000080585479736
INFO:root:current mean train loss 1759.0907814298653
INFO:root:current train perplexity4.0030436515808105
INFO:root:current mean train loss 1760.4996259135585
INFO:root:current train perplexity4.004207134246826
INFO:root:current mean train loss 1760.5656105646149
INFO:root:current train perplexity4.0051679611206055
INFO:root:current mean train loss 1760.563885892305
INFO:root:current train perplexity4.006849765777588
INFO:root:current mean train loss 1759.9320394064744
INFO:root:current train perplexity4.006008148193359
INFO:root:current mean train loss 1759.665845258422
INFO:root:current train perplexity4.006109714508057
INFO:root:current mean train loss 1760.4467601112372
INFO:root:current train perplexity4.007896423339844
INFO:root:current mean train loss 1761.315199160385
INFO:root:current train perplexity4.008902549743652
INFO:root:current mean train loss 1761.142580746359
INFO:root:current train perplexity4.008228302001953
INFO:root:current mean train loss 1761.2597946861715
INFO:root:current train perplexity4.006813049316406
INFO:root:current mean train loss 1761.0185479587153
INFO:root:current train perplexity4.007925510406494

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.61s/it]
INFO:root:final mean train loss: 1760.6809210688311
INFO:root:final train perplexity: 4.009149074554443
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.52s/it]
INFO:root:eval mean loss: 2887.6097203160193
INFO:root:eval perplexity: 10.691985130310059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/73
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [9:59:44<3:39:29, 487.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1739.659390258789
INFO:root:current train perplexity4.005417823791504
INFO:root:current mean train loss 1747.5593985421317
INFO:root:current train perplexity3.9787628650665283
INFO:root:current mean train loss 1745.9293324788412
INFO:root:current train perplexity3.979494333267212
INFO:root:current mean train loss 1750.3366893095128
INFO:root:current train perplexity3.987971305847168
INFO:root:current mean train loss 1755.7686673251064
INFO:root:current train perplexity3.9946401119232178
INFO:root:current mean train loss 1756.0989741572628
INFO:root:current train perplexity3.9998226165771484
INFO:root:current mean train loss 1757.062546157837
INFO:root:current train perplexity3.996181011199951
INFO:root:current mean train loss 1756.5828492860537
INFO:root:current train perplexity3.99587082862854
INFO:root:current mean train loss 1756.8562924339658
INFO:root:current train perplexity3.9960265159606934
INFO:root:current mean train loss 1757.2130546407498
INFO:root:current train perplexity4.000030994415283
INFO:root:current mean train loss 1757.9227840717022
INFO:root:current train perplexity4.002264022827148
INFO:root:current mean train loss 1758.0051396955523
INFO:root:current train perplexity4.005333423614502
INFO:root:current mean train loss 1758.7743562759892
INFO:root:current train perplexity4.006054878234863
INFO:root:current mean train loss 1758.9541141339203
INFO:root:current train perplexity4.005197048187256
INFO:root:current mean train loss 1758.0050986395943
INFO:root:current train perplexity4.002008438110352
INFO:root:current mean train loss 1757.7016309862013
INFO:root:current train perplexity4.001977920532227
INFO:root:current mean train loss 1758.4064514904487
INFO:root:current train perplexity4.0023908615112305
INFO:root:current mean train loss 1758.6565678739
INFO:root:current train perplexity4.002405166625977
INFO:root:current mean train loss 1759.0790354189664
INFO:root:current train perplexity4.0035786628723145
INFO:root:current mean train loss 1759.4568075592986
INFO:root:current train perplexity4.003618240356445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.85s/it]
INFO:root:final mean train loss: 1758.9213108172396
INFO:root:final train perplexity: 4.003588676452637
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.97s/it]
INFO:root:eval mean loss: 2889.1245674385323
INFO:root:eval perplexity: 10.70528507232666
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/74
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [10:08:03<3:32:53, 491.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1740.6231796532347
INFO:root:current train perplexity3.946188449859619
INFO:root:current mean train loss 1762.4241406872015
INFO:root:current train perplexity3.999924659729004
INFO:root:current mean train loss 1759.3814958505593
INFO:root:current train perplexity3.984285831451416
INFO:root:current mean train loss 1754.8975259048932
INFO:root:current train perplexity3.9814071655273438
INFO:root:current mean train loss 1750.6312699265761
INFO:root:current train perplexity3.9760186672210693
INFO:root:current mean train loss 1753.5016989031642
INFO:root:current train perplexity3.985725164413452
INFO:root:current mean train loss 1754.3965982701318
INFO:root:current train perplexity3.9830145835876465
INFO:root:current mean train loss 1752.3981665909841
INFO:root:current train perplexity3.9806602001190186
INFO:root:current mean train loss 1753.1515986510447
INFO:root:current train perplexity3.9853873252868652
INFO:root:current mean train loss 1752.464717215256
INFO:root:current train perplexity3.983682632446289
INFO:root:current mean train loss 1751.9830351137507
INFO:root:current train perplexity3.9815964698791504
INFO:root:current mean train loss 1754.1700963817389
INFO:root:current train perplexity3.983189344406128
INFO:root:current mean train loss 1752.8465035255692
INFO:root:current train perplexity3.982548713684082
INFO:root:current mean train loss 1754.1195084551457
INFO:root:current train perplexity3.9876248836517334
INFO:root:current mean train loss 1754.6656480735512
INFO:root:current train perplexity3.989755868911743
INFO:root:current mean train loss 1754.8802520026745
INFO:root:current train perplexity3.9913291931152344
INFO:root:current mean train loss 1755.3517334131714
INFO:root:current train perplexity3.9924330711364746
INFO:root:current mean train loss 1755.3351071856548
INFO:root:current train perplexity3.992180347442627
INFO:root:current mean train loss 1757.0844982929877
INFO:root:current train perplexity3.99768328666687
INFO:root:current mean train loss 1756.740042069035
INFO:root:current train perplexity3.9963185787200928

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:16<00:00, 436.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:16<00:00, 436.82s/it]
INFO:root:final mean train loss: 1756.7177719600984
INFO:root:final train perplexity: 3.9966368675231934
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.90s/it]
INFO:root:eval mean loss: 2888.681895029795
INFO:root:eval perplexity: 10.701395988464355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/75
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [10:16:15<3:24:42, 491.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1760.584690403294
INFO:root:current train perplexity4.012111663818359
INFO:root:current mean train loss 1745.7718407641883
INFO:root:current train perplexity3.975675582885742
INFO:root:current mean train loss 1751.058583503222
INFO:root:current train perplexity3.9735915660858154
INFO:root:current mean train loss 1751.0355371485418
INFO:root:current train perplexity3.9699387550354004
INFO:root:current mean train loss 1753.4365507359244
INFO:root:current train perplexity3.9782233238220215
INFO:root:current mean train loss 1751.813283461727
INFO:root:current train perplexity3.9813942909240723
INFO:root:current mean train loss 1750.4686139839694
INFO:root:current train perplexity3.977367401123047
INFO:root:current mean train loss 1752.2658331819282
INFO:root:current train perplexity3.9816668033599854
INFO:root:current mean train loss 1752.2330070862236
INFO:root:current train perplexity3.980088472366333
INFO:root:current mean train loss 1753.6894491144765
INFO:root:current train perplexity3.982492685317993
INFO:root:current mean train loss 1753.7435057229836
INFO:root:current train perplexity3.9810738563537598
INFO:root:current mean train loss 1754.3315920464224
INFO:root:current train perplexity3.9813027381896973
INFO:root:current mean train loss 1753.2141280002086
INFO:root:current train perplexity3.981393337249756
INFO:root:current mean train loss 1755.4079317095673
INFO:root:current train perplexity3.987449884414673
INFO:root:current mean train loss 1754.380089686069
INFO:root:current train perplexity3.9864659309387207
INFO:root:current mean train loss 1753.8292057953463
INFO:root:current train perplexity3.98636531829834
INFO:root:current mean train loss 1754.0976343006785
INFO:root:current train perplexity3.9873251914978027
INFO:root:current mean train loss 1753.8464061646746
INFO:root:current train perplexity3.986989736557007
INFO:root:current mean train loss 1754.463055231019
INFO:root:current train perplexity3.98819899559021
INFO:root:current mean train loss 1754.6528842234202
INFO:root:current train perplexity3.9890074729919434

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.21s/it]
INFO:root:final mean train loss: 1754.4096747401743
INFO:root:final train perplexity: 3.9893686771392822
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.35s/it]
INFO:root:eval mean loss: 2890.7452256944443
INFO:root:eval perplexity: 10.719529151916504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/76
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [10:24:32<3:17:14, 493.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1748.5825933100102
INFO:root:current train perplexity3.989769220352173
INFO:root:current mean train loss 1755.0161918919748
INFO:root:current train perplexity4.001480579376221
INFO:root:current mean train loss 1749.7356909263585
INFO:root:current train perplexity3.983323097229004
INFO:root:current mean train loss 1749.217413158368
INFO:root:current train perplexity3.9774227142333984
INFO:root:current mean train loss 1750.5442153091585
INFO:root:current train perplexity3.9808261394500732
INFO:root:current mean train loss 1748.7491194826698
INFO:root:current train perplexity3.971336603164673
INFO:root:current mean train loss 1748.9059487990119
INFO:root:current train perplexity3.9721059799194336
INFO:root:current mean train loss 1750.7120435403663
INFO:root:current train perplexity3.9727158546447754
INFO:root:current mean train loss 1750.381155440034
INFO:root:current train perplexity3.973845958709717
INFO:root:current mean train loss 1750.2535962086513
INFO:root:current train perplexity3.9750590324401855
INFO:root:current mean train loss 1751.077313472982
INFO:root:current train perplexity3.975076913833618
INFO:root:current mean train loss 1752.0662016720455
INFO:root:current train perplexity3.9772706031799316
INFO:root:current mean train loss 1751.3560504514426
INFO:root:current train perplexity3.9772207736968994
INFO:root:current mean train loss 1751.9540568063107
INFO:root:current train perplexity3.9796295166015625
INFO:root:current mean train loss 1752.0216287143433
INFO:root:current train perplexity3.978562355041504
INFO:root:current mean train loss 1752.3809065611988
INFO:root:current train perplexity3.9794673919677734
INFO:root:current mean train loss 1751.8493526736213
INFO:root:current train perplexity3.9778618812561035
INFO:root:current mean train loss 1752.2178752649968
INFO:root:current train perplexity3.979527711868286
INFO:root:current mean train loss 1751.769215067879
INFO:root:current train perplexity3.979458808898926

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:21<00:00, 441.97s/it]
INFO:root:final mean train loss: 1751.9116815441014
INFO:root:final train perplexity: 3.9815173149108887
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.88s/it]
INFO:root:eval mean loss: 2892.143279754364
INFO:root:eval perplexity: 10.731834411621094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/77
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [10:32:49<3:09:24, 494.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1702.5261840820312
INFO:root:current train perplexity3.8574485778808594
INFO:root:current mean train loss 1740.7141689724392
INFO:root:current train perplexity3.960462808609009
INFO:root:current mean train loss 1746.24180661715
INFO:root:current train perplexity3.954906940460205
INFO:root:current mean train loss 1746.4830155806108
INFO:root:current train perplexity3.957848072052002
INFO:root:current mean train loss 1747.5016754748774
INFO:root:current train perplexity3.955731153488159
INFO:root:current mean train loss 1746.2587972325603
INFO:root:current train perplexity3.9563183784484863
INFO:root:current mean train loss 1746.3532851369757
INFO:root:current train perplexity3.9587974548339844
INFO:root:current mean train loss 1745.6138597046588
INFO:root:current train perplexity3.961487054824829
INFO:root:current mean train loss 1749.0187781305597
INFO:root:current train perplexity3.9666430950164795
INFO:root:current mean train loss 1749.9611729021115
INFO:root:current train perplexity3.9703145027160645
INFO:root:current mean train loss 1750.2906976124598
INFO:root:current train perplexity3.968881607055664
INFO:root:current mean train loss 1748.485455784987
INFO:root:current train perplexity3.9675698280334473
INFO:root:current mean train loss 1747.7013817591383
INFO:root:current train perplexity3.9659054279327393
INFO:root:current mean train loss 1748.0925860390387
INFO:root:current train perplexity3.967139482498169
INFO:root:current mean train loss 1749.325748096813
INFO:root:current train perplexity3.9718563556671143
INFO:root:current mean train loss 1749.5112968465062
INFO:root:current train perplexity3.972212076187134
INFO:root:current mean train loss 1748.9629655524866
INFO:root:current train perplexity3.9723005294799805
INFO:root:current mean train loss 1750.5068364377883
INFO:root:current train perplexity3.9741199016571045
INFO:root:current mean train loss 1750.5319283409456
INFO:root:current train perplexity3.9750614166259766
INFO:root:current mean train loss 1749.9279363540234
INFO:root:current train perplexity3.97458553314209

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:18<00:00, 438.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:18<00:00, 438.54s/it]
INFO:root:final mean train loss: 1750.5306087153401
INFO:root:final train perplexity: 3.977182388305664
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.21s/it]
INFO:root:eval mean loss: 2894.102558124531
INFO:root:eval perplexity: 10.749106407165527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/78
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [10:41:01<3:00:59, 493.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1755.574892578125
INFO:root:current train perplexity4.011158466339111
INFO:root:current mean train loss 1734.404701171875
INFO:root:current train perplexity3.9405243396759033
INFO:root:current mean train loss 1745.9544949001736
INFO:root:current train perplexity3.976318120956421
INFO:root:current mean train loss 1741.0056464092547
INFO:root:current train perplexity3.9691784381866455
INFO:root:current mean train loss 1745.3217351217831
INFO:root:current train perplexity3.970677137374878
INFO:root:current mean train loss 1745.4583017113096
INFO:root:current train perplexity3.9701755046844482
INFO:root:current mean train loss 1746.52913125
INFO:root:current train perplexity3.9678750038146973
INFO:root:current mean train loss 1746.91435664736
INFO:root:current train perplexity3.966144561767578
INFO:root:current mean train loss 1746.7248604699337
INFO:root:current train perplexity3.9689431190490723
INFO:root:current mean train loss 1744.672518211571
INFO:root:current train perplexity3.9657678604125977
INFO:root:current mean train loss 1744.4343180735518
INFO:root:current train perplexity3.9666459560394287
INFO:root:current mean train loss 1745.9853480902777
INFO:root:current train perplexity3.9674947261810303
INFO:root:current mean train loss 1746.5034435786033
INFO:root:current train perplexity3.968566656112671
INFO:root:current mean train loss 1747.733489736881
INFO:root:current train perplexity3.9696292877197266
INFO:root:current mean train loss 1746.5930814830044
INFO:root:current train perplexity3.9662392139434814
INFO:root:current mean train loss 1746.8210224289192
INFO:root:current train perplexity3.966644525527954
INFO:root:current mean train loss 1747.1128255709134
INFO:root:current train perplexity3.9657702445983887
INFO:root:current mean train loss 1748.160182716259
INFO:root:current train perplexity3.966749429702759
INFO:root:current mean train loss 1748.160328151755
INFO:root:current train perplexity3.970519542694092
INFO:root:current mean train loss 1748.6205411678166
INFO:root:current train perplexity3.970578193664551

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:15<00:00, 435.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:15<00:00, 435.08s/it]
INFO:root:final mean train loss: 1748.5440149966118
INFO:root:final train perplexity: 3.9709572792053223
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.03s/it]
INFO:root:eval mean loss: 2894.6491618571695
INFO:root:eval perplexity: 10.753928184509277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/79
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [10:49:10<2:52:15, 492.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1744.1392706008185
INFO:root:current train perplexity3.935145616531372
INFO:root:current mean train loss 1744.3473854602223
INFO:root:current train perplexity3.9585375785827637
INFO:root:current mean train loss 1744.1508723487539
INFO:root:current train perplexity3.9587931632995605
INFO:root:current mean train loss 1750.4362386067708
INFO:root:current train perplexity3.9681475162506104
INFO:root:current mean train loss 1747.5830774091487
INFO:root:current train perplexity3.9558753967285156
INFO:root:current mean train loss 1749.0363909168877
INFO:root:current train perplexity3.9586567878723145
INFO:root:current mean train loss 1748.881129755038
INFO:root:current train perplexity3.9567461013793945
INFO:root:current mean train loss 1747.6643378985218
INFO:root:current train perplexity3.9585535526275635
INFO:root:current mean train loss 1748.5437590175457
INFO:root:current train perplexity3.9645392894744873
INFO:root:current mean train loss 1749.9966045792696
INFO:root:current train perplexity3.969130039215088
INFO:root:current mean train loss 1748.4372350066728
INFO:root:current train perplexity3.967554807662964
INFO:root:current mean train loss 1747.253467994062
INFO:root:current train perplexity3.9653642177581787
INFO:root:current mean train loss 1747.9572402044962
INFO:root:current train perplexity3.9656691551208496
INFO:root:current mean train loss 1747.4974061423015
INFO:root:current train perplexity3.965955972671509
INFO:root:current mean train loss 1747.4041061507185
INFO:root:current train perplexity3.9645450115203857
INFO:root:current mean train loss 1747.415465596121
INFO:root:current train perplexity3.96455979347229
INFO:root:current mean train loss 1748.550326422855
INFO:root:current train perplexity3.9672625064849854
INFO:root:current mean train loss 1747.946136439572
INFO:root:current train perplexity3.966952323913574
INFO:root:current mean train loss 1746.649877359761
INFO:root:current train perplexity3.966090679168701
INFO:root:current mean train loss 1746.7840539085632
INFO:root:current train perplexity3.9657082557678223

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.06s/it]
INFO:root:final mean train loss: 1746.4377800291738
INFO:root:final train perplexity: 3.9643659591674805
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.36s/it]
INFO:root:eval mean loss: 2893.86047986463
INFO:root:eval perplexity: 10.746969223022461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/80
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [10:57:16<2:43:26, 490.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1724.613452976033
INFO:root:current train perplexity3.9568848609924316
INFO:root:current mean train loss 1744.4678655660377
INFO:root:current train perplexity3.9636428356170654
INFO:root:current mean train loss 1737.810618043406
INFO:root:current train perplexity3.945887327194214
INFO:root:current mean train loss 1735.435507431668
INFO:root:current train perplexity3.9433391094207764
INFO:root:current mean train loss 1736.9432934197985
INFO:root:current train perplexity3.9425973892211914
INFO:root:current mean train loss 1737.7706161253354
INFO:root:current train perplexity3.939517021179199
INFO:root:current mean train loss 1738.772324233569
INFO:root:current train perplexity3.9381608963012695
INFO:root:current mean train loss 1740.3891902315445
INFO:root:current train perplexity3.943692207336426
INFO:root:current mean train loss 1741.2630566917837
INFO:root:current train perplexity3.9482052326202393
INFO:root:current mean train loss 1740.6424393798065
INFO:root:current train perplexity3.9491922855377197
INFO:root:current mean train loss 1740.247239528004
INFO:root:current train perplexity3.948948383331299
INFO:root:current mean train loss 1741.7632370982528
INFO:root:current train perplexity3.9497995376586914
INFO:root:current mean train loss 1743.2825371194585
INFO:root:current train perplexity3.9536492824554443
INFO:root:current mean train loss 1743.2849200138544
INFO:root:current train perplexity3.955422878265381
INFO:root:current mean train loss 1743.604781508364
INFO:root:current train perplexity3.956721067428589
INFO:root:current mean train loss 1744.0223971226799
INFO:root:current train perplexity3.9567480087280273
INFO:root:current mean train loss 1744.256856834407
INFO:root:current train perplexity3.9580981731414795
INFO:root:current mean train loss 1744.1184385298598
INFO:root:current train perplexity3.957528829574585
INFO:root:current mean train loss 1744.2360093894988
INFO:root:current train perplexity3.9571027755737305
INFO:root:current mean train loss 1744.450388730698
INFO:root:current train perplexity3.957731008529663

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.96s/it]
INFO:root:final mean train loss: 1744.4653105165883
INFO:root:final train perplexity: 3.9582033157348633
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.11s/it]
INFO:root:eval mean loss: 2895.4978195969406
INFO:root:eval perplexity: 10.761417388916016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/81
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [11:05:24<2:35:06, 489.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1747.763098465769
INFO:root:current train perplexity3.996391534805298
INFO:root:current mean train loss 1753.5385853160512
INFO:root:current train perplexity3.9856977462768555
INFO:root:current mean train loss 1753.3932035142097
INFO:root:current train perplexity3.975584030151367
INFO:root:current mean train loss 1746.127813785634
INFO:root:current train perplexity3.9588003158569336
INFO:root:current mean train loss 1744.6475258194098
INFO:root:current train perplexity3.957556962966919
INFO:root:current mean train loss 1744.2531912061904
INFO:root:current train perplexity3.9546194076538086
INFO:root:current mean train loss 1743.965342324161
INFO:root:current train perplexity3.9535796642303467
INFO:root:current mean train loss 1742.846764476029
INFO:root:current train perplexity3.95432710647583
INFO:root:current mean train loss 1744.4995740080533
INFO:root:current train perplexity3.9505908489227295
INFO:root:current mean train loss 1744.6627196014904
INFO:root:current train perplexity3.951284170150757
INFO:root:current mean train loss 1742.3255102448304
INFO:root:current train perplexity3.949124574661255
INFO:root:current mean train loss 1742.194623674665
INFO:root:current train perplexity3.9515388011932373
INFO:root:current mean train loss 1743.8872624220892
INFO:root:current train perplexity3.9540297985076904
INFO:root:current mean train loss 1744.6107862605604
INFO:root:current train perplexity3.9542720317840576
INFO:root:current mean train loss 1744.8129969651136
INFO:root:current train perplexity3.952629566192627
INFO:root:current mean train loss 1744.991760718641
INFO:root:current train perplexity3.953312397003174
INFO:root:current mean train loss 1745.78103936316
INFO:root:current train perplexity3.95452880859375
INFO:root:current mean train loss 1744.7366595568958
INFO:root:current train perplexity3.954232931137085
INFO:root:current mean train loss 1744.1399962337796
INFO:root:current train perplexity3.9551734924316406
INFO:root:current mean train loss 1744.2482823669186
INFO:root:current train perplexity3.955817461013794

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:08<00:00, 428.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:08<00:00, 428.59s/it]
INFO:root:final mean train loss: 1743.5777815964507
INFO:root:final train perplexity: 3.9554336071014404
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.50s/it]
INFO:root:eval mean loss: 2897.681983741554
INFO:root:eval perplexity: 10.780723571777344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/82
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [11:13:27<2:26:18, 487.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1743.1679188718078
INFO:root:current train perplexity3.9491159915924072
INFO:root:current mean train loss 1752.9853022283842
INFO:root:current train perplexity3.9573192596435547
INFO:root:current mean train loss 1739.2022871727015
INFO:root:current train perplexity3.944578170776367
INFO:root:current mean train loss 1738.650468588482
INFO:root:current train perplexity3.9429738521575928
INFO:root:current mean train loss 1738.0963852826287
INFO:root:current train perplexity3.93965744972229
INFO:root:current mean train loss 1736.9190638833263
INFO:root:current train perplexity3.9416933059692383
INFO:root:current mean train loss 1737.6126404248962
INFO:root:current train perplexity3.944953680038452
INFO:root:current mean train loss 1737.2641612337936
INFO:root:current train perplexity3.9458305835723877
INFO:root:current mean train loss 1738.199433637493
INFO:root:current train perplexity3.950423002243042
INFO:root:current mean train loss 1740.36010815946
INFO:root:current train perplexity3.9534952640533447
INFO:root:current mean train loss 1740.1551334977914
INFO:root:current train perplexity3.952320098876953
INFO:root:current mean train loss 1739.3982993651116
INFO:root:current train perplexity3.9501664638519287
INFO:root:current mean train loss 1739.7953737145326
INFO:root:current train perplexity3.950718879699707
INFO:root:current mean train loss 1740.488784691454
INFO:root:current train perplexity3.9494409561157227
INFO:root:current mean train loss 1740.7525056709958
INFO:root:current train perplexity3.9494235515594482
INFO:root:current mean train loss 1741.6503772915196
INFO:root:current train perplexity3.950394868850708
INFO:root:current mean train loss 1742.182888655147
INFO:root:current train perplexity3.9506289958953857
INFO:root:current mean train loss 1742.0710646655396
INFO:root:current train perplexity3.9516801834106445
INFO:root:current mean train loss 1742.6443179332573
INFO:root:current train perplexity3.950788974761963

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:12<00:00, 432.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:12<00:00, 432.86s/it]
INFO:root:final mean train loss: 1741.6982713046245
INFO:root:final train perplexity: 3.9495749473571777
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.56s/it]
INFO:root:eval mean loss: 2896.647672819304
INFO:root:eval perplexity: 10.771576881408691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/83
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [11:21:33<2:18:02, 487.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1765.0260986328126
INFO:root:current train perplexity3.955735445022583
INFO:root:current mean train loss 1743.7234008789062
INFO:root:current train perplexity3.935889720916748
INFO:root:current mean train loss 1744.3387602306548
INFO:root:current train perplexity3.932839870452881
INFO:root:current mean train loss 1742.0816516507057
INFO:root:current train perplexity3.9358930587768555
INFO:root:current mean train loss 1737.0524128239329
INFO:root:current train perplexity3.9335553646087646
INFO:root:current mean train loss 1736.21033337163
INFO:root:current train perplexity3.940451145172119
INFO:root:current mean train loss 1737.1507048059682
INFO:root:current train perplexity3.944577693939209
INFO:root:current mean train loss 1736.3994498239438
INFO:root:current train perplexity3.943927764892578
INFO:root:current mean train loss 1737.1222814489295
INFO:root:current train perplexity3.943010091781616
INFO:root:current mean train loss 1737.8782716185183
INFO:root:current train perplexity3.9420063495635986
INFO:root:current mean train loss 1737.3323689375773
INFO:root:current train perplexity3.93886137008667
INFO:root:current mean train loss 1738.19609847885
INFO:root:current train perplexity3.942692995071411
INFO:root:current mean train loss 1739.1708069352078
INFO:root:current train perplexity3.9448201656341553
INFO:root:current mean train loss 1740.3688826000418
INFO:root:current train perplexity3.9459645748138428
INFO:root:current mean train loss 1739.9747130049036
INFO:root:current train perplexity3.946704626083374
INFO:root:current mean train loss 1741.0251773657387
INFO:root:current train perplexity3.9476563930511475
INFO:root:current mean train loss 1740.7487069645283
INFO:root:current train perplexity3.9457006454467773
INFO:root:current mean train loss 1740.4953463370339
INFO:root:current train perplexity3.944824457168579
INFO:root:current mean train loss 1739.3560699294285
INFO:root:current train perplexity3.944690465927124
INFO:root:current mean train loss 1740.071224128763
INFO:root:current train perplexity3.9440720081329346

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:07<00:00, 427.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:07<00:00, 427.15s/it]
INFO:root:final mean train loss: 1739.8062294456493
INFO:root:final train perplexity: 3.94368577003479
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.83s/it]
INFO:root:eval mean loss: 2898.3270340653153
INFO:root:eval perplexity: 10.786428451538086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/84
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [11:29:35<2:09:28, 485.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1720.1495090060764
INFO:root:current train perplexity3.9229557514190674
INFO:root:current mean train loss 1723.3033139686884
INFO:root:current train perplexity3.923128604888916
INFO:root:current mean train loss 1731.3328384197755
INFO:root:current train perplexity3.9360175132751465
INFO:root:current mean train loss 1735.700335674694
INFO:root:current train perplexity3.936556100845337
INFO:root:current mean train loss 1734.9110093127927
INFO:root:current train perplexity3.9287939071655273
INFO:root:current mean train loss 1733.2259206464214
INFO:root:current train perplexity3.9306325912475586
INFO:root:current mean train loss 1733.7105921208383
INFO:root:current train perplexity3.934972047805786
INFO:root:current mean train loss 1733.581207821097
INFO:root:current train perplexity3.9339089393615723
INFO:root:current mean train loss 1733.7829764019045
INFO:root:current train perplexity3.9338550567626953
INFO:root:current mean train loss 1735.2424207109207
INFO:root:current train perplexity3.934365749359131
INFO:root:current mean train loss 1735.3495668227392
INFO:root:current train perplexity3.9333293437957764
INFO:root:current mean train loss 1737.1334779835847
INFO:root:current train perplexity3.9363670349121094
INFO:root:current mean train loss 1737.7039789947535
INFO:root:current train perplexity3.9363112449645996
INFO:root:current mean train loss 1738.1560204857349
INFO:root:current train perplexity3.9377598762512207
INFO:root:current mean train loss 1739.6090631946117
INFO:root:current train perplexity3.9399335384368896
INFO:root:current mean train loss 1739.9876962398187
INFO:root:current train perplexity3.9395675659179688
INFO:root:current mean train loss 1740.0582236376142
INFO:root:current train perplexity3.939629554748535
INFO:root:current mean train loss 1739.977946976671
INFO:root:current train perplexity3.9407339096069336
INFO:root:current mean train loss 1739.1176984982212
INFO:root:current train perplexity3.9397380352020264
INFO:root:current mean train loss 1738.8567593252344
INFO:root:current train perplexity3.9396560192108154

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.72s/it]
INFO:root:final mean train loss: 1738.6362195421336
INFO:root:final train perplexity: 3.940048933029175
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.87s/it]
INFO:root:eval mean loss: 2897.803345826295
INFO:root:eval perplexity: 10.781795501708984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/85
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [11:37:43<2:01:35, 486.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1711.4732693758879
INFO:root:current train perplexity3.928403854370117
INFO:root:current mean train loss 1713.7814068264431
INFO:root:current train perplexity3.934922456741333
INFO:root:current mean train loss 1729.8971317478868
INFO:root:current train perplexity3.948025941848755
INFO:root:current mean train loss 1730.9583449252816
INFO:root:current train perplexity3.935248374938965
INFO:root:current mean train loss 1733.412618001302
INFO:root:current train perplexity3.9369592666625977
INFO:root:current mean train loss 1737.0902027803309
INFO:root:current train perplexity3.938685655593872
INFO:root:current mean train loss 1740.4582483516717
INFO:root:current train perplexity3.93815016746521
INFO:root:current mean train loss 1738.0053525535009
INFO:root:current train perplexity3.9334681034088135
INFO:root:current mean train loss 1739.6969406344879
INFO:root:current train perplexity3.9359288215637207
INFO:root:current mean train loss 1738.2088995464778
INFO:root:current train perplexity3.9341349601745605
INFO:root:current mean train loss 1737.1403835486635
INFO:root:current train perplexity3.9373764991760254
INFO:root:current mean train loss 1737.0557536945475
INFO:root:current train perplexity3.9354248046875
INFO:root:current mean train loss 1737.033618792077
INFO:root:current train perplexity3.9356391429901123
INFO:root:current mean train loss 1736.2103286924817
INFO:root:current train perplexity3.935807228088379
INFO:root:current mean train loss 1737.1965671021521
INFO:root:current train perplexity3.937102794647217
INFO:root:current mean train loss 1737.2238414546987
INFO:root:current train perplexity3.9361960887908936
INFO:root:current mean train loss 1737.4770316984823
INFO:root:current train perplexity3.9355430603027344
INFO:root:current mean train loss 1737.6160477104536
INFO:root:current train perplexity3.934654951095581
INFO:root:current mean train loss 1737.7535295796756
INFO:root:current train perplexity3.9356017112731934
INFO:root:current mean train loss 1737.8286731233322
INFO:root:current train perplexity3.934450149536133

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:07<00:00, 427.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:07<00:00, 427.28s/it]
INFO:root:final mean train loss: 1736.7648073812957
INFO:root:final train perplexity: 3.9342377185821533
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.12s/it]
INFO:root:eval mean loss: 2899.3565068975226
INFO:root:eval perplexity: 10.795546531677246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/86
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [11:45:52<1:53:40, 487.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1731.6273673636015
INFO:root:current train perplexity3.9172489643096924
INFO:root:current mean train loss 1718.6408926448466
INFO:root:current train perplexity3.912285804748535
INFO:root:current mean train loss 1723.3434403810465
INFO:root:current train perplexity3.9118897914886475
INFO:root:current mean train loss 1726.468257999156
INFO:root:current train perplexity3.915747880935669
INFO:root:current mean train loss 1726.8333475439772
INFO:root:current train perplexity3.92195463180542
INFO:root:current mean train loss 1728.05579440139
INFO:root:current train perplexity3.9281210899353027
INFO:root:current mean train loss 1728.9181308948325
INFO:root:current train perplexity3.92728853225708
INFO:root:current mean train loss 1729.7889527810858
INFO:root:current train perplexity3.9276063442230225
INFO:root:current mean train loss 1731.6636015817817
INFO:root:current train perplexity3.929356098175049
INFO:root:current mean train loss 1731.9666815369733
INFO:root:current train perplexity3.927056312561035
INFO:root:current mean train loss 1733.333442249352
INFO:root:current train perplexity3.9313576221466064
INFO:root:current mean train loss 1734.5650616891419
INFO:root:current train perplexity3.9314780235290527
INFO:root:current mean train loss 1733.9833594253382
INFO:root:current train perplexity3.9282357692718506
INFO:root:current mean train loss 1734.570705439044
INFO:root:current train perplexity3.929896116256714
INFO:root:current mean train loss 1735.6601936815537
INFO:root:current train perplexity3.934312582015991
INFO:root:current mean train loss 1735.9271872872957
INFO:root:current train perplexity3.9333982467651367
INFO:root:current mean train loss 1735.6375068053649
INFO:root:current train perplexity3.931502342224121
INFO:root:current mean train loss 1735.6039025622426
INFO:root:current train perplexity3.931109666824341
INFO:root:current mean train loss 1736.1204029146795
INFO:root:current train perplexity3.93119740486145
INFO:root:current mean train loss 1736.6938411823528
INFO:root:current train perplexity3.932615280151367

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:10<00:00, 430.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:10<00:00, 430.83s/it]
INFO:root:final mean train loss: 1736.1533876573926
INFO:root:final train perplexity: 3.9323410987854004
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.23s/it]
INFO:root:eval mean loss: 2899.071682766751
INFO:root:eval perplexity: 10.793022155761719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/87
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [11:53:57<1:45:23, 486.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1739.7194652068308
INFO:root:current train perplexity3.9381134510040283
INFO:root:current mean train loss 1737.044936962342
INFO:root:current train perplexity3.913547992706299
INFO:root:current mean train loss 1739.3200995356058
INFO:root:current train perplexity3.917219877243042
INFO:root:current mean train loss 1740.4619909215855
INFO:root:current train perplexity3.9260597229003906
INFO:root:current mean train loss 1740.9006659216461
INFO:root:current train perplexity3.9279749393463135
INFO:root:current mean train loss 1739.643915829774
INFO:root:current train perplexity3.929762601852417
INFO:root:current mean train loss 1738.324872132248
INFO:root:current train perplexity3.9285616874694824
INFO:root:current mean train loss 1735.173667142814
INFO:root:current train perplexity3.9253413677215576
INFO:root:current mean train loss 1733.8141579595406
INFO:root:current train perplexity3.9221487045288086
INFO:root:current mean train loss 1732.781082871014
INFO:root:current train perplexity3.921140193939209
INFO:root:current mean train loss 1733.3826965445269
INFO:root:current train perplexity3.9209158420562744
INFO:root:current mean train loss 1733.9303217889499
INFO:root:current train perplexity3.919142484664917
INFO:root:current mean train loss 1734.1724381663244
INFO:root:current train perplexity3.919189691543579
INFO:root:current mean train loss 1732.6553823972129
INFO:root:current train perplexity3.918236255645752
INFO:root:current mean train loss 1733.3339789239576
INFO:root:current train perplexity3.9219236373901367
INFO:root:current mean train loss 1733.714603167825
INFO:root:current train perplexity3.9224343299865723
INFO:root:current mean train loss 1734.8731180948068
INFO:root:current train perplexity3.9252548217773438
INFO:root:current mean train loss 1734.336993497456
INFO:root:current train perplexity3.925734043121338
INFO:root:current mean train loss 1734.5172223790894
INFO:root:current train perplexity3.9263274669647217
INFO:root:current mean train loss 1734.6811487643374
INFO:root:current train perplexity3.926530122756958

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.17s/it]
INFO:root:final mean train loss: 1734.2449576281203
INFO:root:final train perplexity: 3.9264276027679443
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.75s/it]
INFO:root:eval mean loss: 2900.6312677423516
INFO:root:eval perplexity: 10.806843757629395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/88
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [12:02:26<1:38:37, 493.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1754.3851048519737
INFO:root:current train perplexity3.9611027240753174
INFO:root:current mean train loss 1745.409185947516
INFO:root:current train perplexity3.9365484714508057
INFO:root:current mean train loss 1742.3193793862554
INFO:root:current train perplexity3.938140630722046
INFO:root:current mean train loss 1736.3784173506724
INFO:root:current train perplexity3.926208734512329
INFO:root:current mean train loss 1734.4000236742424
INFO:root:current train perplexity3.918302536010742
INFO:root:current mean train loss 1731.6557974166228
INFO:root:current train perplexity3.9118847846984863
INFO:root:current mean train loss 1732.3543954094537
INFO:root:current train perplexity3.918229103088379
INFO:root:current mean train loss 1734.2548875724744
INFO:root:current train perplexity3.920707941055298
INFO:root:current mean train loss 1734.0109595954086
INFO:root:current train perplexity3.923731565475464
INFO:root:current mean train loss 1733.4466829999608
INFO:root:current train perplexity3.921616554260254
INFO:root:current mean train loss 1734.0115838595177
INFO:root:current train perplexity3.922130823135376
INFO:root:current mean train loss 1733.2436049457374
INFO:root:current train perplexity3.919983386993408
INFO:root:current mean train loss 1733.1836619019969
INFO:root:current train perplexity3.919606924057007
INFO:root:current mean train loss 1731.566561047407
INFO:root:current train perplexity3.9195334911346436
INFO:root:current mean train loss 1732.265688117292
INFO:root:current train perplexity3.9175472259521484
INFO:root:current mean train loss 1732.0449416970757
INFO:root:current train perplexity3.9175972938537598
INFO:root:current mean train loss 1732.5094378716124
INFO:root:current train perplexity3.9195311069488525
INFO:root:current mean train loss 1733.3273502785514
INFO:root:current train perplexity3.923273801803589
INFO:root:current mean train loss 1733.6125912145449
INFO:root:current train perplexity3.9236061573028564

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.37s/it]
INFO:root:final mean train loss: 1733.2516552438894
INFO:root:final train perplexity: 3.9233527183532715
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.72s/it]
INFO:root:eval mean loss: 2900.8249870964714
INFO:root:eval perplexity: 10.808562278747559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/89
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [12:10:34<1:30:09, 491.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1716.0646464029949
INFO:root:current train perplexity3.885294198989868
INFO:root:current mean train loss 1739.4844131469727
INFO:root:current train perplexity3.930506706237793
INFO:root:current mean train loss 1731.9862584527934
INFO:root:current train perplexity3.9232540130615234
INFO:root:current mean train loss 1729.5480014116335
INFO:root:current train perplexity3.919584035873413
INFO:root:current mean train loss 1731.7010604710256
INFO:root:current train perplexity3.9247779846191406
INFO:root:current mean train loss 1730.2467777729034
INFO:root:current train perplexity3.920076847076416
INFO:root:current mean train loss 1728.0751502342473
INFO:root:current train perplexity3.916670799255371
INFO:root:current mean train loss 1727.4813179273283
INFO:root:current train perplexity3.914546489715576
INFO:root:current mean train loss 1726.854031717836
INFO:root:current train perplexity3.909775495529175
INFO:root:current mean train loss 1726.8384558694404
INFO:root:current train perplexity3.909217596054077
INFO:root:current mean train loss 1728.3519293140516
INFO:root:current train perplexity3.910443067550659
INFO:root:current mean train loss 1728.2732417703533
INFO:root:current train perplexity3.9128565788269043
INFO:root:current mean train loss 1728.4251406830135
INFO:root:current train perplexity3.9142661094665527
INFO:root:current mean train loss 1730.0777613942216
INFO:root:current train perplexity3.9146835803985596
INFO:root:current mean train loss 1731.3117078397497
INFO:root:current train perplexity3.915450096130371
INFO:root:current mean train loss 1731.5537210292916
INFO:root:current train perplexity3.91646671295166
INFO:root:current mean train loss 1730.747521942366
INFO:root:current train perplexity3.9161739349365234
INFO:root:current mean train loss 1731.3807522069628
INFO:root:current train perplexity3.918285608291626
INFO:root:current mean train loss 1731.492099989329
INFO:root:current train perplexity3.9181365966796875
INFO:root:current mean train loss 1732.631604565736
INFO:root:current train perplexity3.920360565185547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.47s/it]
INFO:root:final mean train loss: 1732.437524007777
INFO:root:final train perplexity: 3.920834541320801
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.42s/it]
INFO:root:eval mean loss: 2900.345045484938
INFO:root:eval perplexity: 10.804306030273438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/90
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [12:18:52<1:22:14, 493.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1713.402731007543
INFO:root:current train perplexity3.948052167892456
INFO:root:current mean train loss 1722.2500908430231
INFO:root:current train perplexity3.8952038288116455
INFO:root:current mean train loss 1730.286413201078
INFO:root:current train perplexity3.901124954223633
INFO:root:current mean train loss 1733.9477312731526
INFO:root:current train perplexity3.909670114517212
INFO:root:current mean train loss 1738.4001413625438
INFO:root:current train perplexity3.913252592086792
INFO:root:current mean train loss 1736.336628154906
INFO:root:current train perplexity3.9152307510375977
INFO:root:current mean train loss 1736.6404008486313
INFO:root:current train perplexity3.9184038639068604
INFO:root:current mean train loss 1735.4438794715577
INFO:root:current train perplexity3.9109408855438232
INFO:root:current mean train loss 1735.5590986705085
INFO:root:current train perplexity3.9131696224212646
INFO:root:current mean train loss 1733.6597423409748
INFO:root:current train perplexity3.91166353225708
INFO:root:current mean train loss 1733.51904320601
INFO:root:current train perplexity3.9115591049194336
INFO:root:current mean train loss 1731.316734726182
INFO:root:current train perplexity3.909679651260376
INFO:root:current mean train loss 1731.733340034454
INFO:root:current train perplexity3.911339044570923
INFO:root:current mean train loss 1731.155003302971
INFO:root:current train perplexity3.9132168292999268
INFO:root:current mean train loss 1730.3886199374563
INFO:root:current train perplexity3.9142324924468994
INFO:root:current mean train loss 1730.6883247929356
INFO:root:current train perplexity3.915614366531372
INFO:root:current mean train loss 1730.4094534277403
INFO:root:current train perplexity3.914522647857666
INFO:root:current mean train loss 1730.720119037264
INFO:root:current train perplexity3.9153590202331543
INFO:root:current mean train loss 1731.632761909898
INFO:root:current train perplexity3.916264533996582
INFO:root:current mean train loss 1731.3054425767075
INFO:root:current train perplexity3.91536283493042

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:14<00:00, 434.86s/it]
INFO:root:final mean train loss: 1730.7025728826864
INFO:root:final train perplexity: 3.915473461151123
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.77s/it]
INFO:root:eval mean loss: 2901.044850025807
INFO:root:eval perplexity: 10.810511589050293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/91
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [12:27:20<1:14:40, 497.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1730.86767578125
INFO:root:current train perplexity3.931248903274536
INFO:root:current mean train loss 1727.0864692583475
INFO:root:current train perplexity3.9121580123901367
INFO:root:current mean train loss 1729.5469008034806
INFO:root:current train perplexity3.9150986671447754
INFO:root:current mean train loss 1727.6688267702311
INFO:root:current train perplexity3.9094650745391846
INFO:root:current mean train loss 1729.4639358862632
INFO:root:current train perplexity3.918050765991211
INFO:root:current mean train loss 1729.685270316435
INFO:root:current train perplexity3.9175407886505127
INFO:root:current mean train loss 1729.7091914788118
INFO:root:current train perplexity3.9166791439056396
INFO:root:current mean train loss 1727.4976022837948
INFO:root:current train perplexity3.911975622177124
INFO:root:current mean train loss 1726.3435526097076
INFO:root:current train perplexity3.912531614303589
INFO:root:current mean train loss 1727.3802116023057
INFO:root:current train perplexity3.913095474243164
INFO:root:current mean train loss 1729.33353192127
INFO:root:current train perplexity3.916727304458618
INFO:root:current mean train loss 1729.6462964761943
INFO:root:current train perplexity3.9166572093963623
INFO:root:current mean train loss 1729.601826528485
INFO:root:current train perplexity3.913057327270508
INFO:root:current mean train loss 1729.9511259852688
INFO:root:current train perplexity3.9157581329345703
INFO:root:current mean train loss 1730.6426123992371
INFO:root:current train perplexity3.9151382446289062
INFO:root:current mean train loss 1730.814814282574
INFO:root:current train perplexity3.9155514240264893
INFO:root:current mean train loss 1730.276156790491
INFO:root:current train perplexity3.9149787425994873
INFO:root:current mean train loss 1730.34381306267
INFO:root:current train perplexity3.915092945098877
INFO:root:current mean train loss 1730.3519667339222
INFO:root:current train perplexity3.914330005645752
INFO:root:current mean train loss 1730.2189844803845
INFO:root:current train perplexity3.9134023189544678

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.01s/it]
INFO:root:final mean train loss: 1730.083809364461
INFO:root:final train perplexity: 3.9135630130767822
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.44s/it]
INFO:root:eval mean loss: 2902.0784813133446
INFO:root:eval perplexity: 10.819685935974121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/92
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [12:35:48<1:06:48, 501.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1724.0741431826636
INFO:root:current train perplexity3.8935546875
INFO:root:current mean train loss 1725.39785785324
INFO:root:current train perplexity3.8804118633270264
INFO:root:current mean train loss 1726.6851941242871
INFO:root:current train perplexity3.903357744216919
INFO:root:current mean train loss 1725.167745122568
INFO:root:current train perplexity3.90752911567688
INFO:root:current mean train loss 1730.9278577635664
INFO:root:current train perplexity3.91465425491333
INFO:root:current mean train loss 1732.021276877151
INFO:root:current train perplexity3.9176807403564453
INFO:root:current mean train loss 1732.1413981119792
INFO:root:current train perplexity3.9169859886169434
INFO:root:current mean train loss 1733.7760353738327
INFO:root:current train perplexity3.9153389930725098
INFO:root:current mean train loss 1733.6994954238485
INFO:root:current train perplexity3.9189321994781494
INFO:root:current mean train loss 1733.8736243956062
INFO:root:current train perplexity3.9197754859924316
INFO:root:current mean train loss 1734.2342422499705
INFO:root:current train perplexity3.921252965927124
INFO:root:current mean train loss 1732.4482534183885
INFO:root:current train perplexity3.9173543453216553
INFO:root:current mean train loss 1731.2553939034046
INFO:root:current train perplexity3.913978099822998
INFO:root:current mean train loss 1730.655829426128
INFO:root:current train perplexity3.9108808040618896
INFO:root:current mean train loss 1729.6876809777907
INFO:root:current train perplexity3.910979747772217
INFO:root:current mean train loss 1729.9356680081123
INFO:root:current train perplexity3.9119644165039062
INFO:root:current mean train loss 1729.649742397141
INFO:root:current train perplexity3.9105982780456543
INFO:root:current mean train loss 1729.38061835018
INFO:root:current train perplexity3.910254716873169
INFO:root:current mean train loss 1729.1569697758362
INFO:root:current train perplexity3.9091920852661133
INFO:root:current mean train loss 1730.0728816976368
INFO:root:current train perplexity3.911536455154419

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.28s/it]
INFO:root:final mean train loss: 1729.533006999929
INFO:root:final train perplexity: 3.911863327026367
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.27s/it]
INFO:root:eval mean loss: 2901.277567362284
INFO:root:eval perplexity: 10.812576293945312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/93
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [12:43:54<57:54, 496.32s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1717.9678268432617
INFO:root:current train perplexity3.902810573577881
INFO:root:current mean train loss 1727.231672498915
INFO:root:current train perplexity3.8978676795959473
INFO:root:current mean train loss 1730.3624289376396
INFO:root:current train perplexity3.8982932567596436
INFO:root:current mean train loss 1729.8261073062295
INFO:root:current train perplexity3.912400007247925
INFO:root:current mean train loss 1728.4482610066732
INFO:root:current train perplexity3.9088873863220215
INFO:root:current mean train loss 1728.0684248299435
INFO:root:current train perplexity3.908770799636841
INFO:root:current mean train loss 1727.805856143727
INFO:root:current train perplexity3.9077789783477783
INFO:root:current mean train loss 1727.3712727864583
INFO:root:current train perplexity3.9087278842926025
INFO:root:current mean train loss 1726.5554765181107
INFO:root:current train perplexity3.905287504196167
INFO:root:current mean train loss 1726.316811324139
INFO:root:current train perplexity3.9051663875579834
INFO:root:current mean train loss 1726.0287590874566
INFO:root:current train perplexity3.904099464416504
INFO:root:current mean train loss 1725.322875355866
INFO:root:current train perplexity3.903830051422119
INFO:root:current mean train loss 1726.4071835517884
INFO:root:current train perplexity3.9060487747192383
INFO:root:current mean train loss 1726.8510971290477
INFO:root:current train perplexity3.9045066833496094
INFO:root:current mean train loss 1728.5378859236434
INFO:root:current train perplexity3.9063355922698975
INFO:root:current mean train loss 1728.7048658153678
INFO:root:current train perplexity3.906013250350952
INFO:root:current mean train loss 1728.0371733165923
INFO:root:current train perplexity3.9058265686035156
INFO:root:current mean train loss 1728.505465115322
INFO:root:current train perplexity3.9061334133148193
INFO:root:current mean train loss 1727.9620955446933
INFO:root:current train perplexity3.9055368900299072
INFO:root:current mean train loss 1728.1921706074415
INFO:root:current train perplexity3.9063992500305176

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:10<00:00, 430.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:10<00:00, 430.90s/it]
INFO:root:final mean train loss: 1727.74847002746
INFO:root:final train perplexity: 3.9063615798950195
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.79s/it]
INFO:root:eval mean loss: 2903.5018959389076
INFO:root:eval perplexity: 10.832330703735352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/94
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [12:52:22<50:00, 500.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1729.3625450527545
INFO:root:current train perplexity3.924813985824585
INFO:root:current mean train loss 1730.0640453977633
INFO:root:current train perplexity3.9201581478118896
INFO:root:current mean train loss 1730.3104239826653
INFO:root:current train perplexity3.9065799713134766
INFO:root:current mean train loss 1730.3788481359218
INFO:root:current train perplexity3.914191484451294
INFO:root:current mean train loss 1730.2381250392982
INFO:root:current train perplexity3.911707878112793
INFO:root:current mean train loss 1731.0548238834144
INFO:root:current train perplexity3.9042341709136963
INFO:root:current mean train loss 1729.4685076107426
INFO:root:current train perplexity3.8992786407470703
INFO:root:current mean train loss 1727.7043734254921
INFO:root:current train perplexity3.900162935256958
INFO:root:current mean train loss 1728.2781363224638
INFO:root:current train perplexity3.900331974029541
INFO:root:current mean train loss 1728.3905177446402
INFO:root:current train perplexity3.902121067047119
INFO:root:current mean train loss 1728.760078868327
INFO:root:current train perplexity3.9049479961395264
INFO:root:current mean train loss 1728.2774189094155
INFO:root:current train perplexity3.904667854309082
INFO:root:current mean train loss 1728.668867759734
INFO:root:current train perplexity3.9068963527679443
INFO:root:current mean train loss 1728.271337313915
INFO:root:current train perplexity3.904183864593506
INFO:root:current mean train loss 1728.1802285397619
INFO:root:current train perplexity3.904827117919922
INFO:root:current mean train loss 1728.5190300508523
INFO:root:current train perplexity3.905682325363159
INFO:root:current mean train loss 1728.1938128406748
INFO:root:current train perplexity3.905944347381592
INFO:root:current mean train loss 1728.1287400251504
INFO:root:current train perplexity3.906769037246704
INFO:root:current mean train loss 1728.5033893333841
INFO:root:current train perplexity3.9083235263824463

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:11<00:00, 431.91s/it]
INFO:root:final mean train loss: 1727.3359893321751
INFO:root:final train perplexity: 3.9050915241241455
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.90s/it]
INFO:root:eval mean loss: 2902.5199183558557
INFO:root:eval perplexity: 10.823604583740234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/95
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [13:00:54<41:58, 503.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1696.328159877232
INFO:root:current train perplexity3.8343753814697266
INFO:root:current mean train loss 1717.1919234426398
INFO:root:current train perplexity3.870201826095581
INFO:root:current mean train loss 1721.1403683100905
INFO:root:current train perplexity3.867893934249878
INFO:root:current mean train loss 1720.251627733753
INFO:root:current train perplexity3.871805429458618
INFO:root:current mean train loss 1719.247656191029
INFO:root:current train perplexity3.8717033863067627
INFO:root:current mean train loss 1721.175227421267
INFO:root:current train perplexity3.8787283897399902
INFO:root:current mean train loss 1722.8606352666302
INFO:root:current train perplexity3.8892934322357178
INFO:root:current mean train loss 1724.8421379538142
INFO:root:current train perplexity3.8890540599823
INFO:root:current mean train loss 1724.4616274821963
INFO:root:current train perplexity3.8903825283050537
INFO:root:current mean train loss 1725.2335462841477
INFO:root:current train perplexity3.8917505741119385
INFO:root:current mean train loss 1725.406311275926
INFO:root:current train perplexity3.890308380126953
INFO:root:current mean train loss 1726.1966735730266
INFO:root:current train perplexity3.8918747901916504
INFO:root:current mean train loss 1726.1926424381563
INFO:root:current train perplexity3.8934061527252197
INFO:root:current mean train loss 1725.6641964614846
INFO:root:current train perplexity3.8940212726593018
INFO:root:current mean train loss 1725.844064844717
INFO:root:current train perplexity3.8968794345855713
INFO:root:current mean train loss 1727.0305840959636
INFO:root:current train perplexity3.8977556228637695
INFO:root:current mean train loss 1727.0610294082055
INFO:root:current train perplexity3.899902582168579
INFO:root:current mean train loss 1727.6378451584378
INFO:root:current train perplexity3.9007012844085693
INFO:root:current mean train loss 1727.8313713031673
INFO:root:current train perplexity3.9004616737365723
INFO:root:current mean train loss 1727.7655732763724
INFO:root:current train perplexity3.9013290405273438

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.57s/it]
INFO:root:final mean train loss: 1726.2764888576828
INFO:root:final train perplexity: 3.901829481124878
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:53<00:00, 53.24s/it]
INFO:root:eval mean loss: 2902.690663563955
INFO:root:eval perplexity: 10.825124740600586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/96
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [13:09:11<33:26, 501.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1743.0540062689013
INFO:root:current train perplexity3.9503707885742188
INFO:root:current mean train loss 1732.1283788317032
INFO:root:current train perplexity3.940791606903076
INFO:root:current mean train loss 1730.492837484781
INFO:root:current train perplexity3.925621271133423
INFO:root:current mean train loss 1730.084974582822
INFO:root:current train perplexity3.914484977722168
INFO:root:current mean train loss 1733.5965140004168
INFO:root:current train perplexity3.91727352142334
INFO:root:current mean train loss 1732.1900685340895
INFO:root:current train perplexity3.912996530532837
INFO:root:current mean train loss 1731.156633621917
INFO:root:current train perplexity3.9085569381713867
INFO:root:current mean train loss 1730.3667321159478
INFO:root:current train perplexity3.9058690071105957
INFO:root:current mean train loss 1729.833310270711
INFO:root:current train perplexity3.9062209129333496
INFO:root:current mean train loss 1728.3174023489946
INFO:root:current train perplexity3.9038925170898438
INFO:root:current mean train loss 1727.2810455233466
INFO:root:current train perplexity3.90303635597229
INFO:root:current mean train loss 1726.8733133574062
INFO:root:current train perplexity3.9017021656036377
INFO:root:current mean train loss 1727.2940111570877
INFO:root:current train perplexity3.9019694328308105
INFO:root:current mean train loss 1727.2284516091636
INFO:root:current train perplexity3.901156425476074
INFO:root:current mean train loss 1725.7817300067425
INFO:root:current train perplexity3.901050090789795
INFO:root:current mean train loss 1725.5644630915506
INFO:root:current train perplexity3.902021646499634
INFO:root:current mean train loss 1727.2540240542132
INFO:root:current train perplexity3.905130624771118
INFO:root:current mean train loss 1727.1462589927246
INFO:root:current train perplexity3.9031450748443604
INFO:root:current mean train loss 1726.5079835051074
INFO:root:current train perplexity3.902486801147461
INFO:root:current mean train loss 1726.4659791745898
INFO:root:current train perplexity3.9016058444976807

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.78s/it]
INFO:root:final mean train loss: 1726.0614780689573
INFO:root:final train perplexity: 3.901167154312134
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.53s/it]
INFO:root:eval mean loss: 2903.3829459342155
INFO:root:eval perplexity: 10.831271171569824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/97
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [13:17:31<25:03, 501.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1725.0328521728516
INFO:root:current train perplexity3.9071543216705322
INFO:root:current mean train loss 1721.9563747096706
INFO:root:current train perplexity3.9154930114746094
INFO:root:current mean train loss 1726.551043110509
INFO:root:current train perplexity3.9216535091400146
INFO:root:current mean train loss 1724.0580009372754
INFO:root:current train perplexity3.904430389404297
INFO:root:current mean train loss 1727.782345363072
INFO:root:current train perplexity3.906794309616089
INFO:root:current mean train loss 1728.7606450658645
INFO:root:current train perplexity3.898688793182373
INFO:root:current mean train loss 1730.1074128327546
INFO:root:current train perplexity3.8997347354888916
INFO:root:current mean train loss 1729.9626706373244
INFO:root:current train perplexity3.8983020782470703
INFO:root:current mean train loss 1728.042434548432
INFO:root:current train perplexity3.899902105331421
INFO:root:current mean train loss 1728.0888774887921
INFO:root:current train perplexity3.900367498397827
INFO:root:current mean train loss 1727.8139562242814
INFO:root:current train perplexity3.901212215423584
INFO:root:current mean train loss 1725.8336770725582
INFO:root:current train perplexity3.9008803367614746
INFO:root:current mean train loss 1726.4637979360728
INFO:root:current train perplexity3.9000024795532227
INFO:root:current mean train loss 1727.549275836888
INFO:root:current train perplexity3.901128053665161
INFO:root:current mean train loss 1727.1080755581513
INFO:root:current train perplexity3.9007537364959717
INFO:root:current mean train loss 1726.324839431802
INFO:root:current train perplexity3.899024248123169
INFO:root:current mean train loss 1726.5280783199569
INFO:root:current train perplexity3.8986051082611084
INFO:root:current mean train loss 1726.403575626609
INFO:root:current train perplexity3.8986265659332275
INFO:root:current mean train loss 1725.6801350250905
INFO:root:current train perplexity3.8991079330444336
INFO:root:current mean train loss 1725.3931733117702
INFO:root:current train perplexity3.899064779281616

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:22<00:00, 442.42s/it]
INFO:root:final mean train loss: 1725.3366213522952
INFO:root:final train perplexity: 3.898937940597534
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.13s/it]
INFO:root:eval mean loss: 2903.154123850413
INFO:root:eval perplexity: 10.829239845275879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/98
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [13:25:48<16:39, 499.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1727.5926250751202
INFO:root:current train perplexity3.872927188873291
INFO:root:current mean train loss 1722.7367949514678
INFO:root:current train perplexity3.894888401031494
INFO:root:current mean train loss 1722.5079405586675
INFO:root:current train perplexity3.8994925022125244
INFO:root:current mean train loss 1722.4660968937285
INFO:root:current train perplexity3.9018030166625977
INFO:root:current mean train loss 1726.1127367901545
INFO:root:current train perplexity3.904242515563965
INFO:root:current mean train loss 1729.5348049467643
INFO:root:current train perplexity3.9029483795166016
INFO:root:current mean train loss 1728.8379014552984
INFO:root:current train perplexity3.8987584114074707
INFO:root:current mean train loss 1729.3482389961193
INFO:root:current train perplexity3.8988611698150635
INFO:root:current mean train loss 1729.3062913486724
INFO:root:current train perplexity3.900315761566162
INFO:root:current mean train loss 1728.9786927218265
INFO:root:current train perplexity3.9002721309661865
INFO:root:current mean train loss 1727.948328610989
INFO:root:current train perplexity3.8963303565979004
INFO:root:current mean train loss 1727.5155208473043
INFO:root:current train perplexity3.898914098739624
INFO:root:current mean train loss 1727.4858875138957
INFO:root:current train perplexity3.899388313293457
INFO:root:current mean train loss 1727.757076948117
INFO:root:current train perplexity3.900848150253296
INFO:root:current mean train loss 1726.6528060340231
INFO:root:current train perplexity3.8994264602661133
INFO:root:current mean train loss 1725.991341041833
INFO:root:current train perplexity3.8983054161071777
INFO:root:current mean train loss 1725.4055933130396
INFO:root:current train perplexity3.896303415298462
INFO:root:current mean train loss 1725.7958261635756
INFO:root:current train perplexity3.8967957496643066
INFO:root:current mean train loss 1725.2808608804248
INFO:root:current train perplexity3.8960397243499756
INFO:root:current mean train loss 1725.5803438841842
INFO:root:current train perplexity3.8976645469665527

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:19<00:00, 439.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:19<00:00, 439.91s/it]
INFO:root:final mean train loss: 1725.0858297727953
INFO:root:final train perplexity: 3.898167371749878
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.02s/it]
INFO:root:eval mean loss: 2903.3745080529748
INFO:root:eval perplexity: 10.831199645996094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/99
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [13:34:03<08:18, 498.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1721.0614356064216
INFO:root:current train perplexity3.857203960418701
INFO:root:current mean train loss 1715.9528064098986
INFO:root:current train perplexity3.870647430419922
INFO:root:current mean train loss 1720.5466334566156
INFO:root:current train perplexity3.880195379257202
INFO:root:current mean train loss 1722.0647822674657
INFO:root:current train perplexity3.8784658908843994
INFO:root:current mean train loss 1722.6588089179202
INFO:root:current train perplexity3.8793036937713623
INFO:root:current mean train loss 1723.2031503788794
INFO:root:current train perplexity3.8874411582946777
INFO:root:current mean train loss 1724.7573147323474
INFO:root:current train perplexity3.8918561935424805
INFO:root:current mean train loss 1725.5207380602121
INFO:root:current train perplexity3.8941729068756104
INFO:root:current mean train loss 1724.9161570715526
INFO:root:current train perplexity3.893693447113037
INFO:root:current mean train loss 1725.1484821265196
INFO:root:current train perplexity3.894015073776245
INFO:root:current mean train loss 1724.7630800257768
INFO:root:current train perplexity3.8929383754730225
INFO:root:current mean train loss 1724.7344783776505
INFO:root:current train perplexity3.8920772075653076
INFO:root:current mean train loss 1724.6666742524194
INFO:root:current train perplexity3.8920042514801025
INFO:root:current mean train loss 1724.962116158647
INFO:root:current train perplexity3.893146276473999
INFO:root:current mean train loss 1726.8429377629207
INFO:root:current train perplexity3.896688938140869
INFO:root:current mean train loss 1724.998119561621
INFO:root:current train perplexity3.894268751144409
INFO:root:current mean train loss 1723.9738810172971
INFO:root:current train perplexity3.89400315284729
INFO:root:current mean train loss 1723.757844010855
INFO:root:current train perplexity3.8937361240386963
INFO:root:current mean train loss 1724.5433515656134
INFO:root:current train perplexity3.895806074142456
INFO:root:current mean train loss 1725.223856135887
INFO:root:current train perplexity3.8971424102783203

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:13<00:00, 433.73s/it]
INFO:root:final mean train loss: 1724.7130595412568
INFO:root:final train perplexity: 3.8970210552215576
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:52<00:00, 52.73s/it]
INFO:root:eval mean loss: 2903.327296534816
INFO:root:eval perplexity: 10.830778121948242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_24/100
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [13:42:10<00:00, 494.92s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [13:42:10<00:00, 493.30s/it]
INFO:root:evaluating final model
INFO:root:start evaluating
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.04s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:54<00:00, 54.04s/it]
INFO:root:eval mean loss: 2903.327296534816
INFO:root:eval perplexity: 10.830778121948242
INFO:root:evalaution complete
INFO:root:save model final: std_24/final
