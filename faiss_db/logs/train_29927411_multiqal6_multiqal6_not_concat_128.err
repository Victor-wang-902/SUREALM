INFO:root:Output: multiqal6_multiqal6_not_concat_100e_128
INFO:root:Steps per epochs:992
INFO:root:Total steps:99200
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.query.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.self.query.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.query.bias', 'cls.predictions.decoder.weight', 'encoder.layer.5.crossattention.self.key.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24632.450737847223
INFO:root:current train perplexity16625.38671875
INFO:root:current mean train loss 20789.630888819094
INFO:root:current train perplexity3617.131591796875
INFO:root:current mean train loss 17929.946873693563
INFO:root:current train perplexity1174.9649658203125
INFO:root:current mean train loss 15992.085724565319
INFO:root:current train perplexity542.6629028320312
INFO:root:current mean train loss 14589.357906242172
INFO:root:current train perplexity312.1738586425781
INFO:root:current mean train loss 13526.906361677015
INFO:root:current train perplexity206.0193328857422
INFO:root:current mean train loss 12701.944138249955
INFO:root:current train perplexity148.81069946289062
INFO:root:current mean train loss 12039.993642565903
INFO:root:current train perplexity114.90868377685547
INFO:root:current mean train loss 11498.522105181974
INFO:root:current train perplexity92.86811828613281

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.19s/it]
INFO:root:final mean train loss: 11061.838442894721
INFO:root:final train perplexity: 78.58767700195312
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 27.00s/it]
INFO:root:eval mean loss: 6395.002711519282
INFO:root:eval perplexity: 13.27591323852539
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.86s/it]
INFO:root:eval mean loss: 6905.143260333555
INFO:root:eval perplexity: 16.83749008178711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/1
  1%|          | 1/100 [06:23<10:32:00, 383.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6800.462472098215
INFO:root:current train perplexity14.76167106628418
INFO:root:current mean train loss 6809.458455023365
INFO:root:current train perplexity14.328185081481934
INFO:root:current mean train loss 6712.221849524457
INFO:root:current train perplexity13.983262062072754
INFO:root:current mean train loss 6625.458558122964
INFO:root:current train perplexity13.609824180603027
INFO:root:current mean train loss 6556.23073988406
INFO:root:current train perplexity13.290528297424316
INFO:root:current mean train loss 6502.421537922214
INFO:root:current train perplexity12.969462394714355
INFO:root:current mean train loss 6447.808477913921
INFO:root:current train perplexity12.685128211975098
INFO:root:current mean train loss 6400.325327915046
INFO:root:current train perplexity12.44903564453125
INFO:root:current mean train loss 6351.71888492778
INFO:root:current train perplexity12.227574348449707
INFO:root:current mean train loss 6305.036682465374
INFO:root:current train perplexity12.016439437866211

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.88s/it]
INFO:root:final mean train loss: 6269.216108383671
INFO:root:final train perplexity: 11.862557411193848
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.90s/it]
INFO:root:eval mean loss: 5475.577879127881
INFO:root:eval perplexity: 9.153742790222168
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it]
INFO:root:eval mean loss: 6090.14356853945
INFO:root:eval perplexity: 12.065421104431152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/2
  2%|â–         | 2/100 [12:51<10:30:49, 386.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5861.007877604166
INFO:root:current train perplexity10.16102123260498
INFO:root:current mean train loss 5763.943635360054
INFO:root:current train perplexity9.86546802520752
INFO:root:current mean train loss 5767.860165334302
INFO:root:current train perplexity9.788458824157715
INFO:root:current mean train loss 5743.437087673611
INFO:root:current train perplexity9.681325912475586
INFO:root:current mean train loss 5729.847945689006
INFO:root:current train perplexity9.602254867553711
INFO:root:current mean train loss 5720.118051236347
INFO:root:current train perplexity9.533145904541016
INFO:root:current mean train loss 5693.536062944614
INFO:root:current train perplexity9.436627388000488
INFO:root:current mean train loss 5668.690905676355
INFO:root:current train perplexity9.356915473937988
INFO:root:current mean train loss 5655.620928393405
INFO:root:current train perplexity9.297718048095703
INFO:root:current mean train loss 5636.107927232752
INFO:root:current train perplexity9.220049858093262

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.71s/it]
INFO:root:final mean train loss: 5615.848655577629
INFO:root:final train perplexity: 9.167043685913086
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.94s/it]
INFO:root:eval mean loss: 5095.658210050975
INFO:root:eval perplexity: 7.850166320800781
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 5766.834767010195
INFO:root:eval perplexity: 10.571249961853027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/3
  3%|â–Ž         | 3/100 [19:16<10:23:35, 385.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5527.840862771739
INFO:root:current train perplexity8.559661865234375
INFO:root:current mean train loss 5417.461338446392
INFO:root:current train perplexity8.448992729187012
INFO:root:current mean train loss 5403.6926740295685
INFO:root:current train perplexity8.422719955444336
INFO:root:current mean train loss 5379.393042218943
INFO:root:current train perplexity8.341280937194824
INFO:root:current mean train loss 5372.805542857935
INFO:root:current train perplexity8.291071891784668
INFO:root:current mean train loss 5352.476649326302
INFO:root:current train perplexity8.235208511352539
INFO:root:current mean train loss 5343.435859594452
INFO:root:current train perplexity8.19764232635498
INFO:root:current mean train loss 5329.25990609872
INFO:root:current train perplexity8.160287857055664
INFO:root:current mean train loss 5310.778597380961
INFO:root:current train perplexity8.123300552368164
INFO:root:current mean train loss 5298.392400904828
INFO:root:current train perplexity8.077535629272461

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.74s/it]
INFO:root:final mean train loss: 5286.091963121968
INFO:root:final train perplexity: 8.048745155334473
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.74s/it]
INFO:root:eval mean loss: 4858.423007396941
INFO:root:eval perplexity: 7.132084369659424
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.55s/it]
INFO:root:eval mean loss: 5563.918245789007
INFO:root:eval perplexity: 9.729501724243164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/4
  4%|â–         | 4/100 [25:41<10:16:51, 385.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5109.179151965725
INFO:root:current train perplexity7.5728936195373535
INFO:root:current mean train loss 5128.584837935353
INFO:root:current train perplexity7.576070308685303
INFO:root:current mean train loss 5119.530011329816
INFO:root:current train perplexity7.560373783111572
INFO:root:current mean train loss 5122.9084583294
INFO:root:current train perplexity7.54609489440918
INFO:root:current mean train loss 5121.802220036978
INFO:root:current train perplexity7.525973320007324
INFO:root:current mean train loss 5101.525358440736
INFO:root:current train perplexity7.480144500732422
INFO:root:current mean train loss 5093.468184336619
INFO:root:current train perplexity7.457995414733887
INFO:root:current mean train loss 5091.700684929677
INFO:root:current train perplexity7.4434075355529785
INFO:root:current mean train loss 5078.954771994397
INFO:root:current train perplexity7.4095306396484375
INFO:root:current mean train loss 5071.683750566427
INFO:root:current train perplexity7.3888421058654785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.36s/it]
INFO:root:final mean train loss: 5065.73514409219
INFO:root:final train perplexity: 7.37856388092041
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.05s/it]
INFO:root:eval mean loss: 4736.005800504211
INFO:root:eval perplexity: 6.787628650665283
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it]
INFO:root:eval mean loss: 5465.14960106383
INFO:root:eval perplexity: 9.344377517700195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/5
  5%|â–Œ         | 5/100 [32:05<10:09:17, 384.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5045.663423978365
INFO:root:current train perplexity7.206459045410156
INFO:root:current mean train loss 4975.468915102293
INFO:root:current train perplexity7.089998722076416
INFO:root:current mean train loss 4970.422365324268
INFO:root:current train perplexity7.065722465515137
INFO:root:current mean train loss 4954.7470703125
INFO:root:current train perplexity7.044631481170654
INFO:root:current mean train loss 4945.316059225513
INFO:root:current train perplexity7.027101039886475
INFO:root:current mean train loss 4939.091952690167
INFO:root:current train perplexity7.0047125816345215
INFO:root:current mean train loss 4931.8076148950995
INFO:root:current train perplexity6.989588260650635
INFO:root:current mean train loss 4924.938853840706
INFO:root:current train perplexity6.975003719329834
INFO:root:current mean train loss 4920.467890997467
INFO:root:current train perplexity6.963650703430176
INFO:root:current mean train loss 4911.8755860415
INFO:root:current train perplexity6.940131187438965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.72s/it]
INFO:root:final mean train loss: 4911.918047628095
INFO:root:final train perplexity: 6.9441094398498535
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.07s/it]
INFO:root:eval mean loss: 4571.891395514738
INFO:root:eval perplexity: 6.351804256439209
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.88s/it]
INFO:root:eval mean loss: 5320.117848930629
INFO:root:eval perplexity: 8.806315422058105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/6
  6%|â–Œ         | 6/100 [38:29<10:02:19, 384.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4877.539862450133
INFO:root:current train perplexity6.783234119415283
INFO:root:current mean train loss 4828.5470992107785
INFO:root:current train perplexity6.727269172668457
INFO:root:current mean train loss 4840.209481552062
INFO:root:current train perplexity6.759521484375
INFO:root:current mean train loss 4860.683082250765
INFO:root:current train perplexity6.77590274810791
INFO:root:current mean train loss 4868.726673373707
INFO:root:current train perplexity6.800955295562744
INFO:root:current mean train loss 4860.18811905493
INFO:root:current train perplexity6.788217067718506
INFO:root:current mean train loss 4854.567102446991
INFO:root:current train perplexity6.78680419921875
INFO:root:current mean train loss 4858.462240563817
INFO:root:current train perplexity6.7885026931762695
INFO:root:current mean train loss 4857.356494025328
INFO:root:current train perplexity6.785847187042236
INFO:root:current mean train loss 4853.12974024675
INFO:root:current train perplexity6.774690628051758

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.96s/it]
INFO:root:final mean train loss: 4851.29211899542
INFO:root:final train perplexity: 6.779987335205078
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.05s/it]
INFO:root:eval mean loss: 4512.02555511691
INFO:root:eval perplexity: 6.199882507324219
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.79s/it]
INFO:root:eval mean loss: 5275.562562333776
INFO:root:eval perplexity: 8.647326469421387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/7
  7%|â–‹         | 7/100 [44:52<9:55:10, 383.99s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4801.025745738636
INFO:root:current train perplexity6.6280107498168945
INFO:root:current mean train loss 4796.334532510081
INFO:root:current train perplexity6.645015239715576
INFO:root:current mean train loss 4788.126789407169
INFO:root:current train perplexity6.633753299713135
INFO:root:current mean train loss 4785.771848178917
INFO:root:current train perplexity6.6268486976623535
INFO:root:current mean train loss 4783.956034834307
INFO:root:current train perplexity6.6110920906066895
INFO:root:current mean train loss 4777.933597709037
INFO:root:current train perplexity6.598667621612549
INFO:root:current mean train loss 4775.782884437619
INFO:root:current train perplexity6.590519428253174
INFO:root:current mean train loss 4771.218274976718
INFO:root:current train perplexity6.573578834533691
INFO:root:current mean train loss 4774.462151350055
INFO:root:current train perplexity6.5724077224731445
INFO:root:current mean train loss 4768.731167426783
INFO:root:current train perplexity6.556583404541016

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.53s/it]
INFO:root:final mean train loss: 4765.934526505009
INFO:root:final train perplexity: 6.555465221405029
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.81s/it]
INFO:root:eval mean loss: 4442.069625096964
INFO:root:eval perplexity: 6.0269598960876465
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it]
INFO:root:eval mean loss: 5214.758631496565
INFO:root:eval perplexity: 8.434972763061523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/8
  8%|â–Š         | 8/100 [51:15<9:48:27, 383.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4684.633091517857
INFO:root:current train perplexity6.292695045471191
INFO:root:current mean train loss 4696.7452430023
INFO:root:current train perplexity6.339962959289551
INFO:root:current mean train loss 4699.577096453185
INFO:root:current train perplexity6.343398094177246
INFO:root:current mean train loss 4698.209081224173
INFO:root:current train perplexity6.349522590637207
INFO:root:current mean train loss 4690.975765220032
INFO:root:current train perplexity6.3261518478393555
INFO:root:current mean train loss 4678.824633312056
INFO:root:current train perplexity6.312722206115723
INFO:root:current mean train loss 4675.840306991186
INFO:root:current train perplexity6.314076900482178
INFO:root:current mean train loss 4670.916530784117
INFO:root:current train perplexity6.303468227386475
INFO:root:current mean train loss 4665.650983012565
INFO:root:current train perplexity6.293852806091309
INFO:root:current mean train loss 4661.960107979621
INFO:root:current train perplexity6.2848052978515625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.42s/it]
INFO:root:final mean train loss: 4658.091263678766
INFO:root:final train perplexity: 6.282397747039795
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.07s/it]
INFO:root:eval mean loss: 4355.515391248337
INFO:root:eval perplexity: 5.819664478302002
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.82s/it]
INFO:root:eval mean loss: 5141.641837045656
INFO:root:eval perplexity: 8.186514854431152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/9
  9%|â–‰         | 9/100 [57:40<9:42:24, 384.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4614.545674928477
INFO:root:current train perplexity6.168553352355957
INFO:root:current mean train loss 4599.747682805647
INFO:root:current train perplexity6.132104873657227
INFO:root:current mean train loss 4590.95248987402
INFO:root:current train perplexity6.132325649261475
INFO:root:current mean train loss 4576.401359290769
INFO:root:current train perplexity6.104909420013428
INFO:root:current mean train loss 4586.170417413084
INFO:root:current train perplexity6.106324672698975
INFO:root:current mean train loss 4575.098294607186
INFO:root:current train perplexity6.093526840209961
INFO:root:current mean train loss 4572.464717131613
INFO:root:current train perplexity6.090744495391846
INFO:root:current mean train loss 4571.457071781777
INFO:root:current train perplexity6.074986457824707
INFO:root:current mean train loss 4573.7826929804105
INFO:root:current train perplexity6.075782775878906
INFO:root:current mean train loss 4575.122485426992
INFO:root:current train perplexity6.073552131652832

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.47s/it]
INFO:root:final mean train loss: 4572.879471563524
INFO:root:final train perplexity: 6.074704170227051
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.23s/it]
INFO:root:eval mean loss: 4302.624045946919
INFO:root:eval perplexity: 5.696516990661621
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.52s/it]
INFO:root:eval mean loss: 5096.635804521276
INFO:root:eval perplexity: 8.03722858428955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/10
 10%|â–ˆ         | 10/100 [1:04:01<9:34:47, 383.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4518.926009938687
INFO:root:current train perplexity5.897523880004883
INFO:root:current mean train loss 4513.784621595671
INFO:root:current train perplexity5.912569522857666
INFO:root:current mean train loss 4510.128695361504
INFO:root:current train perplexity5.920624256134033
INFO:root:current mean train loss 4509.521757503298
INFO:root:current train perplexity5.910548686981201
INFO:root:current mean train loss 4515.3408478356605
INFO:root:current train perplexity5.921472549438477
INFO:root:current mean train loss 4514.402714388358
INFO:root:current train perplexity5.919266700744629
INFO:root:current mean train loss 4512.3780968824785
INFO:root:current train perplexity5.918900489807129
INFO:root:current mean train loss 4509.91468460416
INFO:root:current train perplexity5.91474723815918
INFO:root:current mean train loss 4507.964930962919
INFO:root:current train perplexity5.910490036010742
INFO:root:current mean train loss 4503.545192699024
INFO:root:current train perplexity5.902361869812012

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.69s/it]
INFO:root:final mean train loss: 4501.222636438185
INFO:root:final train perplexity: 5.905372619628906
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.58s/it]
INFO:root:eval mean loss: 4253.126662234043
INFO:root:eval perplexity: 5.583631992340088
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.42s/it]
INFO:root:eval mean loss: 5053.969307541001
INFO:root:eval perplexity: 7.898219108581543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/11
 11%|â–ˆ         | 11/100 [1:10:23<9:27:48, 382.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4447.138318292026
INFO:root:current train perplexity5.821719646453857
INFO:root:current mean train loss 4454.747059867981
INFO:root:current train perplexity5.815483570098877
INFO:root:current mean train loss 4452.778189310214
INFO:root:current train perplexity5.8046770095825195
INFO:root:current mean train loss 4444.480791747416
INFO:root:current train perplexity5.785882472991943
INFO:root:current mean train loss 4443.582415758951
INFO:root:current train perplexity5.780112266540527
INFO:root:current mean train loss 4448.016889373936
INFO:root:current train perplexity5.775228023529053
INFO:root:current mean train loss 4449.810068544169
INFO:root:current train perplexity5.781073570251465
INFO:root:current mean train loss 4449.23096385602
INFO:root:current train perplexity5.780179500579834
INFO:root:current mean train loss 4445.528975666309
INFO:root:current train perplexity5.7708210945129395
INFO:root:current mean train loss 4442.831760889612
INFO:root:current train perplexity5.762701988220215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.36s/it]
INFO:root:final mean train loss: 4439.173604596046
INFO:root:final train perplexity: 5.762563228607178
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it]
INFO:root:eval mean loss: 4206.485093569925
INFO:root:eval perplexity: 5.47930908203125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it]
INFO:root:eval mean loss: 5018.277655418883
INFO:root:eval perplexity: 7.783784866333008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/12
 12%|â–ˆâ–        | 12/100 [1:16:44<9:20:54, 382.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4385.515535053454
INFO:root:current train perplexity5.671922206878662
INFO:root:current mean train loss 4383.816158353366
INFO:root:current train perplexity5.665267467498779
INFO:root:current mean train loss 4386.95210043697
INFO:root:current train perplexity5.651674747467041
INFO:root:current mean train loss 4387.239906175831
INFO:root:current train perplexity5.645088195800781
INFO:root:current mean train loss 4385.43851158065
INFO:root:current train perplexity5.643781661987305
INFO:root:current mean train loss 4390.083361508666
INFO:root:current train perplexity5.642782688140869
INFO:root:current mean train loss 4386.050938624101
INFO:root:current train perplexity5.640755653381348
INFO:root:current mean train loss 4384.258925412736
INFO:root:current train perplexity5.638448715209961
INFO:root:current mean train loss 4384.3414458035095
INFO:root:current train perplexity5.636938571929932

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.28s/it]
INFO:root:final mean train loss: 4385.909945826376
INFO:root:final train perplexity: 5.642732620239258
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.94s/it]
INFO:root:eval mean loss: 4163.688180477061
INFO:root:eval perplexity: 5.385300636291504
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.53s/it]
INFO:root:eval mean loss: 4982.090887840758
INFO:root:eval perplexity: 7.669454574584961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/13
 13%|â–ˆâ–Ž        | 13/100 [1:23:06<9:14:19, 382.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4515.71240234375
INFO:root:current train perplexity5.788931369781494
INFO:root:current mean train loss 4362.8032629513045
INFO:root:current train perplexity5.566936492919922
INFO:root:current mean train loss 4352.213832310268
INFO:root:current train perplexity5.550171852111816
INFO:root:current mean train loss 4343.93218450263
INFO:root:current train perplexity5.545650482177734
INFO:root:current mean train loss 4345.335628537919
INFO:root:current train perplexity5.544139862060547
INFO:root:current mean train loss 4348.891899093719
INFO:root:current train perplexity5.557421684265137
INFO:root:current mean train loss 4345.49168585782
INFO:root:current train perplexity5.55253791809082
INFO:root:current mean train loss 4340.254990470528
INFO:root:current train perplexity5.54502534866333
INFO:root:current mean train loss 4340.812184410998
INFO:root:current train perplexity5.542555332183838
INFO:root:current mean train loss 4338.814009994895
INFO:root:current train perplexity5.533782482147217

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.10s/it]
INFO:root:final mean train loss: 4335.05851241081
INFO:root:final train perplexity: 5.530654430389404
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.49s/it]
INFO:root:eval mean loss: 4131.44189453125
INFO:root:eval perplexity: 5.315535068511963
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.72s/it]
INFO:root:eval mean loss: 4955.651929922983
INFO:root:eval perplexity: 7.586984157562256
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/14
 14%|â–ˆâ–        | 14/100 [1:29:29<9:08:02, 382.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4414.716641512784
INFO:root:current train perplexity5.514276027679443
INFO:root:current mean train loss 4310.600418778153
INFO:root:current train perplexity5.469912528991699
INFO:root:current mean train loss 4305.957459363892
INFO:root:current train perplexity5.463856220245361
INFO:root:current mean train loss 4307.913109488042
INFO:root:current train perplexity5.462480545043945
INFO:root:current mean train loss 4291.368050011405
INFO:root:current train perplexity5.439264297485352
INFO:root:current mean train loss 4295.286430463399
INFO:root:current train perplexity5.439215660095215
INFO:root:current mean train loss 4295.282586580018
INFO:root:current train perplexity5.441196441650391
INFO:root:current mean train loss 4296.586749241825
INFO:root:current train perplexity5.439439296722412
INFO:root:current mean train loss 4297.42627826131
INFO:root:current train perplexity5.438979625701904
INFO:root:current mean train loss 4299.725068445133
INFO:root:current train perplexity5.444357395172119

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.27s/it]
INFO:root:final mean train loss: 4292.51607507275
INFO:root:final train perplexity: 5.438601016998291
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.09s/it]
INFO:root:eval mean loss: 4098.347138533355
INFO:root:eval perplexity: 5.244875431060791
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.80s/it]
INFO:root:eval mean loss: 4928.2487827598625
INFO:root:eval perplexity: 7.502443313598633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/15
 15%|â–ˆâ–Œ        | 15/100 [1:35:54<9:02:58, 383.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4209.078664679277
INFO:root:current train perplexity5.302687168121338
INFO:root:current mean train loss 4285.212223854385
INFO:root:current train perplexity5.3689398765563965
INFO:root:current mean train loss 4280.044745737015
INFO:root:current train perplexity5.373233318328857
INFO:root:current mean train loss 4270.163909433777
INFO:root:current train perplexity5.375903129577637
INFO:root:current mean train loss 4267.516752475201
INFO:root:current train perplexity5.372119903564453
INFO:root:current mean train loss 4263.221598777697
INFO:root:current train perplexity5.362053394317627
INFO:root:current mean train loss 4261.170018900192
INFO:root:current train perplexity5.358654975891113
INFO:root:current mean train loss 4263.670790798309
INFO:root:current train perplexity5.364131927490234
INFO:root:current mean train loss 4261.259978763641
INFO:root:current train perplexity5.361975193023682
INFO:root:current mean train loss 4261.644187487248
INFO:root:current train perplexity5.3629350662231445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.56s/it]
INFO:root:final mean train loss: 4253.665809385238
INFO:root:final train perplexity: 5.3558759689331055
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.90s/it]
INFO:root:eval mean loss: 4077.2470824329566
INFO:root:eval perplexity: 5.200314998626709
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.64s/it]
INFO:root:eval mean loss: 4913.228048121676
INFO:root:eval perplexity: 7.4565019607543945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/16
 16%|â–ˆâ–Œ        | 16/100 [1:42:20<8:57:26, 383.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4155.665717230902
INFO:root:current train perplexity5.099669933319092
INFO:root:current mean train loss 4226.284150851993
INFO:root:current train perplexity5.2562408447265625
INFO:root:current mean train loss 4244.096103214482
INFO:root:current train perplexity5.301995277404785
INFO:root:current mean train loss 4227.360053666141
INFO:root:current train perplexity5.280085563659668
INFO:root:current mean train loss 4215.256862810122
INFO:root:current train perplexity5.276635646820068
INFO:root:current mean train loss 4210.527934412802
INFO:root:current train perplexity5.269835472106934
INFO:root:current mean train loss 4212.10312702477
INFO:root:current train perplexity5.2675461769104
INFO:root:current mean train loss 4208.540507530412
INFO:root:current train perplexity5.2659454345703125
INFO:root:current mean train loss 4215.255842252683
INFO:root:current train perplexity5.2757720947265625
INFO:root:current mean train loss 4218.652976092654
INFO:root:current train perplexity5.277988433837891

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.89s/it]
INFO:root:final mean train loss: 4219.196361418693
INFO:root:final train perplexity: 5.283533573150635
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.96s/it]
INFO:root:eval mean loss: 4056.194102185838
INFO:root:eval perplexity: 5.156230926513672
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.52s/it]
INFO:root:eval mean loss: 4890.398472129876
INFO:root:eval perplexity: 7.387217044830322
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/17
 17%|â–ˆâ–‹        | 17/100 [1:48:44<8:51:19, 384.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4192.87433733259
INFO:root:current train perplexity5.279639720916748
INFO:root:current mean train loss 4189.683018663194
INFO:root:current train perplexity5.206158638000488
INFO:root:current mean train loss 4199.826136552527
INFO:root:current train perplexity5.217301368713379
INFO:root:current mean train loss 4189.7243805387125
INFO:root:current train perplexity5.211398124694824
INFO:root:current mean train loss 4199.343119163074
INFO:root:current train perplexity5.229315280914307
INFO:root:current mean train loss 4194.496801529644
INFO:root:current train perplexity5.230838775634766
INFO:root:current mean train loss 4201.439807225024
INFO:root:current train perplexity5.230720520019531
INFO:root:current mean train loss 4195.444663783482
INFO:root:current train perplexity5.22505521774292
INFO:root:current mean train loss 4193.460493661115
INFO:root:current train perplexity5.221930027008057
INFO:root:current mean train loss 4189.146289584726
INFO:root:current train perplexity5.216777801513672

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.32s/it]
INFO:root:final mean train loss: 4187.038512445265
INFO:root:final train perplexity: 5.216923236846924
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.79s/it]
INFO:root:eval mean loss: 4022.650750775709
INFO:root:eval perplexity: 5.086763858795166
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.65s/it]
INFO:root:eval mean loss: 4866.7955469442595
INFO:root:eval perplexity: 7.316262722015381
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/18
 18%|â–ˆâ–Š        | 18/100 [1:55:07<8:44:26, 383.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4100.350114689317
INFO:root:current train perplexity5.101778984069824
INFO:root:current mean train loss 4145.273843831949
INFO:root:current train perplexity5.136476993560791
INFO:root:current mean train loss 4146.296332465277
INFO:root:current train perplexity5.1381096839904785
INFO:root:current mean train loss 4154.398821861334
INFO:root:current train perplexity5.152780532836914
INFO:root:current mean train loss 4149.445594667043
INFO:root:current train perplexity5.146326541900635
INFO:root:current mean train loss 4152.9692985295815
INFO:root:current train perplexity5.1486496925354
INFO:root:current mean train loss 4157.876336508553
INFO:root:current train perplexity5.155115127563477
INFO:root:current mean train loss 4157.410304443031
INFO:root:current train perplexity5.154844284057617
INFO:root:current mean train loss 4162.293851479092
INFO:root:current train perplexity5.157500743865967
INFO:root:current mean train loss 4159.231092693697
INFO:root:current train perplexity5.1558837890625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.11s/it]
INFO:root:final mean train loss: 4156.333025593912
INFO:root:final train perplexity: 5.1541056632995605
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.95s/it]
INFO:root:eval mean loss: 4008.9393492353724
INFO:root:eval perplexity: 5.058638095855713
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it]
INFO:root:eval mean loss: 4860.138680532469
INFO:root:eval perplexity: 7.296374320983887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/19
 19%|â–ˆâ–‰        | 19/100 [2:01:32<8:38:31, 384.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4157.519114774816
INFO:root:current train perplexity5.122424602508545
INFO:root:current mean train loss 4144.232111444537
INFO:root:current train perplexity5.117579460144043
INFO:root:current mean train loss 4138.645205311566
INFO:root:current train perplexity5.10841703414917
INFO:root:current mean train loss 4128.376991380654
INFO:root:current train perplexity5.08976936340332
INFO:root:current mean train loss 4132.542862648975
INFO:root:current train perplexity5.092497825622559
INFO:root:current mean train loss 4132.849107358071
INFO:root:current train perplexity5.099359512329102
INFO:root:current mean train loss 4129.640014460925
INFO:root:current train perplexity5.097826957702637
INFO:root:current mean train loss 4130.548714344416
INFO:root:current train perplexity5.102080345153809
INFO:root:current mean train loss 4136.761828340739
INFO:root:current train perplexity5.10543966293335
INFO:root:current mean train loss 4131.7152049548995
INFO:root:current train perplexity5.0994768142700195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.73s/it]
INFO:root:final mean train loss: 4130.070356492073
INFO:root:final train perplexity: 5.100978374481201
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.67s/it]
INFO:root:eval mean loss: 3988.76650113586
INFO:root:eval perplexity: 5.017541408538818
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.52s/it]
INFO:root:eval mean loss: 4841.711304576685
INFO:root:eval perplexity: 7.24160099029541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/20
 20%|â–ˆâ–ˆ        | 20/100 [2:07:52<8:30:33, 382.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4093.1181599245233
INFO:root:current train perplexity5.032937049865723
INFO:root:current mean train loss 4098.743617027811
INFO:root:current train perplexity5.033924102783203
INFO:root:current mean train loss 4106.894568012488
INFO:root:current train perplexity5.044071197509766
INFO:root:current mean train loss 4110.226450290521
INFO:root:current train perplexity5.048730850219727
INFO:root:current mean train loss 4113.279453252655
INFO:root:current train perplexity5.054764747619629
INFO:root:current mean train loss 4114.268965228086
INFO:root:current train perplexity5.055125713348389
INFO:root:current mean train loss 4109.379679053253
INFO:root:current train perplexity5.049962997436523
INFO:root:current mean train loss 4106.490856467185
INFO:root:current train perplexity5.048567771911621
INFO:root:current mean train loss 4103.391807902539
INFO:root:current train perplexity5.046669006347656
INFO:root:current mean train loss 4106.339580516
INFO:root:current train perplexity5.045766353607178

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.14s/it]
INFO:root:final mean train loss: 4103.511212625811
INFO:root:final train perplexity: 5.047807216644287
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.47s/it]
INFO:root:eval mean loss: 3975.364266469969
INFO:root:eval perplexity: 4.990423202514648
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.59s/it]
INFO:root:eval mean loss: 4829.676096381871
INFO:root:eval perplexity: 7.206047534942627
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/21
 21%|â–ˆâ–ˆ        | 21/100 [2:14:13<8:23:10, 382.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4121.663023991371
INFO:root:current train perplexity5.055869102478027
INFO:root:current mean train loss 4108.779801237369
INFO:root:current train perplexity5.0431671142578125
INFO:root:current mean train loss 4100.913335564431
INFO:root:current train perplexity5.025479793548584
INFO:root:current mean train loss 4091.318128539041
INFO:root:current train perplexity5.01324462890625
INFO:root:current mean train loss 4095.300429938437
INFO:root:current train perplexity5.01664924621582
INFO:root:current mean train loss 4095.3049441275352
INFO:root:current train perplexity5.01638650894165
INFO:root:current mean train loss 4085.4865122370456
INFO:root:current train perplexity5.007143497467041
INFO:root:current mean train loss 4084.665505698949
INFO:root:current train perplexity5.00199031829834
INFO:root:current mean train loss 4085.075626712082
INFO:root:current train perplexity5.003629207611084
INFO:root:current mean train loss 4082.260326870718
INFO:root:current train perplexity4.9990949630737305

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.91s/it]
INFO:root:final mean train loss: 4078.348985856579
INFO:root:final train perplexity: 4.9979448318481445
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it]
INFO:root:eval mean loss: 3971.7231635776816
INFO:root:eval perplexity: 4.983080863952637
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.92s/it]
INFO:root:eval mean loss: 4829.4425421099295
INFO:root:eval perplexity: 7.205361366271973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/22
 22%|â–ˆâ–ˆâ–       | 22/100 [2:20:35<8:16:56, 382.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4056.2155403645834
INFO:root:current train perplexity4.920271873474121
INFO:root:current mean train loss 4057.473949497768
INFO:root:current train perplexity4.927488803863525
INFO:root:current mean train loss 4070.103008700284
INFO:root:current train perplexity4.9538702964782715
INFO:root:current mean train loss 4055.22325
INFO:root:current train perplexity4.944278240203857
INFO:root:current mean train loss 4060.87142526727
INFO:root:current train perplexity4.943182468414307
INFO:root:current mean train loss 4064.3635130774455
INFO:root:current train perplexity4.950644016265869
INFO:root:current mean train loss 4068.5594831452545
INFO:root:current train perplexity4.960574150085449
INFO:root:current mean train loss 4064.128351499496
INFO:root:current train perplexity4.958103179931641
INFO:root:current mean train loss 4061.69033203125
INFO:root:current train perplexity4.955723762512207
INFO:root:current mean train loss 4059.4944784154645
INFO:root:current train perplexity4.9537224769592285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.83s/it]
INFO:root:final mean train loss: 4055.9769800247686
INFO:root:final train perplexity: 4.954023838043213
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.65s/it]
INFO:root:eval mean loss: 3957.9327643644724
INFO:root:eval perplexity: 4.955369472503662
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it]
INFO:root:eval mean loss: 4817.745098141068
INFO:root:eval perplexity: 7.1709794998168945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/23
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [2:26:57<8:10:17, 382.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4034.3637371752634
INFO:root:current train perplexity4.909824371337891
INFO:root:current mean train loss 4046.8917416431864
INFO:root:current train perplexity4.932704448699951
INFO:root:current mean train loss 4050.5818129900067
INFO:root:current train perplexity4.930534839630127
INFO:root:current mean train loss 4056.691784253631
INFO:root:current train perplexity4.931200981140137
INFO:root:current mean train loss 4046.51074926404
INFO:root:current train perplexity4.922246932983398
INFO:root:current mean train loss 4041.979491768734
INFO:root:current train perplexity4.913113117218018
INFO:root:current mean train loss 4043.3701411368734
INFO:root:current train perplexity4.912245750427246
INFO:root:current mean train loss 4038.8178922962566
INFO:root:current train perplexity4.90863561630249
INFO:root:current mean train loss 4037.2968174900907
INFO:root:current train perplexity4.910374641418457
INFO:root:current mean train loss 4037.0986534266117
INFO:root:current train perplexity4.910572528839111

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.34s/it]
INFO:root:final mean train loss: 4032.979903744113
INFO:root:final train perplexity: 4.909279823303223
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.75s/it]
INFO:root:eval mean loss: 3957.754706200133
INFO:root:eval perplexity: 4.955013275146484
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it]
INFO:root:eval mean loss: 4822.2802180296985
INFO:root:eval perplexity: 7.184289455413818
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/24
 24%|â–ˆâ–ˆâ–       | 24/100 [2:33:19<8:03:55, 382.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4042.5300641741073
INFO:root:current train perplexity4.875322341918945
INFO:root:current mean train loss 4030.8290287037794
INFO:root:current train perplexity4.883769989013672
INFO:root:current mean train loss 4014.7177105146584
INFO:root:current train perplexity4.870736122131348
INFO:root:current mean train loss 4009.743054792399
INFO:root:current train perplexity4.87149715423584
INFO:root:current mean train loss 4016.9567254526796
INFO:root:current train perplexity4.875265121459961
INFO:root:current mean train loss 4016.114937770992
INFO:root:current train perplexity4.874764442443848
INFO:root:current mean train loss 4018.5633090912174
INFO:root:current train perplexity4.872220039367676
INFO:root:current mean train loss 4019.594414210651
INFO:root:current train perplexity4.871664047241211
INFO:root:current mean train loss 4016.2171243138855
INFO:root:current train perplexity4.870133399963379
INFO:root:current mean train loss 4016.061278065086
INFO:root:current train perplexity4.8707194328308105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.21s/it]
INFO:root:final mean train loss: 4013.066488204464
INFO:root:final train perplexity: 4.870862007141113
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it]
INFO:root:eval mean loss: 3910.961250900377
INFO:root:eval perplexity: 4.862135410308838
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.06s/it]
INFO:root:eval mean loss: 4776.88693345523
INFO:root:eval perplexity: 7.052164554595947
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/25
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [2:39:44<7:58:40, 382.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4010.9488463738953
INFO:root:current train perplexity4.852483749389648
INFO:root:current mean train loss 4000.232441504397
INFO:root:current train perplexity4.834782600402832
INFO:root:current mean train loss 4007.695583585911
INFO:root:current train perplexity4.838184356689453
INFO:root:current mean train loss 4000.5547768346646
INFO:root:current train perplexity4.8330841064453125
INFO:root:current mean train loss 3996.0246210193827
INFO:root:current train perplexity4.830387592315674
INFO:root:current mean train loss 3999.224317955055
INFO:root:current train perplexity4.832788467407227
INFO:root:current mean train loss 3996.853422020297
INFO:root:current train perplexity4.83314323425293
INFO:root:current mean train loss 3995.9436203213
INFO:root:current train perplexity4.8294572830200195
INFO:root:current mean train loss 3993.90490356038
INFO:root:current train perplexity4.831070899963379

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.24s/it]
INFO:root:final mean train loss: 3992.9265397594822
INFO:root:final train perplexity: 4.832311153411865
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.23s/it]
INFO:root:eval mean loss: 3902.9543318511746
INFO:root:eval perplexity: 4.846419334411621
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.14s/it]
INFO:root:eval mean loss: 4767.164252964318
INFO:root:eval perplexity: 7.024184703826904
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/26
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [2:46:07<7:52:35, 383.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3950.507080078125
INFO:root:current train perplexity4.691104888916016
INFO:root:current mean train loss 3967.904693888727
INFO:root:current train perplexity4.766050338745117
INFO:root:current mean train loss 3970.0831328313707
INFO:root:current train perplexity4.790921211242676
INFO:root:current mean train loss 3981.6464644938414
INFO:root:current train perplexity4.792088508605957
INFO:root:current mean train loss 3978.2792716811273
INFO:root:current train perplexity4.789485454559326
INFO:root:current mean train loss 3976.645589674248
INFO:root:current train perplexity4.789738655090332
INFO:root:current mean train loss 3975.0990108885912
INFO:root:current train perplexity4.791220188140869
INFO:root:current mean train loss 3979.7280798322577
INFO:root:current train perplexity4.7987589836120605
INFO:root:current mean train loss 3977.771753020446
INFO:root:current train perplexity4.798401355743408
INFO:root:current mean train loss 3980.3174735240664
INFO:root:current train perplexity4.8051533699035645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.17s/it]
INFO:root:final mean train loss: 3976.8237676312847
INFO:root:final train perplexity: 4.80171012878418
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it]
INFO:root:eval mean loss: 3902.854895625554
INFO:root:eval perplexity: 4.846224308013916
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.58s/it]
INFO:root:eval mean loss: 4766.276245982935
INFO:root:eval perplexity: 7.021634101867676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/27
 27%|â–ˆâ–ˆâ–‹       | 27/100 [2:52:24<7:43:48, 381.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3971.364501953125
INFO:root:current train perplexity4.7699713706970215
INFO:root:current mean train loss 3930.602829908288
INFO:root:current train perplexity4.750586986541748
INFO:root:current mean train loss 3952.8525776707847
INFO:root:current train perplexity4.75750207901001
INFO:root:current mean train loss 3960.9693607390873
INFO:root:current train perplexity4.768823623657227
INFO:root:current mean train loss 3955.936722279744
INFO:root:current train perplexity4.7683281898498535
INFO:root:current mean train loss 3957.127235190382
INFO:root:current train perplexity4.773038387298584
INFO:root:current mean train loss 3958.8931505652945
INFO:root:current train perplexity4.7736310958862305
INFO:root:current mean train loss 3965.067409104567
INFO:root:current train perplexity4.776410102844238
INFO:root:current mean train loss 3965.6162696510737
INFO:root:current train perplexity4.776457786560059
INFO:root:current mean train loss 3965.4992438311133
INFO:root:current train perplexity4.775744438171387

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.54s/it]
INFO:root:final mean train loss: 3962.8029710708124
INFO:root:final train perplexity: 4.775221824645996
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.76s/it]
INFO:root:eval mean loss: 3892.552188954455
INFO:root:eval perplexity: 4.826076030731201
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it]
INFO:root:eval mean loss: 4762.920867270612
INFO:root:eval perplexity: 7.01200532913208
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/28
 28%|â–ˆâ–ˆâ–Š       | 28/100 [2:58:47<7:38:09, 381.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3946.7617505944295
INFO:root:current train perplexity4.7291083335876465
INFO:root:current mean train loss 3932.3638032742633
INFO:root:current train perplexity4.72865104675293
INFO:root:current mean train loss 3938.547043599355
INFO:root:current train perplexity4.723265171051025
INFO:root:current mean train loss 3959.694791717057
INFO:root:current train perplexity4.745570182800293
INFO:root:current mean train loss 3954.5287658835696
INFO:root:current train perplexity4.7406005859375
INFO:root:current mean train loss 3951.8664975576603
INFO:root:current train perplexity4.740592956542969
INFO:root:current mean train loss 3952.9692970631017
INFO:root:current train perplexity4.745073318481445
INFO:root:current mean train loss 3951.3388486152535
INFO:root:current train perplexity4.73984956741333
INFO:root:current mean train loss 3948.7944481294617
INFO:root:current train perplexity4.739211082458496
INFO:root:current mean train loss 3949.125817593361
INFO:root:current train perplexity4.740866184234619

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.82s/it]
INFO:root:final mean train loss: 3945.351878935291
INFO:root:final train perplexity: 4.742457866668701
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.15s/it]
INFO:root:eval mean loss: 3883.0417186114805
INFO:root:eval perplexity: 4.807552337646484
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.69s/it]
INFO:root:eval mean loss: 4755.344911832336
INFO:root:eval perplexity: 6.990316390991211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/29
 29%|â–ˆâ–ˆâ–‰       | 29/100 [3:05:11<7:32:31, 382.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3871.6495873235885
INFO:root:current train perplexity4.6787238121032715
INFO:root:current mean train loss 3952.3915400614264
INFO:root:current train perplexity4.749282360076904
INFO:root:current mean train loss 3943.4223844189664
INFO:root:current train perplexity4.736286640167236
INFO:root:current mean train loss 3942.7507552870093
INFO:root:current train perplexity4.73806095123291
INFO:root:current mean train loss 3936.370064507504
INFO:root:current train perplexity4.720489025115967
INFO:root:current mean train loss 3942.227674236405
INFO:root:current train perplexity4.723933219909668
INFO:root:current mean train loss 3942.770502395751
INFO:root:current train perplexity4.724680423736572
INFO:root:current mean train loss 3939.8805888498205
INFO:root:current train perplexity4.724142551422119
INFO:root:current mean train loss 3935.755193056182
INFO:root:current train perplexity4.71834659576416
INFO:root:current mean train loss 3935.869258368438
INFO:root:current train perplexity4.717762470245361

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.14s/it]
INFO:root:final mean train loss: 3931.6948552900744
INFO:root:final train perplexity: 4.716973781585693
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.38s/it]
INFO:root:eval mean loss: 3890.150338680186
INFO:root:eval perplexity: 4.8213911056518555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.48s/it]
INFO:root:eval mean loss: 4762.072579025376
INFO:root:eval perplexity: 7.009573459625244
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/30
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [3:11:32<7:25:42, 382.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3943.413092197516
INFO:root:current train perplexity4.747282028198242
INFO:root:current mean train loss 3920.643159495841
INFO:root:current train perplexity4.689429759979248
INFO:root:current mean train loss 3915.500706884153
INFO:root:current train perplexity4.692182540893555
INFO:root:current mean train loss 3927.6480766904037
INFO:root:current train perplexity4.696558952331543
INFO:root:current mean train loss 3925.914619741244
INFO:root:current train perplexity4.696094989776611
INFO:root:current mean train loss 3927.312852848881
INFO:root:current train perplexity4.695582389831543
INFO:root:current mean train loss 3928.556212328223
INFO:root:current train perplexity4.697611331939697
INFO:root:current mean train loss 3932.0240120068293
INFO:root:current train perplexity4.703902244567871
INFO:root:current mean train loss 3925.683297522162
INFO:root:current train perplexity4.696483612060547
INFO:root:current mean train loss 3921.1104358027155
INFO:root:current train perplexity4.692917823791504

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.66s/it]
INFO:root:final mean train loss: 3918.282887797202
INFO:root:final train perplexity: 4.692080020904541
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it]
INFO:root:eval mean loss: 3878.36663515348
INFO:root:eval perplexity: 4.798472881317139
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.70s/it]
INFO:root:eval mean loss: 4755.498552471188
INFO:root:eval perplexity: 6.990755081176758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/31
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [3:17:55<7:19:44, 382.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3894.870797664561
INFO:root:current train perplexity4.668184280395508
INFO:root:current mean train loss 3912.331660887011
INFO:root:current train perplexity4.681856632232666
INFO:root:current mean train loss 3914.2091988629177
INFO:root:current train perplexity4.683263778686523
INFO:root:current mean train loss 3917.4723459732977
INFO:root:current train perplexity4.680120944976807
INFO:root:current mean train loss 3919.7832320723223
INFO:root:current train perplexity4.67769718170166
INFO:root:current mean train loss 3915.6843596463664
INFO:root:current train perplexity4.67332124710083
INFO:root:current mean train loss 3916.7931679868625
INFO:root:current train perplexity4.6756815910339355
INFO:root:current mean train loss 3910.495517878807
INFO:root:current train perplexity4.6678242683410645
INFO:root:current mean train loss 3907.1405918522173
INFO:root:current train perplexity4.663291931152344
INFO:root:current mean train loss 3907.658579261401
INFO:root:current train perplexity4.666227340698242

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.87s/it]
INFO:root:final mean train loss: 3904.2852608465378
INFO:root:final train perplexity: 4.6662397384643555
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.56s/it]
INFO:root:eval mean loss: 3849.5251741882757
INFO:root:eval perplexity: 4.742833614349365
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.24s/it]
INFO:root:eval mean loss: 4721.814884266955
INFO:root:eval perplexity: 6.8951263427734375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/32
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [3:24:12<7:11:28, 380.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3849.878786399148
INFO:root:current train perplexity4.598733901977539
INFO:root:current mean train loss 3881.8216355846776
INFO:root:current train perplexity4.627387523651123
INFO:root:current mean train loss 3883.24685680913
INFO:root:current train perplexity4.621868133544922
INFO:root:current mean train loss 3888.2722965724033
INFO:root:current train perplexity4.629524230957031
INFO:root:current mean train loss 3882.825724373283
INFO:root:current train perplexity4.622425556182861
INFO:root:current mean train loss 3886.2114948444537
INFO:root:current train perplexity4.629885673522949
INFO:root:current mean train loss 3905.3159425691792
INFO:root:current train perplexity4.658921241760254
INFO:root:current mean train loss 4041.3166187008487
INFO:root:current train perplexity4.919271945953369
INFO:root:current mean train loss 4066.0174290707237
INFO:root:current train perplexity4.966190814971924
INFO:root:current mean train loss 4080.0607912712694
INFO:root:current train perplexity4.997198104858398

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.36s/it]
INFO:root:final mean train loss: 4083.266234613234
INFO:root:final train perplexity: 5.007649898529053
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 3951.272369168329
INFO:root:eval perplexity: 4.942041397094727
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.07s/it]
INFO:root:eval mean loss: 4819.295501925421
INFO:root:eval perplexity: 7.1755266189575195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/33
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [3:30:29<7:03:55, 379.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4106.48779296875
INFO:root:current train perplexity5.083264350891113
INFO:root:current mean train loss 4133.695636023773
INFO:root:current train perplexity5.103583812713623
INFO:root:current mean train loss 4133.743579937025
INFO:root:current train perplexity5.1022443771362305
INFO:root:current mean train loss 4129.21340984418
INFO:root:current train perplexity5.088935852050781
INFO:root:current mean train loss 4135.542049136069
INFO:root:current train perplexity5.0915913581848145
INFO:root:current mean train loss 4131.629452205679
INFO:root:current train perplexity5.089947700500488
INFO:root:current mean train loss 4122.000600593302
INFO:root:current train perplexity5.078846454620361
INFO:root:current mean train loss 4122.446107316923
INFO:root:current train perplexity5.079562187194824
INFO:root:current mean train loss 4116.339503141295
INFO:root:current train perplexity5.070155620574951
INFO:root:current mean train loss 4117.164331992715
INFO:root:current train perplexity5.068510055541992

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.88s/it]
INFO:root:final mean train loss: 4113.351782275784
INFO:root:final train perplexity: 5.067442893981934
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.37s/it]
INFO:root:eval mean loss: 3929.5634471271055
INFO:root:eval perplexity: 4.898848533630371
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.10s/it]
INFO:root:eval mean loss: 4807.002244015957
INFO:root:eval perplexity: 7.139545440673828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/34
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [3:36:46<6:56:34, 378.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4047.5471707196302
INFO:root:current train perplexity4.966837406158447
INFO:root:current mean train loss 4058.2934370431285
INFO:root:current train perplexity4.967167377471924
INFO:root:current mean train loss 4067.606872333372
INFO:root:current train perplexity4.970829010009766
INFO:root:current mean train loss 4081.147269441754
INFO:root:current train perplexity4.989024639129639
INFO:root:current mean train loss 4082.425948157179
INFO:root:current train perplexity4.994764804840088
INFO:root:current mean train loss 4077.577984330533
INFO:root:current train perplexity4.99267053604126
INFO:root:current mean train loss 4074.78296480591
INFO:root:current train perplexity4.992194652557373
INFO:root:current mean train loss 4077.809755872041
INFO:root:current train perplexity4.991799354553223
INFO:root:current mean train loss 4075.844320689222
INFO:root:current train perplexity4.990737438201904
INFO:root:current mean train loss 4078.6288795981914
INFO:root:current train perplexity4.991132736206055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.55s/it]
INFO:root:final mean train loss: 4074.7287452451646
INFO:root:final train perplexity: 4.990810871124268
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.69s/it]
INFO:root:eval mean loss: 3917.620001177416
INFO:root:eval perplexity: 4.875246047973633
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.58s/it]
INFO:root:eval mean loss: 4797.558988530585
INFO:root:eval perplexity: 7.112030982971191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/35
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [3:43:09<6:51:39, 380.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4082.514404296875
INFO:root:current train perplexity5.038360118865967
INFO:root:current mean train loss 4073.261657373865
INFO:root:current train perplexity4.9917893409729
INFO:root:current mean train loss 4071.50050578237
INFO:root:current train perplexity4.9893269538879395
INFO:root:current mean train loss 4069.313799291928
INFO:root:current train perplexity4.982359886169434
INFO:root:current mean train loss 4067.209934433716
INFO:root:current train perplexity4.970262050628662
INFO:root:current mean train loss 4062.8254871006043
INFO:root:current train perplexity4.960380554199219
INFO:root:current mean train loss 4058.4591163331875
INFO:root:current train perplexity4.955119609832764
INFO:root:current mean train loss 4059.6626948110556
INFO:root:current train perplexity4.9513702392578125
INFO:root:current mean train loss 4058.183443765998
INFO:root:current train perplexity4.950852394104004
INFO:root:current mean train loss 4055.8503013977115
INFO:root:current train perplexity4.948669910430908

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.19s/it]
INFO:root:final mean train loss: 4052.557011204381
INFO:root:final train perplexity: 4.9473443031311035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.72s/it]
INFO:root:eval mean loss: 3905.5084064023713
INFO:root:eval perplexity: 4.851428031921387
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.74s/it]
INFO:root:eval mean loss: 4791.742403936724
INFO:root:eval perplexity: 7.095133304595947
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/36
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [3:49:32<6:46:14, 380.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4058.178365773168
INFO:root:current train perplexity4.922625541687012
INFO:root:current mean train loss 4055.023095442012
INFO:root:current train perplexity4.913506031036377
INFO:root:current mean train loss 4037.504415797855
INFO:root:current train perplexity4.895657062530518
INFO:root:current mean train loss 4029.452567324774
INFO:root:current train perplexity4.8948283195495605
INFO:root:current mean train loss 4029.136109651726
INFO:root:current train perplexity4.900051116943359
INFO:root:current mean train loss 4031.5662128506974
INFO:root:current train perplexity4.890771389007568
INFO:root:current mean train loss 4033.4597555324326
INFO:root:current train perplexity4.896629333496094
INFO:root:current mean train loss 4032.391558752581
INFO:root:current train perplexity4.8988871574401855
INFO:root:current mean train loss 4034.0484628774134
INFO:root:current train perplexity4.902966022491455
INFO:root:current mean train loss 4035.617704474576
INFO:root:current train perplexity4.908717632293701

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.16s/it]
INFO:root:final mean train loss: 4032.7424969826975
INFO:root:final train perplexity: 4.908819198608398
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.59s/it]
INFO:root:eval mean loss: 3898.6129055158467
INFO:root:eval perplexity: 4.837917804718018
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.72s/it]
INFO:root:eval mean loss: 4778.771790849401
INFO:root:eval perplexity: 7.057602405548096
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/37
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [3:55:58<6:41:43, 382.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4009.83734323602
INFO:root:current train perplexity4.8754096031188965
INFO:root:current mean train loss 4032.698498848157
INFO:root:current train perplexity4.886635780334473
INFO:root:current mean train loss 4024.326220703125
INFO:root:current train perplexity4.889538764953613
INFO:root:current mean train loss 4020.936172369462
INFO:root:current train perplexity4.87946891784668
INFO:root:current mean train loss 4020.2961539220328
INFO:root:current train perplexity4.874049186706543
INFO:root:current mean train loss 4018.0849806328783
INFO:root:current train perplexity4.8690996170043945
INFO:root:current mean train loss 4018.0313265793616
INFO:root:current train perplexity4.866858959197998
INFO:root:current mean train loss 4017.396887283805
INFO:root:current train perplexity4.8710784912109375
INFO:root:current mean train loss 4018.147873385126
INFO:root:current train perplexity4.8734588623046875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.30s/it]
INFO:root:final mean train loss: 4014.6913361703196
INFO:root:final train perplexity: 4.873985290527344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.31s/it]
INFO:root:eval mean loss: 3896.113743558843
INFO:root:eval perplexity: 4.83303165435791
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.55s/it]
INFO:root:eval mean loss: 4785.366269808289
INFO:root:eval perplexity: 7.076660633087158
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/38
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [4:02:22<6:35:36, 382.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4165.959228515625
INFO:root:current train perplexity5.085944175720215
INFO:root:current mean train loss 4010.7133504626822
INFO:root:current train perplexity4.85413122177124
INFO:root:current mean train loss 4001.28461505157
INFO:root:current train perplexity4.842207908630371
INFO:root:current mean train loss 3999.555954936314
INFO:root:current train perplexity4.83681583404541
INFO:root:current mean train loss 4007.3192147758996
INFO:root:current train perplexity4.85243558883667
INFO:root:current mean train loss 4009.9814123074057
INFO:root:current train perplexity4.848544597625732
INFO:root:current mean train loss 4011.5557579938845
INFO:root:current train perplexity4.85032320022583
INFO:root:current mean train loss 4005.713053848462
INFO:root:current train perplexity4.843990802764893
INFO:root:current mean train loss 4003.878705282437
INFO:root:current train perplexity4.843192100524902
INFO:root:current mean train loss 4002.5599472029003
INFO:root:current train perplexity4.842844486236572

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.83s/it]
INFO:root:final mean train loss: 3997.9268913884316
INFO:root:final train perplexity: 4.841854095458984
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.01s/it]
INFO:root:eval mean loss: 3892.788723127216
INFO:root:eval perplexity: 4.8265380859375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.74s/it]
INFO:root:eval mean loss: 4777.168545337434
INFO:root:eval perplexity: 7.052977561950684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/39
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [4:08:44<6:28:54, 382.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3990.9646218039775
INFO:root:current train perplexity4.888958930969238
INFO:root:current mean train loss 3974.7186158326294
INFO:root:current train perplexity4.802279472351074
INFO:root:current mean train loss 3973.5666874166914
INFO:root:current train perplexity4.799737453460693
INFO:root:current mean train loss 3969.722655464982
INFO:root:current train perplexity4.80234432220459
INFO:root:current mean train loss 3978.3521226572007
INFO:root:current train perplexity4.804191589355469
INFO:root:current mean train loss 3982.015758775685
INFO:root:current train perplexity4.808490753173828
INFO:root:current mean train loss 3977.6951450778693
INFO:root:current train perplexity4.809772968292236
INFO:root:current mean train loss 3980.1017517003997
INFO:root:current train perplexity4.81244421005249
INFO:root:current mean train loss 3986.5870453144266
INFO:root:current train perplexity4.815094947814941
INFO:root:current mean train loss 3987.0047496205234
INFO:root:current train perplexity4.814136505126953

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.77s/it]
INFO:root:final mean train loss: 3983.0637547892907
INFO:root:final train perplexity: 4.813546180725098
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.34s/it]
INFO:root:eval mean loss: 3885.0290406139184
INFO:root:eval perplexity: 4.811417102813721
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it]
INFO:root:eval mean loss: 4773.028396498227
INFO:root:eval perplexity: 7.041046619415283
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/40
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [4:15:07<6:22:39, 382.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3979.34423828125
INFO:root:current train perplexity4.828649044036865
INFO:root:current mean train loss 3978.5927631794907
INFO:root:current train perplexity4.8068766593933105
INFO:root:current mean train loss 3981.7912553064357
INFO:root:current train perplexity4.788369655609131
INFO:root:current mean train loss 3983.005626714342
INFO:root:current train perplexity4.795932292938232
INFO:root:current mean train loss 3982.1823444958236
INFO:root:current train perplexity4.794468402862549
INFO:root:current mean train loss 3985.5652368211104
INFO:root:current train perplexity4.794610023498535
INFO:root:current mean train loss 3977.146357768957
INFO:root:current train perplexity4.788074493408203
INFO:root:current mean train loss 3975.208009510279
INFO:root:current train perplexity4.788049697875977
INFO:root:current mean train loss 3971.5721016721996
INFO:root:current train perplexity4.786538124084473
INFO:root:current mean train loss 3972.430556736262
INFO:root:current train perplexity4.787099361419678

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.42s/it]
INFO:root:final mean train loss: 3968.76459054024
INFO:root:final train perplexity: 4.786465644836426
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.03s/it]
INFO:root:eval mean loss: 3883.1336574689717
INFO:root:eval perplexity: 4.807731628417969
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.82s/it]
INFO:root:eval mean loss: 4770.252420628324
INFO:root:eval perplexity: 7.0330586433410645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/41
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [4:21:36<6:18:17, 384.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3986.6367277922454
INFO:root:current train perplexity4.808079242706299
INFO:root:current mean train loss 3968.1892935685287
INFO:root:current train perplexity4.796204566955566
INFO:root:current mean train loss 3967.908763465377
INFO:root:current train perplexity4.781750202178955
INFO:root:current mean train loss 3967.1177302835913
INFO:root:current train perplexity4.77577018737793
INFO:root:current mean train loss 3954.2245173219776
INFO:root:current train perplexity4.759007453918457
INFO:root:current mean train loss 3955.23860553546
INFO:root:current train perplexity4.757591724395752
INFO:root:current mean train loss 3958.3536892880284
INFO:root:current train perplexity4.761537551879883
INFO:root:current mean train loss 3958.5312416045176
INFO:root:current train perplexity4.75968599319458
INFO:root:current mean train loss 3957.519411098568
INFO:root:current train perplexity4.759113788604736
INFO:root:current mean train loss 3957.776567345941
INFO:root:current train perplexity4.761020660400391

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.52s/it]
INFO:root:final mean train loss: 3955.406036315426
INFO:root:final train perplexity: 4.7613067626953125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.13s/it]
INFO:root:eval mean loss: 3871.179273672983
INFO:root:eval perplexity: 4.784546375274658
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.06s/it]
INFO:root:eval mean loss: 4758.383598598182
INFO:root:eval perplexity: 6.999007701873779
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/42
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [4:27:59<6:11:21, 384.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4000.5302804129465
INFO:root:current train perplexity4.812647342681885
INFO:root:current mean train loss 3946.1862919560185
INFO:root:current train perplexity4.743182182312012
INFO:root:current mean train loss 3949.648650473737
INFO:root:current train perplexity4.741081237792969
INFO:root:current mean train loss 3954.758595207556
INFO:root:current train perplexity4.746020793914795
INFO:root:current mean train loss 3946.385848823635
INFO:root:current train perplexity4.7429704666137695
INFO:root:current mean train loss 3948.923555235105
INFO:root:current train perplexity4.746279716491699
INFO:root:current mean train loss 3956.1958411509595
INFO:root:current train perplexity4.752063274383545
INFO:root:current mean train loss 3956.0731196189413
INFO:root:current train perplexity4.75430965423584
INFO:root:current mean train loss 3956.636388940868
INFO:root:current train perplexity4.755463123321533
INFO:root:current mean train loss 3954.2109563001336
INFO:root:current train perplexity4.751276016235352

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.19s/it]
INFO:root:final mean train loss: 3948.1613193635017
INFO:root:final train perplexity: 4.747717380523682
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.67s/it]
INFO:root:eval mean loss: 3869.290087544326
INFO:root:eval perplexity: 4.780892848968506
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.38s/it]
INFO:root:eval mean loss: 4762.432431917664
INFO:root:eval perplexity: 7.010606288909912
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/43
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [4:34:24<6:05:18, 384.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3964.3033873092295
INFO:root:current train perplexity4.747402667999268
INFO:root:current mean train loss 3921.133476630791
INFO:root:current train perplexity4.712726593017578
INFO:root:current mean train loss 3917.459026572145
INFO:root:current train perplexity4.706333637237549
INFO:root:current mean train loss 3921.3992354056577
INFO:root:current train perplexity4.700540065765381
INFO:root:current mean train loss 3926.172045843327
INFO:root:current train perplexity4.7005414962768555
INFO:root:current mean train loss 3928.562315658092
INFO:root:current train perplexity4.702596187591553
INFO:root:current mean train loss 3933.031505151633
INFO:root:current train perplexity4.709774017333984
INFO:root:current mean train loss 3932.4798979932493
INFO:root:current train perplexity4.712183952331543
INFO:root:current mean train loss 3931.3571728110173
INFO:root:current train perplexity4.713161468505859
INFO:root:current mean train loss 3935.953741176763
INFO:root:current train perplexity4.720778942108154

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.84s/it]
INFO:root:final mean train loss: 3934.8190766611406
INFO:root:final train perplexity: 4.7227911949157715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it]
INFO:root:eval mean loss: 3857.557750512522
INFO:root:eval perplexity: 4.758265018463135
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it]
INFO:root:eval mean loss: 4752.035036776928
INFO:root:eval perplexity: 6.980862140655518
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/44
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [4:40:47<5:58:18, 383.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3946.8212842754288
INFO:root:current train perplexity4.776078224182129
INFO:root:current mean train loss 3939.882476200331
INFO:root:current train perplexity4.720466613769531
INFO:root:current mean train loss 3934.47780751992
INFO:root:current train perplexity4.709746360778809
INFO:root:current mean train loss 3927.425724909856
INFO:root:current train perplexity4.701786994934082
INFO:root:current mean train loss 3923.298909866096
INFO:root:current train perplexity4.694869518280029
INFO:root:current mean train loss 3919.299778102314
INFO:root:current train perplexity4.694827556610107
INFO:root:current mean train loss 3920.805606308804
INFO:root:current train perplexity4.694112777709961
INFO:root:current mean train loss 3925.4903120708846
INFO:root:current train perplexity4.699676036834717
INFO:root:current mean train loss 3928.32820446763
INFO:root:current train perplexity4.7071709632873535
INFO:root:current mean train loss 3931.3839374466024
INFO:root:current train perplexity4.70994234085083

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.66s/it]
INFO:root:final mean train loss: 3927.1772906395695
INFO:root:final train perplexity: 4.708573818206787
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.01s/it]
INFO:root:eval mean loss: 3856.0660062749334
INFO:root:eval perplexity: 4.755395889282227
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.06s/it]
INFO:root:eval mean loss: 4750.32161285184
INFO:root:eval perplexity: 6.975971698760986
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/45
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [4:47:10<5:51:37, 383.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3919.4248915850108
INFO:root:current train perplexity4.729020595550537
INFO:root:current mean train loss 3935.883649334218
INFO:root:current train perplexity4.720179080963135
INFO:root:current mean train loss 3924.653515436474
INFO:root:current train perplexity4.708498477935791
INFO:root:current mean train loss 3912.632866904596
INFO:root:current train perplexity4.6927337646484375
INFO:root:current mean train loss 3908.0911729600693
INFO:root:current train perplexity4.682200908660889
INFO:root:current mean train loss 3912.7887668234293
INFO:root:current train perplexity4.685687065124512
INFO:root:current mean train loss 3910.9021051664454
INFO:root:current train perplexity4.680743217468262
INFO:root:current mean train loss 3912.547386119174
INFO:root:current train perplexity4.683655738830566
INFO:root:current mean train loss 3916.7845423457507
INFO:root:current train perplexity4.68546724319458
INFO:root:current mean train loss 3919.319561239328
INFO:root:current train perplexity4.687735080718994

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.06s/it]
INFO:root:final mean train loss: 3916.064462600216
INFO:root:final train perplexity: 4.68797492980957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.73s/it]
INFO:root:eval mean loss: 3852.1323536541445
INFO:root:eval perplexity: 4.747837543487549
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it]
INFO:root:eval mean loss: 4746.4766992880095
INFO:root:eval perplexity: 6.965013027191162
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/46
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [4:53:31<5:44:42, 383.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3902.6726620802237
INFO:root:current train perplexity4.64499568939209
INFO:root:current mean train loss 3914.6363211077846
INFO:root:current train perplexity4.67902946472168
INFO:root:current mean train loss 3917.1757126711727
INFO:root:current train perplexity4.686065673828125
INFO:root:current mean train loss 3907.1128009515496
INFO:root:current train perplexity4.671125411987305
INFO:root:current mean train loss 3901.3356985872256
INFO:root:current train perplexity4.660679817199707
INFO:root:current mean train loss 3906.3629208519346
INFO:root:current train perplexity4.67047643661499
INFO:root:current mean train loss 3904.4347932235055
INFO:root:current train perplexity4.668334007263184
INFO:root:current mean train loss 3907.9954103472337
INFO:root:current train perplexity4.670543670654297
INFO:root:current mean train loss 3911.518060211217
INFO:root:current train perplexity4.673705101013184
INFO:root:current mean train loss 3909.378505829078
INFO:root:current train perplexity4.67170524597168

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.76s/it]
INFO:root:final mean train loss: 3907.563260601413
INFO:root:final train perplexity: 4.672277927398682
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.80s/it]
INFO:root:eval mean loss: 3851.207746356937
INFO:root:eval perplexity: 4.746063232421875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.76s/it]
INFO:root:eval mean loss: 4749.641811073249
INFO:root:eval perplexity: 6.974034309387207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/47
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [4:59:56<5:38:43, 383.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3885.8951171875
INFO:root:current train perplexity4.588210582733154
INFO:root:current mean train loss 3888.9788657924105
INFO:root:current train perplexity4.630298614501953
INFO:root:current mean train loss 3896.291913174716
INFO:root:current train perplexity4.640782833099365
INFO:root:current mean train loss 3894.630537109375
INFO:root:current train perplexity4.647970676422119
INFO:root:current mean train loss 3890.995377261513
INFO:root:current train perplexity4.643231391906738
INFO:root:current mean train loss 3896.6746297554346
INFO:root:current train perplexity4.6488728523254395
INFO:root:current mean train loss 3897.6857801649307
INFO:root:current train perplexity4.648671627044678
INFO:root:current mean train loss 3904.5746342615926
INFO:root:current train perplexity4.6594624519348145
INFO:root:current mean train loss 3902.6772787388395
INFO:root:current train perplexity4.656386375427246
INFO:root:current mean train loss 3902.6870998597756
INFO:root:current train perplexity4.6559624671936035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.77s/it]
INFO:root:final mean train loss: 3898.879254064252
INFO:root:final train perplexity: 4.65629768371582
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.71s/it]
INFO:root:eval mean loss: 3843.7412230579566
INFO:root:eval perplexity: 4.731754779815674
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.63s/it]
INFO:root:eval mean loss: 4740.020050698138
INFO:root:eval perplexity: 6.946649551391602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/48
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [5:06:19<5:32:17, 383.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3918.9048939900226
INFO:root:current train perplexity4.662405490875244
INFO:root:current mean train loss 3895.48427761057
INFO:root:current train perplexity4.646098613739014
INFO:root:current mean train loss 3884.3918500165637
INFO:root:current train perplexity4.638384819030762
INFO:root:current mean train loss 3883.0071922680727
INFO:root:current train perplexity4.634150505065918
INFO:root:current mean train loss 3891.4315440807777
INFO:root:current train perplexity4.640005588531494
INFO:root:current mean train loss 3889.841577441574
INFO:root:current train perplexity4.637233734130859
INFO:root:current mean train loss 3890.3909084604916
INFO:root:current train perplexity4.6369757652282715
INFO:root:current mean train loss 3895.760170967034
INFO:root:current train perplexity4.643073558807373
INFO:root:current mean train loss 3891.474587808784
INFO:root:current train perplexity4.638729095458984
INFO:root:current mean train loss 3894.319094280503
INFO:root:current train perplexity4.642115116119385

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.18s/it]
INFO:root:final mean train loss: 3890.994275246897
INFO:root:final train perplexity: 4.641834735870361
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.83s/it]
INFO:root:eval mean loss: 3845.216738004211
INFO:root:eval perplexity: 4.734579086303711
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.96s/it]
INFO:root:eval mean loss: 4746.385688511193
INFO:root:eval perplexity: 6.964754104614258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/49
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [5:12:42<5:25:49, 383.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3895.656716818338
INFO:root:current train perplexity4.607121467590332
INFO:root:current mean train loss 3890.9591556569044
INFO:root:current train perplexity4.62448787689209
INFO:root:current mean train loss 3883.897685781787
INFO:root:current train perplexity4.613105297088623
INFO:root:current mean train loss 3892.1050116887786
INFO:root:current train perplexity4.624346733093262
INFO:root:current mean train loss 3893.497493953666
INFO:root:current train perplexity4.626636505126953
INFO:root:current mean train loss 3889.438166739372
INFO:root:current train perplexity4.625888824462891
INFO:root:current mean train loss 3889.5920427821998
INFO:root:current train perplexity4.6299729347229
INFO:root:current mean train loss 3888.389131760627
INFO:root:current train perplexity4.628239631652832
INFO:root:current mean train loss 3886.0011116481655
INFO:root:current train perplexity4.62625789642334
INFO:root:current mean train loss 3887.0269441575742
INFO:root:current train perplexity4.628896713256836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.02s/it]
INFO:root:final mean train loss: 3883.9244442601357
INFO:root:final train perplexity: 4.628905773162842
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it]
INFO:root:eval mean loss: 3847.508248836436
INFO:root:eval perplexity: 4.738967418670654
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.51s/it]
INFO:root:eval mean loss: 4750.248232144836
INFO:root:eval perplexity: 6.97576379776001
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/50
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [5:19:07<5:19:41, 383.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3866.062285452178
INFO:root:current train perplexity4.600404739379883
INFO:root:current mean train loss 3878.9123915475816
INFO:root:current train perplexity4.618221282958984
INFO:root:current mean train loss 3876.7970701491954
INFO:root:current train perplexity4.610177040100098
INFO:root:current mean train loss 3867.5830794026083
INFO:root:current train perplexity4.596785545349121
INFO:root:current mean train loss 3873.177107633235
INFO:root:current train perplexity4.6016926765441895
INFO:root:current mean train loss 3872.739467308796
INFO:root:current train perplexity4.602695941925049
INFO:root:current mean train loss 3874.7214414844866
INFO:root:current train perplexity4.60618257522583
INFO:root:current mean train loss 3878.5259944070713
INFO:root:current train perplexity4.613419055938721
INFO:root:current mean train loss 3881.8084910968787
INFO:root:current train perplexity4.618978500366211

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.28s/it]
INFO:root:final mean train loss: 3876.764830435476
INFO:root:final train perplexity: 4.615849494934082
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.35s/it]
INFO:root:eval mean loss: 3844.314056612921
INFO:root:eval perplexity: 4.732850551605225
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.27s/it]
INFO:root:eval mean loss: 4743.448020556294
INFO:root:eval perplexity: 6.95639181137085
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/51
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [5:25:31<5:13:23, 383.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3888.7060546875
INFO:root:current train perplexity4.591142654418945
INFO:root:current mean train loss 3875.364611474153
INFO:root:current train perplexity4.5902228355407715
INFO:root:current mean train loss 3888.014840683499
INFO:root:current train perplexity4.622514724731445
INFO:root:current mean train loss 3881.5790435095173
INFO:root:current train perplexity4.6143412590026855
INFO:root:current mean train loss 3877.074467689458
INFO:root:current train perplexity4.603845119476318
INFO:root:current mean train loss 3880.248497596154
INFO:root:current train perplexity4.609686851501465
INFO:root:current mean train loss 3881.6982417852914
INFO:root:current train perplexity4.61278772354126
INFO:root:current mean train loss 3881.0477355352723
INFO:root:current train perplexity4.61234712600708
INFO:root:current mean train loss 3881.294827788588
INFO:root:current train perplexity4.61100959777832
INFO:root:current mean train loss 3878.0726341239147
INFO:root:current train perplexity4.609622001647949

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.83s/it]
INFO:root:final mean train loss: 3871.8441998881676
INFO:root:final train perplexity: 4.606897354125977
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.20s/it]
INFO:root:eval mean loss: 3839.410575271498
INFO:root:eval perplexity: 4.723475456237793
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.55s/it]
INFO:root:eval mean loss: 4739.034953665226
INFO:root:eval perplexity: 6.943849563598633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/52
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [5:31:55<5:07:14, 384.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3921.552180989583
INFO:root:current train perplexity4.632672309875488
INFO:root:current mean train loss 3882.7638884171197
INFO:root:current train perplexity4.598055362701416
INFO:root:current mean train loss 3879.5787609011627
INFO:root:current train perplexity4.6038360595703125
INFO:root:current mean train loss 3876.1297766307043
INFO:root:current train perplexity4.598886489868164
INFO:root:current mean train loss 3878.0223515154366
INFO:root:current train perplexity4.603538990020752
INFO:root:current mean train loss 3876.9765852548544
INFO:root:current train perplexity4.59735107421875
INFO:root:current mean train loss 3873.81171994093
INFO:root:current train perplexity4.59387731552124
INFO:root:current mean train loss 3874.0894411740605
INFO:root:current train perplexity4.598948955535889
INFO:root:current mean train loss 3872.114783239072
INFO:root:current train perplexity4.599828243255615
INFO:root:current mean train loss 3871.5323653090845
INFO:root:current train perplexity4.600664138793945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.98s/it]
INFO:root:final mean train loss: 3865.477526080224
INFO:root:final train perplexity: 4.595339775085449
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.60s/it]
INFO:root:eval mean loss: 3830.157268118351
INFO:root:eval perplexity: 4.705833911895752
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.51s/it]
INFO:root:eval mean loss: 4729.539266816268
INFO:root:eval perplexity: 6.916939735412598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/53
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [5:38:20<5:00:54, 384.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3848.826309867527
INFO:root:current train perplexity4.511343955993652
INFO:root:current mean train loss 3830.7379557291665
INFO:root:current train perplexity4.528336048126221
INFO:root:current mean train loss 3850.783440696819
INFO:root:current train perplexity4.550394058227539
INFO:root:current mean train loss 3847.7416652053503
INFO:root:current train perplexity4.559128761291504
INFO:root:current mean train loss 3857.6911344054743
INFO:root:current train perplexity4.569921016693115
INFO:root:current mean train loss 3864.1213761688873
INFO:root:current train perplexity4.5845723152160645
INFO:root:current mean train loss 3860.0194806976074
INFO:root:current train perplexity4.582632541656494
INFO:root:current mean train loss 3861.2584854906854
INFO:root:current train perplexity4.584269046783447
INFO:root:current mean train loss 3856.9714833070702
INFO:root:current train perplexity4.581682205200195
INFO:root:current mean train loss 3860.891732229313
INFO:root:current train perplexity4.584383487701416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.55s/it]
INFO:root:final mean train loss: 3859.444008119645
INFO:root:final train perplexity: 4.584414482116699
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.17s/it]
INFO:root:eval mean loss: 3830.9222593916224
INFO:root:eval perplexity: 4.707291126251221
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.63s/it]
INFO:root:eval mean loss: 4733.773640084774
INFO:root:eval perplexity: 6.92892599105835
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/54
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [5:44:45<4:54:49, 384.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3895.6682522681454
INFO:root:current train perplexity4.594137668609619
INFO:root:current mean train loss 3849.9456405057254
INFO:root:current train perplexity4.548563480377197
INFO:root:current mean train loss 3856.2395114650976
INFO:root:current train perplexity4.5581746101379395
INFO:root:current mean train loss 3859.716519543051
INFO:root:current train perplexity4.573326110839844
INFO:root:current mean train loss 3856.823532210702
INFO:root:current train perplexity4.5753326416015625
INFO:root:current mean train loss 3858.4198712997295
INFO:root:current train perplexity4.576579570770264
INFO:root:current mean train loss 3857.0251097278624
INFO:root:current train perplexity4.573596477508545
INFO:root:current mean train loss 3858.046085133272
INFO:root:current train perplexity4.577016353607178
INFO:root:current mean train loss 3860.6758276690357
INFO:root:current train perplexity4.5805277824401855
INFO:root:current mean train loss 3859.937693529303
INFO:root:current train perplexity4.578744411468506

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.36s/it]
INFO:root:final mean train loss: 3856.0765226425665
INFO:root:final train perplexity: 4.578327655792236
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.05s/it]
INFO:root:eval mean loss: 3833.5529750526375
INFO:root:eval perplexity: 4.712301254272461
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.74s/it]
INFO:root:eval mean loss: 4737.833851049978
INFO:root:eval perplexity: 6.940440654754639
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/55
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [5:51:09<4:48:08, 384.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3925.733435997596
INFO:root:current train perplexity4.601351737976074
INFO:root:current mean train loss 3882.924486777765
INFO:root:current train perplexity4.5715837478637695
INFO:root:current mean train loss 3867.5506658194954
INFO:root:current train perplexity4.558416843414307
INFO:root:current mean train loss 3853.6331977956766
INFO:root:current train perplexity4.5536065101623535
INFO:root:current mean train loss 3858.9915991155326
INFO:root:current train perplexity4.5586771965026855
INFO:root:current mean train loss 3857.1354763052236
INFO:root:current train perplexity4.559050559997559
INFO:root:current mean train loss 3854.0144738330155
INFO:root:current train perplexity4.558245658874512
INFO:root:current mean train loss 3849.799408248055
INFO:root:current train perplexity4.556638717651367
INFO:root:current mean train loss 3846.393524133548
INFO:root:current train perplexity4.554997444152832
INFO:root:current mean train loss 3849.3657853164104
INFO:root:current train perplexity4.5613932609558105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.24s/it]
INFO:root:final mean train loss: 3845.771214269823
INFO:root:final train perplexity: 4.559750556945801
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.41s/it]
INFO:root:eval mean loss: 3816.504159048094
INFO:root:eval perplexity: 4.679925441741943
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.64s/it]
INFO:root:eval mean loss: 4718.879666375776
INFO:root:eval perplexity: 6.886856555938721
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/56
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [5:57:36<4:42:27, 385.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3838.977300116356
INFO:root:current train perplexity4.542949676513672
INFO:root:current mean train loss 3847.752134154443
INFO:root:current train perplexity4.544834136962891
INFO:root:current mean train loss 3834.4981457173585
INFO:root:current train perplexity4.550362586975098
INFO:root:current mean train loss 3838.0692733192996
INFO:root:current train perplexity4.55450439453125
INFO:root:current mean train loss 3833.8543605591094
INFO:root:current train perplexity4.548341274261475
INFO:root:current mean train loss 3835.9182843028734
INFO:root:current train perplexity4.547306060791016
INFO:root:current mean train loss 3837.689993479521
INFO:root:current train perplexity4.552043914794922
INFO:root:current mean train loss 3842.6170427151314
INFO:root:current train perplexity4.553913593292236
INFO:root:current mean train loss 3842.1045114996864
INFO:root:current train perplexity4.553886890411377
INFO:root:current mean train loss 3843.723732840549
INFO:root:current train perplexity4.55423641204834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.09s/it]
INFO:root:final mean train loss: 3842.222862674344
INFO:root:final train perplexity: 4.553371906280518
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.09s/it]
INFO:root:eval mean loss: 3822.1765119403813
INFO:root:eval perplexity: 4.690672397613525
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it]
INFO:root:eval mean loss: 4724.23652897828
INFO:root:eval perplexity: 6.90195894241333
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/57
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [6:04:03<4:36:30, 385.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3844.0562943892046
INFO:root:current train perplexity4.569187641143799
INFO:root:current mean train loss 3839.733699281754
INFO:root:current train perplexity4.55557107925415
INFO:root:current mean train loss 3843.5944584865197
INFO:root:current train perplexity4.553384304046631
INFO:root:current mean train loss 3837.7261732504403
INFO:root:current train perplexity4.538957595825195
INFO:root:current mean train loss 3839.7425335894573
INFO:root:current train perplexity4.542886734008789
INFO:root:current mean train loss 3841.7669130067566
INFO:root:current train perplexity4.5444560050964355
INFO:root:current mean train loss 3841.8151303822756
INFO:root:current train perplexity4.548341274261475
INFO:root:current mean train loss 3842.7702701391763
INFO:root:current train perplexity4.546903133392334
INFO:root:current mean train loss 3840.0978958219116
INFO:root:current train perplexity4.541308403015137
INFO:root:current mean train loss 3840.453025298593
INFO:root:current train perplexity4.5447821617126465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.00s/it]
INFO:root:final mean train loss: 3837.9930742325323
INFO:root:final train perplexity: 4.545780181884766
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.76s/it]
INFO:root:eval mean loss: 3824.088321766955
INFO:root:eval perplexity: 4.694300651550293
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.56s/it]
INFO:root:eval mean loss: 4731.695113378214
INFO:root:eval perplexity: 6.923042297363281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/58
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [6:10:28<4:29:48, 385.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3822.9592246403768
INFO:root:current train perplexity4.532952308654785
INFO:root:current mean train loss 3839.9184600268404
INFO:root:current train perplexity4.53946590423584
INFO:root:current mean train loss 3844.0876195639257
INFO:root:current train perplexity4.545391082763672
INFO:root:current mean train loss 3839.4105685315512
INFO:root:current train perplexity4.540219306945801
INFO:root:current mean train loss 3841.8713827112583
INFO:root:current train perplexity4.54334020614624
INFO:root:current mean train loss 3836.8632877546347
INFO:root:current train perplexity4.536168575286865
INFO:root:current mean train loss 3834.8649876567215
INFO:root:current train perplexity4.536005020141602
INFO:root:current mean train loss 3838.271135282704
INFO:root:current train perplexity4.538228511810303
INFO:root:current mean train loss 3838.111644404512
INFO:root:current train perplexity4.537450790405273
INFO:root:current mean train loss 3837.6878906757042
INFO:root:current train perplexity4.538341522216797

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.40s/it]
INFO:root:final mean train loss: 3834.276784158522
INFO:root:final train perplexity: 4.539119720458984
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.11s/it]
INFO:root:eval mean loss: 3815.583539381095
INFO:root:eval perplexity: 4.678183555603027
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.08s/it]
INFO:root:eval mean loss: 4724.217593362146
INFO:root:eval perplexity: 6.901905536651611
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/59
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [6:16:52<4:23:03, 384.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3834.1885522117077
INFO:root:current train perplexity4.555954456329346
INFO:root:current mean train loss 3828.019050107365
INFO:root:current train perplexity4.542374134063721
INFO:root:current mean train loss 3845.74471539149
INFO:root:current train perplexity4.5403218269348145
INFO:root:current mean train loss 3840.098743366745
INFO:root:current train perplexity4.537085056304932
INFO:root:current mean train loss 3836.8411354664277
INFO:root:current train perplexity4.533782005310059
INFO:root:current mean train loss 3835.130849968531
INFO:root:current train perplexity4.531843185424805
INFO:root:current mean train loss 3838.081068877492
INFO:root:current train perplexity4.536874294281006
INFO:root:current mean train loss 3837.0066769769373
INFO:root:current train perplexity4.538079261779785
INFO:root:current mean train loss 3834.1134883911272
INFO:root:current train perplexity4.535438060760498
INFO:root:current mean train loss 3835.7909940018344
INFO:root:current train perplexity4.536491394042969

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.34s/it]
INFO:root:final mean train loss: 3832.7713480918637
INFO:root:final train perplexity: 4.536424160003662
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.16s/it]
INFO:root:eval mean loss: 3812.788312763187
INFO:root:eval perplexity: 4.6728997230529785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.18s/it]
INFO:root:eval mean loss: 4722.786813289561
INFO:root:eval perplexity: 6.897866725921631
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/60
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [6:23:19<4:17:01, 385.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3828.8255877917327
INFO:root:current train perplexity4.535419464111328
INFO:root:current mean train loss 3808.8174810143155
INFO:root:current train perplexity4.50587272644043
INFO:root:current mean train loss 3812.010044767865
INFO:root:current train perplexity4.499088287353516
INFO:root:current mean train loss 3815.8391718801536
INFO:root:current train perplexity4.500624179840088
INFO:root:current mean train loss 3816.9861252691153
INFO:root:current train perplexity4.508591651916504
INFO:root:current mean train loss 3821.529137909515
INFO:root:current train perplexity4.512834072113037
INFO:root:current mean train loss 3826.1389573649208
INFO:root:current train perplexity4.52226448059082
INFO:root:current mean train loss 3827.571842844893
INFO:root:current train perplexity4.523989677429199
INFO:root:current mean train loss 3829.1838901072774
INFO:root:current train perplexity4.526891708374023
INFO:root:current mean train loss 3830.745442874585
INFO:root:current train perplexity4.528998374938965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.51s/it]
INFO:root:final mean train loss: 3829.2171725611533
INFO:root:final train perplexity: 4.5300679206848145
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.85s/it]
INFO:root:eval mean loss: 3814.6793290807846
INFO:root:eval perplexity: 4.676473617553711
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.80s/it]
INFO:root:eval mean loss: 4720.68982712766
INFO:root:eval perplexity: 6.891955375671387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/61
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [6:29:45<4:10:45, 385.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3777.4912895114944
INFO:root:current train perplexity4.460770606994629
INFO:root:current mean train loss 3806.4002143737466
INFO:root:current train perplexity4.507162094116211
INFO:root:current mean train loss 3792.8103656835256
INFO:root:current train perplexity4.492838382720947
INFO:root:current mean train loss 3791.487994842135
INFO:root:current train perplexity4.4917755126953125
INFO:root:current mean train loss 3806.3778735401693
INFO:root:current train perplexity4.501372814178467
INFO:root:current mean train loss 3813.153453404493
INFO:root:current train perplexity4.504169940948486
INFO:root:current mean train loss 3814.9411695721888
INFO:root:current train perplexity4.50683069229126
INFO:root:current mean train loss 3821.2002672827984
INFO:root:current train perplexity4.511190891265869
INFO:root:current mean train loss 3824.687926626797
INFO:root:current train perplexity4.515102863311768
INFO:root:current mean train loss 3825.681382879781
INFO:root:current train perplexity4.518121719360352

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.26s/it]
INFO:root:final mean train loss: 3822.145036266696
INFO:root:final train perplexity: 4.517446041107178
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.25s/it]
INFO:root:eval mean loss: 3808.038517079455
INFO:root:eval perplexity: 4.663932800292969
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it]
INFO:root:eval mean loss: 4715.697662137079
INFO:root:eval perplexity: 6.877900123596191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/62
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [6:36:09<4:03:54, 385.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3840.576765522204
INFO:root:current train perplexity4.502181529998779
INFO:root:current mean train loss 3833.152125901442
INFO:root:current train perplexity4.506041526794434
INFO:root:current mean train loss 3832.3790146649894
INFO:root:current train perplexity4.511832237243652
INFO:root:current mean train loss 3824.014733732199
INFO:root:current train perplexity4.508279323577881
INFO:root:current mean train loss 3821.1084339488634
INFO:root:current train perplexity4.503223896026611
INFO:root:current mean train loss 3819.996499556854
INFO:root:current train perplexity4.506220817565918
INFO:root:current mean train loss 3819.7069209476167
INFO:root:current train perplexity4.5083160400390625
INFO:root:current mean train loss 3826.4946200004915
INFO:root:current train perplexity4.514285564422607
INFO:root:current mean train loss 3823.4653890428594
INFO:root:current train perplexity4.512274742126465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.03s/it]
INFO:root:final mean train loss: 3819.070097707933
INFO:root:final train perplexity: 4.511969089508057
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.29s/it]
INFO:root:eval mean loss: 3800.707265001662
INFO:root:eval perplexity: 4.650126934051514
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.33s/it]
INFO:root:eval mean loss: 4712.2469854693045
INFO:root:eval perplexity: 6.868203163146973
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/63
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [6:42:34<3:57:36, 385.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3554.807373046875
INFO:root:current train perplexity4.2806596755981445
INFO:root:current mean train loss 3802.9134320009102
INFO:root:current train perplexity4.504722595214844
INFO:root:current mean train loss 3812.234281192272
INFO:root:current train perplexity4.492422580718994
INFO:root:current mean train loss 3802.3194825830237
INFO:root:current train perplexity4.49000883102417
INFO:root:current mean train loss 3803.04533745929
INFO:root:current train perplexity4.488579750061035
INFO:root:current mean train loss 3804.782962867327
INFO:root:current train perplexity4.490877151489258
INFO:root:current mean train loss 3812.253132530706
INFO:root:current train perplexity4.498318672180176
INFO:root:current mean train loss 3817.4947792802054
INFO:root:current train perplexity4.503794193267822
INFO:root:current mean train loss 3821.679578959274
INFO:root:current train perplexity4.5066609382629395
INFO:root:current mean train loss 3817.7517614354065
INFO:root:current train perplexity4.504473686218262

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.89s/it]
INFO:root:final mean train loss: 3815.0711030652446
INFO:root:final train perplexity: 4.504856109619141
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.46s/it]
INFO:root:eval mean loss: 3802.218523174313
INFO:root:eval perplexity: 4.652968883514404
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it]
INFO:root:eval mean loss: 4713.791084884751
INFO:root:eval perplexity: 6.872540473937988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/64
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [6:49:01<3:51:20, 385.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3834.0652077414775
INFO:root:current train perplexity4.418312072753906
INFO:root:current mean train loss 3807.4332594313064
INFO:root:current train perplexity4.48960542678833
INFO:root:current mean train loss 3819.0795019068423
INFO:root:current train perplexity4.501893997192383
INFO:root:current mean train loss 3805.200441023161
INFO:root:current train perplexity4.493011951446533
INFO:root:current mean train loss 3809.9578076290677
INFO:root:current train perplexity4.49589204788208
INFO:root:current mean train loss 3806.087120459271
INFO:root:current train perplexity4.48581600189209
INFO:root:current mean train loss 3804.9136561317255
INFO:root:current train perplexity4.487236499786377
INFO:root:current mean train loss 3806.9131937576917
INFO:root:current train perplexity4.488731384277344
INFO:root:current mean train loss 3810.0519128463125
INFO:root:current train perplexity4.489472389221191
INFO:root:current mean train loss 3808.8816470032075
INFO:root:current train perplexity4.489886283874512

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.00s/it]
INFO:root:final mean train loss: 3811.849682654104
INFO:root:final train perplexity: 4.499133586883545
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.29s/it]
INFO:root:eval mean loss: 3797.2768675892066
INFO:root:eval perplexity: 4.643680095672607
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it]
INFO:root:eval mean loss: 4708.5263117796985
INFO:root:eval perplexity: 6.857762336730957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/65
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [6:55:25<3:44:43, 385.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3802.808478104441
INFO:root:current train perplexity4.526003360748291
INFO:root:current mean train loss 3799.1653447511817
INFO:root:current train perplexity4.4896559715271
INFO:root:current mean train loss 3797.086170492651
INFO:root:current train perplexity4.482411861419678
INFO:root:current mean train loss 3802.5171135690143
INFO:root:current train perplexity4.483398914337158
INFO:root:current mean train loss 3796.5749750615305
INFO:root:current train perplexity4.478269100189209
INFO:root:current mean train loss 3801.9282626407453
INFO:root:current train perplexity4.481470108032227
INFO:root:current mean train loss 3809.0151702437147
INFO:root:current train perplexity4.488667011260986
INFO:root:current mean train loss 3814.8906002124263
INFO:root:current train perplexity4.4950151443481445
INFO:root:current mean train loss 3814.799322964362
INFO:root:current train perplexity4.4941864013671875
INFO:root:current mean train loss 3812.5315127367553
INFO:root:current train perplexity4.49497127532959

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.04s/it]
INFO:root:final mean train loss: 3808.5514205809563
INFO:root:final train perplexity: 4.493283748626709
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.82s/it]
INFO:root:eval mean loss: 3794.604156277704
INFO:root:eval perplexity: 4.638664722442627
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it]
INFO:root:eval mean loss: 4706.798178814827
INFO:root:eval perplexity: 6.852917671203613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/66
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [7:01:50<3:38:15, 385.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3884.4497884114585
INFO:root:current train perplexity4.583750247955322
INFO:root:current mean train loss 3819.478884719488
INFO:root:current train perplexity4.495092391967773
INFO:root:current mean train loss 3809.1750348465034
INFO:root:current train perplexity4.487179756164551
INFO:root:current mean train loss 3805.916629336296
INFO:root:current train perplexity4.47877311706543
INFO:root:current mean train loss 3804.1824536647396
INFO:root:current train perplexity4.480776309967041
INFO:root:current mean train loss 3806.6444219194736
INFO:root:current train perplexity4.481147289276123
INFO:root:current mean train loss 3804.6219441537082
INFO:root:current train perplexity4.478432655334473
INFO:root:current mean train loss 3801.2001200889786
INFO:root:current train perplexity4.474874019622803
INFO:root:current mean train loss 3801.266406131915
INFO:root:current train perplexity4.473718166351318
INFO:root:current mean train loss 3802.541073828968
INFO:root:current train perplexity4.480274677276611

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.91s/it]
INFO:root:final mean train loss: 3802.133086173765
INFO:root:final train perplexity: 4.481919765472412
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.34s/it]
INFO:root:eval mean loss: 3797.601081144725
INFO:root:eval perplexity: 4.644289016723633
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it]
INFO:root:eval mean loss: 4707.206674562279
INFO:root:eval perplexity: 6.854063034057617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/67
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [7:08:15<3:31:51, 385.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3799.848158482143
INFO:root:current train perplexity4.480410099029541
INFO:root:current mean train loss 3794.939579716435
INFO:root:current train perplexity4.439208030700684
INFO:root:current mean train loss 3800.947764295213
INFO:root:current train perplexity4.455561637878418
INFO:root:current mean train loss 3812.0190590018656
INFO:root:current train perplexity4.480631351470947
INFO:root:current mean train loss 3805.1897141029094
INFO:root:current train perplexity4.47206974029541
INFO:root:current mean train loss 3806.0582469334113
INFO:root:current train perplexity4.475273132324219
INFO:root:current mean train loss 3807.2839343934547
INFO:root:current train perplexity4.476774215698242
INFO:root:current mean train loss 3804.3385436596514
INFO:root:current train perplexity4.477330684661865
INFO:root:current mean train loss 3804.3753008631174
INFO:root:current train perplexity4.480048656463623
INFO:root:current mean train loss 3805.085733570772
INFO:root:current train perplexity4.479702472686768

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 329.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 329.00s/it]
INFO:root:final mean train loss: 3799.6377281681184
INFO:root:final train perplexity: 4.477509498596191
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.42s/it]
INFO:root:eval mean loss: 3797.540594872008
INFO:root:eval perplexity: 4.644176006317139
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.58s/it]
INFO:root:eval mean loss: 4710.935616134751
INFO:root:eval perplexity: 6.864521503448486
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/68
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [7:14:39<3:25:16, 384.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3800.36952103016
INFO:root:current train perplexity4.452291965484619
INFO:root:current mean train loss 3778.8431473311844
INFO:root:current train perplexity4.465055465698242
INFO:root:current mean train loss 3785.905019249936
INFO:root:current train perplexity4.4632062911987305
INFO:root:current mean train loss 3784.666535224581
INFO:root:current train perplexity4.4568400382995605
INFO:root:current mean train loss 3792.376896360927
INFO:root:current train perplexity4.461795330047607
INFO:root:current mean train loss 3795.0656122309506
INFO:root:current train perplexity4.463245868682861
INFO:root:current mean train loss 3798.607503128645
INFO:root:current train perplexity4.468509674072266
INFO:root:current mean train loss 3798.1804764389512
INFO:root:current train perplexity4.469124794006348
INFO:root:current mean train loss 3799.4198422324475
INFO:root:current train perplexity4.469418525695801
INFO:root:current mean train loss 3797.453672309948
INFO:root:current train perplexity4.470186233520508

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.27s/it]
INFO:root:final mean train loss: 3796.2726707458496
INFO:root:final train perplexity: 4.471569061279297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.56s/it]
INFO:root:eval mean loss: 3793.6793827570923
INFO:root:eval perplexity: 4.636929988861084
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.10s/it]
INFO:root:eval mean loss: 4704.550661776928
INFO:root:eval perplexity: 6.846622943878174
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/69
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [7:21:03<3:18:35, 384.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3794.7645479090074
INFO:root:current train perplexity4.449551105499268
INFO:root:current mean train loss 3799.145317027111
INFO:root:current train perplexity4.474185943603516
INFO:root:current mean train loss 3810.0712131940986
INFO:root:current train perplexity4.486978530883789
INFO:root:current mean train loss 3809.36659210292
INFO:root:current train perplexity4.484804153442383
INFO:root:current mean train loss 3812.006085651677
INFO:root:current train perplexity4.487504959106445
INFO:root:current mean train loss 3807.0800227391956
INFO:root:current train perplexity4.482263088226318
INFO:root:current mean train loss 3803.3947975170413
INFO:root:current train perplexity4.474795341491699
INFO:root:current mean train loss 3795.9745547603197
INFO:root:current train perplexity4.467518329620361
INFO:root:current mean train loss 3794.737581246328
INFO:root:current train perplexity4.464700222015381
INFO:root:current mean train loss 3795.444777752448
INFO:root:current train perplexity4.465127468109131

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.39s/it]
INFO:root:final mean train loss: 3794.062376514558
INFO:root:final train perplexity: 4.467671871185303
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.07s/it]
INFO:root:eval mean loss: 3796.3957381011746
INFO:root:eval perplexity: 4.642026424407959
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.12s/it]
INFO:root:eval mean loss: 4710.8795832640735
INFO:root:eval perplexity: 6.864365100860596
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/70
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [7:27:29<3:12:32, 385.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3795.0710407838983
INFO:root:current train perplexity4.459916591644287
INFO:root:current mean train loss 3809.1175160917846
INFO:root:current train perplexity4.47247838973999
INFO:root:current mean train loss 3802.439065704935
INFO:root:current train perplexity4.472480297088623
INFO:root:current mean train loss 3794.764062227977
INFO:root:current train perplexity4.464802265167236
INFO:root:current mean train loss 3792.7196228426264
INFO:root:current train perplexity4.4670562744140625
INFO:root:current mean train loss 3793.192257903343
INFO:root:current train perplexity4.46848726272583
INFO:root:current mean train loss 3785.4553952484825
INFO:root:current train perplexity4.455723285675049
INFO:root:current mean train loss 3792.480630223773
INFO:root:current train perplexity4.455590724945068
INFO:root:current mean train loss 3789.952217217513
INFO:root:current train perplexity4.454472064971924
INFO:root:current mean train loss 3792.696362635639
INFO:root:current train perplexity4.458846092224121

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.85s/it]
INFO:root:final mean train loss: 3788.6612286721506
INFO:root:final train perplexity: 4.4581618309021
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.49s/it]
INFO:root:eval mean loss: 3795.0291670129654
INFO:root:eval perplexity: 4.639462471008301
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.15s/it]
INFO:root:eval mean loss: 4706.837083748892
INFO:root:eval perplexity: 6.853025436401367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/71
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [7:33:51<3:05:37, 384.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3783.3106197527986
INFO:root:current train perplexity4.446017265319824
INFO:root:current mean train loss 3780.35221159244
INFO:root:current train perplexity4.431593894958496
INFO:root:current mean train loss 3794.904486152563
INFO:root:current train perplexity4.450476169586182
INFO:root:current mean train loss 3783.3188463257834
INFO:root:current train perplexity4.443387508392334
INFO:root:current mean train loss 3785.522539878045
INFO:root:current train perplexity4.444829940795898
INFO:root:current mean train loss 3787.991265621555
INFO:root:current train perplexity4.448986053466797
INFO:root:current mean train loss 3791.5269876048305
INFO:root:current train perplexity4.454221248626709
INFO:root:current mean train loss 3790.567129122698
INFO:root:current train perplexity4.455835342407227
INFO:root:current mean train loss 3790.819877158124
INFO:root:current train perplexity4.454421043395996
INFO:root:current mean train loss 3789.842260918918
INFO:root:current train perplexity4.455188751220703

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:27<00:00, 327.61s/it]
INFO:root:final mean train loss: 3786.824281877087
INFO:root:final train perplexity: 4.454931735992432
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.00s/it]
INFO:root:eval mean loss: 3793.879219650377
INFO:root:eval perplexity: 4.63730525970459
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.72s/it]
INFO:root:eval mean loss: 4711.632956213985
INFO:root:eval perplexity: 6.8664774894714355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/72
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [7:40:13<2:59:00, 383.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3798.2603841145833
INFO:root:current train perplexity4.499505519866943
INFO:root:current mean train loss 3795.2722600446427
INFO:root:current train perplexity4.471660614013672
INFO:root:current mean train loss 3798.756863458807
INFO:root:current train perplexity4.464868545532227
INFO:root:current mean train loss 3794.27268359375
INFO:root:current train perplexity4.455170631408691
INFO:root:current mean train loss 3786.860754523026
INFO:root:current train perplexity4.448591232299805
INFO:root:current mean train loss 3788.6057154381792
INFO:root:current train perplexity4.449456214904785
INFO:root:current mean train loss 3783.548415798611
INFO:root:current train perplexity4.4450602531433105
INFO:root:current mean train loss 3781.7254227570565
INFO:root:current train perplexity4.443691730499268
INFO:root:current mean train loss 3786.6426487165177
INFO:root:current train perplexity4.448151111602783
INFO:root:current mean train loss 3784.9009031951123
INFO:root:current train perplexity4.446777820587158

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.99s/it]
INFO:root:final mean train loss: 3781.8192407546503
INFO:root:final train perplexity: 4.44614315032959
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.81s/it]
INFO:root:eval mean loss: 3789.1955427886746
INFO:root:eval perplexity: 4.628530502319336
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.78s/it]
INFO:root:eval mean loss: 4703.831106632314
INFO:root:eval perplexity: 6.844606399536133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/73
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [7:46:36<2:52:29, 383.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3756.5115334384413
INFO:root:current train perplexity4.415150165557861
INFO:root:current mean train loss 3770.919390902493
INFO:root:current train perplexity4.418666839599609
INFO:root:current mean train loss 3784.4528584294944
INFO:root:current train perplexity4.438844203948975
INFO:root:current mean train loss 3789.9242074035164
INFO:root:current train perplexity4.4391703605651855
INFO:root:current mean train loss 3793.391951851223
INFO:root:current train perplexity4.445706844329834
INFO:root:current mean train loss 3795.964832443316
INFO:root:current train perplexity4.45169734954834
INFO:root:current mean train loss 3794.7871747889594
INFO:root:current train perplexity4.451488494873047
INFO:root:current mean train loss 3792.217540833533
INFO:root:current train perplexity4.447054386138916
INFO:root:current mean train loss 3789.6768684084795
INFO:root:current train perplexity4.4465765953063965
INFO:root:current mean train loss 3783.4170661996122
INFO:root:current train perplexity4.4437384605407715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.42s/it]
INFO:root:final mean train loss: 3779.3850406523675
INFO:root:final train perplexity: 4.441874980926514
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.95s/it]
INFO:root:eval mean loss: 3793.9907694065823
INFO:root:eval perplexity: 4.637514591217041
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.96s/it]
INFO:root:eval mean loss: 4708.9867090536345
INFO:root:eval perplexity: 6.859051704406738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/74
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [7:52:57<2:45:44, 382.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3768.9034571385646
INFO:root:current train perplexity4.384482383728027
INFO:root:current mean train loss 3788.8720894858475
INFO:root:current train perplexity4.420205116271973
INFO:root:current mean train loss 3786.6668545962198
INFO:root:current train perplexity4.429152488708496
INFO:root:current mean train loss 3791.6633188389146
INFO:root:current train perplexity4.4403181076049805
INFO:root:current mean train loss 3789.561553271385
INFO:root:current train perplexity4.441049098968506
INFO:root:current mean train loss 3787.4507025962353
INFO:root:current train perplexity4.438133716583252
INFO:root:current mean train loss 3783.711400695889
INFO:root:current train perplexity4.436888217926025
INFO:root:current mean train loss 3781.9972854402063
INFO:root:current train perplexity4.434601783752441
INFO:root:current mean train loss 3781.030073960087
INFO:root:current train perplexity4.436424255371094
INFO:root:current mean train loss 3779.2432037261133
INFO:root:current train perplexity4.436604022979736

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.03s/it]
INFO:root:final mean train loss: 3776.3757326679847
INFO:root:final train perplexity: 4.436605930328369
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.95s/it]
INFO:root:eval mean loss: 3786.9142668162676
INFO:root:eval perplexity: 4.62426233291626
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it]
INFO:root:eval mean loss: 4702.425332793107
INFO:root:eval perplexity: 6.840673923492432
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/75
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [7:59:17<2:39:04, 381.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3757.713746350221
INFO:root:current train perplexity4.3998541831970215
INFO:root:current mean train loss 3764.2334757282506
INFO:root:current train perplexity4.425870895385742
INFO:root:current mean train loss 3762.4015411070754
INFO:root:current train perplexity4.41851282119751
INFO:root:current mean train loss 3758.071823846726
INFO:root:current train perplexity4.410818576812744
INFO:root:current mean train loss 3763.7306189527494
INFO:root:current train perplexity4.413307189941406
INFO:root:current mean train loss 3766.2149696923257
INFO:root:current train perplexity4.417871952056885
INFO:root:current mean train loss 3773.175877648873
INFO:root:current train perplexity4.425625324249268
INFO:root:current mean train loss 3777.9862691523585
INFO:root:current train perplexity4.430633544921875
INFO:root:current mean train loss 3775.5547931403817
INFO:root:current train perplexity4.428858757019043

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.56s/it]
INFO:root:final mean train loss: 3772.185265202676
INFO:root:final train perplexity: 4.429275989532471
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.56s/it]
INFO:root:eval mean loss: 3786.8785963126106
INFO:root:eval perplexity: 4.6241960525512695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.79s/it]
INFO:root:eval mean loss: 4706.779844027039
INFO:root:eval perplexity: 6.85286808013916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/76
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [8:05:35<2:32:15, 380.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3710.9554268973216
INFO:root:current train perplexity4.381798267364502
INFO:root:current mean train loss 3821.038517176548
INFO:root:current train perplexity4.467104911804199
INFO:root:current mean train loss 3785.9989385190215
INFO:root:current train perplexity4.435931205749512
INFO:root:current mean train loss 3779.4983347541734
INFO:root:current train perplexity4.439124584197998
INFO:root:current mean train loss 3774.1348933939266
INFO:root:current train perplexity4.436398983001709
INFO:root:current mean train loss 3774.501134989059
INFO:root:current train perplexity4.434110164642334
INFO:root:current mean train loss 3770.7908406642555
INFO:root:current train perplexity4.424195289611816
INFO:root:current mean train loss 3773.288932314688
INFO:root:current train perplexity4.424361705780029
INFO:root:current mean train loss 3775.474979972603
INFO:root:current train perplexity4.425192356109619
INFO:root:current mean train loss 3774.510177999242
INFO:root:current train perplexity4.424890995025635

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.77s/it]
INFO:root:final mean train loss: 3768.724171792307
INFO:root:final train perplexity: 4.423232078552246
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it]
INFO:root:eval mean loss: 3790.90190568207
INFO:root:eval perplexity: 4.631725788116455
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.44s/it]
INFO:root:eval mean loss: 4707.691636538675
INFO:root:eval perplexity: 6.85542106628418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/77
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [8:11:56<2:25:56, 380.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3771.965852864583
INFO:root:current train perplexity4.4623003005981445
INFO:root:current mean train loss 3771.234181810462
INFO:root:current train perplexity4.42652702331543
INFO:root:current mean train loss 3767.077152979651
INFO:root:current train perplexity4.419078350067139
INFO:root:current mean train loss 3770.995126488095
INFO:root:current train perplexity4.410512447357178
INFO:root:current mean train loss 3761.3535232727786
INFO:root:current train perplexity4.402827739715576
INFO:root:current mean train loss 3766.9125459837683
INFO:root:current train perplexity4.407729625701904
INFO:root:current mean train loss 3772.3158203125
INFO:root:current train perplexity4.415877342224121
INFO:root:current mean train loss 3767.4636025595496
INFO:root:current train perplexity4.410358905792236
INFO:root:current mean train loss 3766.2856103815184
INFO:root:current train perplexity4.414228916168213
INFO:root:current mean train loss 3771.5519632641735
INFO:root:current train perplexity4.421314239501953

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.21s/it]
INFO:root:final mean train loss: 3767.2109947819863
INFO:root:final train perplexity: 4.420592784881592
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it]
INFO:root:eval mean loss: 3777.934731341423
INFO:root:eval perplexity: 4.60750150680542
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.75s/it]
INFO:root:eval mean loss: 4698.683735732491
INFO:root:eval perplexity: 6.8302154541015625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/78
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [8:18:14<2:19:18, 379.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3709.5996412194295
INFO:root:current train perplexity4.335555553436279
INFO:root:current mean train loss 3747.1795942104927
INFO:root:current train perplexity4.399659156799316
INFO:root:current mean train loss 3743.7403044422645
INFO:root:current train perplexity4.4072651863098145
INFO:root:current mean train loss 3750.7783830483263
INFO:root:current train perplexity4.41357421875
INFO:root:current mean train loss 3753.92444569112
INFO:root:current train perplexity4.412696838378906
INFO:root:current mean train loss 3756.496622176745
INFO:root:current train perplexity4.4103474617004395
INFO:root:current mean train loss 3760.45072317353
INFO:root:current train perplexity4.413601398468018
INFO:root:current mean train loss 3762.7297633423022
INFO:root:current train perplexity4.41425085067749
INFO:root:current mean train loss 3767.5171533262455
INFO:root:current train perplexity4.419029235839844
INFO:root:current mean train loss 3768.758057434148
INFO:root:current train perplexity4.417491912841797

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.68s/it]
INFO:root:final mean train loss: 3764.2842954820203
INFO:root:final train perplexity: 4.415491104125977
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 3781.153692583666
INFO:root:eval perplexity: 4.613503932952881
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it]
INFO:root:eval mean loss: 4699.575361535904
INFO:root:eval perplexity: 6.832707405090332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/79
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [8:24:32<2:12:50, 379.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3782.7613722278224
INFO:root:current train perplexity4.451746940612793
INFO:root:current mean train loss 3769.9025953453006
INFO:root:current train perplexity4.431395530700684
INFO:root:current mean train loss 3773.3985812364717
INFO:root:current train perplexity4.408599853515625
INFO:root:current mean train loss 3767.6835089277283
INFO:root:current train perplexity4.4083967208862305
INFO:root:current mean train loss 3757.9883316641894
INFO:root:current train perplexity4.398354530334473
INFO:root:current mean train loss 3757.3354768052614
INFO:root:current train perplexity4.396818161010742
INFO:root:current mean train loss 3759.97110319062
INFO:root:current train perplexity4.40001916885376
INFO:root:current mean train loss 3767.086871312842
INFO:root:current train perplexity4.4113335609436035
INFO:root:current mean train loss 3766.4531999167984
INFO:root:current train perplexity4.413022041320801
INFO:root:current mean train loss 3764.0904426943475
INFO:root:current train perplexity4.411135196685791

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.34s/it]
INFO:root:final mean train loss: 3762.901736105642
INFO:root:final train perplexity: 4.413082599639893
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.22s/it]
INFO:root:eval mean loss: 3777.1810311391846
INFO:root:eval perplexity: 4.606098651885986
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.44s/it]
INFO:root:eval mean loss: 4695.966649698027
INFO:root:eval perplexity: 6.8226318359375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/80
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [8:30:51<2:06:22, 379.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3771.172325721154
INFO:root:current train perplexity4.40676736831665
INFO:root:current mean train loss 3776.116432244829
INFO:root:current train perplexity4.417242527008057
INFO:root:current mean train loss 3771.065538988951
INFO:root:current train perplexity4.419299125671387
INFO:root:current mean train loss 3786.927002673304
INFO:root:current train perplexity4.426974296569824
INFO:root:current mean train loss 3782.7337015277976
INFO:root:current train perplexity4.425416469573975
INFO:root:current mean train loss 3777.2118424962314
INFO:root:current train perplexity4.424001693725586
INFO:root:current mean train loss 3769.669816424589
INFO:root:current train perplexity4.415657997131348
INFO:root:current mean train loss 3763.3877980563893
INFO:root:current train perplexity4.4090895652771
INFO:root:current mean train loss 3761.688215253464
INFO:root:current train perplexity4.40818977355957
INFO:root:current mean train loss 3761.8722816930413
INFO:root:current train perplexity4.406056880950928

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.51s/it]
INFO:root:final mean train loss: 3758.335556460965
INFO:root:final train perplexity: 4.405140399932861
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it]
INFO:root:eval mean loss: 3778.69834261414
INFO:root:eval perplexity: 4.6089253425598145
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.30s/it]
INFO:root:eval mean loss: 4697.824410945811
INFO:root:eval perplexity: 6.827816963195801
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/81
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [8:37:10<2:00:02, 379.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3704.383207280585
INFO:root:current train perplexity4.382484436035156
INFO:root:current mean train loss 3731.635652503189
INFO:root:current train perplexity4.3976030349731445
INFO:root:current mean train loss 3738.6890636861085
INFO:root:current train perplexity4.3962507247924805
INFO:root:current mean train loss 3745.6027536529627
INFO:root:current train perplexity4.399144649505615
INFO:root:current mean train loss 3751.905283814842
INFO:root:current train perplexity4.393851280212402
INFO:root:current mean train loss 3755.3697132619686
INFO:root:current train perplexity4.396895408630371
INFO:root:current mean train loss 3756.842265534438
INFO:root:current train perplexity4.395926475524902
INFO:root:current mean train loss 3757.918855107932
INFO:root:current train perplexity4.395365238189697
INFO:root:current mean train loss 3755.8047529308406
INFO:root:current train perplexity4.394948959350586
INFO:root:current mean train loss 3756.601719244984
INFO:root:current train perplexity4.3974151611328125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.31s/it]
INFO:root:final mean train loss: 3754.1498023002378
INFO:root:final train perplexity: 4.397871494293213
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.26s/it]
INFO:root:eval mean loss: 3779.268184147828
INFO:root:eval perplexity: 4.609987258911133
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.40s/it]
INFO:root:eval mean loss: 4696.868210812832
INFO:root:eval perplexity: 6.82514762878418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/82
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [8:43:31<1:53:54, 379.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3733.2724076704544
INFO:root:current train perplexity4.401846408843994
INFO:root:current mean train loss 3743.272095514113
INFO:root:current train perplexity4.400887966156006
INFO:root:current mean train loss 3741.995498238358
INFO:root:current train perplexity4.394092559814453
INFO:root:current mean train loss 3743.750810821963
INFO:root:current train perplexity4.387402534484863
INFO:root:current mean train loss 3753.134315440419
INFO:root:current train perplexity4.394446849822998
INFO:root:current mean train loss 3756.919572160051
INFO:root:current train perplexity4.397968769073486
INFO:root:current mean train loss 3753.9796107168418
INFO:root:current train perplexity4.396814823150635
INFO:root:current mean train loss 3756.220473859168
INFO:root:current train perplexity4.400633335113525
INFO:root:current mean train loss 3760.0539959110015
INFO:root:current train perplexity4.402181625366211
INFO:root:current mean train loss 3758.226634336142
INFO:root:current train perplexity4.40009880065918

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.49s/it]
INFO:root:final mean train loss: 3754.0869844498175
INFO:root:final train perplexity: 4.397763252258301
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 3770.546462904477
INFO:root:eval perplexity: 4.593757629394531
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it]
INFO:root:eval mean loss: 4690.6731441849515
INFO:root:eval perplexity: 6.807878494262695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/83
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [8:49:49<1:47:28, 379.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3720.1798580109125
INFO:root:current train perplexity4.360347270965576
INFO:root:current mean train loss 3729.2545098614837
INFO:root:current train perplexity4.374249458312988
INFO:root:current mean train loss 3739.7044691658743
INFO:root:current train perplexity4.3811798095703125
INFO:root:current mean train loss 3756.0048518745693
INFO:root:current train perplexity4.398348331451416
INFO:root:current mean train loss 3753.616485661616
INFO:root:current train perplexity4.396171569824219
INFO:root:current mean train loss 3756.9445080935
INFO:root:current train perplexity4.4007182121276855
INFO:root:current mean train loss 3754.6222625318155
INFO:root:current train perplexity4.397885322570801
INFO:root:current mean train loss 3755.3137299823884
INFO:root:current train perplexity4.39747953414917
INFO:root:current mean train loss 3754.5038058213536
INFO:root:current train perplexity4.395937442779541
INFO:root:current mean train loss 3755.7537206727025
INFO:root:current train perplexity4.395468235015869

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.84s/it]
INFO:root:final mean train loss: 3753.713884907384
INFO:root:final train perplexity: 4.397115707397461
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.98s/it]
INFO:root:eval mean loss: 3769.310546875
INFO:root:eval perplexity: 4.591461658477783
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.72s/it]
INFO:root:eval mean loss: 4685.8864780723625
INFO:root:eval perplexity: 6.794567584991455
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/84
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [8:56:09<1:41:11, 379.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3717.095049790933
INFO:root:current train perplexity4.356412410736084
INFO:root:current mean train loss 3736.5345780222037
INFO:root:current train perplexity4.386184215545654
INFO:root:current mean train loss 3734.1128623371196
INFO:root:current train perplexity4.381847381591797
INFO:root:current mean train loss 3749.876628700935
INFO:root:current train perplexity4.392170429229736
INFO:root:current mean train loss 3752.004163867602
INFO:root:current train perplexity4.399534702301025
INFO:root:current mean train loss 3745.946309585705
INFO:root:current train perplexity4.388239860534668
INFO:root:current mean train loss 3747.007621480882
INFO:root:current train perplexity4.388531684875488
INFO:root:current mean train loss 3751.709767778251
INFO:root:current train perplexity4.39232063293457
INFO:root:current mean train loss 3752.5174138696543
INFO:root:current train perplexity4.393453121185303
INFO:root:current mean train loss 3751.1261339590305
INFO:root:current train perplexity4.390954494476318

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.56s/it]
INFO:root:final mean train loss: 3750.6812174397132
INFO:root:final train perplexity: 4.391857147216797
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.27s/it]
INFO:root:eval mean loss: 3781.736361023382
INFO:root:eval perplexity: 4.614590167999268
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.32s/it]
INFO:root:eval mean loss: 4705.290542927194
INFO:root:eval perplexity: 6.848692893981934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/85
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [9:02:32<1:35:09, 380.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3719.7787653283226
INFO:root:current train perplexity4.370124816894531
INFO:root:current mean train loss 3725.562220397608
INFO:root:current train perplexity4.370566368103027
INFO:root:current mean train loss 3741.0019294984877
INFO:root:current train perplexity4.380893230438232
INFO:root:current mean train loss 3737.974824527952
INFO:root:current train perplexity4.371106147766113
INFO:root:current mean train loss 3736.827458837585
INFO:root:current train perplexity4.368068218231201
INFO:root:current mean train loss 3741.389971428379
INFO:root:current train perplexity4.372445583343506
INFO:root:current mean train loss 3740.389030714976
INFO:root:current train perplexity4.375211238861084
INFO:root:current mean train loss 3742.2332956414475
INFO:root:current train perplexity4.376816749572754
INFO:root:current mean train loss 3747.4289839639328
INFO:root:current train perplexity4.3829264640808105
INFO:root:current mean train loss 3749.816319715989
INFO:root:current train perplexity4.386058807373047

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:28<00:00, 328.51s/it]
INFO:root:final mean train loss: 3746.9532038165676
INFO:root:final train perplexity: 4.385402679443359
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.91s/it]
INFO:root:eval mean loss: 3769.279466561392
INFO:root:eval perplexity: 4.591403961181641
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.90s/it]
INFO:root:eval mean loss: 4687.576551072141
INFO:root:eval perplexity: 6.799265384674072
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/86
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [9:08:58<1:29:09, 382.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3739.750521955819
INFO:root:current train perplexity4.3619065284729
INFO:root:current mean train loss 3735.699538613386
INFO:root:current train perplexity4.364617824554443
INFO:root:current mean train loss 3742.7353617704703
INFO:root:current train perplexity4.369659900665283
INFO:root:current mean train loss 3745.28937729631
INFO:root:current train perplexity4.373763084411621
INFO:root:current mean train loss 3749.2547835520404
INFO:root:current train perplexity4.380274772644043
INFO:root:current mean train loss 3750.2234111311486
INFO:root:current train perplexity4.38406229019165
INFO:root:current mean train loss 3749.429911739788
INFO:root:current train perplexity4.38530969619751
INFO:root:current mean train loss 3751.0998485521563
INFO:root:current train perplexity4.387343406677246
INFO:root:current mean train loss 3750.3433129139657
INFO:root:current train perplexity4.386148929595947
INFO:root:current mean train loss 3748.956211758723
INFO:root:current train perplexity4.384094715118408

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:26<00:00, 326.80s/it]
INFO:root:final mean train loss: 3746.107354625579
INFO:root:final train perplexity: 4.383939743041992
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it]
INFO:root:eval mean loss: 3779.553418315049
INFO:root:eval perplexity: 4.610518455505371
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it]
INFO:root:eval mean loss: 4699.821140154034
INFO:root:eval perplexity: 6.833393096923828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/87
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [9:15:20<1:22:47, 382.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3774.131640625
INFO:root:current train perplexity4.408426284790039
INFO:root:current mean train loss 3762.0382787459935
INFO:root:current train perplexity4.390008926391602
INFO:root:current mean train loss 3755.0131761453918
INFO:root:current train perplexity4.385105133056641
INFO:root:current mean train loss 3752.6201363479036
INFO:root:current train perplexity4.384712219238281
INFO:root:current mean train loss 3753.7700432054926
INFO:root:current train perplexity4.38350772857666
INFO:root:current mean train loss 3749.3088698956144
INFO:root:current train perplexity4.379706382751465
INFO:root:current mean train loss 3751.2926954530126
INFO:root:current train perplexity4.383079528808594
INFO:root:current mean train loss 3749.002902663129
INFO:root:current train perplexity4.380042552947998
INFO:root:current mean train loss 3747.218820650751
INFO:root:current train perplexity4.379120826721191

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.81s/it]
INFO:root:final mean train loss: 3743.416842306814
INFO:root:final train perplexity: 4.379288673400879
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.31s/it]
INFO:root:eval mean loss: 3767.915925587323
INFO:root:eval perplexity: 4.588873386383057
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.75s/it]
INFO:root:eval mean loss: 4687.894789242575
INFO:root:eval perplexity: 6.800151348114014
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/88
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [9:21:43<1:16:29, 382.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3898.28515625
INFO:root:current train perplexity4.560503005981445
INFO:root:current mean train loss 3708.673991675516
INFO:root:current train perplexity4.325268268585205
INFO:root:current mean train loss 3715.5968528709977
INFO:root:current train perplexity4.342050075531006
INFO:root:current mean train loss 3731.4963636744533
INFO:root:current train perplexity4.366087436676025
INFO:root:current mean train loss 3731.173521586151
INFO:root:current train perplexity4.369597434997559
INFO:root:current mean train loss 3744.8388982511183
INFO:root:current train perplexity4.384368896484375
INFO:root:current mean train loss 3745.5217779105774
INFO:root:current train perplexity4.382460594177246
INFO:root:current mean train loss 3746.2977373060767
INFO:root:current train perplexity4.379814147949219
INFO:root:current mean train loss 3744.4540380190497
INFO:root:current train perplexity4.376978874206543
INFO:root:current mean train loss 3743.5712363411026
INFO:root:current train perplexity4.376106262207031

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.57s/it]
INFO:root:final mean train loss: 3741.5416915647447
INFO:root:final train perplexity: 4.376049995422363
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it]
INFO:root:eval mean loss: 3764.6945090868794
INFO:root:eval perplexity: 4.582900047302246
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.95s/it]
INFO:root:eval mean loss: 4685.796192791445
INFO:root:eval perplexity: 6.794316291809082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/89
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [9:28:04<1:09:59, 381.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3843.0075905539775
INFO:root:current train perplexity4.53049898147583
INFO:root:current mean train loss 3760.563656918637
INFO:root:current train perplexity4.384281635284424
INFO:root:current mean train loss 3746.0251823533767
INFO:root:current train perplexity4.372276306152344
INFO:root:current mean train loss 3733.583647602241
INFO:root:current train perplexity4.355358123779297
INFO:root:current mean train loss 3737.899583357094
INFO:root:current train perplexity4.360712051391602
INFO:root:current mean train loss 3741.577901403498
INFO:root:current train perplexity4.3642730712890625
INFO:root:current mean train loss 3744.2497446712614
INFO:root:current train perplexity4.367733001708984
INFO:root:current mean train loss 3743.1300260004614
INFO:root:current train perplexity4.367504119873047
INFO:root:current mean train loss 3739.8097214328377
INFO:root:current train perplexity4.363999366760254
INFO:root:current mean train loss 3742.9756012130388
INFO:root:current train perplexity4.370002746582031

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.31s/it]
INFO:root:final mean train loss: 3739.3033522944297
INFO:root:final train perplexity: 4.37218713760376
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.47s/it]
INFO:root:eval mean loss: 3767.0489597185283
INFO:root:eval perplexity: 4.587265491485596
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.59s/it]
INFO:root:eval mean loss: 4685.264180934176
INFO:root:eval perplexity: 6.7928385734558105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/90
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [9:34:24<1:03:34, 381.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3754.4490774054275
INFO:root:current train perplexity4.444500923156738
INFO:root:current mean train loss 3739.4144297367384
INFO:root:current train perplexity4.367818832397461
INFO:root:current mean train loss 3722.8406876516124
INFO:root:current train perplexity4.337632179260254
INFO:root:current mean train loss 3725.5703163266558
INFO:root:current train perplexity4.341785907745361
INFO:root:current mean train loss 3731.5963306654608
INFO:root:current train perplexity4.357729434967041
INFO:root:current mean train loss 3732.487156509664
INFO:root:current train perplexity4.3619537353515625
INFO:root:current mean train loss 3738.4674748681086
INFO:root:current train perplexity4.369652271270752
INFO:root:current mean train loss 3743.2962203364045
INFO:root:current train perplexity4.375341892242432
INFO:root:current mean train loss 3743.0597449967568
INFO:root:current train perplexity4.37515926361084
INFO:root:current mean train loss 3740.7383200362146
INFO:root:current train perplexity4.3695902824401855

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.42s/it]
INFO:root:final mean train loss: 3737.210137151903
INFO:root:final train perplexity: 4.36857795715332
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.92s/it]
INFO:root:eval mean loss: 3761.971387065049
INFO:root:eval perplexity: 4.577856540679932
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it]
INFO:root:eval mean loss: 4683.114101978059
INFO:root:eval perplexity: 6.786868095397949
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/91
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [9:40:45<57:11, 381.30s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3703.390010127315
INFO:root:current train perplexity4.3380327224731445
INFO:root:current mean train loss 3750.7427911232776
INFO:root:current train perplexity4.370143413543701
INFO:root:current mean train loss 3752.284281860889
INFO:root:current train perplexity4.380821704864502
INFO:root:current mean train loss 3756.5974091229455
INFO:root:current train perplexity4.376816749572754
INFO:root:current mean train loss 3752.326878567769
INFO:root:current train perplexity4.373802661895752
INFO:root:current mean train loss 3749.9327913751185
INFO:root:current train perplexity4.372415065765381
INFO:root:current mean train loss 3748.7002467105262
INFO:root:current train perplexity4.370284557342529
INFO:root:current mean train loss 3745.4798706558418
INFO:root:current train perplexity4.370059013366699
INFO:root:current mean train loss 3740.5924779299235
INFO:root:current train perplexity4.367358684539795
INFO:root:current mean train loss 3739.285075133158
INFO:root:current train perplexity4.365109443664551

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:25<00:00, 325.06s/it]
INFO:root:final mean train loss: 3736.2373390813027
INFO:root:final train perplexity: 4.366901397705078
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.37s/it]
INFO:root:eval mean loss: 3766.026232130984
INFO:root:eval perplexity: 4.5853681564331055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 4685.827278299535
INFO:root:eval perplexity: 6.794402122497559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/92
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [9:47:06<50:49, 381.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3745.7055036272322
INFO:root:current train perplexity4.359764575958252
INFO:root:current mean train loss 3734.1456452546295
INFO:root:current train perplexity4.326772689819336
INFO:root:current mean train loss 3734.551134474734
INFO:root:current train perplexity4.346656799316406
INFO:root:current mean train loss 3735.932625204058
INFO:root:current train perplexity4.353514194488525
INFO:root:current mean train loss 3746.2383873248923
INFO:root:current train perplexity4.366634368896484
INFO:root:current mean train loss 3738.689144184433
INFO:root:current train perplexity4.3635430335998535
INFO:root:current mean train loss 3736.147814268578
INFO:root:current train perplexity4.364182949066162
INFO:root:current mean train loss 3735.9548316592263
INFO:root:current train perplexity4.362340450286865
INFO:root:current mean train loss 3734.441829622006
INFO:root:current train perplexity4.360634803771973
INFO:root:current mean train loss 3734.8026576077873
INFO:root:current train perplexity4.360461711883545

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.88s/it]
INFO:root:final mean train loss: 3733.3183663275936
INFO:root:final train perplexity: 4.361875534057617
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.52s/it]
INFO:root:eval mean loss: 3765.1835729720747
INFO:root:eval perplexity: 4.58380651473999
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.78s/it]
INFO:root:eval mean loss: 4688.568691821809
INFO:root:eval perplexity: 6.802023410797119
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/93
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [9:53:24<44:22, 380.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3685.3135730832123
INFO:root:current train perplexity4.264337062835693
INFO:root:current mean train loss 3736.155083929742
INFO:root:current train perplexity4.358442783355713
INFO:root:current mean train loss 3744.6319886509773
INFO:root:current train perplexity4.3677592277526855
INFO:root:current mean train loss 3741.5519136923745
INFO:root:current train perplexity4.359249114990234
INFO:root:current mean train loss 3740.087503747531
INFO:root:current train perplexity4.357676982879639
INFO:root:current mean train loss 3737.6565656293164
INFO:root:current train perplexity4.357792377471924
INFO:root:current mean train loss 3740.394829686285
INFO:root:current train perplexity4.362906455993652
INFO:root:current mean train loss 3744.182273156229
INFO:root:current train perplexity4.365163803100586
INFO:root:current mean train loss 3739.947141672227
INFO:root:current train perplexity4.362386226654053
INFO:root:current mean train loss 3740.276700388968
INFO:root:current train perplexity4.365654945373535

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.82s/it]
INFO:root:final mean train loss: 3733.9613261684294
INFO:root:final train perplexity: 4.362982749938965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.71s/it]
INFO:root:eval mean loss: 3762.8954887660684
INFO:root:eval perplexity: 4.579566955566406
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.94s/it]
INFO:root:eval mean loss: 4685.496907552083
INFO:root:eval perplexity: 6.793484687805176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/94
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [9:59:44<38:00, 380.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3745.760191674326
INFO:root:current train perplexity4.388461589813232
INFO:root:current mean train loss 3732.456552669702
INFO:root:current train perplexity4.372054100036621
INFO:root:current mean train loss 3726.330550843501
INFO:root:current train perplexity4.354051113128662
INFO:root:current mean train loss 3731.942984469596
INFO:root:current train perplexity4.356666088104248
INFO:root:current mean train loss 3732.899427595794
INFO:root:current train perplexity4.357929229736328
INFO:root:current mean train loss 3727.546890508025
INFO:root:current train perplexity4.349451065063477
INFO:root:current mean train loss 3731.654526764713
INFO:root:current train perplexity4.354282379150391
INFO:root:current mean train loss 3731.407707041653
INFO:root:current train perplexity4.3533034324646
INFO:root:current mean train loss 3730.3192013876137
INFO:root:current train perplexity4.354266166687012
INFO:root:current mean train loss 3732.7746851587144
INFO:root:current train perplexity4.355413436889648

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:24<00:00, 324.46s/it]
INFO:root:final mean train loss: 3731.0272286938084
INFO:root:final train perplexity: 4.357934951782227
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.30s/it]
INFO:root:eval mean loss: 3762.25259204621
INFO:root:eval perplexity: 4.578376770019531
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it]
INFO:root:eval mean loss: 4683.359709178302
INFO:root:eval perplexity: 6.787550449371338
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/95
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [10:06:04<31:40, 380.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3678.6741053694386
INFO:root:current train perplexity4.28940486907959
INFO:root:current mean train loss 3709.9166850923743
INFO:root:current train perplexity4.325942039489746
INFO:root:current mean train loss 3712.6328266394185
INFO:root:current train perplexity4.337373733520508
INFO:root:current mean train loss 3720.8645978412255
INFO:root:current train perplexity4.341119289398193
INFO:root:current mean train loss 3721.8836816193493
INFO:root:current train perplexity4.343825340270996
INFO:root:current mean train loss 3733.465665267917
INFO:root:current train perplexity4.355125427246094
INFO:root:current mean train loss 3733.31183166967
INFO:root:current train perplexity4.356753826141357
INFO:root:current mean train loss 3729.6268495501895
INFO:root:current train perplexity4.353127956390381
INFO:root:current mean train loss 3730.182066947395
INFO:root:current train perplexity4.354748725891113
INFO:root:current mean train loss 3731.1311809074396
INFO:root:current train perplexity4.3549017906188965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.71s/it]
INFO:root:final mean train loss: 3729.5877730461857
INFO:root:final train perplexity: 4.355460166931152
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.93s/it]
INFO:root:eval mean loss: 3757.3801546570257
INFO:root:eval perplexity: 4.56936502456665
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.81s/it]
INFO:root:eval mean loss: 4679.434982408023
INFO:root:eval perplexity: 6.776665687561035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/96
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [10:12:24<25:19, 379.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3724.4037357159514
INFO:root:current train perplexity4.36750602722168
INFO:root:current mean train loss 3740.61149039811
INFO:root:current train perplexity4.362095832824707
INFO:root:current mean train loss 3737.13247509217
INFO:root:current train perplexity4.362993240356445
INFO:root:current mean train loss 3743.123211187628
INFO:root:current train perplexity4.374111175537109
INFO:root:current mean train loss 3734.524983375435
INFO:root:current train perplexity4.363204002380371
INFO:root:current mean train loss 3736.6419430149085
INFO:root:current train perplexity4.365937232971191
INFO:root:current mean train loss 3735.360510052591
INFO:root:current train perplexity4.362272262573242
INFO:root:current mean train loss 3733.63787229058
INFO:root:current train perplexity4.359622955322266
INFO:root:current mean train loss 3729.15952576458
INFO:root:current train perplexity4.354175567626953
INFO:root:current mean train loss 3731.4691728909484
INFO:root:current train perplexity4.3554253578186035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:22<00:00, 322.75s/it]
INFO:root:final mean train loss: 3730.0414265663394
INFO:root:final train perplexity: 4.3562397956848145
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.00s/it]
INFO:root:eval mean loss: 3759.070270944149
INFO:root:eval perplexity: 4.572488307952881
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it]
INFO:root:eval mean loss: 4680.595540364583
INFO:root:eval perplexity: 6.779882907867432
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/97
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [10:18:41<18:57, 379.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3714.569794921875
INFO:root:current train perplexity4.33709192276001
INFO:root:current mean train loss 3708.822744140625
INFO:root:current train perplexity4.318456172943115
INFO:root:current mean train loss 3725.5242569247157
INFO:root:current train perplexity4.334450721740723
INFO:root:current mean train loss 3734.1167805989585
INFO:root:current train perplexity4.3502678871154785
INFO:root:current mean train loss 3729.496254111842
INFO:root:current train perplexity4.343510150909424
INFO:root:current mean train loss 3731.232429517663
INFO:root:current train perplexity4.34787130355835
INFO:root:current mean train loss 3735.484330150463
INFO:root:current train perplexity4.351925373077393
INFO:root:current mean train loss 3733.8598935231853
INFO:root:current train perplexity4.352797031402588
INFO:root:current mean train loss 3729.6992876674108
INFO:root:current train perplexity4.350580215454102
INFO:root:current mean train loss 3730.1428543169072
INFO:root:current train perplexity4.352336883544922

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:21<00:00, 321.40s/it]
INFO:root:final mean train loss: 3727.7769324394962
INFO:root:final train perplexity: 4.352349758148193
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.25s/it]
INFO:root:eval mean loss: 3757.598154920213
INFO:root:eval perplexity: 4.569767951965332
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it]
INFO:root:eval mean loss: 4679.449461159131
INFO:root:eval perplexity: 6.776705741882324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/98
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [10:24:58<12:37, 378.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3741.964243693524
INFO:root:current train perplexity4.367907524108887
INFO:root:current mean train loss 3734.347632236168
INFO:root:current train perplexity4.36186408996582
INFO:root:current mean train loss 3737.5788927920717
INFO:root:current train perplexity4.361265182495117
INFO:root:current mean train loss 3732.642304662002
INFO:root:current train perplexity4.354781627655029
INFO:root:current mean train loss 3732.9179141595496
INFO:root:current train perplexity4.350998401641846
INFO:root:current mean train loss 3725.6765316788164
INFO:root:current train perplexity4.343822002410889
INFO:root:current mean train loss 3729.0239593818633
INFO:root:current train perplexity4.346251964569092
INFO:root:current mean train loss 3732.127310449593
INFO:root:current train perplexity4.34937047958374
INFO:root:current mean train loss 3729.713058730889
INFO:root:current train perplexity4.349409580230713
INFO:root:current mean train loss 3729.672371477222
INFO:root:current train perplexity4.349670886993408

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:20<00:00, 320.69s/it]
INFO:root:final mean train loss: 3725.962990606985
INFO:root:final train perplexity: 4.349236011505127
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.01s/it]
INFO:root:eval mean loss: 3755.509994182181
INFO:root:eval perplexity: 4.565910339355469
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.63s/it]
INFO:root:eval mean loss: 4677.293025889295
INFO:root:eval perplexity: 6.770732879638672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/99
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [10:31:13<06:17, 377.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3722.4945484203295
INFO:root:current train perplexity4.366184711456299
INFO:root:current mean train loss 3719.106179442081
INFO:root:current train perplexity4.365084648132324
INFO:root:current mean train loss 3714.7374246603845
INFO:root:current train perplexity4.348934650421143
INFO:root:current mean train loss 3712.189391309343
INFO:root:current train perplexity4.337435722351074
INFO:root:current mean train loss 3714.0260658652624
INFO:root:current train perplexity4.339244842529297
INFO:root:current mean train loss 3717.6163513906513
INFO:root:current train perplexity4.340221881866455
INFO:root:current mean train loss 3722.021991028627
INFO:root:current train perplexity4.346166610717773
INFO:root:current mean train loss 3724.0089751772875
INFO:root:current train perplexity4.346208095550537
INFO:root:current mean train loss 3723.5410723445393
INFO:root:current train perplexity4.344648361206055
INFO:root:current mean train loss 3728.462811051416
INFO:root:current train perplexity4.348690509796143

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:23<00:00, 323.58s/it]
INFO:root:final mean train loss: 3725.7991667716733
INFO:root:final train perplexity: 4.348954677581787
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.57s/it]
INFO:root:eval mean loss: 3755.375017314938
INFO:root:eval perplexity: 4.565661430358887
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.64s/it]
INFO:root:eval mean loss: 4677.125606022828
INFO:root:eval perplexity: 6.770269393920898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_100e_128/100
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [10:37:33<00:00, 378.31s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [10:37:34<00:00, 382.54s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it]
INFO:root:eval mean loss: 3755.375017314938
INFO:root:eval perplexity: 4.565661430358887
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.20s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.20s/it]
INFO:root:eval mean loss: 4677.125606022828
INFO:root:eval perplexity: 6.770269393920898
INFO:root:evalaution complete
INFO:root:save model final: multiqal6_multiqal6_not_concat_100e_128/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x14c99bd02f06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x14c99bcfa8e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x14c99bc1fe09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x14c99bd03a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x14c99bc1d948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x14c99bd03a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x14c99bbd8b46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x14c99b63d46a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x14ca97e59a27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x14ca97e59be0]
python(+0x24a989) [0x5587a1a9f989]
python(+0x24a9bd) [0x5587a1a9f9bd]
python(+0x24aa14) [0x5587a1a9fa14]
python(+0x108f75) [0x5587a195df75]
python(Py_RunMain+0x313) [0x5587a1aa2983]
python(Py_BytesMain+0x39) [0x5587a1aa2bc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x14ca97e370b3]
python(+0x1d6e13) [0x5587a1a2be13]
/opt/slurm/data/slurmd/job29927411/slurm_script: line 253: 2415521 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path sentence-transformers/multi-qa-MiniLM-L6-cos-v1 --data_config data_config.json --data_folder fast_processed_data_opt_multiqa_corrected --output multiqal6_multiqal6_not_concat_100e_128 --epochs 100 --save_head  --save_epochs 1 --external_embedding --test_eval --not_concat_self --batch_size 128
"
