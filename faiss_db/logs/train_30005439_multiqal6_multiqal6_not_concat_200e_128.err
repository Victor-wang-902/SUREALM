INFO:root:Output: multiqal6_multiqal6_not_concat_200e_128
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.query.bias', 'cls.predictions.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.value.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.value.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.query.weight', 'cls.predictions.decoder.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.value.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.1.crossattention.self.query.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24629.995265151516
INFO:root:current train perplexity16609.28515625
INFO:root:current mean train loss 20790.029983903896
INFO:root:current train perplexity3617.700927734375
INFO:root:current mean train loss 17929.853401311662
INFO:root:current train perplexity1174.9212646484375
INFO:root:current mean train loss 15991.642747004229
INFO:root:current train perplexity542.5681762695312
INFO:root:current mean train loss 14589.45454776741
INFO:root:current train perplexity312.1860656738281
INFO:root:current mean train loss 13527.47938377113
INFO:root:current train perplexity206.06581115722656
INFO:root:current mean train loss 12702.448781462357
INFO:root:current train perplexity148.84043884277344
INFO:root:current mean train loss 12040.410356084754
INFO:root:current train perplexity114.92764282226562
INFO:root:current mean train loss 11498.734643310276
INFO:root:current train perplexity92.87586975097656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.26s/it]
INFO:root:final mean train loss: 11061.97006717805
INFO:root:final train perplexity: 78.591796875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.98s/it]
INFO:root:eval mean loss: 6394.777097877881
INFO:root:eval perplexity: 13.274700164794922
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.60s/it]
INFO:root:eval mean loss: 6903.549586519282
INFO:root:eval perplexity: 16.82651710510254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/1
  0%|          | 1/200 [07:00<23:16:13, 420.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6803.175711495535
INFO:root:current train perplexity14.777538299560547
INFO:root:current mean train loss 6810.086074401285
INFO:root:current train perplexity14.331704139709473
INFO:root:current mean train loss 6712.368859922252
INFO:root:current train perplexity13.984065055847168
INFO:root:current mean train loss 6624.401744134263
INFO:root:current train perplexity13.60416030883789
INFO:root:current mean train loss 6554.546513887823
INFO:root:current train perplexity13.281702995300293
INFO:root:current mean train loss 6500.531553370008
INFO:root:current train perplexity12.959802627563477
INFO:root:current mean train loss 6445.840814681579
INFO:root:current train perplexity12.675299644470215
INFO:root:current mean train loss 6398.023563886802
INFO:root:current train perplexity12.437749862670898
INFO:root:current mean train loss 6349.625065346189
INFO:root:current train perplexity12.217488288879395
INFO:root:current mean train loss 6302.897956755616
INFO:root:current train perplexity12.00631332397461

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.88s/it]
INFO:root:final mean train loss: 6267.031727575487
INFO:root:final train perplexity: 11.852340698242188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.46s/it]
INFO:root:eval mean loss: 5470.332945478724
INFO:root:eval perplexity: 9.134352684020996
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.24s/it]
INFO:root:eval mean loss: 6087.043346215647
INFO:root:eval perplexity: 12.050132751464844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/2
  1%|          | 2/200 [14:11<23:28:22, 426.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5863.079850260417
INFO:root:current train perplexity10.169355392456055
INFO:root:current mean train loss 5760.748000169837
INFO:root:current train perplexity9.85295581817627
INFO:root:current mean train loss 5766.15629087936
INFO:root:current train perplexity9.781865119934082
INFO:root:current mean train loss 5741.563969494047
INFO:root:current train perplexity9.674160957336426
INFO:root:current mean train loss 5727.684511483434
INFO:root:current train perplexity9.594059944152832
INFO:root:current mean train loss 5718.135124962076
INFO:root:current train perplexity9.525696754455566
INFO:root:current mean train loss 5692.467501111534
INFO:root:current train perplexity9.43265438079834
INFO:root:current mean train loss 5667.180136172421
INFO:root:current train perplexity9.351340293884277
INFO:root:current mean train loss 5654.0590778374235
INFO:root:current train perplexity9.291994094848633
INFO:root:current mean train loss 5634.63541933487
INFO:root:current train perplexity9.214696884155273

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:13<00:00, 373.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:13<00:00, 373.77s/it]
INFO:root:final mean train loss: 5614.468543391074
INFO:root:final train perplexity: 9.162055015563965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.16s/it]
INFO:root:eval mean loss: 5093.858003656915
INFO:root:eval perplexity: 7.844454288482666
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.34s/it]
INFO:root:eval mean loss: 5764.192791445035
INFO:root:eval perplexity: 10.559836387634277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/3
  2%|â–         | 3/200 [21:31<23:40:42, 432.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5522.472911005435
INFO:root:current train perplexity8.541831016540527
INFO:root:current mean train loss 5410.514700044461
INFO:root:current train perplexity8.425905227661133
INFO:root:current mean train loss 5397.99904533352
INFO:root:current train perplexity8.403830528259277
INFO:root:current mean train loss 5374.237180727554
INFO:root:current train perplexity8.324341773986816
INFO:root:current mean train loss 5368.524231678487
INFO:root:current train perplexity8.277112007141113
INFO:root:current mean train loss 5348.506931166348
INFO:root:current train perplexity8.222338676452637
INFO:root:current mean train loss 5339.224611726274
INFO:root:current train perplexity8.184062004089355
INFO:root:current mean train loss 5324.15989218642
INFO:root:current train perplexity8.143908500671387
INFO:root:current mean train loss 5305.852941909364
INFO:root:current train perplexity8.107535362243652
INFO:root:current mean train loss 5293.428562284162
INFO:root:current train perplexity8.06174373626709

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.59s/it]
INFO:root:final mean train loss: 5281.422875435122
INFO:root:final train perplexity: 8.033934593200684
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.23s/it]
INFO:root:eval mean loss: 4851.178790586215
INFO:root:eval perplexity: 7.111222743988037
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.82s/it]
INFO:root:eval mean loss: 5556.66719304078
INFO:root:eval perplexity: 9.70069408416748
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/4
  2%|â–         | 4/200 [28:42<23:31:23, 432.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5102.116242439516
INFO:root:current train perplexity7.551728248596191
INFO:root:current mean train loss 5119.736246123569
INFO:root:current train perplexity7.549647331237793
INFO:root:current mean train loss 5109.974522710362
INFO:root:current train perplexity7.531880855560303
INFO:root:current mean train loss 5114.506052622262
INFO:root:current train perplexity7.521121025085449
INFO:root:current mean train loss 5113.370858106148
INFO:root:current train perplexity7.501008987426758
INFO:root:current mean train loss 5093.87294940266
INFO:root:current train perplexity7.4576005935668945
INFO:root:current mean train loss 5085.312339818987
INFO:root:current train perplexity7.434038162231445
INFO:root:current mean train loss 5083.175684395306
INFO:root:current train perplexity7.418434143066406
INFO:root:current mean train loss 5069.879711238343
INFO:root:current train perplexity7.383062839508057
INFO:root:current mean train loss 5062.91421512067
INFO:root:current train perplexity7.363333702087402

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:06<00:00, 366.29s/it]
INFO:root:final mean train loss: 5056.960348498436
INFO:root:final train perplexity: 7.353063583374023
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.15s/it]
INFO:root:eval mean loss: 4726.112817209663
INFO:root:eval perplexity: 6.760530471801758
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.52s/it]
INFO:root:eval mean loss: 5455.202169215426
INFO:root:eval perplexity: 9.306445121765137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/5
  2%|â–Ž         | 5/200 [35:50<23:19:48, 430.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5050.70947265625
INFO:root:current train perplexity7.220707416534424
INFO:root:current mean train loss 4967.677924066997
INFO:root:current train perplexity7.06828498840332
INFO:root:current mean train loss 4960.25957153831
INFO:root:current train perplexity7.037530422210693
INFO:root:current mean train loss 4945.939680701512
INFO:root:current train perplexity7.020226955413818
INFO:root:current mean train loss 4937.132507741316
INFO:root:current train perplexity7.0044636726379395
INFO:root:current mean train loss 4931.80022502609
INFO:root:current train perplexity6.984611511230469
INFO:root:current mean train loss 4924.216825147936
INFO:root:current train perplexity6.968700408935547
INFO:root:current mean train loss 4917.304789913524
INFO:root:current train perplexity6.954034328460693
INFO:root:current mean train loss 4912.897091380178
INFO:root:current train perplexity6.942885398864746
INFO:root:current mean train loss 4905.214464669029
INFO:root:current train perplexity6.92192268371582

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:10<00:00, 370.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:10<00:00, 370.20s/it]
INFO:root:final mean train loss: 4905.263932135797
INFO:root:final train perplexity: 6.925902843475342
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.97s/it]
INFO:root:eval mean loss: 4565.759609790559
INFO:root:eval perplexity: 6.336073398590088
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.68s/it]
INFO:root:eval mean loss: 5315.082886607935
INFO:root:eval perplexity: 8.788206100463867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/6
  3%|â–Ž         | 6/200 [43:03<23:14:18, 431.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4878.148520611702
INFO:root:current train perplexity6.784853935241699
INFO:root:current mean train loss 4826.632136546024
INFO:root:current train perplexity6.722185134887695
INFO:root:current mean train loss 4840.423388276506
INFO:root:current train perplexity6.760092735290527
INFO:root:current mean train loss 4859.075333916831
INFO:root:current train perplexity6.771615982055664
INFO:root:current mean train loss 4867.296141485774
INFO:root:current train perplexity6.79712438583374
INFO:root:current mean train loss 4858.6325719299875
INFO:root:current train perplexity6.784059524536133
INFO:root:current mean train loss 4852.478428458872
INFO:root:current train perplexity6.781217575073242
INFO:root:current mean train loss 4855.96378972923
INFO:root:current train perplexity6.781817436218262
INFO:root:current mean train loss 4854.687318119558
INFO:root:current train perplexity6.7787089347839355
INFO:root:current mean train loss 4850.05104756179
INFO:root:current train perplexity6.766473293304443

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.76s/it]
INFO:root:final mean train loss: 4847.547128615841
INFO:root:final train perplexity: 6.769976615905762
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.73s/it]
INFO:root:eval mean loss: 4506.79602656804
INFO:root:eval perplexity: 6.186786651611328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it]
INFO:root:eval mean loss: 5271.483439993351
INFO:root:eval perplexity: 8.632912635803223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/7
  4%|â–Ž         | 7/200 [50:10<23:03:07, 429.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4794.538778409091
INFO:root:current train perplexity6.611095428466797
INFO:root:current mean train loss 4788.92939453125
INFO:root:current train perplexity6.62561559677124
INFO:root:current mean train loss 4779.701579733456
INFO:root:current train perplexity6.6117024421691895
INFO:root:current mean train loss 4775.835212643045
INFO:root:current train perplexity6.600879192352295
INFO:root:current mean train loss 4774.033662431319
INFO:root:current train perplexity6.585244178771973
INFO:root:current mean train loss 4767.153521783503
INFO:root:current train perplexity6.57063627243042
INFO:root:current mean train loss 4763.80773646231
INFO:root:current train perplexity6.5594329833984375
INFO:root:current mean train loss 4759.195476769453
INFO:root:current train perplexity6.542459011077881
INFO:root:current mean train loss 4762.110388112208
INFO:root:current train perplexity6.540470123291016
INFO:root:current mean train loss 4755.769637342523
INFO:root:current train perplexity6.523157119750977

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.96s/it]
INFO:root:final mean train loss: 4752.65532991963
INFO:root:final train perplexity: 6.521210193634033
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.29s/it]
INFO:root:eval mean loss: 4427.845675421099
INFO:root:eval perplexity: 5.9923930168151855
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.48s/it]
INFO:root:eval mean loss: 5202.919630984043
INFO:root:eval perplexity: 8.394234657287598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/8
  4%|â–         | 8/200 [57:13<22:48:57, 427.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4669.018159412202
INFO:root:current train perplexity6.254232883453369
INFO:root:current mean train loss 4680.5519839795825
INFO:root:current train perplexity6.299721717834473
INFO:root:current mean train loss 4683.079671533389
INFO:root:current train perplexity6.302394390106201
INFO:root:current mean train loss 4681.724625516529
INFO:root:current train perplexity6.308475494384766
INFO:root:current mean train loss 4675.748890557506
INFO:root:current train perplexity6.2883830070495605
INFO:root:current mean train loss 4663.829033914299
INFO:root:current train perplexity6.275552749633789
INFO:root:current mean train loss 4661.557759326687
INFO:root:current train perplexity6.278636455535889
INFO:root:current mean train loss 4656.0900523734435
INFO:root:current train perplexity6.266737937927246
INFO:root:current mean train loss 4651.091053137221
INFO:root:current train perplexity6.257826328277588
INFO:root:current mean train loss 4647.288690584843
INFO:root:current train perplexity6.24855375289917

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.65s/it]
INFO:root:final mean train loss: 4643.33869466474
INFO:root:final train perplexity: 6.245938777923584
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.71s/it]
INFO:root:eval mean loss: 4346.729812513852
INFO:root:eval perplexity: 5.7990264892578125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.29s/it]
INFO:root:eval mean loss: 5136.298828125
INFO:root:eval perplexity: 8.168643951416016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/9
  4%|â–         | 9/200 [1:04:17<22:38:11, 426.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4593.773949851452
INFO:root:current train perplexity6.118238925933838
INFO:root:current mean train loss 4583.6814578764615
INFO:root:current train perplexity6.093385696411133
INFO:root:current mean train loss 4573.719643680812
INFO:root:current train perplexity6.090721130371094
INFO:root:current mean train loss 4560.419435567933
INFO:root:current train perplexity6.066461563110352
INFO:root:current mean train loss 4569.503028691448
INFO:root:current train perplexity6.066303253173828
INFO:root:current mean train loss 4558.002905316194
INFO:root:current train perplexity6.052515983581543
INFO:root:current mean train loss 4555.737826442576
INFO:root:current train perplexity6.050621032714844
INFO:root:current mean train loss 4554.950711142692
INFO:root:current train perplexity6.0355401039123535
INFO:root:current mean train loss 4557.759392266432
INFO:root:current train perplexity6.0374979972839355
INFO:root:current mean train loss 4559.219382854741
INFO:root:current train perplexity6.035586833953857

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.51s/it]
INFO:root:final mean train loss: 4557.13606803648
INFO:root:final train perplexity: 6.0370893478393555
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.39s/it]
INFO:root:eval mean loss: 4290.186445520279
INFO:root:eval perplexity: 5.667937755584717
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it]
INFO:root:eval mean loss: 5087.932741855053
INFO:root:eval perplexity: 8.00867748260498
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/10
  5%|â–Œ         | 10/200 [1:11:21<22:28:17, 425.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4506.616099683544
INFO:root:current train perplexity5.86908483505249
INFO:root:current mean train loss 4500.305804545653
INFO:root:current train perplexity5.881276607513428
INFO:root:current mean train loss 4495.43840655802
INFO:root:current train perplexity5.886427402496338
INFO:root:current mean train loss 4494.762484024572
INFO:root:current train perplexity5.876276969909668
INFO:root:current mean train loss 4499.035456456322
INFO:root:current train perplexity5.883561611175537
INFO:root:current mean train loss 4497.588585097555
INFO:root:current train perplexity5.880191802978516
INFO:root:current mean train loss 4495.744825585075
INFO:root:current train perplexity5.880231857299805
INFO:root:current mean train loss 4493.456360255034
INFO:root:current train perplexity5.876504421234131
INFO:root:current mean train loss 4491.580117565238
INFO:root:current train perplexity5.872443675994873
INFO:root:current mean train loss 4487.667537825588
INFO:root:current train perplexity5.865532398223877

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.09s/it]
INFO:root:final mean train loss: 4485.2087807193875
INFO:root:final train perplexity: 5.868180274963379
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it]
INFO:root:eval mean loss: 4236.786013339428
INFO:root:eval perplexity: 5.546858787536621
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.35s/it]
INFO:root:eval mean loss: 5042.417958361038
INFO:root:eval perplexity: 7.8610029220581055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/11
  6%|â–Œ         | 11/200 [1:18:23<22:17:07, 424.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4434.194074959591
INFO:root:current train perplexity5.7919464111328125
INFO:root:current mean train loss 4439.775189568015
INFO:root:current train perplexity5.781176567077637
INFO:root:current mean train loss 4435.744565106435
INFO:root:current train perplexity5.765757083892822
INFO:root:current mean train loss 4428.621175761063
INFO:root:current train perplexity5.749753475189209
INFO:root:current mean train loss 4426.922300616819
INFO:root:current train perplexity5.742218017578125
INFO:root:current mean train loss 4432.224773244517
INFO:root:current train perplexity5.739383220672607
INFO:root:current mean train loss 4433.8524644343615
INFO:root:current train perplexity5.74481201171875
INFO:root:current mean train loss 4433.996525882008
INFO:root:current train perplexity5.745560169219971
INFO:root:current mean train loss 4429.728993997499
INFO:root:current train perplexity5.734984397888184
INFO:root:current mean train loss 4426.739302831339
INFO:root:current train perplexity5.726260662078857

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.58s/it]
INFO:root:final mean train loss: 4423.094336909632
INFO:root:final train perplexity: 5.726122856140137
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.89s/it]
INFO:root:eval mean loss: 4191.924290433843
INFO:root:eval perplexity: 5.447142124176025
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it]
INFO:root:eval mean loss: 5008.250832848515
INFO:root:eval perplexity: 7.751935958862305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/12
  6%|â–Œ         | 12/200 [1:25:24<22:06:58, 423.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4375.713186163652
INFO:root:current train perplexity5.64996337890625
INFO:root:current mean train loss 4368.62552709335
INFO:root:current train perplexity5.631323337554932
INFO:root:current mean train loss 4371.861879303496
INFO:root:current train perplexity5.618104457855225
INFO:root:current mean train loss 4371.684751409217
INFO:root:current train perplexity5.61055326461792
INFO:root:current mean train loss 4368.852712673611
INFO:root:current train perplexity5.606966018676758
INFO:root:current mean train loss 4372.3518398765755
INFO:root:current train perplexity5.603482246398926
INFO:root:current mean train loss 4368.043400474932
INFO:root:current train perplexity5.600831985473633
INFO:root:current mean train loss 4366.233056640625
INFO:root:current train perplexity5.598495006561279
INFO:root:current mean train loss 4365.920649386784
INFO:root:current train perplexity5.59613037109375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.38s/it]
INFO:root:final mean train loss: 4366.885436027281
INFO:root:final train perplexity: 5.600536823272705
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.94s/it]
INFO:root:eval mean loss: 4150.104220342974
INFO:root:eval perplexity: 5.355802059173584
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it]
INFO:root:eval mean loss: 4974.172782302749
INFO:root:eval perplexity: 7.6446614265441895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/13
  6%|â–‹         | 13/200 [1:32:27<21:59:35, 423.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4467.851725260417
INFO:root:current train perplexity5.682191371917725
INFO:root:current mean train loss 4344.081386529127
INFO:root:current train perplexity5.526072978973389
INFO:root:current mean train loss 4331.6562283520625
INFO:root:current train perplexity5.5054240226745605
INFO:root:current mean train loss 4324.602580961221
INFO:root:current train perplexity5.503539562225342
INFO:root:current mean train loss 4325.729391017564
INFO:root:current train perplexity5.501460075378418
INFO:root:current mean train loss 4329.828453594837
INFO:root:current train perplexity5.515796661376953
INFO:root:current mean train loss 4326.176914499767
INFO:root:current train perplexity5.5103912353515625
INFO:root:current mean train loss 4320.896032211282
INFO:root:current train perplexity5.50282096862793
INFO:root:current mean train loss 4322.007435191761
INFO:root:current train perplexity5.501589298248291
INFO:root:current mean train loss 4320.793642232056
INFO:root:current train perplexity5.494600296020508

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.89s/it]
INFO:root:final mean train loss: 4317.134412950085
INFO:root:final train perplexity: 5.49168062210083
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.04s/it]
INFO:root:eval mean loss: 4118.0897363973845
INFO:root:eval perplexity: 5.286913871765137
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.37s/it]
INFO:root:eval mean loss: 4948.6646356244455
INFO:root:eval perplexity: 7.565337657928467
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/14
  7%|â–‹         | 14/200 [1:39:28<21:50:01, 422.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4395.026877663352
INFO:root:current train perplexity5.472446441650391
INFO:root:current mean train loss 4293.844627586571
INFO:root:current train perplexity5.433901309967041
INFO:root:current mean train loss 4288.802644123964
INFO:root:current train perplexity5.427015781402588
INFO:root:current mean train loss 4289.6876091175145
INFO:root:current train perplexity5.423382759094238
INFO:root:current mean train loss 4272.7695829294025
INFO:root:current train perplexity5.399486064910889
INFO:root:current mean train loss 4276.418891324456
INFO:root:current train perplexity5.398900032043457
INFO:root:current mean train loss 4276.300685751457
INFO:root:current train perplexity5.400615692138672
INFO:root:current mean train loss 4278.114406494484
INFO:root:current train perplexity5.399974822998047
INFO:root:current mean train loss 4278.581590231485
INFO:root:current train perplexity5.398735523223877
INFO:root:current mean train loss 4280.831282480619
INFO:root:current train perplexity5.403966903686523

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.94s/it]
INFO:root:final mean train loss: 4273.6150669590115
INFO:root:final train perplexity: 5.398196697235107
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.42s/it]
INFO:root:eval mean loss: 4087.5514426806294
INFO:root:eval perplexity: 5.22202730178833
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.25s/it]
INFO:root:eval mean loss: 4919.973134142288
INFO:root:eval perplexity: 7.477097034454346
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/15
  8%|â–Š         | 15/200 [1:46:32<21:44:14, 423.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4189.464753803454
INFO:root:current train perplexity5.261624813079834
INFO:root:current mean train loss 4264.017955619748
INFO:root:current train perplexity5.324496746063232
INFO:root:current mean train loss 4259.6845056542525
INFO:root:current train perplexity5.330425262451172
INFO:root:current mean train loss 4250.458127969485
INFO:root:current train perplexity5.334338665008545
INFO:root:current mean train loss 4247.778526579281
INFO:root:current train perplexity5.330507755279541
INFO:root:current mean train loss 4244.311203561537
INFO:root:current train perplexity5.322259902954102
INFO:root:current mean train loss 4242.022454232507
INFO:root:current train perplexity5.318386077880859
INFO:root:current mean train loss 4245.35151224574
INFO:root:current train perplexity5.325557708740234
INFO:root:current mean train loss 4243.576744815515
INFO:root:current train perplexity5.324738025665283
INFO:root:current mean train loss 4243.86704616941
INFO:root:current train perplexity5.325493335723877

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.65s/it]
INFO:root:final mean train loss: 4235.932565073813
INFO:root:final train perplexity: 5.318534851074219
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.21s/it]
INFO:root:eval mean loss: 4063.214961491578
INFO:root:eval perplexity: 5.170889854431152
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.95s/it]
INFO:root:eval mean loss: 4905.222786112035
INFO:root:eval perplexity: 7.432134628295898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/16
  8%|â–Š         | 16/200 [1:53:34<21:36:26, 422.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4133.120316116898
INFO:root:current train perplexity5.054794788360596
INFO:root:current mean train loss 4210.189187838337
INFO:root:current train perplexity5.223127365112305
INFO:root:current mean train loss 4227.004532196448
INFO:root:current train perplexity5.266498565673828
INFO:root:current mean train loss 4209.096568442995
INFO:root:current train perplexity5.242265224456787
INFO:root:current mean train loss 4195.784757162983
INFO:root:current train perplexity5.236249923706055
INFO:root:current mean train loss 4191.405603282139
INFO:root:current train perplexity5.230207920074463
INFO:root:current mean train loss 4192.27687454832
INFO:root:current train perplexity5.226508617401123
INFO:root:current mean train loss 4188.902308824794
INFO:root:current train perplexity5.225283145904541
INFO:root:current mean train loss 4195.770536152887
INFO:root:current train perplexity5.235367774963379
INFO:root:current mean train loss 4199.053241881995
INFO:root:current train perplexity5.237351417541504

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.72s/it]
INFO:root:final mean train loss: 4199.9123606528
INFO:root:final train perplexity: 5.243488311767578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.11s/it]
INFO:root:eval mean loss: 4037.3704150044327
INFO:root:eval perplexity: 5.11713171005249
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.30s/it]
INFO:root:eval mean loss: 4877.700219553413
INFO:root:eval perplexity: 7.348958969116211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/17
  8%|â–Š         | 17/200 [2:00:36<21:29:07, 422.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4166.726381138393
INFO:root:current train perplexity5.22514009475708
INFO:root:current mean train loss 4166.024014395254
INFO:root:current train perplexity5.157880783081055
INFO:root:current mean train loss 4178.894895902593
INFO:root:current train perplexity5.17452335357666
INFO:root:current mean train loss 4168.7757375233205
INFO:root:current train perplexity5.1685590744018555
INFO:root:current mean train loss 4178.27576721893
INFO:root:current train perplexity5.18609619140625
INFO:root:current mean train loss 4173.281053774825
INFO:root:current train perplexity5.187244892120361
INFO:root:current mean train loss 4180.286313130537
INFO:root:current train perplexity5.187329292297363
INFO:root:current mean train loss 4174.8099486474275
INFO:root:current train perplexity5.182735919952393
INFO:root:current mean train loss 4173.149453241954
INFO:root:current train perplexity5.18029260635376
INFO:root:current mean train loss 4168.885046060327
INFO:root:current train perplexity5.175264358520508

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.22s/it]
INFO:root:final mean train loss: 4166.806626719813
INFO:root:final train perplexity: 5.175447463989258
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.36s/it]
INFO:root:eval mean loss: 4011.957452002992
INFO:root:eval perplexity: 5.064815998077393
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it]
INFO:root:eval mean loss: 4858.82022592531
INFO:root:eval perplexity: 7.292440414428711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/18
  9%|â–‰         | 18/200 [2:07:39<21:21:53, 422.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4072.078142033067
INFO:root:current train perplexity5.044776439666748
INFO:root:current mean train loss 4124.317951335774
INFO:root:current train perplexity5.094161033630371
INFO:root:current mean train loss 4126.558633937757
INFO:root:current train perplexity5.098233222961426
INFO:root:current mean train loss 4135.174870171283
INFO:root:current train perplexity5.113833904266357
INFO:root:current mean train loss 4129.818065083592
INFO:root:current train perplexity5.106599807739258
INFO:root:current mean train loss 4132.374488788415
INFO:root:current train perplexity5.106977462768555
INFO:root:current mean train loss 4137.384447824528
INFO:root:current train perplexity5.113616943359375
INFO:root:current mean train loss 4136.058890793237
INFO:root:current train perplexity5.111610412597656
INFO:root:current mean train loss 4140.807652519832
INFO:root:current train perplexity5.114009380340576
INFO:root:current mean train loss 4137.124204148164
INFO:root:current train perplexity5.1111321449279785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.68s/it]
INFO:root:final mean train loss: 4133.812534209221
INFO:root:final train perplexity: 5.108514308929443
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.73s/it]
INFO:root:eval mean loss: 3988.131136414007
INFO:root:eval perplexity: 5.016252517700195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.84s/it]
INFO:root:eval mean loss: 4846.354840217753
INFO:root:eval perplexity: 7.255363464355469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/19
 10%|â–‰         | 19/200 [2:14:41<21:13:55, 422.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4130.625067018995
INFO:root:current train perplexity5.068578243255615
INFO:root:current mean train loss 4120.699375582057
INFO:root:current train perplexity5.070352077484131
INFO:root:current mean train loss 4115.456212260334
INFO:root:current train perplexity5.061948776245117
INFO:root:current mean train loss 4106.661994608039
INFO:root:current train perplexity5.046390533447266
INFO:root:current mean train loss 4110.455316310976
INFO:root:current train perplexity5.048383712768555
INFO:root:current mean train loss 4110.663427114054
INFO:root:current train perplexity5.054959297180176
INFO:root:current mean train loss 4107.002804054459
INFO:root:current train perplexity5.05251407623291
INFO:root:current mean train loss 4108.084288006617
INFO:root:current train perplexity5.057060241699219
INFO:root:current mean train loss 4114.366879096743
INFO:root:current train perplexity5.060576915740967
INFO:root:current mean train loss 4109.262068659224
INFO:root:current train perplexity5.054530143737793

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.07s/it]
INFO:root:final mean train loss: 4107.406401418871
INFO:root:final train perplexity: 5.055569648742676
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.21s/it]
INFO:root:eval mean loss: 3968.9494507701684
INFO:root:eval perplexity: 4.977494716644287
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.21s/it]
INFO:root:eval mean loss: 4830.746391566932
INFO:root:eval perplexity: 7.20920467376709
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/20
 10%|â–ˆ         | 20/200 [2:21:53<21:16:28, 425.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4066.8731379104875
INFO:root:current train perplexity4.981055736541748
INFO:root:current mean train loss 4076.1221010220124
INFO:root:current train perplexity4.989221096038818
INFO:root:current mean train loss 4084.744068042652
INFO:root:current train perplexity5.000239372253418
INFO:root:current mean train loss 4088.0137385206303
INFO:root:current train perplexity5.004745006561279
INFO:root:current mean train loss 4090.73351758238
INFO:root:current train perplexity5.010068416595459
INFO:root:current mean train loss 4091.641612917878
INFO:root:current train perplexity5.010274410247803
INFO:root:current mean train loss 4085.7193786898947
INFO:root:current train perplexity5.0030975341796875
INFO:root:current mean train loss 4083.739372967103
INFO:root:current train perplexity5.003482341766357
INFO:root:current mean train loss 4079.822443827761
INFO:root:current train perplexity4.999963760375977
INFO:root:current mean train loss 4082.9301210469075
INFO:root:current train perplexity4.999423980712891

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:11<00:00, 371.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:11<00:00, 371.35s/it]
INFO:root:final mean train loss: 4080.3262688421432
INFO:root:final train perplexity: 5.001844882965088
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.52s/it]
INFO:root:eval mean loss: 3960.2702671348625
INFO:root:eval perplexity: 4.960056304931641
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.14s/it]
INFO:root:eval mean loss: 4822.916446766955
INFO:root:eval perplexity: 7.186158657073975
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/21
 10%|â–ˆ         | 21/200 [2:29:05<21:14:39, 427.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4095.3653145405783
INFO:root:current train perplexity5.0038628578186035
INFO:root:current mean train loss 4081.0128619713696
INFO:root:current train perplexity4.988321781158447
INFO:root:current mean train loss 4076.4823386660228
INFO:root:current train perplexity4.9773736000061035
INFO:root:current mean train loss 4066.231693444525
INFO:root:current train perplexity4.963934898376465
INFO:root:current mean train loss 4071.401353072303
INFO:root:current train perplexity4.969655513763428
INFO:root:current mean train loss 4070.4737253878693
INFO:root:current train perplexity4.967573642730713
INFO:root:current mean train loss 4061.0304923221984
INFO:root:current train perplexity4.9590935707092285
INFO:root:current mean train loss 4059.487326332301
INFO:root:current train perplexity4.952599048614502
INFO:root:current mean train loss 4059.87989097868
INFO:root:current train perplexity4.954183578491211
INFO:root:current mean train loss 4057.318952179744
INFO:root:current train perplexity4.950183868408203

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.25s/it]
INFO:root:final mean train loss: 4053.47979810161
INFO:root:final train perplexity: 4.949145793914795
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.51s/it]
INFO:root:eval mean loss: 3959.105463555519
INFO:root:eval perplexity: 4.957720756530762
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.80s/it]
INFO:root:eval mean loss: 4824.156319259751
INFO:root:eval perplexity: 7.189803600311279
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/22
 11%|â–ˆ         | 22/200 [2:36:06<21:01:55, 425.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4030.1458561197915
INFO:root:current train perplexity4.870142459869385
INFO:root:current mean train loss 4030.5182254464285
INFO:root:current train perplexity4.875556468963623
INFO:root:current mean train loss 4042.6037357954547
INFO:root:current train perplexity4.900600433349609
INFO:root:current mean train loss 4027.6181360677083
INFO:root:current train perplexity4.890777587890625
INFO:root:current mean train loss 4033.8720343338814
INFO:root:current train perplexity4.890941143035889
INFO:root:current mean train loss 4037.7948972486415
INFO:root:current train perplexity4.8991498947143555
INFO:root:current mean train loss 4041.5910398582178
INFO:root:current train perplexity4.908192157745361
INFO:root:current mean train loss 4037.860193737399
INFO:root:current train perplexity4.907060623168945
INFO:root:current mean train loss 4035.954132533482
INFO:root:current train perplexity4.905718803405762
INFO:root:current mean train loss 4034.4467625701122
INFO:root:current train perplexity4.905054569244385

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:08<00:00, 368.12s/it]
INFO:root:final mean train loss: 4030.930930168398
INFO:root:final train perplexity: 4.905313014984131
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.62s/it]
INFO:root:eval mean loss: 3979.2349013741136
INFO:root:eval perplexity: 4.998239517211914
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.68s/it]
INFO:root:eval mean loss: 4848.668969553413
INFO:root:eval perplexity: 7.262233734130859
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/23
 12%|â–ˆâ–        | 23/200 [2:43:20<21:02:23, 427.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4006.288459502071
INFO:root:current train perplexity4.855754852294922
INFO:root:current mean train loss 4019.1521102821894
INFO:root:current train perplexity4.879039764404297
INFO:root:current mean train loss 4024.4425346455387
INFO:root:current train perplexity4.880031585693359
INFO:root:current mean train loss 4032.460864194068
INFO:root:current train perplexity4.884427547454834
INFO:root:current mean train loss 4021.750888105752
INFO:root:current train perplexity4.8744797706604
INFO:root:current mean train loss 4017.546568044463
INFO:root:current train perplexity4.866061687469482
INFO:root:current mean train loss 4019.2741055802753
INFO:root:current train perplexity4.865869522094727
INFO:root:current mean train loss 4014.5259774355445
INFO:root:current train perplexity4.861888885498047
INFO:root:current mean train loss 4012.840136276366
INFO:root:current train perplexity4.863266468048096
INFO:root:current mean train loss 4012.8611957476314
INFO:root:current train perplexity4.8638787269592285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:15<00:00, 375.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:15<00:00, 375.38s/it]
INFO:root:final mean train loss: 4008.830228005686
INFO:root:final train perplexity: 4.86272668838501
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.94s/it]
INFO:root:eval mean loss: 3940.944446753103
INFO:root:eval perplexity: 4.921445369720459
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.60s/it]
INFO:root:eval mean loss: 4812.010279878657
INFO:root:eval perplexity: 7.154181480407715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/24
 12%|â–ˆâ–        | 24/200 [2:50:39<21:05:10, 431.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4015.8729154146636
INFO:root:current train perplexity4.824658393859863
INFO:root:current mean train loss 4003.0339291557593
INFO:root:current train perplexity4.83065128326416
INFO:root:current mean train loss 3988.076901779961
INFO:root:current train perplexity4.819831848144531
INFO:root:current mean train loss 3982.7777620983857
INFO:root:current train perplexity4.819899082183838
INFO:root:current mean train loss 3990.1120197738987
INFO:root:current train perplexity4.823924541473389
INFO:root:current mean train loss 3988.8022303960447
INFO:root:current train perplexity4.822530269622803
INFO:root:current mean train loss 3991.4232932061777
INFO:root:current train perplexity4.820390701293945
INFO:root:current mean train loss 3993.6726577315108
INFO:root:current train perplexity4.822171211242676
INFO:root:current mean train loss 3990.037560665246
INFO:root:current train perplexity4.82013463973999
INFO:root:current mean train loss 3989.4441393439392
INFO:root:current train perplexity4.819878101348877

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:15<00:00, 375.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:15<00:00, 375.50s/it]
INFO:root:final mean train loss: 3986.4372836697485
INFO:root:final train perplexity: 4.819956302642822
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.42s/it]
INFO:root:eval mean loss: 3899.100670780696
INFO:root:eval perplexity: 4.838872909545898
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.27s/it]
INFO:root:eval mean loss: 4774.781421417885
INFO:root:eval perplexity: 7.046096324920654
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/25
 12%|â–ˆâ–Ž        | 25/200 [2:58:01<21:07:01, 434.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3984.8511851917615
INFO:root:current train perplexity4.802868843078613
INFO:root:current mean train loss 3971.37905224364
INFO:root:current train perplexity4.780139923095703
INFO:root:current mean train loss 3979.656536599864
INFO:root:current train perplexity4.785113334655762
INFO:root:current mean train loss 3974.3825016643173
INFO:root:current train perplexity4.783525466918945
INFO:root:current mean train loss 3971.64009415315
INFO:root:current train perplexity4.784187316894531
INFO:root:current mean train loss 3974.3849103160214
INFO:root:current train perplexity4.785729885101318
INFO:root:current mean train loss 3971.7763525181063
INFO:root:current train perplexity4.785602569580078
INFO:root:current mean train loss 3971.1346962633957
INFO:root:current train perplexity4.782470703125
INFO:root:current mean train loss 3969.1793827994647
INFO:root:current train perplexity4.784192085266113

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:11<00:00, 371.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:11<00:00, 371.76s/it]
INFO:root:final mean train loss: 3967.6474008867817
INFO:root:final train perplexity: 4.78435754776001
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.33s/it]
INFO:root:eval mean loss: 3894.8069834607713
INFO:root:eval perplexity: 4.830479145050049
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it]
INFO:root:eval mean loss: 4773.8182225869905
INFO:root:eval perplexity: 7.04332160949707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/26
 13%|â–ˆâ–Ž        | 26/200 [3:05:16<21:00:38, 434.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3929.7059500558034
INFO:root:current train perplexity4.65308141708374
INFO:root:current mean train loss 3943.9619802314546
INFO:root:current train perplexity4.721353530883789
INFO:root:current mean train loss 3945.40380859375
INFO:root:current train perplexity4.744487762451172
INFO:root:current mean train loss 3957.867103999135
INFO:root:current train perplexity4.747452735900879
INFO:root:current mean train loss 3952.795669893082
INFO:root:current train perplexity4.741668224334717
INFO:root:current mean train loss 3951.955762874445
INFO:root:current train perplexity4.743380546569824
INFO:root:current mean train loss 3950.185226716948
INFO:root:current train perplexity4.744401931762695
INFO:root:current mean train loss 3954.131206420726
INFO:root:current train perplexity4.750596523284912
INFO:root:current mean train loss 3953.5077432209378
INFO:root:current train perplexity4.7527174949646
INFO:root:current mean train loss 3956.249904981653
INFO:root:current train perplexity4.759760856628418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.31s/it]
INFO:root:final mean train loss: 3952.7341997700355
INFO:root:final train perplexity: 4.756290435791016
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.09s/it]
INFO:root:eval mean loss: 3896.1205933482934
INFO:root:eval perplexity: 4.833045482635498
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.23s/it]
INFO:root:eval mean loss: 4771.179916057181
INFO:root:eval perplexity: 7.035727024078369
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/27
 14%|â–ˆâ–Ž        | 27/200 [3:12:18<20:42:23, 430.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3958.5799641927083
INFO:root:current train perplexity4.746040344238281
INFO:root:current mean train loss 3904.3178519870926
INFO:root:current train perplexity4.701340675354004
INFO:root:current mean train loss 3929.335546875
INFO:root:current train perplexity4.713559627532959
INFO:root:current mean train loss 3936.573329768105
INFO:root:current train perplexity4.7231621742248535
INFO:root:current mean train loss 3931.876607798381
INFO:root:current train perplexity4.723243236541748
INFO:root:current mean train loss 3932.9222732099515
INFO:root:current train perplexity4.72762393951416
INFO:root:current mean train loss 3934.3219087430134
INFO:root:current train perplexity4.727543354034424
INFO:root:current mean train loss 3940.5641321569055
INFO:root:current train perplexity4.7304768562316895
INFO:root:current mean train loss 3941.368556784413
INFO:root:current train perplexity4.7310075759887695
INFO:root:current mean train loss 3941.780501835724
INFO:root:current train perplexity4.731289386749268

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.07s/it]
INFO:root:final mean train loss: 3939.060200291295
INFO:root:final train perplexity: 4.73069953918457
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it]
INFO:root:eval mean loss: 3880.651502244016
INFO:root:eval perplexity: 4.802908420562744
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.40s/it]
INFO:root:eval mean loss: 4758.53059722684
INFO:root:eval perplexity: 6.999428749084473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/28
 14%|â–ˆâ–        | 28/200 [3:19:17<20:25:20, 427.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3916.5356233016305
INFO:root:current train perplexity4.673169136047363
INFO:root:current mean train loss 3904.6922835683436
INFO:root:current train perplexity4.677234649658203
INFO:root:current mean train loss 3913.577956400645
INFO:root:current train perplexity4.677005290985107
INFO:root:current mean train loss 3934.1026101127127
INFO:root:current train perplexity4.698047161102295
INFO:root:current mean train loss 3930.3595354517583
INFO:root:current train perplexity4.69572639465332
INFO:root:current mean train loss 3927.3537312903322
INFO:root:current train perplexity4.695054054260254
INFO:root:current mean train loss 3927.646363284385
INFO:root:current train perplexity4.697976589202881
INFO:root:current mean train loss 3926.2748638485477
INFO:root:current train perplexity4.693296909332275
INFO:root:current mean train loss 3923.560945568803
INFO:root:current train perplexity4.692326545715332
INFO:root:current mean train loss 3924.1868397887324
INFO:root:current train perplexity4.694502353668213

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.27s/it]
INFO:root:final mean train loss: 3920.762943883096
INFO:root:final train perplexity: 4.6966729164123535
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.96s/it]
INFO:root:eval mean loss: 3875.452283494016
INFO:root:eval perplexity: 4.792820930480957
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.67s/it]
INFO:root:eval mean loss: 4759.613255277593
INFO:root:eval perplexity: 7.002527713775635
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/29
 14%|â–ˆâ–        | 29/200 [3:26:21<20:14:35, 426.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3852.3636671496974
INFO:root:current train perplexity4.642899036407471
INFO:root:current mean train loss 3926.6319123479248
INFO:root:current train perplexity4.701300621032715
INFO:root:current mean train loss 3918.4897080458604
INFO:root:current train perplexity4.689941883087158
INFO:root:current mean train loss 3919.2108017843657
INFO:root:current train perplexity4.694258213043213
INFO:root:current mean train loss 3913.437758301914
INFO:root:current train perplexity4.678003311157227
INFO:root:current mean train loss 3918.85243009578
INFO:root:current train perplexity4.680642604827881
INFO:root:current mean train loss 3918.8445149223703
INFO:root:current train perplexity4.6803693771362305
INFO:root:current mean train loss 3916.4415044406205
INFO:root:current train perplexity4.680706024169922
INFO:root:current mean train loss 3912.9203904722285
INFO:root:current train perplexity4.676065921783447
INFO:root:current mean train loss 4009.893397608838
INFO:root:current train perplexity4.857439994812012

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.31s/it]
INFO:root:final mean train loss: 4054.4385681152344
INFO:root:final train perplexity: 4.951018810272217
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.46s/it]
INFO:root:eval mean loss: 4015.9738734901375
INFO:root:eval perplexity: 5.0730485916137695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.60s/it]
INFO:root:eval mean loss: 4871.980136303191
INFO:root:eval perplexity: 7.331790924072266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/30
 15%|â–ˆâ–Œ        | 30/200 [3:33:22<20:03:44, 424.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4335.161633613782
INFO:root:current train perplexity5.541722297668457
INFO:root:current mean train loss 4256.185492426372
INFO:root:current train perplexity5.352502822875977
INFO:root:current mean train loss 4223.983997041711
INFO:root:current train perplexity5.299919128417969
INFO:root:current mean train loss 4215.883806346792
INFO:root:current train perplexity5.261133670806885
INFO:root:current mean train loss 4202.829890153403
INFO:root:current train perplexity5.237428665161133
INFO:root:current mean train loss 4193.469970250174
INFO:root:current train perplexity5.214472770690918
INFO:root:current mean train loss 4186.085329249804
INFO:root:current train perplexity5.199010372161865
INFO:root:current mean train loss 4181.843276254863
INFO:root:current train perplexity5.190182209014893
INFO:root:current mean train loss 4169.165871584941
INFO:root:current train perplexity5.169376373291016
INFO:root:current mean train loss 4159.714110808123
INFO:root:current train perplexity5.155857563018799

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.99s/it]
INFO:root:final mean train loss: 4154.573264091246
INFO:root:final train perplexity: 5.150529384613037
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.60s/it]
INFO:root:eval mean loss: 3967.280363475177
INFO:root:eval perplexity: 4.974135875701904
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.27s/it]
INFO:root:eval mean loss: 4845.043957432957
INFO:root:eval perplexity: 7.251475811004639
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/31
 16%|â–ˆâ–Œ        | 31/200 [3:40:24<19:53:38, 423.78s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4075.813788231383
INFO:root:current train perplexity5.014578819274902
INFO:root:current mean train loss 4100.689428212691
INFO:root:current train perplexity5.043072700500488
INFO:root:current mean train loss 4099.295391376202
INFO:root:current train perplexity5.037973880767822
INFO:root:current mean train loss 4100.283062409942
INFO:root:current train perplexity5.029618263244629
INFO:root:current mean train loss 4102.779997072497
INFO:root:current train perplexity5.027045726776123
INFO:root:current mean train loss 4096.7783140639285
INFO:root:current train perplexity5.018739700317383
INFO:root:current mean train loss 4096.271408151806
INFO:root:current train perplexity5.018097400665283
INFO:root:current mean train loss 4089.3338497218037
INFO:root:current train perplexity5.008585453033447
INFO:root:current mean train loss 4084.475821719119
INFO:root:current train perplexity5.000838279724121
INFO:root:current mean train loss 4083.693380772753
INFO:root:current train perplexity5.001518726348877

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.89s/it]
INFO:root:final mean train loss: 4079.797212108489
INFO:root:final train perplexity: 5.000800609588623
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.79s/it]
INFO:root:eval mean loss: 3926.399356923205
INFO:root:eval perplexity: 4.892584323883057
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.29s/it]
INFO:root:eval mean loss: 4803.238776457225
INFO:root:eval perplexity: 7.128568172454834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/32
 16%|â–ˆâ–Œ        | 32/200 [3:47:25<19:44:39, 423.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4007.7115056818184
INFO:root:current train perplexity4.89558219909668
INFO:root:current mean train loss 4039.7641648815525
INFO:root:current train perplexity4.92500638961792
INFO:root:current mean train loss 4043.5695551853555
INFO:root:current train perplexity4.923398971557617
INFO:root:current mean train loss 4047.537140322403
INFO:root:current train perplexity4.929433345794678
INFO:root:current mean train loss 4042.8637840187157
INFO:root:current train perplexity4.923498153686523
INFO:root:current mean train loss 4044.7142644108953
INFO:root:current train perplexity4.9285149574279785
INFO:root:current mean train loss 4050.278240920205
INFO:root:current train perplexity4.932778835296631
INFO:root:current mean train loss 4050.645982512417
INFO:root:current train perplexity4.9373979568481445
INFO:root:current mean train loss 4048.916586999726
INFO:root:current train perplexity4.9328293800354
INFO:root:current mean train loss 4048.8861269326735
INFO:root:current train perplexity4.936143398284912

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.04s/it]
INFO:root:final mean train loss: 4048.15397619432
INFO:root:final train perplexity: 4.93875789642334
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.21s/it]
INFO:root:eval mean loss: 3910.8940464317375
INFO:root:eval perplexity: 4.862003803253174
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.71s/it]
INFO:root:eval mean loss: 4793.86395653258
INFO:root:eval perplexity: 7.101293563842773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/33
 16%|â–ˆâ–‹        | 33/200 [3:54:27<19:36:58, 422.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3985.9759463355654
INFO:root:current train perplexity4.846405506134033
INFO:root:current mean train loss 4016.695881662193
INFO:root:current train perplexity4.873485565185547
INFO:root:current mean train loss 4020.0899402923005
INFO:root:current train perplexity4.878676414489746
INFO:root:current mean train loss 4022.605722306517
INFO:root:current train perplexity4.879590034484863
INFO:root:current mean train loss 4035.792247401458
INFO:root:current train perplexity4.8955793380737305
INFO:root:current mean train loss 4034.2029983764432
INFO:root:current train perplexity4.898334980010986
INFO:root:current mean train loss 4026.9800264982796
INFO:root:current train perplexity4.892105579376221
INFO:root:current mean train loss 4030.9041900034813
INFO:root:current train perplexity4.899511814117432
INFO:root:current mean train loss 4026.7254758903355
INFO:root:current train perplexity4.894099235534668
INFO:root:current mean train loss 4029.562441183152
INFO:root:current train perplexity4.896462440490723

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.79s/it]
INFO:root:final mean train loss: 4026.4283049798782
INFO:root:final train perplexity: 4.896605968475342
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.90s/it]
INFO:root:eval mean loss: 3913.852674119016
INFO:root:eval perplexity: 4.867825031280518
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.87s/it]
INFO:root:eval mean loss: 4799.39647052305
INFO:root:eval perplexity: 7.11737585067749
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/34
 17%|â–ˆâ–‹        | 34/200 [4:01:28<19:28:18, 422.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3980.4170162577025
INFO:root:current train perplexity4.836544990539551
INFO:root:current mean train loss 3989.4803131281983
INFO:root:current train perplexity4.833986282348633
INFO:root:current mean train loss 3998.0519325847554
INFO:root:current train perplexity4.8363752365112305
INFO:root:current mean train loss 4012.3732344223804
INFO:root:current train perplexity4.855711460113525
INFO:root:current mean train loss 4014.067010640592
INFO:root:current train perplexity4.862041473388672
INFO:root:current mean train loss 4009.540299878229
INFO:root:current train perplexity4.86049747467041
INFO:root:current mean train loss 4007.1263837061056
INFO:root:current train perplexity4.860682487487793
INFO:root:current mean train loss 4009.3129414163827
INFO:root:current train perplexity4.858790397644043
INFO:root:current mean train loss 4007.6767536080115
INFO:root:current train perplexity4.858341217041016
INFO:root:current mean train loss 4010.589592820707
INFO:root:current train perplexity4.8590545654296875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.38s/it]
INFO:root:final mean train loss: 4006.578966325329
INFO:root:final train perplexity: 4.858410835266113
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.19s/it]
INFO:root:eval mean loss: 3895.20755589262
INFO:root:eval perplexity: 4.831262111663818
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.19s/it]
INFO:root:eval mean loss: 4783.1771612505545
INFO:root:eval perplexity: 7.0703277587890625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/35
 18%|â–ˆâ–Š        | 35/200 [4:08:31<19:21:16, 422.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4015.545484325554
INFO:root:current train perplexity4.906467914581299
INFO:root:current mean train loss 4006.0844399223115
INFO:root:current train perplexity4.861165523529053
INFO:root:current mean train loss 4001.2497339829747
INFO:root:current train perplexity4.8528594970703125
INFO:root:current mean train loss 3998.869235962236
INFO:root:current train perplexity4.84575891494751
INFO:root:current mean train loss 3996.9759416998304
INFO:root:current train perplexity4.834527015686035
INFO:root:current mean train loss 3991.6397504790048
INFO:root:current train perplexity4.823126792907715
INFO:root:current mean train loss 3988.6262958509756
INFO:root:current train perplexity4.82052755355835
INFO:root:current mean train loss 3990.502311344171
INFO:root:current train perplexity4.818258285522461
INFO:root:current mean train loss 3989.4099846016425
INFO:root:current train perplexity4.818450450897217
INFO:root:current mean train loss 3987.9753560113954
INFO:root:current train perplexity4.817992210388184

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.77s/it]
INFO:root:final mean train loss: 3984.785283180975
INFO:root:final train perplexity: 4.816815376281738
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.62s/it]
INFO:root:eval mean loss: 3887.50850163453
INFO:root:eval perplexity: 4.816243648529053
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.64s/it]
INFO:root:eval mean loss: 4784.146726784131
INFO:root:eval perplexity: 7.073132038116455
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/36
 18%|â–ˆâ–Š        | 36/200 [4:15:35<19:15:59, 422.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3997.618961027299
INFO:root:current train perplexity4.806923866271973
INFO:root:current mean train loss 3989.426606366979
INFO:root:current train perplexity4.788586139678955
INFO:root:current mean train loss 3972.1317227991617
INFO:root:current train perplexity4.771357536315918
INFO:root:current mean train loss 3963.483264065528
INFO:root:current train perplexity4.769196033477783
INFO:root:current mean train loss 3964.4767730524895
INFO:root:current train perplexity4.776659965515137
INFO:root:current mean train loss 3967.0938914102426
INFO:root:current train perplexity4.768182754516602
INFO:root:current mean train loss 3968.955889794851
INFO:root:current train perplexity4.773800849914551
INFO:root:current mean train loss 3967.643015220477
INFO:root:current train perplexity4.775473117828369
INFO:root:current mean train loss 3969.4828325376975
INFO:root:current train perplexity4.779780387878418
INFO:root:current mean train loss 3971.4103892595936
INFO:root:current train perplexity4.786022186279297

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.78s/it]
INFO:root:final mean train loss: 3968.689730736517
INFO:root:final train perplexity: 4.786325454711914
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.26s/it]
INFO:root:eval mean loss: 3874.7214078429743
INFO:root:eval perplexity: 4.791405200958252
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.61s/it]
INFO:root:eval mean loss: 4767.901507438497
INFO:root:eval perplexity: 7.026300430297852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/37
 18%|â–ˆâ–Š        | 37/200 [4:22:39<19:09:45, 423.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3947.2060546875
INFO:root:current train perplexity4.756250858306885
INFO:root:current mean train loss 3968.860662059295
INFO:root:current train perplexity4.765439510345459
INFO:root:current mean train loss 3961.1957238148834
INFO:root:current train perplexity4.76930570602417
INFO:root:current mean train loss 3958.218032411986
INFO:root:current train perplexity4.760311126708984
INFO:root:current mean train loss 3956.589101957071
INFO:root:current train perplexity4.753235340118408
INFO:root:current mean train loss 3953.258198611476
INFO:root:current train perplexity4.746324062347412
INFO:root:current mean train loss 3954.4579354485163
INFO:root:current train perplexity4.746518135070801
INFO:root:current mean train loss 3954.2915247887186
INFO:root:current train perplexity4.751425266265869
INFO:root:current mean train loss 3955.483622392196
INFO:root:current train perplexity4.754559516906738

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.83s/it]
INFO:root:final mean train loss: 3952.4671278307515
INFO:root:final train perplexity: 4.755789279937744
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.21s/it]
INFO:root:eval mean loss: 3881.1636036541445
INFO:root:eval perplexity: 4.803901672363281
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.70s/it]
INFO:root:eval mean loss: 4776.340427263409
INFO:root:eval perplexity: 7.050589084625244
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/38
 19%|â–ˆâ–‰        | 38/200 [4:29:41<19:01:49, 422.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4056.1073404947915
INFO:root:current train perplexity4.872426986694336
INFO:root:current mean train loss 3946.414557892142
INFO:root:current train perplexity4.73273229598999
INFO:root:current mean train loss 3939.86333416718
INFO:root:current train perplexity4.726370334625244
INFO:root:current mean train loss 3941.2665242110147
INFO:root:current train perplexity4.726968288421631
INFO:root:current mean train loss 3949.01805429009
INFO:root:current train perplexity4.742202281951904
INFO:root:current mean train loss 3952.9594377096796
INFO:root:current train perplexity4.740912437438965
INFO:root:current mean train loss 3954.4008270820377
INFO:root:current train perplexity4.742421627044678
INFO:root:current mean train loss 3948.901249805521
INFO:root:current train perplexity4.736802577972412
INFO:root:current mean train loss 3947.1140866404303
INFO:root:current train perplexity4.736071586608887
INFO:root:current mean train loss 3945.1818069001765
INFO:root:current train perplexity4.734557628631592

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.53s/it]
INFO:root:final mean train loss: 3940.1964449113416
INFO:root:final train perplexity: 4.732820987701416
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.39s/it]
INFO:root:eval mean loss: 3869.340408216977
INFO:root:eval perplexity: 4.780990123748779
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.94s/it]
INFO:root:eval mean loss: 4764.971343777704
INFO:root:eval perplexity: 7.017886638641357
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/39
 20%|â–ˆâ–‰        | 39/200 [4:36:44<18:55:03, 423.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3917.535222833807
INFO:root:current train perplexity4.748271465301514
INFO:root:current mean train loss 3919.6649532833617
INFO:root:current train perplexity4.699036121368408
INFO:root:current mean train loss 3913.8724278454533
INFO:root:current train perplexity4.687957286834717
INFO:root:current mean train loss 3912.492920706893
INFO:root:current train perplexity4.694929122924805
INFO:root:current mean train loss 3923.7683087648265
INFO:root:current train perplexity4.701844692230225
INFO:root:current mean train loss 3925.2535097006485
INFO:root:current train perplexity4.702046871185303
INFO:root:current mean train loss 3921.323293333163
INFO:root:current train perplexity4.703893661499023
INFO:root:current mean train loss 3924.4912875104387
INFO:root:current train perplexity4.707947254180908
INFO:root:current mean train loss 3930.9311156172935
INFO:root:current train perplexity4.710588455200195
INFO:root:current mean train loss 3931.2836514754563
INFO:root:current train perplexity4.709552764892578

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.53s/it]
INFO:root:final mean train loss: 3927.316850108485
INFO:root:final train perplexity: 4.70883321762085
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.41s/it]
INFO:root:eval mean loss: 3867.572662137079
INFO:root:eval perplexity: 4.777574062347412
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.14s/it]
INFO:root:eval mean loss: 4765.252626676086
INFO:root:eval perplexity: 7.018694877624512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/40
 20%|â–ˆâ–ˆ        | 40/200 [4:43:46<18:46:42, 422.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3917.8815532483554
INFO:root:current train perplexity4.712634086608887
INFO:root:current mean train loss 3927.101209624475
INFO:root:current train perplexity4.710188388824463
INFO:root:current mean train loss 3930.847659594392
INFO:root:current train perplexity4.6933746337890625
INFO:root:current mean train loss 3930.563258443133
INFO:root:current train perplexity4.697948455810547
INFO:root:current mean train loss 3931.556177981429
INFO:root:current train perplexity4.6998724937438965
INFO:root:current mean train loss 3933.371744321261
INFO:root:current train perplexity4.697192668914795
INFO:root:current mean train loss 3925.7778900097182
INFO:root:current train perplexity4.692194938659668
INFO:root:current mean train loss 3924.7863918935805
INFO:root:current train perplexity4.693873882293701
INFO:root:current mean train loss 3921.310333736359
INFO:root:current train perplexity4.692622184753418
INFO:root:current mean train loss 3921.4998392763023
INFO:root:current train perplexity4.691948413848877

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.07s/it]
INFO:root:final mean train loss: 3917.682742149599
INFO:root:final train perplexity: 4.6909685134887695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.16s/it]
INFO:root:eval mean loss: 3862.438459247562
INFO:root:eval perplexity: 4.767665863037109
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.71s/it]
INFO:root:eval mean loss: 4761.5284796099295
INFO:root:eval perplexity: 7.00801420211792
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/41
 20%|â–ˆâ–ˆ        | 41/200 [4:50:48<18:39:28, 422.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3928.5769856770835
INFO:root:current train perplexity4.699370384216309
INFO:root:current mean train loss 3911.928309162771
INFO:root:current train perplexity4.690767288208008
INFO:root:current mean train loss 3912.1095320243667
INFO:root:current train perplexity4.677676677703857
INFO:root:current mean train loss 3912.3357015720567
INFO:root:current train perplexity4.67376184463501
INFO:root:current mean train loss 3900.671940752159
INFO:root:current train perplexity4.659514904022217
INFO:root:current mean train loss 3902.895783455141
INFO:root:current train perplexity4.660396099090576
INFO:root:current mean train loss 3906.360223846192
INFO:root:current train perplexity4.664927005767822
INFO:root:current mean train loss 3907.4542180917942
INFO:root:current train perplexity4.664827346801758
INFO:root:current mean train loss 3907.781571781477
INFO:root:current train perplexity4.666711330413818
INFO:root:current mean train loss 3908.685556619556
INFO:root:current train perplexity4.669755458831787

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.49s/it]
INFO:root:final mean train loss: 3906.279195354831
INFO:root:final train perplexity: 4.6699113845825195
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.09s/it]
INFO:root:eval mean loss: 3847.4107570783467
INFO:root:eval perplexity: 4.738781452178955
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it]
INFO:root:eval mean loss: 4745.592492935505
INFO:root:eval perplexity: 6.962496757507324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/42
 21%|â–ˆâ–ˆ        | 42/200 [4:57:50<18:32:22, 422.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3932.779568917411
INFO:root:current train perplexity4.686272144317627
INFO:root:current mean train loss 3896.3320511429397
INFO:root:current train perplexity4.650811195373535
INFO:root:current mean train loss 3898.3046064660903
INFO:root:current train perplexity4.646128177642822
INFO:root:current mean train loss 3904.4216294018192
INFO:root:current train perplexity4.652871131896973
INFO:root:current mean train loss 3898.4669691765444
INFO:root:current train perplexity4.654162406921387
INFO:root:current mean train loss 3901.3864691333238
INFO:root:current train perplexity4.658128261566162
INFO:root:current mean train loss 3907.7651178795522
INFO:root:current train perplexity4.662254333496094
INFO:root:current mean train loss 3907.7765631643283
INFO:root:current train perplexity4.664675235748291
INFO:root:current mean train loss 3908.622260069704
INFO:root:current train perplexity4.666324615478516
INFO:root:current mean train loss 3906.4122845818015
INFO:root:current train perplexity4.6626081466674805

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.66s/it]
INFO:root:final mean train loss: 3900.9190384034187
INFO:root:final train perplexity: 4.660046100616455
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.20s/it]
INFO:root:eval mean loss: 3852.4883608987147
INFO:root:eval perplexity: 4.748520374298096
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.60s/it]
INFO:root:eval mean loss: 4756.425107698914
INFO:root:eval perplexity: 6.993403911590576
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/43
 22%|â–ˆâ–ˆâ–       | 43/200 [5:04:53<18:25:37, 422.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3906.462152525436
INFO:root:current train perplexity4.6407294273376465
INFO:root:current mean train loss 3877.743251133632
INFO:root:current train perplexity4.632568836212158
INFO:root:current mean train loss 3870.414670339828
INFO:root:current train perplexity4.619601726531982
INFO:root:current mean train loss 3872.9135322237153
INFO:root:current train perplexity4.611445426940918
INFO:root:current mean train loss 3877.820017106377
INFO:root:current train perplexity4.6117963790893555
INFO:root:current mean train loss 3881.1395778480373
INFO:root:current train perplexity4.6155314445495605
INFO:root:current mean train loss 3884.6117446448534
INFO:root:current train perplexity4.620773792266846
INFO:root:current mean train loss 3882.785023500589
INFO:root:current train perplexity4.620773792266846
INFO:root:current mean train loss 3882.0179160990324
INFO:root:current train perplexity4.622342586517334
INFO:root:current mean train loss 3886.2857462780853
INFO:root:current train perplexity4.629225254058838

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.42s/it]
INFO:root:final mean train loss: 3885.1668480903872
INFO:root:final train perplexity: 4.631175518035889
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.93s/it]
INFO:root:eval mean loss: 3853.102118309508
INFO:root:eval perplexity: 4.749699115753174
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.40s/it]
INFO:root:eval mean loss: 4754.4622655557405
INFO:root:eval perplexity: 6.987794399261475
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/44
 22%|â–ˆâ–ˆâ–       | 44/200 [5:11:56<18:19:01, 422.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3903.9318464690564
INFO:root:current train perplexity4.695610523223877
INFO:root:current mean train loss 3891.3495738048427
INFO:root:current train perplexity4.631082534790039
INFO:root:current mean train loss 3885.1439690456923
INFO:root:current train perplexity4.619115829467773
INFO:root:current mean train loss 3876.4613875255964
INFO:root:current train perplexity4.608284950256348
INFO:root:current mean train loss 3872.8173238073377
INFO:root:current train perplexity4.602371692657471
INFO:root:current mean train loss 3870.318619909823
INFO:root:current train perplexity4.60496187210083
INFO:root:current mean train loss 3872.2576137372794
INFO:root:current train perplexity4.605091094970703
INFO:root:current mean train loss 3875.51697053668
INFO:root:current train perplexity4.607996463775635
INFO:root:current mean train loss 3879.011413502497
INFO:root:current train perplexity4.616512775421143
INFO:root:current mean train loss 3881.7824719867244
INFO:root:current train perplexity4.618748188018799

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.25s/it]
INFO:root:final mean train loss: 3877.418645120436
INFO:root:final train perplexity: 4.617040634155273
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.14s/it]
INFO:root:eval mean loss: 3846.8024192431294
INFO:root:eval perplexity: 4.73761510848999
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.22s/it]
INFO:root:eval mean loss: 4758.353380568484
INFO:root:eval perplexity: 6.9989213943481445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [5:19:00<18:12:56, 423.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3855.9053189552437
INFO:root:current train perplexity4.6114301681518555
INFO:root:current mean train loss 3881.8296635465804
INFO:root:current train perplexity4.620645523071289
INFO:root:current mean train loss 3872.7643571654803
INFO:root:current train perplexity4.613028049468994
INFO:root:current mean train loss 3860.8361034340182
INFO:root:current train perplexity4.5976643562316895
INFO:root:current mean train loss 3858.7927777990535
INFO:root:current train perplexity4.591902256011963
INFO:root:current mean train loss 3863.7984354909718
INFO:root:current train perplexity4.595944404602051
INFO:root:current mean train loss 3864.019112246894
INFO:root:current train perplexity4.594933986663818
INFO:root:current mean train loss 3865.8012347918725
INFO:root:current train perplexity4.5980424880981445
INFO:root:current mean train loss 3869.2044497257893
INFO:root:current train perplexity4.598378658294678
INFO:root:current mean train loss 3872.9268899386566
INFO:root:current train perplexity4.602787494659424

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.00s/it]
INFO:root:final mean train loss: 3869.632561283727
INFO:root:final train perplexity: 4.602879047393799
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.09s/it]
INFO:root:eval mean loss: 3855.416329025377
INFO:root:eval perplexity: 4.75414514541626
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it]
INFO:root:eval mean loss: 4758.894808289007
INFO:root:eval perplexity: 7.0004730224609375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [5:26:01<18:04:24, 422.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3849.1746006296644
INFO:root:current train perplexity4.548227310180664
INFO:root:current mean train loss 3863.096532033589
INFO:root:current train perplexity4.584927558898926
INFO:root:current mean train loss 3867.110515237301
INFO:root:current train perplexity4.594463348388672
INFO:root:current mean train loss 3857.896757120657
INFO:root:current train perplexity4.581303119659424
INFO:root:current mean train loss 3850.678179787875
INFO:root:current train perplexity4.568458080291748
INFO:root:current mean train loss 3855.9673295063108
INFO:root:current train perplexity4.578527450561523
INFO:root:current mean train loss 3855.8473897816716
INFO:root:current train perplexity4.579676628112793
INFO:root:current mean train loss 3859.268203596093
INFO:root:current train perplexity4.5816450119018555
INFO:root:current mean train loss 3863.6345738605646
INFO:root:current train perplexity4.586311340332031
INFO:root:current mean train loss 3861.9234451246607
INFO:root:current train perplexity4.585099697113037

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.61s/it]
INFO:root:final mean train loss: 3860.1582856947375
INFO:root:final train perplexity: 4.5857062339782715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.37s/it]
INFO:root:eval mean loss: 3844.0894281914893
INFO:root:eval perplexity: 4.732420921325684
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it]
INFO:root:eval mean loss: 4751.978861923759
INFO:root:eval perplexity: 6.980701923370361
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [5:33:03<17:56:45, 422.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3828.4225065104165
INFO:root:current train perplexity4.485982894897461
INFO:root:current mean train loss 3837.0457421875
INFO:root:current train perplexity4.536496162414551
INFO:root:current mean train loss 3847.208749112216
INFO:root:current train perplexity4.551910877227783
INFO:root:current mean train loss 3845.378224609375
INFO:root:current train perplexity4.558532238006592
INFO:root:current mean train loss 3844.0851187294406
INFO:root:current train perplexity4.558070659637451
INFO:root:current mean train loss 3848.9256343410325
INFO:root:current train perplexity4.5621562004089355
INFO:root:current mean train loss 3850.37085973669
INFO:root:current train perplexity4.562763690948486
INFO:root:current mean train loss 3857.693771421371
INFO:root:current train perplexity4.574160099029541
INFO:root:current mean train loss 3855.7375170200894
INFO:root:current train perplexity4.571028709411621
INFO:root:current mean train loss 3856.370518078926
INFO:root:current train perplexity4.571741580963135

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.71s/it]
INFO:root:final mean train loss: 3852.5284588106215
INFO:root:final train perplexity: 4.57192325592041
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.90s/it]
INFO:root:eval mean loss: 3841.67509211547
INFO:root:eval perplexity: 4.727802753448486
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it]
INFO:root:eval mean loss: 4751.234381925975
INFO:root:eval perplexity: 6.978577613830566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/48
 24%|â–ˆâ–ˆâ–       | 48/200 [5:40:04<17:48:25, 421.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3872.234780920557
INFO:root:current train perplexity4.577702522277832
INFO:root:current mean train loss 3847.055450606216
INFO:root:current train perplexity4.558218479156494
INFO:root:current mean train loss 3836.6784797371906
INFO:root:current train perplexity4.551783084869385
INFO:root:current mean train loss 3838.1410877835347
INFO:root:current train perplexity4.552764892578125
INFO:root:current mean train loss 3846.9264762673074
INFO:root:current train perplexity4.559274673461914
INFO:root:current mean train loss 3846.8019688706045
INFO:root:current train perplexity4.559183120727539
INFO:root:current mean train loss 3848.0837330853083
INFO:root:current train perplexity4.560260772705078
INFO:root:current mean train loss 3853.231685711506
INFO:root:current train perplexity4.565898895263672
INFO:root:current mean train loss 3849.4018961127726
INFO:root:current train perplexity4.562409400939941
INFO:root:current mean train loss 3852.205031432795
INFO:root:current train perplexity4.565684795379639

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.28s/it]
INFO:root:final mean train loss: 3848.760836447439
INFO:root:final train perplexity: 4.565131664276123
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.68s/it]
INFO:root:eval mean loss: 3826.4620768229165
INFO:root:eval perplexity: 4.698808670043945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it]
INFO:root:eval mean loss: 4738.83455923094
INFO:root:eval perplexity: 6.943281173706055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/49
 24%|â–ˆâ–ˆâ–       | 49/200 [5:47:06<17:42:06, 422.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3844.947268307864
INFO:root:current train perplexity4.516415119171143
INFO:root:current mean train loss 3844.491919073135
INFO:root:current train perplexity4.540682792663574
INFO:root:current mean train loss 3838.7155132490334
INFO:root:current train perplexity4.5317816734313965
INFO:root:current mean train loss 3847.5744004505673
INFO:root:current train perplexity4.544031143188477
INFO:root:current mean train loss 3850.6088156146575
INFO:root:current train perplexity4.549222469329834
INFO:root:current mean train loss 3847.1605325818264
INFO:root:current train perplexity4.549510955810547
INFO:root:current mean train loss 3845.9814544986884
INFO:root:current train perplexity4.5510945320129395
INFO:root:current mean train loss 3844.0772922675014
INFO:root:current train perplexity4.548129558563232
INFO:root:current mean train loss 3842.6281809523184
INFO:root:current train perplexity4.54783821105957
INFO:root:current mean train loss 3843.6053679896413
INFO:root:current train perplexity4.550336837768555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.41s/it]
INFO:root:final mean train loss: 3840.548100194623
INFO:root:final train perplexity: 4.550364971160889
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.93s/it]
INFO:root:eval mean loss: 3833.583572279477
INFO:root:eval perplexity: 4.712358474731445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.61s/it]
INFO:root:eval mean loss: 4747.660725911458
INFO:root:eval perplexity: 6.968385696411133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [5:54:09<17:35:18, 422.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3818.532564413668
INFO:root:current train perplexity4.514893531799316
INFO:root:current mean train loss 3834.9193882007694
INFO:root:current train perplexity4.538773536682129
INFO:root:current mean train loss 3830.7211930392978
INFO:root:current train perplexity4.527195453643799
INFO:root:current mean train loss 3823.008221848567
INFO:root:current train perplexity4.516678810119629
INFO:root:current mean train loss 3828.330214139216
INFO:root:current train perplexity4.521075248718262
INFO:root:current mean train loss 3828.3161189058587
INFO:root:current train perplexity4.522795677185059
INFO:root:current mean train loss 3830.003476297054
INFO:root:current train perplexity4.525697708129883
INFO:root:current mean train loss 3833.1713188849344
INFO:root:current train perplexity4.5316667556762695
INFO:root:current mean train loss 3836.553651463866
INFO:root:current train perplexity4.537310600280762

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.79s/it]
INFO:root:final mean train loss: 3832.5307076977147
INFO:root:final train perplexity: 4.535993576049805
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.87s/it]
INFO:root:eval mean loss: 3851.2190824468084
INFO:root:eval perplexity: 4.746085166931152
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.46s/it]
INFO:root:eval mean loss: 4756.797922553746
INFO:root:eval perplexity: 6.994472503662109
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [6:01:11<17:28:34, 422.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3862.983642578125
INFO:root:current train perplexity4.545089244842529
INFO:root:current mean train loss 3830.7655223240363
INFO:root:current train perplexity4.510422229766846
INFO:root:current mean train loss 3843.0367437537743
INFO:root:current train perplexity4.541367530822754
INFO:root:current mean train loss 3839.532459569676
INFO:root:current train perplexity4.538536548614502
INFO:root:current mean train loss 3832.698252984874
INFO:root:current train perplexity4.524084568023682
INFO:root:current mean train loss 3836.3340214535565
INFO:root:current train perplexity4.530649185180664
INFO:root:current mean train loss 3838.6889881718494
INFO:root:current train perplexity4.53530740737915
INFO:root:current mean train loss 3838.229719752807
INFO:root:current train perplexity4.535208225250244
INFO:root:current mean train loss 3838.356715773118
INFO:root:current train perplexity4.533698558807373
INFO:root:current mean train loss 3835.488734538658
INFO:root:current train perplexity4.532918930053711

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.64s/it]
INFO:root:final mean train loss: 3830.443649599629
INFO:root:final train perplexity: 4.532260417938232
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.61s/it]
INFO:root:eval mean loss: 3825.3926231438386
INFO:root:eval perplexity: 4.69677734375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.67s/it]
INFO:root:eval mean loss: 4741.415669326241
INFO:root:eval perplexity: 6.950613975524902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [6:08:14<17:22:16, 422.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3868.1686197916665
INFO:root:current train perplexity4.536989212036133
INFO:root:current mean train loss 3841.922208305027
INFO:root:current train perplexity4.5248565673828125
INFO:root:current mean train loss 3835.185520757631
INFO:root:current train perplexity4.524097442626953
INFO:root:current mean train loss 3829.9635122147815
INFO:root:current train perplexity4.5160651206970215
INFO:root:current mean train loss 3831.6569241810994
INFO:root:current train perplexity4.520264625549316
INFO:root:current mean train loss 3830.0034265018203
INFO:root:current train perplexity4.51315975189209
INFO:root:current mean train loss 3828.7892463001776
INFO:root:current train perplexity4.513187885284424
INFO:root:current mean train loss 3829.191525076486
INFO:root:current train perplexity4.518338680267334
INFO:root:current mean train loss 3827.726228192101
INFO:root:current train perplexity4.520059585571289
INFO:root:current mean train loss 3827.0094811945014
INFO:root:current train perplexity4.520619869232178

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.71s/it]
INFO:root:final mean train loss: 3821.610414258895
INFO:root:final train perplexity: 4.516493320465088
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.62s/it]
INFO:root:eval mean loss: 3813.7980558787676
INFO:root:eval perplexity: 4.674807071685791
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it]
INFO:root:eval mean loss: 4730.655065658245
INFO:root:eval perplexity: 6.920097827911377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [6:15:18<17:15:43, 422.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3803.7797002377715
INFO:root:current train perplexity4.432491779327393
INFO:root:current mean train loss 3784.4007062214177
INFO:root:current train perplexity4.446356296539307
INFO:root:current mean train loss 3805.4122845431616
INFO:root:current train perplexity4.469878196716309
INFO:root:current mean train loss 3801.7665033015674
INFO:root:current train perplexity4.477227210998535
INFO:root:current mean train loss 3811.37961039081
INFO:root:current train perplexity4.487314701080322
INFO:root:current mean train loss 3816.534168484106
INFO:root:current train perplexity4.499402046203613
INFO:root:current mean train loss 3814.196472461878
INFO:root:current train perplexity4.500563144683838
INFO:root:current mean train loss 3815.566380248855
INFO:root:current train perplexity4.502408981323242
INFO:root:current mean train loss 3812.40000528032
INFO:root:current train perplexity4.501798629760742
INFO:root:current mean train loss 3815.809933481599
INFO:root:current train perplexity4.503595352172852

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.77s/it]
INFO:root:final mean train loss: 3815.0863520714543
INFO:root:final train perplexity: 4.504883289337158
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.44s/it]
INFO:root:eval mean loss: 3828.355707696144
INFO:root:eval perplexity: 4.702407360076904
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.45s/it]
INFO:root:eval mean loss: 4749.335255291445
INFO:root:eval perplexity: 6.973160743713379
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [6:22:19<17:07:25, 422.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3864.7182380922377
INFO:root:current train perplexity4.538821220397949
INFO:root:current mean train loss 3804.073117321684
INFO:root:current train perplexity4.467203140258789
INFO:root:current mean train loss 3809.167732007576
INFO:root:current train perplexity4.474550247192383
INFO:root:current mean train loss 3809.8067040573073
INFO:root:current train perplexity4.484300136566162
INFO:root:current mean train loss 3807.5691354136457
INFO:root:current train perplexity4.487334728240967
INFO:root:current mean train loss 3809.077395796551
INFO:root:current train perplexity4.4884233474731445
INFO:root:current mean train loss 3808.0978288121532
INFO:root:current train perplexity4.486238479614258
INFO:root:current mean train loss 3808.7225597292877
INFO:root:current train perplexity4.4888715744018555
INFO:root:current mean train loss 3811.051023627877
INFO:root:current train perplexity4.49179744720459
INFO:root:current mean train loss 3810.019073650225
INFO:root:current train perplexity4.489532947540283

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.28s/it]
INFO:root:final mean train loss: 3806.303909117176
INFO:root:final train perplexity: 4.4893012046813965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.78s/it]
INFO:root:eval mean loss: 3829.024817500554
INFO:root:eval perplexity: 4.703680038452148
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.02s/it]
INFO:root:eval mean loss: 4746.242052443484
INFO:root:eval perplexity: 6.9643449783325195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [6:29:19<16:59:06, 421.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3877.4297375801284
INFO:root:current train perplexity4.51574182510376
INFO:root:current mean train loss 3832.9532356536647
INFO:root:current train perplexity4.483033657073975
INFO:root:current mean train loss 3817.502025652131
INFO:root:current train perplexity4.469804286956787
INFO:root:current mean train loss 3804.5727567869653
INFO:root:current train perplexity4.4665679931640625
INFO:root:current mean train loss 3810.746209980958
INFO:root:current train perplexity4.473030090332031
INFO:root:current mean train loss 3809.5750847924396
INFO:root:current train perplexity4.4745588302612305
INFO:root:current mean train loss 3806.4052455466303
INFO:root:current train perplexity4.4736247062683105
INFO:root:current mean train loss 3801.4922505999452
INFO:root:current train perplexity4.470746040344238
INFO:root:current mean train loss 3797.5423905528346
INFO:root:current train perplexity4.468122482299805
INFO:root:current mean train loss 3800.26888670835
INFO:root:current train perplexity4.473948955535889

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.93s/it]
INFO:root:final mean train loss: 3796.8484673038606
INFO:root:final train perplexity: 4.4725847244262695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.45s/it]
INFO:root:eval mean loss: 3811.676110233821
INFO:root:eval perplexity: 4.6707987785339355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.73s/it]
INFO:root:eval mean loss: 4726.420178136082
INFO:root:eval perplexity: 6.908123970031738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [6:36:20<16:51:13, 421.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3783.2855406416224
INFO:root:current train perplexity4.444285869598389
INFO:root:current mean train loss 3794.0380477386266
INFO:root:current train perplexity4.449787139892578
INFO:root:current mean train loss 3783.9628016668776
INFO:root:current train perplexity4.460397243499756
INFO:root:current mean train loss 3786.812832087536
INFO:root:current train perplexity4.4632158279418945
INFO:root:current mean train loss 3782.3987275194004
INFO:root:current train perplexity4.4568071365356445
INFO:root:current mean train loss 3784.919227837209
INFO:root:current train perplexity4.4566569328308105
INFO:root:current mean train loss 3786.4563905223627
INFO:root:current train perplexity4.460867404937744
INFO:root:current mean train loss 3792.7694067284765
INFO:root:current train perplexity4.465231418609619
INFO:root:current mean train loss 3792.2843710799143
INFO:root:current train perplexity4.4652419090271
INFO:root:current mean train loss 3794.174215604788
INFO:root:current train perplexity4.466094493865967

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.63s/it]
INFO:root:final mean train loss: 3792.7605953216553
INFO:root:final train perplexity: 4.465377330780029
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.25s/it]
INFO:root:eval mean loss: 3804.5919423204787
INFO:root:eval perplexity: 4.657436847686768
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.85s/it]
INFO:root:eval mean loss: 4719.1515559203235
INFO:root:eval perplexity: 6.887621879577637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [6:43:23<16:45:27, 421.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3787.304811789773
INFO:root:current train perplexity4.467837810516357
INFO:root:current mean train loss 3780.413063886089
INFO:root:current train perplexity4.450092792510986
INFO:root:current mean train loss 3785.7537712545954
INFO:root:current train perplexity4.450689315795898
INFO:root:current mean train loss 3782.590466824384
INFO:root:current train perplexity4.441378593444824
INFO:root:current mean train loss 3784.5942940848213
INFO:root:current train perplexity4.445198059082031
INFO:root:current mean train loss 3787.4971178209457
INFO:root:current train perplexity4.448301792144775
INFO:root:current mean train loss 3787.922932072996
INFO:root:current train perplexity4.452714443206787
INFO:root:current mean train loss 3790.001048349545
INFO:root:current train perplexity4.453320026397705
INFO:root:current mean train loss 3786.7782689144738
INFO:root:current train perplexity4.446887016296387
INFO:root:current mean train loss 3786.9135634816753
INFO:root:current train perplexity4.449863910675049

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.81s/it]
INFO:root:final mean train loss: 3784.5040809877455
INFO:root:final train perplexity: 4.450855255126953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.26s/it]
INFO:root:eval mean loss: 3809.8320018146055
INFO:root:eval perplexity: 4.66731595993042
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.71s/it]
INFO:root:eval mean loss: 4734.606949177194
INFO:root:eval perplexity: 6.931288719177246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [6:50:28<16:40:45, 422.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3772.1999240451387
INFO:root:current train perplexity4.44289493560791
INFO:root:current mean train loss 3788.261371261503
INFO:root:current train perplexity4.4480156898498535
INFO:root:current mean train loss 3788.614213254515
INFO:root:current train perplexity4.447152137756348
INFO:root:current mean train loss 3782.170019396737
INFO:root:current train perplexity4.438954830169678
INFO:root:current mean train loss 3784.9962930699917
INFO:root:current train perplexity4.442663669586182
INFO:root:current mean train loss 3781.409824947269
INFO:root:current train perplexity4.438111782073975
INFO:root:current mean train loss 3779.625416475184
INFO:root:current train perplexity4.438277244567871
INFO:root:current mean train loss 3782.5837063170666
INFO:root:current train perplexity4.439723968505859
INFO:root:current mean train loss 3781.9241780693255
INFO:root:current train perplexity4.438096046447754
INFO:root:current mean train loss 3780.4936363719335
INFO:root:current train perplexity4.437182426452637

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.44s/it]
INFO:root:final mean train loss: 3777.3274354011783
INFO:root:final train perplexity: 4.4382710456848145
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.28s/it]
INFO:root:eval mean loss: 3807.9717835771276
INFO:root:eval perplexity: 4.663806438446045
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it]
INFO:root:eval mean loss: 4724.046230884309
INFO:root:eval perplexity: 6.901422500610352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [6:57:31<16:34:13, 423.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3766.2329067176497
INFO:root:current train perplexity4.435136318206787
INFO:root:current mean train loss 3763.05432485837
INFO:root:current train perplexity4.42719030380249
INFO:root:current mean train loss 3782.4353721027446
INFO:root:current train perplexity4.428631782531738
INFO:root:current mean train loss 3778.974032255517
INFO:root:current train perplexity4.429174423217773
INFO:root:current mean train loss 3774.768143121351
INFO:root:current train perplexity4.424257755279541
INFO:root:current mean train loss 3773.3273374220116
INFO:root:current train perplexity4.422817230224609
INFO:root:current mean train loss 3775.767936149404
INFO:root:current train perplexity4.426842212677002
INFO:root:current mean train loss 3774.731350949457
INFO:root:current train perplexity4.42803430557251
INFO:root:current mean train loss 3772.894077725854
INFO:root:current train perplexity4.4272589683532715
INFO:root:current mean train loss 3774.24378057415
INFO:root:current train perplexity4.427745819091797

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.70s/it]
INFO:root:final mean train loss: 3771.6392579232493
INFO:root:final train perplexity: 4.4283223152160645
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.92s/it]
INFO:root:eval mean loss: 3814.2043110732493
INFO:root:eval perplexity: 4.675574779510498
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it]
INFO:root:eval mean loss: 4736.481097282247
INFO:root:eval perplexity: 6.93660306930542
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [7:04:34<16:26:34, 422.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3823.3911472755144
INFO:root:current train perplexity4.525696277618408
INFO:root:current mean train loss 3780.3385234811453
INFO:root:current train perplexity4.455440044403076
INFO:root:current mean train loss 3770.3783645903336
INFO:root:current train perplexity4.425797939300537
INFO:root:current mean train loss 3769.7976641088803
INFO:root:current train perplexity4.419675827026367
INFO:root:current mean train loss 3766.325030683227
INFO:root:current train perplexity4.419367790222168
INFO:root:current mean train loss 3769.5625333110697
INFO:root:current train perplexity4.421299457550049
INFO:root:current mean train loss 3773.071646823799
INFO:root:current train perplexity4.428599834442139
INFO:root:current mean train loss 3773.9952278186174
INFO:root:current train perplexity4.429409980773926
INFO:root:current mean train loss 3774.5979878812927
INFO:root:current train perplexity4.430487155914307
INFO:root:current mean train loss 3775.458003323704
INFO:root:current train perplexity4.431332588195801

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.54s/it]
INFO:root:final mean train loss: 3773.7886280552034
INFO:root:final train perplexity: 4.432079315185547
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it]
INFO:root:eval mean loss: 3796.4302814023713
INFO:root:eval perplexity: 4.642090797424316
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.56s/it]
INFO:root:eval mean loss: 4718.716701642841
INFO:root:eval perplexity: 6.886397838592529
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [7:11:34<16:17:30, 421.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3714.08941720546
INFO:root:current train perplexity4.350208759307861
INFO:root:current mean train loss 3744.160493085729
INFO:root:current train perplexity4.397551536560059
INFO:root:current mean train loss 3732.118331643347
INFO:root:current train perplexity4.386106967926025
INFO:root:current mean train loss 3731.1559989199773
INFO:root:current train perplexity4.385674953460693
INFO:root:current mean train loss 3745.3656208892135
INFO:root:current train perplexity4.394126892089844
INFO:root:current mean train loss 3752.8154779333477
INFO:root:current train perplexity4.398171901702881
INFO:root:current mean train loss 3753.9206617596888
INFO:root:current train perplexity4.399593830108643
INFO:root:current mean train loss 3760.0356246773745
INFO:root:current train perplexity4.4037041664123535
INFO:root:current mean train loss 3763.5498990958813
INFO:root:current train perplexity4.40760612487793
INFO:root:current mean train loss 3764.6835437840364
INFO:root:current train perplexity4.410776615142822

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.70s/it]
INFO:root:final mean train loss: 3761.1345665224135
INFO:root:final train perplexity: 4.410007953643799
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.29s/it]
INFO:root:eval mean loss: 3797.766980759641
INFO:root:eval perplexity: 4.644601345062256
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.09s/it]
INFO:root:eval mean loss: 4725.432928856383
INFO:root:eval perplexity: 6.905335426330566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [7:18:34<16:09:25, 421.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3778.633601459704
INFO:root:current train perplexity4.3942437171936035
INFO:root:current mean train loss 3770.424426582532
INFO:root:current train perplexity4.396389484405518
INFO:root:current mean train loss 3766.920496226165
INFO:root:current train perplexity4.397200584411621
INFO:root:current mean train loss 3758.3583477551424
INFO:root:current train perplexity4.393207550048828
INFO:root:current mean train loss 3755.6136817392676
INFO:root:current train perplexity4.3885579109191895
INFO:root:current mean train loss 3755.7103413044906
INFO:root:current train perplexity4.39348840713501
INFO:root:current mean train loss 3754.8865364349144
INFO:root:current train perplexity4.394562721252441
INFO:root:current mean train loss 3762.410068727889
INFO:root:current train perplexity4.401759147644043
INFO:root:current mean train loss 3760.1631183986556
INFO:root:current train perplexity4.40109920501709

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.60s/it]
INFO:root:final mean train loss: 3756.0374781085598
INFO:root:final train perplexity: 4.401148319244385
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.48s/it]
INFO:root:eval mean loss: 3786.1235057208555
INFO:root:eval perplexity: 4.622783660888672
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it]
INFO:root:eval mean loss: 4714.206236494349
INFO:root:eval perplexity: 6.873709201812744
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [7:25:36<16:02:40, 421.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3521.279541015625
INFO:root:current train perplexity4.222352027893066
INFO:root:current mean train loss 3737.8051283753034
INFO:root:current train perplexity4.3901238441467285
INFO:root:current mean train loss 3746.213954981912
INFO:root:current train perplexity4.377043724060059
INFO:root:current mean train loss 3737.052503126289
INFO:root:current train perplexity4.375738620758057
INFO:root:current mean train loss 3739.0247418046292
INFO:root:current train perplexity4.376544952392578
INFO:root:current mean train loss 3740.352671082878
INFO:root:current train perplexity4.378088474273682
INFO:root:current mean train loss 3747.7557168584162
INFO:root:current train perplexity4.385324001312256
INFO:root:current mean train loss 3753.8176526521383
INFO:root:current train perplexity4.39214563369751
INFO:root:current mean train loss 3757.0812811940573
INFO:root:current train perplexity4.3934197425842285
INFO:root:current mean train loss 3753.1256721302257
INFO:root:current train perplexity4.391160488128662

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.08s/it]
INFO:root:final mean train loss: 3750.133923499815
INFO:root:final train perplexity: 4.390909194946289
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.76s/it]
INFO:root:eval mean loss: 3804.5434691517066
INFO:root:eval perplexity: 4.657345771789551
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.31s/it]
INFO:root:eval mean loss: 4729.661939688608
INFO:root:eval perplexity: 6.917287826538086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [7:32:36<15:54:52, 421.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3765.8603959517045
INFO:root:current train perplexity4.303063869476318
INFO:root:current mean train loss 3736.9952513548706
INFO:root:current train perplexity4.366587162017822
INFO:root:current mean train loss 3748.6458757590344
INFO:root:current train perplexity4.378697395324707
INFO:root:current mean train loss 3737.429524216238
INFO:root:current train perplexity4.374372959136963
INFO:root:current mean train loss 3744.2796277419784
INFO:root:current train perplexity4.380888938903809
INFO:root:current mean train loss 3740.2657678533205
INFO:root:current train perplexity4.370877265930176
INFO:root:current mean train loss 3737.649217870934
INFO:root:current train perplexity4.369714260101318
INFO:root:current mean train loss 3739.9408372752946
INFO:root:current train perplexity4.37170934677124
INFO:root:current mean train loss 3743.3381221220907
INFO:root:current train perplexity4.372958660125732
INFO:root:current mean train loss 3741.861005462747
INFO:root:current train perplexity4.372791290283203

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.89s/it]
INFO:root:final mean train loss: 3744.9547811323596
INFO:root:final train perplexity: 4.381946563720703
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.31s/it]
INFO:root:eval mean loss: 3798.5465962294993
INFO:root:eval perplexity: 4.646065711975098
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.25s/it]
INFO:root:eval mean loss: 4728.187186599624
INFO:root:eval perplexity: 6.913115501403809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [7:39:37<15:47:34, 421.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3724.345086348684
INFO:root:current train perplexity4.387181282043457
INFO:root:current mean train loss 3725.163159795168
INFO:root:current train perplexity4.360225200653076
INFO:root:current mean train loss 3725.5138781125142
INFO:root:current train perplexity4.357438564300537
INFO:root:current mean train loss 3729.499031090811
INFO:root:current train perplexity4.356070041656494
INFO:root:current mean train loss 3725.1459564718825
INFO:root:current train perplexity4.353715896606445
INFO:root:current mean train loss 3730.381918728926
INFO:root:current train perplexity4.356741428375244
INFO:root:current mean train loss 3737.171964136965
INFO:root:current train perplexity4.363325119018555
INFO:root:current mean train loss 3742.662984070758
INFO:root:current train perplexity4.368907928466797
INFO:root:current mean train loss 3742.753916385264
INFO:root:current train perplexity4.368429183959961
INFO:root:current mean train loss 3739.8019049875884
INFO:root:current train perplexity4.36792516708374

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.20s/it]
INFO:root:final mean train loss: 3736.1739518565514
INFO:root:final train perplexity: 4.36679220199585
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.12s/it]
INFO:root:eval mean loss: 3792.938975232713
INFO:root:eval perplexity: 4.635541915893555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.28s/it]
INFO:root:eval mean loss: 4727.679490109707
INFO:root:eval perplexity: 6.911683559417725
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [7:46:40<15:41:44, 421.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3808.1039767795137
INFO:root:current train perplexity4.448619365692139
INFO:root:current mean train loss 3745.5282203494094
INFO:root:current train perplexity4.366170883178711
INFO:root:current mean train loss 3738.05667396579
INFO:root:current train perplexity4.363157749176025
INFO:root:current mean train loss 3734.6450053457093
INFO:root:current train perplexity4.354767799377441
INFO:root:current mean train loss 3734.079564114644
INFO:root:current train perplexity4.3586320877075195
INFO:root:current mean train loss 3737.7207707616817
INFO:root:current train perplexity4.36108922958374
INFO:root:current mean train loss 3735.8256617885268
INFO:root:current train perplexity4.358652114868164
INFO:root:current mean train loss 3732.4690267150963
INFO:root:current train perplexity4.3552565574646
INFO:root:current mean train loss 3732.8917822324665
INFO:root:current train perplexity4.354766368865967
INFO:root:current mean train loss 3733.3173701709143
INFO:root:current train perplexity4.359612941741943

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.08s/it]
INFO:root:final mean train loss: 3733.023105313701
INFO:root:final train perplexity: 4.361367702484131
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.07s/it]
INFO:root:eval mean loss: 3789.750848431959
INFO:root:eval perplexity: 4.629570007324219
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.68s/it]
INFO:root:eval mean loss: 4721.58871654754
INFO:root:eval perplexity: 6.894489765167236
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [7:53:41<15:34:23, 421.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3728.1191196986606
INFO:root:current train perplexity4.355349063873291
INFO:root:current mean train loss 3720.342726417824
INFO:root:current train perplexity4.311033725738525
INFO:root:current mean train loss 3725.0703550947474
INFO:root:current train perplexity4.324626445770264
INFO:root:current mean train loss 3739.7320647737874
INFO:root:current train perplexity4.354997158050537
INFO:root:current mean train loss 3738.866421964799
INFO:root:current train perplexity4.356827735900879
INFO:root:current mean train loss 3743.0750451774243
INFO:root:current train perplexity4.36565637588501
INFO:root:current mean train loss 3744.6394611989417
INFO:root:current train perplexity4.367715358734131
INFO:root:current mean train loss 3741.8607126248935
INFO:root:current train perplexity4.368452072143555
INFO:root:current mean train loss 3741.0164849012913
INFO:root:current train perplexity4.369544982910156
INFO:root:current mean train loss 3740.7890230719418
INFO:root:current train perplexity4.367618560791016

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.87s/it]
INFO:root:final mean train loss: 3735.2223233869
INFO:root:final train perplexity: 4.3651533126831055
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.41s/it]
INFO:root:eval mean loss: 3788.5136372451243
INFO:root:eval perplexity: 4.627254009246826
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.35s/it]
INFO:root:eval mean loss: 4726.237230233267
INFO:root:eval perplexity: 6.907607078552246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [8:00:44<15:28:17, 421.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3717.6342035337934
INFO:root:current train perplexity4.309866905212402
INFO:root:current mean train loss 3704.2912102545893
INFO:root:current train perplexity4.3351731300354
INFO:root:current mean train loss 3708.6070280349795
INFO:root:current train perplexity4.328954219818115
INFO:root:current mean train loss 3708.189547791773
INFO:root:current train perplexity4.3242621421813965
INFO:root:current mean train loss 3717.4325675878245
INFO:root:current train perplexity4.331856727600098
INFO:root:current mean train loss 3719.7954317377416
INFO:root:current train perplexity4.3327717781066895
INFO:root:current mean train loss 3724.023828580628
INFO:root:current train perplexity4.339073657989502
INFO:root:current mean train loss 3724.0790923620457
INFO:root:current train perplexity4.340471267700195
INFO:root:current mean train loss 3725.621717568394
INFO:root:current train perplexity4.341310024261475
INFO:root:current mean train loss 3723.206515007788
INFO:root:current train perplexity4.3412065505981445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.42s/it]
INFO:root:final mean train loss: 3721.7975463251914
INFO:root:final train perplexity: 4.3420939445495605
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.56s/it]
INFO:root:eval mean loss: 3792.447499376662
INFO:root:eval perplexity: 4.634621620178223
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.27s/it]
INFO:root:eval mean loss: 4722.753982435727
INFO:root:eval perplexity: 6.897775173187256
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [8:07:49<15:22:57, 422.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3715.868173636642
INFO:root:current train perplexity4.313573837280273
INFO:root:current mean train loss 3719.55324690863
INFO:root:current train perplexity4.335923194885254
INFO:root:current mean train loss 3728.680740903573
INFO:root:current train perplexity4.345371723175049
INFO:root:current mean train loss 3727.1255042790685
INFO:root:current train perplexity4.341830730438232
INFO:root:current mean train loss 3730.7942841861836
INFO:root:current train perplexity4.346248149871826
INFO:root:current mean train loss 3726.512349261995
INFO:root:current train perplexity4.342201232910156
INFO:root:current mean train loss 3723.558404362879
INFO:root:current train perplexity4.336236476898193
INFO:root:current mean train loss 3717.2731582499378
INFO:root:current train perplexity4.3310041427612305
INFO:root:current mean train loss 3717.390320900044
INFO:root:current train perplexity4.330596923828125
INFO:root:current mean train loss 3718.0586420133413
INFO:root:current train perplexity4.330960273742676

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.14s/it]
INFO:root:final mean train loss: 3716.788034746724
INFO:root:final train perplexity: 4.333521366119385
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.02s/it]
INFO:root:eval mean loss: 3784.27643125277
INFO:root:eval perplexity: 4.619332790374756
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it]
INFO:root:eval mean loss: 4719.318714331228
INFO:root:eval perplexity: 6.8880934715271
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [8:14:49<15:14:15, 421.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3721.4719858977755
INFO:root:current train perplexity4.332455635070801
INFO:root:current mean train loss 3735.3955815153304
INFO:root:current train perplexity4.344676971435547
INFO:root:current mean train loss 3727.040933616373
INFO:root:current train perplexity4.34158992767334
INFO:root:current mean train loss 3717.438752665825
INFO:root:current train perplexity4.330732345581055
INFO:root:current mean train loss 3715.1485486664283
INFO:root:current train perplexity4.3323822021484375
INFO:root:current mean train loss 3715.989915987673
INFO:root:current train perplexity4.334388256072998
INFO:root:current mean train loss 3708.1779596215856
INFO:root:current train perplexity4.321864128112793
INFO:root:current mean train loss 3714.986598641819
INFO:root:current train perplexity4.321612358093262
INFO:root:current mean train loss 3712.665743062882
INFO:root:current train perplexity4.320816516876221
INFO:root:current mean train loss 3715.0071251384907
INFO:root:current train perplexity4.3243794441223145

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.73s/it]
INFO:root:final mean train loss: 3710.8878726343955
INFO:root:final train perplexity: 4.323445796966553
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.97s/it]
INFO:root:eval mean loss: 3787.288818359375
INFO:root:eval perplexity: 4.624963760375977
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it]
INFO:root:eval mean loss: 4721.565611494349
INFO:root:eval perplexity: 6.8944244384765625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [8:21:50<15:06:52, 421.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3699.1539871443565
INFO:root:current train perplexity4.300881385803223
INFO:root:current mean train loss 3696.4179278162424
INFO:root:current train perplexity4.287504196166992
INFO:root:current mean train loss 3712.9886378599017
INFO:root:current train perplexity4.3093342781066895
INFO:root:current mean train loss 3700.7814615441926
INFO:root:current train perplexity4.301139831542969
INFO:root:current mean train loss 3701.4871682405983
INFO:root:current train perplexity4.300048351287842
INFO:root:current mean train loss 3703.411323130236
INFO:root:current train perplexity4.303149700164795
INFO:root:current mean train loss 3706.587474085223
INFO:root:current train perplexity4.307622909545898
INFO:root:current mean train loss 3705.955243007456
INFO:root:current train perplexity4.309669494628906
INFO:root:current mean train loss 3707.364525043703
INFO:root:current train perplexity4.310305595397949
INFO:root:current mean train loss 3705.885667960671
INFO:root:current train perplexity4.310142993927002

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.18s/it]
INFO:root:final mean train loss: 3702.9225522318193
INFO:root:final train perplexity: 4.309879779815674
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.09s/it]
INFO:root:eval mean loss: 3784.111083984375
INFO:root:eval perplexity: 4.619023323059082
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.32s/it]
INFO:root:eval mean loss: 4722.59407378934
INFO:root:eval perplexity: 6.89732551574707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [8:28:50<14:58:42, 421.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3711.5335872395835
INFO:root:current train perplexity4.347614288330078
INFO:root:current mean train loss 3711.110284598214
INFO:root:current train perplexity4.325581073760986
INFO:root:current mean train loss 3714.287060546875
INFO:root:current train perplexity4.318763256072998
INFO:root:current mean train loss 3712.8475260416667
INFO:root:current train perplexity4.314591884613037
INFO:root:current mean train loss 3706.1767485608552
INFO:root:current train perplexity4.30934476852417
INFO:root:current mean train loss 3708.1147724184784
INFO:root:current train perplexity4.3105573654174805
INFO:root:current mean train loss 3703.995747612847
INFO:root:current train perplexity4.307799339294434
INFO:root:current mean train loss 3702.0711898311492
INFO:root:current train perplexity4.306262016296387
INFO:root:current mean train loss 3707.180112165179
INFO:root:current train perplexity4.310994625091553
INFO:root:current mean train loss 3705.1021864983973
INFO:root:current train perplexity4.309058666229248

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.58s/it]
INFO:root:final mean train loss: 3702.206035675541
INFO:root:final train perplexity: 4.308661460876465
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.35s/it]
INFO:root:eval mean loss: 3777.3983180269283
INFO:root:eval perplexity: 4.606502532958984
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it]
INFO:root:eval mean loss: 4711.795275099734
INFO:root:eval perplexity: 6.866934299468994
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [8:35:52<14:52:11, 421.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3675.0114628435617
INFO:root:current train perplexity4.275165557861328
INFO:root:current mean train loss 3687.2547240543886
INFO:root:current train perplexity4.275376796722412
INFO:root:current mean train loss 3700.1580055695117
INFO:root:current train perplexity4.2939066886901855
INFO:root:current mean train loss 3705.641434552464
INFO:root:current train perplexity4.2944416999816895
INFO:root:current mean train loss 3709.81877183618
INFO:root:current train perplexity4.301955223083496
INFO:root:current mean train loss 3711.460756174287
INFO:root:current train perplexity4.306142807006836
INFO:root:current mean train loss 3710.8910296371705
INFO:root:current train perplexity4.306931495666504
INFO:root:current mean train loss 3708.3930682770592
INFO:root:current train perplexity4.302761554718018
INFO:root:current mean train loss 3706.1533717396305
INFO:root:current train perplexity4.3027238845825195
INFO:root:current mean train loss 3699.4488700486395
INFO:root:current train perplexity4.2990498542785645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.03s/it]
INFO:root:final mean train loss: 3695.6055040667134
INFO:root:final train perplexity: 4.29745626449585
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.79s/it]
INFO:root:eval mean loss: 3770.0478654144504
INFO:root:eval perplexity: 4.592831134796143
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.06s/it]
INFO:root:eval mean loss: 4712.561597891733
INFO:root:eval perplexity: 6.869086742401123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [8:42:53<14:44:19, 421.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3679.147632640797
INFO:root:current train perplexity4.232832908630371
INFO:root:current mean train loss 3698.493017066836
INFO:root:current train perplexity4.2662482261657715
INFO:root:current mean train loss 3695.4968127483353
INFO:root:current train perplexity4.273261070251465
INFO:root:current mean train loss 3700.489021164682
INFO:root:current train perplexity4.283968925476074
INFO:root:current mean train loss 3698.12132197922
INFO:root:current train perplexity4.28412389755249
INFO:root:current mean train loss 3697.213884950693
INFO:root:current train perplexity4.283321380615234
INFO:root:current mean train loss 3694.21334746122
INFO:root:current train perplexity4.283243656158447
INFO:root:current mean train loss 3693.0282792623066
INFO:root:current train perplexity4.281912803649902
INFO:root:current mean train loss 3692.447926256927
INFO:root:current train perplexity4.284244537353516
INFO:root:current mean train loss 3691.785242228888
INFO:root:current train perplexity4.286243915557861

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.77s/it]
INFO:root:final mean train loss: 3688.9752484598466
INFO:root:final train perplexity: 4.286229133605957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.03s/it]
INFO:root:eval mean loss: 3760.116550310284
INFO:root:eval perplexity: 4.574423789978027
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.98s/it]
INFO:root:eval mean loss: 4693.964687915559
INFO:root:eval perplexity: 6.817048072814941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [8:49:53<14:36:41, 420.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3668.180629537563
INFO:root:current train perplexity4.2472453117370605
INFO:root:current mean train loss 3673.096463764133
INFO:root:current train perplexity4.269315719604492
INFO:root:current mean train loss 3671.717357010347
INFO:root:current train perplexity4.263077259063721
INFO:root:current mean train loss 3668.3127637208254
INFO:root:current train perplexity4.257211685180664
INFO:root:current mean train loss 3675.722900879885
INFO:root:current train perplexity4.262726783752441
INFO:root:current mean train loss 3677.8346055274415
INFO:root:current train perplexity4.266502857208252
INFO:root:current mean train loss 3685.2384384220763
INFO:root:current train perplexity4.274836540222168
INFO:root:current mean train loss 3689.9568259152065
INFO:root:current train perplexity4.279596328735352
INFO:root:current mean train loss 3687.4111415027114
INFO:root:current train perplexity4.277632713317871

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.41s/it]
INFO:root:final mean train loss: 3684.7353558694163
INFO:root:final train perplexity: 4.27906608581543
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.08s/it]
INFO:root:eval mean loss: 3772.45318906527
INFO:root:eval perplexity: 4.5973005294799805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.32s/it]
INFO:root:eval mean loss: 4715.73100724457
INFO:root:eval perplexity: 6.877995014190674
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [8:56:52<14:28:40, 420.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3635.9744001116073
INFO:root:current train perplexity4.252923965454102
INFO:root:current mean train loss 3726.539662583966
INFO:root:current train perplexity4.30477237701416
INFO:root:current mean train loss 3694.703856242452
INFO:root:current train perplexity4.2794060707092285
INFO:root:current mean train loss 3690.0804773386603
INFO:root:current train perplexity4.285318851470947
INFO:root:current mean train loss 3683.797835966293
INFO:root:current train perplexity4.280982494354248
INFO:root:current mean train loss 3685.4353571483603
INFO:root:current train perplexity4.280987739562988
INFO:root:current mean train loss 3681.3509853306477
INFO:root:current train perplexity4.270863056182861
INFO:root:current mean train loss 3683.232529959888
INFO:root:current train perplexity4.270081996917725
INFO:root:current mean train loss 3685.0251050379493
INFO:root:current train perplexity4.270290851593018
INFO:root:current mean train loss 3684.9034896228122
INFO:root:current train perplexity4.271387100219727

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.15s/it]
INFO:root:final mean train loss: 3679.1571246731664
INFO:root:final train perplexity: 4.26965856552124
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.96s/it]
INFO:root:eval mean loss: 3764.3770674035904
INFO:root:eval perplexity: 4.582311153411865
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it]
INFO:root:eval mean loss: 4701.35605745789
INFO:root:eval perplexity: 6.8376851081848145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [9:03:55<14:23:18, 421.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3664.4039225260417
INFO:root:current train perplexity4.275981426239014
INFO:root:current mean train loss 3673.4479301120923
INFO:root:current train perplexity4.259032726287842
INFO:root:current mean train loss 3667.8753122728926
INFO:root:current train perplexity4.249497413635254
INFO:root:current mean train loss 3671.8705380394345
INFO:root:current train perplexity4.241778373718262
INFO:root:current mean train loss 3663.7671645566643
INFO:root:current train perplexity4.236725330352783
INFO:root:current mean train loss 3671.3108720797936
INFO:root:current train perplexity4.244877338409424
INFO:root:current mean train loss 3677.2030122586384
INFO:root:current train perplexity4.253573894500732
INFO:root:current mean train loss 3672.303052611451
INFO:root:current train perplexity4.248106956481934
INFO:root:current mean train loss 3672.047953712136
INFO:root:current train perplexity4.253237724304199
INFO:root:current mean train loss 3676.6755811347334
INFO:root:current train perplexity4.259042739868164

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.38s/it]
INFO:root:final mean train loss: 3673.472627578243
INFO:root:final train perplexity: 4.260094165802002
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.71s/it]
INFO:root:eval mean loss: 3760.707699606605
INFO:root:eval perplexity: 4.575517654418945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.71s/it]
INFO:root:eval mean loss: 4701.100362574801
INFO:root:eval perplexity: 6.836968421936035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [9:10:58<14:17:30, 421.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3612.5615552819295
INFO:root:current train perplexity4.172348499298096
INFO:root:current mean train loss 3648.782276184578
INFO:root:current train perplexity4.231784343719482
INFO:root:current mean train loss 3645.660138733184
INFO:root:current train perplexity4.239287376403809
INFO:root:current mean train loss 3651.587381179857
INFO:root:current train perplexity4.243641376495361
INFO:root:current mean train loss 3654.772825705526
INFO:root:current train perplexity4.243025302886963
INFO:root:current mean train loss 3659.418623681734
INFO:root:current train perplexity4.244416236877441
INFO:root:current mean train loss 3663.2161314644363
INFO:root:current train perplexity4.24737548828125
INFO:root:current mean train loss 3666.8373371720477
INFO:root:current train perplexity4.250333309173584
INFO:root:current mean train loss 3671.8991168220305
INFO:root:current train perplexity4.255482196807861
INFO:root:current mean train loss 3674.605295232936
INFO:root:current train perplexity4.25654935836792

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.76s/it]
INFO:root:final mean train loss: 3670.635965162708
INFO:root:final train perplexity: 4.255329132080078
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.69s/it]
INFO:root:eval mean loss: 3805.164358585439
INFO:root:eval perplexity: 4.658514976501465
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it]
INFO:root:eval mean loss: 4741.6853061973625
INFO:root:eval perplexity: 6.951380729675293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [9:18:00<14:10:24, 421.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3687.9077699722784
INFO:root:current train perplexity4.288135528564453
INFO:root:current mean train loss 3676.398122539957
INFO:root:current train perplexity4.270752906799316
INFO:root:current mean train loss 3678.526676855046
INFO:root:current train perplexity4.247188568115234
INFO:root:current mean train loss 3672.4565606707893
INFO:root:current train perplexity4.246163368225098
INFO:root:current mean train loss 3662.8283204257905
INFO:root:current train perplexity4.236437797546387
INFO:root:current mean train loss 3661.7515563390125
INFO:root:current train perplexity4.234259605407715
INFO:root:current mean train loss 3663.9193039786796
INFO:root:current train perplexity4.2365946769714355
INFO:root:current mean train loss 3670.0688820563655
INFO:root:current train perplexity4.245898246765137
INFO:root:current mean train loss 3669.509956589388
INFO:root:current train perplexity4.247579574584961
INFO:root:current mean train loss 3667.3137204408904
INFO:root:current train perplexity4.245987892150879

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.36s/it]
INFO:root:final mean train loss: 3665.7962716625584
INFO:root:final train perplexity: 4.247211456298828
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.94s/it]
INFO:root:eval mean loss: 3751.3394108765515
INFO:root:eval perplexity: 4.5582170486450195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.87s/it]
INFO:root:eval mean loss: 4694.268000609486
INFO:root:eval perplexity: 6.8178935050964355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [9:25:00<14:02:40, 421.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3663.823692908654
INFO:root:current train perplexity4.224593162536621
INFO:root:current mean train loss 3671.45564017536
INFO:root:current train perplexity4.239062309265137
INFO:root:current mean train loss 3667.652183373104
INFO:root:current train perplexity4.242833137512207
INFO:root:current mean train loss 3683.5658545930123
INFO:root:current train perplexity4.250812530517578
INFO:root:current mean train loss 3681.44945454869
INFO:root:current train perplexity4.252638816833496
INFO:root:current mean train loss 3674.8798606178975
INFO:root:current train perplexity4.249314308166504
INFO:root:current mean train loss 3667.861109964911
INFO:root:current train perplexity4.2420501708984375
INFO:root:current mean train loss 3661.87983755233
INFO:root:current train perplexity4.2361297607421875
INFO:root:current mean train loss 3660.965920995046
INFO:root:current train perplexity4.23652458190918
INFO:root:current mean train loss 3660.9464845830007
INFO:root:current train perplexity4.234197616577148

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.12s/it]
INFO:root:final mean train loss: 3657.5258820441463
INFO:root:final train perplexity: 4.233375072479248
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.93s/it]
INFO:root:eval mean loss: 3769.3185238669103
INFO:root:eval perplexity: 4.591477394104004
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.25s/it]
INFO:root:eval mean loss: 4713.227629100177
INFO:root:eval perplexity: 6.870957374572754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [9:32:01<13:55:15, 421.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3608.302220121343
INFO:root:current train perplexity4.217703819274902
INFO:root:current mean train loss 3631.5997223107993
INFO:root:current train perplexity4.226423740386963
INFO:root:current mean train loss 3639.497055486146
INFO:root:current train perplexity4.2268877029418945
INFO:root:current mean train loss 3645.091052492345
INFO:root:current train perplexity4.227695941925049
INFO:root:current mean train loss 3651.9303947977837
INFO:root:current train perplexity4.223921298980713
INFO:root:current mean train loss 3654.3712303259254
INFO:root:current train perplexity4.225218296051025
INFO:root:current mean train loss 3656.329476640987
INFO:root:current train perplexity4.225185871124268
INFO:root:current mean train loss 3656.961877784576
INFO:root:current train perplexity4.22396993637085
INFO:root:current mean train loss 3655.3575046003357
INFO:root:current train perplexity4.224334716796875
INFO:root:current mean train loss 3656.8911661311213
INFO:root:current train perplexity4.227904796600342

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.83s/it]
INFO:root:final mean train loss: 3654.5927413202103
INFO:root:final train perplexity: 4.228479862213135
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.59s/it]
INFO:root:eval mean loss: 3764.4426131011746
INFO:root:eval perplexity: 4.582432746887207
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.52s/it]
INFO:root:eval mean loss: 4710.912183829233
INFO:root:eval perplexity: 6.86445426940918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [9:39:02<13:48:19, 421.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3632.90380859375
INFO:root:current train perplexity4.2299065589904785
INFO:root:current mean train loss 3639.236970766129
INFO:root:current train perplexity4.223326683044434
INFO:root:current mean train loss 3640.576299211091
INFO:root:current train perplexity4.2212934494018555
INFO:root:current mean train loss 3643.446562775088
INFO:root:current train perplexity4.216976642608643
INFO:root:current mean train loss 3653.5260672433037
INFO:root:current train perplexity4.225143909454346
INFO:root:current mean train loss 3657.074338400901
INFO:root:current train perplexity4.228211879730225
INFO:root:current mean train loss 3653.5963856005487
INFO:root:current train perplexity4.226105213165283
INFO:root:current mean train loss 3655.590366954677
INFO:root:current train perplexity4.229365825653076
INFO:root:current mean train loss 3659.6155618946455
INFO:root:current train perplexity4.231305122375488
INFO:root:current mean train loss 3658.132702061518
INFO:root:current train perplexity4.229848861694336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.09s/it]
INFO:root:final mean train loss: 3653.777748046383
INFO:root:final train perplexity: 4.227120399475098
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 30.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 30.00s/it]
INFO:root:eval mean loss: 3765.0122416611257
INFO:root:eval perplexity: 4.583488941192627
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.21s/it]
INFO:root:eval mean loss: 4715.637172401374
INFO:root:eval perplexity: 6.877730369567871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [9:46:05<13:42:08, 421.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3622.35208953373
INFO:root:current train perplexity4.194729328155518
INFO:root:current mean train loss 3626.5921922929447
INFO:root:current train perplexity4.200104713439941
INFO:root:current mean train loss 3633.1714229221125
INFO:root:current train perplexity4.200627326965332
INFO:root:current mean train loss 3648.9759524847195
INFO:root:current train perplexity4.216564178466797
INFO:root:current mean train loss 3647.8022292201
INFO:root:current train perplexity4.216444969177246
INFO:root:current mean train loss 3651.540732022924
INFO:root:current train perplexity4.221521854400635
INFO:root:current mean train loss 3648.2473663744345
INFO:root:current train perplexity4.217156410217285
INFO:root:current mean train loss 3649.5665035222805
INFO:root:current train perplexity4.217854022979736
INFO:root:current mean train loss 3648.3537077124674
INFO:root:current train perplexity4.2157087326049805
INFO:root:current mean train loss 3648.760893792997
INFO:root:current train perplexity4.213931560516357

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.18s/it]
INFO:root:final mean train loss: 3646.5206748593237
INFO:root:final train perplexity: 4.2150349617004395
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.10s/it]
INFO:root:eval mean loss: 3749.523866910461
INFO:root:eval perplexity: 4.554872035980225
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it]
INFO:root:eval mean loss: 4697.395691350842
INFO:root:eval perplexity: 6.8266191482543945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [9:53:06<13:34:36, 421.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3595.164598921655
INFO:root:current train perplexity4.151106834411621
INFO:root:current mean train loss 3619.1311249314695
INFO:root:current train perplexity4.187088966369629
INFO:root:current mean train loss 3621.9028059055004
INFO:root:current train perplexity4.191557884216309
INFO:root:current mean train loss 3638.714543674191
INFO:root:current train perplexity4.203658103942871
INFO:root:current mean train loss 3641.501527045183
INFO:root:current train perplexity4.21169900894165
INFO:root:current mean train loss 3636.3293495512257
INFO:root:current train perplexity4.202378273010254
INFO:root:current mean train loss 3637.4925185998045
INFO:root:current train perplexity4.202869415283203
INFO:root:current mean train loss 3642.366390163951
INFO:root:current train perplexity4.206905364990234
INFO:root:current mean train loss 3642.927948803907
INFO:root:current train perplexity4.2075886726379395
INFO:root:current mean train loss 3641.450025847226
INFO:root:current train perplexity4.205055236816406

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.08s/it]
INFO:root:final mean train loss: 3640.8758234823904
INFO:root:final train perplexity: 4.205658435821533
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.36s/it]
INFO:root:eval mean loss: 3768.137383643617
INFO:root:eval perplexity: 4.589284896850586
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.24s/it]
INFO:root:eval mean loss: 4718.258456615691
INFO:root:eval perplexity: 6.885107517242432
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [10:00:06<13:26:49, 420.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3604.3336444323577
INFO:root:current train perplexity4.1746087074279785
INFO:root:current mean train loss 3611.514913036837
INFO:root:current train perplexity4.1776251792907715
INFO:root:current mean train loss 3627.9881211147513
INFO:root:current train perplexity4.189685344696045
INFO:root:current mean train loss 3627.622610127391
INFO:root:current train perplexity4.184849739074707
INFO:root:current mean train loss 3628.5217504322154
INFO:root:current train perplexity4.1853485107421875
INFO:root:current mean train loss 3632.8211903942683
INFO:root:current train perplexity4.189206123352051
INFO:root:current mean train loss 3631.040031511759
INFO:root:current train perplexity4.1904401779174805
INFO:root:current mean train loss 3633.50122853819
INFO:root:current train perplexity4.193043231964111
INFO:root:current mean train loss 3637.7280815046397
INFO:root:current train perplexity4.197371482849121
INFO:root:current mean train loss 3641.261545931355
INFO:root:current train perplexity4.202298164367676

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.16s/it]
INFO:root:final mean train loss: 3638.5594620243196
INFO:root:final train perplexity: 4.201816558837891
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.98s/it]
INFO:root:eval mean loss: 3743.3348639738474
INFO:root:eval perplexity: 4.543487548828125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.81s/it]
INFO:root:eval mean loss: 4693.215867062832
INFO:root:eval perplexity: 6.814963340759277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [10:07:05<13:18:52, 420.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3630.787841796875
INFO:root:current train perplexity4.178675174713135
INFO:root:current mean train loss 3627.7281383167615
INFO:root:current train perplexity4.182636737823486
INFO:root:current mean train loss 3630.1877960311413
INFO:root:current train perplexity4.18011999130249
INFO:root:current mean train loss 3633.0887025345205
INFO:root:current train perplexity4.184625625610352
INFO:root:current mean train loss 3635.257568359375
INFO:root:current train perplexity4.187900543212891
INFO:root:current mean train loss 3635.1734658652313
INFO:root:current train perplexity4.18972110748291
INFO:root:current mean train loss 3635.495929212723
INFO:root:current train perplexity4.192681312561035
INFO:root:current mean train loss 3637.43778539946
INFO:root:current train perplexity4.195099353790283
INFO:root:current mean train loss 3638.0901553251833
INFO:root:current train perplexity4.196284770965576
INFO:root:current mean train loss 3637.448095257884
INFO:root:current train perplexity4.195540904998779

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.43s/it]
INFO:root:final mean train loss: 3634.847296684019
INFO:root:final train perplexity: 4.195667743682861
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it]
INFO:root:eval mean loss: 3791.3699769365026
INFO:root:eval perplexity: 4.632602214813232
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.34s/it]
INFO:root:eval mean loss: 4741.908710452682
INFO:root:eval perplexity: 6.952015399932861
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [10:14:08<13:13:08, 421.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3659.1597579152963
INFO:root:current train perplexity4.213632583618164
INFO:root:current mean train loss 3649.0941356169874
INFO:root:current train perplexity4.199304580688477
INFO:root:current mean train loss 3645.2508557335805
INFO:root:current train perplexity4.199662208557129
INFO:root:current mean train loss 3641.8988417227056
INFO:root:current train perplexity4.197595119476318
INFO:root:current mean train loss 3641.6556985874367
INFO:root:current train perplexity4.194231986999512
INFO:root:current mean train loss 3637.931081768645
INFO:root:current train perplexity4.19169807434082
INFO:root:current mean train loss 3640.0815440225942
INFO:root:current train perplexity4.19520378112793
INFO:root:current mean train loss 3637.6573844093946
INFO:root:current train perplexity4.192049980163574
INFO:root:current mean train loss 3636.8153827688548
INFO:root:current train perplexity4.192662715911865

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.72s/it]
INFO:root:final mean train loss: 3633.175121307373
INFO:root:final train perplexity: 4.19290018081665
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.41s/it]
INFO:root:eval mean loss: 3767.213782344304
INFO:root:eval perplexity: 4.587571620941162
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.46s/it]
INFO:root:eval mean loss: 4719.858133518949
INFO:root:eval perplexity: 6.889610767364502
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [10:21:11<13:07:39, 421.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3785.888427734375
INFO:root:current train perplexity4.365277290344238
INFO:root:current mean train loss 3597.4980302829185
INFO:root:current train perplexity4.139492034912109
INFO:root:current mean train loss 3602.4128730661178
INFO:root:current train perplexity4.152115821838379
INFO:root:current mean train loss 3616.9864804107365
INFO:root:current train perplexity4.173011779785156
INFO:root:current mean train loss 3615.8491810687424
INFO:root:current train perplexity4.174903869628906
INFO:root:current mean train loss 3629.7819508728876
INFO:root:current train perplexity4.18972110748291
INFO:root:current mean train loss 3630.356335995802
INFO:root:current train perplexity4.187808036804199
INFO:root:current mean train loss 3632.0020941222883
INFO:root:current train perplexity4.186832904815674
INFO:root:current mean train loss 3630.3400997480153
INFO:root:current train perplexity4.184411525726318
INFO:root:current mean train loss 3629.7775519319284
INFO:root:current train perplexity4.184086322784424

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.59s/it]
INFO:root:final mean train loss: 3627.5423787024715
INFO:root:final train perplexity: 4.183592796325684
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.18s/it]
INFO:root:eval mean loss: 3750.067677166445
INFO:root:eval perplexity: 4.555873870849609
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.44s/it]
INFO:root:eval mean loss: 4703.417335023271
INFO:root:eval perplexity: 6.843450546264648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [10:28:12<12:59:53, 421.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3736.851717862216
INFO:root:current train perplexity4.345314979553223
INFO:root:current mean train loss 3637.4393519496057
INFO:root:current train perplexity4.177169322967529
INFO:root:current mean train loss 3620.9551741613595
INFO:root:current train perplexity4.162134170532227
INFO:root:current mean train loss 3609.7398073251607
INFO:root:current train perplexity4.147891521453857
INFO:root:current mean train loss 3614.8720014066303
INFO:root:current train perplexity4.154390335083008
INFO:root:current mean train loss 3619.6073530760764
INFO:root:current train perplexity4.159599781036377
INFO:root:current mean train loss 3622.703004727777
INFO:root:current train perplexity4.163629055023193
INFO:root:current mean train loss 3623.7337170908054
INFO:root:current train perplexity4.166884899139404
INFO:root:current mean train loss 3621.58588632379
INFO:root:current train perplexity4.165397644042969
INFO:root:current mean train loss 3624.68715804233
INFO:root:current train perplexity4.171004295349121

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.59s/it]
INFO:root:final mean train loss: 3624.846726448305
INFO:root:final train perplexity: 4.179145812988281
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.13s/it]
INFO:root:eval mean loss: 3792.508046251662
INFO:root:eval perplexity: 4.634735584259033
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.51s/it]
INFO:root:eval mean loss: 4733.130561558068
INFO:root:eval perplexity: 6.9271063804626465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [10:35:14<12:52:52, 421.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5000.805252878289
INFO:root:current train perplexity7.292551517486572
INFO:root:current mean train loss 11377.05827780331
INFO:root:current train perplexity88.71282958984375
INFO:root:current mean train loss 11351.75892952697
INFO:root:current train perplexity87.72504425048828
INFO:root:current mean train loss 13493.87674036295
INFO:root:current train perplexity203.99105834960938
INFO:root:current mean train loss 15212.651400982622
INFO:root:current train perplexity403.7209167480469
INFO:root:current mean train loss 16335.207641836765
INFO:root:current train perplexity630.3187255859375
INFO:root:current mean train loss 17510.851320331432
INFO:root:current train perplexity999.6091918945312
INFO:root:current mean train loss 18356.55929255585
INFO:root:current train perplexity1391.3157958984375
INFO:root:current mean train loss 18844.185158754008
INFO:root:current train perplexity1686.712646484375
INFO:root:current mean train loss 18976.88970210062
INFO:root:current train perplexity1774.0958251953125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.63s/it]
INFO:root:final mean train loss: 18696.597623271326
INFO:root:final train perplexity: 1597.744873046875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.00s/it]
INFO:root:eval mean loss: 14246.925171764184
INFO:root:eval perplexity: 317.6780090332031
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it]
INFO:root:eval mean loss: 14394.360039893618
INFO:root:eval perplexity: 359.9809875488281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [10:42:16<12:46:25, 421.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 15784.058485243055
INFO:root:current train perplexity520.2094116210938
INFO:root:current mean train loss 16617.95836921752
INFO:root:current train perplexity688.28173828125
INFO:root:current mean train loss 16189.671388869769
INFO:root:current train perplexity586.2282104492188
INFO:root:current mean train loss 15600.184973480504
INFO:root:current train perplexity459.7969665527344
INFO:root:current mean train loss 15227.379121230972
INFO:root:current train perplexity398.73211669921875
INFO:root:current mean train loss 14983.914427552776
INFO:root:current train perplexity363.23101806640625
INFO:root:current mean train loss 14777.149965423147
INFO:root:current train perplexity334.85028076171875
INFO:root:current mean train loss 14630.359991564219
INFO:root:current train perplexity317.56427001953125
INFO:root:current mean train loss 14495.478372742216
INFO:root:current train perplexity302.6668395996094
INFO:root:current mean train loss 14403.40702851099
INFO:root:current train perplexity291.8817443847656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.19s/it]
INFO:root:final mean train loss: 14330.143325805664
INFO:root:final train perplexity: 285.3328857421875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.28s/it]
INFO:root:eval mean loss: 12625.842129321809
INFO:root:eval perplexity: 164.92977905273438
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.25s/it]
INFO:root:eval mean loss: 12834.728120844415
INFO:root:eval perplexity: 190.24195861816406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [10:49:17<12:38:57, 421.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13518.902650669643
INFO:root:current train perplexity203.20448303222656
INFO:root:current mean train loss 13624.523010706018
INFO:root:current train perplexity209.47312927246094
INFO:root:current mean train loss 13585.924239527925
INFO:root:current train perplexity209.6744842529297
INFO:root:current mean train loss 13586.286409748134
INFO:root:current train perplexity210.49322509765625
INFO:root:current mean train loss 13616.416828304598
INFO:root:current train perplexity212.1952362060547
INFO:root:current mean train loss 13589.174005183995
INFO:root:current train perplexity211.66619873046875
INFO:root:current mean train loss 13576.490847994586
INFO:root:current train perplexity211.49136352539062
INFO:root:current mean train loss 13574.49732541454
INFO:root:current train perplexity211.05947875976562
INFO:root:current mean train loss 13582.457791448353
INFO:root:current train perplexity211.88128662109375
INFO:root:current mean train loss 13584.541865808824
INFO:root:current train perplexity211.9150390625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.53s/it]
INFO:root:final mean train loss: 13577.966650193737
INFO:root:final train perplexity: 212.0667724609375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.03s/it]
INFO:root:eval mean loss: 12900.48592641844
INFO:root:eval perplexity: 184.30233764648438
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.61s/it]
INFO:root:eval mean loss: 13095.460258754432
INFO:root:eval perplexity: 211.6457061767578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [10:56:17<12:30:47, 421.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13673.719272347384
INFO:root:current train perplexity217.247802734375
INFO:root:current mean train loss 13665.640631829108
INFO:root:current train perplexity218.0047149658203
INFO:root:current mean train loss 13610.991857960391
INFO:root:current train perplexity212.4285888671875
INFO:root:current mean train loss 13650.253282730502
INFO:root:current train perplexity215.1579132080078
INFO:root:current mean train loss 13641.917472753245
INFO:root:current train perplexity214.6219024658203
INFO:root:current mean train loss 13644.777135128914
INFO:root:current train perplexity215.63601684570312
INFO:root:current mean train loss 13650.485196649008
INFO:root:current train perplexity216.19589233398438
INFO:root:current mean train loss 13682.293912453735
INFO:root:current train perplexity218.1432342529297
INFO:root:current mean train loss 13674.519674896204
INFO:root:current train perplexity218.29776000976562
INFO:root:current mean train loss 13665.831724715006
INFO:root:current train perplexity218.04473876953125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.07s/it]
INFO:root:final mean train loss: 13645.516706405147
INFO:root:final train perplexity: 217.7943115234375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.84s/it]
INFO:root:eval mean loss: 12739.989507147606
INFO:root:eval perplexity: 172.72108459472656
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.64s/it]
INFO:root:eval mean loss: 12944.350675975178
INFO:root:eval perplexity: 198.96377563476562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [11:03:19<12:24:15, 421.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13591.557578890932
INFO:root:current train perplexity214.11244201660156
INFO:root:current mean train loss 13524.452549410182
INFO:root:current train perplexity209.6553955078125
INFO:root:current mean train loss 13545.236985651145
INFO:root:current train perplexity210.0789031982422
INFO:root:current mean train loss 13563.035785033831
INFO:root:current train perplexity210.3218536376953
INFO:root:current mean train loss 13600.583594616131
INFO:root:current train perplexity213.3914337158203
INFO:root:current mean train loss 13620.995622306034
INFO:root:current train perplexity215.2443084716797
INFO:root:current mean train loss 13631.142936647946
INFO:root:current train perplexity215.7054443359375
INFO:root:current mean train loss 13618.808383093376
INFO:root:current train perplexity214.55917358398438
INFO:root:current mean train loss 13619.11069238396
INFO:root:current train perplexity215.09461975097656
INFO:root:current mean train loss 13638.026704004009
INFO:root:current train perplexity216.14785766601562

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.22s/it]
INFO:root:final mean train loss: 13624.363099621189
INFO:root:final train perplexity: 215.9842529296875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.55s/it]
INFO:root:eval mean loss: 12686.22147883422
INFO:root:eval perplexity: 169.00625610351562
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.35s/it]
INFO:root:eval mean loss: 12922.094234818262
INFO:root:eval perplexity: 197.1613311767578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [11:10:20<12:17:21, 421.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13560.79872881356
INFO:root:current train perplexity214.39901733398438
INFO:root:current mean train loss 13647.653787097091
INFO:root:current train perplexity218.7495574951172
INFO:root:current mean train loss 13667.060494087838
INFO:root:current train perplexity221.7071075439453
INFO:root:current mean train loss 13660.573598537605
INFO:root:current train perplexity219.20742797851562
INFO:root:current mean train loss 13641.27946920956
INFO:root:current train perplexity217.72132873535156
INFO:root:current mean train loss 13687.82769524262
INFO:root:current train perplexity220.15963745117188
INFO:root:current mean train loss 13694.665616997818
INFO:root:current train perplexity221.1057586669922
INFO:root:current mean train loss 13686.82797188941
INFO:root:current train perplexity220.92596435546875
INFO:root:current mean train loss 13696.432196549404
INFO:root:current train perplexity221.88902282714844
INFO:root:current mean train loss 13699.811848279458
INFO:root:current train perplexity221.90838623046875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.24s/it]
INFO:root:final mean train loss: 13696.826439642136
INFO:root:final train perplexity: 222.24798583984375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.40s/it]
INFO:root:eval mean loss: 12854.101507092199
INFO:root:eval perplexity: 180.87770080566406
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.94s/it]
INFO:root:eval mean loss: 13057.87418273493
INFO:root:eval perplexity: 208.41770935058594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [11:17:21<12:10:06, 421.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13660.873469566232
INFO:root:current train perplexity223.01583862304688
INFO:root:current mean train loss 13750.710627572978
INFO:root:current train perplexity224.67645263671875
INFO:root:current mean train loss 13734.215674011002
INFO:root:current train perplexity224.5183868408203
INFO:root:current mean train loss 13706.857272862739
INFO:root:current train perplexity222.2591094970703
INFO:root:current mean train loss 13705.666701519005
INFO:root:current train perplexity222.8841094970703
INFO:root:current mean train loss 13694.05779286541
INFO:root:current train perplexity221.69610595703125
INFO:root:current mean train loss 13678.29608877202
INFO:root:current train perplexity220.0526885986328
INFO:root:current mean train loss 13673.635691258556
INFO:root:current train perplexity219.70628356933594
INFO:root:current mean train loss 13657.419745034962
INFO:root:current train perplexity218.7183837890625
INFO:root:current mean train loss 13649.974294289685
INFO:root:current train perplexity217.57965087890625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.42s/it]
INFO:root:final mean train loss: 13637.778206856021
INFO:root:final train perplexity: 217.13037109375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.24s/it]
INFO:root:eval mean loss: 12471.571732324912
INFO:root:eval perplexity: 154.95535278320312
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.32s/it]
INFO:root:eval mean loss: 12699.949786679965
INFO:root:eval perplexity: 180.04087829589844
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [11:24:24<12:03:39, 421.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13571.06796875
INFO:root:current train perplexity212.80715942382812
INFO:root:current mean train loss 13508.520122767857
INFO:root:current train perplexity206.0799560546875
INFO:root:current mean train loss 13527.702439630682
INFO:root:current train perplexity205.47679138183594
INFO:root:current mean train loss 13535.93403125
INFO:root:current train perplexity206.33816528320312
INFO:root:current mean train loss 13563.007121710527
INFO:root:current train perplexity208.75030517578125
INFO:root:current mean train loss 13563.443682065217
INFO:root:current train perplexity209.02911376953125
INFO:root:current mean train loss 13558.484557291667
INFO:root:current train perplexity208.0596466064453
INFO:root:current mean train loss 13532.807982610888
INFO:root:current train perplexity206.59463500976562
INFO:root:current mean train loss 13508.400897321428
INFO:root:current train perplexity205.4567108154297
INFO:root:current mean train loss 13498.324988982371
INFO:root:current train perplexity204.8118133544922

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.41s/it]
INFO:root:final mean train loss: 13486.941170723208
INFO:root:final train perplexity: 204.58604431152344
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.50s/it]
INFO:root:eval mean loss: 12362.274711879432
INFO:root:eval perplexity: 148.2560577392578
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.14s/it]
INFO:root:eval mean loss: 12573.933718417553
INFO:root:eval perplexity: 170.99844360351562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [11:31:25<11:56:32, 421.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 13258.780249905874
INFO:root:current train perplexity185.6352081298828
INFO:root:current mean train loss 13291.379573300888
INFO:root:current train perplexity189.11952209472656
INFO:root:current mean train loss 13320.701779207155
INFO:root:current train perplexity190.35911560058594
INFO:root:current mean train loss 13330.535276089262
INFO:root:current train perplexity191.41067504882812
INFO:root:current mean train loss 13337.373152012164
INFO:root:current train perplexity191.2581329345703
INFO:root:current mean train loss 13319.09270810999
INFO:root:current train perplexity190.70335388183594
INFO:root:current mean train loss 13314.313254941435
INFO:root:current train perplexity189.82821655273438
INFO:root:current mean train loss 13306.682496208494
INFO:root:current train perplexity188.91744995117188
INFO:root:current mean train loss 13273.707006918885
INFO:root:current train perplexity187.1177520751953
INFO:root:current mean train loss 13239.59010701456
INFO:root:current train perplexity184.6682891845703

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.12s/it]
INFO:root:final mean train loss: 13222.684825774162
INFO:root:final train perplexity: 184.330810546875
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.85s/it]
INFO:root:eval mean loss: 11450.088604000443
INFO:root:eval perplexity: 102.5222396850586
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it]
INFO:root:eval mean loss: 11752.868261026153
INFO:root:eval perplexity: 122.23062896728516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [11:38:27<11:49:39, 421.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12334.004957932691
INFO:root:current train perplexity132.09779357910156
INFO:root:current mean train loss 12163.382669339006
INFO:root:current train perplexity123.90926361083984
INFO:root:current mean train loss 11973.014272578394
INFO:root:current train perplexity114.17718505859375
INFO:root:current mean train loss 11821.752784826567
INFO:root:current train perplexity106.98375701904297
INFO:root:current mean train loss 11697.148883019348
INFO:root:current train perplexity101.74327850341797
INFO:root:current mean train loss 11628.604854060914
INFO:root:current train perplexity98.65524291992188
INFO:root:current mean train loss 11502.713511046039
INFO:root:current train perplexity93.76360321044922
INFO:root:current mean train loss 11369.41586377015
INFO:root:current train perplexity88.74713897705078
INFO:root:current mean train loss 11253.211076695778
INFO:root:current train perplexity84.7254409790039
INFO:root:current mean train loss 11187.4986026583
INFO:root:current train perplexity82.30699920654297

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.38s/it]
INFO:root:final mean train loss: 11178.92283138152
INFO:root:final train perplexity: 82.3030776977539
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.58s/it]
INFO:root:eval mean loss: 8629.220668495123
INFO:root:eval perplexity: 32.766387939453125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.11s/it]
INFO:root:eval mean loss: 9141.495047927749
INFO:root:eval perplexity: 42.017372131347656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [11:45:29<11:43:01, 421.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 10184.83989307134
INFO:root:current train perplexity54.64130783081055
INFO:root:current mean train loss 9997.943580205716
INFO:root:current train perplexity50.66450119018555
INFO:root:current mean train loss 9935.163517062081
INFO:root:current train perplexity50.13472366333008
INFO:root:current mean train loss 9760.395566553101
INFO:root:current train perplexity46.658592224121094
INFO:root:current mean train loss 9634.798223399925
INFO:root:current train perplexity44.6427116394043
INFO:root:current mean train loss 9501.577600036519
INFO:root:current train perplexity42.32674026489258
INFO:root:current mean train loss 9405.533952661168
INFO:root:current train perplexity40.83899688720703
INFO:root:current mean train loss 9314.84599218261
INFO:root:current train perplexity39.38502502441406
INFO:root:current mean train loss 9224.108293068688
INFO:root:current train perplexity37.9439582824707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.97s/it]
INFO:root:final mean train loss: 9163.053216995731
INFO:root:final train perplexity: 37.15467834472656
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it]
INFO:root:eval mean loss: 7272.247897966534
INFO:root:eval perplexity: 18.928781509399414
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it]
INFO:root:eval mean loss: 7911.552291112589
INFO:root:eval perplexity: 25.409992218017578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [11:52:30<11:35:22, 421.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 9587.539481026786
INFO:root:current train perplexity40.81779479980469
INFO:root:current mean train loss 9126.679463894568
INFO:root:current train perplexity36.03068161010742
INFO:root:current mean train loss 8994.03158495622
INFO:root:current train perplexity34.80052947998047
INFO:root:current mean train loss 8857.071005954804
INFO:root:current train perplexity32.88483810424805
INFO:root:current mean train loss 8811.500157161778
INFO:root:current train perplexity32.202911376953125
INFO:root:current mean train loss 8803.38011876695
INFO:root:current train perplexity32.17644119262695
INFO:root:current mean train loss 8685.032762304365
INFO:root:current train perplexity30.751928329467773
INFO:root:current mean train loss 8593.974413233735
INFO:root:current train perplexity29.70457649230957
INFO:root:current mean train loss 8516.004470163414
INFO:root:current train perplexity28.82502555847168
INFO:root:current mean train loss 8411.068476734772
INFO:root:current train perplexity27.568721771240234

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.21s/it]
INFO:root:final mean train loss: 8323.243381500244
INFO:root:final train perplexity: 26.675888061523438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.88s/it]
INFO:root:eval mean loss: 5942.282673287899
INFO:root:eval perplexity: 11.055018424987793
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.42s/it]
INFO:root:eval mean loss: 6696.482196780807
INFO:root:eval perplexity: 15.460430145263672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [11:59:31<11:28:31, 421.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7374.853385416666
INFO:root:current train perplexity18.391571044921875
INFO:root:current mean train loss 7672.008992866848
INFO:root:current train perplexity20.735816955566406
INFO:root:current mean train loss 7848.810760356105
INFO:root:current train perplexity22.090925216674805
INFO:root:current mean train loss 8085.295777529762
INFO:root:current train perplexity24.340068817138672
INFO:root:current mean train loss 8293.985277437876
INFO:root:current train perplexity26.277254104614258
INFO:root:current mean train loss 8367.725312879247
INFO:root:current train perplexity26.967622756958008
INFO:root:current mean train loss 8455.740326473577
INFO:root:current train perplexity27.882535934448242
INFO:root:current mean train loss 8512.825732763331
INFO:root:current train perplexity28.62383270263672
INFO:root:current mean train loss 8570.176038271664
INFO:root:current train perplexity29.27887725830078
INFO:root:current mean train loss 8651.964334656763
INFO:root:current train perplexity30.275516510009766

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.64s/it]
INFO:root:final mean train loss: 8657.387225735572
INFO:root:final train perplexity: 30.434894561767578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.62s/it]
INFO:root:eval mean loss: 6976.736518589318
INFO:root:eval perplexity: 16.796785354614258
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.40s/it]
INFO:root:eval mean loss: 7626.481840093085
INFO:root:eval perplexity: 22.614084243774414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [12:06:33<11:21:44, 421.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 8921.14548658288
INFO:root:current train perplexity32.874977111816406
INFO:root:current mean train loss 8370.36627445376
INFO:root:current train perplexity26.843624114990234
INFO:root:current mean train loss 8189.550908246917
INFO:root:current train perplexity25.057777404785156
INFO:root:current mean train loss 8057.787333107585
INFO:root:current train perplexity23.918127059936523
INFO:root:current mean train loss 7906.996225343529
INFO:root:current train perplexity22.6427059173584
INFO:root:current mean train loss 7880.4634246534415
INFO:root:current train perplexity22.384967803955078
INFO:root:current mean train loss 7790.006435437149
INFO:root:current train perplexity21.586851119995117
INFO:root:current mean train loss 7687.812916018326
INFO:root:current train perplexity20.730329513549805
INFO:root:current mean train loss 7606.153248523884
INFO:root:current train perplexity20.082687377929688
INFO:root:current mean train loss 7540.021377513882
INFO:root:current train perplexity19.545692443847656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.14s/it]
INFO:root:final mean train loss: 7506.189428021831
INFO:root:final train perplexity: 19.325183868408203
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.90s/it]
INFO:root:eval mean loss: 5639.320520279255
INFO:root:eval perplexity: 9.780354499816895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.36s/it]
INFO:root:eval mean loss: 6422.598362699468
INFO:root:eval perplexity: 13.822378158569336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [12:13:33<11:13:46, 421.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6716.029107862903
INFO:root:current train perplexity14.690622329711914
INFO:root:current mean train loss 6825.872293952767
INFO:root:current train perplexity14.760139465332031
INFO:root:current mean train loss 6821.319050578328
INFO:root:current train perplexity14.803643226623535
INFO:root:current mean train loss 6874.537936945336
INFO:root:current train perplexity15.113776206970215
INFO:root:current mean train loss 6834.6065280144285
INFO:root:current train perplexity14.848698616027832
INFO:root:current mean train loss 6745.46984794315
INFO:root:current train perplexity14.310282707214355
INFO:root:current mean train loss 6655.838823079685
INFO:root:current train perplexity13.807968139648438
INFO:root:current mean train loss 6586.055338764321
INFO:root:current train perplexity13.399746894836426
INFO:root:current mean train loss 6526.698309759514
INFO:root:current train perplexity13.06682014465332
INFO:root:current mean train loss 6452.518473919173
INFO:root:current train perplexity12.731728553771973

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.75s/it]
INFO:root:final mean train loss: 6435.245429131292
INFO:root:final train perplexity: 12.665609359741211
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.49s/it]
INFO:root:eval mean loss: 4943.513439854832
INFO:root:eval perplexity: 7.381756782531738
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it]
INFO:root:eval mean loss: 5767.149739583333
INFO:root:eval perplexity: 10.572611808776855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [12:20:36<11:07:39, 421.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5874.510491786859
INFO:root:current train perplexity10.142677307128906
INFO:root:current mean train loss 5789.817544401978
INFO:root:current train perplexity9.861207008361816
INFO:root:current mean train loss 5830.399520299425
INFO:root:current train perplexity10.066861152648926
INFO:root:current mean train loss 5948.027420088956
INFO:root:current train perplexity10.523015022277832
INFO:root:current mean train loss 5906.111593954655
INFO:root:current train perplexity10.303555488586426
INFO:root:current mean train loss 5854.630237020234
INFO:root:current train perplexity10.089529037475586
INFO:root:current mean train loss 5810.366556325802
INFO:root:current train perplexity9.901331901550293
INFO:root:current mean train loss 5757.794705815502
INFO:root:current train perplexity9.697884559631348
INFO:root:current mean train loss 5726.847911157256
INFO:root:current train perplexity9.572685241699219
INFO:root:current mean train loss 5716.052509734425
INFO:root:current train perplexity9.524227142333984

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.45s/it]
INFO:root:final mean train loss: 5701.175760576802
INFO:root:final train perplexity: 9.4808931350708
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.90s/it]
INFO:root:eval mean loss: 4562.704330119681
INFO:root:eval perplexity: 6.328249931335449
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it]
INFO:root:eval mean loss: 5426.31481847019
INFO:root:eval perplexity: 9.197159767150879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [12:27:38<11:00:50, 421.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5467.569980053191
INFO:root:current train perplexity8.740028381347656
INFO:root:current mean train loss 5551.239789275085
INFO:root:current train perplexity9.000334739685059
INFO:root:current mean train loss 5611.576672017333
INFO:root:current train perplexity9.177536010742188
INFO:root:current mean train loss 5723.915858024136
INFO:root:current train perplexity9.561619758605957
INFO:root:current mean train loss 5696.404946824315
INFO:root:current train perplexity9.442233085632324
INFO:root:current mean train loss 5693.411365794961
INFO:root:current train perplexity9.43474006652832
INFO:root:current mean train loss 5663.657560887993
INFO:root:current train perplexity9.314560890197754
INFO:root:current mean train loss 5639.36359500502
INFO:root:current train perplexity9.222732543945312
INFO:root:current mean train loss 5617.965680803572
INFO:root:current train perplexity9.158185005187988
INFO:root:current mean train loss 5622.266273635493
INFO:root:current train perplexity9.182915687561035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.17s/it]
INFO:root:final mean train loss: 5631.738086577385
INFO:root:final train perplexity: 9.224689483642578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.03s/it]
INFO:root:eval mean loss: 4873.282375470966
INFO:root:eval perplexity: 7.17506742477417
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.24s/it]
INFO:root:eval mean loss: 5718.252510666001
INFO:root:eval perplexity: 10.363311767578125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [12:34:40<10:53:49, 421.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6062.477707741477
INFO:root:current train perplexity11.08303451538086
INFO:root:current mean train loss 6038.607141507056
INFO:root:current train perplexity10.78614330291748
INFO:root:current mean train loss 5854.25876416973
INFO:root:current train perplexity9.999731063842773
INFO:root:current mean train loss 5765.146657680458
INFO:root:current train perplexity9.650718688964844
INFO:root:current mean train loss 5685.383507898352
INFO:root:current train perplexity9.360199928283691
INFO:root:current mean train loss 5625.110856559685
INFO:root:current train perplexity9.141871452331543
INFO:root:current mean train loss 5581.078119781727
INFO:root:current train perplexity9.000605583190918
INFO:root:current mean train loss 5561.4461985202815
INFO:root:current train perplexity8.940719604492188
INFO:root:current mean train loss 5559.104098135965
INFO:root:current train perplexity8.940826416015625
INFO:root:current mean train loss 5526.154902752782
INFO:root:current train perplexity8.829936027526855

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.68s/it]
INFO:root:final mean train loss: 5508.941912128079
INFO:root:final train perplexity: 8.78843879699707
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.01s/it]
INFO:root:eval mean loss: 4414.99987186946
INFO:root:eval perplexity: 5.9613471031188965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it]
INFO:root:eval mean loss: 5278.225939162234
INFO:root:eval perplexity: 8.65674877166748
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [12:41:41<10:46:10, 421.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5276.103329613095
INFO:root:current train perplexity7.923500061035156
INFO:root:current mean train loss 5229.8394423408745
INFO:root:current train perplexity7.867762565612793
INFO:root:current mean train loss 5309.109391709244
INFO:root:current train perplexity8.091472625732422
INFO:root:current mean train loss 5316.114884641874
INFO:root:current train perplexity8.142227172851562
INFO:root:current mean train loss 5320.807970479549
INFO:root:current train perplexity8.14510726928711
INFO:root:current mean train loss 5337.452039159636
INFO:root:current train perplexity8.206564903259277
INFO:root:current mean train loss 5341.517911747031
INFO:root:current train perplexity8.20651626586914
INFO:root:current mean train loss 5314.6401360788
INFO:root:current train perplexity8.119547843933105
INFO:root:current mean train loss 5281.425230731279
INFO:root:current train perplexity8.023259162902832
INFO:root:current mean train loss 5272.2346122955605
INFO:root:current train perplexity7.997410297393799

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.57s/it]
INFO:root:final mean train loss: 5273.001493884671
INFO:root:final train perplexity: 8.007284164428711
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.18s/it]
INFO:root:eval mean loss: 4471.608369002105
INFO:root:eval perplexity: 6.099380016326904
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it]
INFO:root:eval mean loss: 5328.742442029587
INFO:root:eval perplexity: 8.837430000305176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [12:48:42<10:39:18, 421.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5302.568352497799
INFO:root:current train perplexity8.286321640014648
INFO:root:current mean train loss 5283.287146495797
INFO:root:current train perplexity8.129995346069336
INFO:root:current mean train loss 5235.045887626845
INFO:root:current train perplexity7.946713447570801
INFO:root:current mean train loss 5270.5110580567725
INFO:root:current train perplexity7.994346618652344
INFO:root:current mean train loss 5258.971199699775
INFO:root:current train perplexity7.94962215423584
INFO:root:current mean train loss 5241.852192733417
INFO:root:current train perplexity7.907228946685791
INFO:root:current mean train loss 5249.4806150160675
INFO:root:current train perplexity7.923794746398926
INFO:root:current mean train loss 5252.705953358058
INFO:root:current train perplexity7.919666290283203
INFO:root:current mean train loss 5230.0535758332735
INFO:root:current train perplexity7.860935688018799
INFO:root:current mean train loss 5214.3068759655
INFO:root:current train perplexity7.811904430389404

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.03s/it]
INFO:root:final mean train loss: 5208.267408001808
INFO:root:final train perplexity: 7.8053717613220215
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.98s/it]
INFO:root:eval mean loss: 4350.696770417775
INFO:root:eval perplexity: 5.808335304260254
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it]
INFO:root:eval mean loss: 5216.420789353391
INFO:root:eval perplexity: 8.44070816040039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/110
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [12:55:45<10:32:56, 421.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5025.292987292326
INFO:root:current train perplexity7.278402805328369
INFO:root:current mean train loss 5028.683443719448
INFO:root:current train perplexity7.247709274291992
INFO:root:current mean train loss 5018.460146449373
INFO:root:current train perplexity7.2341084480285645
INFO:root:current mean train loss 5027.65914232561
INFO:root:current train perplexity7.256389141082764
INFO:root:current mean train loss 5025.050429565174
INFO:root:current train perplexity7.258812427520752
INFO:root:current mean train loss 5026.9029821418935
INFO:root:current train perplexity7.265871524810791
INFO:root:current mean train loss 5031.1765801903075
INFO:root:current train perplexity7.2665510177612305
INFO:root:current mean train loss 5030.434370988447
INFO:root:current train perplexity7.256120204925537
INFO:root:current mean train loss 5044.636042710999
INFO:root:current train perplexity7.301988124847412
INFO:root:current mean train loss 5044.071937942895
INFO:root:current train perplexity7.306284427642822

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.32s/it]
INFO:root:final mean train loss: 5040.651181867046
INFO:root:final train perplexity: 7.305903911590576
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.82s/it]
INFO:root:eval mean loss: 4356.955422692265
INFO:root:eval perplexity: 5.823054790496826
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.02s/it]
INFO:root:eval mean loss: 5222.951440256538
INFO:root:eval perplexity: 8.463276863098145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/111
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [13:02:48<10:26:08, 422.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5022.940008755388
INFO:root:current train perplexity7.24202299118042
INFO:root:current mean train loss 4993.5620952749
INFO:root:current train perplexity7.1864824295043945
INFO:root:current mean train loss 4991.4561924951
INFO:root:current train perplexity7.159672737121582
INFO:root:current mean train loss 4981.515030735223
INFO:root:current train perplexity7.125227451324463
INFO:root:current mean train loss 4985.360401694045
INFO:root:current train perplexity7.128829002380371
INFO:root:current mean train loss 4977.711681151512
INFO:root:current train perplexity7.12126350402832
INFO:root:current mean train loss 4984.171634768468
INFO:root:current train perplexity7.134073257446289
INFO:root:current mean train loss 4988.275234896164
INFO:root:current train perplexity7.148458957672119
INFO:root:current mean train loss 4990.944824769236
INFO:root:current train perplexity7.156672477722168
INFO:root:current mean train loss 4992.143030786949
INFO:root:current train perplexity7.155429363250732

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.31s/it]
INFO:root:final mean train loss: 4987.885460146012
INFO:root:final train perplexity: 7.155385971069336
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.33s/it]
INFO:root:eval mean loss: 4296.105200368462
INFO:root:eval perplexity: 5.681519508361816
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.67s/it]
INFO:root:eval mean loss: 5167.636085023271
INFO:root:eval perplexity: 8.27399730682373
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/112
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [13:09:49<10:18:27, 421.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4952.377790912829
INFO:root:current train perplexity7.020442008972168
INFO:root:current mean train loss 4970.894436097757
INFO:root:current train perplexity7.0875935554504395
INFO:root:current mean train loss 4970.06411215572
INFO:root:current train perplexity7.11985445022583
INFO:root:current mean train loss 4977.006199317642
INFO:root:current train perplexity7.129044532775879
INFO:root:current mean train loss 4980.908626302084
INFO:root:current train perplexity7.145069599151611
INFO:root:current mean train loss 4988.643466058298
INFO:root:current train perplexity7.163055896759033
INFO:root:current mean train loss 4984.317874606565
INFO:root:current train perplexity7.15721321105957
INFO:root:current mean train loss 4986.925315079599
INFO:root:current train perplexity7.15289306640625
INFO:root:current mean train loss 4986.168382288757
INFO:root:current train perplexity7.14105224609375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.95s/it]
INFO:root:final mean train loss: 4980.031528349846
INFO:root:final train perplexity: 7.133245944976807
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.37s/it]
INFO:root:eval mean loss: 4278.783949398825
INFO:root:eval perplexity: 5.641865253448486
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.47s/it]
INFO:root:eval mean loss: 5150.959585203346
INFO:root:eval perplexity: 8.217764854431152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/113
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [13:16:50<10:11:09, 421.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5025.8212890625
INFO:root:current train perplexity7.286092758178711
INFO:root:current mean train loss 5023.812760732706
INFO:root:current train perplexity7.3138813972473145
INFO:root:current mean train loss 5095.96402593904
INFO:root:current train perplexity7.528708457946777
INFO:root:current mean train loss 5137.007061545998
INFO:root:current train perplexity7.61231803894043
INFO:root:current mean train loss 5152.856849992246
INFO:root:current train perplexity7.655517578125
INFO:root:current mean train loss 5155.867202061071
INFO:root:current train perplexity7.6589860916137695
INFO:root:current mean train loss 5147.178841307784
INFO:root:current train perplexity7.624395370483398
INFO:root:current mean train loss 5139.141066745199
INFO:root:current train perplexity7.5964741706848145
INFO:root:current mean train loss 5135.98517339761
INFO:root:current train perplexity7.5749287605285645
INFO:root:current mean train loss 5134.476041774813
INFO:root:current train perplexity7.567931652069092

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.93s/it]
INFO:root:final mean train loss: 5120.0480435279105
INFO:root:final train perplexity: 7.538378715515137
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.47s/it]
INFO:root:eval mean loss: 4348.041621647828
INFO:root:eval perplexity: 5.802103042602539
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.22s/it]
INFO:root:eval mean loss: 5218.760953429743
INFO:root:eval perplexity: 8.448789596557617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/114
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [13:23:54<10:05:14, 422.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5097.965243252841
INFO:root:current train perplexity7.454893112182617
INFO:root:current mean train loss 5049.508705482826
INFO:root:current train perplexity7.31770658493042
INFO:root:current mean train loss 5135.652922282286
INFO:root:current train perplexity7.586023807525635
INFO:root:current mean train loss 5518.332192963726
INFO:root:current train perplexity8.821906089782715
INFO:root:current mean train loss 5570.495517554365
INFO:root:current train perplexity8.996119499206543
INFO:root:current mean train loss 5637.528199914384
INFO:root:current train perplexity9.229423522949219
INFO:root:current mean train loss 5773.245624648373
INFO:root:current train perplexity9.721283912658691
INFO:root:current mean train loss 5832.5041287579115
INFO:root:current train perplexity9.949687004089355
INFO:root:current mean train loss 5841.398616315698
INFO:root:current train perplexity10.002828598022461
INFO:root:current mean train loss 5856.87663099873
INFO:root:current train perplexity10.064861297607422

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.10s/it]
INFO:root:final mean train loss: 5861.712926680042
INFO:root:final train perplexity: 10.100805282592773
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.60s/it]
INFO:root:eval mean loss: 4694.159477504432
INFO:root:eval perplexity: 6.6737380027771
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.13s/it]
INFO:root:eval mean loss: 5524.104194370568
INFO:root:eval perplexity: 9.572381973266602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/115
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [13:30:58<9:59:00, 422.83s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5818.358192845395
INFO:root:current train perplexity9.861178398132324
INFO:root:current mean train loss 5798.52185366334
INFO:root:current train perplexity9.682682991027832
INFO:root:current mean train loss 5831.730361729452
INFO:root:current train perplexity9.892563819885254
INFO:root:current mean train loss 5853.8545687206115
INFO:root:current train perplexity10.019359588623047
INFO:root:current mean train loss 5895.512064858666
INFO:root:current train perplexity10.253534317016602
INFO:root:current mean train loss 5922.134076950867
INFO:root:current train perplexity10.325789451599121
INFO:root:current mean train loss 5959.581834044326
INFO:root:current train perplexity10.482686996459961
INFO:root:current mean train loss 5986.967020981832
INFO:root:current train perplexity10.586958885192871
INFO:root:current mean train loss 5990.113909040178
INFO:root:current train perplexity10.601823806762695
INFO:root:current mean train loss 5984.470653712425
INFO:root:current train perplexity10.59011173248291

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.79s/it]
INFO:root:final mean train loss: 5977.09107466667
INFO:root:final train perplexity: 10.571222305297852
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 30.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 30.00s/it]
INFO:root:eval mean loss: 4823.756586602393
INFO:root:eval perplexity: 7.0328049659729
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it]
INFO:root:eval mean loss: 5617.004910516401
INFO:root:eval perplexity: 9.94301700592041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/116
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [13:38:00<9:51:31, 422.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6333.392053674768
INFO:root:current train perplexity11.931933403015137
INFO:root:current mean train loss 6427.29836675689
INFO:root:current train perplexity12.428053855895996
INFO:root:current mean train loss 6257.884692490364
INFO:root:current train perplexity11.749906539916992
INFO:root:current mean train loss 6154.778038094897
INFO:root:current train perplexity11.280412673950195
INFO:root:current mean train loss 6060.392315116364
INFO:root:current train perplexity10.933577537536621
INFO:root:current mean train loss 6038.690860523897
INFO:root:current train perplexity10.790205001831055
INFO:root:current mean train loss 6035.106032570773
INFO:root:current train perplexity10.799078941345215
INFO:root:current mean train loss 6009.871021884672
INFO:root:current train perplexity10.686416625976562
INFO:root:current mean train loss 6016.716978725816
INFO:root:current train perplexity10.71399974822998
INFO:root:current mean train loss 6024.922206841627
INFO:root:current train perplexity10.754045486450195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.51s/it]
INFO:root:final mean train loss: 6005.539656362226
INFO:root:final train perplexity: 10.690543174743652
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.61s/it]
INFO:root:eval mean loss: 4705.334550573471
INFO:root:eval perplexity: 6.7039642333984375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it]
INFO:root:eval mean loss: 5520.154667414672
INFO:root:eval perplexity: 9.556934356689453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/117
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [13:45:03<9:44:43, 422.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6008.784458705357
INFO:root:current train perplexity10.492606163024902
INFO:root:current mean train loss 5956.131083622685
INFO:root:current train perplexity10.366761207580566
INFO:root:current mean train loss 5940.802827875665
INFO:root:current train perplexity10.360189437866211
INFO:root:current mean train loss 6019.909205923507
INFO:root:current train perplexity10.687402725219727
INFO:root:current mean train loss 5969.048324128951
INFO:root:current train perplexity10.506414413452148
INFO:root:current mean train loss 5970.25525244597
INFO:root:current train perplexity10.526886940002441
INFO:root:current mean train loss 5961.452924304872
INFO:root:current train perplexity10.51352310180664
INFO:root:current mean train loss 5989.799918287627
INFO:root:current train perplexity10.615811347961426
INFO:root:current mean train loss 6027.648495392028
INFO:root:current train perplexity10.757189750671387
INFO:root:current mean train loss 6059.784261676972
INFO:root:current train perplexity10.8975830078125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.75s/it]
INFO:root:final mean train loss: 6068.685460490565
INFO:root:final train perplexity: 10.960217475891113
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.21s/it]
INFO:root:eval mean loss: 4897.228120844415
INFO:root:eval perplexity: 7.2448811531066895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.68s/it]
INFO:root:eval mean loss: 5689.32409061946
INFO:root:eval perplexity: 10.241447448730469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/118
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [13:52:06<9:37:48, 422.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6448.8437045784885
INFO:root:current train perplexity13.054611206054688
INFO:root:current mean train loss 6425.195220307037
INFO:root:current train perplexity12.757412910461426
INFO:root:current mean train loss 6561.936067306456
INFO:root:current train perplexity13.382474899291992
INFO:root:current mean train loss 6688.864098373724
INFO:root:current train perplexity14.018378257751465
INFO:root:current mean train loss 6774.414492363854
INFO:root:current train perplexity14.512930870056152
INFO:root:current mean train loss 6807.999810262719
INFO:root:current train perplexity14.707437515258789
INFO:root:current mean train loss 6813.527582195276
INFO:root:current train perplexity14.733963012695312
INFO:root:current mean train loss 6881.828348439603
INFO:root:current train perplexity15.085103034973145
INFO:root:current mean train loss 6850.143477651431
INFO:root:current train perplexity14.895620346069336
INFO:root:current mean train loss 6835.9061821687765
INFO:root:current train perplexity14.808906555175781

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.51s/it]
INFO:root:final mean train loss: 6825.606020773611
INFO:root:final train perplexity: 14.774444580078125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.94s/it]
INFO:root:eval mean loss: 5128.048762328236
INFO:root:eval perplexity: 7.953662395477295
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it]
INFO:root:eval mean loss: 5899.429968001995
INFO:root:eval perplexity: 11.160246849060059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/119
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [13:59:07<9:29:57, 422.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6805.924220664829
INFO:root:current train perplexity14.733907699584961
INFO:root:current mean train loss 7036.942589766142
INFO:root:current train perplexity15.920137405395508
INFO:root:current mean train loss 7143.092695623755
INFO:root:current train perplexity16.760705947875977
INFO:root:current mean train loss 7339.159231158743
INFO:root:current train perplexity18.078176498413086
INFO:root:current mean train loss 7424.666565618071
INFO:root:current train perplexity18.719717025756836
INFO:root:current mean train loss 7474.411558175477
INFO:root:current train perplexity19.11843490600586
INFO:root:current mean train loss 7515.672609296995
INFO:root:current train perplexity19.383758544921875
INFO:root:current mean train loss 7500.2681372752995
INFO:root:current train perplexity19.219226837158203
INFO:root:current mean train loss 7468.000226640534
INFO:root:current train perplexity18.9731502532959
INFO:root:current mean train loss 7427.7557890337475
INFO:root:current train perplexity18.667922973632812

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.47s/it]
INFO:root:final mean train loss: 7406.47729713686
INFO:root:final train perplexity: 18.57969856262207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.28s/it]
INFO:root:eval mean loss: 5401.064906776374
INFO:root:eval perplexity: 8.882046699523926
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.37s/it]
INFO:root:eval mean loss: 6177.008851396276
INFO:root:eval perplexity: 12.501690864562988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/120
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [14:06:08<9:22:37, 421.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 7143.818442134534
INFO:root:current train perplexity16.648502349853516
INFO:root:current mean train loss 7056.382047833137
INFO:root:current train perplexity16.30611801147461
INFO:root:current mean train loss 6970.077953441723
INFO:root:current train perplexity15.70038890838623
INFO:root:current mean train loss 6965.87472797702
INFO:root:current train perplexity15.545531272888184
INFO:root:current mean train loss 6920.948306015114
INFO:root:current train perplexity15.26601791381836
INFO:root:current mean train loss 6881.966685068202
INFO:root:current train perplexity15.035799026489258
INFO:root:current mean train loss 6836.432008132587
INFO:root:current train perplexity14.810090065002441
INFO:root:current mean train loss 6799.774507344162
INFO:root:current train perplexity14.60482406616211
INFO:root:current mean train loss 6761.102958563737
INFO:root:current train perplexity14.390016555786133
INFO:root:current mean train loss 6732.090007189292
INFO:root:current train perplexity14.214950561523438

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.12s/it]
INFO:root:final mean train loss: 6718.24275970459
INFO:root:final train perplexity: 14.161702156066895
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.98s/it]
INFO:root:eval mean loss: 5106.771134613254
INFO:root:eval perplexity: 7.885519981384277
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.56s/it]
INFO:root:eval mean loss: 5908.434861203457
INFO:root:eval perplexity: 11.20141887664795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/121
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [14:13:10<9:15:36, 421.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6326.615350979478
INFO:root:current train perplexity12.047219276428223
INFO:root:current mean train loss 6356.714101094685
INFO:root:current train perplexity12.33821964263916
INFO:root:current mean train loss 6410.099965984901
INFO:root:current train perplexity12.541449546813965
INFO:root:current mean train loss 6433.92333186095
INFO:root:current train perplexity12.646800994873047
INFO:root:current mean train loss 6431.05525629015
INFO:root:current train perplexity12.603885650634766
INFO:root:current mean train loss 6417.362229766039
INFO:root:current train perplexity12.537898063659668
INFO:root:current mean train loss 6392.128531437406
INFO:root:current train perplexity12.430688858032227
INFO:root:current mean train loss 6370.089675047873
INFO:root:current train perplexity12.344266891479492
INFO:root:current mean train loss 6352.080251585929
INFO:root:current train perplexity12.256425857543945
INFO:root:current mean train loss 6336.142242841908
INFO:root:current train perplexity12.162275314331055

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.53s/it]
INFO:root:final mean train loss: 6327.156607104886
INFO:root:final train perplexity: 12.136850357055664
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.48s/it]
INFO:root:eval mean loss: 5039.469269448138
INFO:root:eval perplexity: 7.673811435699463
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.18s/it]
INFO:root:eval mean loss: 5852.55510305851
INFO:root:eval perplexity: 10.948368072509766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/122
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [14:20:13<9:08:47, 422.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6088.864134114583
INFO:root:current train perplexity11.233966827392578
INFO:root:current mean train loss 6124.182391183036
INFO:root:current train perplexity11.25578498840332
INFO:root:current mean train loss 6131.226569602272
INFO:root:current train perplexity11.250129699707031
INFO:root:current mean train loss 6143.86787890625
INFO:root:current train perplexity11.286688804626465
INFO:root:current mean train loss 6126.843816817434
INFO:root:current train perplexity11.207415580749512
INFO:root:current mean train loss 6118.030202955163
INFO:root:current train perplexity11.145403861999512
INFO:root:current mean train loss 6109.438097511574
INFO:root:current train perplexity11.110634803771973
INFO:root:current mean train loss 6097.141303553428
INFO:root:current train perplexity11.045378684997559
INFO:root:current mean train loss 6086.661728794643
INFO:root:current train perplexity11.016378402709961
INFO:root:current mean train loss 6081.2917307692305
INFO:root:current train perplexity10.997239112854004

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.72s/it]
INFO:root:final mean train loss: 6075.931181261616
INFO:root:final train perplexity: 10.991593360900879
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.78s/it]
INFO:root:eval mean loss: 4965.317126551418
INFO:root:eval perplexity: 7.4471282958984375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it]
INFO:root:eval mean loss: 5787.869022883422
INFO:root:eval perplexity: 10.662568092346191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/123
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [14:27:13<9:01:05, 421.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6033.35353327372
INFO:root:current train perplexity10.644678115844727
INFO:root:current mean train loss 6020.550370346653
INFO:root:current train perplexity10.670838356018066
INFO:root:current mean train loss 5998.083818738957
INFO:root:current train perplexity10.615110397338867
INFO:root:current mean train loss 5995.744679901681
INFO:root:current train perplexity10.603636741638184
INFO:root:current mean train loss 5984.058302600932
INFO:root:current train perplexity10.578201293945312
INFO:root:current mean train loss 5971.246795601951
INFO:root:current train perplexity10.53334903717041
INFO:root:current mean train loss 5964.856072846129
INFO:root:current train perplexity10.503984451293945
INFO:root:current mean train loss 5957.637514467592
INFO:root:current train perplexity10.475661277770996
INFO:root:current mean train loss 5946.310142646695
INFO:root:current train perplexity10.428207397460938
INFO:root:current mean train loss 5937.112907215635
INFO:root:current train perplexity10.387110710144043

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.32s/it]
INFO:root:final mean train loss: 5932.064883693572
INFO:root:final train perplexity: 10.385089874267578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.40s/it]
INFO:root:eval mean loss: 4914.00674936281
INFO:root:eval perplexity: 7.294205188751221
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.33s/it]
INFO:root:eval mean loss: 5741.2758234984485
INFO:root:eval perplexity: 10.461339950561523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/124
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [14:34:11<8:52:50, 420.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5897.406781207074
INFO:root:current train perplexity10.198346138000488
INFO:root:current mean train loss 5856.580990776341
INFO:root:current train perplexity10.106499671936035
INFO:root:current mean train loss 5888.608826312822
INFO:root:current train perplexity10.188899040222168
INFO:root:current mean train loss 5892.304181735534
INFO:root:current train perplexity10.172857284545898
INFO:root:current mean train loss 5878.386407483134
INFO:root:current train perplexity10.14129638671875
INFO:root:current mean train loss 5875.579261844332
INFO:root:current train perplexity10.140568733215332
INFO:root:current mean train loss 5885.343511159099
INFO:root:current train perplexity10.175057411193848
INFO:root:current mean train loss 5881.3440907474715
INFO:root:current train perplexity10.167088508605957
INFO:root:current mean train loss 5883.080613535529
INFO:root:current train perplexity10.170015335083008
INFO:root:current mean train loss 5883.716520954213
INFO:root:current train perplexity10.170369148254395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.76s/it]
INFO:root:final mean train loss: 5879.1082737830375
INFO:root:final train perplexity: 10.170369148254395
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.73s/it]
INFO:root:eval mean loss: 4918.746879848182
INFO:root:eval perplexity: 7.308199882507324
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.84s/it]
INFO:root:eval mean loss: 5740.857615802305
INFO:root:eval perplexity: 10.459551811218262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/125
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [14:41:15<8:46:57, 421.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5851.79738794192
INFO:root:current train perplexity10.028716087341309
INFO:root:current mean train loss 5865.140595555905
INFO:root:current train perplexity10.01968002319336
INFO:root:current mean train loss 5850.1078007420565
INFO:root:current train perplexity9.959482192993164
INFO:root:current mean train loss 5833.168349340147
INFO:root:current train perplexity9.927929878234863
INFO:root:current mean train loss 5820.948331232778
INFO:root:current train perplexity9.89976692199707
INFO:root:current mean train loss 5812.588096860653
INFO:root:current train perplexity9.868182182312012
INFO:root:current mean train loss 5801.84453027204
INFO:root:current train perplexity9.852142333984375
INFO:root:current mean train loss 5801.008468838
INFO:root:current train perplexity9.838561058044434
INFO:root:current mean train loss 5796.380927267276
INFO:root:current train perplexity9.81673526763916

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.00s/it]
INFO:root:final mean train loss: 5780.211040989046
INFO:root:final train perplexity: 9.781184196472168
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.18s/it]
INFO:root:eval mean loss: 4854.206878878546
INFO:root:eval perplexity: 7.119936943054199
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.55s/it]
INFO:root:eval mean loss: 5686.071496841755
INFO:root:eval perplexity: 10.22783374786377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/126
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [14:48:18<8:40:30, 422.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5638.394949776785
INFO:root:current train perplexity9.308073997497559
INFO:root:current mean train loss 5742.211886682243
INFO:root:current train perplexity9.537786483764648
INFO:root:current mean train loss 5695.074780155495
INFO:root:current train perplexity9.460143089294434
INFO:root:current mean train loss 5696.90013455568
INFO:root:current train perplexity9.451050758361816
INFO:root:current mean train loss 5693.827511949094
INFO:root:current train perplexity9.43149185180664
INFO:root:current mean train loss 5669.866089589497
INFO:root:current train perplexity9.360654830932617
INFO:root:current mean train loss 5665.527924539229
INFO:root:current train perplexity9.320356369018555
INFO:root:current mean train loss 5658.224533404791
INFO:root:current train perplexity9.295284271240234
INFO:root:current mean train loss 5651.396871006622
INFO:root:current train perplexity9.26660442352295
INFO:root:current mean train loss 5646.586094697492
INFO:root:current train perplexity9.254143714904785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.28s/it]
INFO:root:final mean train loss: 5632.382868366857
INFO:root:final train perplexity: 9.227038383483887
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.87s/it]
INFO:root:eval mean loss: 4807.1339483599295
INFO:root:eval perplexity: 6.985690593719482
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it]
INFO:root:eval mean loss: 5645.2797366744235
INFO:root:eval perplexity: 10.058646202087402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/127
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [14:55:23<8:34:35, 422.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5648.252408854167
INFO:root:current train perplexity9.15823745727539
INFO:root:current mean train loss 5573.60368970788
INFO:root:current train perplexity9.056634902954102
INFO:root:current mean train loss 5558.610964752907
INFO:root:current train perplexity8.993498802185059
INFO:root:current mean train loss 5555.765842013889
INFO:root:current train perplexity8.9609956741333
INFO:root:current mean train loss 5552.9037603539155
INFO:root:current train perplexity8.913534164428711
INFO:root:current mean train loss 5546.974474742112
INFO:root:current train perplexity8.904674530029297
INFO:root:current mean train loss 5545.314797700711
INFO:root:current train perplexity8.902307510375977
INFO:root:current mean train loss 5552.226447088068
INFO:root:current train perplexity8.911248207092285
INFO:root:current mean train loss 5547.478410180215
INFO:root:current train perplexity8.905071258544922
INFO:root:current mean train loss 5551.173198962602
INFO:root:current train perplexity8.913400650024414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.24s/it]
INFO:root:final mean train loss: 5553.758014063681
INFO:root:final train perplexity: 8.945210456848145
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.53s/it]
INFO:root:eval mean loss: 4784.860666694371
INFO:root:eval perplexity: 6.923055648803711
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.17s/it]
INFO:root:eval mean loss: 5627.766244874779
INFO:root:eval perplexity: 9.98686695098877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/128
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [15:02:25<8:26:56, 422.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5524.999384341033
INFO:root:current train perplexity8.991571426391602
INFO:root:current mean train loss 5573.011706840702
INFO:root:current train perplexity9.010128021240234
INFO:root:current mean train loss 5579.796870620796
INFO:root:current train perplexity9.024506568908691
INFO:root:current mean train loss 5576.8657634723295
INFO:root:current train perplexity9.00003719329834
INFO:root:current mean train loss 5575.1674839317375
INFO:root:current train perplexity8.98766803741455
INFO:root:current mean train loss 5567.911032915571
INFO:root:current train perplexity8.970982551574707
INFO:root:current mean train loss 5562.58057816262
INFO:root:current train perplexity8.973711967468262
INFO:root:current mean train loss 5562.344392937413
INFO:root:current train perplexity8.972268104553223
INFO:root:current mean train loss 5560.8214112811365
INFO:root:current train perplexity8.967069625854492
INFO:root:current mean train loss 5557.353529379401
INFO:root:current train perplexity8.93840503692627

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.02s/it]
INFO:root:final mean train loss: 5548.999538052467
INFO:root:final train perplexity: 8.928433418273926
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.34s/it]
INFO:root:eval mean loss: 4765.901263297872
INFO:root:eval perplexity: 6.870182514190674
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.31s/it]
INFO:root:eval mean loss: 5608.459531527039
INFO:root:eval perplexity: 9.908333778381348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/129
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [15:09:26<8:19:23, 422.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5498.305742817541
INFO:root:current train perplexity8.86630916595459
INFO:root:current mean train loss 5491.947265625
INFO:root:current train perplexity8.771171569824219
INFO:root:current mean train loss 5520.400295505276
INFO:root:current train perplexity8.820263862609863
INFO:root:current mean train loss 5510.11890164747
INFO:root:current train perplexity8.788244247436523
INFO:root:current mean train loss 5516.075151129277
INFO:root:current train perplexity8.79937744140625
INFO:root:current mean train loss 5518.436612633886
INFO:root:current train perplexity8.810131072998047
INFO:root:current mean train loss 5515.344051016492
INFO:root:current train perplexity8.806285858154297
INFO:root:current mean train loss 5511.8571379905525
INFO:root:current train perplexity8.792963981628418
INFO:root:current mean train loss 5516.506675527415
INFO:root:current train perplexity8.796149253845215
INFO:root:current mean train loss 5516.9012087976635
INFO:root:current train perplexity8.796889305114746

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.31s/it]
INFO:root:final mean train loss: 5511.053948556223
INFO:root:final train perplexity: 8.79576301574707
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.89s/it]
INFO:root:eval mean loss: 4765.431820700354
INFO:root:eval perplexity: 6.86887788772583
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.61s/it]
INFO:root:eval mean loss: 5602.793311585771
INFO:root:eval perplexity: 9.885403633117676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/130
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [15:16:28<8:12:25, 422.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5480.787009214743
INFO:root:current train perplexity8.660676002502441
INFO:root:current mean train loss 5507.402294570594
INFO:root:current train perplexity8.782609939575195
INFO:root:current mean train loss 5524.218864408996
INFO:root:current train perplexity8.824604988098145
INFO:root:current mean train loss 5535.670353982301
INFO:root:current train perplexity8.890995979309082
INFO:root:current mean train loss 5541.8365025270505
INFO:root:current train perplexity8.91373348236084
INFO:root:current mean train loss 5554.342795179151
INFO:root:current train perplexity8.96248722076416
INFO:root:current mean train loss 5567.070928391529
INFO:root:current train perplexity9.006790161132812
INFO:root:current mean train loss 5582.513764377537
INFO:root:current train perplexity9.040468215942383
INFO:root:current mean train loss 5589.014743300246
INFO:root:current train perplexity9.063558578491211
INFO:root:current mean train loss 5596.569921458999
INFO:root:current train perplexity9.08960247039795

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.88s/it]
INFO:root:final mean train loss: 5598.958260690012
INFO:root:final train perplexity: 9.106159210205078
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.03s/it]
INFO:root:eval mean loss: 4806.32361619016
INFO:root:eval perplexity: 6.983401775360107
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.79s/it]
INFO:root:eval mean loss: 5636.137986203457
INFO:root:eval perplexity: 10.02111530303955
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/131
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [15:23:31<8:05:42, 422.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5739.93671043883
INFO:root:current train perplexity9.631644248962402
INFO:root:current mean train loss 5748.15871797938
INFO:root:current train perplexity9.673949241638184
INFO:root:current mean train loss 5798.698965713563
INFO:root:current train perplexity9.798563957214355
INFO:root:current mean train loss 5804.157759872568
INFO:root:current train perplexity9.839947700500488
INFO:root:current mean train loss 5789.207274844449
INFO:root:current train perplexity9.805912017822266
INFO:root:current mean train loss 5786.518682336894
INFO:root:current train perplexity9.802157402038574
INFO:root:current mean train loss 5782.106559269948
INFO:root:current train perplexity9.786778450012207
INFO:root:current mean train loss 5784.089039099104
INFO:root:current train perplexity9.794569969177246
INFO:root:current mean train loss 5781.144522026269
INFO:root:current train perplexity9.791726112365723
INFO:root:current mean train loss 5786.379592009305
INFO:root:current train perplexity9.791726112365723

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.40s/it]
INFO:root:final mean train loss: 5782.271917650776
INFO:root:final train perplexity: 9.789137840270996
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.16s/it]
INFO:root:eval mean loss: 4839.7690568207
INFO:root:eval perplexity: 7.078489780426025
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.14s/it]
INFO:root:eval mean loss: 5666.792653618129
INFO:root:eval perplexity: 10.1475191116333
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/132
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [15:30:34<7:58:53, 422.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5805.023526278409
INFO:root:current train perplexity9.710952758789062
INFO:root:current mean train loss 5773.647334929436
INFO:root:current train perplexity9.693790435791016
INFO:root:current mean train loss 5777.587088311887
INFO:root:current train perplexity9.707989692687988
INFO:root:current mean train loss 5785.156142715669
INFO:root:current train perplexity9.739028930664062
INFO:root:current mean train loss 5792.6979857057
INFO:root:current train perplexity9.79119873046875
INFO:root:current mean train loss 5797.902582172016
INFO:root:current train perplexity9.806356430053711
INFO:root:current mean train loss 5791.2222581703245
INFO:root:current train perplexity9.807377815246582
INFO:root:current mean train loss 5794.453875853684
INFO:root:current train perplexity9.823412895202637
INFO:root:current mean train loss 5798.136785567434
INFO:root:current train perplexity9.834081649780273
INFO:root:current mean train loss 5805.407313481675
INFO:root:current train perplexity9.864303588867188

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.57s/it]
INFO:root:final mean train loss: 5801.156719207764
INFO:root:final train perplexity: 9.862347602844238
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it]
INFO:root:eval mean loss: 4847.06251385195
INFO:root:eval perplexity: 7.099396705627441
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it]
INFO:root:eval mean loss: 5674.902447639628
INFO:root:eval perplexity: 10.181228637695312
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/133
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [15:37:35<7:51:19, 422.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5798.686097160218
INFO:root:current train perplexity9.981057167053223
INFO:root:current mean train loss 5843.859614647239
INFO:root:current train perplexity10.106740951538086
INFO:root:current mean train loss 5823.6176349364305
INFO:root:current train perplexity9.99520492553711
INFO:root:current mean train loss 5802.846496750172
INFO:root:current train perplexity9.893132209777832
INFO:root:current mean train loss 5798.390120899703
INFO:root:current train perplexity9.829269409179688
INFO:root:current mean train loss 5784.076495372169
INFO:root:current train perplexity9.78145694732666
INFO:root:current mean train loss 5795.4086766768005
INFO:root:current train perplexity9.817364692687988
INFO:root:current mean train loss 5791.958386022486
INFO:root:current train perplexity9.804153442382812
INFO:root:current mean train loss 5774.963632948291
INFO:root:current train perplexity9.73909854888916
INFO:root:current mean train loss 5759.955279927635
INFO:root:current train perplexity9.68069076538086

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.09s/it]
INFO:root:final mean train loss: 5749.9449209397835
INFO:root:final train perplexity: 9.665081977844238
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.27s/it]
INFO:root:eval mean loss: 4770.673751939273
INFO:root:eval perplexity: 6.883452892303467
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.27s/it]
INFO:root:eval mean loss: 5618.7252569536795
INFO:root:eval perplexity: 9.95001220703125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/134
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [15:44:38<7:44:36, 422.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5611.634738116197
INFO:root:current train perplexity9.199728012084961
INFO:root:current mean train loss 5600.760179664657
INFO:root:current train perplexity9.163837432861328
INFO:root:current mean train loss 5588.713186116236
INFO:root:current train perplexity9.06384563446045
INFO:root:current mean train loss 5576.954314774259
INFO:root:current train perplexity9.008834838867188
INFO:root:current mean train loss 5558.17837297638
INFO:root:current train perplexity8.963025093078613
INFO:root:current mean train loss 5556.873018655593
INFO:root:current train perplexity8.942713737487793
INFO:root:current mean train loss 5544.622349018489
INFO:root:current train perplexity8.908575057983398
INFO:root:current mean train loss 5537.8565156098
INFO:root:current train perplexity8.88922119140625
INFO:root:current mean train loss 5536.839869537529
INFO:root:current train perplexity8.877163887023926
INFO:root:current mean train loss 5535.221887370462
INFO:root:current train perplexity8.8672456741333

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.39s/it]
INFO:root:final mean train loss: 5532.277174180554
INFO:root:final train perplexity: 8.869721412658691
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.19s/it]
INFO:root:eval mean loss: 4755.663148271276
INFO:root:eval perplexity: 6.841797828674316
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.01s/it]
INFO:root:eval mean loss: 5602.677000221631
INFO:root:eval perplexity: 9.884931564331055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/135
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [15:51:39<7:37:04, 421.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5486.750908573971
INFO:root:current train perplexity8.705599784851074
INFO:root:current mean train loss 5485.530873559706
INFO:root:current train perplexity8.712276458740234
INFO:root:current mean train loss 5494.293766801075
INFO:root:current train perplexity8.742362976074219
INFO:root:current mean train loss 5497.1354535991095
INFO:root:current train perplexity8.738348960876465
INFO:root:current mean train loss 5488.421981015135
INFO:root:current train perplexity8.72404956817627
INFO:root:current mean train loss 5489.348981946244
INFO:root:current train perplexity8.720171928405762
INFO:root:current mean train loss 5493.635781019882
INFO:root:current train perplexity8.71785831451416
INFO:root:current mean train loss 5491.259946144897
INFO:root:current train perplexity8.717273712158203
INFO:root:current mean train loss 5486.192377257537
INFO:root:current train perplexity8.693065643310547
INFO:root:current mean train loss 5484.319106510151
INFO:root:current train perplexity8.687722206115723

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.39s/it]
INFO:root:final mean train loss: 5479.720624739124
INFO:root:final train perplexity: 8.687701225280762
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.85s/it]
INFO:root:eval mean loss: 4739.176546570257
INFO:root:eval perplexity: 6.796338081359863
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it]
INFO:root:eval mean loss: 5586.650542996454
INFO:root:eval perplexity: 9.820363998413086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/136
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [15:58:38<7:29:10, 421.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5418.051623114224
INFO:root:current train perplexity8.57569694519043
INFO:root:current mean train loss 5448.200882039606
INFO:root:current train perplexity8.608868598937988
INFO:root:current mean train loss 5448.6620055939675
INFO:root:current train perplexity8.581888198852539
INFO:root:current mean train loss 5439.338922702681
INFO:root:current train perplexity8.55408763885498
INFO:root:current mean train loss 5441.777451031507
INFO:root:current train perplexity8.56890869140625
INFO:root:current mean train loss 5449.5927767648
INFO:root:current train perplexity8.572477340698242
INFO:root:current mean train loss 5439.422673165712
INFO:root:current train perplexity8.5527925491333
INFO:root:current mean train loss 5439.514584532838
INFO:root:current train perplexity8.546327590942383
INFO:root:current mean train loss 5443.434569211528
INFO:root:current train perplexity8.551420211791992
INFO:root:current mean train loss 5442.165870179521
INFO:root:current train perplexity8.546598434448242

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.06s/it]
INFO:root:final mean train loss: 5438.604695104784
INFO:root:final train perplexity: 8.547910690307617
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.17s/it]
INFO:root:eval mean loss: 4714.362107297207
INFO:root:eval perplexity: 6.728484153747559
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.28s/it]
INFO:root:eval mean loss: 5567.855773492908
INFO:root:eval perplexity: 9.745179176330566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/137
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [16:05:41<7:22:43, 421.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5415.781805098684
INFO:root:current train perplexity8.518331527709961
INFO:root:current mean train loss 5443.941696714744
INFO:root:current train perplexity8.525294303894043
INFO:root:current mean train loss 5436.930106263241
INFO:root:current train perplexity8.537516593933105
INFO:root:current mean train loss 5446.198516613924
INFO:root:current train perplexity8.560530662536621
INFO:root:current mean train loss 5457.154889717487
INFO:root:current train perplexity8.595664978027344
INFO:root:current mean train loss 5462.081224560136
INFO:root:current train perplexity8.60672378540039
INFO:root:current mean train loss 5462.118091698516
INFO:root:current train perplexity8.611030578613281
INFO:root:current mean train loss 5470.355140772405
INFO:root:current train perplexity8.631661415100098
INFO:root:current mean train loss 5471.739246355622
INFO:root:current train perplexity8.633618354797363

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.50s/it]
INFO:root:final mean train loss: 5460.919175178774
INFO:root:final train perplexity: 8.623495101928711
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.49s/it]
INFO:root:eval mean loss: 4711.501388658023
INFO:root:eval perplexity: 6.720703601837158
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.46s/it]
INFO:root:eval mean loss: 5565.860032967642
INFO:root:eval perplexity: 9.737227439880371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/138
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [16:12:42<7:15:43, 421.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5432.0625
INFO:root:current train perplexity8.717377662658691
INFO:root:current mean train loss 5397.9718835330705
INFO:root:current train perplexity8.398398399353027
INFO:root:current mean train loss 5414.957158732297
INFO:root:current train perplexity8.396580696105957
INFO:root:current mean train loss 5416.210447607261
INFO:root:current train perplexity8.429779052734375
INFO:root:current mean train loss 5417.033010478055
INFO:root:current train perplexity8.449577331542969
INFO:root:current mean train loss 5422.934912983039
INFO:root:current train perplexity8.460753440856934
INFO:root:current mean train loss 5425.641469572709
INFO:root:current train perplexity8.469488143920898
INFO:root:current mean train loss 5422.881807460215
INFO:root:current train perplexity8.470516204833984
INFO:root:current mean train loss 5419.816586847174
INFO:root:current train perplexity8.465909004211426
INFO:root:current mean train loss 5421.100110093093
INFO:root:current train perplexity8.463119506835938

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.88s/it]
INFO:root:final mean train loss: 5410.859162484446
INFO:root:final train perplexity: 8.454851150512695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.10s/it]
INFO:root:eval mean loss: 4682.68487159242
INFO:root:eval perplexity: 6.64284610748291
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.46s/it]
INFO:root:eval mean loss: 5538.347760139628
INFO:root:eval perplexity: 9.628299713134766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/139
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [16:19:45<7:09:03, 422.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5410.074174360795
INFO:root:current train perplexity8.532785415649414
INFO:root:current mean train loss 5393.758023648648
INFO:root:current train perplexity8.376531600952148
INFO:root:current mean train loss 5395.6572821016
INFO:root:current train perplexity8.346972465515137
INFO:root:current mean train loss 5387.812691544414
INFO:root:current train perplexity8.33777904510498
INFO:root:current mean train loss 5379.881783664082
INFO:root:current train perplexity8.332244873046875
INFO:root:current mean train loss 5374.763586831886
INFO:root:current train perplexity8.321288108825684
INFO:root:current mean train loss 5371.616360378734
INFO:root:current train perplexity8.312630653381348
INFO:root:current mean train loss 5371.562413469145
INFO:root:current train perplexity8.311352729797363
INFO:root:current mean train loss 5370.902422019498
INFO:root:current train perplexity8.303936958312988
INFO:root:current mean train loss 5366.411192842686
INFO:root:current train perplexity8.290289878845215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.75s/it]
INFO:root:final mean train loss: 5359.889882733745
INFO:root:final train perplexity: 8.28653335571289
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.48s/it]
INFO:root:eval mean loss: 4654.218992409131
INFO:root:eval perplexity: 6.566818714141846
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.52s/it]
INFO:root:eval mean loss: 5515.13203679078
INFO:root:eval perplexity: 9.53732681274414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/140
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [16:26:45<7:01:24, 421.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5357.0849609375
INFO:root:current train perplexity8.35496997833252
INFO:root:current mean train loss 5349.540112920168
INFO:root:current train perplexity8.263725280761719
INFO:root:current mean train loss 5334.4426436750855
INFO:root:current train perplexity8.235675811767578
INFO:root:current mean train loss 5348.800294499412
INFO:root:current train perplexity8.266411781311035
INFO:root:current mean train loss 5338.2628677841585
INFO:root:current train perplexity8.224349975585938
INFO:root:current mean train loss 5359.92808059369
INFO:root:current train perplexity8.262017250061035
INFO:root:current mean train loss 5359.049400810279
INFO:root:current train perplexity8.254136085510254
INFO:root:current mean train loss 5359.992713132388
INFO:root:current train perplexity8.259021759033203
INFO:root:current mean train loss 5364.424246055593
INFO:root:current train perplexity8.26977252960205
INFO:root:current mean train loss 5358.007247708957
INFO:root:current train perplexity8.261375427246094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.97s/it]
INFO:root:final mean train loss: 5350.63612451861
INFO:root:final train perplexity: 8.25633430480957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.85s/it]
INFO:root:eval mean loss: 4650.034688746676
INFO:root:eval perplexity: 6.5557169914245605
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it]
INFO:root:eval mean loss: 5511.249795683732
INFO:root:eval perplexity: 9.522194862365723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/141
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [16:33:48<6:54:39, 421.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5386.881202980324
INFO:root:current train perplexity8.228507995605469
INFO:root:current mean train loss 5353.7146246001475
INFO:root:current train perplexity8.242452621459961
INFO:root:current mean train loss 5350.014207478662
INFO:root:current train perplexity8.247251510620117
INFO:root:current mean train loss 5353.583215369362
INFO:root:current train perplexity8.248690605163574
INFO:root:current mean train loss 5341.077891722775
INFO:root:current train perplexity8.224095344543457
INFO:root:current mean train loss 5339.2683693815225
INFO:root:current train perplexity8.22472095489502
INFO:root:current mean train loss 5336.28462202203
INFO:root:current train perplexity8.225552558898926
INFO:root:current mean train loss 5339.996205242005
INFO:root:current train perplexity8.213512420654297
INFO:root:current mean train loss 5338.108514751171
INFO:root:current train perplexity8.207183837890625
INFO:root:current mean train loss 5341.255315786812
INFO:root:current train perplexity8.209551811218262

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.66s/it]
INFO:root:final mean train loss: 5334.327552303191
INFO:root:final train perplexity: 8.20338249206543
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.04s/it]
INFO:root:eval mean loss: 4637.769548564938
INFO:root:eval perplexity: 6.523282051086426
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it]
INFO:root:eval mean loss: 5500.850980718085
INFO:root:eval perplexity: 9.481795310974121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/142
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [16:40:47<6:46:59, 421.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5316.124609375
INFO:root:current train perplexity8.092705726623535
INFO:root:current mean train loss 5292.349616608796
INFO:root:current train perplexity8.087553977966309
INFO:root:current mean train loss 5325.01630028258
INFO:root:current train perplexity8.139366149902344
INFO:root:current mean train loss 5308.044219333023
INFO:root:current train perplexity8.133918762207031
INFO:root:current mean train loss 5311.506947063577
INFO:root:current train perplexity8.137152671813965
INFO:root:current mean train loss 5319.3849034389605
INFO:root:current train perplexity8.132426261901855
INFO:root:current mean train loss 5318.91513671875
INFO:root:current train perplexity8.141161918640137
INFO:root:current mean train loss 5322.050833731931
INFO:root:current train perplexity8.13776969909668
INFO:root:current mean train loss 5317.798675500561
INFO:root:current train perplexity8.138266563415527
INFO:root:current mean train loss 5320.603112988803
INFO:root:current train perplexity8.146202087402344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.39s/it]
INFO:root:final mean train loss: 5317.267064617527
INFO:root:final train perplexity: 8.14835262298584
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.02s/it]
INFO:root:eval mean loss: 4639.556495179521
INFO:root:eval perplexity: 6.527998924255371
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.44s/it]
INFO:root:eval mean loss: 5502.09462613586
INFO:root:eval perplexity: 9.486616134643555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/143
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [16:47:48<6:40:00, 421.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5288.628611010175
INFO:root:current train perplexity8.112196922302246
INFO:root:current mean train loss 5313.466086647727
INFO:root:current train perplexity8.145825386047363
INFO:root:current mean train loss 5317.876808449074
INFO:root:current train perplexity8.17066764831543
INFO:root:current mean train loss 5325.057289768586
INFO:root:current train perplexity8.189330101013184
INFO:root:current mean train loss 5331.6752852532445
INFO:root:current train perplexity8.193559646606445
INFO:root:current mean train loss 5336.126600627302
INFO:root:current train perplexity8.193512916564941
INFO:root:current mean train loss 5335.874644610226
INFO:root:current train perplexity8.190255165100098
INFO:root:current mean train loss 5334.776933015436
INFO:root:current train perplexity8.190808296203613
INFO:root:current mean train loss 5334.736359402803
INFO:root:current train perplexity8.192424774169922
INFO:root:current mean train loss 5339.083893242974
INFO:root:current train perplexity8.205133438110352

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.87s/it]
INFO:root:final mean train loss: 5337.311381678427
INFO:root:final train perplexity: 8.213046073913574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.32s/it]
INFO:root:eval mean loss: 4634.192559424867
INFO:root:eval perplexity: 6.513855457305908
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.19s/it]
INFO:root:eval mean loss: 5496.509613253546
INFO:root:eval perplexity: 9.464973449707031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/144
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [16:54:49<6:32:54, 420.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5328.381548713235
INFO:root:current train perplexity8.178321838378906
INFO:root:current mean train loss 5310.531861159975
INFO:root:current train perplexity8.129349708557129
INFO:root:current mean train loss 5318.050820156873
INFO:root:current train perplexity8.15565299987793
INFO:root:current mean train loss 5326.66338363604
INFO:root:current train perplexity8.172101974487305
INFO:root:current mean train loss 5323.143893561183
INFO:root:current train perplexity8.149965286254883
INFO:root:current mean train loss 5317.667021431204
INFO:root:current train perplexity8.133682250976562
INFO:root:current mean train loss 5316.726344986079
INFO:root:current train perplexity8.142910957336426
INFO:root:current mean train loss 5315.21621041736
INFO:root:current train perplexity8.14013671875
INFO:root:current mean train loss 5313.342123925896
INFO:root:current train perplexity8.131292343139648
INFO:root:current mean train loss 5317.785733356335
INFO:root:current train perplexity8.139793395996094

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.71s/it]
INFO:root:final mean train loss: 5316.654392857706
INFO:root:final train perplexity: 8.146384239196777
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.64s/it]
INFO:root:eval mean loss: 4627.593064328457
INFO:root:eval perplexity: 6.496494770050049
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.55s/it]
INFO:root:eval mean loss: 5490.995290336879
INFO:root:eval perplexity: 9.443658828735352
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/145
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [17:01:51<6:26:13, 421.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5376.900870630297
INFO:root:current train perplexity8.248516082763672
INFO:root:current mean train loss 5355.653839303262
INFO:root:current train perplexity8.245340347290039
INFO:root:current mean train loss 5344.079998944257
INFO:root:current train perplexity8.214851379394531
INFO:root:current mean train loss 5339.883551042392
INFO:root:current train perplexity8.204058647155762
INFO:root:current mean train loss 5334.93322461363
INFO:root:current train perplexity8.192769050598145
INFO:root:current mean train loss 5329.018213152673
INFO:root:current train perplexity8.18796157836914
INFO:root:current mean train loss 5332.611048789596
INFO:root:current train perplexity8.192612648010254
INFO:root:current mean train loss 5331.321451822917
INFO:root:current train perplexity8.18126392364502
INFO:root:current mean train loss 5329.101671070103
INFO:root:current train perplexity8.179156303405762
INFO:root:current mean train loss 5333.909218383407
INFO:root:current train perplexity8.192907333374023

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.21s/it]
INFO:root:final mean train loss: 5330.204125065958
INFO:root:final train perplexity: 8.190048217773438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.78s/it]
INFO:root:eval mean loss: 4622.090577903369
INFO:root:eval perplexity: 6.482055187225342
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.71s/it]
INFO:root:eval mean loss: 5487.260818373227
INFO:root:eval perplexity: 9.429247856140137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/146
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [17:08:53<6:19:22, 421.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5328.602152810168
INFO:root:current train perplexity8.314071655273438
INFO:root:current mean train loss 5331.615596931138
INFO:root:current train perplexity8.215415954589844
INFO:root:current mean train loss 5349.216952320342
INFO:root:current train perplexity8.205634117126465
INFO:root:current mean train loss 5349.171458563947
INFO:root:current train perplexity8.206304550170898
INFO:root:current mean train loss 5348.712459850107
INFO:root:current train perplexity8.205757141113281
INFO:root:current mean train loss 5342.9980718488205
INFO:root:current train perplexity8.199006080627441
INFO:root:current mean train loss 5337.666276968937
INFO:root:current train perplexity8.197547912597656
INFO:root:current mean train loss 5339.132275836253
INFO:root:current train perplexity8.197927474975586
INFO:root:current mean train loss 5340.5770324214245
INFO:root:current train perplexity8.208562850952148
INFO:root:current mean train loss 5341.1009171810365
INFO:root:current train perplexity8.210005760192871

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.70s/it]
INFO:root:final mean train loss: 5337.299318005962
INFO:root:final train perplexity: 8.213006973266602
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.83s/it]
INFO:root:eval mean loss: 4626.78748337766
INFO:root:eval perplexity: 6.49437952041626
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it]
INFO:root:eval mean loss: 5490.511452099956
INFO:root:eval perplexity: 9.441789627075195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/147
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [17:15:55<6:12:29, 421.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5392.35791015625
INFO:root:current train perplexity8.306984901428223
INFO:root:current mean train loss 5350.032991071429
INFO:root:current train perplexity8.259480476379395
INFO:root:current mean train loss 5355.479850852273
INFO:root:current train perplexity8.237286567687988
INFO:root:current mean train loss 5349.685576822917
INFO:root:current train perplexity8.221482276916504
INFO:root:current mean train loss 5356.862182360197
INFO:root:current train perplexity8.244457244873047
INFO:root:current mean train loss 5353.881804517663
INFO:root:current train perplexity8.239853858947754
INFO:root:current mean train loss 5349.914900173611
INFO:root:current train perplexity8.232595443725586
INFO:root:current mean train loss 5344.434624495968
INFO:root:current train perplexity8.222901344299316
INFO:root:current mean train loss 5340.642368861607
INFO:root:current train perplexity8.213433265686035
INFO:root:current mean train loss 5341.783164563301
INFO:root:current train perplexity8.213891983032227

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.26s/it]
INFO:root:final mean train loss: 5336.787421441847
INFO:root:final train perplexity: 8.211346626281738
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.57s/it]
INFO:root:eval mean loss: 4623.3693362837985
INFO:root:eval perplexity: 6.48540735244751
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.65s/it]
INFO:root:eval mean loss: 5487.873400099734
INFO:root:eval perplexity: 9.431609153747559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/148
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [17:22:57<6:05:30, 421.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5345.1001506024095
INFO:root:current train perplexity8.188693046569824
INFO:root:current mean train loss 5352.981616077527
INFO:root:current train perplexity8.225708961486816
INFO:root:current mean train loss 5357.375726383061
INFO:root:current train perplexity8.224944114685059
INFO:root:current mean train loss 5359.35880512606
INFO:root:current train perplexity8.239136695861816
INFO:root:current mean train loss 5356.959372573758
INFO:root:current train perplexity8.247692108154297
INFO:root:current mean train loss 5355.278850470358
INFO:root:current train perplexity8.239197731018066
INFO:root:current mean train loss 5352.388066349057
INFO:root:current train perplexity8.241377830505371
INFO:root:current mean train loss 5348.673599886255
INFO:root:current train perplexity8.232248306274414
INFO:root:current mean train loss 5350.691395743382
INFO:root:current train perplexity8.24006175994873
INFO:root:current mean train loss 5352.55416544141
INFO:root:current train perplexity8.24858283996582

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.50s/it]
INFO:root:final mean train loss: 5348.183967590332
INFO:root:final train perplexity: 8.24835205078125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.10s/it]
INFO:root:eval mean loss: 4632.270847185284
INFO:root:eval perplexity: 6.508794784545898
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.33s/it]
INFO:root:eval mean loss: 5497.994545794548
INFO:root:eval perplexity: 9.470725059509277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/149
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [17:29:59<5:58:35, 421.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5397.0494881095465
INFO:root:current train perplexity8.388687133789062
INFO:root:current mean train loss 5420.391115837696
INFO:root:current train perplexity8.378908157348633
INFO:root:current mean train loss 5417.343563748389
INFO:root:current train perplexity8.41053295135498
INFO:root:current mean train loss 5396.571958419917
INFO:root:current train perplexity8.388086318969727
INFO:root:current mean train loss 5389.219208447365
INFO:root:current train perplexity8.376667022705078
INFO:root:current mean train loss 5388.718135310914
INFO:root:current train perplexity8.375137329101562
INFO:root:current mean train loss 5380.968155017637
INFO:root:current train perplexity8.368926048278809
INFO:root:current mean train loss 5384.5231911988385
INFO:root:current train perplexity8.370506286621094
INFO:root:current mean train loss 5387.3769125719
INFO:root:current train perplexity8.365520477294922
INFO:root:current mean train loss 5386.234058183811
INFO:root:current train perplexity8.358895301818848

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.09s/it]
INFO:root:final mean train loss: 5381.974662042433
INFO:root:final train perplexity: 8.359048843383789
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.22s/it]
INFO:root:eval mean loss: 4638.314401180186
INFO:root:eval perplexity: 6.524720191955566
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.17s/it]
INFO:root:eval mean loss: 5503.161943151596
INFO:root:eval perplexity: 9.490760803222656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/150
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [17:37:00<5:51:18, 421.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5361.764702690973
INFO:root:current train perplexity8.341044425964355
INFO:root:current mean train loss 5355.217508440641
INFO:root:current train perplexity8.311652183532715
INFO:root:current mean train loss 5376.765024038462
INFO:root:current train perplexity8.340972900390625
INFO:root:current mean train loss 5388.513387962093
INFO:root:current train perplexity8.349249839782715
INFO:root:current mean train loss 5382.464968021982
INFO:root:current train perplexity8.345890045166016
INFO:root:current mean train loss 5380.620502758504
INFO:root:current train perplexity8.338858604431152
INFO:root:current mean train loss 5390.189832433611
INFO:root:current train perplexity8.358895301818848
INFO:root:current mean train loss 5395.241389383214
INFO:root:current train perplexity8.373526573181152
INFO:root:current mean train loss 5396.389047183503
INFO:root:current train perplexity8.379417419433594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.85s/it]
INFO:root:final mean train loss: 5391.209939402918
INFO:root:final train perplexity: 8.389562606811523
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.38s/it]
INFO:root:eval mean loss: 4647.950673204788
INFO:root:eval perplexity: 6.550195693969727
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it]
INFO:root:eval mean loss: 5513.492644614362
INFO:root:eval perplexity: 9.530935287475586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/151
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [17:44:01<5:44:11, 421.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5452.02734375
INFO:root:current train perplexity8.34683895111084
INFO:root:current mean train loss 5444.715920706775
INFO:root:current train perplexity8.476366996765137
INFO:root:current mean train loss 5427.11113941727
INFO:root:current train perplexity8.45188045501709
INFO:root:current mean train loss 5417.33768227046
INFO:root:current train perplexity8.444157600402832
INFO:root:current mean train loss 5410.061485046836
INFO:root:current train perplexity8.424439430236816
INFO:root:current mean train loss 5414.770609898916
INFO:root:current train perplexity8.425893783569336
INFO:root:current mean train loss 5410.565411990321
INFO:root:current train perplexity8.429234504699707
INFO:root:current mean train loss 5409.023209589374
INFO:root:current train perplexity8.429421424865723
INFO:root:current mean train loss 5406.790568487647
INFO:root:current train perplexity8.433195114135742
INFO:root:current mean train loss 5411.67981616507
INFO:root:current train perplexity8.435770988464355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.49s/it]
INFO:root:final mean train loss: 5404.383109431113
INFO:root:final train perplexity: 8.433277130126953
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.72s/it]
INFO:root:eval mean loss: 4656.0574578900705
INFO:root:eval perplexity: 6.5717034339904785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.13s/it]
INFO:root:eval mean loss: 5520.8046320921985
INFO:root:eval perplexity: 9.559477806091309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/152
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [17:51:02<5:36:57, 421.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5358.668815104166
INFO:root:current train perplexity8.41586685180664
INFO:root:current mean train loss 5404.666648267663
INFO:root:current train perplexity8.484539031982422
INFO:root:current mean train loss 5408.188733194041
INFO:root:current train perplexity8.438273429870605
INFO:root:current mean train loss 5409.500396825397
INFO:root:current train perplexity8.454197883605957
INFO:root:current mean train loss 5422.208847891567
INFO:root:current train perplexity8.484416007995605
INFO:root:current mean train loss 5421.007072967233
INFO:root:current train perplexity8.484726905822754
INFO:root:current mean train loss 5417.074516482469
INFO:root:current train perplexity8.476365089416504
INFO:root:current mean train loss 5413.742458615603
INFO:root:current train perplexity8.475281715393066
INFO:root:current mean train loss 5416.336410803297
INFO:root:current train perplexity8.47024154663086
INFO:root:current mean train loss 5419.902579619194
INFO:root:current train perplexity8.476815223693848

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.01s/it]
INFO:root:final mean train loss: 5416.685392564343
INFO:root:final train perplexity: 8.474309921264648
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.80s/it]
INFO:root:eval mean loss: 4644.666749778369
INFO:root:eval perplexity: 6.541501998901367
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.68s/it]
INFO:root:eval mean loss: 5508.833322944371
INFO:root:eval perplexity: 9.51279354095459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/153
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [17:58:03<5:29:52, 421.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5422.247877038043
INFO:root:current train perplexity8.197044372558594
INFO:root:current mean train loss 5409.4921676511685
INFO:root:current train perplexity8.390158653259277
INFO:root:current mean train loss 5421.101636946469
INFO:root:current train perplexity8.454469680786133
INFO:root:current mean train loss 5417.333022929566
INFO:root:current train perplexity8.456006050109863
INFO:root:current mean train loss 5414.077566304669
INFO:root:current train perplexity8.460162162780762
INFO:root:current mean train loss 5409.852639893045
INFO:root:current train perplexity8.46936321258545
INFO:root:current mean train loss 5414.480003981491
INFO:root:current train perplexity8.472707748413086
INFO:root:current mean train loss 5408.787472715681
INFO:root:current train perplexity8.459049224853516
INFO:root:current mean train loss 5410.681331518644
INFO:root:current train perplexity8.465157508850098
INFO:root:current mean train loss 5417.150086970139
INFO:root:current train perplexity8.467065811157227

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.93s/it]
INFO:root:final mean train loss: 5415.633792508033
INFO:root:final train perplexity: 8.470792770385742
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.38s/it]
INFO:root:eval mean loss: 4640.513536818484
INFO:root:eval perplexity: 6.530525207519531
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it]
INFO:root:eval mean loss: 5507.566697140957
INFO:root:eval perplexity: 9.507866859436035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/154
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [18:05:05<5:23:05, 421.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5445.656927293347
INFO:root:current train perplexity8.460799217224121
INFO:root:current mean train loss 5411.68152135019
INFO:root:current train perplexity8.408955574035645
INFO:root:current mean train loss 5406.925861573322
INFO:root:current train perplexity8.430573463439941
INFO:root:current mean train loss 5396.884317173339
INFO:root:current train perplexity8.41259479522705
INFO:root:current mean train loss 5401.076898065908
INFO:root:current train perplexity8.440574645996094
INFO:root:current mean train loss 5402.717778035252
INFO:root:current train perplexity8.438788414001465
INFO:root:current mean train loss 5402.6133539892035
INFO:root:current train perplexity8.440423965454102
INFO:root:current mean train loss 5406.369133945366
INFO:root:current train perplexity8.436601638793945
INFO:root:current mean train loss 5412.682682996766
INFO:root:current train perplexity8.441545486450195
INFO:root:current mean train loss 5411.296015394233
INFO:root:current train perplexity8.44221305847168

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.17s/it]
INFO:root:final mean train loss: 5408.124164581299
INFO:root:final train perplexity: 8.445734024047852
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.46s/it]
INFO:root:eval mean loss: 4643.298201324246
INFO:root:eval perplexity: 6.537882328033447
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.67s/it]
INFO:root:eval mean loss: 5509.112394725177
INFO:root:eval perplexity: 9.513877868652344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/155
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [18:12:07<5:16:06, 421.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5453.275553385417
INFO:root:current train perplexity8.538433074951172
INFO:root:current mean train loss 5411.173515484487
INFO:root:current train perplexity8.437027931213379
INFO:root:current mean train loss 5414.368682989017
INFO:root:current train perplexity8.443455696105957
INFO:root:current mean train loss 5412.315611172567
INFO:root:current train perplexity8.438961029052734
INFO:root:current mean train loss 5412.642647084995
INFO:root:current train perplexity8.451563835144043
INFO:root:current mean train loss 5412.656338778409
INFO:root:current train perplexity8.456768035888672
INFO:root:current mean train loss 5416.323239130967
INFO:root:current train perplexity8.466039657592773
INFO:root:current mean train loss 5422.485196951116
INFO:root:current train perplexity8.46937084197998
INFO:root:current mean train loss 5418.549392645635
INFO:root:current train perplexity8.46184253692627
INFO:root:current mean train loss 5416.188009081303
INFO:root:current train perplexity8.458470344543457

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.94s/it]
INFO:root:final mean train loss: 5413.706656548285
INFO:root:final train perplexity: 8.464356422424316
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.65s/it]
INFO:root:eval mean loss: 4650.664429576685
INFO:root:eval perplexity: 6.557387351989746
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.24s/it]
INFO:root:eval mean loss: 5515.558659546764
INFO:root:eval perplexity: 9.538991928100586
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/156
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [18:19:06<5:08:35, 420.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5389.258331948138
INFO:root:current train perplexity8.41832160949707
INFO:root:current mean train loss 5403.65438323767
INFO:root:current train perplexity8.422334671020508
INFO:root:current mean train loss 5388.644214954454
INFO:root:current train perplexity8.382356643676758
INFO:root:current mean train loss 5390.032042225775
INFO:root:current train perplexity8.392053604125977
INFO:root:current mean train loss 5393.745712519225
INFO:root:current train perplexity8.37464427947998
INFO:root:current mean train loss 5383.9456401036905
INFO:root:current train perplexity8.354616165161133
INFO:root:current mean train loss 5383.219755240533
INFO:root:current train perplexity8.365522384643555
INFO:root:current mean train loss 5384.466417100694
INFO:root:current train perplexity8.371330261230469
INFO:root:current mean train loss 5390.930115827
INFO:root:current train perplexity8.378384590148926
INFO:root:current mean train loss 5390.590508884966
INFO:root:current train perplexity8.380680084228516

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.01s/it]
INFO:root:final mean train loss: 5387.349780051939
INFO:root:final train perplexity: 8.376792907714844
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.63s/it]
INFO:root:eval mean loss: 4641.934689785572
INFO:root:eval perplexity: 6.534280300140381
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.83s/it]
INFO:root:eval mean loss: 5506.924413369902
INFO:root:eval perplexity: 9.50537109375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/157
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [18:26:08<5:01:47, 421.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5428.84208984375
INFO:root:current train perplexity8.386239051818848
INFO:root:current mean train loss 5417.847139616935
INFO:root:current train perplexity8.428092956542969
INFO:root:current mean train loss 5421.6631395526965
INFO:root:current train perplexity8.471463203430176
INFO:root:current mean train loss 5402.0064411861795
INFO:root:current train perplexity8.4381103515625
INFO:root:current mean train loss 5399.84151356456
INFO:root:current train perplexity8.428567886352539
INFO:root:current mean train loss 5402.115441124718
INFO:root:current train perplexity8.427637100219727
INFO:root:current mean train loss 5403.738659202051
INFO:root:current train perplexity8.421958923339844
INFO:root:current mean train loss 5408.206511925704
INFO:root:current train perplexity8.430887222290039
INFO:root:current mean train loss 5408.111709612573
INFO:root:current train perplexity8.423203468322754
INFO:root:current mean train loss 5406.034292171139
INFO:root:current train perplexity8.418383598327637

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.41s/it]
INFO:root:final mean train loss: 5398.446445711197
INFO:root:final train perplexity: 8.413549423217773
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.57s/it]
INFO:root:eval mean loss: 4641.367966672207
INFO:root:eval perplexity: 6.532782554626465
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it]
INFO:root:eval mean loss: 5509.02273451352
INFO:root:eval perplexity: 9.513530731201172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/158
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [18:33:14<4:55:46, 422.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5371.989172557043
INFO:root:current train perplexity8.377891540527344
INFO:root:current mean train loss 5392.2158742331285
INFO:root:current train perplexity8.381797790527344
INFO:root:current mean train loss 5399.012656324263
INFO:root:current train perplexity8.379192352294922
INFO:root:current mean train loss 5406.055329125775
INFO:root:current train perplexity8.395467758178711
INFO:root:current mean train loss 5399.419314423596
INFO:root:current train perplexity8.388762474060059
INFO:root:current mean train loss 5401.29439803508
INFO:root:current train perplexity8.403708457946777
INFO:root:current mean train loss 5402.784832938584
INFO:root:current train perplexity8.397804260253906
INFO:root:current mean train loss 5398.666887875778
INFO:root:current train perplexity8.386510848999023
INFO:root:current mean train loss 5399.473029109031
INFO:root:current train perplexity8.389278411865234
INFO:root:current mean train loss 5395.574876890252
INFO:root:current train perplexity8.383975982666016

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.94s/it]
INFO:root:final mean train loss: 5387.511456274217
INFO:root:final train perplexity: 8.377327919006348
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it]
INFO:root:eval mean loss: 4637.904033687943
INFO:root:eval perplexity: 6.52363920211792
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.07s/it]
INFO:root:eval mean loss: 5503.62297415226
INFO:root:eval perplexity: 9.492546081542969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/159
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [18:40:13<4:48:00, 421.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5365.137681558099
INFO:root:current train perplexity8.313138008117676
INFO:root:current mean train loss 5358.992236042581
INFO:root:current train perplexity8.2868013381958
INFO:root:current mean train loss 5380.343591443727
INFO:root:current train perplexity8.314411163330078
INFO:root:current mean train loss 5362.950042642352
INFO:root:current train perplexity8.304651260375977
INFO:root:current mean train loss 5365.2348477308915
INFO:root:current train perplexity8.306378364562988
INFO:root:current mean train loss 5364.212259536449
INFO:root:current train perplexity8.313992500305176
INFO:root:current mean train loss 5360.763044604601
INFO:root:current train perplexity8.298234939575195
INFO:root:current mean train loss 5363.173838891254
INFO:root:current train perplexity8.310433387756348
INFO:root:current mean train loss 5368.802689527124
INFO:root:current train perplexity8.311001777648926
INFO:root:current mean train loss 5373.122610891639
INFO:root:current train perplexity8.317097663879395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.18s/it]
INFO:root:final mean train loss: 5370.608029519358
INFO:root:final train perplexity: 8.321649551391602
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.10s/it]
INFO:root:eval mean loss: 4632.460267411901
INFO:root:eval perplexity: 6.509293556213379
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it]
INFO:root:eval mean loss: 5498.017900182846
INFO:root:eval perplexity: 9.470817565917969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/160
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [18:47:14<4:40:57, 421.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5377.056652986551
INFO:root:current train perplexity8.280268669128418
INFO:root:current mean train loss 5354.261044976432
INFO:root:current train perplexity8.225964546203613
INFO:root:current mean train loss 5347.463571418571
INFO:root:current train perplexity8.256905555725098
INFO:root:current mean train loss 5359.2312456196405
INFO:root:current train perplexity8.27913761138916
INFO:root:current mean train loss 5365.722343301474
INFO:root:current train perplexity8.283238410949707
INFO:root:current mean train loss 5359.048244548791
INFO:root:current train perplexity8.26785659790039
INFO:root:current mean train loss 5359.213693160898
INFO:root:current train perplexity8.274409294128418
INFO:root:current mean train loss 5360.059217421173
INFO:root:current train perplexity8.276277542114258
INFO:root:current mean train loss 5363.5608773953
INFO:root:current train perplexity8.28673267364502
INFO:root:current mean train loss 5363.437412717856
INFO:root:current train perplexity8.282975196838379

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 362.00s/it]
INFO:root:final mean train loss: 5358.392954180317
INFO:root:final train perplexity: 8.281641006469727
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.81s/it]
INFO:root:eval mean loss: 4629.302682430186
INFO:root:eval perplexity: 6.500986576080322
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.86s/it]
INFO:root:eval mean loss: 5497.172560671543
INFO:root:eval perplexity: 9.467543601989746
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/161
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [18:54:18<4:34:25, 422.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5394.133356905531
INFO:root:current train perplexity8.259925842285156
INFO:root:current mean train loss 5377.957806755515
INFO:root:current train perplexity8.283761978149414
INFO:root:current mean train loss 5373.210493453288
INFO:root:current train perplexity8.284796714782715
INFO:root:current mean train loss 5357.636641785772
INFO:root:current train perplexity8.26749324798584
INFO:root:current mean train loss 5353.789647033816
INFO:root:current train perplexity8.25550365447998
INFO:root:current mean train loss 5349.948708009476
INFO:root:current train perplexity8.245023727416992
INFO:root:current mean train loss 5346.727238417713
INFO:root:current train perplexity8.242704391479492
INFO:root:current mean train loss 5354.194804985308
INFO:root:current train perplexity8.253837585449219
INFO:root:current mean train loss 5353.525742936161
INFO:root:current train perplexity8.25045108795166
INFO:root:current mean train loss 5352.318221844921
INFO:root:current train perplexity8.247973442077637

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.81s/it]
INFO:root:final mean train loss: 5347.923922261884
INFO:root:final train perplexity: 8.247507095336914
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.61s/it]
INFO:root:eval mean loss: 4624.333577473958
INFO:root:eval perplexity: 6.4879374504089355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.83s/it]
INFO:root:eval mean loss: 5492.860389655363
INFO:root:eval perplexity: 9.4508638381958
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/162
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [19:01:21<4:27:39, 422.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5340.310557154606
INFO:root:current train perplexity8.255016326904297
INFO:root:current mean train loss 5346.014508213141
INFO:root:current train perplexity8.258076667785645
INFO:root:current mean train loss 5360.147782044492
INFO:root:current train perplexity8.295568466186523
INFO:root:current mean train loss 5374.842491594146
INFO:root:current train perplexity8.319401741027832
INFO:root:current mean train loss 5377.51884469697
INFO:root:current train perplexity8.336499214172363
INFO:root:current mean train loss 5379.654726070115
INFO:root:current train perplexity8.32802677154541
INFO:root:current mean train loss 5383.16566083071
INFO:root:current train perplexity8.322690963745117
INFO:root:current mean train loss 5377.3433599891905
INFO:root:current train perplexity8.321030616760254
INFO:root:current mean train loss 5378.99516847067
INFO:root:current train perplexity8.331342697143555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.77s/it]
INFO:root:final mean train loss: 5377.040273358745
INFO:root:final train perplexity: 8.342792510986328
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.75s/it]
INFO:root:eval mean loss: 4632.495181252771
INFO:root:eval perplexity: 6.509385108947754
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it]
INFO:root:eval mean loss: 5499.537535322474
INFO:root:eval perplexity: 9.476700782775879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/163
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [19:08:22<4:20:11, 421.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5390.50048828125
INFO:root:current train perplexity8.305896759033203
INFO:root:current mean train loss 5387.051520782767
INFO:root:current train perplexity8.318764686584473
INFO:root:current mean train loss 5379.989296297722
INFO:root:current train perplexity8.306602478027344
INFO:root:current mean train loss 5388.128219755569
INFO:root:current train perplexity8.334251403808594
INFO:root:current mean train loss 5390.1440175248135
INFO:root:current train perplexity8.349739074707031
INFO:root:current mean train loss 5382.061070102821
INFO:root:current train perplexity8.352546691894531
INFO:root:current mean train loss 5385.35040536251
INFO:root:current train perplexity8.349958419799805
INFO:root:current mean train loss 5390.2868391880775
INFO:root:current train perplexity8.363716125488281
INFO:root:current mean train loss 5387.772037719878
INFO:root:current train perplexity8.357195854187012
INFO:root:current mean train loss 5387.898383426772
INFO:root:current train perplexity8.3622465133667

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.27s/it]
INFO:root:final mean train loss: 5384.912300109863
INFO:root:final train perplexity: 8.368741989135742
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.41s/it]
INFO:root:eval mean loss: 4637.072206754211
INFO:root:eval perplexity: 6.5214433670043945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.52s/it]
INFO:root:eval mean loss: 5501.21270362367
INFO:root:eval perplexity: 9.483197212219238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/164
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [19:15:23<4:13:04, 421.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5431.541725852273
INFO:root:current train perplexity8.28533935546875
INFO:root:current mean train loss 5374.171501090935
INFO:root:current train perplexity8.35407829284668
INFO:root:current mean train loss 5373.420026010812
INFO:root:current train perplexity8.32844352722168
INFO:root:current mean train loss 5370.793073942424
INFO:root:current train perplexity8.318628311157227
INFO:root:current mean train loss 5376.415053318887
INFO:root:current train perplexity8.336352348327637
INFO:root:current mean train loss 5377.992573538405
INFO:root:current train perplexity8.346357345581055
INFO:root:current mean train loss 5382.684986670161
INFO:root:current train perplexity8.360031127929688
INFO:root:current mean train loss 5382.379288084564
INFO:root:current train perplexity8.350910186767578
INFO:root:current mean train loss 5385.2606205687425
INFO:root:current train perplexity8.34719181060791
INFO:root:current mean train loss 5386.324694703622
INFO:root:current train perplexity8.351999282836914

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.54s/it]
INFO:root:final mean train loss: 5381.910375779675
INFO:root:final train perplexity: 8.358839988708496
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it]
INFO:root:eval mean loss: 4627.801274725732
INFO:root:eval perplexity: 6.497042655944824
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.12s/it]
INFO:root:eval mean loss: 5494.196950493129
INFO:root:eval perplexity: 9.456031799316406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/165
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [19:22:25<4:06:01, 421.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5372.450632195723
INFO:root:current train perplexity8.444615364074707
INFO:root:current mean train loss 5446.749384519433
INFO:root:current train perplexity8.529143333435059
INFO:root:current mean train loss 5424.439339415668
INFO:root:current train perplexity8.440816879272461
INFO:root:current mean train loss 5412.9960172168885
INFO:root:current train perplexity8.440140724182129
INFO:root:current mean train loss 5403.694180946077
INFO:root:current train perplexity8.430832862854004
INFO:root:current mean train loss 5402.320933435693
INFO:root:current train perplexity8.411765098571777
INFO:root:current mean train loss 5394.8998139956075
INFO:root:current train perplexity8.405247688293457
INFO:root:current mean train loss 5393.769985575669
INFO:root:current train perplexity8.398544311523438
INFO:root:current mean train loss 5395.063648861988
INFO:root:current train perplexity8.40292739868164
INFO:root:current mean train loss 5402.334661274143
INFO:root:current train perplexity8.411373138427734

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.95s/it]
INFO:root:final mean train loss: 5397.618802101381
INFO:root:final train perplexity: 8.410801887512207
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.38s/it]
INFO:root:eval mean loss: 4634.716511178524
INFO:root:eval perplexity: 6.515235424041748
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.83s/it]
INFO:root:eval mean loss: 5502.34313358821
INFO:root:eval perplexity: 9.487579345703125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/166
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [19:29:27<3:59:07, 421.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5309.974537037037
INFO:root:current train perplexity8.286718368530273
INFO:root:current mean train loss 5370.10842535064
INFO:root:current train perplexity8.364531517028809
INFO:root:current mean train loss 5389.289690597467
INFO:root:current train perplexity8.40624713897705
INFO:root:current mean train loss 5396.045157802943
INFO:root:current train perplexity8.431230545043945
INFO:root:current mean train loss 5405.841600190281
INFO:root:current train perplexity8.439136505126953
INFO:root:current mean train loss 5413.814238170066
INFO:root:current train perplexity8.450638771057129
INFO:root:current mean train loss 5410.981154057017
INFO:root:current train perplexity8.441197395324707
INFO:root:current mean train loss 5412.875429848693
INFO:root:current train perplexity8.438576698303223
INFO:root:current mean train loss 5413.424543719771
INFO:root:current train perplexity8.447065353393555
INFO:root:current mean train loss 5411.595252241775
INFO:root:current train perplexity8.43821907043457

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.66s/it]
INFO:root:final mean train loss: 5405.63578414917
INFO:root:final train perplexity: 8.437448501586914
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.57s/it]
INFO:root:eval mean loss: 4630.061433399823
INFO:root:eval perplexity: 6.502981662750244
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.27s/it]
INFO:root:eval mean loss: 5495.364437887854
INFO:root:eval perplexity: 9.46054458618164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/167
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [19:36:30<3:52:14, 422.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5411.99638671875
INFO:root:current train perplexity8.446934700012207
INFO:root:current mean train loss 5372.975868055555
INFO:root:current train perplexity8.38830280303955
INFO:root:current mean train loss 5390.616769863696
INFO:root:current train perplexity8.39344596862793
INFO:root:current mean train loss 5400.778575384795
INFO:root:current train perplexity8.409370422363281
INFO:root:current mean train loss 5403.022361036279
INFO:root:current train perplexity8.408133506774902
INFO:root:current mean train loss 5407.556420670268
INFO:root:current train perplexity8.420531272888184
INFO:root:current mean train loss 5405.695274052658
INFO:root:current train perplexity8.425124168395996
INFO:root:current mean train loss 5407.807714179422
INFO:root:current train perplexity8.425093650817871
INFO:root:current mean train loss 5410.977040840195
INFO:root:current train perplexity8.433323860168457
INFO:root:current mean train loss 5407.421045182988
INFO:root:current train perplexity8.42827033996582

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.16s/it]
INFO:root:final mean train loss: 5402.57998435728
INFO:root:final train perplexity: 8.427279472351074
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.36s/it]
INFO:root:eval mean loss: 4627.730002978169
INFO:root:eval perplexity: 6.49685525894165
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.78s/it]
INFO:root:eval mean loss: 5492.516850897607
INFO:root:eval perplexity: 9.449536323547363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/168
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [19:43:33<3:45:15, 422.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5473.831406704215
INFO:root:current train perplexity8.583279609680176
INFO:root:current mean train loss 5431.052519258085
INFO:root:current train perplexity8.454071044921875
INFO:root:current mean train loss 5414.3260774337705
INFO:root:current train perplexity8.427878379821777
INFO:root:current mean train loss 5405.523531454993
INFO:root:current train perplexity8.400763511657715
INFO:root:current mean train loss 5413.827875899407
INFO:root:current train perplexity8.422075271606445
INFO:root:current mean train loss 5415.1159132927605
INFO:root:current train perplexity8.430217742919922
INFO:root:current mean train loss 5409.564403765309
INFO:root:current train perplexity8.432641983032227
INFO:root:current mean train loss 5408.4418636440105
INFO:root:current train perplexity8.437104225158691
INFO:root:current mean train loss 5411.553574241919
INFO:root:current train perplexity8.445289611816406
INFO:root:current mean train loss 5410.855144092159
INFO:root:current train perplexity8.442511558532715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.24s/it]
INFO:root:final mean train loss: 5407.646543195171
INFO:root:final train perplexity: 8.444144248962402
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.88s/it]
INFO:root:eval mean loss: 4627.772507687832
INFO:root:eval perplexity: 6.4969658851623535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.69s/it]
INFO:root:eval mean loss: 5491.451379654255
INFO:root:eval perplexity: 9.445419311523438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/169
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [19:50:36<3:38:20, 422.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5458.379432827819
INFO:root:current train perplexity8.529301643371582
INFO:root:current mean train loss 5446.022457703849
INFO:root:current train perplexity8.541071891784668
INFO:root:current mean train loss 5449.388771087525
INFO:root:current train perplexity8.504486083984375
INFO:root:current mean train loss 5437.803599648326
INFO:root:current train perplexity8.481375694274902
INFO:root:current mean train loss 5429.1873765763585
INFO:root:current train perplexity8.486763000488281
INFO:root:current mean train loss 5426.288839184437
INFO:root:current train perplexity8.47887134552002
INFO:root:current mean train loss 5423.691604262673
INFO:root:current train perplexity8.480334281921387
INFO:root:current mean train loss 5429.05785580164
INFO:root:current train perplexity8.494781494140625
INFO:root:current mean train loss 5428.893868541605
INFO:root:current train perplexity8.491172790527344
INFO:root:current mean train loss 5426.154236802543
INFO:root:current train perplexity8.491559028625488

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.38s/it]
INFO:root:final mean train loss: 5420.66843709638
INFO:root:final train perplexity: 8.48763656616211
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.82s/it]
INFO:root:eval mean loss: 4636.41014239805
INFO:root:eval perplexity: 6.519698143005371
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.43s/it]
INFO:root:eval mean loss: 5501.253895861038
INFO:root:eval perplexity: 9.483355522155762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/170
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [19:57:37<3:31:02, 422.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5412.729997020657
INFO:root:current train perplexity8.426966667175293
INFO:root:current mean train loss 5406.774165315448
INFO:root:current train perplexity8.436650276184082
INFO:root:current mean train loss 5410.915582016168
INFO:root:current train perplexity8.448616027832031
INFO:root:current mean train loss 5422.258557842966
INFO:root:current train perplexity8.45910930633545
INFO:root:current mean train loss 5429.245359732435
INFO:root:current train perplexity8.473804473876953
INFO:root:current mean train loss 5433.994640261628
INFO:root:current train perplexity8.489921569824219
INFO:root:current mean train loss 5428.12343142427
INFO:root:current train perplexity8.49182415008545
INFO:root:current mean train loss 5432.545774276392
INFO:root:current train perplexity8.513864517211914
INFO:root:current mean train loss 5438.104073823123
INFO:root:current train perplexity8.525613784790039
INFO:root:current mean train loss 5441.326152017889
INFO:root:current train perplexity8.538662910461426

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.38s/it]
INFO:root:final mean train loss: 5436.757869843514
INFO:root:final train perplexity: 8.541685104370117
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.24s/it]
INFO:root:eval mean loss: 4654.22648977726
INFO:root:eval perplexity: 6.566838264465332
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.33s/it]
INFO:root:eval mean loss: 5514.2260776817375
INFO:root:eval perplexity: 9.533794403076172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/171
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [20:04:41<3:24:19, 422.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5405.614600338153
INFO:root:current train perplexity8.501394271850586
INFO:root:current mean train loss 5437.671722960329
INFO:root:current train perplexity8.559714317321777
INFO:root:current mean train loss 5459.659892907303
INFO:root:current train perplexity8.60577392578125
INFO:root:current mean train loss 5476.664039882067
INFO:root:current train perplexity8.633630752563477
INFO:root:current mean train loss 5465.774565670169
INFO:root:current train perplexity8.61213493347168
INFO:root:current mean train loss 5474.94580078125
INFO:root:current train perplexity8.627357482910156
INFO:root:current mean train loss 5478.885684355088
INFO:root:current train perplexity8.642770767211914
INFO:root:current mean train loss 5477.563066584501
INFO:root:current train perplexity8.648268699645996
INFO:root:current mean train loss 5470.547584049705
INFO:root:current train perplexity8.644850730895996
INFO:root:current mean train loss 5475.760107977314
INFO:root:current train perplexity8.664690971374512

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.12s/it]
INFO:root:final mean train loss: 5473.72825167256
INFO:root:final train perplexity: 8.667186737060547
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.76s/it]
INFO:root:eval mean loss: 4645.338926058289
INFO:root:eval perplexity: 6.543281078338623
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.80s/it]
INFO:root:eval mean loss: 5506.704395916445
INFO:root:eval perplexity: 9.5045166015625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/172
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [20:11:44<3:17:19, 422.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5501.246673177084
INFO:root:current train perplexity8.637096405029297
INFO:root:current mean train loss 5478.5742578125
INFO:root:current train perplexity8.657106399536133
INFO:root:current mean train loss 5491.360404829546
INFO:root:current train perplexity8.709380149841309
INFO:root:current mean train loss 5496.82294921875
INFO:root:current train perplexity8.71110725402832
INFO:root:current mean train loss 5500.5497841282895
INFO:root:current train perplexity8.722284317016602
INFO:root:current mean train loss 5508.242770040761
INFO:root:current train perplexity8.752888679504395
INFO:root:current mean train loss 5500.744208622686
INFO:root:current train perplexity8.747722625732422
INFO:root:current mean train loss 5501.549868951613
INFO:root:current train perplexity8.754864692687988
INFO:root:current mean train loss 5508.355256696429
INFO:root:current train perplexity8.768769264221191
INFO:root:current mean train loss 5508.602647235577
INFO:root:current train perplexity8.776976585388184

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.78s/it]
INFO:root:final mean train loss: 5506.358213855374
INFO:root:final train perplexity: 8.779483795166016
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.69s/it]
INFO:root:eval mean loss: 4655.678719594969
INFO:root:eval perplexity: 6.57069730758667
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it]
INFO:root:eval mean loss: 5512.855915475399
INFO:root:eval perplexity: 9.528456687927246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/173
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [20:18:48<3:10:22, 423.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5616.011354009789
INFO:root:current train perplexity8.949786186218262
INFO:root:current mean train loss 5589.014907253245
INFO:root:current train perplexity8.937949180603027
INFO:root:current mean train loss 5569.523943035005
INFO:root:current train perplexity8.925183296203613
INFO:root:current mean train loss 5560.471612118554
INFO:root:current train perplexity8.907243728637695
INFO:root:current mean train loss 5558.5737567530405
INFO:root:current train perplexity8.900798797607422
INFO:root:current mean train loss 5558.145640142581
INFO:root:current train perplexity8.89385986328125
INFO:root:current mean train loss 5548.857108745882
INFO:root:current train perplexity8.879484176635742
INFO:root:current mean train loss 5542.344247011693
INFO:root:current train perplexity8.876188278198242
INFO:root:current mean train loss 5542.624991705302
INFO:root:current train perplexity8.868474006652832
INFO:root:current mean train loss 5538.915532807731
INFO:root:current train perplexity8.873080253601074

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.52s/it]
INFO:root:final mean train loss: 5533.915436037125
INFO:root:final train perplexity: 8.875456809997559
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.78s/it]
INFO:root:eval mean loss: 4658.420299340647
INFO:root:eval perplexity: 6.57798433303833
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.07s/it]
INFO:root:eval mean loss: 5516.443110039893
INFO:root:eval perplexity: 9.542440414428711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/174
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [20:25:51<3:03:17, 422.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5530.840594951923
INFO:root:current train perplexity8.849610328674316
INFO:root:current mean train loss 5549.012355305137
INFO:root:current train perplexity8.878745079040527
INFO:root:current mean train loss 5518.845481636598
INFO:root:current train perplexity8.82650375366211
INFO:root:current mean train loss 5528.970601972107
INFO:root:current train perplexity8.848912239074707
INFO:root:current mean train loss 5527.998233834012
INFO:root:current train perplexity8.85299301147461
INFO:root:current mean train loss 5525.466975333122
INFO:root:current train perplexity8.855562210083008
INFO:root:current mean train loss 5522.462265257553
INFO:root:current train perplexity8.836540222167969
INFO:root:current mean train loss 5531.087305428256
INFO:root:current train perplexity8.84219741821289
INFO:root:current mean train loss 5530.30759581492
INFO:root:current train perplexity8.84591293334961
INFO:root:current mean train loss 5529.909130415931
INFO:root:current train perplexity8.846287727355957

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.16s/it]
INFO:root:final mean train loss: 5525.711369668284
INFO:root:final train perplexity: 8.84677505493164
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.84s/it]
INFO:root:eval mean loss: 4662.609381925975
INFO:root:eval perplexity: 6.589136600494385
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.16s/it]
INFO:root:eval mean loss: 5519.029639710771
INFO:root:eval perplexity: 9.552539825439453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/175
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [20:32:51<2:55:55, 422.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5573.698848839962
INFO:root:current train perplexity8.949506759643555
INFO:root:current mean train loss 5551.340035136621
INFO:root:current train perplexity8.909172058105469
INFO:root:current mean train loss 5562.660306490385
INFO:root:current train perplexity8.940530776977539
INFO:root:current mean train loss 5563.218430597979
INFO:root:current train perplexity8.94874095916748
INFO:root:current mean train loss 5567.399687069452
INFO:root:current train perplexity8.955194473266602
INFO:root:current mean train loss 5567.3745728558015
INFO:root:current train perplexity8.9505033493042
INFO:root:current mean train loss 5562.613301507734
INFO:root:current train perplexity8.93642807006836
INFO:root:current mean train loss 5556.375255446261
INFO:root:current train perplexity8.931304931640625
INFO:root:current mean train loss 5552.356055882404
INFO:root:current train perplexity8.918731689453125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.36s/it]
INFO:root:final mean train loss: 5544.663859705771
INFO:root:final train perplexity: 8.91317081451416
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.98s/it]
INFO:root:eval mean loss: 4666.8276332557625
INFO:root:eval perplexity: 6.60038423538208
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.31s/it]
INFO:root:eval mean loss: 5524.961384225399
INFO:root:eval perplexity: 9.575739860534668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/176
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [20:39:52<2:48:44, 421.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5669.019740513393
INFO:root:current train perplexity9.14404010772705
INFO:root:current mean train loss 5569.532039464077
INFO:root:current train perplexity8.957825660705566
INFO:root:current mean train loss 5555.851852638134
INFO:root:current train perplexity8.929819107055664
INFO:root:current mean train loss 5551.457788324511
INFO:root:current train perplexity8.940472602844238
INFO:root:current mean train loss 5551.492710572788
INFO:root:current train perplexity8.93691635131836
INFO:root:current mean train loss 5541.48974609375
INFO:root:current train perplexity8.91961669921875
INFO:root:current mean train loss 5551.637779776308
INFO:root:current train perplexity8.946413040161133
INFO:root:current mean train loss 5549.960494110237
INFO:root:current train perplexity8.922370910644531
INFO:root:current mean train loss 5551.698218590265
INFO:root:current train perplexity8.91374683380127
INFO:root:current mean train loss 5548.002644363286
INFO:root:current train perplexity8.908543586730957

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.82s/it]
INFO:root:final mean train loss: 5541.90846190914
INFO:root:final train perplexity: 8.903488159179688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.64s/it]
INFO:root:eval mean loss: 4661.716355344082
INFO:root:eval perplexity: 6.586758136749268
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.56s/it]
INFO:root:eval mean loss: 5515.185910488697
INFO:root:eval perplexity: 9.53753662109375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/177
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [20:46:54<2:41:45, 421.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5624.33837890625
INFO:root:current train perplexity9.094258308410645
INFO:root:current mean train loss 5540.902267323369
INFO:root:current train perplexity8.898344039916992
INFO:root:current mean train loss 5527.117759811046
INFO:root:current train perplexity8.870840072631836
INFO:root:current mean train loss 5546.478931051587
INFO:root:current train perplexity8.896017074584961
INFO:root:current mean train loss 5554.394015907379
INFO:root:current train perplexity8.906965255737305
INFO:root:current mean train loss 5550.706997117719
INFO:root:current train perplexity8.908995628356934
INFO:root:current mean train loss 5546.07891339558
INFO:root:current train perplexity8.914335250854492
INFO:root:current mean train loss 5545.021984265734
INFO:root:current train perplexity8.904681205749512
INFO:root:current mean train loss 5541.564810798504
INFO:root:current train perplexity8.890151977539062
INFO:root:current mean train loss 5545.416056715335
INFO:root:current train perplexity8.899139404296875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.93s/it]
INFO:root:final mean train loss: 5539.155859178112
INFO:root:final train perplexity: 8.893826484680176
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.23s/it]
INFO:root:eval mean loss: 4665.69794090758
INFO:root:eval perplexity: 6.597371578216553
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.68s/it]
INFO:root:eval mean loss: 5519.94854346742
INFO:root:eval perplexity: 9.556130409240723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/178
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [20:53:57<2:34:45, 422.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5559.086277173913
INFO:root:current train perplexity8.901183128356934
INFO:root:current mean train loss 5561.2294286712395
INFO:root:current train perplexity8.920267105102539
INFO:root:current mean train loss 5541.833115102999
INFO:root:current train perplexity8.928988456726074
INFO:root:current mean train loss 5537.827317748645
INFO:root:current train perplexity8.897686004638672
INFO:root:current mean train loss 5537.244848228797
INFO:root:current train perplexity8.87239933013916
INFO:root:current mean train loss 5538.7551367560945
INFO:root:current train perplexity8.874709129333496
INFO:root:current mean train loss 5536.1056278528795
INFO:root:current train perplexity8.864656448364258
INFO:root:current mean train loss 5535.558836202239
INFO:root:current train perplexity8.86668586730957
INFO:root:current mean train loss 5531.0915233663045
INFO:root:current train perplexity8.864840507507324
INFO:root:current mean train loss 5530.559184660245
INFO:root:current train perplexity8.85819149017334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.73s/it]
INFO:root:final mean train loss: 5528.956098618046
INFO:root:final train perplexity: 8.85810661315918
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.20s/it]
INFO:root:eval mean loss: 4667.561403964428
INFO:root:eval perplexity: 6.602344036102295
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it]
INFO:root:eval mean loss: 5522.425615026596
INFO:root:eval perplexity: 9.565815925598145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/179
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [21:00:58<2:27:41, 421.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5492.477932837702
INFO:root:current train perplexity8.779155731201172
INFO:root:current mean train loss 5539.739690183683
INFO:root:current train perplexity8.912097930908203
INFO:root:current mean train loss 5531.368772828734
INFO:root:current train perplexity8.895927429199219
INFO:root:current mean train loss 5530.285250660876
INFO:root:current train perplexity8.876816749572754
INFO:root:current mean train loss 5533.4766746574105
INFO:root:current train perplexity8.872095108032227
INFO:root:current mean train loss 5530.975419498882
INFO:root:current train perplexity8.870758056640625
INFO:root:current mean train loss 5525.386998099495
INFO:root:current train perplexity8.861788749694824
INFO:root:current mean train loss 5535.951183230378
INFO:root:current train perplexity8.880678176879883
INFO:root:current mean train loss 5535.968715332619
INFO:root:current train perplexity8.876317977905273
INFO:root:current mean train loss 5537.845330227075
INFO:root:current train perplexity8.877238273620605

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.84s/it]
INFO:root:final mean train loss: 5535.620790173931
INFO:root:final train perplexity: 8.881427764892578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.01s/it]
INFO:root:eval mean loss: 4668.56239957336
INFO:root:eval perplexity: 6.605018138885498
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.13s/it]
INFO:root:eval mean loss: 5520.32429147274
INFO:root:eval perplexity: 9.557597160339355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/180
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [21:08:00<2:20:36, 421.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5580.554174178686
INFO:root:current train perplexity8.954299926757812
INFO:root:current mean train loss 5530.623788078912
INFO:root:current train perplexity8.869917869567871
INFO:root:current mean train loss 5532.6240642978555
INFO:root:current train perplexity8.858668327331543
INFO:root:current mean train loss 5531.973701949668
INFO:root:current train perplexity8.864349365234375
INFO:root:current mean train loss 5531.266602674758
INFO:root:current train perplexity8.859038352966309
INFO:root:current mean train loss 5533.057940594562
INFO:root:current train perplexity8.86330795288086
INFO:root:current mean train loss 5536.909686307952
INFO:root:current train perplexity8.87368106842041
INFO:root:current mean train loss 5544.764947088549
INFO:root:current train perplexity8.89539909362793
INFO:root:current mean train loss 5543.470487210407
INFO:root:current train perplexity8.889354705810547
INFO:root:current mean train loss 5545.362233967319
INFO:root:current train perplexity8.903694152832031

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.55s/it]
INFO:root:final mean train loss: 5544.04828828381
INFO:root:final train perplexity: 8.91100788116455
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.95s/it]
INFO:root:eval mean loss: 4667.054131690492
INFO:root:eval perplexity: 6.600988388061523
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it]
INFO:root:eval mean loss: 5520.264496066046
INFO:root:eval perplexity: 9.557365417480469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/181
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [21:15:00<2:13:27, 421.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5524.259765625
INFO:root:current train perplexity8.866594314575195
INFO:root:current mean train loss 5568.683683434311
INFO:root:current train perplexity8.963534355163574
INFO:root:current mean train loss 5544.51087463626
INFO:root:current train perplexity8.893527030944824
INFO:root:current mean train loss 5555.903731200468
INFO:root:current train perplexity8.90973949432373
INFO:root:current mean train loss 5553.083649023
INFO:root:current train perplexity8.911080360412598
INFO:root:current mean train loss 5554.6789207109805
INFO:root:current train perplexity8.911375045776367
INFO:root:current mean train loss 5551.435331789751
INFO:root:current train perplexity8.905829429626465
INFO:root:current mean train loss 5548.9341951137885
INFO:root:current train perplexity8.904809951782227
INFO:root:current mean train loss 5551.832485518743
INFO:root:current train perplexity8.910639762878418
INFO:root:current mean train loss 5546.166432236669
INFO:root:current train perplexity8.900736808776855

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.39s/it]
INFO:root:final mean train loss: 5540.7935175126595
INFO:root:final train perplexity: 8.899574279785156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.77s/it]
INFO:root:eval mean loss: 4669.881139876995
INFO:root:eval perplexity: 6.608541011810303
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.22s/it]
INFO:root:eval mean loss: 5526.8687596963655
INFO:root:eval perplexity: 9.583208084106445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/182
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [21:22:01<2:06:21, 421.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5527.415580610796
INFO:root:current train perplexity8.809274673461914
INFO:root:current mean train loss 5539.024584173387
INFO:root:current train perplexity8.825577735900879
INFO:root:current mean train loss 5532.938271675858
INFO:root:current train perplexity8.841020584106445
INFO:root:current mean train loss 5522.087032350352
INFO:root:current train perplexity8.836898803710938
INFO:root:current mean train loss 5523.315189302884
INFO:root:current train perplexity8.838632583618164
INFO:root:current mean train loss 5522.948725190034
INFO:root:current train perplexity8.836275100708008
INFO:root:current mean train loss 5519.912830987595
INFO:root:current train perplexity8.831037521362305
INFO:root:current mean train loss 5523.48569432947
INFO:root:current train perplexity8.845159530639648
INFO:root:current mean train loss 5527.326322071454
INFO:root:current train perplexity8.849549293518066
INFO:root:current mean train loss 5530.850178951244
INFO:root:current train perplexity8.851882934570312

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.26s/it]
INFO:root:final mean train loss: 5528.842417317052
INFO:root:final train perplexity: 8.857711791992188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.07s/it]
INFO:root:eval mean loss: 4660.67545746066
INFO:root:eval perplexity: 6.583985328674316
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.87s/it]
INFO:root:eval mean loss: 5516.515098625887
INFO:root:eval perplexity: 9.54272174835205
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/183
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [21:29:03<1:59:22, 421.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5523.964657738095
INFO:root:current train perplexity8.84697151184082
INFO:root:current mean train loss 5541.825914254217
INFO:root:current train perplexity8.845695495605469
INFO:root:current mean train loss 5544.5085644159935
INFO:root:current train perplexity8.876465797424316
INFO:root:current mean train loss 5528.859754325929
INFO:root:current train perplexity8.844217300415039
INFO:root:current mean train loss 5533.134710785637
INFO:root:current train perplexity8.84945011138916
INFO:root:current mean train loss 5538.865977637933
INFO:root:current train perplexity8.862257957458496
INFO:root:current mean train loss 5538.620623880562
INFO:root:current train perplexity8.858630180358887
INFO:root:current mean train loss 5538.913732286206
INFO:root:current train perplexity8.8497896194458
INFO:root:current mean train loss 5536.158840210385
INFO:root:current train perplexity8.850788116455078
INFO:root:current mean train loss 5531.456154574734
INFO:root:current train perplexity8.8579740524292

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.51s/it]
INFO:root:final mean train loss: 5527.010032653809
INFO:root:final train perplexity: 8.851308822631836
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.33s/it]
INFO:root:eval mean loss: 4664.537244431516
INFO:root:eval perplexity: 6.594275951385498
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it]
INFO:root:eval mean loss: 5518.581875415559
INFO:root:eval perplexity: 9.550788879394531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/184
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [21:36:04<1:52:22, 421.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5543.876492352553
INFO:root:current train perplexity8.823233604431152
INFO:root:current mean train loss 5528.776384320176
INFO:root:current train perplexity8.856066703796387
INFO:root:current mean train loss 5534.068840449147
INFO:root:current train perplexity8.85025405883789
INFO:root:current mean train loss 5542.240225162146
INFO:root:current train perplexity8.890800476074219
INFO:root:current mean train loss 5544.314087173235
INFO:root:current train perplexity8.894485473632812
INFO:root:current mean train loss 5541.492215719407
INFO:root:current train perplexity8.888047218322754
INFO:root:current mean train loss 5546.346964942716
INFO:root:current train perplexity8.905702590942383
INFO:root:current mean train loss 5545.632431881282
INFO:root:current train perplexity8.900208473205566
INFO:root:current mean train loss 5540.807963637342
INFO:root:current train perplexity8.886670112609863
INFO:root:current mean train loss 5541.024680580587
INFO:root:current train perplexity8.887825012207031

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.60s/it]
INFO:root:final mean train loss: 5537.436243980162
INFO:root:final train perplexity: 8.88779354095459
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.63s/it]
INFO:root:eval mean loss: 4672.332093583776
INFO:root:eval perplexity: 6.6150946617126465
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.56s/it]
INFO:root:eval mean loss: 5527.744795129654
INFO:root:eval perplexity: 9.586642265319824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/185
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [21:43:03<1:45:10, 420.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5579.588663221914
INFO:root:current train perplexity9.017087936401367
INFO:root:current mean train loss 5587.592939835021
INFO:root:current train perplexity8.951213836669922
INFO:root:current mean train loss 5570.778238057235
INFO:root:current train perplexity8.933941841125488
INFO:root:current mean train loss 5562.189176131678
INFO:root:current train perplexity8.929865837097168
INFO:root:current mean train loss 5553.7639736103865
INFO:root:current train perplexity8.925613403320312
INFO:root:current mean train loss 5556.569320757772
INFO:root:current train perplexity8.923887252807617
INFO:root:current mean train loss 5552.640600549981
INFO:root:current train perplexity8.913565635681152
INFO:root:current mean train loss 5549.783191842506
INFO:root:current train perplexity8.91053581237793
INFO:root:current mean train loss 5545.097362947952
INFO:root:current train perplexity8.903460502624512
INFO:root:current mean train loss 5543.851408384672
INFO:root:current train perplexity8.89620590209961

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.27s/it]
INFO:root:final mean train loss: 5540.74739825341
INFO:root:final train perplexity: 8.89941120147705
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.97s/it]
INFO:root:eval mean loss: 4665.716192583665
INFO:root:eval perplexity: 6.597419261932373
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it]
INFO:root:eval mean loss: 5519.5004917442375
INFO:root:eval perplexity: 9.554380416870117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/186
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [21:50:04<1:38:10, 420.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5557.528926454741
INFO:root:current train perplexity8.964335441589355
INFO:root:current mean train loss 5550.290018173462
INFO:root:current train perplexity8.952912330627441
INFO:root:current mean train loss 5546.126970138284
INFO:root:current train perplexity8.90864372253418
INFO:root:current mean train loss 5546.697091509205
INFO:root:current train perplexity8.91775131225586
INFO:root:current mean train loss 5542.0364215702
INFO:root:current train perplexity8.901342391967773
INFO:root:current mean train loss 5545.089461942344
INFO:root:current train perplexity8.90419864654541
INFO:root:current mean train loss 5543.0544294998635
INFO:root:current train perplexity8.903178215026855
INFO:root:current mean train loss 5548.584988236579
INFO:root:current train perplexity8.913084030151367
INFO:root:current mean train loss 5549.684693621406
INFO:root:current train perplexity8.920699119567871
INFO:root:current mean train loss 5551.350179283814
INFO:root:current train perplexity8.92230224609375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.63s/it]
INFO:root:final mean train loss: 5547.477504853279
INFO:root:final train perplexity: 8.923072814941406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.32s/it]
INFO:root:eval mean loss: 4662.892108890182
INFO:root:eval perplexity: 6.589890956878662
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.57s/it]
INFO:root:eval mean loss: 5516.75646193484
INFO:root:eval perplexity: 9.54366397857666
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/187
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [21:57:06<1:31:13, 421.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5586.379039884869
INFO:root:current train perplexity8.923238754272461
INFO:root:current mean train loss 5574.222040264423
INFO:root:current train perplexity8.946100234985352
INFO:root:current mean train loss 5558.894244902012
INFO:root:current train perplexity8.92406177520752
INFO:root:current mean train loss 5561.388565565665
INFO:root:current train perplexity8.92648983001709
INFO:root:current mean train loss 5561.124806660354
INFO:root:current train perplexity8.931831359863281
INFO:root:current mean train loss 5564.245863149948
INFO:root:current train perplexity8.936447143554688
INFO:root:current mean train loss 5559.579653776978
INFO:root:current train perplexity8.931083679199219
INFO:root:current mean train loss 5554.077457375197
INFO:root:current train perplexity8.93237018585205
INFO:root:current mean train loss 5553.421453277759
INFO:root:current train perplexity8.936134338378906

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.84s/it]
INFO:root:final mean train loss: 5548.893006970806
INFO:root:final train perplexity: 8.928058624267578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.51s/it]
INFO:root:eval mean loss: 4666.060709635417
INFO:root:eval perplexity: 6.598339080810547
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.33s/it]
INFO:root:eval mean loss: 5519.439141456117
INFO:root:eval perplexity: 9.554139137268066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/188
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [22:04:08<1:24:16, 421.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5558.31689453125
INFO:root:current train perplexity9.351603507995605
INFO:root:current mean train loss 5566.748155908677
INFO:root:current train perplexity8.908538818359375
INFO:root:current mean train loss 5553.8747787099755
INFO:root:current train perplexity8.95506477355957
INFO:root:current mean train loss 5548.836443507632
INFO:root:current train perplexity8.946869850158691
INFO:root:current mean train loss 5548.075898049783
INFO:root:current train perplexity8.916701316833496
INFO:root:current mean train loss 5545.3384439457
INFO:root:current train perplexity8.904731750488281
INFO:root:current mean train loss 5551.17919193097
INFO:root:current train perplexity8.916841506958008
INFO:root:current mean train loss 5552.319308154783
INFO:root:current train perplexity8.931413650512695
INFO:root:current mean train loss 5556.267883984861
INFO:root:current train perplexity8.941576957702637
INFO:root:current mean train loss 5556.184593023256
INFO:root:current train perplexity8.9369478225708

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.96s/it]
INFO:root:final mean train loss: 5553.227959171419
INFO:root:final train perplexity: 8.943340301513672
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.07s/it]
INFO:root:eval mean loss: 4666.501885596742
INFO:root:eval perplexity: 6.59951639175415
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.46s/it]
INFO:root:eval mean loss: 5520.904639710771
INFO:root:eval perplexity: 9.559866905212402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/189
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [22:11:09<1:17:13, 421.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5434.152254971591
INFO:root:current train perplexity8.599912643432617
INFO:root:current mean train loss 5532.744496938345
INFO:root:current train perplexity8.88736343383789
INFO:root:current mean train loss 5545.557295523548
INFO:root:current train perplexity8.931624412536621
INFO:root:current mean train loss 5554.246404617163
INFO:root:current train perplexity8.949468612670898
INFO:root:current mean train loss 5547.249579436588
INFO:root:current train perplexity8.917581558227539
INFO:root:current mean train loss 5548.378352991988
INFO:root:current train perplexity8.909040451049805
INFO:root:current mean train loss 5550.501795692257
INFO:root:current train perplexity8.906097412109375
INFO:root:current mean train loss 5545.708356682929
INFO:root:current train perplexity8.897953033447266
INFO:root:current mean train loss 5544.835043421509
INFO:root:current train perplexity8.89106559753418
INFO:root:current mean train loss 5544.194096888721
INFO:root:current train perplexity8.886189460754395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.32s/it]
INFO:root:final mean train loss: 5536.187729743219
INFO:root:final train perplexity: 8.883416175842285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.74s/it]
INFO:root:eval mean loss: 4666.050227171986
INFO:root:eval perplexity: 6.598310470581055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.66s/it]
INFO:root:eval mean loss: 5522.359527371454
INFO:root:eval perplexity: 9.565558433532715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/190
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [22:18:12<1:10:17, 421.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5472.701917146382
INFO:root:current train perplexity8.824870109558105
INFO:root:current mean train loss 5574.688300124737
INFO:root:current train perplexity8.964752197265625
INFO:root:current mean train loss 5533.98769932577
INFO:root:current train perplexity8.892017364501953
INFO:root:current mean train loss 5518.439355162617
INFO:root:current train perplexity8.904336929321289
INFO:root:current mean train loss 5518.440138350239
INFO:root:current train perplexity8.885183334350586
INFO:root:current mean train loss 5525.282167291366
INFO:root:current train perplexity8.895322799682617
INFO:root:current mean train loss 5527.23013823329
INFO:root:current train perplexity8.877776145935059
INFO:root:current mean train loss 5530.298910297505
INFO:root:current train perplexity8.87140941619873
INFO:root:current mean train loss 5530.5130780677655
INFO:root:current train perplexity8.863200187683105
INFO:root:current mean train loss 5536.971500633331
INFO:root:current train perplexity8.875727653503418

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.33s/it]
INFO:root:final mean train loss: 5533.363617681688
INFO:root:final train perplexity: 8.87352466583252
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.98s/it]
INFO:root:eval mean loss: 4663.303840799535
INFO:root:eval perplexity: 6.590988636016846
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.78s/it]
INFO:root:eval mean loss: 5518.828242741578
INFO:root:eval perplexity: 9.551752090454102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/191
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [22:25:14<1:03:17, 421.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5515.390643084491
INFO:root:current train perplexity8.792106628417969
INFO:root:current mean train loss 5504.341535433071
INFO:root:current train perplexity8.828824996948242
INFO:root:current mean train loss 5508.239356759361
INFO:root:current train perplexity8.820734977722168
INFO:root:current mean train loss 5516.371496918005
INFO:root:current train perplexity8.8156156539917
INFO:root:current mean train loss 5519.9077194178135
INFO:root:current train perplexity8.824135780334473
INFO:root:current mean train loss 5522.882597545066
INFO:root:current train perplexity8.829679489135742
INFO:root:current mean train loss 5522.080976811702
INFO:root:current train perplexity8.835241317749023
INFO:root:current mean train loss 5528.06094515668
INFO:root:current train perplexity8.843442916870117
INFO:root:current mean train loss 5528.602167094921
INFO:root:current train perplexity8.848287582397461
INFO:root:current mean train loss 5530.093847445557
INFO:root:current train perplexity8.853974342346191

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.42s/it]
INFO:root:final mean train loss: 5529.711983342325
INFO:root:final train perplexity: 8.860751152038574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.99s/it]
INFO:root:eval mean loss: 4660.891231022828
INFO:root:eval perplexity: 6.584561347961426
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.01s/it]
INFO:root:eval mean loss: 5515.781419686392
INFO:root:eval perplexity: 9.539860725402832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/192
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [22:32:15<56:12, 421.59s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5594.498953683035
INFO:root:current train perplexity9.008622169494629
INFO:root:current mean train loss 5549.630794270834
INFO:root:current train perplexity8.876920700073242
INFO:root:current mean train loss 5532.436375914229
INFO:root:current train perplexity8.857523918151855
INFO:root:current mean train loss 5551.404002448694
INFO:root:current train perplexity8.90208911895752
INFO:root:current mean train loss 5551.312840113146
INFO:root:current train perplexity8.903483390808105
INFO:root:current mean train loss 5548.494984849591
INFO:root:current train perplexity8.902390480041504
INFO:root:current mean train loss 5547.3619140625
INFO:root:current train perplexity8.901969909667969
INFO:root:current mean train loss 5547.435236633716
INFO:root:current train perplexity8.905296325683594
INFO:root:current mean train loss 5549.482692622568
INFO:root:current train perplexity8.911521911621094
INFO:root:current mean train loss 5549.7735711898395
INFO:root:current train perplexity8.90932559967041

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.88s/it]
INFO:root:final mean train loss: 5543.4658308952085
INFO:root:final train perplexity: 8.90896224975586
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.94s/it]
INFO:root:eval mean loss: 4664.967337101064
INFO:root:eval perplexity: 6.595422267913818
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.56s/it]
INFO:root:eval mean loss: 5519.162417580896
INFO:root:eval perplexity: 9.553056716918945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/193
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [22:39:16<49:09, 421.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5557.019429051599
INFO:root:current train perplexity9.041213989257812
INFO:root:current mean train loss 5549.368143575175
INFO:root:current train perplexity8.948354721069336
INFO:root:current mean train loss 5523.556391460906
INFO:root:current train perplexity8.884653091430664
INFO:root:current mean train loss 5540.278644884293
INFO:root:current train perplexity8.904129028320312
INFO:root:current mean train loss 5546.5806534812355
INFO:root:current train perplexity8.902288436889648
INFO:root:current mean train loss 5551.590552342312
INFO:root:current train perplexity8.914297103881836
INFO:root:current mean train loss 5555.481799942894
INFO:root:current train perplexity8.923460006713867
INFO:root:current mean train loss 5551.857981131183
INFO:root:current train perplexity8.919082641601562
INFO:root:current mean train loss 5549.9874819283805
INFO:root:current train perplexity8.922168731689453
INFO:root:current mean train loss 5548.869285607768
INFO:root:current train perplexity8.917383193969727

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.05s/it]
INFO:root:final mean train loss: 5545.070021844679
INFO:root:final train perplexity: 8.914603233337402
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.67s/it]
INFO:root:eval mean loss: 4669.104587419659
INFO:root:eval perplexity: 6.606466293334961
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.44s/it]
INFO:root:eval mean loss: 5523.232563857491
INFO:root:eval perplexity: 9.568970680236816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/194
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [22:46:18<42:10, 421.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5523.54332299326
INFO:root:current train perplexity8.925253868103027
INFO:root:current mean train loss 5530.52085057947
INFO:root:current train perplexity8.921589851379395
INFO:root:current mean train loss 5546.690248770543
INFO:root:current train perplexity8.919618606567383
INFO:root:current mean train loss 5556.731117009437
INFO:root:current train perplexity8.946528434753418
INFO:root:current mean train loss 5553.744836777647
INFO:root:current train perplexity8.938264846801758
INFO:root:current mean train loss 5547.707531051497
INFO:root:current train perplexity8.917593955993652
INFO:root:current mean train loss 5549.223381546419
INFO:root:current train perplexity8.913788795471191
INFO:root:current mean train loss 5553.936696383988
INFO:root:current train perplexity8.926487922668457
INFO:root:current mean train loss 5552.778602609063
INFO:root:current train perplexity8.93423843383789
INFO:root:current mean train loss 5554.618414107683
INFO:root:current train perplexity8.933145523071289

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.87s/it]
INFO:root:final mean train loss: 5548.479559498449
INFO:root:final train perplexity: 8.926600456237793
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.88s/it]
INFO:root:eval mean loss: 4665.953140583444
INFO:root:eval perplexity: 6.598053455352783
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.13s/it]
INFO:root:eval mean loss: 5519.837350398936
INFO:root:eval perplexity: 9.555694580078125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/195
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [22:53:21<35:09, 421.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5572.559512380826
INFO:root:current train perplexity8.963491439819336
INFO:root:current mean train loss 5566.717487839033
INFO:root:current train perplexity8.918827056884766
INFO:root:current mean train loss 5584.850974300193
INFO:root:current train perplexity8.954524993896484
INFO:root:current mean train loss 5567.930598776985
INFO:root:current train perplexity8.938128471374512
INFO:root:current mean train loss 5558.383915653935
INFO:root:current train perplexity8.921066284179688
INFO:root:current mean train loss 5553.249880331787
INFO:root:current train perplexity8.912714004516602
INFO:root:current mean train loss 5549.073787521339
INFO:root:current train perplexity8.909686088562012
INFO:root:current mean train loss 5543.358197077775
INFO:root:current train perplexity8.902876853942871
INFO:root:current mean train loss 5547.567313464057
INFO:root:current train perplexity8.902099609375
INFO:root:current mean train loss 5545.60987244607
INFO:root:current train perplexity8.905583381652832

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.81s/it]
INFO:root:final mean train loss: 5542.300114416307
INFO:root:final train perplexity: 8.904865264892578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.89s/it]
INFO:root:eval mean loss: 4663.521056696033
INFO:root:eval perplexity: 6.591566562652588
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.04s/it]
INFO:root:eval mean loss: 5518.118299119016
INFO:root:eval perplexity: 9.548978805541992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/196
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [23:00:23<28:07, 421.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5558.067207905784
INFO:root:current train perplexity8.923872947692871
INFO:root:current mean train loss 5551.238368965194
INFO:root:current train perplexity8.955578804016113
INFO:root:current mean train loss 5549.732131100773
INFO:root:current train perplexity8.942975997924805
INFO:root:current mean train loss 5567.1191286508
INFO:root:current train perplexity8.963031768798828
INFO:root:current mean train loss 5557.3561400060225
INFO:root:current train perplexity8.944299697875977
INFO:root:current mean train loss 5552.348712039793
INFO:root:current train perplexity8.935428619384766
INFO:root:current mean train loss 5552.175363246111
INFO:root:current train perplexity8.931720733642578
INFO:root:current mean train loss 5548.25309966285
INFO:root:current train perplexity8.924683570861816
INFO:root:current mean train loss 5548.5915361204225
INFO:root:current train perplexity8.926161766052246
INFO:root:current mean train loss 5548.350237525853
INFO:root:current train perplexity8.918956756591797

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.77s/it]
INFO:root:final mean train loss: 5544.449104678246
INFO:root:final train perplexity: 8.912418365478516
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.88s/it]
INFO:root:eval mean loss: 4664.791422526042
INFO:root:eval perplexity: 6.594954490661621
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.06s/it]
INFO:root:eval mean loss: 5519.823997118794
INFO:root:eval perplexity: 9.555642127990723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/197
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [23:07:25<21:05, 421.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5569.818834635416
INFO:root:current train perplexity8.93892765045166
INFO:root:current mean train loss 5538.641936383929
INFO:root:current train perplexity8.908344268798828
INFO:root:current mean train loss 5543.129536576705
INFO:root:current train perplexity8.915044784545898
INFO:root:current mean train loss 5552.431805989583
INFO:root:current train perplexity8.926864624023438
INFO:root:current mean train loss 5550.703772615131
INFO:root:current train perplexity8.934868812561035
INFO:root:current mean train loss 5554.320380434782
INFO:root:current train perplexity8.944762229919434
INFO:root:current mean train loss 5553.169584056713
INFO:root:current train perplexity8.937127113342285
INFO:root:current mean train loss 5558.128810483871
INFO:root:current train perplexity8.938665390014648
INFO:root:current mean train loss 5554.637059151786
INFO:root:current train perplexity8.930045127868652
INFO:root:current mean train loss 5552.1428340344555
INFO:root:current train perplexity8.92656421661377

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.96s/it]
INFO:root:final mean train loss: 5548.267892529888
INFO:root:final train perplexity: 8.92585563659668
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.93s/it]
INFO:root:eval mean loss: 4666.581381939827
INFO:root:eval perplexity: 6.599728107452393
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.51s/it]
INFO:root:eval mean loss: 5520.7465854942375
INFO:root:eval perplexity: 9.559245109558105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/198
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [23:14:25<14:03, 421.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5572.164380176958
INFO:root:current train perplexity8.89677619934082
INFO:root:current mean train loss 5578.937209165812
INFO:root:current train perplexity8.963892936706543
INFO:root:current mean train loss 5558.40838083867
INFO:root:current train perplexity8.94192886352539
INFO:root:current mean train loss 5555.244776793
INFO:root:current train perplexity8.941877365112305
INFO:root:current mean train loss 5554.756087846144
INFO:root:current train perplexity8.92937183380127
INFO:root:current mean train loss 5544.626355127037
INFO:root:current train perplexity8.912364959716797
INFO:root:current mean train loss 5548.587429510203
INFO:root:current train perplexity8.913504600524902
INFO:root:current mean train loss 5546.458580280172
INFO:root:current train perplexity8.900764465332031
INFO:root:current mean train loss 5544.35015295424
INFO:root:current train perplexity8.903055191040039
INFO:root:current mean train loss 5549.419435580652
INFO:root:current train perplexity8.913345336914062

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.29s/it]
INFO:root:final mean train loss: 5544.829123958464
INFO:root:final train perplexity: 8.913755416870117
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.53s/it]
INFO:root:eval mean loss: 4664.76276803524
INFO:root:eval perplexity: 6.594877243041992
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.39s/it]
INFO:root:eval mean loss: 5519.03456754211
INFO:root:eval perplexity: 9.552557945251465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/199
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [23:21:27<07:01, 421.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5549.1858634529535
INFO:root:current train perplexity8.992643356323242
INFO:root:current mean train loss 5589.490881155923
INFO:root:current train perplexity9.032073974609375
INFO:root:current mean train loss 5558.83516732442
INFO:root:current train perplexity8.951420783996582
INFO:root:current mean train loss 5554.835421745125
INFO:root:current train perplexity8.934061050415039
INFO:root:current mean train loss 5550.729548871881
INFO:root:current train perplexity8.937094688415527
INFO:root:current mean train loss 5545.4824623585555
INFO:root:current train perplexity8.92477035522461
INFO:root:current mean train loss 5540.766717449801
INFO:root:current train perplexity8.921923637390137
INFO:root:current mean train loss 5544.20025457293
INFO:root:current train perplexity8.924168586730957
INFO:root:current mean train loss 5546.811389721872
INFO:root:current train perplexity8.917562484741211
INFO:root:current mean train loss 5552.244364810639
INFO:root:current train perplexity8.924514770507812

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.02s/it]
INFO:root:final mean train loss: 5547.812489171182
INFO:root:final train perplexity: 8.924251556396484
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.75s/it]
INFO:root:eval mean loss: 4664.507769212655
INFO:root:eval perplexity: 6.5941972732543945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.50s/it]
INFO:root:eval mean loss: 5518.869545794548
INFO:root:eval perplexity: 9.551913261413574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multiqal6_multiqal6_not_concat_200e_128/200
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [23:28:28<00:00, 421.29s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [23:28:28<00:00, 422.54s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.37s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.37s/it]
INFO:root:eval mean loss: 4664.507769212655
INFO:root:eval perplexity: 6.5941972732543945
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.24s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.24s/it]
INFO:root:eval mean loss: 5518.869545794548
INFO:root:eval perplexity: 9.551913261413574
INFO:root:evalaution complete
INFO:root:save model final: multiqal6_multiqal6_not_concat_200e_128/final
