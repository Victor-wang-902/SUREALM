INFO:root:Output: std_13_single_gpu
INFO:root:Steps per epochs:1983
INFO:root:Total steps:198300
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['cls.predictions.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.query.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.value.weight', 'cls.predictions.decoder.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.value.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/100 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12239.522017045454
INFO:root:current train perplexity16718.57421875
INFO:root:current mean train loss 10566.927582247174
INFO:root:current train perplexity4186.78076171875
INFO:root:current mean train loss 9189.063249568875
INFO:root:current train perplexity1401.0596923828125
INFO:root:current mean train loss 8236.876456277412
INFO:root:current train perplexity660.5242919921875
INFO:root:current mean train loss 7543.318098599543
INFO:root:current train perplexity383.0232849121094
INFO:root:current mean train loss 7017.642086990688
INFO:root:current train perplexity252.9873504638672
INFO:root:current mean train loss 6608.3379527952875
INFO:root:current train perplexity182.61407470703125
INFO:root:current mean train loss 6282.961643949468
INFO:root:current train perplexity140.8274688720703
INFO:root:current mean train loss 6005.932362727249
INFO:root:current train perplexity113.75933074951172
INFO:root:current mean train loss 5781.83606335828
INFO:root:current train perplexity94.83674621582031
INFO:root:current mean train loss 5582.5464631376535
INFO:root:current train perplexity81.23382568359375
INFO:root:current mean train loss 5412.919136511872
INFO:root:current train perplexity71.10575103759766
INFO:root:current mean train loss 5266.400239329231
INFO:root:current train perplexity63.17350387573242
INFO:root:current mean train loss 5130.7032037043755
INFO:root:current train perplexity56.908939361572266
INFO:root:current mean train loss 5011.975265737054
INFO:root:current train perplexity51.89676284790039
INFO:root:current mean train loss 4905.380121761892
INFO:root:current train perplexity47.73923873901367
INFO:root:current mean train loss 4809.8634937773595
INFO:root:current train perplexity44.24430847167969
INFO:root:current mean train loss 4721.525779974335
INFO:root:current train perplexity41.31460189819336
INFO:root:current mean train loss 4639.16240082671
INFO:root:current train perplexity38.77638244628906


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.78s/it]
INFO:root:final mean train loss: 4575.116823197373
INFO:root:final train perplexity: 36.9000358581543
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.15s/it]
INFO:root:eval mean loss: 3479.952434367962
INFO:root:eval perplexity: 17.384082794189453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/1

  1%|          | 1/100 [02:23<3:56:20, 143.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3104.22509765625
INFO:root:current train perplexity11.483468055725098
INFO:root:current mean train loss 3101.287206189386
INFO:root:current train perplexity11.562768936157227
INFO:root:current mean train loss 3083.727528889974
INFO:root:current train perplexity11.502511978149414
INFO:root:current mean train loss 3082.4501914495154
INFO:root:current train perplexity11.482414245605469
INFO:root:current mean train loss 3076.219518221342
INFO:root:current train perplexity11.393915176391602
INFO:root:current mean train loss 3066.5125287669575
INFO:root:current train perplexity11.256335258483887
INFO:root:current mean train loss 3048.7262652508625
INFO:root:current train perplexity11.126582145690918
INFO:root:current mean train loss 3038.249523993977
INFO:root:current train perplexity11.029134750366211
INFO:root:current mean train loss 3029.8209593529796
INFO:root:current train perplexity10.955023765563965
INFO:root:current mean train loss 3024.0270367085154
INFO:root:current train perplexity10.879776000976562
INFO:root:current mean train loss 3011.526984507643
INFO:root:current train perplexity10.793333053588867
INFO:root:current mean train loss 3003.4034863543766
INFO:root:current train perplexity10.702949523925781
INFO:root:current mean train loss 2996.5982963160463
INFO:root:current train perplexity10.629983901977539
INFO:root:current mean train loss 2988.1707116216876
INFO:root:current train perplexity10.551725387573242
INFO:root:current mean train loss 2979.532499151715
INFO:root:current train perplexity10.482644081115723
INFO:root:current mean train loss 2971.8388530157486
INFO:root:current train perplexity10.412351608276367
INFO:root:current mean train loss 2963.058787581944
INFO:root:current train perplexity10.342991828918457
INFO:root:current mean train loss 2955.892301403837
INFO:root:current train perplexity10.282567977905273
INFO:root:current mean train loss 2946.1138169881006
INFO:root:current train perplexity10.214703559875488
INFO:root:current mean train loss 2938.540224971254
INFO:root:current train perplexity10.146926879882812


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.60s/it]
INFO:root:final mean train loss: 2933.058521603552
INFO:root:final train perplexity: 10.106576919555664
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.15s/it]
INFO:root:eval mean loss: 3240.3640730574325
INFO:root:eval perplexity: 14.28135871887207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/2

  2%|â–         | 2/100 [04:50<3:58:03, 145.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2822.324092980587
INFO:root:current train perplexity9.235899925231934
INFO:root:current mean train loss 2768.0901025757753
INFO:root:current train perplexity8.94870662689209
INFO:root:current mean train loss 2764.7995752162687
INFO:root:current train perplexity8.904875755310059
INFO:root:current mean train loss 2751.999640754035
INFO:root:current train perplexity8.829693794250488
INFO:root:current mean train loss 2755.4554570222285
INFO:root:current train perplexity8.801255226135254
INFO:root:current mean train loss 2751.3169178917974
INFO:root:current train perplexity8.7571382522583
INFO:root:current mean train loss 2747.0600817350414
INFO:root:current train perplexity8.717726707458496
INFO:root:current mean train loss 2741.6744223226465
INFO:root:current train perplexity8.684812545776367
INFO:root:current mean train loss 2737.763272105717
INFO:root:current train perplexity8.65739917755127
INFO:root:current mean train loss 2731.983186220944
INFO:root:current train perplexity8.627494812011719
INFO:root:current mean train loss 2727.3688844309654
INFO:root:current train perplexity8.596941947937012
INFO:root:current mean train loss 2722.8747905519085
INFO:root:current train perplexity8.576038360595703
INFO:root:current mean train loss 2717.778552770808
INFO:root:current train perplexity8.54585075378418
INFO:root:current mean train loss 2711.524606737622
INFO:root:current train perplexity8.507803916931152
INFO:root:current mean train loss 2710.7360378140265
INFO:root:current train perplexity8.491446495056152
INFO:root:current mean train loss 2709.7257221020363
INFO:root:current train perplexity8.468642234802246
INFO:root:current mean train loss 2705.542314070394
INFO:root:current train perplexity8.440814971923828
INFO:root:current mean train loss 2701.983025112251
INFO:root:current train perplexity8.411662101745605
INFO:root:current mean train loss 2697.8876754669172
INFO:root:current train perplexity8.380126953125
INFO:root:current mean train loss 2693.2746830845026
INFO:root:current train perplexity8.354711532592773


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:16<00:00, 136.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:16<00:00, 136.97s/it]
INFO:root:final mean train loss: 2689.476575242589
INFO:root:final train perplexity: 8.340167045593262
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.44s/it]
INFO:root:eval mean loss: 3127.0349817591027
INFO:root:eval perplexity: 13.013153076171875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/3

  3%|â–Ž         | 3/100 [07:27<4:04:02, 150.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2623.559755859375
INFO:root:current train perplexity7.871338367462158
INFO:root:current mean train loss 2610.6439420572915
INFO:root:current train perplexity7.830224990844727
INFO:root:current mean train loss 2602.078888671875
INFO:root:current train perplexity7.796544551849365
INFO:root:current mean train loss 2595.3176625279016
INFO:root:current train perplexity7.742896556854248
INFO:root:current mean train loss 2599.6156884765624
INFO:root:current train perplexity7.735727787017822
INFO:root:current mean train loss 2591.6997811612214
INFO:root:current train perplexity7.696194171905518
INFO:root:current mean train loss 2587.7495278695915
INFO:root:current train perplexity7.679135799407959
INFO:root:current mean train loss 2585.0981328125
INFO:root:current train perplexity7.666183948516846
INFO:root:current mean train loss 2582.8215662339153
INFO:root:current train perplexity7.662136554718018
INFO:root:current mean train loss 2579.684627364309
INFO:root:current train perplexity7.640869617462158
INFO:root:current mean train loss 2576.2175678943454
INFO:root:current train perplexity7.6216254234313965
INFO:root:current mean train loss 2575.6497012992527
INFO:root:current train perplexity7.613799095153809
INFO:root:current mean train loss 2572.7223873046873
INFO:root:current train perplexity7.601157188415527
INFO:root:current mean train loss 2570.4339563440394
INFO:root:current train perplexity7.586183071136475
INFO:root:current mean train loss 2569.878991278287
INFO:root:current train perplexity7.580851078033447
INFO:root:current mean train loss 2567.000076471144
INFO:root:current train perplexity7.56666898727417
INFO:root:current mean train loss 2565.463992587003
INFO:root:current train perplexity7.555398464202881
INFO:root:current mean train loss 2562.9568812081475
INFO:root:current train perplexity7.539590358734131
INFO:root:current mean train loss 2562.0292696236274
INFO:root:current train perplexity7.533989429473877
INFO:root:current mean train loss 2559.944305451222
INFO:root:current train perplexity7.524317264556885


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:17<00:00, 137.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:17<00:00, 137.36s/it]
INFO:root:final mean train loss: 2558.3696080379514
INFO:root:final train perplexity: 7.520887851715088
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.79s/it]
INFO:root:eval mean loss: 3061.6298916103606
INFO:root:eval perplexity: 12.333149909973145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/4

  4%|â–         | 4/100 [10:03<4:04:11, 152.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2539.1290228544776
INFO:root:current train perplexity7.254113674163818
INFO:root:current mean train loss 2501.095312792384
INFO:root:current train perplexity7.155902862548828
INFO:root:current mean train loss 2497.73627783386
INFO:root:current train perplexity7.158956527709961
INFO:root:current mean train loss 2498.2421675430005
INFO:root:current train perplexity7.169328689575195
INFO:root:current mean train loss 2498.8218374640323
INFO:root:current train perplexity7.178131103515625
INFO:root:current mean train loss 2493.823037229938
INFO:root:current train perplexity7.1438798904418945
INFO:root:current mean train loss 2494.9345582335786
INFO:root:current train perplexity7.142337799072266
INFO:root:current mean train loss 2491.9788711726897
INFO:root:current train perplexity7.1279449462890625
INFO:root:current mean train loss 2491.635587452467
INFO:root:current train perplexity7.113563060760498
INFO:root:current mean train loss 2488.223923281775
INFO:root:current train perplexity7.098583698272705
INFO:root:current mean train loss 2487.6769616825063
INFO:root:current train perplexity7.09395694732666
INFO:root:current mean train loss 2486.857658902702
INFO:root:current train perplexity7.08553409576416
INFO:root:current mean train loss 2483.7080228424675
INFO:root:current train perplexity7.073267459869385
INFO:root:current mean train loss 2483.242996896717
INFO:root:current train perplexity7.068047523498535
INFO:root:current mean train loss 2480.765320947565
INFO:root:current train perplexity7.063368797302246
INFO:root:current mean train loss 2478.4094453287034
INFO:root:current train perplexity7.058000087738037
INFO:root:current mean train loss 2474.902256023405
INFO:root:current train perplexity7.042424201965332
INFO:root:current mean train loss 2473.503779620185
INFO:root:current train perplexity7.030900955200195
INFO:root:current mean train loss 2471.5866650835233
INFO:root:current train perplexity7.021055698394775
INFO:root:current mean train loss 2469.6483384536255
INFO:root:current train perplexity7.008376598358154


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.18s/it]
INFO:root:final mean train loss: 2468.637685555493
INFO:root:final train perplexity: 7.007046699523926
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.32s/it]
INFO:root:eval mean loss: 3023.625129035285
INFO:root:eval perplexity: 11.9544677734375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/5

  5%|â–Œ         | 5/100 [12:53<4:11:52, 159.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2425.426997593471
INFO:root:current train perplexity6.711633205413818
INFO:root:current mean train loss 2421.9544180165167
INFO:root:current train perplexity6.73666524887085
INFO:root:current mean train loss 2419.6067706900585
INFO:root:current train perplexity6.757894515991211
INFO:root:current mean train loss 2420.911046028137
INFO:root:current train perplexity6.7613983154296875
INFO:root:current mean train loss 2426.6946852502742
INFO:root:current train perplexity6.7733306884765625
INFO:root:current mean train loss 2419.8459637785613
INFO:root:current train perplexity6.737386226654053
INFO:root:current mean train loss 2417.4802392435354
INFO:root:current train perplexity6.713906764984131
INFO:root:current mean train loss 2417.737797484106
INFO:root:current train perplexity6.7216410636901855
INFO:root:current mean train loss 2415.9508908647217
INFO:root:current train perplexity6.708996772766113
INFO:root:current mean train loss 2411.6726658518724
INFO:root:current train perplexity6.6905012130737305
INFO:root:current mean train loss 2410.7894211660014
INFO:root:current train perplexity6.689108848571777
INFO:root:current mean train loss 2409.1225329218682
INFO:root:current train perplexity6.681485176086426
INFO:root:current mean train loss 2407.9408295533367
INFO:root:current train perplexity6.676166534423828
INFO:root:current mean train loss 2407.9054731247743
INFO:root:current train perplexity6.6727681159973145
INFO:root:current mean train loss 2408.243888669901
INFO:root:current train perplexity6.674510478973389
INFO:root:current mean train loss 2407.4411520139133
INFO:root:current train perplexity6.665985107421875
INFO:root:current mean train loss 2406.5936688855822
INFO:root:current train perplexity6.660208702087402
INFO:root:current mean train loss 2403.5931876828317
INFO:root:current train perplexity6.654205799102783
INFO:root:current mean train loss 2403.225026837327
INFO:root:current train perplexity6.648630142211914


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:20<00:00, 140.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:20<00:00, 140.19s/it]
INFO:root:final mean train loss: 2400.78073743396
INFO:root:final train perplexity: 6.641913414001465
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.74s/it]
INFO:root:eval mean loss: 2986.1055383997277
INFO:root:eval perplexity: 11.59202766418457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/6

  6%|â–Œ         | 6/100 [15:31<4:08:39, 158.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2487.906005859375
INFO:root:current train perplexity6.1964592933654785
INFO:root:current mean train loss 2341.900985264542
INFO:root:current train perplexity6.358727931976318
INFO:root:current mean train loss 2354.2031577950092
INFO:root:current train perplexity6.4191765785217285
INFO:root:current mean train loss 2363.629090774891
INFO:root:current train perplexity6.434603691101074
INFO:root:current mean train loss 2359.953777360797
INFO:root:current train perplexity6.427561283111572
INFO:root:current mean train loss 2357.42084629569
INFO:root:current train perplexity6.4292120933532715
INFO:root:current mean train loss 2355.0306189310136
INFO:root:current train perplexity6.421436786651611
INFO:root:current mean train loss 2357.226978165957
INFO:root:current train perplexity6.424326419830322
INFO:root:current mean train loss 2357.2432614444347
INFO:root:current train perplexity6.4222822189331055
INFO:root:current mean train loss 2356.293622998101
INFO:root:current train perplexity6.4143805503845215
INFO:root:current mean train loss 2353.299589326689
INFO:root:current train perplexity6.403633117675781
INFO:root:current mean train loss 2352.109099926026
INFO:root:current train perplexity6.394874095916748
INFO:root:current mean train loss 2351.775740268526
INFO:root:current train perplexity6.391754627227783
INFO:root:current mean train loss 2351.5729999234363
INFO:root:current train perplexity6.3919172286987305
INFO:root:current mean train loss 2351.149804495812
INFO:root:current train perplexity6.390484809875488
INFO:root:current mean train loss 2351.631525190888
INFO:root:current train perplexity6.387074947357178
INFO:root:current mean train loss 2350.1740640310254
INFO:root:current train perplexity6.379868030548096
INFO:root:current mean train loss 2350.2021152826005
INFO:root:current train perplexity6.38090705871582
INFO:root:current mean train loss 2349.9450036980325
INFO:root:current train perplexity6.376508712768555
INFO:root:current mean train loss 2349.4301666628994
INFO:root:current train perplexity6.373757362365723


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:22<00:00, 142.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:22<00:00, 142.70s/it]
INFO:root:final mean train loss: 2347.9605191490955
INFO:root:final train perplexity: 6.370913505554199
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.69s/it]
INFO:root:eval mean loss: 2956.2491568717155
INFO:root:eval perplexity: 11.311477661132812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/7

  7%|â–‹         | 7/100 [18:12<4:06:55, 159.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2308.3580457899307
INFO:root:current train perplexity6.158072471618652
INFO:root:current mean train loss 2297.5435966879636
INFO:root:current train perplexity6.195527076721191
INFO:root:current mean train loss 2313.4823731588663
INFO:root:current train perplexity6.238656520843506
INFO:root:current mean train loss 2316.8961484897063
INFO:root:current train perplexity6.2377471923828125
INFO:root:current mean train loss 2315.8761082699425
INFO:root:current train perplexity6.211703777313232
INFO:root:current mean train loss 2315.5806675030917
INFO:root:current train perplexity6.207108974456787
INFO:root:current mean train loss 2315.3654151101714
INFO:root:current train perplexity6.20060920715332
INFO:root:current mean train loss 2316.4316702074993
INFO:root:current train perplexity6.2044148445129395
INFO:root:current mean train loss 2315.170279430585
INFO:root:current train perplexity6.193686485290527
INFO:root:current mean train loss 2313.5772472373283
INFO:root:current train perplexity6.189509391784668
INFO:root:current mean train loss 2310.840354454775
INFO:root:current train perplexity6.180702209472656
INFO:root:current mean train loss 2311.0631119893574
INFO:root:current train perplexity6.174700736999512
INFO:root:current mean train loss 2311.013910403197
INFO:root:current train perplexity6.171689033508301
INFO:root:current mean train loss 2311.659146622931
INFO:root:current train perplexity6.178506851196289
INFO:root:current mean train loss 2311.9324358898425
INFO:root:current train perplexity6.176457405090332
INFO:root:current mean train loss 2311.8925211106052
INFO:root:current train perplexity6.172096252441406
INFO:root:current mean train loss 2310.0483894112376
INFO:root:current train perplexity6.166275501251221
INFO:root:current mean train loss 2307.9630870885703
INFO:root:current train perplexity6.158236026763916
INFO:root:current mean train loss 2307.0476686584675
INFO:root:current train perplexity6.158171653747559
INFO:root:current mean train loss 2304.865294519132
INFO:root:current train perplexity6.154845237731934


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:22<00:00, 142.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:22<00:00, 142.73s/it]
INFO:root:final mean train loss: 2304.319304635052
INFO:root:final train perplexity: 6.155369281768799
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.20s/it]
INFO:root:eval mean loss: 2935.0791374870964
INFO:root:eval perplexity: 11.116678237915039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/8

  8%|â–Š         | 8/100 [20:53<4:05:07, 159.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2273.909068080357
INFO:root:current train perplexity5.979801177978516
INFO:root:current mean train loss 2280.0745270905672
INFO:root:current train perplexity5.990509033203125
INFO:root:current mean train loss 2272.469208153258
INFO:root:current train perplexity5.99686336517334
INFO:root:current mean train loss 2272.912876778218
INFO:root:current train perplexity6.0045037269592285
INFO:root:current mean train loss 2270.105811949982
INFO:root:current train perplexity6.0092034339904785
INFO:root:current mean train loss 2269.0608031085717
INFO:root:current train perplexity5.996860504150391
INFO:root:current mean train loss 2272.359446704294
INFO:root:current train perplexity5.995633602142334
INFO:root:current mean train loss 2274.710026207749
INFO:root:current train perplexity5.999766826629639
INFO:root:current mean train loss 2275.4041948329905
INFO:root:current train perplexity6.005086421966553
INFO:root:current mean train loss 2277.332883000501
INFO:root:current train perplexity6.008965969085693
INFO:root:current mean train loss 2275.9637871046575
INFO:root:current train perplexity6.0077948570251465
INFO:root:current mean train loss 2273.264217265797
INFO:root:current train perplexity6.000865459442139
INFO:root:current mean train loss 2271.277641660868
INFO:root:current train perplexity5.996670246124268
INFO:root:current mean train loss 2272.0504005003513
INFO:root:current train perplexity5.9986348152160645
INFO:root:current mean train loss 2271.4207618208297
INFO:root:current train perplexity5.996103763580322
INFO:root:current mean train loss 2271.8829169953683
INFO:root:current train perplexity5.993542194366455
INFO:root:current mean train loss 2270.999075177394
INFO:root:current train perplexity5.992215156555176
INFO:root:current mean train loss 2269.742581431804
INFO:root:current train perplexity5.987508296966553
INFO:root:current mean train loss 2268.301526510878
INFO:root:current train perplexity5.981924533843994
INFO:root:current mean train loss 2268.2182087269866
INFO:root:current train perplexity5.9810686111450195


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.33s/it]
INFO:root:final mean train loss: 2268.4087172915583
INFO:root:final train perplexity: 5.9834885597229
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.06s/it]
INFO:root:eval mean loss: 2918.412548534863
INFO:root:eval perplexity: 10.965680122375488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/9

  9%|â–‰         | 9/100 [23:35<4:03:43, 160.70s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2220.3113638070913
INFO:root:current train perplexity5.801715850830078
INFO:root:current mean train loss 2228.738226639597
INFO:root:current train perplexity5.762564659118652
INFO:root:current mean train loss 2239.192093137711
INFO:root:current train perplexity5.8158721923828125
INFO:root:current mean train loss 2235.462849356911
INFO:root:current train perplexity5.827386379241943
INFO:root:current mean train loss 2242.1889197425503
INFO:root:current train perplexity5.845644474029541
INFO:root:current mean train loss 2244.2082119264464
INFO:root:current train perplexity5.852705478668213
INFO:root:current mean train loss 2247.428587369392
INFO:root:current train perplexity5.86236047744751
INFO:root:current mean train loss 2243.705139322484
INFO:root:current train perplexity5.851861953735352
INFO:root:current mean train loss 2243.323005927001
INFO:root:current train perplexity5.854388236999512
INFO:root:current mean train loss 2240.432005040786
INFO:root:current train perplexity5.8487229347229
INFO:root:current mean train loss 2241.5437671965974
INFO:root:current train perplexity5.852043151855469
INFO:root:current mean train loss 2240.9617993036904
INFO:root:current train perplexity5.844732761383057
INFO:root:current mean train loss 2240.4948259542543
INFO:root:current train perplexity5.844080924987793
INFO:root:current mean train loss 2241.125251273432
INFO:root:current train perplexity5.850293159484863
INFO:root:current mean train loss 2240.049010053482
INFO:root:current train perplexity5.846889495849609
INFO:root:current mean train loss 2237.4284605832445
INFO:root:current train perplexity5.838848114013672
INFO:root:current mean train loss 2237.2873747227554
INFO:root:current train perplexity5.834975242614746
INFO:root:current mean train loss 2238.7445615306838
INFO:root:current train perplexity5.838513374328613
INFO:root:current mean train loss 2237.00641758962
INFO:root:current train perplexity5.833683490753174
INFO:root:current mean train loss 2237.0473652198666
INFO:root:current train perplexity5.83354377746582


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:22<00:00, 142.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:22<00:00, 142.03s/it]
INFO:root:final mean train loss: 2236.184984108083
INFO:root:final train perplexity: 5.8333420753479
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.77s/it]
INFO:root:eval mean loss: 2900.9323583837745
INFO:root:eval perplexity: 10.809514045715332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/10

 10%|â–ˆ         | 10/100 [26:15<4:00:41, 160.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2226.6559333248415
INFO:root:current train perplexity5.732653617858887
INFO:root:current mean train loss 2229.1770785179365
INFO:root:current train perplexity5.722093105316162
INFO:root:current mean train loss 2210.8354433194413
INFO:root:current train perplexity5.683662414550781
INFO:root:current mean train loss 2209.999355243797
INFO:root:current train perplexity5.689492225646973
INFO:root:current mean train loss 2211.331147086137
INFO:root:current train perplexity5.692270755767822
INFO:root:current mean train loss 2214.6902960323073
INFO:root:current train perplexity5.7032928466796875
INFO:root:current mean train loss 2210.777988770261
INFO:root:current train perplexity5.696422576904297
INFO:root:current mean train loss 2212.2296045747316
INFO:root:current train perplexity5.708100318908691
INFO:root:current mean train loss 2213.7032642079166
INFO:root:current train perplexity5.704539775848389
INFO:root:current mean train loss 2212.924936835857
INFO:root:current train perplexity5.706482887268066
INFO:root:current mean train loss 2211.543665430053
INFO:root:current train perplexity5.708648681640625
INFO:root:current mean train loss 2211.5235609278097
INFO:root:current train perplexity5.709072589874268
INFO:root:current mean train loss 2210.9289940367353
INFO:root:current train perplexity5.7060041427612305
INFO:root:current mean train loss 2211.332243646994
INFO:root:current train perplexity5.70780611038208
INFO:root:current mean train loss 2212.0185936602547
INFO:root:current train perplexity5.708860874176025
INFO:root:current mean train loss 2210.177386291776
INFO:root:current train perplexity5.705564022064209
INFO:root:current mean train loss 2209.2740351983784
INFO:root:current train perplexity5.704338550567627
INFO:root:current mean train loss 2208.180275976894
INFO:root:current train perplexity5.703232765197754
INFO:root:current mean train loss 2207.2805088914733
INFO:root:current train perplexity5.702271461486816
INFO:root:current mean train loss 2208.702680116017
INFO:root:current train perplexity5.706100940704346


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.94s/it]
INFO:root:final mean train loss: 2208.2371404804608
INFO:root:final train perplexity: 5.706172943115234
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.95s/it]
INFO:root:eval mean loss: 2884.6729952608857
INFO:root:eval perplexity: 10.666252136230469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/11

 11%|â–ˆ         | 11/100 [29:07<4:03:18, 164.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2210.726366619731
INFO:root:current train perplexity5.636340141296387
INFO:root:current mean train loss 2181.6622839486727
INFO:root:current train perplexity5.585217475891113
INFO:root:current mean train loss 2184.406760049033
INFO:root:current train perplexity5.591283798217773
INFO:root:current mean train loss 2193.298516308088
INFO:root:current train perplexity5.618885517120361
INFO:root:current mean train loss 2188.6232636377154
INFO:root:current train perplexity5.599783897399902
INFO:root:current mean train loss 2188.0540275703925
INFO:root:current train perplexity5.59426212310791
INFO:root:current mean train loss 2189.3754886371403
INFO:root:current train perplexity5.599205017089844
INFO:root:current mean train loss 2189.0329647306876
INFO:root:current train perplexity5.605499744415283
INFO:root:current mean train loss 2186.6910534034196
INFO:root:current train perplexity5.602113723754883
INFO:root:current mean train loss 2186.6805677433285
INFO:root:current train perplexity5.605519771575928
INFO:root:current mean train loss 2183.1702683029034
INFO:root:current train perplexity5.596105098724365
INFO:root:current mean train loss 2186.276313974725
INFO:root:current train perplexity5.601415157318115
INFO:root:current mean train loss 2184.994382582408
INFO:root:current train perplexity5.599367618560791
INFO:root:current mean train loss 2185.110722000981
INFO:root:current train perplexity5.600780010223389
INFO:root:current mean train loss 2184.687383022796
INFO:root:current train perplexity5.598982334136963
INFO:root:current mean train loss 2184.345761851134
INFO:root:current train perplexity5.596487998962402
INFO:root:current mean train loss 2184.3077766898123
INFO:root:current train perplexity5.596108913421631
INFO:root:current mean train loss 2184.368408203125
INFO:root:current train perplexity5.597337245941162
INFO:root:current mean train loss 2184.455066862946
INFO:root:current train perplexity5.597523212432861


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.24s/it]
INFO:root:final mean train loss: 2184.203822056573
INFO:root:final train perplexity: 5.59903621673584
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.66s/it]
INFO:root:eval mean loss: 2872.3089002088027
INFO:root:eval perplexity: 10.55858325958252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/12

 12%|â–ˆâ–        | 12/100 [31:48<3:59:16, 163.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2049.191446940104
INFO:root:current train perplexity5.1160783767700195
INFO:root:current mean train loss 2160.189583491353
INFO:root:current train perplexity5.483498573303223
INFO:root:current mean train loss 2165.9851585350602
INFO:root:current train perplexity5.5093865394592285
INFO:root:current mean train loss 2161.5134462665014
INFO:root:current train perplexity5.502929210662842
INFO:root:current mean train loss 2156.6155724158652
INFO:root:current train perplexity5.496926784515381
INFO:root:current mean train loss 2160.670377879209
INFO:root:current train perplexity5.510532379150391
INFO:root:current mean train loss 2159.0936771222014
INFO:root:current train perplexity5.510003566741943
INFO:root:current mean train loss 2157.2301942220283
INFO:root:current train perplexity5.504087924957275
INFO:root:current mean train loss 2157.1293474057247
INFO:root:current train perplexity5.499543190002441
INFO:root:current mean train loss 2160.457448695321
INFO:root:current train perplexity5.504238128662109
INFO:root:current mean train loss 2160.1269623745948
INFO:root:current train perplexity5.501617431640625
INFO:root:current mean train loss 2158.940418067026
INFO:root:current train perplexity5.497986316680908
INFO:root:current mean train loss 2157.824551170901
INFO:root:current train perplexity5.49989652633667
INFO:root:current mean train loss 2157.118631826944
INFO:root:current train perplexity5.498420238494873
INFO:root:current mean train loss 2157.4068888897395
INFO:root:current train perplexity5.497589588165283
INFO:root:current mean train loss 2157.941891932281
INFO:root:current train perplexity5.49343204498291
INFO:root:current mean train loss 2160.0357868577717
INFO:root:current train perplexity5.495134353637695
INFO:root:current mean train loss 2159.0608249917427
INFO:root:current train perplexity5.494019985198975
INFO:root:current mean train loss 2160.122153385308
INFO:root:current train perplexity5.496683597564697
INFO:root:current mean train loss 2161.0625517660233
INFO:root:current train perplexity5.49833345413208


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.62s/it]
INFO:root:final mean train loss: 2161.532109170626
INFO:root:final train perplexity: 5.499813556671143
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.59s/it]
INFO:root:eval mean loss: 2873.376806493994
INFO:root:eval perplexity: 10.567838668823242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/13

 13%|â–ˆâ–Ž        | 13/100 [34:41<4:00:36, 165.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2213.960333251953
INFO:root:current train perplexity5.505437850952148
INFO:root:current mean train loss 2147.755792236328
INFO:root:current train perplexity5.397141933441162
INFO:root:current mean train loss 2153.0664722789415
INFO:root:current train perplexity5.421698570251465
INFO:root:current mean train loss 2143.3334568023683
INFO:root:current train perplexity5.403628349304199
INFO:root:current mean train loss 2146.3696338471914
INFO:root:current train perplexity5.403876304626465
INFO:root:current mean train loss 2147.0435218224156
INFO:root:current train perplexity5.41904878616333
INFO:root:current mean train loss 2146.3321869880924
INFO:root:current train perplexity5.415655136108398
INFO:root:current mean train loss 2147.556430731879
INFO:root:current train perplexity5.418792247772217
INFO:root:current mean train loss 2148.1281912454747
INFO:root:current train perplexity5.421405792236328
INFO:root:current mean train loss 2148.7208987028703
INFO:root:current train perplexity5.422441482543945
INFO:root:current mean train loss 2146.619957299326
INFO:root:current train perplexity5.422374248504639
INFO:root:current mean train loss 2147.156724330357
INFO:root:current train perplexity5.424962520599365
INFO:root:current mean train loss 2144.702496738121
INFO:root:current train perplexity5.424962997436523
INFO:root:current mean train loss 2143.5407048080906
INFO:root:current train perplexity5.424040794372559
INFO:root:current mean train loss 2142.9669387172644
INFO:root:current train perplexity5.417881011962891
INFO:root:current mean train loss 2142.013564742239
INFO:root:current train perplexity5.4164299964904785
INFO:root:current mean train loss 2142.047796254099
INFO:root:current train perplexity5.414693832397461
INFO:root:current mean train loss 2141.8455437948537
INFO:root:current train perplexity5.41343879699707
INFO:root:current mean train loss 2142.399889533074
INFO:root:current train perplexity5.416361331939697
INFO:root:current mean train loss 2143.3596605936687
INFO:root:current train perplexity5.417444229125977


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.23s/it]
INFO:root:final mean train loss: 2142.2938462034717
INFO:root:final train perplexity: 5.41699743270874
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.77s/it]
INFO:root:eval mean loss: 2858.841912713495
INFO:root:eval perplexity: 10.442545890808105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/14

 14%|â–ˆâ–        | 14/100 [37:24<3:56:37, 165.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2100.4034687763938
INFO:root:current train perplexity5.271693229675293
INFO:root:current mean train loss 2102.8142918496237
INFO:root:current train perplexity5.310642242431641
INFO:root:current mean train loss 2116.4801118102255
INFO:root:current train perplexity5.326794624328613
INFO:root:current mean train loss 2113.504905632766
INFO:root:current train perplexity5.323378086090088
INFO:root:current mean train loss 2113.1911531705878
INFO:root:current train perplexity5.335020065307617
INFO:root:current mean train loss 2116.3941132103264
INFO:root:current train perplexity5.336800575256348
INFO:root:current mean train loss 2115.7899346224367
INFO:root:current train perplexity5.3276047706604
INFO:root:current mean train loss 2113.727968047723
INFO:root:current train perplexity5.327938079833984
INFO:root:current mean train loss 2115.0324539312182
INFO:root:current train perplexity5.32941198348999
INFO:root:current mean train loss 2116.5358673063133
INFO:root:current train perplexity5.334678649902344
INFO:root:current mean train loss 2117.13575042754
INFO:root:current train perplexity5.336594104766846
INFO:root:current mean train loss 2119.883134692619
INFO:root:current train perplexity5.3395609855651855
INFO:root:current mean train loss 2121.953120164555
INFO:root:current train perplexity5.344583988189697
INFO:root:current mean train loss 2122.0909479522134
INFO:root:current train perplexity5.344546318054199
INFO:root:current mean train loss 2122.4327854695384
INFO:root:current train perplexity5.340210437774658
INFO:root:current mean train loss 2123.599874323967
INFO:root:current train perplexity5.346238613128662
INFO:root:current mean train loss 2123.4013476502846
INFO:root:current train perplexity5.344052314758301
INFO:root:current mean train loss 2124.0166267917702
INFO:root:current train perplexity5.340285778045654
INFO:root:current mean train loss 2123.9640278657885
INFO:root:current train perplexity5.338021278381348
INFO:root:current mean train loss 2124.8149399567833
INFO:root:current train perplexity5.338817119598389


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:23<00:00, 143.33s/it]
INFO:root:final mean train loss: 2123.5858431001893
INFO:root:final train perplexity: 5.3376617431640625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.15s/it]
INFO:root:eval mean loss: 2854.0093572576484
INFO:root:eval perplexity: 10.40121841430664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/15

 15%|â–ˆâ–Œ        | 15/100 [40:06<3:52:25, 164.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2112.0356422706886
INFO:root:current train perplexity5.230484485626221
INFO:root:current mean train loss 2104.7702731838476
INFO:root:current train perplexity5.202838897705078
INFO:root:current mean train loss 2102.040047713152
INFO:root:current train perplexity5.236361980438232
INFO:root:current mean train loss 2099.115736794337
INFO:root:current train perplexity5.24765157699585
INFO:root:current mean train loss 2100.1392295266037
INFO:root:current train perplexity5.248095512390137
INFO:root:current mean train loss 2099.2407325717086
INFO:root:current train perplexity5.249387264251709
INFO:root:current mean train loss 2100.602858423822
INFO:root:current train perplexity5.247755527496338
INFO:root:current mean train loss 2102.3365057583514
INFO:root:current train perplexity5.256165981292725
INFO:root:current mean train loss 2103.2860164597664
INFO:root:current train perplexity5.2547807693481445
INFO:root:current mean train loss 2101.8595596409446
INFO:root:current train perplexity5.253161907196045
INFO:root:current mean train loss 2102.2557209745983
INFO:root:current train perplexity5.252548694610596
INFO:root:current mean train loss 2101.685335737787
INFO:root:current train perplexity5.254589080810547
INFO:root:current mean train loss 2103.64420251679
INFO:root:current train perplexity5.2592973709106445
INFO:root:current mean train loss 2105.7982925122033
INFO:root:current train perplexity5.265107154846191
INFO:root:current mean train loss 2105.4136036868927
INFO:root:current train perplexity5.2618279457092285
INFO:root:current mean train loss 2105.7173015736857
INFO:root:current train perplexity5.263894081115723
INFO:root:current mean train loss 2105.1486163986924
INFO:root:current train perplexity5.262736797332764
INFO:root:current mean train loss 2105.3449683368817
INFO:root:current train perplexity5.262642860412598
INFO:root:current mean train loss 2105.2907196012
INFO:root:current train perplexity5.263211250305176
INFO:root:current mean train loss 2106.806121857408
INFO:root:current train perplexity5.26521635055542


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.10s/it]
INFO:root:final mean train loss: 2106.4731566582554
INFO:root:final train perplexity: 5.266107082366943
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.44s/it]
INFO:root:eval mean loss: 2845.72595031555
INFO:root:eval perplexity: 10.330758094787598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/16

 16%|â–ˆâ–Œ        | 16/100 [42:53<3:51:12, 165.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2105.844521965779
INFO:root:current train perplexity5.274017810821533
INFO:root:current mean train loss 2084.5676426580776
INFO:root:current train perplexity5.208452224731445
INFO:root:current mean train loss 2083.1068853962465
INFO:root:current train perplexity5.214413166046143
INFO:root:current mean train loss 2084.7012814421537
INFO:root:current train perplexity5.207912921905518
INFO:root:current mean train loss 2086.2347070001492
INFO:root:current train perplexity5.203406810760498
INFO:root:current mean train loss 2087.2604020581352
INFO:root:current train perplexity5.197608470916748
INFO:root:current mean train loss 2086.123656498871
INFO:root:current train perplexity5.195764064788818
INFO:root:current mean train loss 2088.6723487151426
INFO:root:current train perplexity5.195481777191162
INFO:root:current mean train loss 2087.295967531259
INFO:root:current train perplexity5.19559383392334
INFO:root:current mean train loss 2088.293831665165
INFO:root:current train perplexity5.19495964050293
INFO:root:current mean train loss 2088.1187559496457
INFO:root:current train perplexity5.192054748535156
INFO:root:current mean train loss 2089.1745484545127
INFO:root:current train perplexity5.191857814788818
INFO:root:current mean train loss 2088.0980700981327
INFO:root:current train perplexity5.191833972930908
INFO:root:current mean train loss 2088.305893779062
INFO:root:current train perplexity5.195152282714844
INFO:root:current mean train loss 2088.207150747791
INFO:root:current train perplexity5.196275234222412
INFO:root:current mean train loss 2089.061041605541
INFO:root:current train perplexity5.199159145355225
INFO:root:current mean train loss 2088.866093104218
INFO:root:current train perplexity5.194721698760986
INFO:root:current mean train loss 2089.9945188982215
INFO:root:current train perplexity5.199137210845947
INFO:root:current mean train loss 2089.9486774259044
INFO:root:current train perplexity5.200272560119629
INFO:root:current mean train loss 2091.3652973610515
INFO:root:current train perplexity5.202280044555664


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.67s/it]
INFO:root:final mean train loss: 2091.260880262997
INFO:root:final train perplexity: 5.203305721282959
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.97s/it]
INFO:root:eval mean loss: 2843.2824369779937
INFO:root:eval perplexity: 10.310067176818848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/17

 17%|â–ˆâ–‹        | 17/100 [45:39<3:48:43, 165.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2055.643725308505
INFO:root:current train perplexity5.077605247497559
INFO:root:current mean train loss 2065.5259295524434
INFO:root:current train perplexity5.104343414306641
INFO:root:current mean train loss 2072.5567071702744
INFO:root:current train perplexity5.113940715789795
INFO:root:current mean train loss 2064.8396260369686
INFO:root:current train perplexity5.10546350479126
INFO:root:current mean train loss 2069.0427923984216
INFO:root:current train perplexity5.124413967132568
INFO:root:current mean train loss 2071.929158943851
INFO:root:current train perplexity5.129223823547363
INFO:root:current mean train loss 2072.789488149244
INFO:root:current train perplexity5.134180068969727
INFO:root:current mean train loss 2071.0539925667235
INFO:root:current train perplexity5.133068084716797
INFO:root:current mean train loss 2072.069510932441
INFO:root:current train perplexity5.134037494659424
INFO:root:current mean train loss 2075.9047795963675
INFO:root:current train perplexity5.13824987411499
INFO:root:current mean train loss 2077.2922161326687
INFO:root:current train perplexity5.13750696182251
INFO:root:current mean train loss 2077.139934706768
INFO:root:current train perplexity5.13337516784668
INFO:root:current mean train loss 2074.9960792494117
INFO:root:current train perplexity5.131299018859863
INFO:root:current mean train loss 2074.334593319412
INFO:root:current train perplexity5.129416465759277
INFO:root:current mean train loss 2074.570553523238
INFO:root:current train perplexity5.129354000091553
INFO:root:current mean train loss 2074.9345578594834
INFO:root:current train perplexity5.133911609649658
INFO:root:current mean train loss 2075.9550491983855
INFO:root:current train perplexity5.137792587280273
INFO:root:current mean train loss 2076.0048058016987
INFO:root:current train perplexity5.140460014343262
INFO:root:current mean train loss 2076.260247182038
INFO:root:current train perplexity5.142024993896484


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.20s/it]
INFO:root:final mean train loss: 2076.30182294129
INFO:root:final train perplexity: 5.142279624938965
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.86s/it]
INFO:root:eval mean loss: 2843.1437152484514
INFO:root:eval perplexity: 10.308892250061035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/18

 18%|â–ˆâ–Š        | 18/100 [48:29<3:47:57, 166.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2088.5234130859376
INFO:root:current train perplexity5.182481288909912
INFO:root:current mean train loss 2058.359308733259
INFO:root:current train perplexity5.080323219299316
INFO:root:current mean train loss 2061.80766542016
INFO:root:current train perplexity5.078671455383301
INFO:root:current mean train loss 2065.483085056993
INFO:root:current train perplexity5.091254234313965
INFO:root:current mean train loss 2061.750454222126
INFO:root:current train perplexity5.087151050567627
INFO:root:current mean train loss 2060.220944848391
INFO:root:current train perplexity5.082422256469727
INFO:root:current mean train loss 2063.964149664256
INFO:root:current train perplexity5.089450836181641
INFO:root:current mean train loss 2063.27933323637
INFO:root:current train perplexity5.091870307922363
INFO:root:current mean train loss 2063.5344840292605
INFO:root:current train perplexity5.086905479431152
INFO:root:current mean train loss 2064.983614117533
INFO:root:current train perplexity5.09194278717041
INFO:root:current mean train loss 2067.190428837259
INFO:root:current train perplexity5.0963544845581055
INFO:root:current mean train loss 2065.3343104850114
INFO:root:current train perplexity5.089802265167236
INFO:root:current mean train loss 2064.8200099074493
INFO:root:current train perplexity5.087526798248291
INFO:root:current mean train loss 2063.8226753322556
INFO:root:current train perplexity5.086511135101318
INFO:root:current mean train loss 2063.762019016904
INFO:root:current train perplexity5.085675239562988
INFO:root:current mean train loss 2062.3354870159365
INFO:root:current train perplexity5.08467960357666
INFO:root:current mean train loss 2061.1965982312354
INFO:root:current train perplexity5.082424163818359
INFO:root:current mean train loss 2062.0121591338666
INFO:root:current train perplexity5.084265232086182
INFO:root:current mean train loss 2061.0905514196675
INFO:root:current train perplexity5.0818023681640625
INFO:root:current mean train loss 2061.58566676663
INFO:root:current train perplexity5.083860874176025


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:36<00:00, 156.23s/it]
INFO:root:final mean train loss: 2062.426596067797
INFO:root:final train perplexity: 5.086315155029297
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.92s/it]
INFO:root:eval mean loss: 2839.972413575685
INFO:root:eval perplexity: 10.282099723815918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/19

 19%|â–ˆâ–‰        | 19/100 [51:25<3:48:38, 169.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2011.6315973455255
INFO:root:current train perplexity4.950150012969971
INFO:root:current mean train loss 2035.7096587634478
INFO:root:current train perplexity4.95982551574707
INFO:root:current mean train loss 2034.2361681139148
INFO:root:current train perplexity4.9755330085754395
INFO:root:current mean train loss 2035.8414954902223
INFO:root:current train perplexity4.980417728424072
INFO:root:current mean train loss 2044.4703059625851
INFO:root:current train perplexity4.986813545227051
INFO:root:current mean train loss 2045.9407666670409
INFO:root:current train perplexity4.998217582702637
INFO:root:current mean train loss 2046.1418172462193
INFO:root:current train perplexity5.006932258605957
INFO:root:current mean train loss 2044.4680118296615
INFO:root:current train perplexity5.00969123840332
INFO:root:current mean train loss 2047.0911565256235
INFO:root:current train perplexity5.011929988861084
INFO:root:current mean train loss 2048.1778353941413
INFO:root:current train perplexity5.013996601104736
INFO:root:current mean train loss 2047.310773218681
INFO:root:current train perplexity5.017587661743164
INFO:root:current mean train loss 2047.3658588701817
INFO:root:current train perplexity5.020617485046387
INFO:root:current mean train loss 2048.4745734132057
INFO:root:current train perplexity5.0239739418029785
INFO:root:current mean train loss 2050.355706334655
INFO:root:current train perplexity5.030253887176514
INFO:root:current mean train loss 2050.4553875929864
INFO:root:current train perplexity5.02921199798584
INFO:root:current mean train loss 2051.0452875245105
INFO:root:current train perplexity5.031745910644531
INFO:root:current mean train loss 2050.765297773293
INFO:root:current train perplexity5.0311198234558105
INFO:root:current mean train loss 2050.965666413169
INFO:root:current train perplexity5.035296440124512
INFO:root:current mean train loss 2051.771250887053
INFO:root:current train perplexity5.038791179656982
INFO:root:current mean train loss 2052.098636115131
INFO:root:current train perplexity5.039802551269531


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:34<00:00, 154.80s/it]
INFO:root:final mean train loss: 2050.138928819773
INFO:root:final train perplexity: 5.037263870239258
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:18<00:00, 18.08s/it]
INFO:root:eval mean loss: 2832.818019191066
INFO:root:eval perplexity: 10.221915245056152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/20

 20%|â–ˆâ–ˆ        | 20/100 [54:19<3:47:42, 170.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2019.077139047476
INFO:root:current train perplexity4.952711582183838
INFO:root:current mean train loss 2048.9757844115334
INFO:root:current train perplexity4.97458553314209
INFO:root:current mean train loss 2044.5623804834597
INFO:root:current train perplexity4.970290660858154
INFO:root:current mean train loss 2044.2686933219256
INFO:root:current train perplexity4.974238395690918
INFO:root:current mean train loss 2041.6479989922943
INFO:root:current train perplexity4.9739861488342285
INFO:root:current mean train loss 2041.50401020227
INFO:root:current train perplexity4.980964660644531
INFO:root:current mean train loss 2039.3057998872139
INFO:root:current train perplexity4.985039710998535
INFO:root:current mean train loss 2040.671606577459
INFO:root:current train perplexity4.98649787902832
INFO:root:current mean train loss 2039.212356803812
INFO:root:current train perplexity4.986968040466309
INFO:root:current mean train loss 2039.3346874167999
INFO:root:current train perplexity4.984600067138672
INFO:root:current mean train loss 2038.7122981316545
INFO:root:current train perplexity4.983299255371094
INFO:root:current mean train loss 2039.5434426700367
INFO:root:current train perplexity4.985717296600342
INFO:root:current mean train loss 2038.0454884822375
INFO:root:current train perplexity4.982043266296387
INFO:root:current mean train loss 2039.4190068490652
INFO:root:current train perplexity4.985257148742676
INFO:root:current mean train loss 2039.9826985054997
INFO:root:current train perplexity4.989830017089844
INFO:root:current mean train loss 2041.1882104508052
INFO:root:current train perplexity4.99425745010376
INFO:root:current mean train loss 2039.8625682670215
INFO:root:current train perplexity4.991820812225342
INFO:root:current mean train loss 2040.1136851560254
INFO:root:current train perplexity4.993753910064697
INFO:root:current mean train loss 2040.1012742175817
INFO:root:current train perplexity4.992868900299072
INFO:root:current mean train loss 2039.1843094257672
INFO:root:current train perplexity4.992054462432861


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:33<00:00, 153.67s/it]
INFO:root:final mean train loss: 2038.035752627805
INFO:root:final train perplexity: 4.989409923553467
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.80s/it]
INFO:root:eval mean loss: 2837.8784128366647
INFO:root:eval perplexity: 10.264447212219238
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/21

 21%|â–ˆâ–ˆ        | 21/100 [57:11<3:45:35, 171.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2003.1835523332868
INFO:root:current train perplexity4.9388837814331055
INFO:root:current mean train loss 2012.634981595553
INFO:root:current train perplexity4.93585205078125
INFO:root:current mean train loss 2017.3066267967224
INFO:root:current train perplexity4.943160533905029
INFO:root:current mean train loss 2022.592237493965
INFO:root:current train perplexity4.952676296234131
INFO:root:current mean train loss 2023.7774446721662
INFO:root:current train perplexity4.952010154724121
INFO:root:current mean train loss 2023.7575938272819
INFO:root:current train perplexity4.939828872680664
INFO:root:current mean train loss 2022.0365801555354
INFO:root:current train perplexity4.93778133392334
INFO:root:current mean train loss 2022.9413831599807
INFO:root:current train perplexity4.935080051422119
INFO:root:current mean train loss 2023.1497096837124
INFO:root:current train perplexity4.937239170074463
INFO:root:current mean train loss 2025.173607351391
INFO:root:current train perplexity4.9390435218811035
INFO:root:current mean train loss 2025.1138447848234
INFO:root:current train perplexity4.939844608306885
INFO:root:current mean train loss 2025.4043754392842
INFO:root:current train perplexity4.9391889572143555
INFO:root:current mean train loss 2025.1232430038938
INFO:root:current train perplexity4.936676502227783
INFO:root:current mean train loss 2026.13149907385
INFO:root:current train perplexity4.940232753753662
INFO:root:current mean train loss 2026.698001568134
INFO:root:current train perplexity4.93988561630249
INFO:root:current mean train loss 2026.956175737945
INFO:root:current train perplexity4.940598964691162
INFO:root:current mean train loss 2027.6121406002321
INFO:root:current train perplexity4.940296649932861
INFO:root:current mean train loss 2027.8198190050407
INFO:root:current train perplexity4.942079067230225
INFO:root:current mean train loss 2028.4206864587193
INFO:root:current train perplexity4.9447760581970215
INFO:root:current mean train loss 2027.9465293962287
INFO:root:current train perplexity4.946918487548828


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.30s/it]
INFO:root:final mean train loss: 2027.501044153626
INFO:root:final train perplexity: 4.948127746582031
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.53s/it]
INFO:root:eval mean loss: 2832.0226266305367
INFO:root:eval perplexity: 10.21524429321289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/22

 22%|â–ˆâ–ˆâ–       | 22/100 [1:00:00<3:41:49, 170.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2007.8365662457193
INFO:root:current train perplexity4.896545886993408
INFO:root:current mean train loss 2014.8878124435514
INFO:root:current train perplexity4.889920234680176
INFO:root:current mean train loss 2013.0686401814332
INFO:root:current train perplexity4.886830806732178
INFO:root:current mean train loss 2011.695049050666
INFO:root:current train perplexity4.892903804779053
INFO:root:current mean train loss 2008.8003809729287
INFO:root:current train perplexity4.8730902671813965
INFO:root:current mean train loss 2011.3274062125054
INFO:root:current train perplexity4.8824782371521
INFO:root:current mean train loss 2011.9225383152047
INFO:root:current train perplexity4.88707971572876
INFO:root:current mean train loss 2010.1263165591142
INFO:root:current train perplexity4.885824680328369
INFO:root:current mean train loss 2010.687681357612
INFO:root:current train perplexity4.888108253479004
INFO:root:current mean train loss 2013.1568421602003
INFO:root:current train perplexity4.892139434814453
INFO:root:current mean train loss 2015.24457407131
INFO:root:current train perplexity4.897704601287842
INFO:root:current mean train loss 2015.1980056437487
INFO:root:current train perplexity4.897653102874756
INFO:root:current mean train loss 2014.9759736282097
INFO:root:current train perplexity4.899240016937256
INFO:root:current mean train loss 2014.321781611321
INFO:root:current train perplexity4.89888334274292
INFO:root:current mean train loss 2015.4364787695445
INFO:root:current train perplexity4.898854732513428
INFO:root:current mean train loss 2016.9821477018188
INFO:root:current train perplexity4.905734539031982
INFO:root:current mean train loss 2017.2975710853445
INFO:root:current train perplexity4.904616832733154
INFO:root:current mean train loss 2016.253833751388
INFO:root:current train perplexity4.9013752937316895
INFO:root:current mean train loss 2016.4743450305325
INFO:root:current train perplexity4.902073383331299
INFO:root:current mean train loss 2016.9254059441128
INFO:root:current train perplexity4.904254913330078


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:31<00:00, 151.70s/it]
INFO:root:final mean train loss: 2016.0067146366675
INFO:root:final train perplexity: 4.903474807739258
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.78s/it]
INFO:root:eval mean loss: 2832.631060992633
INFO:root:eval perplexity: 10.220348358154297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/23

 23%|â–ˆâ–ˆâ–Ž       | 23/100 [1:02:58<3:41:40, 172.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2020.8730590820312
INFO:root:current train perplexity4.854691028594971
INFO:root:current mean train loss 2003.6290758634868
INFO:root:current train perplexity4.822092056274414
INFO:root:current mean train loss 2004.3860292632005
INFO:root:current train perplexity4.83521032333374
INFO:root:current mean train loss 2009.3689368614785
INFO:root:current train perplexity4.849541664123535
INFO:root:current mean train loss 2000.9516870615435
INFO:root:current train perplexity4.835958957672119
INFO:root:current mean train loss 2004.2916141833289
INFO:root:current train perplexity4.846404552459717
INFO:root:current mean train loss 2006.592139733356
INFO:root:current train perplexity4.854742527008057
INFO:root:current mean train loss 2007.8857842167722
INFO:root:current train perplexity4.853930950164795
INFO:root:current mean train loss 2006.9360754806005
INFO:root:current train perplexity4.854109287261963
INFO:root:current mean train loss 2008.8599693221274
INFO:root:current train perplexity4.862220764160156
INFO:root:current mean train loss 2006.7590263716672
INFO:root:current train perplexity4.861464023590088
INFO:root:current mean train loss 2005.2922180688681
INFO:root:current train perplexity4.853696823120117
INFO:root:current mean train loss 2004.3349193011143
INFO:root:current train perplexity4.8495097160339355
INFO:root:current mean train loss 2003.9477453876743
INFO:root:current train perplexity4.851428985595703
INFO:root:current mean train loss 2004.508665599439
INFO:root:current train perplexity4.855210781097412
INFO:root:current mean train loss 2006.1663077492385
INFO:root:current train perplexity4.860558032989502
INFO:root:current mean train loss 2005.5427204922107
INFO:root:current train perplexity4.862077236175537
INFO:root:current mean train loss 2005.929905726257
INFO:root:current train perplexity4.863790512084961
INFO:root:current mean train loss 2006.5209190409018
INFO:root:current train perplexity4.865577220916748


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.69s/it]
INFO:root:final mean train loss: 2006.1817597405093
INFO:root:final train perplexity: 4.865626811981201
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.49s/it]
INFO:root:eval mean loss: 2826.044295760604
INFO:root:eval perplexity: 10.165254592895508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/24

 24%|â–ˆâ–ˆâ–       | 24/100 [1:05:45<3:36:43, 171.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1923.4727434430804
INFO:root:current train perplexity4.70195198059082
INFO:root:current mean train loss 1966.8280611127336
INFO:root:current train perplexity4.75333833694458
INFO:root:current mean train loss 1978.352166954446
INFO:root:current train perplexity4.7802276611328125
INFO:root:current mean train loss 1984.3406894944778
INFO:root:current train perplexity4.799886703491211
INFO:root:current mean train loss 1985.3192435599663
INFO:root:current train perplexity4.798666000366211
INFO:root:current mean train loss 1985.3579599956083
INFO:root:current train perplexity4.795935153961182
INFO:root:current mean train loss 1987.0988057622014
INFO:root:current train perplexity4.804659843444824
INFO:root:current mean train loss 1990.6025506306908
INFO:root:current train perplexity4.814931392669678
INFO:root:current mean train loss 1989.784794879521
INFO:root:current train perplexity4.812586784362793
INFO:root:current mean train loss 1991.2420227656423
INFO:root:current train perplexity4.815993785858154
INFO:root:current mean train loss 1991.593684297806
INFO:root:current train perplexity4.820016860961914
INFO:root:current mean train loss 1992.73426858821
INFO:root:current train perplexity4.820031642913818
INFO:root:current mean train loss 1995.9041812773469
INFO:root:current train perplexity4.829984188079834
INFO:root:current mean train loss 1995.4630999284202
INFO:root:current train perplexity4.827861785888672
INFO:root:current mean train loss 1995.50792641494
INFO:root:current train perplexity4.82808256149292
INFO:root:current mean train loss 1996.7068441349224
INFO:root:current train perplexity4.829263687133789
INFO:root:current mean train loss 1998.456318881991
INFO:root:current train perplexity4.831573963165283
INFO:root:current mean train loss 1997.6349626394763
INFO:root:current train perplexity4.831352710723877
INFO:root:current mean train loss 1997.645523417504
INFO:root:current train perplexity4.831737518310547
INFO:root:current mean train loss 1997.282675732601
INFO:root:current train perplexity4.831012725830078


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.04s/it]
INFO:root:final mean train loss: 1996.7207856132595
INFO:root:final train perplexity: 4.8294572830200195
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.90s/it]
INFO:root:eval mean loss: 2828.0846295514266
INFO:root:eval perplexity: 10.182289123535156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/25

 25%|â–ˆâ–ˆâ–Œ       | 25/100 [1:08:32<3:32:22, 169.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1969.401138305664
INFO:root:current train perplexity4.750380516052246
INFO:root:current mean train loss 1959.976571359942
INFO:root:current train perplexity4.77268648147583
INFO:root:current mean train loss 1973.126746586391
INFO:root:current train perplexity4.789432525634766
INFO:root:current mean train loss 1980.1961157527971
INFO:root:current train perplexity4.779911518096924
INFO:root:current mean train loss 1979.0515620393573
INFO:root:current train perplexity4.775435447692871
INFO:root:current mean train loss 1980.883736180895
INFO:root:current train perplexity4.775273323059082
INFO:root:current mean train loss 1984.3715051504282
INFO:root:current train perplexity4.784450531005859
INFO:root:current mean train loss 1986.4435603526415
INFO:root:current train perplexity4.790943145751953
INFO:root:current mean train loss 1987.2391723336525
INFO:root:current train perplexity4.789957523345947
INFO:root:current mean train loss 1986.0871900418103
INFO:root:current train perplexity4.784037113189697
INFO:root:current mean train loss 1986.903680562973
INFO:root:current train perplexity4.790970325469971
INFO:root:current mean train loss 1987.606700965094
INFO:root:current train perplexity4.788086414337158
INFO:root:current mean train loss 1986.387061324774
INFO:root:current train perplexity4.783308029174805
INFO:root:current mean train loss 1986.3800117054734
INFO:root:current train perplexity4.785788059234619
INFO:root:current mean train loss 1987.3894443297654
INFO:root:current train perplexity4.787879467010498
INFO:root:current mean train loss 1987.862704780158
INFO:root:current train perplexity4.789313793182373
INFO:root:current mean train loss 1988.6132621577221
INFO:root:current train perplexity4.790165424346924
INFO:root:current mean train loss 1989.606032156889
INFO:root:current train perplexity4.793092727661133
INFO:root:current mean train loss 1988.6799876564428
INFO:root:current train perplexity4.7945990562438965
INFO:root:current mean train loss 1988.924451102338
INFO:root:current train perplexity4.79458475112915


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.37s/it]
INFO:root:final mean train loss: 1987.4129636825123
INFO:root:final train perplexity: 4.794135093688965
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.72s/it]
INFO:root:eval mean loss: 2828.0256274340745
INFO:root:eval perplexity: 10.181794166564941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/26

 26%|â–ˆâ–ˆâ–Œ       | 26/100 [1:11:18<3:28:10, 168.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1992.5858243616615
INFO:root:current train perplexity4.769229888916016
INFO:root:current mean train loss 1972.4805423384862
INFO:root:current train perplexity4.752870559692383
INFO:root:current mean train loss 1973.9745967121046
INFO:root:current train perplexity4.762299537658691
INFO:root:current mean train loss 1983.187875876329
INFO:root:current train perplexity4.771628379821777
INFO:root:current mean train loss 1976.1643312761303
INFO:root:current train perplexity4.76469612121582
INFO:root:current mean train loss 1978.1168436272528
INFO:root:current train perplexity4.765430450439453
INFO:root:current mean train loss 1978.1076102174945
INFO:root:current train perplexity4.766611576080322
INFO:root:current mean train loss 1977.8175323939356
INFO:root:current train perplexity4.768097400665283
INFO:root:current mean train loss 1981.6860286245449
INFO:root:current train perplexity4.774627685546875
INFO:root:current mean train loss 1979.707262547946
INFO:root:current train perplexity4.767221927642822
INFO:root:current mean train loss 1977.4239313160422
INFO:root:current train perplexity4.761693477630615
INFO:root:current mean train loss 1978.6017130284222
INFO:root:current train perplexity4.7594099044799805
INFO:root:current mean train loss 1978.57669753475
INFO:root:current train perplexity4.757298469543457
INFO:root:current mean train loss 1978.7597940261464
INFO:root:current train perplexity4.7587666511535645
INFO:root:current mean train loss 1979.1065551842526
INFO:root:current train perplexity4.761076927185059
INFO:root:current mean train loss 1978.9252320524163
INFO:root:current train perplexity4.7614617347717285
INFO:root:current mean train loss 1978.244313799703
INFO:root:current train perplexity4.759741306304932
INFO:root:current mean train loss 1978.1946637253868
INFO:root:current train perplexity4.759251594543457
INFO:root:current mean train loss 1978.2451295205137
INFO:root:current train perplexity4.758223056793213
INFO:root:current mean train loss 1978.3315795709766
INFO:root:current train perplexity4.7584052085876465


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.12s/it]
INFO:root:final mean train loss: 1978.0140919495398
INFO:root:final train perplexity: 4.758730411529541
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.47s/it]
INFO:root:eval mean loss: 2823.644625093844
INFO:root:eval perplexity: 10.145256996154785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/27
##################best##############
 27%|â–ˆâ–ˆâ–‹       | 27/100 [1:14:14<3:27:53, 170.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1985.214058711611
INFO:root:current train perplexity4.701313495635986
INFO:root:current mean train loss 1961.8669657646856
INFO:root:current train perplexity4.680873870849609
INFO:root:current mean train loss 1952.720095612282
INFO:root:current train perplexity4.694385051727295
INFO:root:current mean train loss 1953.1771018598333
INFO:root:current train perplexity4.691685676574707
INFO:root:current mean train loss 1957.12956297762
INFO:root:current train perplexity4.703494548797607
INFO:root:current mean train loss 1962.889421579231
INFO:root:current train perplexity4.713064193725586
INFO:root:current mean train loss 1964.85170720341
INFO:root:current train perplexity4.716583251953125
INFO:root:current mean train loss 1966.2859195920596
INFO:root:current train perplexity4.719263553619385
INFO:root:current mean train loss 1967.2381485092055
INFO:root:current train perplexity4.7231292724609375
INFO:root:current mean train loss 1966.7356873195704
INFO:root:current train perplexity4.719919204711914
INFO:root:current mean train loss 1965.9297155369431
INFO:root:current train perplexity4.718052387237549
INFO:root:current mean train loss 1967.4749238272816
INFO:root:current train perplexity4.7198944091796875
INFO:root:current mean train loss 1969.0142057628054
INFO:root:current train perplexity4.722615718841553
INFO:root:current mean train loss 1968.9245160514372
INFO:root:current train perplexity4.721068382263184
INFO:root:current mean train loss 1969.25680613158
INFO:root:current train perplexity4.722561359405518
INFO:root:current mean train loss 1970.205728670446
INFO:root:current train perplexity4.725131511688232
INFO:root:current mean train loss 1969.9839871433014
INFO:root:current train perplexity4.724581718444824
INFO:root:current mean train loss 1969.1919916736658
INFO:root:current train perplexity4.722163200378418
INFO:root:current mean train loss 1969.7993139753557
INFO:root:current train perplexity4.726246356964111
INFO:root:current mean train loss 1970.0786422713907
INFO:root:current train perplexity4.726902008056641


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.40s/it]
INFO:root:final mean train loss: 1969.9250927808246
INFO:root:final train perplexity: 4.728468418121338
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.18s/it]
INFO:root:eval mean loss: 2825.328718122419
INFO:root:eval perplexity: 10.159289360046387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/28

 28%|â–ˆâ–ˆâ–Š       | 28/100 [1:17:10<3:26:46, 172.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1983.748095703125
INFO:root:current train perplexity4.743118762969971
INFO:root:current mean train loss 1970.4462576729911
INFO:root:current train perplexity4.69338846206665
INFO:root:current mean train loss 1964.6117103160511
INFO:root:current train perplexity4.689840793609619
INFO:root:current mean train loss 1965.6309290364584
INFO:root:current train perplexity4.699418544769287
INFO:root:current mean train loss 1965.9673524876646
INFO:root:current train perplexity4.704135894775391
INFO:root:current mean train loss 1961.428046875
INFO:root:current train perplexity4.69253396987915
INFO:root:current mean train loss 1960.3692068142361
INFO:root:current train perplexity4.690569877624512
INFO:root:current mean train loss 1963.7212306262602
INFO:root:current train perplexity4.697398662567139
INFO:root:current mean train loss 1964.1649229910715
INFO:root:current train perplexity4.696958065032959
INFO:root:current mean train loss 1965.131688326322
INFO:root:current train perplexity4.696150779724121
INFO:root:current mean train loss 1965.8272456395348
INFO:root:current train perplexity4.697241306304932
INFO:root:current mean train loss 1963.993217669548
INFO:root:current train perplexity4.697122573852539
INFO:root:current mean train loss 1962.0747352749693
INFO:root:current train perplexity4.693862438201904
INFO:root:current mean train loss 1961.1032420099432
INFO:root:current train perplexity4.6954569816589355
INFO:root:current mean train loss 1961.0098555018537
INFO:root:current train perplexity4.693501949310303
INFO:root:current mean train loss 1962.616904451885
INFO:root:current train perplexity4.695736885070801
INFO:root:current mean train loss 1962.966360336987
INFO:root:current train perplexity4.697242736816406
INFO:root:current mean train loss 1962.2602365757043
INFO:root:current train perplexity4.696695804595947
INFO:root:current mean train loss 1962.5449015625
INFO:root:current train perplexity4.698497295379639
INFO:root:current mean train loss 1962.0221931245055
INFO:root:current train perplexity4.69771671295166


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.72s/it]
INFO:root:final mean train loss: 1961.642848427946
INFO:root:final train perplexity: 4.697683334350586
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.47s/it]
INFO:root:eval mean loss: 2827.0718337966873
INFO:root:eval perplexity: 10.173830032348633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/29

 29%|â–ˆâ–ˆâ–‰       | 29/100 [1:19:57<3:22:13, 170.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1950.6230216648269
INFO:root:current train perplexity4.650261402130127
INFO:root:current mean train loss 1947.2727915445964
INFO:root:current train perplexity4.651373863220215
INFO:root:current mean train loss 1954.2993648999359
INFO:root:current train perplexity4.651768207550049
INFO:root:current mean train loss 1955.1128225521165
INFO:root:current train perplexity4.653321266174316
INFO:root:current mean train loss 1962.815597658235
INFO:root:current train perplexity4.665258407592773
INFO:root:current mean train loss 1962.2462867530617
INFO:root:current train perplexity4.670092582702637
INFO:root:current mean train loss 1961.8181148815706
INFO:root:current train perplexity4.664698123931885
INFO:root:current mean train loss 1959.3899082993016
INFO:root:current train perplexity4.662745952606201
INFO:root:current mean train loss 1960.565617445873
INFO:root:current train perplexity4.663556098937988
INFO:root:current mean train loss 1960.201335168654
INFO:root:current train perplexity4.665786266326904
INFO:root:current mean train loss 1958.8099928635818
INFO:root:current train perplexity4.661868572235107
INFO:root:current mean train loss 1958.4386251564795
INFO:root:current train perplexity4.6640095710754395
INFO:root:current mean train loss 1957.7255638287902
INFO:root:current train perplexity4.663145542144775
INFO:root:current mean train loss 1957.1298060800837
INFO:root:current train perplexity4.6650567054748535
INFO:root:current mean train loss 1958.3224533121963
INFO:root:current train perplexity4.668140888214111
INFO:root:current mean train loss 1957.5106375229418
INFO:root:current train perplexity4.667266845703125
INFO:root:current mean train loss 1956.5359202716368
INFO:root:current train perplexity4.666875839233398
INFO:root:current mean train loss 1954.6639934948512
INFO:root:current train perplexity4.667646884918213
INFO:root:current mean train loss 1954.6363310541713
INFO:root:current train perplexity4.669764518737793


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.96s/it]
INFO:root:final mean train loss: 1954.1532260973647
INFO:root:final train perplexity: 4.670017242431641
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.64s/it]
INFO:root:eval mean loss: 2823.7326748134856
INFO:root:eval perplexity: 10.145992279052734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/30

 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [1:22:44<3:17:54, 169.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1897.4470757378472
INFO:root:current train perplexity4.671713352203369
INFO:root:current mean train loss 1931.0044986829846
INFO:root:current train perplexity4.629834175109863
INFO:root:current mean train loss 1941.7898439836274
INFO:root:current train perplexity4.635406017303467
INFO:root:current mean train loss 1942.148006895985
INFO:root:current train perplexity4.642219543457031
INFO:root:current mean train loss 1946.4324312466572
INFO:root:current train perplexity4.6372904777526855
INFO:root:current mean train loss 1941.4661630207054
INFO:root:current train perplexity4.620611667633057
INFO:root:current mean train loss 1942.0471345748024
INFO:root:current train perplexity4.620755672454834
INFO:root:current mean train loss 1941.2473323590664
INFO:root:current train perplexity4.621678352355957
INFO:root:current mean train loss 1942.8231143833532
INFO:root:current train perplexity4.622642993927002
INFO:root:current mean train loss 1943.7301467207267
INFO:root:current train perplexity4.626947402954102
INFO:root:current mean train loss 1945.3745648296194
INFO:root:current train perplexity4.631183624267578
INFO:root:current mean train loss 1945.0854635281644
INFO:root:current train perplexity4.631644248962402
INFO:root:current mean train loss 1945.9180542698964
INFO:root:current train perplexity4.6369709968566895
INFO:root:current mean train loss 1946.206968489633
INFO:root:current train perplexity4.636740207672119
INFO:root:current mean train loss 1946.7949207487302
INFO:root:current train perplexity4.6363396644592285
INFO:root:current mean train loss 1946.5501782598678
INFO:root:current train perplexity4.637205600738525
INFO:root:current mean train loss 1946.4402197629788
INFO:root:current train perplexity4.636701583862305
INFO:root:current mean train loss 1946.7519310537732
INFO:root:current train perplexity4.639955043792725
INFO:root:current mean train loss 1946.613364722071
INFO:root:current train perplexity4.640688896179199
INFO:root:current mean train loss 1946.48138712288
INFO:root:current train perplexity4.640716552734375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.12s/it]
INFO:root:final mean train loss: 1946.1694305158298
INFO:root:final train perplexity: 4.640705585479736
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.39s/it]
INFO:root:eval mean loss: 2824.476668074324
INFO:root:eval perplexity: 10.15218734741211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/31

 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [1:25:41<3:17:29, 171.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1927.822481595553
INFO:root:current train perplexity4.592116832733154
INFO:root:current mean train loss 1933.1944328187003
INFO:root:current train perplexity4.589545726776123
INFO:root:current mean train loss 1936.06667199599
INFO:root:current train perplexity4.591501235961914
INFO:root:current mean train loss 1926.5859902972825
INFO:root:current train perplexity4.566011428833008
INFO:root:current mean train loss 1926.0675180641138
INFO:root:current train perplexity4.565897464752197
INFO:root:current mean train loss 1928.4798140725256
INFO:root:current train perplexity4.572251319885254
INFO:root:current mean train loss 1930.3135288226338
INFO:root:current train perplexity4.579050540924072
INFO:root:current mean train loss 1933.8860695578835
INFO:root:current train perplexity4.584763050079346
INFO:root:current mean train loss 1937.518086504994
INFO:root:current train perplexity4.591887950897217
INFO:root:current mean train loss 1936.2280763827957
INFO:root:current train perplexity4.592784881591797
INFO:root:current mean train loss 1936.2063769959566
INFO:root:current train perplexity4.597470283508301
INFO:root:current mean train loss 1938.2451756208022
INFO:root:current train perplexity4.605447769165039
INFO:root:current mean train loss 1938.3452270906084
INFO:root:current train perplexity4.6079301834106445
INFO:root:current mean train loss 1939.3270154121594
INFO:root:current train perplexity4.6085100173950195
INFO:root:current mean train loss 1938.3000104778446
INFO:root:current train perplexity4.609619140625
INFO:root:current mean train loss 1936.9392145839306
INFO:root:current train perplexity4.609350204467773
INFO:root:current mean train loss 1938.101138557162
INFO:root:current train perplexity4.611814022064209
INFO:root:current mean train loss 1938.845864800976
INFO:root:current train perplexity4.6137871742248535
INFO:root:current mean train loss 1938.5928828060823
INFO:root:current train perplexity4.612534523010254
INFO:root:current mean train loss 1938.9627090406566
INFO:root:current train perplexity4.615113258361816


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.46s/it]
INFO:root:final mean train loss: 1939.181014022019
INFO:root:final train perplexity: 4.615197658538818
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.53s/it]
INFO:root:eval mean loss: 2824.5429012997374
INFO:root:eval perplexity: 10.152739524841309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/32

 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [1:28:29<3:13:24, 170.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1913.0583268986193
INFO:root:current train perplexity4.491274833679199
INFO:root:current mean train loss 1929.6372300794908
INFO:root:current train perplexity4.540374279022217
INFO:root:current mean train loss 1935.9449362421233
INFO:root:current train perplexity4.568018913269043
INFO:root:current mean train loss 1935.547607421875
INFO:root:current train perplexity4.576536178588867
INFO:root:current mean train loss 1929.6417272150113
INFO:root:current train perplexity4.568212509155273
INFO:root:current mean train loss 1925.9382677166063
INFO:root:current train perplexity4.564242362976074
INFO:root:current mean train loss 1923.6601600468994
INFO:root:current train perplexity4.567455768585205
INFO:root:current mean train loss 1924.8625332202116
INFO:root:current train perplexity4.570528507232666
INFO:root:current mean train loss 1925.3399469957092
INFO:root:current train perplexity4.573362827301025
INFO:root:current mean train loss 1928.9485905344893
INFO:root:current train perplexity4.579681396484375
INFO:root:current mean train loss 1929.7018528002907
INFO:root:current train perplexity4.582792282104492
INFO:root:current mean train loss 1930.1645388198544
INFO:root:current train perplexity4.58444356918335
INFO:root:current mean train loss 1931.8724270956418
INFO:root:current train perplexity4.586601734161377
INFO:root:current mean train loss 1932.3107989233818
INFO:root:current train perplexity4.586217880249023
INFO:root:current mean train loss 1932.3406573828938
INFO:root:current train perplexity4.586653709411621
INFO:root:current mean train loss 1933.4535836932416
INFO:root:current train perplexity4.587352275848389
INFO:root:current mean train loss 1933.84187191518
INFO:root:current train perplexity4.587070941925049
INFO:root:current mean train loss 1933.1748955223798
INFO:root:current train perplexity4.587738990783691
INFO:root:current mean train loss 1932.776683258868
INFO:root:current train perplexity4.590008735656738
INFO:root:current mean train loss 1933.0386049405115
INFO:root:current train perplexity4.590702056884766


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.28s/it]
INFO:root:final mean train loss: 1932.1062480793778
INFO:root:final train perplexity: 4.589519023895264
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.96s/it]
INFO:root:eval mean loss: 2826.698624161271
INFO:root:eval perplexity: 10.170713424682617
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/33

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [1:31:16<3:09:27, 169.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1895.8348124186198
INFO:root:current train perplexity4.493283748626709
INFO:root:current mean train loss 1905.3631492614745
INFO:root:current train perplexity4.535376071929932
INFO:root:current mean train loss 1908.7266164926382
INFO:root:current train perplexity4.544698238372803
INFO:root:current mean train loss 1911.101475016276
INFO:root:current train perplexity4.548224449157715
INFO:root:current mean train loss 1910.1251547108525
INFO:root:current train perplexity4.549646854400635
INFO:root:current mean train loss 1912.464125279018
INFO:root:current train perplexity4.547243118286133
INFO:root:current mean train loss 1914.8004788485441
INFO:root:current train perplexity4.552195072174072
INFO:root:current mean train loss 1917.6665199681331
INFO:root:current train perplexity4.551921367645264
INFO:root:current mean train loss 1920.9968842262444
INFO:root:current train perplexity4.555180549621582
INFO:root:current mean train loss 1921.6086503346762
INFO:root:current train perplexity4.55075740814209
INFO:root:current mean train loss 1921.4710552863355
INFO:root:current train perplexity4.550629138946533
INFO:root:current mean train loss 1920.793806931068
INFO:root:current train perplexity4.5504841804504395
INFO:root:current mean train loss 1921.5159345354352
INFO:root:current train perplexity4.5531134605407715
INFO:root:current mean train loss 1921.0763455559227
INFO:root:current train perplexity4.553152084350586
INFO:root:current mean train loss 1921.0042555717573
INFO:root:current train perplexity4.552334785461426
INFO:root:current mean train loss 1920.8094724997495
INFO:root:current train perplexity4.55383825302124
INFO:root:current mean train loss 1921.1966655685242
INFO:root:current train perplexity4.554514408111572
INFO:root:current mean train loss 1923.2569297096945
INFO:root:current train perplexity4.557760715484619
INFO:root:current mean train loss 1924.4917267173848
INFO:root:current train perplexity4.561145782470703
INFO:root:current mean train loss 1926.059393310547
INFO:root:current train perplexity4.565977573394775


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.48s/it]
INFO:root:final mean train loss: 1925.208287903232
INFO:root:final train perplexity: 4.564619064331055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.24s/it]
INFO:root:eval mean loss: 2826.982027437594
INFO:root:eval perplexity: 10.173080444335938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/34

 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [1:34:02<3:05:20, 168.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1934.7161674994927
INFO:root:current train perplexity4.508642673492432
INFO:root:current mean train loss 1927.6481823247705
INFO:root:current train perplexity4.523016929626465
INFO:root:current mean train loss 1917.787751015343
INFO:root:current train perplexity4.515129089355469
INFO:root:current mean train loss 1915.8834859913793
INFO:root:current train perplexity4.518082618713379
INFO:root:current mean train loss 1912.9725400656773
INFO:root:current train perplexity4.5221848487854
INFO:root:current mean train loss 1914.650903658809
INFO:root:current train perplexity4.525944709777832
INFO:root:current mean train loss 1913.6432825987238
INFO:root:current train perplexity4.5223236083984375
INFO:root:current mean train loss 1914.7013577298
INFO:root:current train perplexity4.5196123123168945
INFO:root:current mean train loss 1914.1316640368889
INFO:root:current train perplexity4.519566535949707
INFO:root:current mean train loss 1915.214101457547
INFO:root:current train perplexity4.524098873138428
INFO:root:current mean train loss 1915.6754849716372
INFO:root:current train perplexity4.52699613571167
INFO:root:current mean train loss 1917.1915187787079
INFO:root:current train perplexity4.531047821044922
INFO:root:current mean train loss 1918.6375907354272
INFO:root:current train perplexity4.536672592163086
INFO:root:current mean train loss 1919.030239839353
INFO:root:current train perplexity4.538067817687988
INFO:root:current mean train loss 1918.2400809812966
INFO:root:current train perplexity4.537421226501465
INFO:root:current mean train loss 1918.152144118208
INFO:root:current train perplexity4.536641597747803
INFO:root:current mean train loss 1919.0899239655541
INFO:root:current train perplexity4.53903865814209
INFO:root:current mean train loss 1919.3641437107617
INFO:root:current train perplexity4.540294170379639
INFO:root:current mean train loss 1919.6720662673356
INFO:root:current train perplexity4.542013645172119
INFO:root:current mean train loss 1919.2010614745352
INFO:root:current train perplexity4.541454315185547


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.13s/it]
INFO:root:final mean train loss: 1918.640283012294
INFO:root:final train perplexity: 4.5410356521606445
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.67s/it]
INFO:root:eval mean loss: 2825.603047872091
INFO:root:eval perplexity: 10.16157341003418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/35

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [1:36:48<3:01:42, 167.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1934.462654276097
INFO:root:current train perplexity4.559268951416016
INFO:root:current mean train loss 1919.221757082595
INFO:root:current train perplexity4.522397041320801
INFO:root:current mean train loss 1917.4610936171343
INFO:root:current train perplexity4.510493278503418
INFO:root:current mean train loss 1913.8959397059407
INFO:root:current train perplexity4.5030646324157715
INFO:root:current mean train loss 1912.0463610197369
INFO:root:current train perplexity4.509990692138672
INFO:root:current mean train loss 1913.3893599076705
INFO:root:current train perplexity4.511067867279053
INFO:root:current mean train loss 1912.7223275044466
INFO:root:current train perplexity4.514501571655273
INFO:root:current mean train loss 1913.4559922686751
INFO:root:current train perplexity4.512107849121094
INFO:root:current mean train loss 1913.125607620683
INFO:root:current train perplexity4.514187335968018
INFO:root:current mean train loss 1911.5454318931165
INFO:root:current train perplexity4.512019634246826
INFO:root:current mean train loss 1913.2771360965708
INFO:root:current train perplexity4.5145769119262695
INFO:root:current mean train loss 1914.2801991116062
INFO:root:current train perplexity4.514184474945068
INFO:root:current mean train loss 1913.8129409247608
INFO:root:current train perplexity4.517574787139893
INFO:root:current mean train loss 1914.0103267631366
INFO:root:current train perplexity4.517426013946533
INFO:root:current mean train loss 1914.0082140900843
INFO:root:current train perplexity4.516752243041992
INFO:root:current mean train loss 1912.667173608184
INFO:root:current train perplexity4.514830589294434
INFO:root:current mean train loss 1912.304865561241
INFO:root:current train perplexity4.514906406402588
INFO:root:current mean train loss 1912.9858424974525
INFO:root:current train perplexity4.5168137550354
INFO:root:current mean train loss 1912.951141002941
INFO:root:current train perplexity4.518153190612793


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.10s/it]
INFO:root:final mean train loss: 1912.4773750401362
INFO:root:final train perplexity: 4.519018173217773
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.74s/it]
INFO:root:eval mean loss: 2831.5244089304147
INFO:root:eval perplexity: 10.211068153381348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/36

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [1:39:34<2:58:21, 167.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1935.6867564808238
INFO:root:current train perplexity4.600335597991943
INFO:root:current mean train loss 1891.9289979676942
INFO:root:current train perplexity4.488892555236816
INFO:root:current mean train loss 1886.2588249315017
INFO:root:current train perplexity4.458313465118408
INFO:root:current mean train loss 1892.6169684799538
INFO:root:current train perplexity4.471822738647461
INFO:root:current mean train loss 1895.5034265819838
INFO:root:current train perplexity4.463728427886963
INFO:root:current mean train loss 1898.44788792082
INFO:root:current train perplexity4.474881172180176
INFO:root:current mean train loss 1902.2813580851703
INFO:root:current train perplexity4.484768390655518
INFO:root:current mean train loss 1902.5566476642164
INFO:root:current train perplexity4.483850479125977
INFO:root:current mean train loss 1900.486375989808
INFO:root:current train perplexity4.48345947265625
INFO:root:current mean train loss 1899.6860571315863
INFO:root:current train perplexity4.485314846038818
INFO:root:current mean train loss 1899.9466287101648
INFO:root:current train perplexity4.485740661621094
INFO:root:current mean train loss 1899.7746801779788
INFO:root:current train perplexity4.486298561096191
INFO:root:current mean train loss 1901.401764747626
INFO:root:current train perplexity4.487518787384033
INFO:root:current mean train loss 1900.7028881221395
INFO:root:current train perplexity4.487010478973389
INFO:root:current mean train loss 1903.7856516253432
INFO:root:current train perplexity4.4889235496521
INFO:root:current mean train loss 1903.7516206025605
INFO:root:current train perplexity4.490597248077393
INFO:root:current mean train loss 1904.5082680473115
INFO:root:current train perplexity4.491771697998047
INFO:root:current mean train loss 1905.4871744125785
INFO:root:current train perplexity4.491790771484375
INFO:root:current mean train loss 1905.6861818967636
INFO:root:current train perplexity4.49323034286499
INFO:root:current mean train loss 1905.5312980360413
INFO:root:current train perplexity4.4932379722595215


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.04s/it]
INFO:root:final mean train loss: 1906.0322001231661
INFO:root:final train perplexity: 4.496106147766113
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:19<00:00, 19.10s/it]
INFO:root:eval mean loss: 2828.6821435693505
INFO:root:eval perplexity: 10.187281608581543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/37

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [1:42:23<2:56:13, 167.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1882.8123386928014
INFO:root:current train perplexity4.404805660247803
INFO:root:current mean train loss 1891.0516681671143
INFO:root:current train perplexity4.443240642547607
INFO:root:current mean train loss 1890.0423070004113
INFO:root:current train perplexity4.432426929473877
INFO:root:current mean train loss 1883.8757986673495
INFO:root:current train perplexity4.427674293518066
INFO:root:current mean train loss 1884.4104896616714
INFO:root:current train perplexity4.43572473526001
INFO:root:current mean train loss 1887.4100575302587
INFO:root:current train perplexity4.445557117462158
INFO:root:current mean train loss 1888.9260327770453
INFO:root:current train perplexity4.448497295379639
INFO:root:current mean train loss 1887.844998034802
INFO:root:current train perplexity4.44865083694458
INFO:root:current mean train loss 1888.7105547771362
INFO:root:current train perplexity4.454315185546875
INFO:root:current mean train loss 1889.3244289529734
INFO:root:current train perplexity4.456911563873291
INFO:root:current mean train loss 1891.7072964085678
INFO:root:current train perplexity4.45893669128418
INFO:root:current mean train loss 1892.960608191524
INFO:root:current train perplexity4.458791732788086
INFO:root:current mean train loss 1892.6528489302345
INFO:root:current train perplexity4.460875988006592
INFO:root:current mean train loss 1893.554629590138
INFO:root:current train perplexity4.461163520812988
INFO:root:current mean train loss 1893.0179605777857
INFO:root:current train perplexity4.4607696533203125
INFO:root:current mean train loss 1895.2340283618548
INFO:root:current train perplexity4.465078353881836
INFO:root:current mean train loss 1898.0118924077665
INFO:root:current train perplexity4.469744682312012
INFO:root:current mean train loss 1899.6343545560483
INFO:root:current train perplexity4.471498012542725
INFO:root:current mean train loss 1900.3737211331759
INFO:root:current train perplexity4.47355842590332
INFO:root:current mean train loss 1900.2123815766015
INFO:root:current train perplexity4.473197937011719


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.00s/it]
INFO:root:final mean train loss: 1899.6116134789756
INFO:root:final train perplexity: 4.473395824432373
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.42s/it]
INFO:root:eval mean loss: 2833.4471519859703
INFO:root:eval perplexity: 10.227194786071777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/38

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [1:45:10<2:53:00, 167.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1871.9984049479167
INFO:root:current train perplexity4.424144268035889
INFO:root:current mean train loss 1894.0265911233837
INFO:root:current train perplexity4.432796955108643
INFO:root:current mean train loss 1897.943080357143
INFO:root:current train perplexity4.444607734680176
INFO:root:current mean train loss 1890.282082554914
INFO:root:current train perplexity4.43543004989624
INFO:root:current mean train loss 1892.054587100597
INFO:root:current train perplexity4.438344478607178
INFO:root:current mean train loss 1890.5745518115682
INFO:root:current train perplexity4.436883926391602
INFO:root:current mean train loss 1891.3546394289
INFO:root:current train perplexity4.436076641082764
INFO:root:current mean train loss 1888.8630856097946
INFO:root:current train perplexity4.429449558258057
INFO:root:current mean train loss 1890.2525130593565
INFO:root:current train perplexity4.430537700653076
INFO:root:current mean train loss 1890.5140590122767
INFO:root:current train perplexity4.431321620941162
INFO:root:current mean train loss 1891.0960735412305
INFO:root:current train perplexity4.435275554656982
INFO:root:current mean train loss 1892.7398729615857
INFO:root:current train perplexity4.44029426574707
INFO:root:current mean train loss 1893.2629933797691
INFO:root:current train perplexity4.442899703979492
INFO:root:current mean train loss 1891.6828470790254
INFO:root:current train perplexity4.444454193115234
INFO:root:current mean train loss 1893.1820761921497
INFO:root:current train perplexity4.445570468902588
INFO:root:current mean train loss 1893.5134991593345
INFO:root:current train perplexity4.446592330932617
INFO:root:current mean train loss 1894.0206213490217
INFO:root:current train perplexity4.448122978210449
INFO:root:current mean train loss 1894.712676844556
INFO:root:current train perplexity4.450080871582031
INFO:root:current mean train loss 1894.9505943401718
INFO:root:current train perplexity4.4519572257995605
INFO:root:current mean train loss 1894.8720621535588
INFO:root:current train perplexity4.453180313110352


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.47s/it]
INFO:root:final mean train loss: 1894.4125610597796
INFO:root:final train perplexity: 4.45509147644043
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.80s/it]
INFO:root:eval mean loss: 2830.999804247607
INFO:root:eval perplexity: 10.206677436828613
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/39

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [1:47:56<2:49:54, 167.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1873.6802702872983
INFO:root:current train perplexity4.396594524383545
INFO:root:current mean train loss 1877.4793452510128
INFO:root:current train perplexity4.399533748626709
INFO:root:current mean train loss 1884.0148147699488
INFO:root:current train perplexity4.402218818664551
INFO:root:current mean train loss 1884.5855820798083
INFO:root:current train perplexity4.406555652618408
INFO:root:current mean train loss 1880.2917557092971
INFO:root:current train perplexity4.407210350036621
INFO:root:current mean train loss 1883.1783931637149
INFO:root:current train perplexity4.421010494232178
INFO:root:current mean train loss 1883.087806171521
INFO:root:current train perplexity4.422549247741699
INFO:root:current mean train loss 1883.3800026400509
INFO:root:current train perplexity4.4230852127075195
INFO:root:current mean train loss 1885.7350427047836
INFO:root:current train perplexity4.429264068603516
INFO:root:current mean train loss 1884.868780504889
INFO:root:current train perplexity4.4285478591918945
INFO:root:current mean train loss 1886.4093152062367
INFO:root:current train perplexity4.4275970458984375
INFO:root:current mean train loss 1886.496272233185
INFO:root:current train perplexity4.425014019012451
INFO:root:current mean train loss 1885.6630666886947
INFO:root:current train perplexity4.424296855926514
INFO:root:current mean train loss 1886.9197040843544
INFO:root:current train perplexity4.4283833503723145
INFO:root:current mean train loss 1886.4675367279679
INFO:root:current train perplexity4.430397033691406
INFO:root:current mean train loss 1887.270137381462
INFO:root:current train perplexity4.431147575378418
INFO:root:current mean train loss 1888.3806357997705
INFO:root:current train perplexity4.432600021362305
INFO:root:current mean train loss 1888.5701247528111
INFO:root:current train perplexity4.433645248413086
INFO:root:current mean train loss 1889.0640450876074
INFO:root:current train perplexity4.433883190155029
INFO:root:current mean train loss 1889.2453924989845
INFO:root:current train perplexity4.433873653411865


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.09s/it]
INFO:root:final mean train loss: 1888.5951447287293
INFO:root:final train perplexity: 4.434699535369873
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.80s/it]
INFO:root:eval mean loss: 2831.1039357228324
INFO:root:eval perplexity: 10.207549095153809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/40

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [1:50:42<2:46:47, 166.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1877.1845471345925
INFO:root:current train perplexity4.4071478843688965
INFO:root:current mean train loss 1882.2138555942302
INFO:root:current train perplexity4.398956775665283
INFO:root:current mean train loss 1880.7867444766466
INFO:root:current train perplexity4.404362678527832
INFO:root:current mean train loss 1881.2111384812006
INFO:root:current train perplexity4.4113030433654785
INFO:root:current mean train loss 1879.6887859432086
INFO:root:current train perplexity4.41068172454834
INFO:root:current mean train loss 1881.820480320326
INFO:root:current train perplexity4.404174327850342
INFO:root:current mean train loss 1882.4584626547542
INFO:root:current train perplexity4.405168533325195
INFO:root:current mean train loss 1884.6436921145398
INFO:root:current train perplexity4.411657810211182
INFO:root:current mean train loss 1883.780673672586
INFO:root:current train perplexity4.411715984344482
INFO:root:current mean train loss 1884.6718100371472
INFO:root:current train perplexity4.41370153427124
INFO:root:current mean train loss 1884.980904311356
INFO:root:current train perplexity4.413371562957764
INFO:root:current mean train loss 1884.8182249837653
INFO:root:current train perplexity4.416514873504639
INFO:root:current mean train loss 1885.6761280862124
INFO:root:current train perplexity4.415297031402588
INFO:root:current mean train loss 1886.7273911440866
INFO:root:current train perplexity4.420045852661133
INFO:root:current mean train loss 1887.1202033547795
INFO:root:current train perplexity4.420875549316406
INFO:root:current mean train loss 1885.9576992737937
INFO:root:current train perplexity4.420653820037842
INFO:root:current mean train loss 1885.1092307549136
INFO:root:current train perplexity4.417238235473633
INFO:root:current mean train loss 1884.048322346319
INFO:root:current train perplexity4.416594982147217
INFO:root:current mean train loss 1883.757314473914
INFO:root:current train perplexity4.417226314544678
INFO:root:current mean train loss 1883.9856563373428
INFO:root:current train perplexity4.416791915893555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.15s/it]
INFO:root:final mean train loss: 1883.421932156977
INFO:root:final train perplexity: 4.416642665863037
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.70s/it]
INFO:root:eval mean loss: 2836.7407827749626
INFO:root:eval perplexity: 10.254868507385254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/41

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [1:53:31<2:44:39, 167.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1862.7406489054363
INFO:root:current train perplexity4.357101917266846
INFO:root:current mean train loss 1861.874311174665
INFO:root:current train perplexity4.3541579246521
INFO:root:current mean train loss 1867.983297811972
INFO:root:current train perplexity4.371467113494873
INFO:root:current mean train loss 1870.289637093592
INFO:root:current train perplexity4.375319004058838
INFO:root:current mean train loss 1869.5088764313728
INFO:root:current train perplexity4.380989074707031
INFO:root:current mean train loss 1872.2540334407115
INFO:root:current train perplexity4.375622749328613
INFO:root:current mean train loss 1869.0412944925242
INFO:root:current train perplexity4.37168025970459
INFO:root:current mean train loss 1870.5025958343965
INFO:root:current train perplexity4.376289367675781
INFO:root:current mean train loss 1871.7238121032715
INFO:root:current train perplexity4.378188133239746
INFO:root:current mean train loss 1872.0599175265515
INFO:root:current train perplexity4.381251335144043
INFO:root:current mean train loss 1872.2683771509323
INFO:root:current train perplexity4.377054691314697
INFO:root:current mean train loss 1873.2674106355496
INFO:root:current train perplexity4.37876033782959
INFO:root:current mean train loss 1875.0131123860676
INFO:root:current train perplexity4.38196325302124
INFO:root:current mean train loss 1875.096637540014
INFO:root:current train perplexity4.384957313537598
INFO:root:current mean train loss 1875.9296395204922
INFO:root:current train perplexity4.388250827789307
INFO:root:current mean train loss 1878.3445917191661
INFO:root:current train perplexity4.392195224761963
INFO:root:current mean train loss 1878.5635222668918
INFO:root:current train perplexity4.39395809173584
INFO:root:current mean train loss 1878.326479429657
INFO:root:current train perplexity4.394599914550781
INFO:root:current mean train loss 1878.6698582645206
INFO:root:current train perplexity4.396017551422119


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.23s/it]
INFO:root:final mean train loss: 1877.842721451429
INFO:root:final train perplexity: 4.397252082824707
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.44s/it]
INFO:root:eval mean loss: 2830.456497513138
INFO:root:eval perplexity: 10.202127456665039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/42

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [1:56:15<2:40:47, 166.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1884.7015380859375
INFO:root:current train perplexity4.469823360443115
INFO:root:current mean train loss 1857.2664006326052
INFO:root:current train perplexity4.385614395141602
INFO:root:current mean train loss 1856.7165200676716
INFO:root:current train perplexity4.372201442718506
INFO:root:current mean train loss 1861.2673761044828
INFO:root:current train perplexity4.358529567718506
INFO:root:current mean train loss 1861.3683833752648
INFO:root:current train perplexity4.3609089851379395
INFO:root:current mean train loss 1864.8087148684972
INFO:root:current train perplexity4.359511375427246
INFO:root:current mean train loss 1866.333133068987
INFO:root:current train perplexity4.367883682250977
INFO:root:current mean train loss 1869.3217328300316
INFO:root:current train perplexity4.367522716522217
INFO:root:current mean train loss 1869.4251007793282
INFO:root:current train perplexity4.372805595397949
INFO:root:current mean train loss 1871.1864929533474
INFO:root:current train perplexity4.371791362762451
INFO:root:current mean train loss 1871.9891988861596
INFO:root:current train perplexity4.37192964553833
INFO:root:current mean train loss 1871.9479849953323
INFO:root:current train perplexity4.373929500579834
INFO:root:current mean train loss 1871.972749639324
INFO:root:current train perplexity4.375793933868408
INFO:root:current mean train loss 1871.992657373084
INFO:root:current train perplexity4.375330924987793
INFO:root:current mean train loss 1873.5607675173057
INFO:root:current train perplexity4.378186225891113
INFO:root:current mean train loss 1873.5424974117543
INFO:root:current train perplexity4.379455089569092
INFO:root:current mean train loss 1872.112877199536
INFO:root:current train perplexity4.375006198883057
INFO:root:current mean train loss 1872.6269031709492
INFO:root:current train perplexity4.377213954925537
INFO:root:current mean train loss 1871.914072532254
INFO:root:current train perplexity4.375667572021484
INFO:root:current mean train loss 1872.8828421720832
INFO:root:current train perplexity4.378106117248535


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.06s/it]
INFO:root:final mean train loss: 1872.8899027968198
INFO:root:final train perplexity: 4.380108833312988
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.66s/it]
INFO:root:eval mean loss: 2833.088403833521
INFO:root:eval perplexity: 10.22418212890625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/43

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [1:59:02<2:38:08, 166.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1879.9918334960937
INFO:root:current train perplexity4.395839214324951
INFO:root:current mean train loss 1869.9159592848557
INFO:root:current train perplexity4.354994297027588
INFO:root:current mean train loss 1878.6930499532948
INFO:root:current train perplexity4.374223709106445
INFO:root:current mean train loss 1873.8733627781723
INFO:root:current train perplexity4.353425979614258
INFO:root:current mean train loss 1870.210096066497
INFO:root:current train perplexity4.354691982269287
INFO:root:current mean train loss 1870.043261027786
INFO:root:current train perplexity4.348659515380859
INFO:root:current mean train loss 1867.3147055974082
INFO:root:current train perplexity4.347212791442871
INFO:root:current mean train loss 1868.408496929848
INFO:root:current train perplexity4.351290225982666
INFO:root:current mean train loss 1869.7372071783227
INFO:root:current train perplexity4.350646018981934
INFO:root:current mean train loss 1869.549945265247
INFO:root:current train perplexity4.351612091064453
INFO:root:current mean train loss 1868.525824863471
INFO:root:current train perplexity4.352657318115234
INFO:root:current mean train loss 1868.4742415436601
INFO:root:current train perplexity4.353010177612305
INFO:root:current mean train loss 1868.7853991996951
INFO:root:current train perplexity4.355634689331055
INFO:root:current mean train loss 1868.2101989287182
INFO:root:current train perplexity4.354183673858643
INFO:root:current mean train loss 1868.7735555582112
INFO:root:current train perplexity4.357902526855469
INFO:root:current mean train loss 1867.382181404463
INFO:root:current train perplexity4.35678243637085
INFO:root:current mean train loss 1867.5149667189896
INFO:root:current train perplexity4.360392093658447
INFO:root:current mean train loss 1868.517689822864
INFO:root:current train perplexity4.361248970031738
INFO:root:current mean train loss 1868.406602202869
INFO:root:current train perplexity4.362666130065918
INFO:root:current mean train loss 1867.6247683826505
INFO:root:current train perplexity4.360335826873779


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.45s/it]
INFO:root:final mean train loss: 1867.506281942655
INFO:root:final train perplexity: 4.361550807952881
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.33s/it]
INFO:root:eval mean loss: 2832.7613096494933
INFO:root:eval perplexity: 10.221439361572266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/44

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [2:01:49<2:35:28, 166.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1851.9736795628326
INFO:root:current train perplexity4.326568126678467
INFO:root:current mean train loss 1835.9876451557186
INFO:root:current train perplexity4.291269302368164
INFO:root:current mean train loss 1848.635870188354
INFO:root:current train perplexity4.295670509338379
INFO:root:current mean train loss 1855.9058669032556
INFO:root:current train perplexity4.321552753448486
INFO:root:current mean train loss 1857.407007545966
INFO:root:current train perplexity4.3251953125
INFO:root:current mean train loss 1857.859212983461
INFO:root:current train perplexity4.327564716339111
INFO:root:current mean train loss 1857.8243874221164
INFO:root:current train perplexity4.329585552215576
INFO:root:current mean train loss 1858.1701888935952
INFO:root:current train perplexity4.322028160095215
INFO:root:current mean train loss 1860.9256036931818
INFO:root:current train perplexity4.3293776512146
INFO:root:current mean train loss 1861.1192442623087
INFO:root:current train perplexity4.3273749351501465
INFO:root:current mean train loss 1860.7142420261387
INFO:root:current train perplexity4.332026958465576
INFO:root:current mean train loss 1862.4958913282612
INFO:root:current train perplexity4.335205554962158
INFO:root:current mean train loss 1860.854858104764
INFO:root:current train perplexity4.3341851234436035
INFO:root:current mean train loss 1859.6266766316642
INFO:root:current train perplexity4.332979679107666
INFO:root:current mean train loss 1860.698567145927
INFO:root:current train perplexity4.334921360015869
INFO:root:current mean train loss 1862.0819201478669
INFO:root:current train perplexity4.341507911682129
INFO:root:current mean train loss 1861.53074659893
INFO:root:current train perplexity4.341203689575195
INFO:root:current mean train loss 1861.2226746968017
INFO:root:current train perplexity4.339284420013428
INFO:root:current mean train loss 1861.727789481782
INFO:root:current train perplexity4.341014385223389
INFO:root:current mean train loss 1862.9778435172702
INFO:root:current train perplexity4.344003200531006


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.71s/it]
INFO:root:final mean train loss: 1862.4125108896815
INFO:root:final train perplexity: 4.344065189361572
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.82s/it]
INFO:root:eval mean loss: 2836.9334397874436
INFO:root:eval perplexity: 10.256492614746094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/45

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [2:04:45<2:35:28, 169.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1846.2279586791992
INFO:root:current train perplexity4.287068843841553
INFO:root:current mean train loss 1856.4203089272103
INFO:root:current train perplexity4.306091785430908
INFO:root:current mean train loss 1858.4173505378492
INFO:root:current train perplexity4.3224711418151855
INFO:root:current mean train loss 1860.4368876362894
INFO:root:current train perplexity4.343050003051758
INFO:root:current mean train loss 1858.7760057120488
INFO:root:current train perplexity4.331975936889648
INFO:root:current mean train loss 1857.9157807911542
INFO:root:current train perplexity4.3299455642700195
INFO:root:current mean train loss 1855.0339895960797
INFO:root:current train perplexity4.323429584503174
INFO:root:current mean train loss 1854.4077233119785
INFO:root:current train perplexity4.324201583862305
INFO:root:current mean train loss 1856.5782135857476
INFO:root:current train perplexity4.327338695526123
INFO:root:current mean train loss 1857.28514776586
INFO:root:current train perplexity4.327930927276611
INFO:root:current mean train loss 1855.6675458635602
INFO:root:current train perplexity4.326451778411865
INFO:root:current mean train loss 1856.9518212387243
INFO:root:current train perplexity4.325920104980469
INFO:root:current mean train loss 1858.0059091109263
INFO:root:current train perplexity4.326594352722168
INFO:root:current mean train loss 1859.2113595554206
INFO:root:current train perplexity4.326944828033447
INFO:root:current mean train loss 1859.8110835174393
INFO:root:current train perplexity4.325965881347656
INFO:root:current mean train loss 1859.472977347996
INFO:root:current train perplexity4.325551509857178
INFO:root:current mean train loss 1858.4492472868699
INFO:root:current train perplexity4.327293872833252
INFO:root:current mean train loss 1858.3153460928643
INFO:root:current train perplexity4.326498985290527
INFO:root:current mean train loss 1857.9432925768676
INFO:root:current train perplexity4.327163219451904
INFO:root:current mean train loss 1857.9621849914674
INFO:root:current train perplexity4.326610565185547


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.76s/it]
INFO:root:final mean train loss: 1857.2689247766168
INFO:root:final train perplexity: 4.326478958129883
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.62s/it]
INFO:root:eval mean loss: 2837.3045115427926
INFO:root:eval perplexity: 10.259615898132324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/46

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [2:07:32<2:31:47, 168.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1859.6855800298997
INFO:root:current train perplexity4.313490390777588
INFO:root:current mean train loss 1858.4560250129489
INFO:root:current train perplexity4.299412727355957
INFO:root:current mean train loss 1858.7204442143016
INFO:root:current train perplexity4.30108118057251
INFO:root:current mean train loss 1857.787424322814
INFO:root:current train perplexity4.297449111938477
INFO:root:current mean train loss 1852.8959098070427
INFO:root:current train perplexity4.2951507568359375
INFO:root:current mean train loss 1854.446166361876
INFO:root:current train perplexity4.301144123077393
INFO:root:current mean train loss 1855.0675989898816
INFO:root:current train perplexity4.308407306671143
INFO:root:current mean train loss 1856.2856800113536
INFO:root:current train perplexity4.308745384216309
INFO:root:current mean train loss 1859.0017132796982
INFO:root:current train perplexity4.311327934265137
INFO:root:current mean train loss 1856.3752361768125
INFO:root:current train perplexity4.310039520263672
INFO:root:current mean train loss 1855.9812819121835
INFO:root:current train perplexity4.309452533721924
INFO:root:current mean train loss 1856.324296788176
INFO:root:current train perplexity4.310664653778076
INFO:root:current mean train loss 1856.5703789192098
INFO:root:current train perplexity4.313999652862549
INFO:root:current mean train loss 1856.3621728055982
INFO:root:current train perplexity4.315106391906738
INFO:root:current mean train loss 1855.8225024298667
INFO:root:current train perplexity4.315854549407959
INFO:root:current mean train loss 1854.482764227793
INFO:root:current train perplexity4.313344955444336
INFO:root:current mean train loss 1854.8290247329994
INFO:root:current train perplexity4.312519073486328
INFO:root:current mean train loss 1854.7590131208108
INFO:root:current train perplexity4.313623905181885
INFO:root:current mean train loss 1853.5190948210518
INFO:root:current train perplexity4.312380790710449
INFO:root:current mean train loss 1854.0060053540865
INFO:root:current train perplexity4.313426971435547


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.83s/it]
INFO:root:final mean train loss: 1853.4126149849403
INFO:root:final train perplexity: 4.313340663909912
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.76s/it]
INFO:root:eval mean loss: 2838.327193893112
INFO:root:eval perplexity: 10.268229484558105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/47

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [2:10:16<2:27:55, 167.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1847.2350650709502
INFO:root:current train perplexity4.25671911239624
INFO:root:current mean train loss 1844.9108350349195
INFO:root:current train perplexity4.259235858917236
INFO:root:current mean train loss 1843.774040478188
INFO:root:current train perplexity4.278735160827637
INFO:root:current mean train loss 1840.7474273221576
INFO:root:current train perplexity4.275335311889648
INFO:root:current mean train loss 1842.4389530779367
INFO:root:current train perplexity4.27577543258667
INFO:root:current mean train loss 1842.89039474028
INFO:root:current train perplexity4.27720308303833
INFO:root:current mean train loss 1846.1263646341667
INFO:root:current train perplexity4.284997940063477
INFO:root:current mean train loss 1846.5305386880286
INFO:root:current train perplexity4.289132595062256
INFO:root:current mean train loss 1847.6281962575254
INFO:root:current train perplexity4.292988300323486
INFO:root:current mean train loss 1846.1356416446174
INFO:root:current train perplexity4.290055751800537
INFO:root:current mean train loss 1848.1978036015412
INFO:root:current train perplexity4.290085792541504
INFO:root:current mean train loss 1848.7063936924496
INFO:root:current train perplexity4.292401313781738
INFO:root:current mean train loss 1846.8398792989817
INFO:root:current train perplexity4.289836883544922
INFO:root:current mean train loss 1847.6160473039051
INFO:root:current train perplexity4.293259143829346
INFO:root:current mean train loss 1847.4840844107248
INFO:root:current train perplexity4.294383525848389
INFO:root:current mean train loss 1848.0551384268176
INFO:root:current train perplexity4.29734992980957
INFO:root:current mean train loss 1848.2695409552368
INFO:root:current train perplexity4.297501087188721
INFO:root:current mean train loss 1848.4607971666653
INFO:root:current train perplexity4.297201633453369
INFO:root:current mean train loss 1848.4510709643992
INFO:root:current train perplexity4.296228408813477


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.05s/it]
INFO:root:final mean train loss: 1848.525070182735
INFO:root:final train perplexity: 4.296745777130127
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.51s/it]
INFO:root:eval mean loss: 2838.20459277637
INFO:root:eval perplexity: 10.267196655273438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/48

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [2:13:01<2:24:23, 166.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1784.132470703125
INFO:root:current train perplexity4.063747406005859
INFO:root:current mean train loss 1838.8441979449728
INFO:root:current train perplexity4.258853912353516
INFO:root:current mean train loss 1843.8973922374637
INFO:root:current train perplexity4.253115177154541
INFO:root:current mean train loss 1842.1399979848711
INFO:root:current train perplexity4.249573707580566
INFO:root:current mean train loss 1845.1900796545558
INFO:root:current train perplexity4.258860111236572
INFO:root:current mean train loss 1841.2409324275636
INFO:root:current train perplexity4.25111198425293
INFO:root:current mean train loss 1838.2583694582063
INFO:root:current train perplexity4.251442909240723
INFO:root:current mean train loss 1840.6639026988637
INFO:root:current train perplexity4.262091636657715
INFO:root:current mean train loss 1840.1556236220283
INFO:root:current train perplexity4.265778541564941
INFO:root:current mean train loss 1839.0517496744792
INFO:root:current train perplexity4.266778469085693
INFO:root:current mean train loss 1841.1296955578432
INFO:root:current train perplexity4.270866870880127
INFO:root:current mean train loss 1842.0943768830577
INFO:root:current train perplexity4.268136024475098
INFO:root:current mean train loss 1843.0053446702996
INFO:root:current train perplexity4.267817497253418
INFO:root:current mean train loss 1843.2732756059886
INFO:root:current train perplexity4.269635200500488
INFO:root:current mean train loss 1842.7246606186507
INFO:root:current train perplexity4.271749973297119
INFO:root:current mean train loss 1842.1653364628455
INFO:root:current train perplexity4.273935317993164
INFO:root:current mean train loss 1843.100426074521
INFO:root:current train perplexity4.2754740715026855
INFO:root:current mean train loss 1842.8230966996173
INFO:root:current train perplexity4.276596546173096
INFO:root:current mean train loss 1843.7534183050318
INFO:root:current train perplexity4.278167247772217
INFO:root:current mean train loss 1843.9058155826738
INFO:root:current train perplexity4.280877590179443


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.09s/it]
INFO:root:final mean train loss: 1844.4284908354311
INFO:root:final train perplexity: 4.282886981964111
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.27s/it]
INFO:root:eval mean loss: 2843.0743426532
INFO:root:eval perplexity: 10.308307647705078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/49

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [2:15:45<2:21:04, 165.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1859.009017944336
INFO:root:current train perplexity4.3020148277282715
INFO:root:current mean train loss 1836.7561673251066
INFO:root:current train perplexity4.2174973487854
INFO:root:current mean train loss 1834.4044252592942
INFO:root:current train perplexity4.221126079559326
INFO:root:current mean train loss 1835.5580705389918
INFO:root:current train perplexity4.231400012969971
INFO:root:current mean train loss 1837.1559589527271
INFO:root:current train perplexity4.239483833312988
INFO:root:current mean train loss 1835.1283147137865
INFO:root:current train perplexity4.2461395263671875
INFO:root:current mean train loss 1835.8869146033178
INFO:root:current train perplexity4.251721382141113
INFO:root:current mean train loss 1837.0134377401382
INFO:root:current train perplexity4.254848003387451
INFO:root:current mean train loss 1836.5262487851655
INFO:root:current train perplexity4.2550201416015625
INFO:root:current mean train loss 1837.1509995358185
INFO:root:current train perplexity4.2580108642578125
INFO:root:current mean train loss 1836.1752106422603
INFO:root:current train perplexity4.255982398986816
INFO:root:current mean train loss 1838.0720391694733
INFO:root:current train perplexity4.258415222167969
INFO:root:current mean train loss 1838.8459113975623
INFO:root:current train perplexity4.259928226470947
INFO:root:current mean train loss 1837.637013936544
INFO:root:current train perplexity4.257598876953125
INFO:root:current mean train loss 1837.0893514622524
INFO:root:current train perplexity4.2573933601379395
INFO:root:current mean train loss 1837.2757891064837
INFO:root:current train perplexity4.2574262619018555
INFO:root:current mean train loss 1838.2775628332997
INFO:root:current train perplexity4.259178638458252
INFO:root:current mean train loss 1837.7115365043799
INFO:root:current train perplexity4.259832859039307
INFO:root:current mean train loss 1838.9688883952178
INFO:root:current train perplexity4.262127876281738
INFO:root:current mean train loss 1839.0708192939837
INFO:root:current train perplexity4.264405250549316


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.45s/it]
INFO:root:final mean train loss: 1839.6298175298139
INFO:root:final train perplexity: 4.266708850860596
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.63s/it]
INFO:root:eval mean loss: 2843.9097346858575
INFO:root:eval perplexity: 10.315373420715332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/50

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [2:18:32<2:18:22, 166.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1811.5195088289222
INFO:root:current train perplexity4.202547550201416
INFO:root:current mean train loss 1824.3708020920722
INFO:root:current train perplexity4.189602851867676
INFO:root:current mean train loss 1825.5653821340047
INFO:root:current train perplexity4.211625099182129
INFO:root:current mean train loss 1828.00269079345
INFO:root:current train perplexity4.223630905151367
INFO:root:current mean train loss 1832.3810325571583
INFO:root:current train perplexity4.224514484405518
INFO:root:current mean train loss 1832.7489745204348
INFO:root:current train perplexity4.227664947509766
INFO:root:current mean train loss 1830.8769858526339
INFO:root:current train perplexity4.229565143585205
INFO:root:current mean train loss 1832.7550171061416
INFO:root:current train perplexity4.234034061431885
INFO:root:current mean train loss 1832.2536557829983
INFO:root:current train perplexity4.232965469360352
INFO:root:current mean train loss 1834.458406181054
INFO:root:current train perplexity4.239704608917236
INFO:root:current mean train loss 1835.4527811317698
INFO:root:current train perplexity4.2458672523498535
INFO:root:current mean train loss 1835.0511099580478
INFO:root:current train perplexity4.2485032081604
INFO:root:current mean train loss 1835.2222377511384
INFO:root:current train perplexity4.251634120941162
INFO:root:current mean train loss 1833.8379557774276
INFO:root:current train perplexity4.249833106994629
INFO:root:current mean train loss 1833.727905863149
INFO:root:current train perplexity4.250341892242432
INFO:root:current mean train loss 1833.6479541047147
INFO:root:current train perplexity4.250369548797607
INFO:root:current mean train loss 1834.0359934939263
INFO:root:current train perplexity4.251341819763184
INFO:root:current mean train loss 1834.2133255833692
INFO:root:current train perplexity4.251931667327881
INFO:root:current mean train loss 1834.8818693434373
INFO:root:current train perplexity4.252223014831543
INFO:root:current mean train loss 1836.4236153005147
INFO:root:current train perplexity4.254352569580078


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.35s/it]
INFO:root:final mean train loss: 1835.6892100616471
INFO:root:final train perplexity: 4.253469944000244
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.05s/it]
INFO:root:eval mean loss: 2842.9150867175767
INFO:root:eval perplexity: 10.306958198547363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/51

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [2:21:28<2:18:10, 169.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1830.6820068359375
INFO:root:current train perplexity4.203989028930664
INFO:root:current mean train loss 1823.1301129812218
INFO:root:current train perplexity4.214759826660156
INFO:root:current mean train loss 1826.9441055642035
INFO:root:current train perplexity4.20543909072876
INFO:root:current mean train loss 1827.1208923006318
INFO:root:current train perplexity4.222414016723633
INFO:root:current mean train loss 1827.830227176519
INFO:root:current train perplexity4.222414016723633
INFO:root:current mean train loss 1833.3884421843943
INFO:root:current train perplexity4.225175380706787
INFO:root:current mean train loss 1833.8095943233272
INFO:root:current train perplexity4.225833415985107
INFO:root:current mean train loss 1831.0785178241779
INFO:root:current train perplexity4.224331378936768
INFO:root:current mean train loss 1833.193212073064
INFO:root:current train perplexity4.230148792266846
INFO:root:current mean train loss 1831.6323407727987
INFO:root:current train perplexity4.22786283493042
INFO:root:current mean train loss 1831.6274018994416
INFO:root:current train perplexity4.233991622924805
INFO:root:current mean train loss 1830.7553293218334
INFO:root:current train perplexity4.232573509216309
INFO:root:current mean train loss 1831.4164888644104
INFO:root:current train perplexity4.233565807342529
INFO:root:current mean train loss 1830.554633256457
INFO:root:current train perplexity4.23518705368042
INFO:root:current mean train loss 1830.0533806149012
INFO:root:current train perplexity4.235650539398193
INFO:root:current mean train loss 1831.4636641267311
INFO:root:current train perplexity4.238871097564697
INFO:root:current mean train loss 1830.981098665052
INFO:root:current train perplexity4.237547397613525
INFO:root:current mean train loss 1832.056309666531
INFO:root:current train perplexity4.238868236541748
INFO:root:current mean train loss 1831.7244895943236
INFO:root:current train perplexity4.238816261291504
INFO:root:current mean train loss 1832.0030616302336
INFO:root:current train perplexity4.23949670791626


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.42s/it]
INFO:root:final mean train loss: 1831.7648643843766
INFO:root:final train perplexity: 4.240324974060059
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.46s/it]
INFO:root:eval mean loss: 2846.273485888232
INFO:root:eval perplexity: 10.335402488708496
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/52

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [2:24:13<2:14:20, 167.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1821.776958419616
INFO:root:current train perplexity4.217526435852051
INFO:root:current mean train loss 1818.804085820099
INFO:root:current train perplexity4.207536697387695
INFO:root:current mean train loss 1814.9938084902274
INFO:root:current train perplexity4.194845199584961
INFO:root:current mean train loss 1816.9280894306871
INFO:root:current train perplexity4.2030181884765625
INFO:root:current mean train loss 1816.7662848873415
INFO:root:current train perplexity4.200847148895264
INFO:root:current mean train loss 1817.2552850373204
INFO:root:current train perplexity4.207970142364502
INFO:root:current mean train loss 1820.2867413767958
INFO:root:current train perplexity4.2113165855407715
INFO:root:current mean train loss 1820.6189276645314
INFO:root:current train perplexity4.208559989929199
INFO:root:current mean train loss 1822.3509448214538
INFO:root:current train perplexity4.2097296714782715
INFO:root:current mean train loss 1822.6992363837583
INFO:root:current train perplexity4.212043285369873
INFO:root:current mean train loss 1822.5583389014528
INFO:root:current train perplexity4.211597442626953
INFO:root:current mean train loss 1823.4972307684052
INFO:root:current train perplexity4.217330455780029
INFO:root:current mean train loss 1822.6144482916627
INFO:root:current train perplexity4.2188544273376465
INFO:root:current mean train loss 1823.7841433223743
INFO:root:current train perplexity4.221024513244629
INFO:root:current mean train loss 1825.3201291887485
INFO:root:current train perplexity4.221970558166504
INFO:root:current mean train loss 1826.9382688193402
INFO:root:current train perplexity4.2242112159729
INFO:root:current mean train loss 1827.0164540336732
INFO:root:current train perplexity4.223038196563721
INFO:root:current mean train loss 1827.652638964351
INFO:root:current train perplexity4.224304676055908
INFO:root:current mean train loss 1827.811326685828
INFO:root:current train perplexity4.225360870361328
INFO:root:current mean train loss 1827.3886205660713
INFO:root:current train perplexity4.225715637207031


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.08s/it]
INFO:root:final mean train loss: 1827.3886205660713
INFO:root:final train perplexity: 4.225715637207031
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.15s/it]
INFO:root:eval mean loss: 2846.4375828465186
INFO:root:eval perplexity: 10.33679485321045
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/53

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [2:26:58<2:10:56, 167.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1819.153819580078
INFO:root:current train perplexity4.271851062774658
INFO:root:current mean train loss 1832.9893029785155
INFO:root:current train perplexity4.24564790725708
INFO:root:current mean train loss 1820.3605354817707
INFO:root:current train perplexity4.221494197845459
INFO:root:current mean train loss 1820.2270822143555
INFO:root:current train perplexity4.215050220489502
INFO:root:current mean train loss 1818.7594431152343
INFO:root:current train perplexity4.208761215209961
INFO:root:current mean train loss 1823.81033203125
INFO:root:current train perplexity4.216063022613525
INFO:root:current mean train loss 1822.0714249093191
INFO:root:current train perplexity4.209349632263184
INFO:root:current mean train loss 1821.5007592773438
INFO:root:current train perplexity4.210573673248291
INFO:root:current mean train loss 1822.162537299262
INFO:root:current train perplexity4.210619926452637
INFO:root:current mean train loss 1822.1189133300782
INFO:root:current train perplexity4.211766719818115
INFO:root:current mean train loss 1824.6754896129262
INFO:root:current train perplexity4.215168476104736
INFO:root:current mean train loss 1825.1221680704753
INFO:root:current train perplexity4.215748310089111
INFO:root:current mean train loss 1825.76102341872
INFO:root:current train perplexity4.215311527252197
INFO:root:current mean train loss 1823.5756480189732
INFO:root:current train perplexity4.212824821472168
INFO:root:current mean train loss 1823.530255859375
INFO:root:current train perplexity4.212876319885254
INFO:root:current mean train loss 1823.909316482544
INFO:root:current train perplexity4.213456153869629
INFO:root:current mean train loss 1824.6906536506203
INFO:root:current train perplexity4.213632583618164
INFO:root:current mean train loss 1826.101091240777
INFO:root:current train perplexity4.216248035430908
INFO:root:current mean train loss 1824.6269453510486
INFO:root:current train perplexity4.214382648468018


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.48s/it]
INFO:root:final mean train loss: 1823.563648864469
INFO:root:final train perplexity: 4.212987422943115
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.12s/it]
INFO:root:eval mean loss: 2845.4332887575074
INFO:root:eval perplexity: 10.328280448913574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/54

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [2:29:45<2:08:02, 167.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1825.9227366727941
INFO:root:current train perplexity4.27888298034668
INFO:root:current mean train loss 1810.43261197082
INFO:root:current train perplexity4.191627502441406
INFO:root:current mean train loss 1814.068352624568
INFO:root:current train perplexity4.179756164550781
INFO:root:current mean train loss 1812.2428371297071
INFO:root:current train perplexity4.182942867279053
INFO:root:current mean train loss 1818.652084972647
INFO:root:current train perplexity4.197779178619385
INFO:root:current mean train loss 1817.6867255500483
INFO:root:current train perplexity4.193268775939941
INFO:root:current mean train loss 1815.8515126430814
INFO:root:current train perplexity4.189000606536865
INFO:root:current mean train loss 1815.9309167156991
INFO:root:current train perplexity4.19463586807251
INFO:root:current mean train loss 1816.2415303822102
INFO:root:current train perplexity4.195322036743164
INFO:root:current mean train loss 1817.2462745258827
INFO:root:current train perplexity4.19804048538208
INFO:root:current mean train loss 1817.7402271732117
INFO:root:current train perplexity4.199865341186523
INFO:root:current mean train loss 1818.2883102977073
INFO:root:current train perplexity4.202822208404541
INFO:root:current mean train loss 1818.4713374492862
INFO:root:current train perplexity4.2041239738464355
INFO:root:current mean train loss 1817.5646341449851
INFO:root:current train perplexity4.203824043273926
INFO:root:current mean train loss 1818.371529136986
INFO:root:current train perplexity4.203773021697998
INFO:root:current mean train loss 1818.000554023798
INFO:root:current train perplexity4.200229644775391
INFO:root:current mean train loss 1818.63295616098
INFO:root:current train perplexity4.2019805908203125
INFO:root:current mean train loss 1818.778420983183
INFO:root:current train perplexity4.201836585998535
INFO:root:current mean train loss 1819.304898654096
INFO:root:current train perplexity4.201505661010742
INFO:root:current mean train loss 1819.7612616708643
INFO:root:current train perplexity4.200109004974365


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.29s/it]
INFO:root:final mean train loss: 1819.7777559758435
INFO:root:final train perplexity: 4.200427055358887
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.87s/it]
INFO:root:eval mean loss: 2850.235062699418
INFO:root:eval perplexity: 10.36905288696289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/55

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [2:32:30<2:04:51, 166.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1792.0446633731617
INFO:root:current train perplexity4.143033027648926
INFO:root:current mean train loss 1805.9996183025303
INFO:root:current train perplexity4.155429363250732
INFO:root:current mean train loss 1815.7192852313701
INFO:root:current train perplexity4.166707992553711
INFO:root:current mean train loss 1818.3326098048044
INFO:root:current train perplexity4.175233364105225
INFO:root:current mean train loss 1818.012008737309
INFO:root:current train perplexity4.178345203399658
INFO:root:current mean train loss 1816.9070768320605
INFO:root:current train perplexity4.1754469871521
INFO:root:current mean train loss 1814.5589395517054
INFO:root:current train perplexity4.170050621032715
INFO:root:current mean train loss 1814.1230613438245
INFO:root:current train perplexity4.169816493988037
INFO:root:current mean train loss 1813.7220965415167
INFO:root:current train perplexity4.171821117401123
INFO:root:current mean train loss 1811.419877699662
INFO:root:current train perplexity4.171357154846191
INFO:root:current mean train loss 1810.7980570986838
INFO:root:current train perplexity4.174898624420166
INFO:root:current mean train loss 1811.0417439563355
INFO:root:current train perplexity4.174546718597412
INFO:root:current mean train loss 1812.0303670181447
INFO:root:current train perplexity4.178475379943848
INFO:root:current mean train loss 1812.3424007295669
INFO:root:current train perplexity4.180211067199707
INFO:root:current mean train loss 1812.8263432331164
INFO:root:current train perplexity4.183354377746582
INFO:root:current mean train loss 1813.8732458957638
INFO:root:current train perplexity4.183891773223877
INFO:root:current mean train loss 1814.6562992315398
INFO:root:current train perplexity4.185745716094971
INFO:root:current mean train loss 1815.8533920763273
INFO:root:current train perplexity4.189127445220947
INFO:root:current mean train loss 1815.5341296346783
INFO:root:current train perplexity4.187413692474365
INFO:root:current mean train loss 1816.6870651166219
INFO:root:current train perplexity4.188589096069336


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.64s/it]
INFO:root:final mean train loss: 1816.2326171382533
INFO:root:final train perplexity: 4.188699722290039
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.91s/it]
INFO:root:eval mean loss: 2853.3751774235175
INFO:root:eval perplexity: 10.395804405212402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/56

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [2:35:16<2:01:53, 166.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1815.770206227022
INFO:root:current train perplexity4.181214332580566
INFO:root:current mean train loss 1810.5830660182119
INFO:root:current train perplexity4.161111831665039
INFO:root:current mean train loss 1806.7939997821215
INFO:root:current train perplexity4.161069393157959
INFO:root:current mean train loss 1806.2157872735265
INFO:root:current train perplexity4.153209686279297
INFO:root:current mean train loss 1806.2650124831105
INFO:root:current train perplexity4.153603553771973
INFO:root:current mean train loss 1808.3087862710554
INFO:root:current train perplexity4.15629768371582
INFO:root:current mean train loss 1809.9823129305275
INFO:root:current train perplexity4.161531448364258
INFO:root:current mean train loss 1807.7663028071945
INFO:root:current train perplexity4.1605377197265625
INFO:root:current mean train loss 1807.4824083913227
INFO:root:current train perplexity4.161620616912842
INFO:root:current mean train loss 1807.4633443774235
INFO:root:current train perplexity4.16368293762207
INFO:root:current mean train loss 1809.1196344812977
INFO:root:current train perplexity4.168512344360352
INFO:root:current mean train loss 1810.2689889863095
INFO:root:current train perplexity4.168454170227051
INFO:root:current mean train loss 1812.0473104914506
INFO:root:current train perplexity4.170473098754883
INFO:root:current mean train loss 1812.8971236403302
INFO:root:current train perplexity4.1723127365112305
INFO:root:current mean train loss 1812.8600590480435
INFO:root:current train perplexity4.173235893249512
INFO:root:current mean train loss 1813.1435598032772
INFO:root:current train perplexity4.175212860107422
INFO:root:current mean train loss 1812.839097058246
INFO:root:current train perplexity4.174775123596191
INFO:root:current mean train loss 1812.9774166436143
INFO:root:current train perplexity4.175803184509277
INFO:root:current mean train loss 1813.8424376287312
INFO:root:current train perplexity4.177378177642822
INFO:root:current mean train loss 1813.2427464206057
INFO:root:current train perplexity4.177092552185059


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.76s/it]
INFO:root:final mean train loss: 1812.7184632609603
INFO:root:final train perplexity: 4.177106857299805
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.69s/it]
INFO:root:eval mean loss: 2854.722910654795
INFO:root:eval perplexity: 10.40731143951416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/57

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [2:37:59<1:58:20, 165.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1793.2715292537914
INFO:root:current train perplexity4.100369930267334
INFO:root:current mean train loss 1787.2223358154297
INFO:root:current train perplexity4.111257076263428
INFO:root:current mean train loss 1798.1615044892724
INFO:root:current train perplexity4.1240034103393555
INFO:root:current mean train loss 1796.362108313519
INFO:root:current train perplexity4.126704692840576
INFO:root:current mean train loss 1799.1877892649072
INFO:root:current train perplexity4.13070011138916
INFO:root:current mean train loss 1800.969858303876
INFO:root:current train perplexity4.136744976043701
INFO:root:current mean train loss 1800.5760518148275
INFO:root:current train perplexity4.136236667633057
INFO:root:current mean train loss 1801.6382975578308
INFO:root:current train perplexity4.139643669128418
INFO:root:current mean train loss 1803.6487127207392
INFO:root:current train perplexity4.142655849456787
INFO:root:current mean train loss 1806.5166206044598
INFO:root:current train perplexity4.149806499481201
INFO:root:current mean train loss 1805.396643020687
INFO:root:current train perplexity4.150819301605225
INFO:root:current mean train loss 1805.530567744007
INFO:root:current train perplexity4.153705596923828
INFO:root:current mean train loss 1807.0551336150063
INFO:root:current train perplexity4.155700206756592
INFO:root:current mean train loss 1805.5976967616389
INFO:root:current train perplexity4.156299591064453
INFO:root:current mean train loss 1806.4927708264593
INFO:root:current train perplexity4.160762310028076
INFO:root:current mean train loss 1807.0106757806273
INFO:root:current train perplexity4.160740852355957
INFO:root:current mean train loss 1807.3897777529928
INFO:root:current train perplexity4.160801410675049
INFO:root:current mean train loss 1808.1130154985108
INFO:root:current train perplexity4.161739826202393
INFO:root:current mean train loss 1808.4563783568028
INFO:root:current train perplexity4.162385940551758
INFO:root:current mean train loss 1809.3014919001882
INFO:root:current train perplexity4.164972305297852


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.86s/it]
INFO:root:final mean train loss: 1808.91233868005
INFO:root:final train perplexity: 4.164587497711182
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:24<00:00, 24.63s/it]
INFO:root:eval mean loss: 2857.620563678913
INFO:root:eval perplexity: 10.432084083557129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/58

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [2:40:55<1:58:00, 168.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1802.2404024011948
INFO:root:current train perplexity4.151369094848633
INFO:root:current mean train loss 1799.7173445418075
INFO:root:current train perplexity4.132572650909424
INFO:root:current mean train loss 1795.9271831311678
INFO:root:current train perplexity4.120175838470459
INFO:root:current mean train loss 1795.6234273538962
INFO:root:current train perplexity4.119801998138428
INFO:root:current mean train loss 1798.4791018141914
INFO:root:current train perplexity4.126387596130371
INFO:root:current mean train loss 1797.9728747245592
INFO:root:current train perplexity4.126306056976318
INFO:root:current mean train loss 1794.6116651103443
INFO:root:current train perplexity4.124427318572998
INFO:root:current mean train loss 1796.5123563146894
INFO:root:current train perplexity4.125185966491699
INFO:root:current mean train loss 1797.9570723539018
INFO:root:current train perplexity4.130406379699707
INFO:root:current mean train loss 1798.1723389911167
INFO:root:current train perplexity4.133402347564697
INFO:root:current mean train loss 1798.894437981531
INFO:root:current train perplexity4.132622718811035
INFO:root:current mean train loss 1800.0894884584322
INFO:root:current train perplexity4.135440826416016
INFO:root:current mean train loss 1799.6662059026933
INFO:root:current train perplexity4.137683391571045
INFO:root:current mean train loss 1800.8023396956792
INFO:root:current train perplexity4.138001441955566
INFO:root:current mean train loss 1800.8291273740003
INFO:root:current train perplexity4.139615535736084
INFO:root:current mean train loss 1801.4968839338526
INFO:root:current train perplexity4.144567966461182
INFO:root:current mean train loss 1801.7704313102745
INFO:root:current train perplexity4.146381855010986
INFO:root:current mean train loss 1803.8526555251008
INFO:root:current train perplexity4.149831295013428
INFO:root:current mean train loss 1804.5153837735204
INFO:root:current train perplexity4.15109395980835


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.13s/it]
INFO:root:final mean train loss: 1805.3690710332257
INFO:root:final train perplexity: 4.152965545654297
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.54s/it]
INFO:root:eval mean loss: 2858.0222849802926
INFO:root:eval perplexity: 10.435526847839355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/59

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [2:43:49<1:56:16, 170.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1828.6224975585938
INFO:root:current train perplexity4.193985939025879
INFO:root:current mean train loss 1803.4665970147826
INFO:root:current train perplexity4.116421699523926
INFO:root:current mean train loss 1795.2162771697092
INFO:root:current train perplexity4.1143107414245605
INFO:root:current mean train loss 1792.5151819898592
INFO:root:current train perplexity4.105698108673096
INFO:root:current mean train loss 1795.2200226285565
INFO:root:current train perplexity4.113076210021973
INFO:root:current mean train loss 1799.8948198903604
INFO:root:current train perplexity4.122950553894043
INFO:root:current mean train loss 1798.4101694303495
INFO:root:current train perplexity4.12315034866333
INFO:root:current mean train loss 1801.730558303007
INFO:root:current train perplexity4.1293206214904785
INFO:root:current mean train loss 1801.3172234513813
INFO:root:current train perplexity4.136587619781494
INFO:root:current mean train loss 1800.1217334688106
INFO:root:current train perplexity4.137061595916748
INFO:root:current mean train loss 1799.6333450043273
INFO:root:current train perplexity4.1377458572387695
INFO:root:current mean train loss 1800.6380358244244
INFO:root:current train perplexity4.1383376121521
INFO:root:current mean train loss 1800.0939306681248
INFO:root:current train perplexity4.138445854187012
INFO:root:current mean train loss 1800.7593431604623
INFO:root:current train perplexity4.140959739685059
INFO:root:current mean train loss 1800.7472143241241
INFO:root:current train perplexity4.141201972961426
INFO:root:current mean train loss 1802.4513714786535
INFO:root:current train perplexity4.14122200012207
INFO:root:current mean train loss 1802.9731792778557
INFO:root:current train perplexity4.141228675842285
INFO:root:current mean train loss 1802.7264464543093
INFO:root:current train perplexity4.1419358253479
INFO:root:current mean train loss 1802.6517323145724
INFO:root:current train perplexity4.141678333282471
INFO:root:current mean train loss 1802.2315106477147
INFO:root:current train perplexity4.141882419586182


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.05s/it]
INFO:root:final mean train loss: 1802.1490448967593
INFO:root:final train perplexity: 4.142432689666748
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.74s/it]
INFO:root:eval mean loss: 2855.4505992809213
INFO:root:eval perplexity: 10.41352653503418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/60

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [2:46:32<1:51:58, 167.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1760.3962659333881
INFO:root:current train perplexity4.103189468383789
INFO:root:current mean train loss 1784.2265758354122
INFO:root:current train perplexity4.11367654800415
INFO:root:current mean train loss 1797.6226684012913
INFO:root:current train perplexity4.122686862945557
INFO:root:current mean train loss 1798.2297634973795
INFO:root:current train perplexity4.127556324005127
INFO:root:current mean train loss 1799.5031178913707
INFO:root:current train perplexity4.131775379180908
INFO:root:current mean train loss 1796.5767939867083
INFO:root:current train perplexity4.130763530731201
INFO:root:current mean train loss 1796.1977598224203
INFO:root:current train perplexity4.129106521606445
INFO:root:current mean train loss 1793.0621210557197
INFO:root:current train perplexity4.124770641326904
INFO:root:current mean train loss 1792.9680585663252
INFO:root:current train perplexity4.124629497528076
INFO:root:current mean train loss 1792.7058169226912
INFO:root:current train perplexity4.121318340301514
INFO:root:current mean train loss 1795.5129549065796
INFO:root:current train perplexity4.1242756843566895
INFO:root:current mean train loss 1795.6650571712328
INFO:root:current train perplexity4.126796245574951
INFO:root:current mean train loss 1796.0051045218288
INFO:root:current train perplexity4.126049041748047
INFO:root:current mean train loss 1795.0132528193708
INFO:root:current train perplexity4.124149799346924
INFO:root:current mean train loss 1795.9638979846613
INFO:root:current train perplexity4.126470565795898
INFO:root:current mean train loss 1795.904735974531
INFO:root:current train perplexity4.126180648803711
INFO:root:current mean train loss 1796.3676333318454
INFO:root:current train perplexity4.1264119148254395
INFO:root:current mean train loss 1797.5672767199771
INFO:root:current train perplexity4.127330303192139
INFO:root:current mean train loss 1798.1210234874286
INFO:root:current train perplexity4.128857612609863
INFO:root:current mean train loss 1799.218745928869
INFO:root:current train perplexity4.130697727203369


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.56s/it]
INFO:root:final mean train loss: 1798.810911177627
INFO:root:final train perplexity: 4.131541728973389
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.20s/it]
INFO:root:eval mean loss: 2857.401710304054
INFO:root:eval perplexity: 10.430213928222656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/61

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [2:49:19<1:48:58, 167.66s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1796.087137858073
INFO:root:current train perplexity4.064208984375
INFO:root:current mean train loss 1784.189437866211
INFO:root:current train perplexity4.069188117980957
INFO:root:current mean train loss 1790.4631492485435
INFO:root:current train perplexity4.093228340148926
INFO:root:current mean train loss 1792.965418861026
INFO:root:current train perplexity4.113862991333008
INFO:root:current mean train loss 1794.0616298290568
INFO:root:current train perplexity4.114371299743652
INFO:root:current mean train loss 1795.5586044539266
INFO:root:current train perplexity4.1161699295043945
INFO:root:current mean train loss 1794.0517069498699
INFO:root:current train perplexity4.114179611206055
INFO:root:current mean train loss 1795.2920668228812
INFO:root:current train perplexity4.116559028625488
INFO:root:current mean train loss 1797.5187034789456
INFO:root:current train perplexity4.12399435043335
INFO:root:current mean train loss 1797.6471073770115
INFO:root:current train perplexity4.123643398284912
INFO:root:current mean train loss 1796.5171884661936
INFO:root:current train perplexity4.120387554168701
INFO:root:current mean train loss 1796.642881581481
INFO:root:current train perplexity4.119255542755127
INFO:root:current mean train loss 1796.1954402985311
INFO:root:current train perplexity4.117703437805176
INFO:root:current mean train loss 1796.5284141494842
INFO:root:current train perplexity4.118202209472656
INFO:root:current mean train loss 1796.391207044171
INFO:root:current train perplexity4.120812892913818
INFO:root:current mean train loss 1796.191172838211
INFO:root:current train perplexity4.121745586395264
INFO:root:current mean train loss 1795.7023334829614
INFO:root:current train perplexity4.12141752243042
INFO:root:current mean train loss 1795.7949735579953
INFO:root:current train perplexity4.12110710144043
INFO:root:current mean train loss 1795.9616796289913
INFO:root:current train perplexity4.121038913726807
INFO:root:current mean train loss 1796.486914327322
INFO:root:current train perplexity4.122372150421143


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.34s/it]
INFO:root:final mean train loss: 1796.0567434890909
INFO:root:final train perplexity: 4.122576713562012
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.26s/it]
INFO:root:eval mean loss: 2859.9647960949233
INFO:root:eval perplexity: 10.45217227935791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/62

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [2:52:06<1:45:59, 167.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1792.9228377432194
INFO:root:current train perplexity4.0748820304870605
INFO:root:current mean train loss 1780.1517780777676
INFO:root:current train perplexity4.083901882171631
INFO:root:current mean train loss 1783.0055727751358
INFO:root:current train perplexity4.085954189300537
INFO:root:current mean train loss 1787.0886908252921
INFO:root:current train perplexity4.096948146820068
INFO:root:current mean train loss 1786.931364956281
INFO:root:current train perplexity4.097436904907227
INFO:root:current mean train loss 1789.3962636330243
INFO:root:current train perplexity4.102962493896484
INFO:root:current mean train loss 1789.4715462139884
INFO:root:current train perplexity4.100743770599365
INFO:root:current mean train loss 1790.4842185619502
INFO:root:current train perplexity4.103241443634033
INFO:root:current mean train loss 1792.8803261581368
INFO:root:current train perplexity4.106423854827881
INFO:root:current mean train loss 1792.7962149492967
INFO:root:current train perplexity4.104804515838623
INFO:root:current mean train loss 1793.6436334014052
INFO:root:current train perplexity4.106470584869385
INFO:root:current mean train loss 1793.4587288002087
INFO:root:current train perplexity4.108278274536133
INFO:root:current mean train loss 1792.7292576916961
INFO:root:current train perplexity4.109068393707275
INFO:root:current mean train loss 1792.6535389203102
INFO:root:current train perplexity4.1082563400268555
INFO:root:current mean train loss 1793.525495892792
INFO:root:current train perplexity4.110802173614502
INFO:root:current mean train loss 1794.1431698476738
INFO:root:current train perplexity4.1131510734558105
INFO:root:current mean train loss 1793.936653852607
INFO:root:current train perplexity4.1139092445373535
INFO:root:current mean train loss 1793.7344325882193
INFO:root:current train perplexity4.113348007202148
INFO:root:current mean train loss 1793.5267513828926
INFO:root:current train perplexity4.113439083099365
INFO:root:current mean train loss 1793.6670461909562
INFO:root:current train perplexity4.112922668457031


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.18s/it]
INFO:root:final mean train loss: 1792.9570039796276
INFO:root:final train perplexity: 4.1125102043151855
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.60s/it]
INFO:root:eval mean loss: 2862.8826805320946
INFO:root:eval perplexity: 10.477227210998535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/63

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [2:55:00<1:44:36, 169.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1794.0429303850447
INFO:root:current train perplexity4.115715503692627
INFO:root:current mean train loss 1791.4951818129596
INFO:root:current train perplexity4.109508037567139
INFO:root:current mean train loss 1791.321661150897
INFO:root:current train perplexity4.101268291473389
INFO:root:current mean train loss 1786.5143825221705
INFO:root:current train perplexity4.087435245513916
INFO:root:current mean train loss 1788.306155720163
INFO:root:current train perplexity4.098379611968994
INFO:root:current mean train loss 1787.0954795435855
INFO:root:current train perplexity4.101984024047852
INFO:root:current mean train loss 1788.372165418027
INFO:root:current train perplexity4.096600532531738
INFO:root:current mean train loss 1789.673138348468
INFO:root:current train perplexity4.099085330963135
INFO:root:current mean train loss 1791.5843698085039
INFO:root:current train perplexity4.101694583892822
INFO:root:current mean train loss 1792.4684079514336
INFO:root:current train perplexity4.101324558258057
INFO:root:current mean train loss 1792.0352416992187
INFO:root:current train perplexity4.099578857421875
INFO:root:current mean train loss 1791.8582682291667
INFO:root:current train perplexity4.097164630889893
INFO:root:current mean train loss 1791.6527874323326
INFO:root:current train perplexity4.095165252685547
INFO:root:current mean train loss 1791.0435454208484
INFO:root:current train perplexity4.095636367797852
INFO:root:current mean train loss 1790.6586390073608
INFO:root:current train perplexity4.096499919891357
INFO:root:current mean train loss 1790.1434062593303
INFO:root:current train perplexity4.096405506134033
INFO:root:current mean train loss 1790.282160337528
INFO:root:current train perplexity4.098097801208496
INFO:root:current mean train loss 1790.3598703847767
INFO:root:current train perplexity4.09775972366333
INFO:root:current mean train loss 1790.1526098893926
INFO:root:current train perplexity4.09916877746582
INFO:root:current mean train loss 1790.1025794014713
INFO:root:current train perplexity4.1012797355651855


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.61s/it]
INFO:root:final mean train loss: 1789.5686443904044
INFO:root:final train perplexity: 4.101536750793457
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.14s/it]
INFO:root:eval mean loss: 2862.7396647135415
INFO:root:eval perplexity: 10.475997924804688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/64

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [2:57:47<1:41:16, 168.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1786.2497825184087
INFO:root:current train perplexity4.069461822509766
INFO:root:current mean train loss 1788.8644307998413
INFO:root:current train perplexity4.086671352386475
INFO:root:current mean train loss 1787.9990008948987
INFO:root:current train perplexity4.078341484069824
INFO:root:current mean train loss 1780.5622631141998
INFO:root:current train perplexity4.076994895935059
INFO:root:current mean train loss 1779.5888646809228
INFO:root:current train perplexity4.078823089599609
INFO:root:current mean train loss 1777.7019891430207
INFO:root:current train perplexity4.075445652008057
INFO:root:current mean train loss 1778.8311442412664
INFO:root:current train perplexity4.07719612121582
INFO:root:current mean train loss 1778.282962862085
INFO:root:current train perplexity4.07451868057251
INFO:root:current mean train loss 1781.1812631290957
INFO:root:current train perplexity4.076298713684082
INFO:root:current mean train loss 1782.9821527513932
INFO:root:current train perplexity4.079665660858154
INFO:root:current mean train loss 1782.3264732887246
INFO:root:current train perplexity4.077913761138916
INFO:root:current mean train loss 1783.8754713127566
INFO:root:current train perplexity4.083528995513916
INFO:root:current mean train loss 1783.5508513432098
INFO:root:current train perplexity4.082674026489258
INFO:root:current mean train loss 1784.7924204457124
INFO:root:current train perplexity4.086052417755127
INFO:root:current mean train loss 1786.0164894252796
INFO:root:current train perplexity4.087668418884277
INFO:root:current mean train loss 1786.773077904089
INFO:root:current train perplexity4.090076446533203
INFO:root:current mean train loss 1786.3741847989681
INFO:root:current train perplexity4.091444492340088
INFO:root:current mean train loss 1786.1118348500017
INFO:root:current train perplexity4.089988708496094
INFO:root:current mean train loss 1786.2279480336265
INFO:root:current train perplexity4.0902910232543945


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.15s/it]
INFO:root:final mean train loss: 1786.5059882782953
INFO:root:final train perplexity: 4.091640472412109
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.91s/it]
INFO:root:eval mean loss: 2862.5136784733954
INFO:root:eval perplexity: 10.474055290222168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/65

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [3:00:34<1:38:10, 168.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1754.3169860839844
INFO:root:current train perplexity4.046539783477783
INFO:root:current mean train loss 1770.6687387319712
INFO:root:current train perplexity4.052973747253418
INFO:root:current mean train loss 1785.686268525965
INFO:root:current train perplexity4.083407402038574
INFO:root:current mean train loss 1782.2148774799548
INFO:root:current train perplexity4.070738315582275
INFO:root:current mean train loss 1780.9611765040029
INFO:root:current train perplexity4.069572925567627
INFO:root:current mean train loss 1782.5872979542567
INFO:root:current train perplexity4.072445869445801
INFO:root:current mean train loss 1782.0692122503622
INFO:root:current train perplexity4.0691819190979
INFO:root:current mean train loss 1782.1010570526123
INFO:root:current train perplexity4.0723114013671875
INFO:root:current mean train loss 1784.37249922871
INFO:root:current train perplexity4.078146934509277
INFO:root:current mean train loss 1784.3718461568376
INFO:root:current train perplexity4.075911045074463
INFO:root:current mean train loss 1784.1114504384805
INFO:root:current train perplexity4.07420015335083
INFO:root:current mean train loss 1783.2151958078578
INFO:root:current train perplexity4.075094699859619
INFO:root:current mean train loss 1783.771765015054
INFO:root:current train perplexity4.077297687530518
INFO:root:current mean train loss 1784.0933410082857
INFO:root:current train perplexity4.07882833480835
INFO:root:current mean train loss 1784.083753536909
INFO:root:current train perplexity4.0807342529296875
INFO:root:current mean train loss 1783.5865144932525
INFO:root:current train perplexity4.079925060272217
INFO:root:current mean train loss 1783.6212868250516
INFO:root:current train perplexity4.078628063201904
INFO:root:current mean train loss 1782.822714505621
INFO:root:current train perplexity4.079760551452637
INFO:root:current mean train loss 1783.0510740428172
INFO:root:current train perplexity4.081114292144775
INFO:root:current mean train loss 1783.807386574625
INFO:root:current train perplexity4.082376003265381


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.92s/it]
INFO:root:final mean train loss: 1784.2457255999727
INFO:root:final train perplexity: 4.084353446960449
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.14s/it]
INFO:root:eval mean loss: 2862.476838166291
INFO:root:eval perplexity: 10.473740577697754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/66

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [3:03:29<1:36:21, 170.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1745.5596226283483
INFO:root:current train perplexity3.9752864837646484
INFO:root:current mean train loss 1778.297782961002
INFO:root:current train perplexity4.025826454162598
INFO:root:current mean train loss 1771.4819750203267
INFO:root:current train perplexity4.0422587394714355
INFO:root:current mean train loss 1778.4371904509833
INFO:root:current train perplexity4.063045978546143
INFO:root:current mean train loss 1781.9853886765143
INFO:root:current train perplexity4.072670936584473
INFO:root:current mean train loss 1781.9714212545734
INFO:root:current train perplexity4.075483322143555
INFO:root:current mean train loss 1782.0595518348682
INFO:root:current train perplexity4.0745720863342285
INFO:root:current mean train loss 1780.8383745042693
INFO:root:current train perplexity4.065723896026611
INFO:root:current mean train loss 1781.7094238875989
INFO:root:current train perplexity4.067319869995117
INFO:root:current mean train loss 1782.1615436897735
INFO:root:current train perplexity4.06774377822876
INFO:root:current mean train loss 1780.5677571534877
INFO:root:current train perplexity4.066908359527588
INFO:root:current mean train loss 1780.4994660921122
INFO:root:current train perplexity4.067551612854004
INFO:root:current mean train loss 1780.7967985186003
INFO:root:current train perplexity4.068118095397949
INFO:root:current mean train loss 1778.745311428073
INFO:root:current train perplexity4.068420886993408
INFO:root:current mean train loss 1779.5715891269626
INFO:root:current train perplexity4.070396423339844
INFO:root:current mean train loss 1779.2429960051468
INFO:root:current train perplexity4.071151256561279
INFO:root:current mean train loss 1780.2420640741875
INFO:root:current train perplexity4.07195520401001
INFO:root:current mean train loss 1780.3130099148614
INFO:root:current train perplexity4.073466777801514
INFO:root:current mean train loss 1781.3449939641896
INFO:root:current train perplexity4.073635578155518
INFO:root:current mean train loss 1780.756075937012
INFO:root:current train perplexity4.072713851928711


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.88s/it]
INFO:root:final mean train loss: 1781.3916357889718
INFO:root:final train perplexity: 4.075170516967773
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.51s/it]
INFO:root:eval mean loss: 2864.5769893428583
INFO:root:eval perplexity: 10.491805076599121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/67

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [3:06:14<1:32:46, 168.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1767.1875578227796
INFO:root:current train perplexity4.046289443969727
INFO:root:current mean train loss 1764.5288749363112
INFO:root:current train perplexity4.034992218017578
INFO:root:current mean train loss 1767.3074438271403
INFO:root:current train perplexity4.038059711456299
INFO:root:current mean train loss 1768.0580577963203
INFO:root:current train perplexity4.0462565422058105
INFO:root:current mean train loss 1770.6183443809753
INFO:root:current train perplexity4.050263404846191
INFO:root:current mean train loss 1775.3849789077021
INFO:root:current train perplexity4.055550575256348
INFO:root:current mean train loss 1778.3813440209271
INFO:root:current train perplexity4.0571746826171875
INFO:root:current mean train loss 1775.1219690834603
INFO:root:current train perplexity4.054586887359619
INFO:root:current mean train loss 1776.4173203789248
INFO:root:current train perplexity4.055972576141357
INFO:root:current mean train loss 1778.460075199477
INFO:root:current train perplexity4.0581865310668945
INFO:root:current mean train loss 1778.7358895891664
INFO:root:current train perplexity4.061391353607178
INFO:root:current mean train loss 1780.1040430588546
INFO:root:current train perplexity4.061466693878174
INFO:root:current mean train loss 1779.7350390901088
INFO:root:current train perplexity4.060982704162598
INFO:root:current mean train loss 1778.7630510315944
INFO:root:current train perplexity4.061208724975586
INFO:root:current mean train loss 1778.8409948441847
INFO:root:current train perplexity4.062071800231934
INFO:root:current mean train loss 1779.7387100041144
INFO:root:current train perplexity4.0635905265808105
INFO:root:current mean train loss 1779.3276738317022
INFO:root:current train perplexity4.063490390777588
INFO:root:current mean train loss 1779.7897334653023
INFO:root:current train perplexity4.065664768218994
INFO:root:current mean train loss 1780.3214856501631
INFO:root:current train perplexity4.066918849945068
INFO:root:current mean train loss 1779.1037460972773
INFO:root:current train perplexity4.066382884979248


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.97s/it]
INFO:root:final mean train loss: 1778.832023308966
INFO:root:final train perplexity: 4.066952228546143
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.75s/it]
INFO:root:eval mean loss: 2866.091379709788
INFO:root:eval perplexity: 10.504851341247559
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/68

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [3:08:59<1:29:20, 167.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1762.4037286931818
INFO:root:current train perplexity4.0394721031188965
INFO:root:current mean train loss 1780.6919528099797
INFO:root:current train perplexity4.043064117431641
INFO:root:current mean train loss 1778.302246572457
INFO:root:current train perplexity4.051418781280518
INFO:root:current mean train loss 1781.4709046269807
INFO:root:current train perplexity4.061800003051758
INFO:root:current mean train loss 1780.4265021355598
INFO:root:current train perplexity4.065352439880371
INFO:root:current mean train loss 1777.620169094876
INFO:root:current train perplexity4.057735443115234
INFO:root:current mean train loss 1776.8760613594347
INFO:root:current train perplexity4.056150436401367
INFO:root:current mean train loss 1776.3951042528975
INFO:root:current train perplexity4.049659252166748
INFO:root:current mean train loss 1775.0213962844937
INFO:root:current train perplexity4.048399925231934
INFO:root:current mean train loss 1775.3986179851113
INFO:root:current train perplexity4.049190044403076
INFO:root:current mean train loss 1774.9210524427947
INFO:root:current train perplexity4.049368858337402
INFO:root:current mean train loss 1776.4630615234375
INFO:root:current train perplexity4.052181720733643
INFO:root:current mean train loss 1776.9375855951196
INFO:root:current train perplexity4.0534210205078125
INFO:root:current mean train loss 1776.5954238497463
INFO:root:current train perplexity4.053954124450684
INFO:root:current mean train loss 1777.0925591642504
INFO:root:current train perplexity4.054986953735352
INFO:root:current mean train loss 1777.5326300617967
INFO:root:current train perplexity4.0554962158203125
INFO:root:current mean train loss 1778.687474332043
INFO:root:current train perplexity4.058772563934326
INFO:root:current mean train loss 1777.725480212785
INFO:root:current train perplexity4.058001518249512
INFO:root:current mean train loss 1777.1584214696345
INFO:root:current train perplexity4.057629108428955
INFO:root:current mean train loss 1776.386509201167
INFO:root:current train perplexity4.056832790374756


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.34s/it]
INFO:root:final mean train loss: 1775.9404181760788
INFO:root:final train perplexity: 4.0576887130737305
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.87s/it]
INFO:root:eval mean loss: 2866.471552118525
INFO:root:eval perplexity: 10.508130073547363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/69

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [3:11:54<1:27:45, 169.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1760.4456549750435
INFO:root:current train perplexity4.041349411010742
INFO:root:current mean train loss 1762.703171840934
INFO:root:current train perplexity4.037148475646973
INFO:root:current mean train loss 1763.7017736995922
INFO:root:current train perplexity4.040881633758545
INFO:root:current mean train loss 1763.4373336299773
INFO:root:current train perplexity4.036662578582764
INFO:root:current mean train loss 1767.7740359548795
INFO:root:current train perplexity4.03720235824585
INFO:root:current mean train loss 1770.1765326653326
INFO:root:current train perplexity4.045209884643555
INFO:root:current mean train loss 1770.9262310209729
INFO:root:current train perplexity4.04783296585083
INFO:root:current mean train loss 1769.5953943124089
INFO:root:current train perplexity4.044295310974121
INFO:root:current mean train loss 1767.9980488348444
INFO:root:current train perplexity4.0443220138549805
INFO:root:current mean train loss 1768.5885368943705
INFO:root:current train perplexity4.045236587524414
INFO:root:current mean train loss 1768.4791493202324
INFO:root:current train perplexity4.045071601867676
INFO:root:current mean train loss 1770.0986662464338
INFO:root:current train perplexity4.04727840423584
INFO:root:current mean train loss 1770.7747599283855
INFO:root:current train perplexity4.0480570793151855
INFO:root:current mean train loss 1770.3701767101231
INFO:root:current train perplexity4.049254417419434
INFO:root:current mean train loss 1771.0653811745021
INFO:root:current train perplexity4.049996852874756
INFO:root:current mean train loss 1770.8316203110091
INFO:root:current train perplexity4.04915189743042
INFO:root:current mean train loss 1772.3210908442593
INFO:root:current train perplexity4.049713134765625
INFO:root:current mean train loss 1772.8295835060137
INFO:root:current train perplexity4.049443244934082
INFO:root:current mean train loss 1773.8310683160767
INFO:root:current train perplexity4.049931526184082
INFO:root:current mean train loss 1774.0095204320446
INFO:root:current train perplexity4.050333499908447


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.36s/it]
INFO:root:final mean train loss: 1773.8424449310842
INFO:root:final train perplexity: 4.050981044769287
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.29s/it]
INFO:root:eval mean loss: 2869.877665018534
INFO:root:eval perplexity: 10.537538528442383
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/70

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [3:14:38<1:24:00, 168.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1763.6089059208216
INFO:root:current train perplexity4.068526744842529
INFO:root:current mean train loss 1755.541086025339
INFO:root:current train perplexity4.035885810852051
INFO:root:current mean train loss 1761.9730934222264
INFO:root:current train perplexity4.036753177642822
INFO:root:current mean train loss 1760.1637204520807
INFO:root:current train perplexity4.0307936668396
INFO:root:current mean train loss 1765.0434105995973
INFO:root:current train perplexity4.037160396575928
INFO:root:current mean train loss 1764.5632581208881
INFO:root:current train perplexity4.0369157791137695
INFO:root:current mean train loss 1765.5317237532884
INFO:root:current train perplexity4.035518169403076
INFO:root:current mean train loss 1764.6418272920132
INFO:root:current train perplexity4.030341148376465
INFO:root:current mean train loss 1766.6385336018789
INFO:root:current train perplexity4.033531665802002
INFO:root:current mean train loss 1769.1730636118396
INFO:root:current train perplexity4.034453868865967
INFO:root:current mean train loss 1767.4325994766557
INFO:root:current train perplexity4.033766269683838
INFO:root:current mean train loss 1766.8003714058557
INFO:root:current train perplexity4.034905433654785
INFO:root:current mean train loss 1766.9750645107035
INFO:root:current train perplexity4.035040855407715
INFO:root:current mean train loss 1766.982977738734
INFO:root:current train perplexity4.035899639129639
INFO:root:current mean train loss 1767.8590687994513
INFO:root:current train perplexity4.038497447967529
INFO:root:current mean train loss 1767.826001253122
INFO:root:current train perplexity4.039259910583496
INFO:root:current mean train loss 1769.0928874854296
INFO:root:current train perplexity4.03960657119751
INFO:root:current mean train loss 1770.1239957345672
INFO:root:current train perplexity4.039647579193115
INFO:root:current mean train loss 1771.3177340958343
INFO:root:current train perplexity4.0409064292907715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.28s/it]
INFO:root:final mean train loss: 1771.5576054606242
INFO:root:final train perplexity: 4.043687343597412
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.41s/it]
INFO:root:eval mean loss: 2866.8836746903153
INFO:root:eval perplexity: 10.511683464050293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/71

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [3:17:24<1:20:53, 167.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1818.8069458007812
INFO:root:current train perplexity4.07048225402832
INFO:root:current mean train loss 1762.0814324145047
INFO:root:current train perplexity3.9921469688415527
INFO:root:current mean train loss 1755.2264220598831
INFO:root:current train perplexity3.9908924102783203
INFO:root:current mean train loss 1756.7552510180506
INFO:root:current train perplexity3.9931883811950684
INFO:root:current mean train loss 1759.1222985178379
INFO:root:current train perplexity4.004570960998535
INFO:root:current mean train loss 1759.231467024611
INFO:root:current train perplexity4.007390022277832
INFO:root:current mean train loss 1761.5075363310257
INFO:root:current train perplexity4.013518333435059
INFO:root:current mean train loss 1763.457088999978
INFO:root:current train perplexity4.0174689292907715
INFO:root:current mean train loss 1764.708246349401
INFO:root:current train perplexity4.018119812011719
INFO:root:current mean train loss 1764.4760668083006
INFO:root:current train perplexity4.017404079437256
INFO:root:current mean train loss 1765.7178082627283
INFO:root:current train perplexity4.023025035858154
INFO:root:current mean train loss 1761.68800505764
INFO:root:current train perplexity4.019071102142334
INFO:root:current mean train loss 1763.4294656275913
INFO:root:current train perplexity4.020027160644531
INFO:root:current mean train loss 1765.4596569768137
INFO:root:current train perplexity4.022774696350098
INFO:root:current mean train loss 1766.1892286927398
INFO:root:current train perplexity4.026625633239746
INFO:root:current mean train loss 1766.7431930805424
INFO:root:current train perplexity4.026416778564453
INFO:root:current mean train loss 1766.5850675019944
INFO:root:current train perplexity4.028690338134766
INFO:root:current mean train loss 1765.5335723411856
INFO:root:current train perplexity4.027397632598877
INFO:root:current mean train loss 1766.578474988969
INFO:root:current train perplexity4.030261039733887
INFO:root:current mean train loss 1768.9140234964216
INFO:root:current train perplexity4.033163070678711


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.39s/it]
INFO:root:final mean train loss: 1768.743541969534
INFO:root:final train perplexity: 4.034722805023193
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.31s/it]
INFO:root:eval mean loss: 2871.835477811796
INFO:root:eval perplexity: 10.554483413696289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/72

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [3:20:07<1:17:35, 166.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1793.133444081182
INFO:root:current train perplexity4.038635730743408
INFO:root:current mean train loss 1776.7674352134147
INFO:root:current train perplexity4.031285285949707
INFO:root:current mean train loss 1767.8364892797085
INFO:root:current train perplexity4.018551826477051
INFO:root:current mean train loss 1766.2113173162975
INFO:root:current train perplexity4.014928340911865
INFO:root:current mean train loss 1765.773316872599
INFO:root:current train perplexity4.01659631729126
INFO:root:current mean train loss 1766.3189323819163
INFO:root:current train perplexity4.016197681427002
INFO:root:current mean train loss 1764.8013863111958
INFO:root:current train perplexity4.0123443603515625
INFO:root:current mean train loss 1764.2950697776193
INFO:root:current train perplexity4.019480228424072
INFO:root:current mean train loss 1764.3566611233198
INFO:root:current train perplexity4.020182132720947
INFO:root:current mean train loss 1765.5569223257212
INFO:root:current train perplexity4.023505210876465
INFO:root:current mean train loss 1766.6553533857984
INFO:root:current train perplexity4.023678779602051
INFO:root:current mean train loss 1766.9594053708329
INFO:root:current train perplexity4.025402069091797
INFO:root:current mean train loss 1766.813147282074
INFO:root:current train perplexity4.026639461517334
INFO:root:current mean train loss 1766.1305399438422
INFO:root:current train perplexity4.025636196136475
INFO:root:current mean train loss 1765.931299462925
INFO:root:current train perplexity4.025954723358154
INFO:root:current mean train loss 1766.7792283457045
INFO:root:current train perplexity4.027960777282715
INFO:root:current mean train loss 1767.6242757763162
INFO:root:current train perplexity4.028891086578369
INFO:root:current mean train loss 1767.6680044571606
INFO:root:current train perplexity4.028900623321533
INFO:root:current mean train loss 1767.7621947103846
INFO:root:current train perplexity4.027398109436035
INFO:root:current mean train loss 1767.4586564419608
INFO:root:current train perplexity4.02832555770874


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.94s/it]
INFO:root:final mean train loss: 1766.9194157418133
INFO:root:final train perplexity: 4.0289225578308105
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.93s/it]
INFO:root:eval mean loss: 2872.7374388548706
INFO:root:eval perplexity: 10.562296867370605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/73

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [3:22:52<1:14:38, 165.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1749.6539978027345
INFO:root:current train perplexity4.037477016448975
INFO:root:current mean train loss 1754.3507986886161
INFO:root:current train perplexity4.000173091888428
INFO:root:current mean train loss 1752.9452173868815
INFO:root:current train perplexity4.00164270401001
INFO:root:current mean train loss 1757.778540398093
INFO:root:current train perplexity4.0114946365356445
INFO:root:current mean train loss 1762.5449393532492
INFO:root:current train perplexity4.016049385070801
INFO:root:current mean train loss 1763.4900716145833
INFO:root:current train perplexity4.023227691650391
INFO:root:current mean train loss 1763.9699720382691
INFO:root:current train perplexity4.018004417419434
INFO:root:current mean train loss 1764.0412071434228
INFO:root:current train perplexity4.019443035125732
INFO:root:current mean train loss 1764.1586807977585
INFO:root:current train perplexity4.019102096557617
INFO:root:current mean train loss 1764.2225154795544
INFO:root:current train perplexity4.02221155166626
INFO:root:current mean train loss 1764.8362154447116
INFO:root:current train perplexity4.024152755737305
INFO:root:current mean train loss 1764.6245032594916
INFO:root:current train perplexity4.026315689086914
INFO:root:current mean train loss 1765.376556002709
INFO:root:current train perplexity4.026979446411133
INFO:root:current mean train loss 1765.674910087016
INFO:root:current train perplexity4.026488304138184
INFO:root:current mean train loss 1764.8883926391602
INFO:root:current train perplexity4.023797988891602
INFO:root:current mean train loss 1764.5797609799868
INFO:root:current train perplexity4.023754596710205
INFO:root:current mean train loss 1765.0935311666349
INFO:root:current train perplexity4.023555755615234
INFO:root:current mean train loss 1765.3014814705684
INFO:root:current train perplexity4.023432731628418
INFO:root:current mean train loss 1765.6279081261675
INFO:root:current train perplexity4.024308204650879
INFO:root:current mean train loss 1765.948492620409
INFO:root:current train perplexity4.0241618156433105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.01s/it]
INFO:root:final mean train loss: 1765.3407437646263
INFO:root:final train perplexity: 4.023909091949463
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.59s/it]
INFO:root:eval mean loss: 2874.0715002111488
INFO:root:eval perplexity: 10.573866844177246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/74

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [3:25:37<1:11:43, 165.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1748.3186313562226
INFO:root:current train perplexity3.9702115058898926
INFO:root:current mean train loss 1768.2088242063096
INFO:root:current train perplexity4.018165588378906
INFO:root:current mean train loss 1766.0648711089493
INFO:root:current train perplexity4.005263328552246
INFO:root:current mean train loss 1761.121536212141
INFO:root:current train perplexity4.000964641571045
INFO:root:current mean train loss 1757.0242524595699
INFO:root:current train perplexity3.996110439300537
INFO:root:current mean train loss 1760.365916829135
INFO:root:current train perplexity4.007358074188232
INFO:root:current mean train loss 1760.6791364184978
INFO:root:current train perplexity4.002776145935059
INFO:root:current mean train loss 1759.144437560632
INFO:root:current train perplexity4.001886367797852
INFO:root:current mean train loss 1759.541209199743
INFO:root:current train perplexity4.005521774291992
INFO:root:current mean train loss 1759.1315093962253
INFO:root:current train perplexity4.004684925079346
INFO:root:current mean train loss 1758.4623581120284
INFO:root:current train perplexity4.001994609832764
INFO:root:current mean train loss 1760.4832512567862
INFO:root:current train perplexity4.003051280975342
INFO:root:current mean train loss 1758.8629567002909
INFO:root:current train perplexity4.001483917236328
INFO:root:current mean train loss 1759.9772666756862
INFO:root:current train perplexity4.006086826324463
INFO:root:current mean train loss 1760.2433529908149
INFO:root:current train perplexity4.0073442459106445
INFO:root:current mean train loss 1760.5753744587196
INFO:root:current train perplexity4.009297847747803
INFO:root:current mean train loss 1761.29474241617
INFO:root:current train perplexity4.0111894607543945
INFO:root:current mean train loss 1761.0609028034069
INFO:root:current train perplexity4.010248184204102
INFO:root:current mean train loss 1762.650064906961
INFO:root:current train perplexity4.0152692794799805
INFO:root:current mean train loss 1762.2798714225976
INFO:root:current train perplexity4.013815879821777


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.28s/it]
INFO:root:final mean train loss: 1762.1790333188549
INFO:root:final train perplexity: 4.013887882232666
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.98s/it]
INFO:root:eval mean loss: 2872.4687316711243
INFO:root:eval perplexity: 10.559967994689941
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/75

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [3:28:22<1:08:56, 165.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1764.4059827649914
INFO:root:current train perplexity4.024228572845459
INFO:root:current mean train loss 1751.1747990750719
INFO:root:current train perplexity3.99269437789917
INFO:root:current mean train loss 1756.7765199981466
INFO:root:current train perplexity3.9915342330932617
INFO:root:current mean train loss 1756.3349694236715
INFO:root:current train perplexity3.986539125442505
INFO:root:current mean train loss 1758.8595581054688
INFO:root:current train perplexity3.9952492713928223
INFO:root:current mean train loss 1757.2989901765297
INFO:root:current train perplexity3.998656988143921
INFO:root:current mean train loss 1756.3276921393963
INFO:root:current train perplexity3.9957897663116455
INFO:root:current mean train loss 1758.4948167431262
INFO:root:current train perplexity4.001270771026611
INFO:root:current mean train loss 1758.2939224068577
INFO:root:current train perplexity3.999149799346924
INFO:root:current mean train loss 1759.6109107798864
INFO:root:current train perplexity4.0011186599731445
INFO:root:current mean train loss 1759.441141764323
INFO:root:current train perplexity3.9989826679229736
INFO:root:current mean train loss 1759.9044639678384
INFO:root:current train perplexity3.998814344406128
INFO:root:current mean train loss 1758.676689112018
INFO:root:current train perplexity3.998570203781128
INFO:root:current mean train loss 1760.9182641530488
INFO:root:current train perplexity4.0047993659973145
INFO:root:current mean train loss 1760.2274256050182
INFO:root:current train perplexity4.004882335662842
INFO:root:current mean train loss 1759.6909844327004
INFO:root:current train perplexity4.004833221435547
INFO:root:current mean train loss 1760.0215162416227
INFO:root:current train perplexity4.005993366241455
INFO:root:current mean train loss 1759.814740134737
INFO:root:current train perplexity4.005799770355225
INFO:root:current mean train loss 1760.2545620685198
INFO:root:current train perplexity4.0064520835876465
INFO:root:current mean train loss 1760.3218259492544
INFO:root:current train perplexity4.006877899169922


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.77s/it]
INFO:root:final mean train loss: 1760.0693207325746
INFO:root:final train perplexity: 4.0072150230407715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.82s/it]
INFO:root:eval mean loss: 2875.221945089621
INFO:root:eval perplexity: 10.583849906921387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/76

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [3:31:06<1:05:58, 164.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1757.137948843149
INFO:root:current train perplexity4.016871929168701
INFO:root:current mean train loss 1763.276280907436
INFO:root:current train perplexity4.02768087387085
INFO:root:current mean train loss 1757.7193007846058
INFO:root:current train perplexity4.0085225105285645
INFO:root:current mean train loss 1757.237990591532
INFO:root:current train perplexity4.002681732177734
INFO:root:current mean train loss 1757.1673780390784
INFO:root:current train perplexity4.001688480377197
INFO:root:current mean train loss 1755.4572646500899
INFO:root:current train perplexity3.9924020767211914
INFO:root:current mean train loss 1755.219045547949
INFO:root:current train perplexity3.9919323921203613
INFO:root:current mean train loss 1757.5838498044407
INFO:root:current train perplexity3.9942843914031982
INFO:root:current mean train loss 1757.3613826524797
INFO:root:current train perplexity3.9957706928253174
INFO:root:current mean train loss 1757.1405221455996
INFO:root:current train perplexity3.9967026710510254
INFO:root:current mean train loss 1757.8290711288382
INFO:root:current train perplexity3.9962847232818604
INFO:root:current mean train loss 1758.8876377108916
INFO:root:current train perplexity3.9987056255340576
INFO:root:current mean train loss 1757.8508714931497
INFO:root:current train perplexity3.997636079788208
INFO:root:current mean train loss 1758.4891201213998
INFO:root:current train perplexity4.000185966491699
INFO:root:current mean train loss 1758.602483963023
INFO:root:current train perplexity3.999253273010254
INFO:root:current mean train loss 1759.1219779349663
INFO:root:current train perplexity4.000666618347168
INFO:root:current mean train loss 1758.4284220401667
INFO:root:current train perplexity3.9985415935516357
INFO:root:current mean train loss 1758.839683988519
INFO:root:current train perplexity4.00035285949707
INFO:root:current mean train loss 1758.4914652129949
INFO:root:current train perplexity4.000606060028076


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:30<00:00, 150.00s/it]
INFO:root:final mean train loss: 1758.5492548478474
INFO:root:final train perplexity: 4.002414226531982
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.07s/it]
INFO:root:eval mean loss: 2877.428741730011
INFO:root:eval perplexity: 10.603034973144531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/77

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [3:34:03<1:04:37, 168.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1713.0648803710938
INFO:root:current train perplexity3.8898186683654785
INFO:root:current mean train loss 1746.7465379503037
INFO:root:current train perplexity3.979398012161255
INFO:root:current mean train loss 1752.4022463285005
INFO:root:current train perplexity3.974137306213379
INFO:root:current mean train loss 1753.433656370485
INFO:root:current train perplexity3.9795761108398438
INFO:root:current mean train loss 1754.4818447337432
INFO:root:current train perplexity3.977519989013672
INFO:root:current mean train loss 1752.7266273798905
INFO:root:current train perplexity3.9765233993530273
INFO:root:current mean train loss 1753.0720232913368
INFO:root:current train perplexity3.979809045791626
INFO:root:current mean train loss 1752.3524316475216
INFO:root:current train perplexity3.982595205307007
INFO:root:current mean train loss 1755.769379266418
INFO:root:current train perplexity3.987794876098633
INFO:root:current mean train loss 1756.122216581773
INFO:root:current train perplexity3.9896345138549805
INFO:root:current mean train loss 1756.8250518072218
INFO:root:current train perplexity3.989358901977539
INFO:root:current mean train loss 1755.24061138277
INFO:root:current train perplexity3.988751173019409
INFO:root:current mean train loss 1754.347008711455
INFO:root:current train perplexity3.986736536026001
INFO:root:current mean train loss 1754.7757257584037
INFO:root:current train perplexity3.98809552192688
INFO:root:current mean train loss 1755.6102281050248
INFO:root:current train perplexity3.9915859699249268
INFO:root:current mean train loss 1755.5702853013097
INFO:root:current train perplexity3.991232395172119
INFO:root:current mean train loss 1755.0423223391101
INFO:root:current train perplexity3.9913928508758545
INFO:root:current mean train loss 1756.4774816723004
INFO:root:current train perplexity3.9928677082061768
INFO:root:current mean train loss 1756.3862721265946
INFO:root:current train perplexity3.9934489727020264
INFO:root:current mean train loss 1755.9315387078052
INFO:root:current train perplexity3.9934465885162354


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.39s/it]
INFO:root:final mean train loss: 1756.3654200351425
INFO:root:final train perplexity: 3.995526075363159
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.63s/it]
INFO:root:eval mean loss: 2878.160132055884
INFO:root:eval perplexity: 10.609399795532227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/78

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [3:36:49<1:01:32, 167.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1761.0153662109376
INFO:root:current train perplexity4.028461933135986
INFO:root:current mean train loss 1744.08847265625
INFO:root:current train perplexity3.970810651779175
INFO:root:current mean train loss 1752.7630685763888
INFO:root:current train perplexity3.9977800846099854
INFO:root:current mean train loss 1748.2251573768028
INFO:root:current train perplexity3.9919333457946777
INFO:root:current mean train loss 1751.2843692555148
INFO:root:current train perplexity3.989426851272583
INFO:root:current mean train loss 1751.5786686197916
INFO:root:current train perplexity3.989417314529419
INFO:root:current mean train loss 1752.43668671875
INFO:root:current train perplexity3.9864156246185303
INFO:root:current mean train loss 1752.6366604929956
INFO:root:current train perplexity3.98408579826355
INFO:root:current mean train loss 1752.1796360085227
INFO:root:current train perplexity3.9860663414001465
INFO:root:current mean train loss 1750.5832164537585
INFO:root:current train perplexity3.984321355819702
INFO:root:current mean train loss 1750.1569514576981
INFO:root:current train perplexity3.984616279602051
INFO:root:current mean train loss 1751.9616373697916
INFO:root:current train perplexity3.9862544536590576
INFO:root:current mean train loss 1752.3496603954081
INFO:root:current train perplexity3.9869213104248047
INFO:root:current mean train loss 1753.699218565743
INFO:root:current train perplexity3.988354444503784
INFO:root:current mean train loss 1752.8414902001095
INFO:root:current train perplexity3.98583722114563
INFO:root:current mean train loss 1753.2213527792007
INFO:root:current train perplexity3.9867212772369385
INFO:root:current mean train loss 1753.5240395132212
INFO:root:current train perplexity3.9858710765838623
INFO:root:current mean train loss 1754.7187332286005
INFO:root:current train perplexity3.987309694290161
INFO:root:current mean train loss 1754.6571196088398
INFO:root:current train perplexity3.9909188747406006
INFO:root:current mean train loss 1755.0069326425528
INFO:root:current train perplexity3.9906258583068848


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.21s/it]
INFO:root:final mean train loss: 1754.7498565381425
INFO:root:final train perplexity: 3.9904394149780273
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:25<00:00, 25.97s/it]
INFO:root:eval mean loss: 2877.2277157528624
INFO:root:eval perplexity: 10.601287841796875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/79

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [3:39:46<59:37, 170.37s/it]  

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1752.1308303106398
INFO:root:current train perplexity3.95992374420166
INFO:root:current mean train loss 1750.0155699823943
INFO:root:current train perplexity3.9762754440307617
INFO:root:current mean train loss 1749.0426302823153
INFO:root:current train perplexity3.974100351333618
INFO:root:current mean train loss 1755.231531332808
INFO:root:current train perplexity3.983159303665161
INFO:root:current mean train loss 1753.2549261723168
INFO:root:current train perplexity3.973571300506592
INFO:root:current mean train loss 1755.4790343112172
INFO:root:current train perplexity3.9787704944610596
INFO:root:current mean train loss 1754.894820834246
INFO:root:current train perplexity3.975503921508789
INFO:root:current mean train loss 1754.291291846098
INFO:root:current train perplexity3.979259490966797
INFO:root:current mean train loss 1755.1153316543107
INFO:root:current train perplexity3.9851162433624268
INFO:root:current mean train loss 1756.2085432631702
INFO:root:current train perplexity3.988600254058838
INFO:root:current mean train loss 1754.5408238504303
INFO:root:current train perplexity3.9866883754730225
INFO:root:current mean train loss 1753.115892827824
INFO:root:current train perplexity3.9837348461151123
INFO:root:current mean train loss 1753.7497492742616
INFO:root:current train perplexity3.9838151931762695
INFO:root:current mean train loss 1753.5897057614277
INFO:root:current train perplexity3.985051393508911
INFO:root:current mean train loss 1753.5021344527458
INFO:root:current train perplexity3.983647108078003
INFO:root:current mean train loss 1753.6269481376914
INFO:root:current train perplexity3.984018325805664
INFO:root:current mean train loss 1754.7268797192592
INFO:root:current train perplexity3.9866209030151367
INFO:root:current mean train loss 1754.1254006176673
INFO:root:current train perplexity3.986323356628418
INFO:root:current mean train loss 1752.9022057084903
INFO:root:current train perplexity3.9856996536254883
INFO:root:current mean train loss 1753.0688047870672
INFO:root:current train perplexity3.985414981842041


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.99s/it]
INFO:root:final mean train loss: 1752.770837550084
INFO:root:final train perplexity: 3.984215497970581
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.88s/it]
INFO:root:eval mean loss: 2877.6377041103606
INFO:root:eval perplexity: 10.604854583740234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/80

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [3:42:30<56:09, 168.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1729.8229670120497
INFO:root:current train perplexity3.9733591079711914
INFO:root:current mean train loss 1751.3183724265427
INFO:root:current train perplexity3.9851365089416504
INFO:root:current mean train loss 1744.301278486215
INFO:root:current train perplexity3.9661705493927
INFO:root:current mean train loss 1742.773722444072
INFO:root:current train perplexity3.966283082962036
INFO:root:current mean train loss 1742.7319548696214
INFO:root:current train perplexity3.960663080215454
INFO:root:current mean train loss 1743.5138937416145
INFO:root:current train perplexity3.9574079513549805
INFO:root:current mean train loss 1744.5042706085808
INFO:root:current train perplexity3.955995798110962
INFO:root:current mean train loss 1746.040911889359
INFO:root:current train perplexity3.9613046646118164
INFO:root:current mean train loss 1746.921232674258
INFO:root:current train perplexity3.965862989425659
INFO:root:current mean train loss 1746.1755955351032
INFO:root:current train perplexity3.966472864151001
INFO:root:current mean train loss 1746.0677309261391
INFO:root:current train perplexity3.967130661010742
INFO:root:current mean train loss 1747.7160255886338
INFO:root:current train perplexity3.9683868885040283
INFO:root:current mean train loss 1749.2098228690925
INFO:root:current train perplexity3.9721717834472656
INFO:root:current mean train loss 1749.0966913645718
INFO:root:current train perplexity3.9735968112945557
INFO:root:current mean train loss 1749.3670113807348
INFO:root:current train perplexity3.9747471809387207
INFO:root:current mean train loss 1749.6395411659616
INFO:root:current train perplexity3.9743149280548096
INFO:root:current mean train loss 1750.0535013797846
INFO:root:current train perplexity3.97623610496521
INFO:root:current mean train loss 1750.031397539218
INFO:root:current train perplexity3.9760282039642334
INFO:root:current mean train loss 1750.2028495374068
INFO:root:current train perplexity3.97576642036438
INFO:root:current mean train loss 1750.5190445888766
INFO:root:current train perplexity3.976717710494995


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.32s/it]
INFO:root:final mean train loss: 1750.5600192579307
INFO:root:final train perplexity: 3.9772748947143555
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.50s/it]
INFO:root:eval mean loss: 2879.950982721002
INFO:root:eval perplexity: 10.625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/81

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [3:45:13<52:54, 167.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1755.6335931075246
INFO:root:current train perplexity4.021402359008789
INFO:root:current mean train loss 1758.286642594771
INFO:root:current train perplexity4.000647068023682
INFO:root:current mean train loss 1757.7839359891586
INFO:root:current train perplexity3.9893484115600586
INFO:root:current mean train loss 1750.1905563029836
INFO:root:current train perplexity3.9714951515197754
INFO:root:current mean train loss 1749.0283380075664
INFO:root:current train perplexity3.971250534057617
INFO:root:current mean train loss 1749.3769817352295
INFO:root:current train perplexity3.970623731613159
INFO:root:current mean train loss 1749.1115291076298
INFO:root:current train perplexity3.969648838043213
INFO:root:current mean train loss 1748.244506049402
INFO:root:current train perplexity3.9711997509002686
INFO:root:current mean train loss 1750.4324350574789
INFO:root:current train perplexity3.96909236907959
INFO:root:current mean train loss 1750.8958471329486
INFO:root:current train perplexity3.9707283973693848
INFO:root:current mean train loss 1748.6043030692742
INFO:root:current train perplexity3.968719482421875
INFO:root:current mean train loss 1748.44699688347
INFO:root:current train perplexity3.971073865890503
INFO:root:current mean train loss 1749.9986620098819
INFO:root:current train perplexity3.9731249809265137
INFO:root:current mean train loss 1750.698807738548
INFO:root:current train perplexity3.973288059234619
INFO:root:current mean train loss 1750.8223594107278
INFO:root:current train perplexity3.971383810043335
INFO:root:current mean train loss 1750.8894318711334
INFO:root:current train perplexity3.9717209339141846
INFO:root:current mean train loss 1751.6076804368195
INFO:root:current train perplexity3.9727163314819336
INFO:root:current mean train loss 1750.505014917872
INFO:root:current train perplexity3.9722471237182617
INFO:root:current mean train loss 1750.037802885336
INFO:root:current train perplexity3.9736063480377197
INFO:root:current mean train loss 1749.9519367913003
INFO:root:current train perplexity3.9736461639404297


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.24s/it]
INFO:root:final mean train loss: 1749.2376491375421
INFO:root:final train perplexity: 3.9731297492980957
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.68s/it]
INFO:root:eval mean loss: 2879.4895393440315
INFO:root:eval perplexity: 10.620980262756348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/82

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [3:47:58<49:56, 166.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1749.370098811324
INFO:root:current train perplexity3.9684629440307617
INFO:root:current mean train loss 1758.7842283891273
INFO:root:current train perplexity3.975367546081543
INFO:root:current mean train loss 1745.3104585510878
INFO:root:current train perplexity3.9636363983154297
INFO:root:current mean train loss 1745.3227048296358
INFO:root:current train perplexity3.9637885093688965
INFO:root:current mean train loss 1744.1880452308887
INFO:root:current train perplexity3.958634614944458
INFO:root:current mean train loss 1742.874371327598
INFO:root:current train perplexity3.9602739810943604
INFO:root:current mean train loss 1744.1650462845532
INFO:root:current train perplexity3.965423822402954
INFO:root:current mean train loss 1743.670686931057
INFO:root:current train perplexity3.9658548831939697
INFO:root:current mean train loss 1744.944342635647
INFO:root:current train perplexity3.971538782119751
INFO:root:current mean train loss 1746.5657413171498
INFO:root:current train perplexity3.972921371459961
INFO:root:current mean train loss 1746.4914692619582
INFO:root:current train perplexity3.972147226333618
INFO:root:current mean train loss 1745.723074849873
INFO:root:current train perplexity3.9699478149414062
INFO:root:current mean train loss 1745.9954673489765
INFO:root:current train perplexity3.970109701156616
INFO:root:current mean train loss 1746.706678621904
INFO:root:current train perplexity3.9688689708709717
INFO:root:current mean train loss 1746.6080740885852
INFO:root:current train perplexity3.9677138328552246
INFO:root:current mean train loss 1747.334174032265
INFO:root:current train perplexity3.9681451320648193
INFO:root:current mean train loss 1747.9348515861498
INFO:root:current train perplexity3.9685893058776855
INFO:root:current mean train loss 1747.796463038226
INFO:root:current train perplexity3.96956729888916
INFO:root:current mean train loss 1748.3320046821348
INFO:root:current train perplexity3.968545436859131


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.84s/it]
INFO:root:final mean train loss: 1747.270007004115
INFO:root:final train perplexity: 3.966968297958374
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.89s/it]
INFO:root:eval mean loss: 2879.96142284863
INFO:root:eval perplexity: 10.625093460083008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/83

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [3:50:45<47:11, 166.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1769.7345703125
INFO:root:current train perplexity3.970273017883301
INFO:root:current mean train loss 1746.9522927024148
INFO:root:current train perplexity3.9458882808685303
INFO:root:current mean train loss 1749.5637334914434
INFO:root:current train perplexity3.949004888534546
INFO:root:current mean train loss 1748.9682499054938
INFO:root:current train perplexity3.957268714904785
INFO:root:current mean train loss 1744.2952603968179
INFO:root:current train perplexity3.9560821056365967
INFO:root:current mean train loss 1742.8460255342372
INFO:root:current train perplexity3.9611568450927734
INFO:root:current mean train loss 1743.982096687692
INFO:root:current train perplexity3.9659223556518555
INFO:root:current mean train loss 1743.2529271085498
INFO:root:current train perplexity3.965346097946167
INFO:root:current mean train loss 1743.9306179470486
INFO:root:current train perplexity3.9642698764801025
INFO:root:current mean train loss 1744.585081934667
INFO:root:current train perplexity3.9629294872283936
INFO:root:current mean train loss 1744.0803389445389
INFO:root:current train perplexity3.959890127182007
INFO:root:current mean train loss 1744.7439874322565
INFO:root:current train perplexity3.963120937347412
INFO:root:current mean train loss 1745.5374172746642
INFO:root:current train perplexity3.964688777923584
INFO:root:current mean train loss 1746.5074569119752
INFO:root:current train perplexity3.965116500854492
INFO:root:current mean train loss 1746.1360131662789
INFO:root:current train perplexity3.9659385681152344
INFO:root:current mean train loss 1747.1534061659252
INFO:root:current train perplexity3.9667835235595703
INFO:root:current mean train loss 1747.0797308690799
INFO:root:current train perplexity3.965446949005127
INFO:root:current mean train loss 1746.7638041535315
INFO:root:current train perplexity3.9643707275390625
INFO:root:current mean train loss 1745.782073401351
INFO:root:current train perplexity3.9647417068481445
INFO:root:current mean train loss 1746.4544085277937
INFO:root:current train perplexity3.9639761447906494


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.84s/it]
INFO:root:final mean train loss: 1746.1724377669173
INFO:root:final train perplexity: 3.963536500930786
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.01s/it]
INFO:root:eval mean loss: 2882.6211619334176
INFO:root:eval perplexity: 10.648307800292969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/84

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [3:53:32<44:26, 166.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1724.4163366247105
INFO:root:current train perplexity3.936278820037842
INFO:root:current mean train loss 1727.2740478515625
INFO:root:current train perplexity3.935504674911499
INFO:root:current mean train loss 1733.8142622220885
INFO:root:current train perplexity3.9437551498413086
INFO:root:current mean train loss 1738.2290763271694
INFO:root:current train perplexity3.9444234371185303
INFO:root:current mean train loss 1738.8964046147723
INFO:root:current train perplexity3.9411628246307373
INFO:root:current mean train loss 1737.4009131878558
INFO:root:current train perplexity3.9436137676239014
INFO:root:current mean train loss 1738.3208807986318
INFO:root:current train perplexity3.9493327140808105
INFO:root:current mean train loss 1738.6355605092633
INFO:root:current train perplexity3.9496490955352783
INFO:root:current mean train loss 1739.0961859448212
INFO:root:current train perplexity3.9504005908966064
INFO:root:current mean train loss 1740.7555496561488
INFO:root:current train perplexity3.9515256881713867
INFO:root:current mean train loss 1740.9603852714977
INFO:root:current train perplexity3.9507839679718018
INFO:root:current mean train loss 1742.447348268876
INFO:root:current train perplexity3.9529013633728027
INFO:root:current mean train loss 1743.0672845195345
INFO:root:current train perplexity3.952993869781494
INFO:root:current mean train loss 1743.4812161661937
INFO:root:current train perplexity3.954329490661621
INFO:root:current mean train loss 1744.7470555990496
INFO:root:current train perplexity3.955921173095703
INFO:root:current mean train loss 1745.3130321690048
INFO:root:current train perplexity3.9561333656311035
INFO:root:current mean train loss 1745.4793273513128
INFO:root:current train perplexity3.9564943313598633
INFO:root:current mean train loss 1745.3672655345251
INFO:root:current train perplexity3.957507848739624
INFO:root:current mean train loss 1744.6174623753507
INFO:root:current train perplexity3.956857442855835
INFO:root:current mean train loss 1744.0684260163953
INFO:root:current train perplexity3.9558792114257812


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.52s/it]
INFO:root:final mean train loss: 1743.8955974415344
INFO:root:final train perplexity: 3.956425428390503
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.12s/it]
INFO:root:eval mean loss: 2881.248315942896
INFO:root:eval perplexity: 10.636319160461426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/85

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [3:56:19<41:40, 166.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1720.0513277920809
INFO:root:current train perplexity3.955436944961548
INFO:root:current mean train loss 1719.0562337239583
INFO:root:current train perplexity3.9515492916107178
INFO:root:current mean train loss 1734.6420638287655
INFO:root:current train perplexity3.9629242420196533
INFO:root:current mean train loss 1736.317567337391
INFO:root:current train perplexity3.9519760608673096
INFO:root:current mean train loss 1738.7704465024106
INFO:root:current train perplexity3.953670024871826
INFO:root:current mean train loss 1742.320733238669
INFO:root:current train perplexity3.9549777507781982
INFO:root:current mean train loss 1745.2285326845158
INFO:root:current train perplexity3.952972650527954
INFO:root:current mean train loss 1743.3639608403687
INFO:root:current train perplexity3.9501113891601562
INFO:root:current mean train loss 1745.2975715528733
INFO:root:current train perplexity3.953328847885132
INFO:root:current mean train loss 1743.8182354943226
INFO:root:current train perplexity3.9515628814697266
INFO:root:current mean train loss 1742.8799192932831
INFO:root:current train perplexity3.9552464485168457
INFO:root:current mean train loss 1742.9341021984608
INFO:root:current train perplexity3.9537134170532227
INFO:root:current mean train loss 1742.68168576354
INFO:root:current train perplexity3.9532105922698975
INFO:root:current mean train loss 1741.5559597923643
INFO:root:current train perplexity3.9524457454681396
INFO:root:current mean train loss 1742.4730931332238
INFO:root:current train perplexity3.9535248279571533
INFO:root:current mean train loss 1742.594973628385
INFO:root:current train perplexity3.952906608581543
INFO:root:current mean train loss 1743.2648915385969
INFO:root:current train perplexity3.953545570373535
INFO:root:current mean train loss 1743.329268359263
INFO:root:current train perplexity3.9524166584014893
INFO:root:current mean train loss 1743.5395024562347
INFO:root:current train perplexity3.9535956382751465
INFO:root:current mean train loss 1743.6070917074571
INFO:root:current train perplexity3.9524104595184326


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.83s/it]
INFO:root:final mean train loss: 1742.5561097761145
INFO:root:final train perplexity: 3.9522483348846436
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.00s/it]
INFO:root:eval mean loss: 2881.9565546992303
INFO:root:eval perplexity: 10.642500877380371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/86

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [3:59:06<38:54, 166.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1736.1933293577101
INFO:root:current train perplexity3.931377410888672
INFO:root:current mean train loss 1724.4197800914694
INFO:root:current train perplexity3.930271863937378
INFO:root:current mean train loss 1728.7108219775203
INFO:root:current train perplexity3.928544282913208
INFO:root:current mean train loss 1732.3619993426462
INFO:root:current train perplexity3.9340364933013916
INFO:root:current mean train loss 1733.215054526505
INFO:root:current train perplexity3.9418118000030518
INFO:root:current mean train loss 1734.2843753046318
INFO:root:current train perplexity3.947539806365967
INFO:root:current mean train loss 1734.709008382777
INFO:root:current train perplexity3.945323944091797
INFO:root:current mean train loss 1735.441048059451
INFO:root:current train perplexity3.945202589035034
INFO:root:current mean train loss 1737.1956176048925
INFO:root:current train perplexity3.9465718269348145
INFO:root:current mean train loss 1737.5532692741529
INFO:root:current train perplexity3.9444220066070557
INFO:root:current mean train loss 1738.961091094597
INFO:root:current train perplexity3.9488701820373535
INFO:root:current mean train loss 1739.938312645517
INFO:root:current train perplexity3.9481863975524902
INFO:root:current mean train loss 1739.401836979115
INFO:root:current train perplexity3.9450666904449463
INFO:root:current mean train loss 1739.7638616624954
INFO:root:current train perplexity3.9460318088531494
INFO:root:current mean train loss 1741.00011095782
INFO:root:current train perplexity3.950927495956421
INFO:root:current mean train loss 1741.3533600850567
INFO:root:current train perplexity3.95027232170105
INFO:root:current mean train loss 1740.9579853974215
INFO:root:current train perplexity3.9480366706848145
INFO:root:current mean train loss 1741.055332164342
INFO:root:current train perplexity3.9480483531951904
INFO:root:current mean train loss 1741.767967031439
INFO:root:current train perplexity3.9487431049346924
INFO:root:current mean train loss 1742.3143683418457
INFO:root:current train perplexity3.9500815868377686


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.35s/it]
INFO:root:final mean train loss: 1741.748012925541
INFO:root:final train perplexity: 3.9497294425964355
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.35s/it]
INFO:root:eval mean loss: 2883.70324450427
INFO:root:eval perplexity: 10.657766342163086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/87

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [4:01:49<35:52, 165.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1743.0035103039863
INFO:root:current train perplexity3.948317289352417
INFO:root:current mean train loss 1741.8596273700844
INFO:root:current train perplexity3.9283766746520996
INFO:root:current mean train loss 1745.5915514170695
INFO:root:current train perplexity3.9365522861480713
INFO:root:current mean train loss 1746.250479561942
INFO:root:current train perplexity3.943958282470703
INFO:root:current mean train loss 1746.6165457370391
INFO:root:current train perplexity3.9456591606140137
INFO:root:current mean train loss 1745.1877496316772
INFO:root:current train perplexity3.94693922996521
INFO:root:current mean train loss 1743.8142307697847
INFO:root:current train perplexity3.945573091506958
INFO:root:current mean train loss 1740.5543263099494
INFO:root:current train perplexity3.9420228004455566
INFO:root:current mean train loss 1739.595488876308
INFO:root:current train perplexity3.9400627613067627
INFO:root:current mean train loss 1738.5630771504345
INFO:root:current train perplexity3.939059019088745
INFO:root:current mean train loss 1739.2944561280656
INFO:root:current train perplexity3.939229965209961
INFO:root:current mean train loss 1739.9653923410308
INFO:root:current train perplexity3.9378182888031006
INFO:root:current mean train loss 1740.2948897813967
INFO:root:current train perplexity3.938133716583252
INFO:root:current mean train loss 1739.2445429786715
INFO:root:current train perplexity3.93863844871521
INFO:root:current mean train loss 1739.8861113717333
INFO:root:current train perplexity3.9422359466552734
INFO:root:current mean train loss 1740.179537967735
INFO:root:current train perplexity3.9424757957458496
INFO:root:current mean train loss 1741.3904923085518
INFO:root:current train perplexity3.9454691410064697
INFO:root:current mean train loss 1740.887750580555
INFO:root:current train perplexity3.9460647106170654
INFO:root:current mean train loss 1741.0309160941451
INFO:root:current train perplexity3.9465456008911133
INFO:root:current mean train loss 1741.0608941397363
INFO:root:current train perplexity3.946331024169922


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.54s/it]
INFO:root:final mean train loss: 1740.589577725363
INFO:root:final train perplexity: 3.9461236000061035
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.91s/it]
INFO:root:eval mean loss: 2883.2733458556213
INFO:root:eval perplexity: 10.654008865356445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/88

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [4:04:32<32:59, 164.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1759.8611083984374
INFO:root:current train perplexity3.978158712387085
INFO:root:current mean train loss 1750.2467216296075
INFO:root:current train perplexity3.9515275955200195
INFO:root:current mean train loss 1745.822324384269
INFO:root:current train perplexity3.9490091800689697
INFO:root:current mean train loss 1740.2024494412578
INFO:root:current train perplexity3.93805193901062
INFO:root:current mean train loss 1738.9805338541667
INFO:root:current train perplexity3.932459592819214
INFO:root:current mean train loss 1736.831642881762
INFO:root:current train perplexity3.927866220474243
INFO:root:current mean train loss 1738.0292368058679
INFO:root:current train perplexity3.9357964992523193
INFO:root:current mean train loss 1740.5641392737814
INFO:root:current train perplexity3.940244436264038
INFO:root:current mean train loss 1740.5194871955744
INFO:root:current train perplexity3.9439165592193604
INFO:root:current mean train loss 1739.8683126324984
INFO:root:current train perplexity3.9415194988250732
INFO:root:current mean train loss 1740.2881420118078
INFO:root:current train perplexity3.9415805339813232
INFO:root:current mean train loss 1739.483988052432
INFO:root:current train perplexity3.9393107891082764
INFO:root:current mean train loss 1739.3830030050976
INFO:root:current train perplexity3.938805103302002
INFO:root:current mean train loss 1737.9688599070341
INFO:root:current train perplexity3.9393787384033203
INFO:root:current mean train loss 1738.6098761823266
INFO:root:current train perplexity3.937187671661377
INFO:root:current mean train loss 1738.417237705721
INFO:root:current train perplexity3.9373271465301514
INFO:root:current mean train loss 1738.8624874688883
INFO:root:current train perplexity3.9392130374908447
INFO:root:current mean train loss 1739.5972198571335
INFO:root:current train perplexity3.9427201747894287
INFO:root:current mean train loss 1739.9573358782363
INFO:root:current train perplexity3.9432852268218994


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.29s/it]
INFO:root:final mean train loss: 1739.6808061392933
INFO:root:final train perplexity: 3.943295478820801
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.54s/it]
INFO:root:eval mean loss: 2883.82298851586
INFO:root:eval perplexity: 10.6588134765625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/89

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [4:07:18<30:17, 165.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1717.8792419433594
INFO:root:current train perplexity3.890873432159424
INFO:root:current mean train loss 1746.1744537353516
INFO:root:current train perplexity3.95125150680542
INFO:root:current mean train loss 1736.7242028578273
INFO:root:current train perplexity3.9379520416259766
INFO:root:current mean train loss 1735.9424352401343
INFO:root:current train perplexity3.939429998397827
INFO:root:current mean train loss 1737.8875039109905
INFO:root:current train perplexity3.943995475769043
INFO:root:current mean train loss 1736.8848240375519
INFO:root:current train perplexity3.940676689147949
INFO:root:current mean train loss 1734.4016849293428
INFO:root:current train perplexity3.936296224594116
INFO:root:current mean train loss 1733.6224946439936
INFO:root:current train perplexity3.933583974838257
INFO:root:current mean train loss 1733.3047053896148
INFO:root:current train perplexity3.9297401905059814
INFO:root:current mean train loss 1733.1944916039183
INFO:root:current train perplexity3.9288835525512695
INFO:root:current mean train loss 1734.7478233608804
INFO:root:current train perplexity3.930227041244507
INFO:root:current mean train loss 1734.8694054034117
INFO:root:current train perplexity3.933283805847168
INFO:root:current mean train loss 1735.1387674564576
INFO:root:current train perplexity3.9350693225860596
INFO:root:current mean train loss 1736.5133050127727
INFO:root:current train perplexity3.934607744216919
INFO:root:current mean train loss 1737.5343753285179
INFO:root:current train perplexity3.934706687927246
INFO:root:current mean train loss 1737.4639244281425
INFO:root:current train perplexity3.9347586631774902
INFO:root:current mean train loss 1736.7610903756495
INFO:root:current train perplexity3.934793472290039
INFO:root:current mean train loss 1737.4356594620465
INFO:root:current train perplexity3.937044143676758
INFO:root:current mean train loss 1737.7660481366627
INFO:root:current train perplexity3.937573194503784
INFO:root:current mean train loss 1738.8568716647735
INFO:root:current train perplexity3.9396517276763916


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.25s/it]
INFO:root:final mean train loss: 1738.70792880229
INFO:root:final train perplexity: 3.940272092819214
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.06s/it]
INFO:root:eval mean loss: 2882.644138278904
INFO:root:eval perplexity: 10.648510932922363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/90

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [4:10:02<27:29, 164.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1721.8812213766164
INFO:root:current train perplexity3.974971294403076
INFO:root:current mean train loss 1730.8525286534036
INFO:root:current train perplexity3.9217488765716553
INFO:root:current mean train loss 1738.099894028043
INFO:root:current train perplexity3.9251790046691895
INFO:root:current mean train loss 1740.928250854863
INFO:root:current train perplexity3.931190252304077
INFO:root:current mean train loss 1744.4613677338286
INFO:root:current train perplexity3.931913375854492
INFO:root:current mean train loss 1741.8652122223534
INFO:root:current train perplexity3.9322824478149414
INFO:root:current mean train loss 1742.400125718837
INFO:root:current train perplexity3.936192512512207
INFO:root:current mean train loss 1742.0226809654707
INFO:root:current train perplexity3.9312119483947754
INFO:root:current mean train loss 1742.1633465701334
INFO:root:current train perplexity3.9335389137268066
INFO:root:current mean train loss 1740.4434374264163
INFO:root:current train perplexity3.932596445083618
INFO:root:current mean train loss 1740.7927202200635
INFO:root:current train perplexity3.934009313583374
INFO:root:current mean train loss 1738.3903489632348
INFO:root:current train perplexity3.9315197467803955
INFO:root:current mean train loss 1738.917999044097
INFO:root:current train perplexity3.9335341453552246
INFO:root:current mean train loss 1738.1798790098583
INFO:root:current train perplexity3.9349424839019775
INFO:root:current mean train loss 1737.2436958243582
INFO:root:current train perplexity3.9354496002197266
INFO:root:current mean train loss 1737.4007328050911
INFO:root:current train perplexity3.9363980293273926
INFO:root:current mean train loss 1737.063475963014
INFO:root:current train perplexity3.9351189136505127
INFO:root:current mean train loss 1737.652459677966
INFO:root:current train perplexity3.9368231296539307
INFO:root:current mean train loss 1738.6834701446317
INFO:root:current train perplexity3.938093662261963
INFO:root:current mean train loss 1738.4162802055996
INFO:root:current train perplexity3.937373638153076


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.91s/it]
INFO:root:final mean train loss: 1737.8534489880292
INFO:root:final train perplexity: 3.937617301940918
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.31s/it]
INFO:root:eval mean loss: 2883.1982781120964
INFO:root:eval perplexity: 10.653351783752441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/91

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [4:12:47<24:42, 164.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1742.7528951893682
INFO:root:current train perplexity3.968376398086548
INFO:root:current mean train loss 1735.0752797584012
INFO:root:current train perplexity3.9369211196899414
INFO:root:current mean train loss 1736.8958561594893
INFO:root:current train perplexity3.93786883354187
INFO:root:current mean train loss 1734.9659811912934
INFO:root:current train perplexity3.9320428371429443
INFO:root:current mean train loss 1736.1893357075917
INFO:root:current train perplexity3.938913106918335
INFO:root:current mean train loss 1736.1481953715231
INFO:root:current train perplexity3.9375786781311035
INFO:root:current mean train loss 1735.9750335976805
INFO:root:current train perplexity3.9360971450805664
INFO:root:current mean train loss 1733.5909595642909
INFO:root:current train perplexity3.9308431148529053
INFO:root:current mean train loss 1732.3224439688609
INFO:root:current train perplexity3.931061029434204
INFO:root:current mean train loss 1733.0796258454595
INFO:root:current train perplexity3.9307503700256348
INFO:root:current mean train loss 1735.2706225305853
INFO:root:current train perplexity3.9351284503936768
INFO:root:current mean train loss 1735.728438399017
INFO:root:current train perplexity3.935504674911499
INFO:root:current mean train loss 1735.6532130356202
INFO:root:current train perplexity3.9317803382873535
INFO:root:current mean train loss 1735.8933516299742
INFO:root:current train perplexity3.9341607093811035
INFO:root:current mean train loss 1736.4819568934777
INFO:root:current train perplexity3.933208703994751
INFO:root:current mean train loss 1736.5690726098853
INFO:root:current train perplexity3.9333603382110596
INFO:root:current mean train loss 1736.115823367966
INFO:root:current train perplexity3.9330525398254395
INFO:root:current mean train loss 1736.1627386733292
INFO:root:current train perplexity3.9331037998199463
INFO:root:current mean train loss 1736.2092341364141
INFO:root:current train perplexity3.9324533939361572
INFO:root:current mean train loss 1736.0018368257404
INFO:root:current train perplexity3.9312891960144043


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.80s/it]
INFO:root:final mean train loss: 1735.8250865080233
INFO:root:final train perplexity: 3.9313230514526367
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.17s/it]
INFO:root:eval mean loss: 2885.9187151018205
INFO:root:eval perplexity: 10.677159309387207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/92

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [4:15:30<21:53, 164.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1730.2875182136656
INFO:root:current train perplexity3.912675619125366
INFO:root:current mean train loss 1730.6677493229965
INFO:root:current train perplexity3.896515130996704
INFO:root:current mean train loss 1732.2417558445222
INFO:root:current train perplexity3.920501708984375
INFO:root:current mean train loss 1730.546603284263
INFO:root:current train perplexity3.9241695404052734
INFO:root:current mean train loss 1735.526665903837
INFO:root:current train perplexity3.9288744926452637
INFO:root:current mean train loss 1736.4032867052204
INFO:root:current train perplexity3.931239128112793
INFO:root:current mean train loss 1736.5917136536104
INFO:root:current train perplexity3.930751323699951
INFO:root:current mean train loss 1738.0249855371478
INFO:root:current train perplexity3.928457736968994
INFO:root:current mean train loss 1738.204063795671
INFO:root:current train perplexity3.9328651428222656
INFO:root:current mean train loss 1738.3618584907192
INFO:root:current train perplexity3.9336607456207275
INFO:root:current mean train loss 1738.8587056229053
INFO:root:current train perplexity3.9355669021606445
INFO:root:current mean train loss 1737.0022770364226
INFO:root:current train perplexity3.9314401149749756
INFO:root:current mean train loss 1736.1835566359857
INFO:root:current train perplexity3.9292118549346924
INFO:root:current mean train loss 1735.6343985184621
INFO:root:current train perplexity3.9262540340423584
INFO:root:current mean train loss 1734.6036447041342
INFO:root:current train perplexity3.9261679649353027
INFO:root:current mean train loss 1734.9963399993253
INFO:root:current train perplexity3.927604913711548
INFO:root:current mean train loss 1734.7009806584251
INFO:root:current train perplexity3.9262030124664307
INFO:root:current mean train loss 1734.3437184957504
INFO:root:current train perplexity3.9255871772766113
INFO:root:current mean train loss 1734.1932589929718
INFO:root:current train perplexity3.9247453212738037
INFO:root:current mean train loss 1735.1699435777707
INFO:root:current train perplexity3.927285671234131


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:26<00:00, 146.69s/it]
INFO:root:final mean train loss: 1734.6182760064553
INFO:root:final train perplexity: 3.9275834560394287
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.55s/it]
INFO:root:eval mean loss: 2884.140847879129
INFO:root:eval perplexity: 10.661596298217773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/93

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [4:18:14<19:09, 164.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1723.7201126098632
INFO:root:current train perplexity3.920645236968994
INFO:root:current mean train loss 1730.7712463378907
INFO:root:current train perplexity3.9087493419647217
INFO:root:current mean train loss 1734.7541046142578
INFO:root:current train perplexity3.9117774963378906
INFO:root:current mean train loss 1734.5363319798519
INFO:root:current train perplexity3.926959991455078
INFO:root:current mean train loss 1733.711164601644
INFO:root:current train perplexity3.9251468181610107
INFO:root:current mean train loss 1734.25703125
INFO:root:current train perplexity3.9279000759124756
INFO:root:current mean train loss 1733.613725191004
INFO:root:current train perplexity3.92572283744812
INFO:root:current mean train loss 1733.4640031863482
INFO:root:current train perplexity3.927567481994629
INFO:root:current mean train loss 1732.9290130615234
INFO:root:current train perplexity3.9249768257141113
INFO:root:current mean train loss 1733.1047151526627
INFO:root:current train perplexity3.926140785217285
INFO:root:current mean train loss 1732.8197235107423
INFO:root:current train perplexity3.925076484680176
INFO:root:current mean train loss 1732.152912825245
INFO:root:current train perplexity3.9249348640441895
INFO:root:current mean train loss 1733.138610935211
INFO:root:current train perplexity3.9268555641174316
INFO:root:current mean train loss 1733.4484657177027
INFO:root:current train perplexity3.9248785972595215
INFO:root:current mean train loss 1735.2469789247255
INFO:root:current train perplexity3.9270498752593994
INFO:root:current mean train loss 1735.3674175021015
INFO:root:current train perplexity3.9265782833099365
INFO:root:current mean train loss 1734.8507049560546
INFO:root:current train perplexity3.926865816116333
INFO:root:current mean train loss 1735.1849565484551
INFO:root:current train perplexity3.926754951477051
INFO:root:current mean train loss 1734.6866466765707
INFO:root:current train perplexity3.9262983798980713
INFO:root:current mean train loss 1734.7654081710662
INFO:root:current train perplexity3.9266977310180664


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.99s/it]
INFO:root:final mean train loss: 1734.3093352825185
INFO:root:final train perplexity: 3.926626682281494
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.63s/it]
INFO:root:eval mean loss: 2885.9494782868805
INFO:root:eval perplexity: 10.67742919921875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/94

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [4:20:58<16:24, 164.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1739.6495575265785
INFO:root:current train perplexity3.956866979598999
INFO:root:current mean train loss 1739.544032062976
INFO:root:current train perplexity3.9496140480041504
INFO:root:current mean train loss 1739.299552326652
INFO:root:current train perplexity3.934333324432373
INFO:root:current mean train loss 1737.7238591191751
INFO:root:current train perplexity3.936929702758789
INFO:root:current mean train loss 1737.227023026833
INFO:root:current train perplexity3.9333181381225586
INFO:root:current mean train loss 1738.5181285660071
INFO:root:current train perplexity3.9272286891937256
INFO:root:current mean train loss 1736.6230023902663
INFO:root:current train perplexity3.921290636062622
INFO:root:current mean train loss 1734.581984535514
INFO:root:current train perplexity3.921351909637451
INFO:root:current mean train loss 1734.871958312648
INFO:root:current train perplexity3.9206383228302
INFO:root:current mean train loss 1735.2556784121896
INFO:root:current train perplexity3.9232802391052246
INFO:root:current mean train loss 1735.9354278091528
INFO:root:current train perplexity3.927088737487793
INFO:root:current mean train loss 1735.3070568062408
INFO:root:current train perplexity3.926361560821533
INFO:root:current mean train loss 1735.4797264457943
INFO:root:current train perplexity3.9279298782348633
INFO:root:current mean train loss 1735.098281019316
INFO:root:current train perplexity3.9252469539642334
INFO:root:current mean train loss 1735.023730566602
INFO:root:current train perplexity3.925947427749634
INFO:root:current mean train loss 1735.2869570355306
INFO:root:current train perplexity3.926572799682617
INFO:root:current mean train loss 1734.8416848753084
INFO:root:current train perplexity3.9264698028564453
INFO:root:current mean train loss 1734.7244771151788
INFO:root:current train perplexity3.927140951156616
INFO:root:current mean train loss 1735.0614996283193
INFO:root:current train perplexity3.928588390350342


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:29<00:00, 149.88s/it]
INFO:root:final mean train loss: 1733.8805966129582
INFO:root:final train perplexity: 3.9252989292144775
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.53s/it]
INFO:root:eval mean loss: 2886.17126281555
INFO:root:eval perplexity: 10.679374694824219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/95

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [4:23:45<13:45, 165.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1704.5030255998884
INFO:root:current train perplexity3.859290838241577
INFO:root:current mean train loss 1724.0689290364583
INFO:root:current train perplexity3.8912346363067627
INFO:root:current mean train loss 1727.9846864504234
INFO:root:current train perplexity3.888756036758423
INFO:root:current mean train loss 1728.149098778986
INFO:root:current train perplexity3.895942449569702
INFO:root:current mean train loss 1727.1286948383718
INFO:root:current train perplexity3.895803689956665
INFO:root:current mean train loss 1728.2071996310342
INFO:root:current train perplexity3.900268316268921
INFO:root:current mean train loss 1729.3953670538986
INFO:root:current train perplexity3.90938138961792
INFO:root:current mean train loss 1731.464874865962
INFO:root:current train perplexity3.9093873500823975
INFO:root:current mean train loss 1731.1815170550522
INFO:root:current train perplexity3.91103196144104
INFO:root:current mean train loss 1731.722579321663
INFO:root:current train perplexity3.9116921424865723
INFO:root:current mean train loss 1732.0442085943278
INFO:root:current train perplexity3.9106943607330322
INFO:root:current mean train loss 1732.895108070579
INFO:root:current train perplexity3.9124512672424316
INFO:root:current mean train loss 1732.7628310579053
INFO:root:current train perplexity3.9136011600494385
INFO:root:current mean train loss 1732.1869236497573
INFO:root:current train perplexity3.9140822887420654
INFO:root:current mean train loss 1732.1034956828203
INFO:root:current train perplexity3.9161510467529297
INFO:root:current mean train loss 1733.266842155507
INFO:root:current train perplexity3.916949510574341
INFO:root:current mean train loss 1733.2483706562937
INFO:root:current train perplexity3.91896390914917
INFO:root:current mean train loss 1733.8529447290693
INFO:root:current train perplexity3.9198484420776367
INFO:root:current mean train loss 1734.1465043611538
INFO:root:current train perplexity3.9199142456054688
INFO:root:current mean train loss 1734.1370766698506
INFO:root:current train perplexity3.9209630489349365


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:24<00:00, 144.23s/it]
INFO:root:final mean train loss: 1732.5340273304535
INFO:root:final train perplexity: 3.9211323261260986
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.79s/it]
INFO:root:eval mean loss: 2886.1803187464807
INFO:root:eval perplexity: 10.67945384979248
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/96

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [4:26:27<10:56, 164.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1754.1455353767642
INFO:root:current train perplexity3.985055685043335
INFO:root:current mean train loss 1740.1830383766699
INFO:root:current train perplexity3.966002941131592
INFO:root:current mean train loss 1737.9107317243304
INFO:root:current train perplexity3.9487009048461914
INFO:root:current mean train loss 1737.2762429044326
INFO:root:current train perplexity3.9367527961730957
INFO:root:current mean train loss 1740.0030251345888
INFO:root:current train perplexity3.937089681625366
INFO:root:current mean train loss 1738.439299100312
INFO:root:current train perplexity3.9323034286499023
INFO:root:current mean train loss 1737.6331773567501
INFO:root:current train perplexity3.9285407066345215
INFO:root:current mean train loss 1737.2156296089474
INFO:root:current train perplexity3.9269893169403076
INFO:root:current mean train loss 1736.6590297070077
INFO:root:current train perplexity3.9272801876068115
INFO:root:current mean train loss 1734.8496872587439
INFO:root:current train perplexity3.9240403175354004
INFO:root:current mean train loss 1733.600877319691
INFO:root:current train perplexity3.9225316047668457
INFO:root:current mean train loss 1733.4203533843806
INFO:root:current train perplexity3.9218928813934326
INFO:root:current mean train loss 1733.8402554770005
INFO:root:current train perplexity3.9221551418304443
INFO:root:current mean train loss 1733.8364919982039
INFO:root:current train perplexity3.9215264320373535
INFO:root:current mean train loss 1732.3131131666012
INFO:root:current train perplexity3.921199083328247
INFO:root:current mean train loss 1732.111108382491
INFO:root:current train perplexity3.9222300052642822
INFO:root:current mean train loss 1733.6970871972717
INFO:root:current train perplexity3.925025701522827
INFO:root:current mean train loss 1733.471910499824
INFO:root:current train perplexity3.9226605892181396
INFO:root:current mean train loss 1733.051305198982
INFO:root:current train perplexity3.922677516937256
INFO:root:current mean train loss 1733.1272570680671
INFO:root:current train perplexity3.922154188156128


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:27<00:00, 147.22s/it]
INFO:root:final mean train loss: 1732.6759060904405
INFO:root:final train perplexity: 3.9215712547302246
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.88s/it]
INFO:root:eval mean loss: 2886.408129076342
INFO:root:eval perplexity: 10.68144702911377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/97

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [4:29:13<08:14, 164.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1729.6612141927083
INFO:root:current train perplexity3.9214677810668945
INFO:root:current mean train loss 1729.9116697569152
INFO:root:current train perplexity3.9402613639831543
INFO:root:current mean train loss 1734.3935842206402
INFO:root:current train perplexity3.9460713863372803
INFO:root:current mean train loss 1732.8480989302711
INFO:root:current train perplexity3.931640148162842
INFO:root:current mean train loss 1736.110669544765
INFO:root:current train perplexity3.9325406551361084
INFO:root:current mean train loss 1736.987727923985
INFO:root:current train perplexity3.924015998840332
INFO:root:current mean train loss 1738.2463972303603
INFO:root:current train perplexity3.924781322479248
INFO:root:current mean train loss 1737.3505312669724
INFO:root:current train perplexity3.921018600463867
INFO:root:current mean train loss 1734.806760392099
INFO:root:current train perplexity3.9207329750061035
INFO:root:current mean train loss 1734.6277723352616
INFO:root:current train perplexity3.9205069541931152
INFO:root:current mean train loss 1734.5267013666285
INFO:root:current train perplexity3.9218993186950684
INFO:root:current mean train loss 1732.6388797560635
INFO:root:current train perplexity3.9218740463256836
INFO:root:current mean train loss 1733.2278536283052
INFO:root:current train perplexity3.9208526611328125
INFO:root:current mean train loss 1734.444233065189
INFO:root:current train perplexity3.9223814010620117
INFO:root:current mean train loss 1734.002991312775
INFO:root:current train perplexity3.9220077991485596
INFO:root:current mean train loss 1733.2361365029979
INFO:root:current train perplexity3.920323133468628
INFO:root:current mean train loss 1733.187356078509
INFO:root:current train perplexity3.919119119644165
INFO:root:current mean train loss 1732.924036719979
INFO:root:current train perplexity3.9187135696411133
INFO:root:current mean train loss 1732.2975634290026
INFO:root:current train perplexity3.9195072650909424
INFO:root:current mean train loss 1731.789406277071
INFO:root:current train perplexity3.9187827110290527


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:28<00:00, 148.82s/it]
INFO:root:final mean train loss: 1731.748385661669
INFO:root:final train perplexity: 3.9187042713165283
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.93s/it]
INFO:root:eval mean loss: 2885.854098483249
INFO:root:eval perplexity: 10.676591873168945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/98

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [4:32:00<05:30, 165.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1733.852266751803
INFO:root:current train perplexity3.891974687576294
INFO:root:current mean train loss 1727.9500377308239
INFO:root:current train perplexity3.910947561264038
INFO:root:current mean train loss 1728.2454276606722
INFO:root:current train perplexity3.917207717895508
INFO:root:current mean train loss 1727.2307784407105
INFO:root:current train perplexity3.916524648666382
INFO:root:current mean train loss 1730.5737932102654
INFO:root:current train perplexity3.9180099964141846
INFO:root:current mean train loss 1734.177144116427
INFO:root:current train perplexity3.9172394275665283
INFO:root:current mean train loss 1733.6006184283951
INFO:root:current train perplexity3.913400650024414
INFO:root:current mean train loss 1734.2248080384497
INFO:root:current train perplexity3.9138498306274414
INFO:root:current mean train loss 1734.2038397816564
INFO:root:current train perplexity3.915379047393799
INFO:root:current mean train loss 1734.1365173656088
INFO:root:current train perplexity3.916139841079712
INFO:root:current mean train loss 1733.2708327602334
INFO:root:current train perplexity3.912686824798584
INFO:root:current mean train loss 1732.9311647079533
INFO:root:current train perplexity3.915581226348877
INFO:root:current mean train loss 1732.7201914911684
INFO:root:current train perplexity3.9154999256134033
INFO:root:current mean train loss 1732.9980051117502
INFO:root:current train perplexity3.916987895965576
INFO:root:current mean train loss 1731.7704921475042
INFO:root:current train perplexity3.9151864051818848
INFO:root:current mean train loss 1731.2728069463858
INFO:root:current train perplexity3.9145689010620117
INFO:root:current mean train loss 1730.9189383475273
INFO:root:current train perplexity3.913273572921753
INFO:root:current mean train loss 1731.3375651502745
INFO:root:current train perplexity3.9138526916503906
INFO:root:current mean train loss 1730.959871332
INFO:root:current train perplexity3.9135191440582275
INFO:root:current mean train loss 1731.4367529793853
INFO:root:current train perplexity3.915701150894165


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.86s/it]
INFO:root:final mean train loss: 1730.991229128008
INFO:root:final train perplexity: 3.9163644313812256
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:16<00:00, 16.69s/it]
INFO:root:eval mean loss: 2886.2674021677926
INFO:root:eval perplexity: 10.680217742919922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/99

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [4:34:44<02:44, 164.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1724.0704062857278
INFO:root:current train perplexity3.8663182258605957
INFO:root:current mean train loss 1719.8089981917497
INFO:root:current train perplexity3.8824374675750732
INFO:root:current mean train loss 1725.2364086394614
INFO:root:current train perplexity3.8945624828338623
INFO:root:current mean train loss 1727.3770809473167
INFO:root:current train perplexity3.894716739654541
INFO:root:current mean train loss 1728.061102522854
INFO:root:current train perplexity3.89583158493042
INFO:root:current mean train loss 1728.1577333011169
INFO:root:current train perplexity3.902646780014038
INFO:root:current mean train loss 1729.424800033793
INFO:root:current train perplexity3.906193971633911
INFO:root:current mean train loss 1730.620292956262
INFO:root:current train perplexity3.9098501205444336
INFO:root:current mean train loss 1729.7777202026643
INFO:root:current train perplexity3.9086403846740723
INFO:root:current mean train loss 1730.5140677955146
INFO:root:current train perplexity3.9105148315429688
INFO:root:current mean train loss 1730.434322223205
INFO:root:current train perplexity3.910374879837036
INFO:root:current mean train loss 1730.3088002987522
INFO:root:current train perplexity3.9092092514038086
INFO:root:current mean train loss 1730.4737088922034
INFO:root:current train perplexity3.909852981567383
INFO:root:current mean train loss 1730.4977497371337
INFO:root:current train perplexity3.9101643562316895
INFO:root:current mean train loss 1732.2928423965186
INFO:root:current train perplexity3.9134514331817627
INFO:root:current mean train loss 1730.4490127274119
INFO:root:current train perplexity3.911034107208252
INFO:root:current mean train loss 1729.6531575278918
INFO:root:current train perplexity3.9114809036254883
INFO:root:current mean train loss 1729.4872125524998
INFO:root:current train perplexity3.9113683700561523
INFO:root:current mean train loss 1730.2865342435118
INFO:root:current train perplexity3.9134891033172607
INFO:root:current mean train loss 1731.1072564457068
INFO:root:current train perplexity3.91526198387146


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:25<00:00, 145.43s/it]
INFO:root:final mean train loss: 1730.5999970390408
INFO:root:final train perplexity: 3.915156364440918
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:17<00:00, 17.36s/it]
INFO:root:eval mean loss: 2886.1861018733575
INFO:root:eval perplexity: 10.6795015335083
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13_single_gpu/100

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [4:37:28<00:00, 164.56s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [4:37:28<00:00, 166.48s/it]
INFO:root:evaluating final model
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.73s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:15<00:00, 15.74s/it]
INFO:root:eval mean loss: 2886.1861018733575
INFO:root:eval perplexity: 10.6795015335083
INFO:root:evalaution complete
INFO:root:save model final: std_13_single_gpu/final
