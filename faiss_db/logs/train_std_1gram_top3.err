INFO:root:Output: std_13
INFO:root:Steps per epochs:1983
INFO:root:Total steps:198300
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.key.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.key.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.3.crossattention.output.LayerNorm.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/100 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
INFO:root:current mean train loss 12240.80816958649
INFO:root:current train perplexity16735.642578125
INFO:root:current mean train loss 10574.320842493718
INFO:root:current train perplexity4211.27587890625
INFO:root:current mean train loss 9200.132549579326
INFO:root:current train perplexity1413.34033203125
INFO:root:current mean train loss 8248.726503759399
INFO:root:current train perplexity666.72265625
INFO:root:current mean train loss 7554.6591728378635
INFO:root:current train perplexity386.46405029296875
INFO:root:current mean train loss 7027.339030219637
INFO:root:current train perplexity254.9293670654297
INFO:root:current mean train loss 6616.987994498279
INFO:root:current train perplexity183.86309814453125
INFO:root:current mean train loss 6290.57562706557
INFO:root:current train perplexity141.67430114746094
INFO:root:current mean train loss 6013.004714982793
INFO:root:current train perplexity114.39533233642578
INFO:root:current mean train loss 5788.470835581676
INFO:root:current train perplexity95.33344268798828
INFO:root:current mean train loss 5588.781208236181
INFO:root:current train perplexity81.63374328613281
INFO:root:current mean train loss 5418.9392965410625
INFO:root:current train perplexity71.44381713867188
INFO:root:current mean train loss 5272.02760743691
INFO:root:current train perplexity63.45397186279297
INFO:root:current mean train loss 5135.9576800811965
INFO:root:current train perplexity57.14496994018555
INFO:root:current mean train loss 5017.006212800721
INFO:root:current train perplexity52.10288619995117
INFO:root:current mean train loss 4910.193308989506
INFO:root:current train perplexity47.920658111572266
INFO:root:current mean train loss 4814.640113870981
INFO:root:current train perplexity44.4111328125
INFO:root:current mean train loss 4726.027459781259
INFO:root:current train perplexity41.461429595947266
INFO:root:current mean train loss 4643.2216217057085
INFO:root:current train perplexity38.90069580078125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:09<00:00, 489.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:09<00:00, 489.03s/it]
INFO:root:final mean train loss: 4579.116779244673
INFO:root:final train perplexity: 37.01660919189453
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:56<00:00, 56.28s/it]
INFO:root:eval mean loss: 3479.7027488914696
INFO:root:eval perplexity: 17.38051986694336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/1

  1%|          | 1/100 [09:05<15:00:26, 545.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3113.822280883789
INFO:root:current train perplexity11.570454597473145
INFO:root:current mean train loss 3104.8757724104257
INFO:root:current train perplexity11.595562934875488
INFO:root:current mean train loss 3085.2620612250435
INFO:root:current train perplexity11.516501426696777
INFO:root:current mean train loss 3083.920482007763
INFO:root:current train perplexity11.495789527893066
INFO:root:current mean train loss 3077.3122576200044
INFO:root:current train perplexity11.403766632080078
INFO:root:current mean train loss 3067.283987592357
INFO:root:current train perplexity11.263191223144531
INFO:root:current mean train loss 3049.261654544186
INFO:root:current train perplexity11.1312894821167
INFO:root:current mean train loss 3039.099546634951
INFO:root:current train perplexity11.03654670715332
INFO:root:current mean train loss 3030.2018495447496
INFO:root:current train perplexity10.958322525024414
INFO:root:current mean train loss 3024.4009116893253
INFO:root:current train perplexity10.882987976074219
INFO:root:current mean train loss 3012.232353871263
INFO:root:current train perplexity10.799345970153809
INFO:root:current mean train loss 3003.874822801159
INFO:root:current train perplexity10.706931114196777
INFO:root:current mean train loss 2997.163565585488
INFO:root:current train perplexity10.634724617004395
INFO:root:current mean train loss 2988.6750386246795
INFO:root:current train perplexity10.555922508239746
INFO:root:current mean train loss 2980.140230168057
INFO:root:current train perplexity10.487671852111816
INFO:root:current mean train loss 2972.412483960154
INFO:root:current train perplexity10.417061805725098
INFO:root:current mean train loss 2963.6288840416632
INFO:root:current train perplexity10.347643852233887
INFO:root:current mean train loss 2956.5661441829657
INFO:root:current train perplexity10.288034439086914
INFO:root:current mean train loss 2946.823383616981
INFO:root:current train perplexity10.220420837402344
INFO:root:current mean train loss 2939.264123840969
INFO:root:current train perplexity10.152722358703613


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.75s/it]
INFO:root:final mean train loss: 2933.828647261488
INFO:root:final train perplexity: 10.112715721130371
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.78s/it]
INFO:root:eval mean loss: 3239.4855297191725
INFO:root:eval perplexity: 14.271069526672363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/2

  2%|â–         | 2/100 [18:12<14:52:00, 546.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2822.651611328125
INFO:root:current train perplexity9.238282203674316
INFO:root:current mean train loss 2767.693262085879
INFO:root:current train perplexity8.945897102355957
INFO:root:current mean train loss 2766.1150331947424
INFO:root:current train perplexity8.914144515991211
INFO:root:current mean train loss 2753.8800924948387
INFO:root:current train perplexity8.842846870422363
INFO:root:current mean train loss 2756.26203224235
INFO:root:current train perplexity8.806857109069824
INFO:root:current mean train loss 2752.506008699285
INFO:root:current train perplexity8.765356063842773
INFO:root:current mean train loss 2748.066315613275
INFO:root:current train perplexity8.724644660949707
INFO:root:current mean train loss 2742.5383886985205
INFO:root:current train perplexity8.690730094909668
INFO:root:current mean train loss 2738.298205024197
INFO:root:current train perplexity8.661049842834473
INFO:root:current mean train loss 2732.341031744038
INFO:root:current train perplexity8.62993049621582
INFO:root:current mean train loss 2727.5981840002573
INFO:root:current train perplexity8.598495483398438
INFO:root:current mean train loss 2722.8735595056683
INFO:root:current train perplexity8.576029777526855
INFO:root:current mean train loss 2717.819955892323
INFO:root:current train perplexity8.546127319335938
INFO:root:current mean train loss 2711.624645236016
INFO:root:current train perplexity8.508475303649902
INFO:root:current mean train loss 2710.908374347141
INFO:root:current train perplexity8.492602348327637
INFO:root:current mean train loss 2709.648798853606
INFO:root:current train perplexity8.46812915802002
INFO:root:current mean train loss 2705.7611688729526
INFO:root:current train perplexity8.44227409362793
INFO:root:current mean train loss 2702.501666862017
INFO:root:current train perplexity8.41510009765625
INFO:root:current mean train loss 2698.559349746829
INFO:root:current train perplexity8.384565353393555
INFO:root:current mean train loss 2693.973373515706
INFO:root:current train perplexity8.359312057495117


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:10<00:00, 490.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:10<00:00, 490.49s/it]
INFO:root:final mean train loss: 2690.166544781029
INFO:root:final train perplexity: 8.344705581665039
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:05<00:00, 65.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:05<00:00, 65.71s/it]
INFO:root:eval mean loss: 3127.4527246973535
INFO:root:eval perplexity: 13.01761245727539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/3

  3%|â–Ž         | 3/100 [27:29<14:50:58, 551.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2626.1925439453125
INFO:root:current train perplexity7.8876543045043945
INFO:root:current mean train loss 2611.9165576171877
INFO:root:current train perplexity7.838083267211914
INFO:root:current mean train loss 2602.814111328125
INFO:root:current train perplexity7.801070690155029
INFO:root:current mean train loss 2595.6669880022323
INFO:root:current train perplexity7.745030879974365
INFO:root:current mean train loss 2600.065995551215
INFO:root:current train perplexity7.738469123840332
INFO:root:current mean train loss 2592.513563565341
INFO:root:current train perplexity7.701128005981445
INFO:root:current mean train loss 2588.815598332332
INFO:root:current train perplexity7.685586452484131
INFO:root:current mean train loss 2585.8258209635414
INFO:root:current train perplexity7.670581340789795
INFO:root:current mean train loss 2583.8017325367646
INFO:root:current train perplexity7.668059825897217
INFO:root:current mean train loss 2581.0433372738485
INFO:root:current train perplexity7.649055004119873
INFO:root:current mean train loss 2577.377777390253
INFO:root:current train perplexity7.628602504730225
INFO:root:current mean train loss 2576.784940132473
INFO:root:current train perplexity7.620615005493164
INFO:root:current mean train loss 2573.625640234375
INFO:root:current train perplexity7.60657262802124
INFO:root:current mean train loss 2571.305363317419
INFO:root:current train perplexity7.591397285461426
INFO:root:current mean train loss 2570.6886988146553
INFO:root:current train perplexity7.585690975189209
INFO:root:current mean train loss 2567.91591844128
INFO:root:current train perplexity7.5721354484558105
INFO:root:current mean train loss 2566.4664504912407
INFO:root:current train perplexity7.561370372772217
INFO:root:current mean train loss 2563.648728794643
INFO:root:current train perplexity7.543702602386475
INFO:root:current mean train loss 2562.5949299250424
INFO:root:current train perplexity7.537350654602051
INFO:root:current mean train loss 2560.3992853565705
INFO:root:current train perplexity7.527015686035156


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:06<00:00, 486.29s/it]
INFO:root:final mean train loss: 2558.9381828058026
INFO:root:final train perplexity: 7.524263381958008
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.88s/it]
INFO:root:eval mean loss: 3062.3687095298424
INFO:root:eval perplexity: 12.340629577636719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/4

  4%|â–         | 4/100 [36:38<14:40:40, 550.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2536.7751792793842
INFO:root:current train perplexity7.240800857543945
INFO:root:current mean train loss 2501.0708914202846
INFO:root:current train perplexity7.155764579772949
INFO:root:current mean train loss 2497.724704013782
INFO:root:current train perplexity7.158891677856445
INFO:root:current mean train loss 2497.794366737802
INFO:root:current train perplexity7.166796684265137
INFO:root:current mean train loss 2498.802882584566
INFO:root:current train perplexity7.178024768829346
INFO:root:current mean train loss 2493.9721475160522
INFO:root:current train perplexity7.144720554351807
INFO:root:current mean train loss 2495.458162459298
INFO:root:current train perplexity7.14528751373291
INFO:root:current mean train loss 2492.4237003251815
INFO:root:current train perplexity7.130444526672363
INFO:root:current mean train loss 2492.594740219732
INFO:root:current train perplexity7.11893892288208
INFO:root:current mean train loss 2489.007646499523
INFO:root:current train perplexity7.102966785430908
INFO:root:current mean train loss 2488.3582255712936
INFO:root:current train perplexity7.097763538360596
INFO:root:current mean train loss 2487.5802663036566
INFO:root:current train perplexity7.089566230773926
INFO:root:current mean train loss 2484.3190363979566
INFO:root:current train perplexity7.076671600341797
INFO:root:current mean train loss 2483.7033792312945
INFO:root:current train perplexity7.070610523223877
INFO:root:current mean train loss 2481.200638909525
INFO:root:current train perplexity7.065791606903076
INFO:root:current mean train loss 2478.932670861045
INFO:root:current train perplexity7.0609130859375
INFO:root:current mean train loss 2475.3038524863387
INFO:root:current train perplexity7.044653415679932
INFO:root:current mean train loss 2473.8066553397575
INFO:root:current train perplexity7.032580852508545
INFO:root:current mean train loss 2471.8288182573774
INFO:root:current train perplexity7.022397518157959
INFO:root:current mean train loss 2469.818948254103
INFO:root:current train perplexity7.0093207359313965


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:09<00:00, 489.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:09<00:00, 489.57s/it]
INFO:root:final mean train loss: 2468.841422815366
INFO:root:final train perplexity: 7.008172988891602
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:12<00:00, 72.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:12<00:00, 72.05s/it]
INFO:root:eval mean loss: 3019.6617303338494
INFO:root:eval perplexity: 11.915655136108398
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/5

  5%|â–Œ         | 5/100 [46:01<14:38:30, 554.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2426.97412835984
INFO:root:current train perplexity6.719787120819092
INFO:root:current mean train loss 2422.8815128492274
INFO:root:current train perplexity6.741586208343506
INFO:root:current mean train loss 2420.688848361163
INFO:root:current train perplexity6.763671875
INFO:root:current mean train loss 2422.1101954778037
INFO:root:current train perplexity6.76780366897583
INFO:root:current mean train loss 2427.81722669365
INFO:root:current train perplexity6.779326438903809
INFO:root:current mean train loss 2421.208764899267
INFO:root:current train perplexity6.744627475738525
INFO:root:current mean train loss 2419.5771894845348
INFO:root:current train perplexity6.72500467300415
INFO:root:current mean train loss 2419.3587246330417
INFO:root:current train perplexity6.730231285095215
INFO:root:current mean train loss 2417.4951055880583
INFO:root:current train perplexity6.717164039611816
INFO:root:current mean train loss 2413.2113061920413
INFO:root:current train perplexity6.698617935180664
INFO:root:current mean train loss 2412.4725658233756
INFO:root:current train perplexity6.697989463806152
INFO:root:current mean train loss 2410.8768185795966
INFO:root:current train perplexity6.69073486328125
INFO:root:current mean train loss 2409.634594308253
INFO:root:current train perplexity6.685089588165283
INFO:root:current mean train loss 2409.4187599138027
INFO:root:current train perplexity6.6807332038879395
INFO:root:current mean train loss 2409.5587720845265
INFO:root:current train perplexity6.681430816650391
INFO:root:current mean train loss 2408.7029022833312
INFO:root:current train perplexity6.672614574432373
INFO:root:current mean train loss 2407.7148848508714
INFO:root:current train perplexity6.666094779968262
INFO:root:current mean train loss 2404.671142578125
INFO:root:current train perplexity6.659862518310547
INFO:root:current mean train loss 2404.161581699509
INFO:root:current train perplexity6.653538703918457


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.73s/it]
INFO:root:final mean train loss: 2401.627558397994
INFO:root:final train perplexity: 6.646351337432861
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.88s/it]
INFO:root:eval mean loss: 2982.396823825779
INFO:root:eval perplexity: 11.556802749633789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/6

  6%|â–Œ         | 6/100 [54:56<14:18:35, 548.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2478.32373046875
INFO:root:current train perplexity6.153080463409424
INFO:root:current mean train loss 2341.4972153465346
INFO:root:current train perplexity6.3566999435424805
INFO:root:current mean train loss 2352.8816130528994
INFO:root:current train perplexity6.412479877471924
INFO:root:current mean train loss 2362.3204848584146
INFO:root:current train perplexity6.427975177764893
INFO:root:current mean train loss 2358.9470141784213
INFO:root:current train perplexity6.422461032867432
INFO:root:current mean train loss 2356.4884047822325
INFO:root:current train perplexity6.4244818687438965
INFO:root:current mean train loss 2353.821516751053
INFO:root:current train perplexity6.415307521820068
INFO:root:current mean train loss 2355.777139835113
INFO:root:current train perplexity6.416980266571045
INFO:root:current mean train loss 2356.0803573170256
INFO:root:current train perplexity6.416391849517822
INFO:root:current mean train loss 2355.322884105551
INFO:root:current train perplexity6.4094719886779785
INFO:root:current mean train loss 2352.750538280079
INFO:root:current train perplexity6.4008588790893555
INFO:root:current mean train loss 2351.856382447952
INFO:root:current train perplexity6.393599033355713
INFO:root:current mean train loss 2351.7230619991155
INFO:root:current train perplexity6.391489505767822
INFO:root:current mean train loss 2351.433459200555
INFO:root:current train perplexity6.3912129402160645
INFO:root:current mean train loss 2351.031477411503
INFO:root:current train perplexity6.38988733291626
INFO:root:current mean train loss 2351.515896059528
INFO:root:current train perplexity6.386494159698486
INFO:root:current mean train loss 2350.1920055458504
INFO:root:current train perplexity6.379957675933838
INFO:root:current mean train loss 2350.0522551359954
INFO:root:current train perplexity6.380153179168701
INFO:root:current mean train loss 2349.950471309342
INFO:root:current train perplexity6.376535415649414
INFO:root:current mean train loss 2349.5296706631584
INFO:root:current train perplexity6.374256610870361


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:59<00:00, 479.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:59<00:00, 479.31s/it]
INFO:root:final mean train loss: 2348.1119375531866
INFO:root:final train perplexity: 6.371674537658691
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:02<00:00, 62.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:02<00:00, 62.28s/it]
INFO:root:eval mean loss: 2956.969384912256
INFO:root:eval perplexity: 11.318168640136719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/7

  7%|â–‹         | 7/100 [1:03:58<14:06:47, 546.32s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2308.012905544705
INFO:root:current train perplexity6.156399726867676
INFO:root:current mean train loss 2299.166653907905
INFO:root:current train perplexity6.203514099121094
INFO:root:current mean train loss 2314.4788280802036
INFO:root:current train perplexity6.2435784339904785
INFO:root:current mean train loss 2317.5434758408264
INFO:root:current train perplexity6.240938663482666
INFO:root:current mean train loss 2316.1235999878513
INFO:root:current train perplexity6.212915420532227
INFO:root:current mean train loss 2316.238967247451
INFO:root:current train perplexity6.210330963134766
INFO:root:current mean train loss 2315.019720281212
INFO:root:current train perplexity6.198920249938965
INFO:root:current mean train loss 2316.4152128171786
INFO:root:current train perplexity6.2043328285217285
INFO:root:current mean train loss 2315.3181941771563
INFO:root:current train perplexity6.194407939910889
INFO:root:current mean train loss 2313.6876203416477
INFO:root:current train perplexity6.190047264099121
INFO:root:current mean train loss 2310.9173582785256
INFO:root:current train perplexity6.181075572967529
INFO:root:current mean train loss 2311.1316257538224
INFO:root:current train perplexity6.175034523010254
INFO:root:current mean train loss 2310.8477274075713
INFO:root:current train perplexity6.170881271362305
INFO:root:current mean train loss 2311.5290256899657
INFO:root:current train perplexity6.177873611450195
INFO:root:current mean train loss 2311.567717085436
INFO:root:current train perplexity6.174684047698975
INFO:root:current mean train loss 2311.6171619279585
INFO:root:current train perplexity6.1707587242126465
INFO:root:current mean train loss 2309.801841405767
INFO:root:current train perplexity6.165079593658447
INFO:root:current mean train loss 2307.972582425172
INFO:root:current train perplexity6.158282279968262
INFO:root:current mean train loss 2307.2001651642213
INFO:root:current train perplexity6.15891170501709
INFO:root:current mean train loss 2305.0759775680845
INFO:root:current train perplexity6.1558685302734375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.65s/it]
INFO:root:final mean train loss: 2304.4350950363246
INFO:root:final train perplexity: 6.1559319496154785
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:02<00:00, 62.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:02<00:00, 62.41s/it]
INFO:root:eval mean loss: 2934.812436215512
INFO:root:eval perplexity: 11.114245414733887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/8

  8%|â–Š         | 8/100 [1:12:51<13:50:53, 541.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2273.2707763671874
INFO:root:current train perplexity5.976800918579102
INFO:root:current mean train loss 2281.097146267361
INFO:root:current train perplexity5.995319843292236
INFO:root:current mean train loss 2273.111121904089
INFO:root:current train perplexity5.9998979568481445
INFO:root:current mean train loss 2274.3833321187035
INFO:root:current train perplexity6.01146936416626
INFO:root:current mean train loss 2270.629558414152
INFO:root:current train perplexity6.011690139770508
INFO:root:current mean train loss 2269.7528130932387
INFO:root:current train perplexity6.000136852264404
INFO:root:current mean train loss 2272.810474401759
INFO:root:current train perplexity5.997766017913818
INFO:root:current mean train loss 2274.876953291082
INFO:root:current train perplexity6.000556468963623
INFO:root:current mean train loss 2275.477648267917
INFO:root:current train perplexity6.005434036254883
INFO:root:current mean train loss 2277.3402215804645
INFO:root:current train perplexity6.008998870849609
INFO:root:current mean train loss 2275.9826886605524
INFO:root:current train perplexity6.0078840255737305
INFO:root:current mean train loss 2273.25554231484
INFO:root:current train perplexity6.000823974609375
INFO:root:current mean train loss 2271.3352664592294
INFO:root:current train perplexity5.99694299697876
INFO:root:current mean train loss 2272.2953313363178
INFO:root:current train perplexity5.999794006347656
INFO:root:current mean train loss 2271.562401322953
INFO:root:current train perplexity5.996773719787598
INFO:root:current mean train loss 2272.166907096142
INFO:root:current train perplexity5.994884014129639
INFO:root:current mean train loss 2271.1907637943186
INFO:root:current train perplexity5.9931206703186035
INFO:root:current mean train loss 2269.7554973855144
INFO:root:current train perplexity5.9875688552856445
INFO:root:current mean train loss 2268.283741232225
INFO:root:current train perplexity5.981840133666992
INFO:root:current mean train loss 2268.216263866178
INFO:root:current train perplexity5.981058597564697


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:59<00:00, 479.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:59<00:00, 479.10s/it]
INFO:root:final mean train loss: 2268.3966252514047
INFO:root:final train perplexity: 5.983431339263916
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:03<00:00, 63.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:03<00:00, 63.13s/it]
INFO:root:eval mean loss: 2913.540234081738
INFO:root:eval perplexity: 10.921926498413086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/9

  9%|â–‰         | 9/100 [1:21:54<13:42:36, 542.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2217.4586510291465
INFO:root:current train perplexity5.7886247634887695
INFO:root:current mean train loss 2228.774483931692
INFO:root:current train perplexity5.762729167938232
INFO:root:current mean train loss 2240.3917473687065
INFO:root:current train perplexity5.821361541748047
INFO:root:current mean train loss 2236.661200436679
INFO:root:current train perplexity5.832895755767822
INFO:root:current mean train loss 2243.117281483338
INFO:root:current train perplexity5.849920272827148
INFO:root:current mean train loss 2245.056784146074
INFO:root:current train perplexity5.856616973876953
INFO:root:current mean train loss 2248.069091235202
INFO:root:current train perplexity5.865315914154053
INFO:root:current mean train loss 2244.5429892032703
INFO:root:current train perplexity5.8557233810424805
INFO:root:current mean train loss 2244.08359438041
INFO:root:current train perplexity5.8578972816467285
INFO:root:current mean train loss 2240.7290067272024
INFO:root:current train perplexity5.850090980529785
INFO:root:current mean train loss 2241.7109060541306
INFO:root:current train perplexity5.852814197540283
INFO:root:current mean train loss 2241.1689477496675
INFO:root:current train perplexity5.845686435699463
INFO:root:current mean train loss 2240.6673615184454
INFO:root:current train perplexity5.844875335693359
INFO:root:current mean train loss 2241.2603662253837
INFO:root:current train perplexity5.850916862487793
INFO:root:current mean train loss 2239.89337864395
INFO:root:current train perplexity5.846169948577881
INFO:root:current mean train loss 2237.429524923108
INFO:root:current train perplexity5.838852405548096
INFO:root:current mean train loss 2237.2722353438776
INFO:root:current train perplexity5.834905624389648
INFO:root:current mean train loss 2238.842628235142
INFO:root:current train perplexity5.838964462280273
INFO:root:current mean train loss 2237.2546439448906
INFO:root:current train perplexity5.83482551574707
INFO:root:current mean train loss 2237.3638038635254
INFO:root:current train perplexity5.834997177124023


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.58s/it]
INFO:root:final mean train loss: 2236.4652501585742
INFO:root:final train perplexity: 5.834630966186523
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.27s/it]
INFO:root:eval mean loss: 2898.943254533831
INFO:root:eval perplexity: 10.791884422302246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/10

 10%|â–ˆ         | 10/100 [1:30:46<13:28:46, 539.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2226.040474269701
INFO:root:current train perplexity5.729886531829834
INFO:root:current mean train loss 2227.758532642613
INFO:root:current train perplexity5.7157440185546875
INFO:root:current mean train loss 2210.0962599289905
INFO:root:current train perplexity5.680360794067383
INFO:root:current mean train loss 2209.6204943152948
INFO:root:current train perplexity5.6877970695495605
INFO:root:current mean train loss 2210.114076659115
INFO:root:current train perplexity5.686825275421143
INFO:root:current mean train loss 2214.4810256823926
INFO:root:current train perplexity5.702354431152344
INFO:root:current mean train loss 2210.5549362022957
INFO:root:current train perplexity5.695422649383545
INFO:root:current mean train loss 2212.5036602045066
INFO:root:current train perplexity5.709332466125488
INFO:root:current mean train loss 2213.7012669746564
INFO:root:current train perplexity5.704530239105225
INFO:root:current mean train loss 2212.8178271282814
INFO:root:current train perplexity5.706002712249756
INFO:root:current mean train loss 2211.2936823303394
INFO:root:current train perplexity5.707525253295898
INFO:root:current mean train loss 2211.2512769870414
INFO:root:current train perplexity5.707847595214844
INFO:root:current mean train loss 2210.7147942100387
INFO:root:current train perplexity5.70504093170166
INFO:root:current mean train loss 2211.1610702169123
INFO:root:current train perplexity5.707036972045898
INFO:root:current mean train loss 2211.841993317627
INFO:root:current train perplexity5.708067417144775
INFO:root:current mean train loss 2210.144957756981
INFO:root:current train perplexity5.705419063568115
INFO:root:current mean train loss 2209.245572336424
INFO:root:current train perplexity5.704212188720703
INFO:root:current mean train loss 2208.091201566585
INFO:root:current train perplexity5.7028326988220215
INFO:root:current mean train loss 2207.277808061317
INFO:root:current train perplexity5.7022600173950195
INFO:root:current mean train loss 2208.6906728361873
INFO:root:current train perplexity5.706047058105469


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:55<00:00, 475.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:55<00:00, 475.37s/it]
INFO:root:final mean train loss: 2208.2425309651076
INFO:root:final train perplexity: 5.706198215484619
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.29s/it]
INFO:root:eval mean loss: 2882.5193347644517
INFO:root:eval perplexity: 10.647419929504395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/11

 11%|â–ˆ         | 11/100 [1:39:43<13:18:45, 538.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2213.1620767282884
INFO:root:current train perplexity5.647088527679443
INFO:root:current mean train loss 2182.93606468939
INFO:root:current train perplexity5.590829849243164
INFO:root:current mean train loss 2183.5618550760764
INFO:root:current train perplexity5.5875630378723145
INFO:root:current mean train loss 2193.1206696663494
INFO:root:current train perplexity5.618099689483643
INFO:root:current mean train loss 2188.1273542490517
INFO:root:current train perplexity5.597597599029541
INFO:root:current mean train loss 2187.6603551871135
INFO:root:current train perplexity5.592528343200684
INFO:root:current mean train loss 2189.286899577772
INFO:root:current train perplexity5.598814010620117
INFO:root:current mean train loss 2189.280304498648
INFO:root:current train perplexity5.60659122467041
INFO:root:current mean train loss 2186.7451213208064
INFO:root:current train perplexity5.602352142333984
INFO:root:current mean train loss 2186.760960576984
INFO:root:current train perplexity5.605874538421631
INFO:root:current mean train loss 2183.2975774101133
INFO:root:current train perplexity5.596665859222412
INFO:root:current mean train loss 2186.4319970579613
INFO:root:current train perplexity5.602102756500244
INFO:root:current mean train loss 2185.134511422592
INFO:root:current train perplexity5.599985599517822
INFO:root:current mean train loss 2185.091226156656
INFO:root:current train perplexity5.600693702697754
INFO:root:current mean train loss 2184.4732233922864
INFO:root:current train perplexity5.598037242889404
INFO:root:current mean train loss 2184.210889087499
INFO:root:current train perplexity5.59589147567749
INFO:root:current mean train loss 2184.2783035151615
INFO:root:current train perplexity5.595978736877441
INFO:root:current mean train loss 2184.4176412926276
INFO:root:current train perplexity5.597554683685303
INFO:root:current mean train loss 2184.4699633245377
INFO:root:current train perplexity5.597589015960693


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.89s/it]
INFO:root:final mean train loss: 2184.1777049500834
INFO:root:final train perplexity: 5.598921775817871
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.87s/it]
INFO:root:eval mean loss: 2875.538214972785
INFO:root:eval perplexity: 10.586600303649902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/12

 12%|â–ˆâ–        | 12/100 [1:48:33<13:06:01, 535.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2054.5669759114585
INFO:root:current train perplexity5.138033866882324
INFO:root:current mean train loss 2158.601685755461
INFO:root:current train perplexity5.476642608642578
INFO:root:current mean train loss 2166.0193845250924
INFO:root:current train perplexity5.509535312652588
INFO:root:current mean train loss 2160.9728343195648
INFO:root:current train perplexity5.500583171844482
INFO:root:current mean train loss 2157.3345489880585
INFO:root:current train perplexity5.500051975250244
INFO:root:current mean train loss 2161.4586523825797
INFO:root:current train perplexity5.51396369934082
INFO:root:current mean train loss 2159.567321271248
INFO:root:current train perplexity5.512065887451172
INFO:root:current mean train loss 2157.360857728874
INFO:root:current train perplexity5.504655361175537
INFO:root:current mean train loss 2157.2479845476923
INFO:root:current train perplexity5.500059127807617
INFO:root:current mean train loss 2160.9430684610325
INFO:root:current train perplexity5.506348609924316
INFO:root:current mean train loss 2160.8389948562517
INFO:root:current train perplexity5.504709243774414
INFO:root:current mean train loss 2159.6158894377195
INFO:root:current train perplexity5.500919818878174
INFO:root:current mean train loss 2158.3097099373963
INFO:root:current train perplexity5.502005100250244
INFO:root:current mean train loss 2157.3313705901046
INFO:root:current train perplexity5.499344825744629
INFO:root:current mean train loss 2157.2312103945787
INFO:root:current train perplexity5.496826171875
INFO:root:current mean train loss 2157.8671998451014
INFO:root:current train perplexity5.493108749389648
INFO:root:current mean train loss 2159.832997532093
INFO:root:current train perplexity5.494254112243652
INFO:root:current mean train loss 2158.9243534645893
INFO:root:current train perplexity5.493429183959961
INFO:root:current mean train loss 2160.0755724914857
INFO:root:current train perplexity5.496480464935303
INFO:root:current mean train loss 2161.008958087867
INFO:root:current train perplexity5.498101234436035


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.93s/it]
INFO:root:final mean train loss: 2161.289571772665
INFO:root:final train perplexity: 5.498762607574463
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.65s/it]
INFO:root:eval mean loss: 2868.107690209741
INFO:root:eval perplexity: 10.522247314453125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/13

 13%|â–ˆâ–Ž        | 13/100 [1:57:25<12:55:18, 534.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2209.4244384765625
INFO:root:current train perplexity5.486231327056885
INFO:root:current mean train loss 2144.45070699056
INFO:root:current train perplexity5.3831586837768555
INFO:root:current mean train loss 2150.3078740900214
INFO:root:current train perplexity5.409968376159668
INFO:root:current mean train loss 2141.367767715454
INFO:root:current train perplexity5.395273208618164
INFO:root:current mean train loss 2144.699889846075
INFO:root:current train perplexity5.396787643432617
INFO:root:current mean train loss 2145.8294208233174
INFO:root:current train perplexity5.413871765136719
INFO:root:current mean train loss 2145.470310137349
INFO:root:current train perplexity5.411981582641602
INFO:root:current mean train loss 2146.5864805433484
INFO:root:current train perplexity5.414658546447754
INFO:root:current mean train loss 2147.323744015577
INFO:root:current train perplexity5.417975902557373
INFO:root:current mean train loss 2147.8687539805537
INFO:root:current train perplexity5.418807029724121
INFO:root:current mean train loss 2145.66912578508
INFO:root:current train perplexity5.418315887451172
INFO:root:current mean train loss 2146.3919093540735
INFO:root:current train perplexity5.421696186065674
INFO:root:current mean train loss 2143.6727327940894
INFO:root:current train perplexity5.420560836791992
INFO:root:current mean train loss 2142.715065326113
INFO:root:current train perplexity5.4205098152160645
INFO:root:current mean train loss 2142.1882358604753
INFO:root:current train perplexity5.41455602645874
INFO:root:current mean train loss 2141.2204315185545
INFO:root:current train perplexity5.413041591644287
INFO:root:current mean train loss 2141.315849323037
INFO:root:current train perplexity5.411569595336914
INFO:root:current mean train loss 2141.0130468324173
INFO:root:current train perplexity5.409886360168457
INFO:root:current mean train loss 2141.6318194378864
INFO:root:current train perplexity5.413082599639893
INFO:root:current mean train loss 2142.6333645502727
INFO:root:current train perplexity5.414344310760498


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.68s/it]
INFO:root:final mean train loss: 2141.561509402184
INFO:root:final train perplexity: 5.413870334625244
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.50s/it]
INFO:root:eval mean loss: 2862.194590342295
INFO:root:eval perplexity: 10.4713134765625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/14

 14%|â–ˆâ–        | 14/100 [2:06:10<12:42:21, 531.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2104.8106590477196
INFO:root:current train perplexity5.290112018585205
INFO:root:current mean train loss 2103.319518597457
INFO:root:current train perplexity5.31277322769165
INFO:root:current mean train loss 2118.255542610265
INFO:root:current train perplexity5.334274768829346
INFO:root:current mean train loss 2114.9961477217407
INFO:root:current train perplexity5.329662322998047
INFO:root:current mean train loss 2113.9238211415727
INFO:root:current train perplexity5.338118553161621
INFO:root:current mean train loss 2117.1463370722763
INFO:root:current train perplexity5.3399786949157715
INFO:root:current mean train loss 2116.4581643767783
INFO:root:current train perplexity5.33042049407959
INFO:root:current mean train loss 2113.927379923889
INFO:root:current train perplexity5.328779220581055
INFO:root:current mean train loss 2115.307502263478
INFO:root:current train perplexity5.33057165145874
INFO:root:current mean train loss 2116.6774025574055
INFO:root:current train perplexity5.335276126861572
INFO:root:current mean train loss 2117.0504315191433
INFO:root:current train perplexity5.336234092712402
INFO:root:current mean train loss 2119.585555399523
INFO:root:current train perplexity5.338305950164795
INFO:root:current mean train loss 2121.803052823584
INFO:root:current train perplexity5.343949794769287
INFO:root:current mean train loss 2121.9250728404604
INFO:root:current train perplexity5.343846321105957
INFO:root:current mean train loss 2122.2717832221533
INFO:root:current train perplexity5.33953332901001
INFO:root:current mean train loss 2123.5256334948867
INFO:root:current train perplexity5.345925807952881
INFO:root:current mean train loss 2123.498110930222
INFO:root:current train perplexity5.344460487365723
INFO:root:current mean train loss 2124.3036013061314
INFO:root:current train perplexity5.341494560241699
INFO:root:current mean train loss 2124.128383015574
INFO:root:current train perplexity5.338712692260742
INFO:root:current mean train loss 2125.1202138606336
INFO:root:current train perplexity5.340101718902588


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.90s/it]
INFO:root:final mean train loss: 2123.8839712138133
INFO:root:final train perplexity: 5.338916301727295
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.40s/it]
INFO:root:eval mean loss: 2853.2006176097975
INFO:root:eval perplexity: 10.394317626953125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/15

 15%|â–ˆâ–Œ        | 15/100 [2:15:02<12:33:21, 531.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2113.0046544958045
INFO:root:current train perplexity5.234457492828369
INFO:root:current mean train loss 2107.2281549627132
INFO:root:current train perplexity5.2128682136535645
INFO:root:current mean train loss 2103.940000519039
INFO:root:current train perplexity5.244204044342041
INFO:root:current mean train loss 2100.5352969412074
INFO:root:current train perplexity5.253539085388184
INFO:root:current mean train loss 2101.161576997866
INFO:root:current train perplexity5.252333641052246
INFO:root:current mean train loss 2099.5614203167306
INFO:root:current train perplexity5.250716686248779
INFO:root:current mean train loss 2101.433619694608
INFO:root:current train perplexity5.251195907592773
INFO:root:current mean train loss 2103.327762027002
INFO:root:current train perplexity5.260280132293701
INFO:root:current mean train loss 2104.398360026804
INFO:root:current train perplexity5.259392738342285
INFO:root:current mean train loss 2102.8602457426377
INFO:root:current train perplexity5.257312297821045
INFO:root:current mean train loss 2103.2121344607967
INFO:root:current train perplexity5.256514072418213
INFO:root:current mean train loss 2102.500024117878
INFO:root:current train perplexity5.257969856262207
INFO:root:current mean train loss 2104.493394088137
INFO:root:current train perplexity5.262821674346924
INFO:root:current mean train loss 2106.645438573209
INFO:root:current train perplexity5.268627166748047
INFO:root:current mean train loss 2106.0393628064016
INFO:root:current train perplexity5.264425277709961
INFO:root:current mean train loss 2106.3677782134814
INFO:root:current train perplexity5.266595363616943
INFO:root:current mean train loss 2105.788801163255
INFO:root:current train perplexity5.265395164489746
INFO:root:current mean train loss 2105.6886451225323
INFO:root:current train perplexity5.264069557189941
INFO:root:current mean train loss 2105.491496097437
INFO:root:current train perplexity5.264045238494873
INFO:root:current mean train loss 2106.9340252441907
INFO:root:current train perplexity5.2657470703125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.97s/it]
INFO:root:final mean train loss: 2106.641629725469
INFO:root:final train perplexity: 5.2668070793151855
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:10<00:00, 70.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:10<00:00, 70.64s/it]
INFO:root:eval mean loss: 2847.251519097222
INFO:root:eval perplexity: 10.34369945526123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/16

 16%|â–ˆâ–Œ        | 16/100 [2:24:02<12:27:53, 534.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2106.4309443084285
INFO:root:current train perplexity5.276459693908691
INFO:root:current mean train loss 2084.7006943016722
INFO:root:current train perplexity5.209000587463379
INFO:root:current mean train loss 2082.7916750749537
INFO:root:current train perplexity5.213109970092773
INFO:root:current mean train loss 2084.27937715844
INFO:root:current train perplexity5.206173896789551
INFO:root:current mean train loss 2085.5724270895535
INFO:root:current train perplexity5.200682640075684
INFO:root:current mean train loss 2086.7508837805112
INFO:root:current train perplexity5.195518493652344
INFO:root:current mean train loss 2085.698070088371
INFO:root:current train perplexity5.194018363952637
INFO:root:current mean train loss 2087.970559522181
INFO:root:current train perplexity5.192606449127197
INFO:root:current mean train loss 2086.9961554158294
INFO:root:current train perplexity5.194364547729492
INFO:root:current mean train loss 2088.0089444475734
INFO:root:current train perplexity5.19379186630249
INFO:root:current mean train loss 2087.704750324609
INFO:root:current train perplexity5.190359115600586
INFO:root:current mean train loss 2088.8101188470723
INFO:root:current train perplexity5.190365314483643
INFO:root:current mean train loss 2087.950531269977
INFO:root:current train perplexity5.191229820251465
INFO:root:current mean train loss 2088.206926809098
INFO:root:current train perplexity5.1947479248046875
INFO:root:current mean train loss 2088.0145404745654
INFO:root:current train perplexity5.195485591888428
INFO:root:current mean train loss 2088.8458078677
INFO:root:current train perplexity5.198275089263916
INFO:root:current mean train loss 2088.603749246101
INFO:root:current train perplexity5.193646430969238
INFO:root:current mean train loss 2089.68419252177
INFO:root:current train perplexity5.197863578796387
INFO:root:current mean train loss 2089.7024548855265
INFO:root:current train perplexity5.199262619018555
INFO:root:current mean train loss 2091.322142130224
INFO:root:current train perplexity5.2021026611328125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.28s/it]
INFO:root:final mean train loss: 2091.191572919375
INFO:root:final train perplexity: 5.20302152633667
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:11<00:00, 71.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:11<00:00, 71.10s/it]
INFO:root:eval mean loss: 2841.894433007226
INFO:root:eval perplexity: 10.298331260681152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/17

 17%|â–ˆâ–‹        | 17/100 [2:33:02<12:21:40, 536.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2056.022709239613
INFO:root:current train perplexity5.07912540435791
INFO:root:current mean train loss 2066.3507047612616
INFO:root:current train perplexity5.107668399810791
INFO:root:current mean train loss 2074.2197731865776
INFO:root:current train perplexity5.120640754699707
INFO:root:current mean train loss 2066.15696260118
INFO:root:current train perplexity5.110776901245117
INFO:root:current mean train loss 2069.9120053150614
INFO:root:current train perplexity5.127932071685791
INFO:root:current mean train loss 2071.8137306680483
INFO:root:current train perplexity5.128756523132324
INFO:root:current mean train loss 2072.4208498222883
INFO:root:current train perplexity5.132687091827393
INFO:root:current mean train loss 2070.6657504164023
INFO:root:current train perplexity5.131494522094727
INFO:root:current mean train loss 2071.6139189574096
INFO:root:current train perplexity5.132190704345703
INFO:root:current mean train loss 2075.3119574790057
INFO:root:current train perplexity5.135848045349121
INFO:root:current mean train loss 2076.664654339061
INFO:root:current train perplexity5.134968280792236
INFO:root:current mean train loss 2076.482367929786
INFO:root:current train perplexity5.1307172775268555
INFO:root:current mean train loss 2074.3113608982253
INFO:root:current train perplexity5.128530502319336
INFO:root:current mean train loss 2073.805680772413
INFO:root:current train perplexity5.1272783279418945
INFO:root:current mean train loss 2074.3119259085706
INFO:root:current train perplexity5.128307819366455
INFO:root:current mean train loss 2074.6819448014653
INFO:root:current train perplexity5.132889270782471
INFO:root:current mean train loss 2075.9366063845664
INFO:root:current train perplexity5.137717247009277
INFO:root:current mean train loss 2076.029015389598
INFO:root:current train perplexity5.14055871963501
INFO:root:current mean train loss 2076.2460621332716
INFO:root:current train perplexity5.1419677734375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.09s/it]
INFO:root:final mean train loss: 2076.2715997354467
INFO:root:final train perplexity: 5.142157077789307
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:11<00:00, 71.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:11<00:00, 71.32s/it]
INFO:root:eval mean loss: 2840.7532082864113
INFO:root:eval perplexity: 10.288689613342285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/18

 18%|â–ˆâ–Š        | 18/100 [2:42:05<12:15:24, 538.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2084.9435791015626
INFO:root:current train perplexity5.167886734008789
INFO:root:current mean train loss 2058.8288922991073
INFO:root:current train perplexity5.082207202911377
INFO:root:current mean train loss 2062.41640386814
INFO:root:current train perplexity5.081110000610352
INFO:root:current mean train loss 2066.3405269435193
INFO:root:current train perplexity5.094695568084717
INFO:root:current mean train loss 2062.5098029996143
INFO:root:current train perplexity5.090199947357178
INFO:root:current mean train loss 2060.749606474319
INFO:root:current train perplexity5.084542751312256
INFO:root:current mean train loss 2064.7299364830837
INFO:root:current train perplexity5.092524528503418
INFO:root:current mean train loss 2063.775397377826
INFO:root:current train perplexity5.093863487243652
INFO:root:current mean train loss 2063.5888771957493
INFO:root:current train perplexity5.087123394012451
INFO:root:current mean train loss 2064.988027937241
INFO:root:current train perplexity5.0919599533081055
INFO:root:current mean train loss 2067.513230964319
INFO:root:current train perplexity5.09765100479126
INFO:root:current mean train loss 2065.7375932374152
INFO:root:current train perplexity5.0914201736450195
INFO:root:current mean train loss 2065.058263602989
INFO:root:current train perplexity5.0884809494018555
INFO:root:current mean train loss 2064.341156122785
INFO:root:current train perplexity5.088590145111084
INFO:root:current mean train loss 2063.912533884286
INFO:root:current train perplexity5.086279392242432
INFO:root:current mean train loss 2062.356739173458
INFO:root:current train perplexity5.08476448059082
INFO:root:current mean train loss 2061.2816521094965
INFO:root:current train perplexity5.082764625549316
INFO:root:current mean train loss 2062.126884035351
INFO:root:current train perplexity5.084724426269531
INFO:root:current mean train loss 2061.367976865478
INFO:root:current train perplexity5.08291482925415
INFO:root:current mean train loss 2061.866287896264
INFO:root:current train perplexity5.084985733032227


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.31s/it]
INFO:root:final mean train loss: 2062.668375250912
INFO:root:final train perplexity: 5.087285041809082
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.37s/it]
INFO:root:eval mean loss: 2835.112399997654
INFO:root:eval perplexity: 10.241178512573242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/19

 19%|â–ˆâ–‰        | 19/100 [2:50:57<12:03:57, 536.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2010.2860107421875
INFO:root:current train perplexity4.944857597351074
INFO:root:current mean train loss 2035.9186431384478
INFO:root:current train perplexity4.960640907287598
INFO:root:current mean train loss 2033.6838609850086
INFO:root:current train perplexity4.973365306854248
INFO:root:current mean train loss 2035.0073727435947
INFO:root:current train perplexity4.977143287658691
INFO:root:current mean train loss 2044.4203505674245
INFO:root:current train perplexity4.986616611480713
INFO:root:current mean train loss 2046.616465835279
INFO:root:current train perplexity5.000874042510986
INFO:root:current mean train loss 2046.5399580093826
INFO:root:current train perplexity5.0085015296936035
INFO:root:current mean train loss 2045.0531103921398
INFO:root:current train perplexity5.0120015144348145
INFO:root:current mean train loss 2047.532639700711
INFO:root:current train perplexity5.013672351837158
INFO:root:current mean train loss 2048.6298944634627
INFO:root:current train perplexity5.015780448913574
INFO:root:current mean train loss 2047.792362459485
INFO:root:current train perplexity5.019490718841553
INFO:root:current mean train loss 2048.1471964518228
INFO:root:current train perplexity5.023710250854492
INFO:root:current mean train loss 2049.258560605213
INFO:root:current train perplexity5.027079105377197
INFO:root:current mean train loss 2051.1608938427808
INFO:root:current train perplexity5.033444881439209
INFO:root:current mean train loss 2051.1753134854903
INFO:root:current train perplexity5.032066345214844
INFO:root:current mean train loss 2051.836992020676
INFO:root:current train perplexity5.034884929656982
INFO:root:current mean train loss 2051.655626703867
INFO:root:current train perplexity5.034649848937988
INFO:root:current mean train loss 2051.890398935989
INFO:root:current train perplexity5.038967609405518
INFO:root:current mean train loss 2052.615857590174
INFO:root:current train perplexity5.042146682739258
INFO:root:current mean train loss 2052.929869843323
INFO:root:current train perplexity5.043105602264404


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.13s/it]
INFO:root:final mean train loss: 2051.0874075146558
INFO:root:final train perplexity: 5.041032314300537
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.40s/it]
INFO:root:eval mean loss: 2834.0911744263794
INFO:root:eval perplexity: 10.232600212097168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/20

 20%|â–ˆâ–ˆ        | 20/100 [2:59:42<11:50:24, 532.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2019.7269287109375
INFO:root:current train perplexity4.95526123046875
INFO:root:current mean train loss 2048.192609389051
INFO:root:current train perplexity4.971536636352539
INFO:root:current mean train loss 2045.0954702209729
INFO:root:current train perplexity4.972369194030762
INFO:root:current mean train loss 2044.5375004321072
INFO:root:current train perplexity4.975287914276123
INFO:root:current mean train loss 2042.0644406120978
INFO:root:current train perplexity4.975614070892334
INFO:root:current mean train loss 2041.760108735433
INFO:root:current train perplexity4.981967926025391
INFO:root:current mean train loss 2039.8258631651017
INFO:root:current train perplexity4.987083435058594
INFO:root:current mean train loss 2040.940361797245
INFO:root:current train perplexity4.987553596496582
INFO:root:current mean train loss 2039.2622780328143
INFO:root:current train perplexity4.987164497375488
INFO:root:current mean train loss 2039.6916149005342
INFO:root:current train perplexity4.986001968383789
INFO:root:current mean train loss 2038.7508309945335
INFO:root:current train perplexity4.983450412750244
INFO:root:current mean train loss 2039.7357890436376
INFO:root:current train perplexity4.986473560333252
INFO:root:current mean train loss 2038.380603313061
INFO:root:current train perplexity4.983357906341553
INFO:root:current mean train loss 2039.929812305271
INFO:root:current train perplexity4.987264156341553
INFO:root:current mean train loss 2040.5221329000444
INFO:root:current train perplexity4.991950511932373
INFO:root:current mean train loss 2041.6131623524052
INFO:root:current train perplexity4.9959306716918945
INFO:root:current mean train loss 2040.2863391180313
INFO:root:current train perplexity4.993488311767578
INFO:root:current mean train loss 2040.4550002077792
INFO:root:current train perplexity4.995098114013672
INFO:root:current mean train loss 2040.293114119214
INFO:root:current train perplexity4.993624210357666
INFO:root:current mean train loss 2039.4766013434155
INFO:root:current train perplexity4.9932050704956055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.35s/it]
INFO:root:final mean train loss: 2038.4522878672822
INFO:root:final train perplexity: 4.991048336029053
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.59s/it]
INFO:root:eval mean loss: 2835.490848758915
INFO:root:eval perplexity: 10.24435806274414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/21

 21%|â–ˆâ–ˆ        | 21/100 [3:08:32<11:40:29, 532.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2002.6114392961774
INFO:root:current train perplexity4.936631202697754
INFO:root:current mean train loss 2010.791543813852
INFO:root:current train perplexity4.928638935089111
INFO:root:current mean train loss 2016.5756468772888
INFO:root:current train perplexity4.9402995109558105
INFO:root:current mean train loss 2022.0485466089142
INFO:root:current train perplexity4.950545787811279
INFO:root:current mean train loss 2023.7440324749864
INFO:root:current train perplexity4.951879501342773
INFO:root:current mean train loss 2023.6107911034453
INFO:root:current train perplexity4.9392571449279785
INFO:root:current mean train loss 2021.726439127108
INFO:root:current train perplexity4.936572074890137
INFO:root:current mean train loss 2022.6741964350301
INFO:root:current train perplexity4.93403959274292
INFO:root:current mean train loss 2023.5098424893674
INFO:root:current train perplexity4.938642501831055
INFO:root:current mean train loss 2025.1550340213537
INFO:root:current train perplexity4.938971042633057
INFO:root:current mean train loss 2025.3029490384188
INFO:root:current train perplexity4.940582275390625
INFO:root:current mean train loss 2025.618937667266
INFO:root:current train perplexity4.940024375915527
INFO:root:current mean train loss 2025.1078096620597
INFO:root:current train perplexity4.936615943908691
INFO:root:current mean train loss 2026.1712696896893
INFO:root:current train perplexity4.940386772155762
INFO:root:current mean train loss 2026.8096771240234
INFO:root:current train perplexity4.940319538116455
INFO:root:current mean train loss 2027.2760264732538
INFO:root:current train perplexity4.941844940185547
INFO:root:current mean train loss 2027.8900055816207
INFO:root:current train perplexity4.941378593444824
INFO:root:current mean train loss 2028.1226842789008
INFO:root:current train perplexity4.943258285522461
INFO:root:current mean train loss 2028.6813126925765
INFO:root:current train perplexity4.945791721343994
INFO:root:current mean train loss 2028.2559658432788
INFO:root:current train perplexity4.948124885559082


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.84s/it]
INFO:root:final mean train loss: 2027.825026088451
INFO:root:final train perplexity: 4.949391841888428
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.75s/it]
INFO:root:eval mean loss: 2825.6373646595816
INFO:root:eval perplexity: 10.161861419677734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/22

 22%|â–ˆâ–ˆâ–       | 22/100 [3:17:18<11:29:13, 530.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2010.660858572346
INFO:root:current train perplexity4.907499313354492
INFO:root:current mean train loss 2016.5705065424042
INFO:root:current train perplexity4.896406173706055
INFO:root:current mean train loss 2014.8960497510302
INFO:root:current train perplexity4.89387321472168
INFO:root:current mean train loss 2012.5138073632288
INFO:root:current train perplexity4.8960676193237305
INFO:root:current mean train loss 2009.5028303279432
INFO:root:current train perplexity4.875789642333984
INFO:root:current mean train loss 2012.192766066413
INFO:root:current train perplexity4.885810375213623
INFO:root:current mean train loss 2012.485181788633
INFO:root:current train perplexity4.889247894287109
INFO:root:current mean train loss 2011.2233026067777
INFO:root:current train perplexity4.890056610107422
INFO:root:current mean train loss 2012.000291822156
INFO:root:current train perplexity4.893173694610596
INFO:root:current mean train loss 2014.401231693217
INFO:root:current train perplexity4.896942615509033
INFO:root:current mean train loss 2016.4372748582027
INFO:root:current train perplexity4.9023118019104
INFO:root:current mean train loss 2016.4989758789895
INFO:root:current train perplexity4.902677536010742
INFO:root:current mean train loss 2016.18897213153
INFO:root:current train perplexity4.903929233551025
INFO:root:current mean train loss 2015.4122173089836
INFO:root:current train perplexity4.9030985832214355
INFO:root:current mean train loss 2016.5586913731013
INFO:root:current train perplexity4.903191566467285
INFO:root:current mean train loss 2017.9605212348022
INFO:root:current train perplexity4.909521102905273
INFO:root:current mean train loss 2018.1243659348384
INFO:root:current train perplexity4.90781307220459
INFO:root:current mean train loss 2016.9706291116972
INFO:root:current train perplexity4.904146194458008
INFO:root:current mean train loss 2017.1217654300003
INFO:root:current train perplexity4.904576301574707
INFO:root:current mean train loss 2017.557637109771
INFO:root:current train perplexity4.906700134277344


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.50s/it]
INFO:root:final mean train loss: 2016.6516367517454
INFO:root:final train perplexity: 4.905969619750977
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.62s/it]
INFO:root:eval mean loss: 2828.7069462040167
INFO:root:eval perplexity: 10.187488555908203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/23

 23%|â–ˆâ–ˆâ–Ž       | 23/100 [3:26:07<11:20:05, 529.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2017.599372016059
INFO:root:current train perplexity4.842281818389893
INFO:root:current mean train loss 2001.9398694490133
INFO:root:current train perplexity4.815699577331543
INFO:root:current mean train loss 2004.3508742759968
INFO:root:current train perplexity4.835077285766602
INFO:root:current mean train loss 2009.9452423878206
INFO:root:current train perplexity4.851738452911377
INFO:root:current mean train loss 2000.974767069914
INFO:root:current train perplexity4.83604621887207
INFO:root:current mean train loss 2003.8685995845472
INFO:root:current train perplexity4.844789981842041
INFO:root:current mean train loss 2006.1402743574502
INFO:root:current train perplexity4.8530144691467285
INFO:root:current mean train loss 2007.670251155805
INFO:root:current train perplexity4.853107929229736
INFO:root:current mean train loss 2006.9825329727
INFO:root:current train perplexity4.854288101196289
INFO:root:current mean train loss 2008.8978410817156
INFO:root:current train perplexity4.86236572265625
INFO:root:current mean train loss 2006.9169356319883
INFO:root:current train perplexity4.862068176269531
INFO:root:current mean train loss 2005.2766147132681
INFO:root:current train perplexity4.853637218475342
INFO:root:current mean train loss 2004.3508949930354
INFO:root:current train perplexity4.849570274353027
INFO:root:current mean train loss 2004.0978999515232
INFO:root:current train perplexity4.852002143859863
INFO:root:current mean train loss 2004.716660221791
INFO:root:current train perplexity4.856006622314453
INFO:root:current mean train loss 2006.3615260478086
INFO:root:current train perplexity4.861306190490723
INFO:root:current mean train loss 2005.9330965843426
INFO:root:current train perplexity4.863574028015137
INFO:root:current mean train loss 2006.211726387919
INFO:root:current train perplexity4.864871025085449
INFO:root:current mean train loss 2006.750637930411
INFO:root:current train perplexity4.866459846496582


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.96s/it]
INFO:root:final mean train loss: 2006.3192944163575
INFO:root:final train perplexity: 4.86615514755249
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:10<00:00, 70.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:10<00:00, 70.10s/it]
INFO:root:eval mean loss: 2824.4827569268487
INFO:root:eval perplexity: 10.152235984802246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/24

 24%|â–ˆâ–ˆâ–       | 24/100 [3:35:08<11:15:11, 533.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1922.4053431919642
INFO:root:current train perplexity4.697913646697998
INFO:root:current mean train loss 1966.6333486966998
INFO:root:current train perplexity4.7526044845581055
INFO:root:current mean train loss 1979.3184678819443
INFO:root:current train perplexity4.783883094787598
INFO:root:current mean train loss 1985.356155842834
INFO:root:current train perplexity4.803741455078125
INFO:root:current mean train loss 1985.3203433924868
INFO:root:current train perplexity4.798670291900635
INFO:root:current mean train loss 1984.9412906804735
INFO:root:current train perplexity4.794357776641846
INFO:root:current mean train loss 1986.6590173963268
INFO:root:current train perplexity4.8029913902282715
INFO:root:current mean train loss 1990.1350838365784
INFO:root:current train perplexity4.813155651092529
INFO:root:current mean train loss 1989.4006563964238
INFO:root:current train perplexity4.811127185821533
INFO:root:current mean train loss 1990.7905799672253
INFO:root:current train perplexity4.814277648925781
INFO:root:current mean train loss 1991.025950669532
INFO:root:current train perplexity4.817856311798096
INFO:root:current mean train loss 1992.064174138649
INFO:root:current train perplexity4.817483901977539
INFO:root:current mean train loss 1995.13931630916
INFO:root:current train perplexity4.8270697593688965
INFO:root:current mean train loss 1994.650527452091
INFO:root:current train perplexity4.824767589569092
INFO:root:current mean train loss 1994.7734363721293
INFO:root:current train perplexity4.825285911560059
INFO:root:current mean train loss 1995.8044483005092
INFO:root:current train perplexity4.825828552246094
INFO:root:current mean train loss 1997.5312522788483
INFO:root:current train perplexity4.828052043914795
INFO:root:current mean train loss 1996.9255508396034
INFO:root:current train perplexity4.828650951385498
INFO:root:current mean train loss 1996.8845822830917
INFO:root:current train perplexity4.82883882522583
INFO:root:current mean train loss 1996.5449259717489
INFO:root:current train perplexity4.828202247619629


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.32s/it]
INFO:root:final mean train loss: 1996.01165746861
INFO:root:final train perplexity: 4.826757431030273
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:10<00:00, 70.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:10<00:00, 70.40s/it]
INFO:root:eval mean loss: 2827.832732146209
INFO:root:eval perplexity: 10.180187225341797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/25

 25%|â–ˆâ–ˆâ–Œ       | 25/100 [3:44:10<11:09:39, 535.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1965.6973876953125
INFO:root:current train perplexity4.736479759216309
INFO:root:current mean train loss 1961.4249986217867
INFO:root:current train perplexity4.778202056884766
INFO:root:current mean train loss 1972.6527028764997
INFO:root:current train perplexity4.787630558013916
INFO:root:current mean train loss 1978.5374529803241
INFO:root:current train perplexity4.773651599884033
INFO:root:current mean train loss 1977.9581143361218
INFO:root:current train perplexity4.771312713623047
INFO:root:current mean train loss 1979.5266229760555
INFO:root:current train perplexity4.770161151885986
INFO:root:current mean train loss 1983.423737941644
INFO:root:current train perplexity4.7808756828308105
INFO:root:current mean train loss 1985.9376222389178
INFO:root:current train perplexity4.789031505584717
INFO:root:current mean train loss 1986.8057320604046
INFO:root:current train perplexity4.788322448730469
INFO:root:current mean train loss 1985.667175160858
INFO:root:current train perplexity4.782453536987305
INFO:root:current mean train loss 1986.486020207405
INFO:root:current train perplexity4.789393424987793
INFO:root:current mean train loss 1987.1357030902468
INFO:root:current train perplexity4.786309719085693
INFO:root:current mean train loss 1986.06602886923
INFO:root:current train perplexity4.78209924697876
INFO:root:current mean train loss 1986.1516193493615
INFO:root:current train perplexity4.78492546081543
INFO:root:current mean train loss 1987.1057502660858
INFO:root:current train perplexity4.78680944442749
INFO:root:current mean train loss 1987.4078481278707
INFO:root:current train perplexity4.787599086761475
INFO:root:current mean train loss 1988.2570965395773
INFO:root:current train perplexity4.788821220397949
INFO:root:current mean train loss 1989.2291138686603
INFO:root:current train perplexity4.791670322418213
INFO:root:current mean train loss 1988.3176748041521
INFO:root:current train perplexity4.793230056762695
INFO:root:current mean train loss 1988.4412001135938
INFO:root:current train perplexity4.792758941650391


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.83s/it]
INFO:root:final mean train loss: 1986.8875688099824
INFO:root:final train perplexity: 4.792149543762207
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.27s/it]
INFO:root:eval mean loss: 2830.178083356794
INFO:root:eval perplexity: 10.199797630310059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/26

 26%|â–ˆâ–ˆâ–Œ       | 26/100 [3:53:01<10:59:05, 534.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1987.936240591654
INFO:root:current train perplexity4.7518768310546875
INFO:root:current mean train loss 1969.9316596714318
INFO:root:current train perplexity4.7433061599731445
INFO:root:current mean train loss 1971.8600537311981
INFO:root:current train perplexity4.754344463348389
INFO:root:current mean train loss 1981.2251262944465
INFO:root:current train perplexity4.764253616333008
INFO:root:current mean train loss 1975.1963859437003
INFO:root:current train perplexity4.761053085327148
INFO:root:current mean train loss 1977.6590831143137
INFO:root:current train perplexity4.763708591461182
INFO:root:current mean train loss 1977.834834106255
INFO:root:current train perplexity4.765584945678711
INFO:root:current mean train loss 1977.3736358107183
INFO:root:current train perplexity4.766427040100098
INFO:root:current mean train loss 1981.419928987301
INFO:root:current train perplexity4.773625373840332
INFO:root:current mean train loss 1979.6092098613094
INFO:root:current train perplexity4.766852855682373
INFO:root:current mean train loss 1977.5648585016286
INFO:root:current train perplexity4.762223243713379
INFO:root:current mean train loss 1978.6960159288385
INFO:root:current train perplexity4.759763240814209
INFO:root:current mean train loss 1978.4254171047164
INFO:root:current train perplexity4.756731033325195
INFO:root:current mean train loss 1978.636864032788
INFO:root:current train perplexity4.758304595947266
INFO:root:current mean train loss 1978.917182959425
INFO:root:current train perplexity4.760366916656494
INFO:root:current mean train loss 1978.6414866215373
INFO:root:current train perplexity4.760396480560303
INFO:root:current mean train loss 1977.9376008698011
INFO:root:current train perplexity4.7585906982421875
INFO:root:current mean train loss 1978.0014275425401
INFO:root:current train perplexity4.75852632522583
INFO:root:current mean train loss 1978.0059905293065
INFO:root:current train perplexity4.757325649261475
INFO:root:current mean train loss 1977.9449304406758
INFO:root:current train perplexity4.756955146789551


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.68s/it]
INFO:root:final mean train loss: 1977.6754048511468
INFO:root:final train perplexity: 4.7574591636657715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.13s/it]
INFO:root:eval mean loss: 2824.909154027074
INFO:root:eval perplexity: 10.155789375305176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/27

 27%|â–ˆâ–ˆâ–‹       | 27/100 [4:01:54<10:49:43, 534.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1984.652366901266
INFO:root:current train perplexity4.699254989624023
INFO:root:current mean train loss 1962.6243881032437
INFO:root:current train perplexity4.683664321899414
INFO:root:current mean train loss 1953.4959366672722
INFO:root:current train perplexity4.697270393371582
INFO:root:current mean train loss 1954.0304115338033
INFO:root:current train perplexity4.694854736328125
INFO:root:current mean train loss 1957.978280013305
INFO:root:current train perplexity4.706654071807861
INFO:root:current mean train loss 1963.729758204525
INFO:root:current train perplexity4.716193199157715
INFO:root:current mean train loss 1966.0632277839452
INFO:root:current train perplexity4.721096038818359
INFO:root:current mean train loss 1967.3236407680058
INFO:root:current train perplexity4.723130226135254
INFO:root:current mean train loss 1968.0246065579927
INFO:root:current train perplexity4.726059913635254
INFO:root:current mean train loss 1967.6413352504403
INFO:root:current train perplexity4.723294258117676
INFO:root:current mean train loss 1966.7528644987226
INFO:root:current train perplexity4.721118450164795
INFO:root:current mean train loss 1967.9588397459252
INFO:root:current train perplexity4.721695899963379
INFO:root:current mean train loss 1969.2552174869895
INFO:root:current train perplexity4.723512649536133
INFO:root:current mean train loss 1969.0242050687764
INFO:root:current train perplexity4.721439838409424
INFO:root:current mean train loss 1969.278975121769
INFO:root:current train perplexity4.722644329071045
INFO:root:current mean train loss 1970.1539312125171
INFO:root:current train perplexity4.724939823150635
INFO:root:current mean train loss 1969.8023445304254
INFO:root:current train perplexity4.723905563354492
INFO:root:current mean train loss 1969.0499731417538
INFO:root:current train perplexity4.721635341644287
INFO:root:current mean train loss 1969.7257947316082
INFO:root:current train perplexity4.725971698760986
INFO:root:current mean train loss 1969.9460718546509
INFO:root:current train perplexity4.7264084815979


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.55s/it]
INFO:root:final mean train loss: 1969.761073002356
INFO:root:final train perplexity: 4.7278571128845215
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.65s/it]
INFO:root:eval mean loss: 2826.992677980715
INFO:root:eval perplexity: 10.17317008972168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/28

 28%|â–ˆâ–ˆâ–Š       | 28/100 [4:10:44<10:39:30, 532.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1982.3213932291667
INFO:root:current train perplexity4.737812519073486
INFO:root:current mean train loss 1970.6890611049107
INFO:root:current train perplexity4.694283485412598
INFO:root:current mean train loss 1965.4187349076703
INFO:root:current train perplexity4.6928181648254395
INFO:root:current mean train loss 1966.1877679036459
INFO:root:current train perplexity4.701478004455566
INFO:root:current mean train loss 1966.1964142166942
INFO:root:current train perplexity4.704984664916992
INFO:root:current mean train loss 1961.7769223420516
INFO:root:current train perplexity4.693824768066406
INFO:root:current mean train loss 1960.6205441623265
INFO:root:current train perplexity4.691497802734375
INFO:root:current mean train loss 1963.9413388356854
INFO:root:current train perplexity4.698213577270508
INFO:root:current mean train loss 1964.3545006975446
INFO:root:current train perplexity4.697659015655518
INFO:root:current mean train loss 1965.3344089292868
INFO:root:current train perplexity4.696899890899658
INFO:root:current mean train loss 1966.1922783430232
INFO:root:current train perplexity4.6985907554626465
INFO:root:current mean train loss 1964.2781475440493
INFO:root:current train perplexity4.69817590713501
INFO:root:current mean train loss 1962.5897456150428
INFO:root:current train perplexity4.695766448974609
INFO:root:current mean train loss 1961.7664041193182
INFO:root:current train perplexity4.69791316986084
INFO:root:current mean train loss 1961.76647551973
INFO:root:current train perplexity4.6963019371032715
INFO:root:current mean train loss 1963.3321846323165
INFO:root:current train perplexity4.698385238647461
INFO:root:current mean train loss 1963.5281252186335
INFO:root:current train perplexity4.699323654174805
INFO:root:current mean train loss 1962.9158084837147
INFO:root:current train perplexity4.699123859405518
INFO:root:current mean train loss 1962.9322400390624
INFO:root:current train perplexity4.699932098388672
INFO:root:current mean train loss 1962.3547289111946
INFO:root:current train perplexity4.698949337005615


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.22s/it]
INFO:root:final mean train loss: 1961.9655849747267
INFO:root:final train perplexity: 4.698880195617676
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.58s/it]
INFO:root:eval mean loss: 2826.1890674854544
INFO:root:eval perplexity: 10.166460990905762
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/29

 29%|â–ˆâ–ˆâ–‰       | 29/100 [4:19:39<10:31:22, 533.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1949.9342359459918
INFO:root:current train perplexity4.647737979888916
INFO:root:current mean train loss 1948.627196629842
INFO:root:current train perplexity4.6563496589660645
INFO:root:current mean train loss 1955.366458004468
INFO:root:current train perplexity4.655673980712891
INFO:root:current mean train loss 1956.335455758231
INFO:root:current train perplexity4.657797813415527
INFO:root:current mean train loss 1964.132337616711
INFO:root:current train perplexity4.670081615447998
INFO:root:current mean train loss 1963.6185911023938
INFO:root:current train perplexity4.675129413604736
INFO:root:current mean train loss 1962.7506144088127
INFO:root:current train perplexity4.66811466217041
INFO:root:current mean train loss 1960.450060911853
INFO:root:current train perplexity4.666632175445557
INFO:root:current mean train loss 1961.5549621582031
INFO:root:current train perplexity4.667181491851807
INFO:root:current mean train loss 1960.8343101009245
INFO:root:current train perplexity4.668107509613037
INFO:root:current mean train loss 1959.2908386677614
INFO:root:current train perplexity4.66363000869751
INFO:root:current mean train loss 1958.4995678383232
INFO:root:current train perplexity4.6642327308654785
INFO:root:current mean train loss 1957.8807658381506
INFO:root:current train perplexity4.663714408874512
INFO:root:current mean train loss 1957.4017197181438
INFO:root:current train perplexity4.666055202484131
INFO:root:current mean train loss 1958.5888643239202
INFO:root:current train perplexity4.669119358062744
INFO:root:current mean train loss 1957.7258909599266
INFO:root:current train perplexity4.668057441711426
INFO:root:current mean train loss 1956.6197066791797
INFO:root:current train perplexity4.667183876037598
INFO:root:current mean train loss 1954.7889147486005
INFO:root:current train perplexity4.668107032775879
INFO:root:current mean train loss 1954.7379286526123
INFO:root:current train perplexity4.670137882232666


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.56s/it]
INFO:root:final mean train loss: 1954.2128633546276
INFO:root:final train perplexity: 4.670237064361572
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.97s/it]
INFO:root:eval mean loss: 2823.71253064588
INFO:root:eval perplexity: 10.145820617675781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/30

 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [4:28:26<10:20:05, 531.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1900.4782850477432
INFO:root:current train perplexity4.683231830596924
INFO:root:current mean train loss 1933.22422076584
INFO:root:current train perplexity4.637996673583984
INFO:root:current mean train loss 1941.7159044183613
INFO:root:current train perplexity4.635136127471924
INFO:root:current mean train loss 1943.3827686494994
INFO:root:current train perplexity4.646752834320068
INFO:root:current mean train loss 1947.1758376590196
INFO:root:current train perplexity4.640007972717285
INFO:root:current mean train loss 1942.1477480065846
INFO:root:current train perplexity4.6230950355529785
INFO:root:current mean train loss 1942.689666597714
INFO:root:current train perplexity4.623095989227295
INFO:root:current mean train loss 1941.732202871562
INFO:root:current train perplexity4.623445987701416
INFO:root:current mean train loss 1943.4575658545948
INFO:root:current train perplexity4.624954700469971
INFO:root:current mean train loss 1944.0869358176053
INFO:root:current train perplexity4.628249168395996
INFO:root:current mean train loss 1945.4741158915465
INFO:root:current train perplexity4.631546974182129
INFO:root:current mean train loss 1945.5600860017823
INFO:root:current train perplexity4.633376598358154
INFO:root:current mean train loss 1946.1621572338322
INFO:root:current train perplexity4.6378631591796875
INFO:root:current mean train loss 1946.7681341091125
INFO:root:current train perplexity4.638791084289551
INFO:root:current mean train loss 1947.4255277526725
INFO:root:current train perplexity4.638644218444824
INFO:root:current mean train loss 1947.1415775367327
INFO:root:current train perplexity4.639367580413818
INFO:root:current mean train loss 1947.126854042447
INFO:root:current train perplexity4.6392107009887695
INFO:root:current mean train loss 1947.060773515785
INFO:root:current train perplexity4.641085147857666
INFO:root:current mean train loss 1946.7427785524417
INFO:root:current train perplexity4.641163349151611
INFO:root:current mean train loss 1946.579810005136
INFO:root:current train perplexity4.641076564788818


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.06s/it]
INFO:root:final mean train loss: 1946.281148490194
INFO:root:final train perplexity: 4.64111328125
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.41s/it]
INFO:root:eval mean loss: 2822.911821978228
INFO:root:eval perplexity: 10.139159202575684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/31
##############best##############
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [4:37:15<10:10:16, 530.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1932.3134390024038
INFO:root:current train perplexity4.608452320098877
INFO:root:current mean train loss 1933.076659187438
INFO:root:current train perplexity4.5891194343566895
INFO:root:current mean train loss 1934.971284849454
INFO:root:current train perplexity4.587543964385986
INFO:root:current mean train loss 1926.3237270987106
INFO:root:current train perplexity4.565068244934082
INFO:root:current mean train loss 1925.723624215999
INFO:root:current train perplexity4.564659595489502
INFO:root:current mean train loss 1928.612284729236
INFO:root:current train perplexity4.572728633880615
INFO:root:current mean train loss 1930.4408153984875
INFO:root:current train perplexity4.57951021194458
INFO:root:current mean train loss 1933.803838724604
INFO:root:current train perplexity4.584465503692627
INFO:root:current mean train loss 1937.6197961987364
INFO:root:current train perplexity4.592254638671875
INFO:root:current mean train loss 1935.736507275707
INFO:root:current train perplexity4.59100866317749
INFO:root:current mean train loss 1935.626782750061
INFO:root:current train perplexity4.595371246337891
INFO:root:current mean train loss 1937.8436975292796
INFO:root:current train perplexity4.603991508483887
INFO:root:current mean train loss 1937.9380946198257
INFO:root:current train perplexity4.606451988220215
INFO:root:current mean train loss 1938.7186960533913
INFO:root:current train perplexity4.606302261352539
INFO:root:current mean train loss 1937.9979782211497
INFO:root:current train perplexity4.608520984649658
INFO:root:current mean train loss 1936.7248283176248
INFO:root:current train perplexity4.608570098876953
INFO:root:current mean train loss 1938.0609411636108
INFO:root:current train perplexity4.611669063568115
INFO:root:current mean train loss 1938.8577812256708
INFO:root:current train perplexity4.613831043243408
INFO:root:current mean train loss 1938.5810996115142
INFO:root:current train perplexity4.612491607666016
INFO:root:current mean train loss 1938.8882470373549
INFO:root:current train perplexity4.614842414855957


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.23s/it]
INFO:root:final mean train loss: 1939.1304842996526
INFO:root:final train perplexity: 4.61501407623291
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.79s/it]
INFO:root:eval mean loss: 2824.1992297473253
INFO:root:eval perplexity: 10.14987850189209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/32

 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [4:46:02<10:00:14, 529.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1911.1205089480377
INFO:root:current train perplexity4.4844465255737305
INFO:root:current mean train loss 1928.1998410525023
INFO:root:current train perplexity4.5352606773376465
INFO:root:current mean train loss 1935.0766923064557
INFO:root:current train perplexity4.564907073974609
INFO:root:current mean train loss 1935.269068236949
INFO:root:current train perplexity4.575533866882324
INFO:root:current mean train loss 1930.6221345165245
INFO:root:current train perplexity4.57174015045166
INFO:root:current mean train loss 1927.2572502571795
INFO:root:current train perplexity4.568990707397461
INFO:root:current mean train loss 1924.8604354739746
INFO:root:current train perplexity4.571786880493164
INFO:root:current mean train loss 1926.1357665029861
INFO:root:current train perplexity4.575125217437744
INFO:root:current mean train loss 1926.6452599069544
INFO:root:current train perplexity4.578078746795654
INFO:root:current mean train loss 1929.9245782813744
INFO:root:current train perplexity4.583209037780762
INFO:root:current mean train loss 1930.5108093671352
INFO:root:current train perplexity4.58571720123291
INFO:root:current mean train loss 1930.7561021272488
INFO:root:current train perplexity4.586584091186523
INFO:root:current mean train loss 1932.2125897211886
INFO:root:current train perplexity4.587831020355225
INFO:root:current mean train loss 1932.696167173975
INFO:root:current train perplexity4.587611198425293
INFO:root:current mean train loss 1932.8585510465393
INFO:root:current train perplexity4.588525295257568
INFO:root:current mean train loss 1933.9495674771144
INFO:root:current train perplexity4.589145183563232
INFO:root:current mean train loss 1934.5161921105876
INFO:root:current train perplexity4.589508056640625
INFO:root:current mean train loss 1933.8614235821635
INFO:root:current train perplexity4.590220928192139
INFO:root:current mean train loss 1933.4497963154504
INFO:root:current train perplexity4.592445373535156
INFO:root:current mean train loss 1933.6574939486297
INFO:root:current train perplexity4.59294319152832


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.09s/it]
INFO:root:final mean train loss: 1932.7161743964323
INFO:root:final train perplexity: 4.591727256774902
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.36s/it]
INFO:root:eval mean loss: 2825.8333369991083
INFO:root:eval perplexity: 10.163495063781738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/33

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [4:54:52<9:51:25, 529.64s/it] 

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1897.6278137207032
INFO:root:current train perplexity4.499672889709473
INFO:root:current mean train loss 1905.8899528503418
INFO:root:current train perplexity4.537271499633789
INFO:root:current mean train loss 1909.0645427997297
INFO:root:current train perplexity4.5459160804748535
INFO:root:current mean train loss 1911.4220106336807
INFO:root:current train perplexity4.549380302429199
INFO:root:current mean train loss 1910.9422936480978
INFO:root:current train perplexity4.5525970458984375
INFO:root:current mean train loss 1913.057612173898
INFO:root:current train perplexity4.549380302429199
INFO:root:current mean train loss 1915.5150884454902
INFO:root:current train perplexity4.5547709465026855
INFO:root:current mean train loss 1918.2071430407073
INFO:root:current train perplexity4.553865909576416
INFO:root:current mean train loss 1921.5059631347656
INFO:root:current train perplexity4.557011604309082
INFO:root:current mean train loss 1922.2548234303792
INFO:root:current train perplexity4.55307674407959
INFO:root:current mean train loss 1921.9884676951283
INFO:root:current train perplexity4.552486419677734
INFO:root:current mean train loss 1921.120271774818
INFO:root:current train perplexity4.551657199859619
INFO:root:current mean train loss 1921.74289773608
INFO:root:current train perplexity4.553928852081299
INFO:root:current mean train loss 1921.1827787511488
INFO:root:current train perplexity4.553534030914307
INFO:root:current mean train loss 1921.0898402383882
INFO:root:current train perplexity4.55264139175415
INFO:root:current mean train loss 1920.866065626878
INFO:root:current train perplexity4.554042339324951
INFO:root:current mean train loss 1921.3755707154792
INFO:root:current train perplexity4.555157661437988
INFO:root:current mean train loss 1923.4468123696067
INFO:root:current train perplexity4.558443546295166
INFO:root:current mean train loss 1924.7544497910367
INFO:root:current train perplexity4.562090873718262
INFO:root:current mean train loss 1926.1758561737684
INFO:root:current train perplexity4.566396713256836


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.41s/it]
INFO:root:final mean train loss: 1925.293909362393
INFO:root:final train perplexity: 4.564927577972412
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.45s/it]
INFO:root:eval mean loss: 2826.267991624437
INFO:root:eval perplexity: 10.167120933532715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/34

 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [5:03:42<9:42:43, 529.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1936.8662759359781
INFO:root:current train perplexity4.516195774078369
INFO:root:current mean train loss 1931.0554716465838
INFO:root:current train perplexity4.535099029541016
INFO:root:current mean train loss 1919.658536284409
INFO:root:current train perplexity4.521773815155029
INFO:root:current mean train loss 1917.6737102640086
INFO:root:current train perplexity4.524453639984131
INFO:root:current mean train loss 1914.768280093275
INFO:root:current train perplexity4.528594970703125
INFO:root:current mean train loss 1916.3766070122942
INFO:root:current train perplexity4.532108783721924
INFO:root:current mean train loss 1915.3577668092803
INFO:root:current train perplexity4.5284423828125
INFO:root:current mean train loss 1916.1758877669522
INFO:root:current train perplexity4.52486515045166
INFO:root:current mean train loss 1915.3168435874252
INFO:root:current train perplexity4.523789882659912
INFO:root:current mean train loss 1916.1222860908313
INFO:root:current train perplexity4.527338981628418
INFO:root:current mean train loss 1916.396089148278
INFO:root:current train perplexity4.529568672180176
INFO:root:current mean train loss 1917.6780007102273
INFO:root:current train perplexity4.532784461975098
INFO:root:current mean train loss 1918.8239583588245
INFO:root:current train perplexity4.5373382568359375
INFO:root:current mean train loss 1919.0070686423442
INFO:root:current train perplexity4.5379838943481445
INFO:root:current mean train loss 1918.2665154438369
INFO:root:current train perplexity4.537515163421631
INFO:root:current mean train loss 1918.1607107913562
INFO:root:current train perplexity4.536672592163086
INFO:root:current mean train loss 1919.1261144284342
INFO:root:current train perplexity4.539167881011963
INFO:root:current mean train loss 1919.560156071394
INFO:root:current train perplexity4.5409955978393555
INFO:root:current mean train loss 1920.0263469616784
INFO:root:current train perplexity4.543282508850098
INFO:root:current mean train loss 1919.5040577110403
INFO:root:current train perplexity4.542538642883301


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.46s/it]
INFO:root:final mean train loss: 1918.9808249884763
INFO:root:final train perplexity: 4.54225492477417
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.76s/it]
INFO:root:eval mean loss: 2826.0090412678305
INFO:root:eval perplexity: 10.164960861206055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/35

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [5:12:34<9:34:46, 530.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1934.701054999169
INFO:root:current train perplexity4.560121536254883
INFO:root:current mean train loss 1920.2307783303802
INFO:root:current train perplexity4.525987148284912
INFO:root:current mean train loss 1918.7688195883823
INFO:root:current train perplexity4.515130996704102
INFO:root:current mean train loss 1914.9321948985762
INFO:root:current train perplexity4.506734848022461
INFO:root:current mean train loss 1913.0134746844951
INFO:root:current train perplexity4.513427257537842
INFO:root:current mean train loss 1913.9094458172217
INFO:root:current train perplexity4.512914657592773
INFO:root:current mean train loss 1913.433707377409
INFO:root:current train perplexity4.517033100128174
INFO:root:current mean train loss 1913.9200774608391
INFO:root:current train perplexity4.51375675201416
INFO:root:current mean train loss 1913.9390941508932
INFO:root:current train perplexity4.517081260681152
INFO:root:current mean train loss 1912.2809768768864
INFO:root:current train perplexity4.514636993408203
INFO:root:current mean train loss 1914.0051142328182
INFO:root:current train perplexity4.517168045043945
INFO:root:current mean train loss 1914.7918039702092
INFO:root:current train perplexity4.51600456237793
INFO:root:current mean train loss 1914.5546630670704
INFO:root:current train perplexity4.5202155113220215
INFO:root:current mean train loss 1914.6954259010436
INFO:root:current train perplexity4.5198655128479
INFO:root:current mean train loss 1914.7006028671979
INFO:root:current train perplexity4.519216537475586
INFO:root:current mean train loss 1913.138509523016
INFO:root:current train perplexity4.516508102416992
INFO:root:current mean train loss 1912.748416256595
INFO:root:current train perplexity4.516485214233398
INFO:root:current mean train loss 1913.4357703303547
INFO:root:current train perplexity4.518415927886963
INFO:root:current mean train loss 1913.4526086180867
INFO:root:current train perplexity4.51993989944458


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.30s/it]
INFO:root:final mean train loss: 1912.783824126166
INFO:root:final train perplexity: 4.520110130310059
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.30s/it]
INFO:root:eval mean loss: 2830.731396924268
INFO:root:eval perplexity: 10.204428672790527
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/36

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [5:21:27<9:26:37, 531.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1932.1565940163352
INFO:root:current train perplexity4.587549686431885
INFO:root:current mean train loss 1891.2367867134712
INFO:root:current train perplexity4.486427307128906
INFO:root:current mean train loss 1885.40238424726
INFO:root:current train perplexity4.455289840698242
INFO:root:current mean train loss 1891.8726441607214
INFO:root:current train perplexity4.469188690185547
INFO:root:current mean train loss 1895.1677727246806
INFO:root:current train perplexity4.462547302246094
INFO:root:current mean train loss 1897.9599014550972
INFO:root:current train perplexity4.473158359527588
INFO:root:current mean train loss 1901.4403771433228
INFO:root:current train perplexity4.481793403625488
INFO:root:current mean train loss 1901.6890093109946
INFO:root:current train perplexity4.480783462524414
INFO:root:current mean train loss 1899.8429119143034
INFO:root:current train perplexity4.481183052062988
INFO:root:current mean train loss 1899.443817105173
INFO:root:current train perplexity4.484456539154053
INFO:root:current mean train loss 1899.8822927050492
INFO:root:current train perplexity4.485512733459473
INFO:root:current mean train loss 1899.9794227469622
INFO:root:current train perplexity4.487024784088135
INFO:root:current mean train loss 1901.694508005232
INFO:root:current train perplexity4.488555431365967
INFO:root:current mean train loss 1901.1014784195331
INFO:root:current train perplexity4.4884233474731445
INFO:root:current mean train loss 1904.1922736326742
INFO:root:current train perplexity4.490363597869873
INFO:root:current mean train loss 1904.3528998606573
INFO:root:current train perplexity4.492728233337402
INFO:root:current mean train loss 1905.3803750339464
INFO:root:current train perplexity4.494863033294678
INFO:root:current mean train loss 1906.3403848974694
INFO:root:current train perplexity4.494814395904541
INFO:root:current mean train loss 1906.4668553150668
INFO:root:current train perplexity4.495997905731201
INFO:root:current mean train loss 1906.3290804189764
INFO:root:current train perplexity4.496065139770508


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.27s/it]
INFO:root:final mean train loss: 1906.7523490070876
INFO:root:final train perplexity: 4.498659610748291
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.59s/it]
INFO:root:eval mean loss: 2826.0504498639266
INFO:root:eval perplexity: 10.16530704498291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/37

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [5:30:17<9:17:25, 530.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1883.5814165387835
INFO:root:current train perplexity4.407474517822266
INFO:root:current mean train loss 1892.7969417572021
INFO:root:current train perplexity4.4493608474731445
INFO:root:current mean train loss 1891.810307017544
INFO:root:current train perplexity4.438604831695557
INFO:root:current mean train loss 1884.8369211336462
INFO:root:current train perplexity4.431036949157715
INFO:root:current mean train loss 1884.6881491402598
INFO:root:current train perplexity4.436698913574219
INFO:root:current mean train loss 1887.6687363133285
INFO:root:current train perplexity4.446467399597168
INFO:root:current mean train loss 1889.2868796184564
INFO:root:current train perplexity4.449766159057617
INFO:root:current mean train loss 1888.781493134551
INFO:root:current train perplexity4.45194673538208
INFO:root:current mean train loss 1889.4346561155457
INFO:root:current train perplexity4.45686674118042
INFO:root:current mean train loss 1889.7951190553863
INFO:root:current train perplexity4.458572864532471
INFO:root:current mean train loss 1891.943519087617
INFO:root:current train perplexity4.4597697257995605
INFO:root:current mean train loss 1893.0731182774753
INFO:root:current train perplexity4.459188461303711
INFO:root:current mean train loss 1892.7693006285626
INFO:root:current train perplexity4.461287021636963
INFO:root:current mean train loss 1893.9361061188113
INFO:root:current train perplexity4.462508201599121
INFO:root:current mean train loss 1893.1959529417236
INFO:root:current train perplexity4.461395740509033
INFO:root:current mean train loss 1895.3274379550473
INFO:root:current train perplexity4.465406894683838
INFO:root:current mean train loss 1898.1621425169399
INFO:root:current train perplexity4.470274925231934
INFO:root:current mean train loss 1899.8220411936443
INFO:root:current train perplexity4.4721598625183105
INFO:root:current mean train loss 1900.6789933419593
INFO:root:current train perplexity4.474635124206543
INFO:root:current mean train loss 1900.586066534905
INFO:root:current train perplexity4.474515914916992


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.30s/it]
INFO:root:final mean train loss: 1899.986021133246
INFO:root:final train perplexity: 4.474717617034912
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:10<00:00, 70.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:10<00:00, 70.20s/it]
INFO:root:eval mean loss: 2832.097457564987
INFO:root:eval perplexity: 10.215872764587402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/38

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [5:39:18<9:11:36, 533.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1873.356751844618
INFO:root:current train perplexity4.428920269012451
INFO:root:current mean train loss 1891.7558315934807
INFO:root:current train perplexity4.424890518188477
INFO:root:current mean train loss 1895.72504035794
INFO:root:current train perplexity4.43686580657959
INFO:root:current mean train loss 1890.0829950747282
INFO:root:current train perplexity4.43473482131958
INFO:root:current mean train loss 1891.3948670119382
INFO:root:current train perplexity4.436038970947266
INFO:root:current mean train loss 1889.7687441764622
INFO:root:current train perplexity4.434067249298096
INFO:root:current mean train loss 1890.1772398482922
INFO:root:current train perplexity4.431963920593262
INFO:root:current mean train loss 1888.4319548946098
INFO:root:current train perplexity4.427944183349609
INFO:root:current mean train loss 1890.0910185142382
INFO:root:current train perplexity4.42997407913208
INFO:root:current mean train loss 1890.0077555338542
INFO:root:current train perplexity4.4295549392700195
INFO:root:current mean train loss 1890.706500682192
INFO:root:current train perplexity4.433915138244629
INFO:root:current mean train loss 1892.2644358539164
INFO:root:current train perplexity4.438631534576416
INFO:root:current mean train loss 1892.703117058076
INFO:root:current train perplexity4.440940856933594
INFO:root:current mean train loss 1891.3897263991346
INFO:root:current train perplexity4.443426132202148
INFO:root:current mean train loss 1892.8304930795848
INFO:root:current train perplexity4.444340229034424
INFO:root:current mean train loss 1892.983985323119
INFO:root:current train perplexity4.444736957550049
INFO:root:current mean train loss 1893.3501607320954
INFO:root:current train perplexity4.445773601531982
INFO:root:current mean train loss 1894.2239890199678
INFO:root:current train perplexity4.448368549346924
INFO:root:current mean train loss 1894.433619222667
INFO:root:current train perplexity4.4501447677612305
INFO:root:current mean train loss 1894.38722090145
INFO:root:current train perplexity4.451478481292725


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.84s/it]
INFO:root:final mean train loss: 1893.9136183561247
INFO:root:final train perplexity: 4.453339099884033
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.91s/it]
INFO:root:eval mean loss: 2829.7833849474473
INFO:root:eval perplexity: 10.196493148803711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/39

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [5:48:09<9:01:49, 532.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1875.4737233807964
INFO:root:current train perplexity4.402831554412842
INFO:root:current mean train loss 1877.878682454427
INFO:root:current train perplexity4.400920391082764
INFO:root:current mean train loss 1884.4466781033814
INFO:root:current train perplexity4.403715133666992
INFO:root:current mean train loss 1884.2652129283927
INFO:root:current train perplexity4.405445575714111
INFO:root:current mean train loss 1880.5782465418695
INFO:root:current train perplexity4.408206462860107
INFO:root:current mean train loss 1882.9675095310415
INFO:root:current train perplexity4.42027473449707
INFO:root:current mean train loss 1883.144711589525
INFO:root:current train perplexity4.42274808883667
INFO:root:current mean train loss 1883.0945742149054
INFO:root:current train perplexity4.422088146209717
INFO:root:current mean train loss 1885.3532291421204
INFO:root:current train perplexity4.427929401397705
INFO:root:current mean train loss 1884.73403898941
INFO:root:current train perplexity4.428077220916748
INFO:root:current mean train loss 1886.043367490032
INFO:root:current train perplexity4.426318645477295
INFO:root:current mean train loss 1886.1755433074372
INFO:root:current train perplexity4.423895359039307
INFO:root:current mean train loss 1885.2281338409086
INFO:root:current train perplexity4.422779560089111
INFO:root:current mean train loss 1886.4538696109812
INFO:root:current train perplexity4.426756858825684
INFO:root:current mean train loss 1885.8995877329855
INFO:root:current train perplexity4.428411960601807
INFO:root:current mean train loss 1886.9471362085867
INFO:root:current train perplexity4.430017948150635
INFO:root:current mean train loss 1888.1035105570988
INFO:root:current train perplexity4.431631565093994
INFO:root:current mean train loss 1888.4773439024148
INFO:root:current train perplexity4.433320045471191
INFO:root:current mean train loss 1888.9805918692518
INFO:root:current train perplexity4.433592319488525
INFO:root:current mean train loss 1889.266475199195
INFO:root:current train perplexity4.433947563171387


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.34s/it]
INFO:root:final mean train loss: 1888.67921116108
INFO:root:final train perplexity: 4.434992790222168
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.57s/it]
INFO:root:eval mean loss: 2829.718571110173
INFO:root:eval perplexity: 10.195948600769043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/40

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [5:57:02<8:52:59, 533.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1878.8026293018197
INFO:root:current train perplexity4.412786960601807
INFO:root:current mean train loss 1885.0844862953911
INFO:root:current train perplexity4.40890645980835
INFO:root:current mean train loss 1881.4512738190244
INFO:root:current train perplexity4.406671047210693
INFO:root:current mean train loss 1881.475877746743
INFO:root:current train perplexity4.412224292755127
INFO:root:current mean train loss 1880.4355150194904
INFO:root:current train perplexity4.413282871246338
INFO:root:current mean train loss 1882.4563907498111
INFO:root:current train perplexity4.406381607055664
INFO:root:current mean train loss 1882.6094693842622
INFO:root:current train perplexity4.405693531036377
INFO:root:current mean train loss 1884.3419297577022
INFO:root:current train perplexity4.410609245300293
INFO:root:current mean train loss 1883.4798954778157
INFO:root:current train perplexity4.410671234130859
INFO:root:current mean train loss 1884.2214141004054
INFO:root:current train perplexity4.412136077880859
INFO:root:current mean train loss 1884.2727205773213
INFO:root:current train perplexity4.410910606384277
INFO:root:current mean train loss 1884.1500773215516
INFO:root:current train perplexity4.41418981552124
INFO:root:current mean train loss 1885.1914868984863
INFO:root:current train perplexity4.41361141204834
INFO:root:current mean train loss 1886.2921999460377
INFO:root:current train perplexity4.418530464172363
INFO:root:current mean train loss 1886.5674149188906
INFO:root:current train perplexity4.418951034545898
INFO:root:current mean train loss 1885.4450435433077
INFO:root:current train perplexity4.418868064880371
INFO:root:current mean train loss 1884.5660041231993
INFO:root:current train perplexity4.415348052978516
INFO:root:current mean train loss 1883.4310989594312
INFO:root:current train perplexity4.4144463539123535
INFO:root:current mean train loss 1883.0410908551341
INFO:root:current train perplexity4.414732456207275
INFO:root:current mean train loss 1883.2342979581504
INFO:root:current train perplexity4.414175987243652


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:57<00:00, 477.39s/it]
INFO:root:final mean train loss: 1882.6690720920303
INFO:root:final train perplexity: 4.414021015167236
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.51s/it]
INFO:root:eval mean loss: 2831.3188322599945
INFO:root:eval perplexity: 10.20934772491455
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/41

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [6:06:00<8:45:37, 534.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1861.693795522054
INFO:root:current train perplexity4.353499412536621
INFO:root:current mean train loss 1861.717729218152
INFO:root:current train perplexity4.3536200523376465
INFO:root:current mean train loss 1867.6443254625476
INFO:root:current train perplexity4.370296955108643
INFO:root:current mean train loss 1869.3090163722184
INFO:root:current train perplexity4.37193489074707
INFO:root:current mean train loss 1868.2970034691596
INFO:root:current train perplexity4.376795768737793
INFO:root:current mean train loss 1871.0765800732095
INFO:root:current train perplexity4.371562480926514
INFO:root:current mean train loss 1868.053188104739
INFO:root:current train perplexity4.368271350860596
INFO:root:current mean train loss 1869.2251097712685
INFO:root:current train perplexity4.3718791007995605
INFO:root:current mean train loss 1870.7089933667864
INFO:root:current train perplexity4.3746843338012695
INFO:root:current mean train loss 1870.9350020933343
INFO:root:current train perplexity4.377363204956055
INFO:root:current mean train loss 1871.4409057171677
INFO:root:current train perplexity4.374199390411377
INFO:root:current mean train loss 1872.6974556709213
INFO:root:current train perplexity4.37679386138916
INFO:root:current mean train loss 1874.3852772653838
INFO:root:current train perplexity4.379796028137207
INFO:root:current mean train loss 1874.5667276901638
INFO:root:current train perplexity4.383126258850098
INFO:root:current mean train loss 1875.4841766357422
INFO:root:current train perplexity4.386709213256836
INFO:root:current mean train loss 1877.9016077333226
INFO:root:current train perplexity4.39066219329834
INFO:root:current mean train loss 1878.1459014460725
INFO:root:current train perplexity4.392512798309326
INFO:root:current mean train loss 1877.9420045712477
INFO:root:current train perplexity4.3932671546936035
INFO:root:current mean train loss 1878.3661893691694
INFO:root:current train perplexity4.394966125488281


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.94s/it]
INFO:root:final mean train loss: 1877.5420615638197
INFO:root:final train perplexity: 4.396208763122559
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:10<00:00, 70.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:10<00:00, 70.98s/it]
INFO:root:eval mean loss: 2830.6498950121995
INFO:root:eval perplexity: 10.203742980957031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/42

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [6:15:03<8:39:11, 537.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1875.9056020883413
INFO:root:current train perplexity4.438696384429932
INFO:root:current mean train loss 1855.2131315248203
INFO:root:current train perplexity4.378453254699707
INFO:root:current mean train loss 1855.2302309134757
INFO:root:current train perplexity4.367040634155273
INFO:root:current mean train loss 1860.2686049976287
INFO:root:current train perplexity4.355087757110596
INFO:root:current mean train loss 1859.6390295144142
INFO:root:current train perplexity4.354945659637451
INFO:root:current mean train loss 1862.9591745001067
INFO:root:current train perplexity4.353150367736816
INFO:root:current mean train loss 1864.6255768967296
INFO:root:current train perplexity4.361995220184326
INFO:root:current mean train loss 1867.6419778746274
INFO:root:current train perplexity4.361740589141846
INFO:root:current mean train loss 1867.3176539797626
INFO:root:current train perplexity4.365539073944092
INFO:root:current mean train loss 1869.1318870118257
INFO:root:current train perplexity4.364716053009033
INFO:root:current mean train loss 1870.485264317775
INFO:root:current train perplexity4.366751194000244
INFO:root:current mean train loss 1870.5838733820474
INFO:root:current train perplexity4.369228839874268
INFO:root:current mean train loss 1870.9550750053136
INFO:root:current train perplexity4.372283458709717
INFO:root:current mean train loss 1870.9365179522385
INFO:root:current train perplexity4.3716888427734375
INFO:root:current mean train loss 1872.5141624888038
INFO:root:current train perplexity4.374576091766357
INFO:root:current mean train loss 1872.6029565058554
INFO:root:current train perplexity4.3762125968933105
INFO:root:current mean train loss 1871.293213041983
INFO:root:current train perplexity4.372180461883545
INFO:root:current mean train loss 1871.9549002572242
INFO:root:current train perplexity4.374894618988037
INFO:root:current mean train loss 1871.4099897415153
INFO:root:current train perplexity4.373928546905518
INFO:root:current mean train loss 1872.3485293749795
INFO:root:current train perplexity4.376262664794922


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.98s/it]
INFO:root:final mean train loss: 1872.332665055314
INFO:root:final train perplexity: 4.3781843185424805
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.69s/it]
INFO:root:eval mean loss: 2833.286302904467
INFO:root:eval perplexity: 10.225841522216797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/43

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [6:23:56<8:29:01, 535.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1879.2988037109376
INFO:root:current train perplexity4.393440246582031
INFO:root:current mean train loss 1870.2951866736778
INFO:root:current train perplexity4.356293201446533
INFO:root:current mean train loss 1877.0030618418818
INFO:root:current train perplexity4.3684210777282715
INFO:root:current mean train loss 1873.7917347301136
INFO:root:current train perplexity4.353147506713867
INFO:root:current mean train loss 1869.1710514512174
INFO:root:current train perplexity4.351134777069092
INFO:root:current mean train loss 1869.2070722471992
INFO:root:current train perplexity4.345802307128906
INFO:root:current mean train loss 1866.883964029948
INFO:root:current train perplexity4.345738410949707
INFO:root:current mean train loss 1868.3648659902076
INFO:root:current train perplexity4.35114049911499
INFO:root:current mean train loss 1869.5023705172252
INFO:root:current train perplexity4.3498430252075195
INFO:root:current mean train loss 1869.7699554771505
INFO:root:current train perplexity4.352365493774414
INFO:root:current mean train loss 1868.655739674985
INFO:root:current train perplexity4.353102684020996
INFO:root:current mean train loss 1868.501776393114
INFO:root:current train perplexity4.353104114532471
INFO:root:current mean train loss 1868.7254894721798
INFO:root:current train perplexity4.3554301261901855
INFO:root:current mean train loss 1868.3289866511984
INFO:root:current train perplexity4.354591369628906
INFO:root:current mean train loss 1868.8845523007267
INFO:root:current train perplexity4.358283042907715
INFO:root:current mean train loss 1867.400703779233
INFO:root:current train perplexity4.356846809387207
INFO:root:current mean train loss 1867.652126719469
INFO:root:current train perplexity4.360864639282227
INFO:root:current mean train loss 1868.529952879448
INFO:root:current train perplexity4.36129093170166
INFO:root:current mean train loss 1868.370811253949
INFO:root:current train perplexity4.36254358291626
INFO:root:current mean train loss 1867.5117573318087
INFO:root:current train perplexity4.359947204589844


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.51s/it]
INFO:root:final mean train loss: 1867.4811228080284
INFO:root:final train perplexity: 4.3614654541015625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.14s/it]
INFO:root:eval mean loss: 2834.14270349451
INFO:root:eval perplexity: 10.233031272888184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/44

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [6:32:42<8:17:17, 532.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1851.8991829080785
INFO:root:current train perplexity4.326313018798828
INFO:root:current mean train loss 1835.62919357196
INFO:root:current train perplexity4.290048599243164
INFO:root:current mean train loss 1848.8476503194586
INFO:root:current train perplexity4.296387195587158
INFO:root:current mean train loss 1856.0611653176784
INFO:root:current train perplexity4.32208251953125
INFO:root:current mean train loss 1856.8243099613744
INFO:root:current train perplexity4.323208808898926
INFO:root:current mean train loss 1857.819571151594
INFO:root:current train perplexity4.327429294586182
INFO:root:current mean train loss 1857.6908147655647
INFO:root:current train perplexity4.32913064956665
INFO:root:current mean train loss 1858.0885035911876
INFO:root:current train perplexity4.321750164031982
INFO:root:current mean train loss 1861.0733714638523
INFO:root:current train perplexity4.3298821449279785
INFO:root:current mean train loss 1861.4348426826905
INFO:root:current train perplexity4.328449249267578
INFO:root:current mean train loss 1861.2239211409458
INFO:root:current train perplexity4.333767414093018
INFO:root:current mean train loss 1862.9761790480943
INFO:root:current train perplexity4.3368449211120605
INFO:root:current mean train loss 1861.322117319849
INFO:root:current train perplexity4.335782051086426
INFO:root:current mean train loss 1860.2237044053336
INFO:root:current train perplexity4.335020542144775
INFO:root:current mean train loss 1861.0313052564304
INFO:root:current train perplexity4.336059093475342
INFO:root:current mean train loss 1862.2098925244677
INFO:root:current train perplexity4.341946125030518
INFO:root:current mean train loss 1861.5670618127895
INFO:root:current train perplexity4.341328144073486
INFO:root:current mean train loss 1861.2335122626512
INFO:root:current train perplexity4.339321136474609
INFO:root:current mean train loss 1861.7557519108266
INFO:root:current train perplexity4.341109752655029
INFO:root:current mean train loss 1863.0452166117946
INFO:root:current train perplexity4.344234943389893


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.03s/it]
INFO:root:final mean train loss: 1862.4620457359233
INFO:root:final train perplexity: 4.344234943389893
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:10<00:00, 70.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:10<00:00, 70.54s/it]
INFO:root:eval mean loss: 2837.1484462978606
INFO:root:eval perplexity: 10.258304595947266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/45

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [6:41:43<8:10:52, 535.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1847.7851219177246
INFO:root:current train perplexity4.292335033416748
INFO:root:current mean train loss 1857.1671284001047
INFO:root:current train perplexity4.308621406555176
INFO:root:current mean train loss 1856.7048325972123
INFO:root:current train perplexity4.316644191741943
INFO:root:current mean train loss 1858.2386045351134
INFO:root:current train perplexity4.335520267486572
INFO:root:current mean train loss 1857.3608737814016
INFO:root:current train perplexity4.327143669128418
INFO:root:current mean train loss 1856.3990298873143
INFO:root:current train perplexity4.324767589569092
INFO:root:current mean train loss 1853.8910075727715
INFO:root:current train perplexity4.319531440734863
INFO:root:current mean train loss 1853.7095392836327
INFO:root:current train perplexity4.3218183517456055
INFO:root:current mean train loss 1856.0773483558937
INFO:root:current train perplexity4.325628757476807
INFO:root:current mean train loss 1857.1549571183707
INFO:root:current train perplexity4.32748556137085
INFO:root:current mean train loss 1855.620895959381
INFO:root:current train perplexity4.326292514801025
INFO:root:current mean train loss 1856.8136060786821
INFO:root:current train perplexity4.325448513031006
INFO:root:current mean train loss 1857.849973944169
INFO:root:current train perplexity4.3260626792907715
INFO:root:current mean train loss 1859.1152121803977
INFO:root:current train perplexity4.3266167640686035
INFO:root:current mean train loss 1859.9565107001633
INFO:root:current train perplexity4.326462268829346
INFO:root:current mean train loss 1859.439900117762
INFO:root:current train perplexity4.325439453125
INFO:root:current mean train loss 1858.5167138759907
INFO:root:current train perplexity4.327524185180664
INFO:root:current mean train loss 1858.4239733775999
INFO:root:current train perplexity4.326869487762451
INFO:root:current mean train loss 1858.1973309169
INFO:root:current train perplexity4.328030109405518
INFO:root:current mean train loss 1858.3550172638747
INFO:root:current train perplexity4.327950954437256


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.19s/it]
INFO:root:final mean train loss: 1857.6520189063092
INFO:root:final train perplexity: 4.327786445617676
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.92s/it]
INFO:root:eval mean loss: 2836.106475371856
INFO:root:eval perplexity: 10.24953556060791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/46

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [6:50:38<8:01:36, 535.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1855.9453245563273
INFO:root:current train perplexity4.300827980041504
INFO:root:current mean train loss 1857.2411016811982
INFO:root:current train perplexity4.295315742492676
INFO:root:current mean train loss 1856.8572311672876
INFO:root:current train perplexity4.294795989990234
INFO:root:current mean train loss 1856.4676013856422
INFO:root:current train perplexity4.293000221252441
INFO:root:current mean train loss 1851.806657628557
INFO:root:current train perplexity4.291472434997559
INFO:root:current mean train loss 1853.1876495939114
INFO:root:current train perplexity4.296887397766113
INFO:root:current mean train loss 1854.1309045463931
INFO:root:current train perplexity4.30523157119751
INFO:root:current mean train loss 1855.7287567959247
INFO:root:current train perplexity4.306857585906982
INFO:root:current mean train loss 1858.18766197525
INFO:root:current train perplexity4.308569431304932
INFO:root:current mean train loss 1855.38116710169
INFO:root:current train perplexity4.306669235229492
INFO:root:current mean train loss 1855.052930523134
INFO:root:current train perplexity4.306304931640625
INFO:root:current mean train loss 1854.944555684735
INFO:root:current train perplexity4.305985927581787
INFO:root:current mean train loss 1855.2712894055549
INFO:root:current train perplexity4.309589385986328
INFO:root:current mean train loss 1855.2296185890546
INFO:root:current train perplexity4.311257839202881
INFO:root:current mean train loss 1854.7940551840236
INFO:root:current train perplexity4.312358856201172
INFO:root:current mean train loss 1853.5304977349433
INFO:root:current train perplexity4.310108184814453
INFO:root:current mean train loss 1854.0465524322856
INFO:root:current train perplexity4.309861183166504
INFO:root:current mean train loss 1854.0380849779356
INFO:root:current train perplexity4.311174392700195
INFO:root:current mean train loss 1853.0482518440988
INFO:root:current train perplexity4.310780048370361
INFO:root:current mean train loss 1853.5074197922254
INFO:root:current train perplexity4.311731815338135


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.44s/it]
INFO:root:final mean train loss: 1852.9105856198587
INFO:root:final train perplexity: 4.311633586883545
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:11<00:00, 71.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:11<00:00, 71.92s/it]
INFO:root:eval mean loss: 2840.2893476973068
INFO:root:eval perplexity: 10.284774780273438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/47

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [6:59:38<7:54:08, 536.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1848.042808065609
INFO:root:current train perplexity4.2594170570373535
INFO:root:current mean train loss 1846.1194883404355
INFO:root:current train perplexity4.263280868530273
INFO:root:current mean train loss 1844.8362746270711
INFO:root:current train perplexity4.28231954574585
INFO:root:current mean train loss 1842.5266680693508
INFO:root:current train perplexity4.281342506408691
INFO:root:current mean train loss 1843.7422267193774
INFO:root:current train perplexity4.2801713943481445
INFO:root:current mean train loss 1843.8103880611152
INFO:root:current train perplexity4.280307292938232
INFO:root:current mean train loss 1847.1705268051016
INFO:root:current train perplexity4.2885260581970215
INFO:root:current mean train loss 1847.5684340245143
INFO:root:current train perplexity4.292644500732422
INFO:root:current mean train loss 1848.2446415482757
INFO:root:current train perplexity4.2950758934021
INFO:root:current mean train loss 1846.6810958342467
INFO:root:current train perplexity4.291901588439941
INFO:root:current mean train loss 1848.8310941546774
INFO:root:current train perplexity4.292227268218994
INFO:root:current mean train loss 1849.4368441013341
INFO:root:current train perplexity4.294872760772705
INFO:root:current mean train loss 1847.7278739564774
INFO:root:current train perplexity4.29284143447876
INFO:root:current mean train loss 1848.4396107336652
INFO:root:current train perplexity4.296050071716309
INFO:root:current mean train loss 1848.4806626119982
INFO:root:current train perplexity4.297760009765625
INFO:root:current mean train loss 1848.9754918257197
INFO:root:current train perplexity4.300471782684326
INFO:root:current mean train loss 1849.3056137390497
INFO:root:current train perplexity4.301014423370361
INFO:root:current mean train loss 1849.527248089783
INFO:root:current train perplexity4.300817966461182
INFO:root:current mean train loss 1849.5072760466403
INFO:root:current train perplexity4.299808025360107


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.07s/it]
INFO:root:final mean train loss: 1849.5250044075817
INFO:root:final train perplexity: 4.300136566162109
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.87s/it]
INFO:root:eval mean loss: 2841.2573374155404
INFO:root:eval perplexity: 10.292945861816406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/48

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [7:08:28<7:43:28, 534.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1785.8569417317708
INFO:root:current train perplexity4.069258213043213
INFO:root:current mean train loss 1839.9770401664402
INFO:root:current train perplexity4.262657165527344
INFO:root:current mean train loss 1843.7189197628998
INFO:root:current train perplexity4.252518653869629
INFO:root:current mean train loss 1842.5217044890874
INFO:root:current train perplexity4.250847816467285
INFO:root:current mean train loss 1845.2104209807983
INFO:root:current train perplexity4.2589287757873535
INFO:root:current mean train loss 1841.534640473301
INFO:root:current train perplexity4.252093315124512
INFO:root:current mean train loss 1838.3636393229167
INFO:root:current train perplexity4.251795768737793
INFO:root:current mean train loss 1839.885011472902
INFO:root:current train perplexity4.2594780921936035
INFO:root:current mean train loss 1839.7203023149923
INFO:root:current train perplexity4.264314651489258
INFO:root:current mean train loss 1839.1604714982498
INFO:root:current train perplexity4.267143726348877
INFO:root:current mean train loss 1841.2419451633698
INFO:root:current train perplexity4.271244525909424
INFO:root:current mean train loss 1842.1104657502453
INFO:root:current train perplexity4.268189907073975
INFO:root:current mean train loss 1843.1442958502123
INFO:root:current train perplexity4.268284797668457
INFO:root:current mean train loss 1843.3552541290398
INFO:root:current train perplexity4.269911289215088
INFO:root:current mean train loss 1842.8483697790139
INFO:root:current train perplexity4.272166728973389
INFO:root:current mean train loss 1842.2331650938531
INFO:root:current train perplexity4.274164199829102
INFO:root:current mean train loss 1843.178933536305
INFO:root:current train perplexity4.2757391929626465
INFO:root:current mean train loss 1842.9389962332589
INFO:root:current train perplexity4.2769880294799805
INFO:root:current mean train loss 1843.8939269515108
INFO:root:current train perplexity4.278641700744629
INFO:root:current mean train loss 1844.0211059889034
INFO:root:current train perplexity4.281267166137695


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.29s/it]
INFO:root:final mean train loss: 1844.4509770118764
INFO:root:final train perplexity: 4.282962799072266
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.64s/it]
INFO:root:eval mean loss: 2841.7246988199136
INFO:root:eval perplexity: 10.296897888183594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/49

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [7:17:27<7:35:33, 535.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1863.4393348693848
INFO:root:current train perplexity4.316999912261963
INFO:root:current mean train loss 1840.7886232318301
INFO:root:current train perplexity4.230844974517822
INFO:root:current mean train loss 1836.55902573158
INFO:root:current train perplexity4.228271961212158
INFO:root:current mean train loss 1837.48317084255
INFO:root:current train perplexity4.23780632019043
INFO:root:current mean train loss 1838.4275196216724
INFO:root:current train perplexity4.243725299835205
INFO:root:current mean train loss 1835.3722444692053
INFO:root:current train perplexity4.246955394744873
INFO:root:current mean train loss 1835.9120518165298
INFO:root:current train perplexity4.251805782318115
INFO:root:current mean train loss 1836.9565082821039
INFO:root:current train perplexity4.25465726852417
INFO:root:current mean train loss 1836.4003831423247
INFO:root:current train perplexity4.254598140716553
INFO:root:current mean train loss 1836.9833937223377
INFO:root:current train perplexity4.257447719573975
INFO:root:current mean train loss 1835.9970730330592
INFO:root:current train perplexity4.255384922027588
INFO:root:current mean train loss 1837.9472335977184
INFO:root:current train perplexity4.257997035980225
INFO:root:current mean train loss 1838.7880951522234
INFO:root:current train perplexity4.259734630584717
INFO:root:current mean train loss 1837.9083990606819
INFO:root:current train perplexity4.258509635925293
INFO:root:current mean train loss 1837.4502172203704
INFO:root:current train perplexity4.258605003356934
INFO:root:current mean train loss 1837.8150922411726
INFO:root:current train perplexity4.259237289428711
INFO:root:current mean train loss 1839.0052912095014
INFO:root:current train perplexity4.261622428894043
INFO:root:current mean train loss 1838.3264544973747
INFO:root:current train perplexity4.261899948120117
INFO:root:current mean train loss 1839.5713366379384
INFO:root:current train perplexity4.264152526855469
INFO:root:current mean train loss 1839.6357153345587
INFO:root:current train perplexity4.266304969787598


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.44s/it]
INFO:root:final mean train loss: 1839.9690870014754
INFO:root:final train perplexity: 4.267850875854492
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.79s/it]
INFO:root:eval mean loss: 2844.2140995976447
INFO:root:eval perplexity: 10.317951202392578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/50

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [7:26:39<7:30:36, 540.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1815.0629210180166
INFO:root:current train perplexity4.214365005493164
INFO:root:current mean train loss 1824.8398462077914
INFO:root:current train perplexity4.191146373748779
INFO:root:current mean train loss 1826.0454184903676
INFO:root:current train perplexity4.213217735290527
INFO:root:current mean train loss 1828.050341587012
INFO:root:current train perplexity4.223789691925049
INFO:root:current mean train loss 1832.2816183859097
INFO:root:current train perplexity4.224184989929199
INFO:root:current mean train loss 1832.587791456768
INFO:root:current train perplexity4.227128505706787
INFO:root:current mean train loss 1831.1758995585155
INFO:root:current train perplexity4.230561256408691
INFO:root:current mean train loss 1832.975675086313
INFO:root:current train perplexity4.234769821166992
INFO:root:current mean train loss 1832.5451412852437
INFO:root:current train perplexity4.2339372634887695
INFO:root:current mean train loss 1834.980781836555
INFO:root:current train perplexity4.24144983291626
INFO:root:current mean train loss 1836.0491935213597
INFO:root:current train perplexity4.247862339019775
INFO:root:current mean train loss 1835.7218506284337
INFO:root:current train perplexity4.250750541687012
INFO:root:current mean train loss 1835.769153995071
INFO:root:current train perplexity4.253467559814453
INFO:root:current mean train loss 1834.1850847452106
INFO:root:current train perplexity4.250997066497803
INFO:root:current mean train loss 1833.9216533526624
INFO:root:current train perplexity4.250992774963379
INFO:root:current mean train loss 1833.820225183082
INFO:root:current train perplexity4.25094747543335
INFO:root:current mean train loss 1834.0497372490192
INFO:root:current train perplexity4.251388072967529
INFO:root:current mean train loss 1834.2524630424975
INFO:root:current train perplexity4.252062797546387
INFO:root:current mean train loss 1834.9446338181112
INFO:root:current train perplexity4.2524333000183105
INFO:root:current mean train loss 1836.368512235341
INFO:root:current train perplexity4.254167556762695


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.03s/it]
INFO:root:final mean train loss: 1835.6267018743795
INFO:root:final train perplexity: 4.253259181976318
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.76s/it]
INFO:root:eval mean loss: 2842.5811573292044
INFO:root:eval perplexity: 10.3041353225708
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/51

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [7:35:56<7:25:42, 545.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1832.9748165246212
INFO:root:current train perplexity4.211557388305664
INFO:root:current mean train loss 1826.4537037309394
INFO:root:current train perplexity4.225827693939209
INFO:root:current mean train loss 1829.44613440951
INFO:root:current train perplexity4.213720321655273
INFO:root:current mean train loss 1828.415131449048
INFO:root:current train perplexity4.226725101470947
INFO:root:current mean train loss 1828.6495371806263
INFO:root:current train perplexity4.225141525268555
INFO:root:current mean train loss 1834.157652945906
INFO:root:current train perplexity4.227730751037598
INFO:root:current mean train loss 1834.648671743032
INFO:root:current train perplexity4.228621959686279
INFO:root:current mean train loss 1831.8945640783086
INFO:root:current train perplexity4.227045059204102
INFO:root:current mean train loss 1833.9768270796496
INFO:root:current train perplexity4.232757091522217
INFO:root:current mean train loss 1832.3300410995325
INFO:root:current train perplexity4.230185508728027
INFO:root:current mean train loss 1832.3416356414166
INFO:root:current train perplexity4.236374855041504
INFO:root:current mean train loss 1831.0259887276547
INFO:root:current train perplexity4.233476638793945
INFO:root:current mean train loss 1831.7303589252876
INFO:root:current train perplexity4.23461389541626
INFO:root:current mean train loss 1830.9037243241273
INFO:root:current train perplexity4.236352920532227
INFO:root:current mean train loss 1830.5061057638504
INFO:root:current train perplexity4.23716402053833
INFO:root:current mean train loss 1831.8448392008152
INFO:root:current train perplexity4.240146160125732
INFO:root:current mean train loss 1831.428007311323
INFO:root:current train perplexity4.239040851593018
INFO:root:current mean train loss 1832.3450154253742
INFO:root:current train perplexity4.239832878112793
INFO:root:current mean train loss 1832.0344341641965
INFO:root:current train perplexity4.239852428436279
INFO:root:current mean train loss 1832.2349756654137
INFO:root:current train perplexity4.240272045135498


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.54s/it]
INFO:root:final mean train loss: 1832.006397795569
INFO:root:final train perplexity: 4.241133213043213
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.70s/it]
INFO:root:eval mean loss: 2845.2907876137856
INFO:root:eval perplexity: 10.327072143554688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/52

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [7:44:47<7:13:00, 541.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1822.6323771649097
INFO:root:current train perplexity4.220377445220947
INFO:root:current mean train loss 1821.4875741760588
INFO:root:current train perplexity4.216466903686523
INFO:root:current mean train loss 1815.9693098843309
INFO:root:current train perplexity4.198079586029053
INFO:root:current mean train loss 1818.406186574433
INFO:root:current train perplexity4.207930564880371
INFO:root:current mean train loss 1817.6943020712022
INFO:root:current train perplexity4.203928470611572
INFO:root:current mean train loss 1818.1411099311213
INFO:root:current train perplexity4.210919380187988
INFO:root:current mean train loss 1820.7234481878545
INFO:root:current train perplexity4.212769508361816
INFO:root:current mean train loss 1820.4128567633502
INFO:root:current train perplexity4.207875728607178
INFO:root:current mean train loss 1822.1717236217528
INFO:root:current train perplexity4.209134578704834
INFO:root:current mean train loss 1822.5405005205685
INFO:root:current train perplexity4.211516380310059
INFO:root:current mean train loss 1822.364027986676
INFO:root:current train perplexity4.210951328277588
INFO:root:current mean train loss 1823.3726857202294
INFO:root:current train perplexity4.216916084289551
INFO:root:current mean train loss 1822.3453767795816
INFO:root:current train perplexity4.217958927154541
INFO:root:current mean train loss 1823.4656019452166
INFO:root:current train perplexity4.219963073730469
INFO:root:current mean train loss 1825.036524293556
INFO:root:current train perplexity4.221025466918945
INFO:root:current mean train loss 1826.3728117566282
INFO:root:current train perplexity4.22232723236084
INFO:root:current mean train loss 1826.5150665809056
INFO:root:current train perplexity4.221368789672852
INFO:root:current mean train loss 1827.3497266528718
INFO:root:current train perplexity4.223296165466309
INFO:root:current mean train loss 1827.507710202096
INFO:root:current train perplexity4.224349021911621
INFO:root:current mean train loss 1827.103785312362
INFO:root:current train perplexity4.224766254425049


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.91s/it]
INFO:root:final mean train loss: 1827.103785312362
INFO:root:final train perplexity: 4.224766254425049
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.36s/it]
INFO:root:eval mean loss: 2846.8889519402214
INFO:root:eval perplexity: 10.340622901916504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/53

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [7:53:34<7:00:33, 536.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1819.506114501953
INFO:root:current train perplexity4.27305269241333
INFO:root:current mean train loss 1832.8647583007812
INFO:root:current train perplexity4.245231628417969
INFO:root:current mean train loss 1820.4138533528646
INFO:root:current train perplexity4.221672058105469
INFO:root:current mean train loss 1820.048406677246
INFO:root:current train perplexity4.214455604553223
INFO:root:current mean train loss 1819.28115625
INFO:root:current train perplexity4.210495471954346
INFO:root:current mean train loss 1824.7067478434244
INFO:root:current train perplexity4.219046115875244
INFO:root:current mean train loss 1822.4550563267298
INFO:root:current train perplexity4.210623741149902
INFO:root:current mean train loss 1822.115780944824
INFO:root:current train perplexity4.212618350982666
INFO:root:current mean train loss 1823.0412748209635
INFO:root:current train perplexity4.213540077209473
INFO:root:current mean train loss 1822.9636016845702
INFO:root:current train perplexity4.214575290679932
INFO:root:current mean train loss 1825.3852290482955
INFO:root:current train perplexity4.217527389526367
INFO:root:current mean train loss 1825.5353500366211
INFO:root:current train perplexity4.217121601104736
INFO:root:current mean train loss 1825.9648053448018
INFO:root:current train perplexity4.2159881591796875
INFO:root:current mean train loss 1823.6446303013392
INFO:root:current train perplexity4.2130537033081055
INFO:root:current mean train loss 1823.8757928873697
INFO:root:current train perplexity4.214025020599365
INFO:root:current mean train loss 1823.9366324615478
INFO:root:current train perplexity4.213546276092529
INFO:root:current mean train loss 1824.605351706112
INFO:root:current train perplexity4.213349342346191
INFO:root:current mean train loss 1825.8228047010634
INFO:root:current train perplexity4.215323448181152
INFO:root:current mean train loss 1824.4223930921053
INFO:root:current train perplexity4.213703155517578


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.48s/it]
INFO:root:final mean train loss: 1823.449703214629
INFO:root:final train perplexity: 4.21260929107666
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.18s/it]
INFO:root:eval mean loss: 2846.996804910379
INFO:root:eval perplexity: 10.341537475585938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/54

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [8:02:28<6:51:02, 536.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1822.2650720932904
INFO:root:current train perplexity4.266441345214844
INFO:root:current mean train loss 1809.890881660657
INFO:root:current train perplexity4.189830780029297
INFO:root:current mean train loss 1814.1971041771674
INFO:root:current train perplexity4.18018102645874
INFO:root:current mean train loss 1812.7152099609375
INFO:root:current train perplexity4.184503078460693
INFO:root:current mean train loss 1819.2460454487973
INFO:root:current train perplexity4.199747085571289
INFO:root:current mean train loss 1817.6961218946446
INFO:root:current train perplexity4.193300724029541
INFO:root:current mean train loss 1816.0200436683297
INFO:root:current train perplexity4.189558506011963
INFO:root:current mean train loss 1816.3044060743005
INFO:root:current train perplexity4.195872783660889
INFO:root:current mean train loss 1817.0899782215804
INFO:root:current train perplexity4.1981329917907715
INFO:root:current mean train loss 1817.739483316436
INFO:root:current train perplexity4.199676036834717
INFO:root:current mean train loss 1818.2125688250906
INFO:root:current train perplexity4.201431751251221
INFO:root:current mean train loss 1818.711489166014
INFO:root:current train perplexity4.204226970672607
INFO:root:current mean train loss 1819.1241286566928
INFO:root:current train perplexity4.206292629241943
INFO:root:current mean train loss 1818.0350834897908
INFO:root:current train perplexity4.205386638641357
INFO:root:current mean train loss 1818.946305947314
INFO:root:current train perplexity4.205681800842285
INFO:root:current mean train loss 1818.5064080074262
INFO:root:current train perplexity4.201907157897949
INFO:root:current mean train loss 1819.0225291066356
INFO:root:current train perplexity4.203273296356201
INFO:root:current mean train loss 1819.1236774175752
INFO:root:current train perplexity4.202981472015381
INFO:root:current mean train loss 1819.6056639146989
INFO:root:current train perplexity4.202502250671387
INFO:root:current mean train loss 1819.9172331442358
INFO:root:current train perplexity4.200625419616699


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.51s/it]
INFO:root:final mean train loss: 1820.108781669336
INFO:root:final train perplexity: 4.201524257659912
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.49s/it]
INFO:root:eval mean loss: 2852.0334120741836
INFO:root:eval perplexity: 10.38436508178711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/55

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [8:11:39<6:45:26, 540.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1792.307929543888
INFO:root:current train perplexity4.143898010253906
INFO:root:current mean train loss 1804.575791088503
INFO:root:current train perplexity4.150765419006348
INFO:root:current mean train loss 1814.5894451956465
INFO:root:current train perplexity4.163009166717529
INFO:root:current mean train loss 1817.7757904600953
INFO:root:current train perplexity4.173406600952148
INFO:root:current mean train loss 1817.7993327197942
INFO:root:current train perplexity4.177646636962891
INFO:root:current mean train loss 1817.2001793107736
INFO:root:current train perplexity4.17641019821167
INFO:root:current mean train loss 1814.9599669062377
INFO:root:current train perplexity4.1713666915893555
INFO:root:current mean train loss 1814.7444589391391
INFO:root:current train perplexity4.171856880187988
INFO:root:current mean train loss 1813.91773134227
INFO:root:current train perplexity4.172463893890381
INFO:root:current mean train loss 1811.816179753371
INFO:root:current train perplexity4.1726603507995605
INFO:root:current mean train loss 1811.036154889046
INFO:root:current train perplexity4.175683498382568
INFO:root:current mean train loss 1811.1714858605117
INFO:root:current train perplexity4.174973964691162
INFO:root:current mean train loss 1812.3417286185042
INFO:root:current train perplexity4.179500579833984
INFO:root:current mean train loss 1812.566339541411
INFO:root:current train perplexity4.180950164794922
INFO:root:current mean train loss 1812.8207926091789
INFO:root:current train perplexity4.18333625793457
INFO:root:current mean train loss 1814.0665128824764
INFO:root:current train perplexity4.184529781341553
INFO:root:current mean train loss 1814.9132027783621
INFO:root:current train perplexity4.186594009399414
INFO:root:current mean train loss 1815.9740370384136
INFO:root:current train perplexity4.189525604248047
INFO:root:current mean train loss 1815.610543853194
INFO:root:current train perplexity4.187666416168213
INFO:root:current mean train loss 1816.677201153697
INFO:root:current train perplexity4.18855619430542


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.73s/it]
INFO:root:final mean train loss: 1816.233549624937
INFO:root:final train perplexity: 4.188702583312988
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.89s/it]
INFO:root:eval mean loss: 2851.895700632273
INFO:root:eval perplexity: 10.383195877075195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/56

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [8:20:31<6:34:35, 538.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1814.181365368413
INFO:root:current train perplexity4.17598295211792
INFO:root:current mean train loss 1810.5652397105237
INFO:root:current train perplexity4.16105318069458
INFO:root:current mean train loss 1807.3943104534985
INFO:root:current train perplexity4.163040637969971
INFO:root:current mean train loss 1806.5583078759348
INFO:root:current train perplexity4.154331207275391
INFO:root:current mean train loss 1807.3273806688262
INFO:root:current train perplexity4.157083988189697
INFO:root:current mean train loss 1809.4672477154463
INFO:root:current train perplexity4.160092353820801
INFO:root:current mean train loss 1811.1942740585398
INFO:root:current train perplexity4.1655073165893555
INFO:root:current mean train loss 1808.9359269021513
INFO:root:current train perplexity4.164377212524414
INFO:root:current mean train loss 1808.4470454394186
INFO:root:current train perplexity4.164788722991943
INFO:root:current mean train loss 1808.1767466451843
INFO:root:current train perplexity4.166027545928955
INFO:root:current mean train loss 1809.4209846184438
INFO:root:current train perplexity4.169503211975098
INFO:root:current mean train loss 1810.5480373723935
INFO:root:current train perplexity4.169372081756592
INFO:root:current mean train loss 1812.2029759981078
INFO:root:current train perplexity4.170984745025635
INFO:root:current mean train loss 1813.1215876332924
INFO:root:current train perplexity4.1730499267578125
INFO:root:current mean train loss 1813.069111230536
INFO:root:current train perplexity4.173923015594482
INFO:root:current mean train loss 1813.3628307467964
INFO:root:current train perplexity4.175934314727783
INFO:root:current mean train loss 1813.0485824316938
INFO:root:current train perplexity4.175465106964111
INFO:root:current mean train loss 1813.095043485196
INFO:root:current train perplexity4.176190376281738
INFO:root:current mean train loss 1813.8433926261353
INFO:root:current train perplexity4.17738151550293
INFO:root:current mean train loss 1813.2762812815342
INFO:root:current train perplexity4.17720365524292


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.63s/it]
INFO:root:final mean train loss: 1812.776615298642
INFO:root:final train perplexity: 4.177298545837402
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.54s/it]
INFO:root:eval mean loss: 2852.9758704016517
INFO:root:eval perplexity: 10.392401695251465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/57

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [8:29:19<6:23:25, 535.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1791.6061993767235
INFO:root:current train perplexity4.09499979019165
INFO:root:current mean train loss 1788.117951892671
INFO:root:current train perplexity4.114170074462891
INFO:root:current mean train loss 1798.8607819969975
INFO:root:current train perplexity4.126276016235352
INFO:root:current mean train loss 1797.0831670346467
INFO:root:current train perplexity4.129052639007568
INFO:root:current mean train loss 1800.2237953120828
INFO:root:current train perplexity4.134076118469238
INFO:root:current mean train loss 1801.8382950903665
INFO:root:current train perplexity4.139578342437744
INFO:root:current mean train loss 1801.0697712241533
INFO:root:current train perplexity4.137847900390625
INFO:root:current mean train loss 1802.4097050031025
INFO:root:current train perplexity4.142162799835205
INFO:root:current mean train loss 1804.2788773637762
INFO:root:current train perplexity4.144713401794434
INFO:root:current mean train loss 1806.98899097285
INFO:root:current train perplexity4.151350975036621
INFO:root:current mean train loss 1806.0233963527037
INFO:root:current train perplexity4.1528706550598145
INFO:root:current mean train loss 1805.964565015819
INFO:root:current train perplexity4.155127048492432
INFO:root:current mean train loss 1807.682927850669
INFO:root:current train perplexity4.157757759094238
INFO:root:current mean train loss 1806.0314584475511
INFO:root:current train perplexity4.157721519470215
INFO:root:current mean train loss 1806.8751895914936
INFO:root:current train perplexity4.162018299102783
INFO:root:current mean train loss 1807.524955204555
INFO:root:current train perplexity4.162430286407471
INFO:root:current mean train loss 1807.7461168028467
INFO:root:current train perplexity4.161971569061279
INFO:root:current mean train loss 1808.4509500356821
INFO:root:current train perplexity4.162847995758057
INFO:root:current mean train loss 1808.9878557029576
INFO:root:current train perplexity4.164130210876465
INFO:root:current mean train loss 1809.853423079824
INFO:root:current train perplexity4.1667866706848145


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.54s/it]
INFO:root:final mean train loss: 1809.5181096818071
INFO:root:final train perplexity: 4.166576862335205
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:10<00:00, 70.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:10<00:00, 70.78s/it]
INFO:root:eval mean loss: 2850.057445629223
INFO:root:eval perplexity: 10.367542266845703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/58

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [8:38:22<6:16:04, 537.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1803.710523897059
INFO:root:current train perplexity4.156192779541016
INFO:root:current mean train loss 1801.9604248046876
INFO:root:current train perplexity4.139886856079102
INFO:root:current mean train loss 1795.7140860574286
INFO:root:current train perplexity4.119483470916748
INFO:root:current mean train loss 1794.5324700689935
INFO:root:current train perplexity4.116260528564453
INFO:root:current mean train loss 1796.2963129731797
INFO:root:current train perplexity4.119295597076416
INFO:root:current mean train loss 1796.2807208199786
INFO:root:current train perplexity4.120805263519287
INFO:root:current mean train loss 1793.4716415516652
INFO:root:current train perplexity4.120716571807861
INFO:root:current mean train loss 1795.4731670792696
INFO:root:current train perplexity4.121805667877197
INFO:root:current mean train loss 1797.29581912628
INFO:root:current train perplexity4.128252029418945
INFO:root:current mean train loss 1797.9511282519036
INFO:root:current train perplexity4.132680416107178
INFO:root:current mean train loss 1798.8678613056236
INFO:root:current train perplexity4.1325364112854
INFO:root:current mean train loss 1800.1767252604166
INFO:root:current train perplexity4.135725975036621
INFO:root:current mean train loss 1799.997125125395
INFO:root:current train perplexity4.13876485824585
INFO:root:current mean train loss 1801.3455318740127
INFO:root:current train perplexity4.139774799346924
INFO:root:current mean train loss 1801.355761389941
INFO:root:current train perplexity4.141336441040039
INFO:root:current mean train loss 1801.938782238885
INFO:root:current train perplexity4.146014213562012
INFO:root:current mean train loss 1802.2219297686388
INFO:root:current train perplexity4.147859573364258
INFO:root:current mean train loss 1804.1093605704
INFO:root:current train perplexity4.15067195892334
INFO:root:current mean train loss 1804.7499194400696
INFO:root:current train perplexity4.151862144470215


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.58s/it]
INFO:root:final mean train loss: 1805.669752466276
INFO:root:final train perplexity: 4.1539506912231445
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.82s/it]
INFO:root:eval mean loss: 2853.977975289743
INFO:root:eval perplexity: 10.400948524475098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/59

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [8:47:14<6:06:09, 535.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1834.7604370117188
INFO:root:current train perplexity4.214216709136963
INFO:root:current mean train loss 1803.304303337546
INFO:root:current train perplexity4.115897178649902
INFO:root:current mean train loss 1793.8647847694926
INFO:root:current train perplexity4.109931945800781
INFO:root:current mean train loss 1792.474889894195
INFO:root:current train perplexity4.105567455291748
INFO:root:current mean train loss 1794.6675779428056
INFO:root:current train perplexity4.1112871170043945
INFO:root:current mean train loss 1799.4142159389785
INFO:root:current train perplexity4.121390342712402
INFO:root:current mean train loss 1798.0552248527044
INFO:root:current train perplexity4.121997833251953
INFO:root:current mean train loss 1801.4385490743523
INFO:root:current train perplexity4.128371238708496
INFO:root:current mean train loss 1801.3450188006545
INFO:root:current train perplexity4.1366777420043945
INFO:root:current mean train loss 1800.523275777136
INFO:root:current train perplexity4.138372421264648
INFO:root:current mean train loss 1800.048294767886
INFO:root:current train perplexity4.139101505279541
INFO:root:current mean train loss 1800.6701916038664
INFO:root:current train perplexity4.1384429931640625
INFO:root:current mean train loss 1800.3092718394148
INFO:root:current train perplexity4.139149188995361
INFO:root:current mean train loss 1800.8360704460085
INFO:root:current train perplexity4.141210079193115
INFO:root:current mean train loss 1800.9235415819198
INFO:root:current train perplexity4.141778945922852
INFO:root:current mean train loss 1802.4899488670055
INFO:root:current train perplexity4.141347885131836
INFO:root:current mean train loss 1803.1458139788642
INFO:root:current train perplexity4.141791343688965
INFO:root:current mean train loss 1802.9016423118942
INFO:root:current train perplexity4.142508506774902
INFO:root:current mean train loss 1802.8030062896694
INFO:root:current train perplexity4.142171859741211
INFO:root:current mean train loss 1802.485601158423
INFO:root:current train perplexity4.142711639404297


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.02s/it]
INFO:root:final mean train loss: 1802.5520051541619
INFO:root:final train perplexity: 4.143749237060547
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.42s/it]
INFO:root:eval mean loss: 2855.6307970568223
INFO:root:eval perplexity: 10.41506576538086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/60

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [8:56:06<5:56:22, 534.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1758.2212685032894
INFO:root:current train perplexity4.096038818359375
INFO:root:current mean train loss 1784.3024286863183
INFO:root:current train perplexity4.113924026489258
INFO:root:current mean train loss 1796.9087543923017
INFO:root:current train perplexity4.120368003845215
INFO:root:current mean train loss 1797.691059555006
INFO:root:current train perplexity4.1258039474487305
INFO:root:current mean train loss 1798.8924272122986
INFO:root:current train perplexity4.129787445068359
INFO:root:current mean train loss 1796.3288393112507
INFO:root:current train perplexity4.129954814910889
INFO:root:current mean train loss 1796.0110172894158
INFO:root:current train perplexity4.12849760055542
INFO:root:current mean train loss 1793.0699741326387
INFO:root:current train perplexity4.124795913696289
INFO:root:current mean train loss 1792.8861714457419
INFO:root:current train perplexity4.124362468719482
INFO:root:current mean train loss 1792.7762071279499
INFO:root:current train perplexity4.121547698974609
INFO:root:current mean train loss 1795.4268433455748
INFO:root:current train perplexity4.123995304107666
INFO:root:current mean train loss 1795.7035232830303
INFO:root:current train perplexity4.126920700073242
INFO:root:current mean train loss 1795.969861450696
INFO:root:current train perplexity4.125933647155762
INFO:root:current mean train loss 1795.0526536734742
INFO:root:current train perplexity4.1242780685424805
INFO:root:current mean train loss 1796.1626609710843
INFO:root:current train perplexity4.127116680145264
INFO:root:current mean train loss 1796.478972163147
INFO:root:current train perplexity4.128050804138184
INFO:root:current mean train loss 1796.8662663554614
INFO:root:current train perplexity4.128036022186279
INFO:root:current mean train loss 1797.9460539404495
INFO:root:current train perplexity4.1285624504089355
INFO:root:current mean train loss 1798.4483991542186
INFO:root:current train perplexity4.129924297332764
INFO:root:current mean train loss 1799.5434121851997
INFO:root:current train perplexity4.1317548751831055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.81s/it]
INFO:root:final mean train loss: 1799.2583590154989
INFO:root:final train perplexity: 4.132999420166016
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.93s/it]
INFO:root:eval mean loss: 2855.392865521772
INFO:root:eval perplexity: 10.413034439086914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/61

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [9:04:57<5:46:45, 533.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1796.8176642523872
INFO:root:current train perplexity4.066528797149658
INFO:root:current mean train loss 1786.0347541360295
INFO:root:current train perplexity4.075099468231201
INFO:root:current mean train loss 1790.7211748543432
INFO:root:current train perplexity4.094059467315674
INFO:root:current mean train loss 1793.154179527646
INFO:root:current train perplexity4.114475727081299
INFO:root:current mean train loss 1794.9031470062537
INFO:root:current train perplexity4.117103099822998
INFO:root:current mean train loss 1796.691571136019
INFO:root:current train perplexity4.119847297668457
INFO:root:current mean train loss 1794.9006351494938
INFO:root:current train perplexity4.116933345794678
INFO:root:current mean train loss 1796.140412537948
INFO:root:current train perplexity4.119312286376953
INFO:root:current mean train loss 1798.2588725842927
INFO:root:current train perplexity4.126400947570801
INFO:root:current mean train loss 1798.4329318837222
INFO:root:current train perplexity4.126197338104248
INFO:root:current mean train loss 1797.2478458596013
INFO:root:current train perplexity4.12276029586792
INFO:root:current mean train loss 1797.1098564040492
INFO:root:current train perplexity4.1207709312438965
INFO:root:current mean train loss 1796.6401733595962
INFO:root:current train perplexity4.119146823883057
INFO:root:current mean train loss 1796.7445754548032
INFO:root:current train perplexity4.1189045906066895
INFO:root:current mean train loss 1796.6262215531967
INFO:root:current train perplexity4.12157678604126
INFO:root:current mean train loss 1796.5802869796753
INFO:root:current train perplexity4.123010635375977
INFO:root:current mean train loss 1796.068156944219
INFO:root:current train perplexity4.12260627746582
INFO:root:current mean train loss 1796.1639910579277
INFO:root:current train perplexity4.1223063468933105
INFO:root:current mean train loss 1796.4923550474878
INFO:root:current train perplexity4.1227641105651855
INFO:root:current mean train loss 1797.0922588632127
INFO:root:current train perplexity4.124340534210205


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.21s/it]
INFO:root:final mean train loss: 1796.6570501053388
INFO:root:final train perplexity: 4.1245293617248535
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.26s/it]
INFO:root:eval mean loss: 2857.779277079814
INFO:root:eval perplexity: 10.433442115783691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/62

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [9:13:47<5:37:19, 532.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1796.5553508254718
INFO:root:current train perplexity4.086496829986572
INFO:root:current mean train loss 1784.0239281747856
INFO:root:current train perplexity4.0964202880859375
INFO:root:current mean train loss 1785.4385499011858
INFO:root:current train perplexity4.093810558319092
INFO:root:current mean train loss 1789.614140583503
INFO:root:current train perplexity4.105120658874512
INFO:root:current mean train loss 1789.6320617541046
INFO:root:current train perplexity4.106180191040039
INFO:root:current mean train loss 1791.3924289034246
INFO:root:current train perplexity4.109428405761719
INFO:root:current mean train loss 1791.3009431380408
INFO:root:current train perplexity4.106664180755615
INFO:root:current mean train loss 1792.7069394946257
INFO:root:current train perplexity4.110438346862793
INFO:root:current mean train loss 1794.8831087315907
INFO:root:current train perplexity4.112908363342285
INFO:root:current mean train loss 1794.525725453748
INFO:root:current train perplexity4.110400676727295
INFO:root:current mean train loss 1794.9127389703156
INFO:root:current train perplexity4.110576629638672
INFO:root:current mean train loss 1794.4064078550182
INFO:root:current train perplexity4.11134672164917
INFO:root:current mean train loss 1793.6441605576304
INFO:root:current train perplexity4.112033367156982
INFO:root:current mean train loss 1793.4174358088796
INFO:root:current train perplexity4.110729694366455
INFO:root:current mean train loss 1794.3081627653455
INFO:root:current train perplexity4.113338947296143
INFO:root:current mean train loss 1794.8512255293433
INFO:root:current train perplexity4.115448474884033
INFO:root:current mean train loss 1794.596661299413
INFO:root:current train perplexity4.116049766540527
INFO:root:current mean train loss 1794.2437155027765
INFO:root:current train perplexity4.114999294281006
INFO:root:current mean train loss 1794.0361988213792
INFO:root:current train perplexity4.115091800689697
INFO:root:current mean train loss 1793.987563079037
INFO:root:current train perplexity4.113962650299072


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.78s/it]
INFO:root:final mean train loss: 1793.262576073874
INFO:root:final train perplexity: 4.113502502441406
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.95s/it]
INFO:root:eval mean loss: 2859.9091518276086
INFO:root:eval perplexity: 10.45169448852539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/63

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [9:22:32<5:27:01, 530.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1794.897739955357
INFO:root:current train perplexity4.118490219116211
INFO:root:current mean train loss 1790.3097842945772
INFO:root:current train perplexity4.1056671142578125
INFO:root:current mean train loss 1790.1357453522858
INFO:root:current train perplexity4.097438335418701
INFO:root:current mean train loss 1784.9583093591639
INFO:root:current train perplexity4.08242654800415
INFO:root:current mean train loss 1787.5919906291556
INFO:root:current train perplexity4.096071243286133
INFO:root:current mean train loss 1786.8859000222724
INFO:root:current train perplexity4.101305961608887
INFO:root:current mean train loss 1787.8526984826842
INFO:root:current train perplexity4.0949225425720215
INFO:root:current mean train loss 1789.6252108487215
INFO:root:current train perplexity4.098930835723877
INFO:root:current mean train loss 1791.6061806865123
INFO:root:current train perplexity4.1017656326293945
INFO:root:current mean train loss 1792.9449193580863
INFO:root:current train perplexity4.102863788604736
INFO:root:current mean train loss 1792.4779617452175
INFO:root:current train perplexity4.101007461547852
INFO:root:current mean train loss 1792.123629160824
INFO:root:current train perplexity4.098020076751709
INFO:root:current mean train loss 1792.0577259934794
INFO:root:current train perplexity4.096470832824707
INFO:root:current mean train loss 1791.544992444115
INFO:root:current train perplexity4.09725284576416
INFO:root:current mean train loss 1791.2485502697173
INFO:root:current train perplexity4.098402976989746
INFO:root:current mean train loss 1790.6364013671875
INFO:root:current train perplexity4.097996711730957
INFO:root:current mean train loss 1790.9689842726657
INFO:root:current train perplexity4.100316047668457
INFO:root:current mean train loss 1790.9658075537386
INFO:root:current train perplexity4.099716663360596
INFO:root:current mean train loss 1790.5592945119276
INFO:root:current train perplexity4.100483417510986
INFO:root:current mean train loss 1790.5567576142132
INFO:root:current train perplexity4.102749347686768


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.91s/it]
INFO:root:final mean train loss: 1790.08292033801
INFO:root:final train perplexity: 4.1031999588012695
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.84s/it]
INFO:root:eval mean loss: 2861.217993384009
INFO:root:eval perplexity: 10.462925910949707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/64

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [9:31:24<5:18:28, 530.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1789.7193547391344
INFO:root:current train perplexity4.080571174621582
INFO:root:current mean train loss 1790.7486885601186
INFO:root:current train perplexity4.092735767364502
INFO:root:current mean train loss 1790.198473568162
INFO:root:current train perplexity4.085399627685547
INFO:root:current mean train loss 1782.2942670482073
INFO:root:current train perplexity4.082571983337402
INFO:root:current mean train loss 1780.990938472552
INFO:root:current train perplexity4.0833420753479
INFO:root:current mean train loss 1779.1626473577912
INFO:root:current train perplexity4.080153465270996
INFO:root:current mean train loss 1779.888275812807
INFO:root:current train perplexity4.080603122711182
INFO:root:current mean train loss 1779.2203477716507
INFO:root:current train perplexity4.077537536621094
INFO:root:current mean train loss 1782.3531685434575
INFO:root:current train perplexity4.080069065093994
INFO:root:current mean train loss 1784.31992068769
INFO:root:current train perplexity4.08397102355957
INFO:root:current mean train loss 1783.7662191803342
INFO:root:current train perplexity4.082546234130859
INFO:root:current mean train loss 1785.1089761889875
INFO:root:current train perplexity4.087502956390381
INFO:root:current mean train loss 1785.0118975398516
INFO:root:current train perplexity4.087381362915039
INFO:root:current mean train loss 1786.0400236606943
INFO:root:current train perplexity4.090075969696045
INFO:root:current mean train loss 1786.9996896934895
INFO:root:current train perplexity4.0908379554748535
INFO:root:current mean train loss 1787.8800069596232
INFO:root:current train perplexity4.09364652633667
INFO:root:current mean train loss 1787.3265305605596
INFO:root:current train perplexity4.094518184661865
INFO:root:current mean train loss 1786.96923117699
INFO:root:current train perplexity4.092754364013672
INFO:root:current mean train loss 1787.0796915366655
INFO:root:current train perplexity4.093038558959961


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.04s/it]
INFO:root:final mean train loss: 1787.458007196916
INFO:root:final train perplexity: 4.094714164733887
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.45s/it]
INFO:root:eval mean loss: 2861.138328758446
INFO:root:eval perplexity: 10.46224308013916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/65

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [9:40:19<5:10:18, 531.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1766.2284545898438
INFO:root:current train perplexity4.085129261016846
INFO:root:current mean train loss 1773.7325638991135
INFO:root:current train perplexity4.06279993057251
INFO:root:current mean train loss 1786.5041701372932
INFO:root:current train perplexity4.086040496826172
INFO:root:current mean train loss 1783.450933356034
INFO:root:current train perplexity4.074703216552734
INFO:root:current mean train loss 1782.8184711720685
INFO:root:current train perplexity4.075533390045166
INFO:root:current mean train loss 1783.8322417244078
INFO:root:current train perplexity4.076441764831543
INFO:root:current mean train loss 1782.7980249670168
INFO:root:current train perplexity4.0715179443359375
INFO:root:current mean train loss 1782.4339188662443
INFO:root:current train perplexity4.073379993438721
INFO:root:current mean train loss 1784.5727781988494
INFO:root:current train perplexity4.078790187835693
INFO:root:current mean train loss 1784.672136965051
INFO:root:current train perplexity4.07687520980835
INFO:root:current mean train loss 1784.2923466047919
INFO:root:current train perplexity4.074780464172363
INFO:root:current mean train loss 1783.0882192418196
INFO:root:current train perplexity4.0746870040893555
INFO:root:current mean train loss 1783.6127997616993
INFO:root:current train perplexity4.076786518096924
INFO:root:current mean train loss 1783.9996847141008
INFO:root:current train perplexity4.078527450561523
INFO:root:current mean train loss 1783.794662606003
INFO:root:current train perplexity4.079804420471191
INFO:root:current mean train loss 1783.3188392152178
INFO:root:current train perplexity4.07906436920166
INFO:root:current mean train loss 1783.44244392376
INFO:root:current train perplexity4.0780534744262695
INFO:root:current mean train loss 1782.571092059355
INFO:root:current train perplexity4.078950881958008
INFO:root:current mean train loss 1782.9267324375737
INFO:root:current train perplexity4.080713748931885
INFO:root:current mean train loss 1783.6391539373317
INFO:root:current train perplexity4.08183479309082


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.63s/it]
INFO:root:final mean train loss: 1784.0026997053076
INFO:root:final train perplexity: 4.083570957183838
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.72s/it]
INFO:root:eval mean loss: 2860.248388525244
INFO:root:eval perplexity: 10.454605102539062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/66

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [9:49:13<5:01:51, 532.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1749.1772984095983
INFO:root:current train perplexity3.98667311668396
INFO:root:current mean train loss 1779.6950713859117
INFO:root:current train perplexity4.030234336853027
INFO:root:current mean train loss 1771.8920517312995
INFO:root:current train perplexity4.043565273284912
INFO:root:current mean train loss 1779.3502242899388
INFO:root:current train perplexity4.065971851348877
INFO:root:current mean train loss 1782.5901998125742
INFO:root:current train perplexity4.074612617492676
INFO:root:current mean train loss 1782.164130915607
INFO:root:current train perplexity4.076102256774902
INFO:root:current mean train loss 1781.5091128141983
INFO:root:current train perplexity4.072804927825928
INFO:root:current mean train loss 1780.1882864307927
INFO:root:current train perplexity4.063642978668213
INFO:root:current mean train loss 1781.3043635155775
INFO:root:current train perplexity4.066021919250488
INFO:root:current mean train loss 1782.1331874586472
INFO:root:current train perplexity4.067653656005859
INFO:root:current mean train loss 1780.9733012738354
INFO:root:current train perplexity4.068207740783691
INFO:root:current mean train loss 1781.020634783048
INFO:root:current train perplexity4.069222450256348
INFO:root:current mean train loss 1781.2064236977567
INFO:root:current train perplexity4.069429874420166
INFO:root:current mean train loss 1779.3893999537224
INFO:root:current train perplexity4.070489406585693
INFO:root:current mean train loss 1780.2869338720807
INFO:root:current train perplexity4.072694301605225
INFO:root:current mean train loss 1779.9368955071704
INFO:root:current train perplexity4.073381423950195
INFO:root:current mean train loss 1780.8053232295363
INFO:root:current train perplexity4.073764801025391
INFO:root:current mean train loss 1780.9999817710225
INFO:root:current train perplexity4.075675010681152
INFO:root:current mean train loss 1781.9469314566816
INFO:root:current train perplexity4.075570106506348
INFO:root:current mean train loss 1781.369749832749
INFO:root:current train perplexity4.074685573577881


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.79s/it]
INFO:root:final mean train loss: 1781.9109194510763
INFO:root:final train perplexity: 4.076839923858643
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.93s/it]
INFO:root:eval mean loss: 2863.832317913617
INFO:root:eval perplexity: 10.485396385192871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/67

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [9:58:05<4:52:50, 532.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1770.4095266241777
INFO:root:current train perplexity4.056614398956299
INFO:root:current mean train loss 1765.12963690274
INFO:root:current train perplexity4.036909103393555
INFO:root:current mean train loss 1767.8124635840663
INFO:root:current train perplexity4.039670467376709
INFO:root:current mean train loss 1767.43220763799
INFO:root:current train perplexity4.044255256652832
INFO:root:current mean train loss 1770.0198188677225
INFO:root:current train perplexity4.048348426818848
INFO:root:current mean train loss 1774.4139175131418
INFO:root:current train perplexity4.052445888519287
INFO:root:current mean train loss 1777.687174734277
INFO:root:current train perplexity4.054958343505859
INFO:root:current mean train loss 1774.57881623555
INFO:root:current train perplexity4.052850723266602
INFO:root:current mean train loss 1776.3647324008987
INFO:root:current train perplexity4.0558037757873535
INFO:root:current mean train loss 1778.4786142703058
INFO:root:current train perplexity4.05824613571167
INFO:root:current mean train loss 1778.7900685804657
INFO:root:current train perplexity4.061564922332764
INFO:root:current mean train loss 1779.9829128379351
INFO:root:current train perplexity4.061079502105713
INFO:root:current mean train loss 1779.800300856977
INFO:root:current train perplexity4.061191558837891
INFO:root:current mean train loss 1778.6599473254741
INFO:root:current train perplexity4.060879707336426
INFO:root:current mean train loss 1778.76940816102
INFO:root:current train perplexity4.06184196472168
INFO:root:current mean train loss 1779.8478445144872
INFO:root:current train perplexity4.063939094543457
INFO:root:current mean train loss 1779.5282612149679
INFO:root:current train perplexity4.064132213592529
INFO:root:current mean train loss 1779.95789789303
INFO:root:current train perplexity4.0662031173706055
INFO:root:current mean train loss 1780.5989478176643
INFO:root:current train perplexity4.067808628082275
INFO:root:current mean train loss 1779.420484040913
INFO:root:current train perplexity4.067398548126221


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.35s/it]
INFO:root:final mean train loss: 1779.2049681816927
INFO:root:final train perplexity: 4.068149089813232
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:11<00:00, 71.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:11<00:00, 71.23s/it]
INFO:root:eval mean loss: 2864.705177100929
INFO:root:eval perplexity: 10.492908477783203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/68

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [10:07:10<4:45:55, 536.12s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1761.2327814275568
INFO:root:current train perplexity4.0357279777526855
INFO:root:current mean train loss 1780.3675442603326
INFO:root:current train perplexity4.04203462600708
INFO:root:current mean train loss 1778.4604736328124
INFO:root:current train perplexity4.051923751831055
INFO:root:current mean train loss 1781.6319294674295
INFO:root:current train perplexity4.062315464019775
INFO:root:current mean train loss 1780.8588472806491
INFO:root:current train perplexity4.066737174987793
INFO:root:current mean train loss 1777.8998112858953
INFO:root:current train perplexity4.058629035949707
INFO:root:current mean train loss 1777.108792417104
INFO:root:current train perplexity4.056894779205322
INFO:root:current mean train loss 1776.7478501073572
INFO:root:current train perplexity4.050783157348633
INFO:root:current mean train loss 1775.433040221811
INFO:root:current train perplexity4.049713134765625
INFO:root:current mean train loss 1776.0547328769223
INFO:root:current train perplexity4.05128288269043
INFO:root:current mean train loss 1775.4713863716306
INFO:root:current train perplexity4.0511250495910645
INFO:root:current mean train loss 1777.2590097402597
INFO:root:current train perplexity4.054722309112549
INFO:root:current mean train loss 1777.4537282510582
INFO:root:current train perplexity4.055069446563721
INFO:root:current mean train loss 1776.946474014789
INFO:root:current train perplexity4.055075645446777
INFO:root:current mean train loss 1777.474101797412
INFO:root:current train perplexity4.056206703186035
INFO:root:current mean train loss 1777.9550099069284
INFO:root:current train perplexity4.056845188140869
INFO:root:current mean train loss 1779.0033491520724
INFO:root:current train perplexity4.059782028198242
INFO:root:current mean train loss 1777.9795862964077
INFO:root:current train perplexity4.05881404876709
INFO:root:current mean train loss 1777.3659703504043
INFO:root:current train perplexity4.058292865753174
INFO:root:current mean train loss 1776.6641074568415
INFO:root:current train perplexity4.05772066116333


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:59<00:00, 479.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:59<00:00, 479.41s/it]
INFO:root:final mean train loss: 1776.2609644133336
INFO:root:final train perplexity: 4.058714389801025
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.47s/it]
INFO:root:eval mean loss: 2866.3895780546172
INFO:root:eval perplexity: 10.507423400878906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/69

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [10:16:12<4:37:54, 537.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1758.7831336127388
INFO:root:current train perplexity4.036023139953613
INFO:root:current mean train loss 1761.08154296875
INFO:root:current train perplexity4.03196907043457
INFO:root:current mean train loss 1762.1422047334559
INFO:root:current train perplexity4.035894870758057
INFO:root:current mean train loss 1761.7106323242188
INFO:root:current train perplexity4.031150817871094
INFO:root:current mean train loss 1766.4343365168168
INFO:root:current train perplexity4.03293514251709
INFO:root:current mean train loss 1769.363365333397
INFO:root:current train perplexity4.042614459991455
INFO:root:current mean train loss 1770.5904146830242
INFO:root:current train perplexity4.046760559082031
INFO:root:current mean train loss 1769.039287665965
INFO:root:current train perplexity4.0425190925598145
INFO:root:current mean train loss 1767.711965158445
INFO:root:current train perplexity4.043407917022705
INFO:root:current mean train loss 1767.9196296346531
INFO:root:current train perplexity4.043099880218506
INFO:root:current mean train loss 1767.6791188254285
INFO:root:current train perplexity4.042514801025391
INFO:root:current mean train loss 1769.3872289039168
INFO:root:current train perplexity4.045004844665527
INFO:root:current mean train loss 1769.788975361758
INFO:root:current train perplexity4.044907093048096
INFO:root:current mean train loss 1769.276661597605
INFO:root:current train perplexity4.045758247375488
INFO:root:current mean train loss 1770.291103280109
INFO:root:current train perplexity4.047521114349365
INFO:root:current mean train loss 1770.213055559697
INFO:root:current train perplexity4.047174453735352
INFO:root:current mean train loss 1771.929684506649
INFO:root:current train perplexity4.0484619140625
INFO:root:current mean train loss 1772.6536318260175
INFO:root:current train perplexity4.048880577087402
INFO:root:current mean train loss 1773.6455793462248
INFO:root:current train perplexity4.049339294433594
INFO:root:current mean train loss 1773.8232398352322
INFO:root:current train perplexity4.049738883972168


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.78s/it]
INFO:root:final mean train loss: 1773.619948579035
INFO:root:final train perplexity: 4.050268650054932
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:08<00:00, 68.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:08<00:00, 68.21s/it]
INFO:root:eval mean loss: 2867.736037795608
INFO:root:eval perplexity: 10.519039154052734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/70

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [10:25:13<4:29:25, 538.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1763.719356236833
INFO:root:current train perplexity4.068884372711182
INFO:root:current mean train loss 1754.7536123770255
INFO:root:current train perplexity4.033360958099365
INFO:root:current mean train loss 1761.349488994242
INFO:root:current train perplexity4.034759044647217
INFO:root:current mean train loss 1759.8448047000522
INFO:root:current train perplexity4.029776573181152
INFO:root:current mean train loss 1764.7661287584676
INFO:root:current train perplexity4.036275863647461
INFO:root:current mean train loss 1764.8664105193523
INFO:root:current train perplexity4.037883758544922
INFO:root:current mean train loss 1765.9050817392733
INFO:root:current train perplexity4.036708831787109
INFO:root:current mean train loss 1764.838115426222
INFO:root:current train perplexity4.030965805053711
INFO:root:current mean train loss 1766.6307371673756
INFO:root:current train perplexity4.033507347106934
INFO:root:current mean train loss 1768.9026073922523
INFO:root:current train perplexity4.03359317779541
INFO:root:current mean train loss 1767.0756070335815
INFO:root:current train perplexity4.03262996673584
INFO:root:current mean train loss 1766.9296806213533
INFO:root:current train perplexity4.035317897796631
INFO:root:current mean train loss 1767.182755357078
INFO:root:current train perplexity4.035703182220459
INFO:root:current mean train loss 1767.4060676415418
INFO:root:current train perplexity4.037247180938721
INFO:root:current mean train loss 1768.2794787917385
INFO:root:current train perplexity4.03983736038208
INFO:root:current mean train loss 1768.2521116858086
INFO:root:current train perplexity4.040619850158691
INFO:root:current mean train loss 1769.4443850836294
INFO:root:current train perplexity4.040727138519287
INFO:root:current mean train loss 1770.4512876678007
INFO:root:current train perplexity4.0406904220581055
INFO:root:current mean train loss 1771.5373558420047
INFO:root:current train perplexity4.0416059494018555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.60s/it]
INFO:root:final mean train loss: 1771.8251123317732
INFO:root:final train perplexity: 4.044539928436279
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:08<00:00, 68.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:08<00:00, 68.83s/it]
INFO:root:eval mean loss: 2866.129343210398
INFO:root:eval perplexity: 10.505176544189453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/71

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [10:34:14<4:20:41, 539.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1817.3436889648438
INFO:root:current train perplexity4.065887451171875
INFO:root:current mean train loss 1763.0476661538178
INFO:root:current train perplexity3.995178699493408
INFO:root:current mean train loss 1756.15293869463
INFO:root:current train perplexity3.9938087463378906
INFO:root:current mean train loss 1757.4636094835068
INFO:root:current train perplexity3.9954187870025635
INFO:root:current mean train loss 1759.2746061879425
INFO:root:current train perplexity4.005051612854004
INFO:root:current mean train loss 1758.7166936218503
INFO:root:current train perplexity4.005761623382568
INFO:root:current mean train loss 1760.5421001572813
INFO:root:current train perplexity4.010462760925293
INFO:root:current mean train loss 1762.7016326644941
INFO:root:current train perplexity4.015076637268066
INFO:root:current mean train loss 1764.1494760063683
INFO:root:current train perplexity4.016350269317627
INFO:root:current mean train loss 1764.2393717986859
INFO:root:current train perplexity4.016654968261719
INFO:root:current mean train loss 1765.363419580175
INFO:root:current train perplexity4.021900653839111
INFO:root:current mean train loss 1761.338170967309
INFO:root:current train perplexity4.017961502075195
INFO:root:current mean train loss 1763.1356865169594
INFO:root:current train perplexity4.019094944000244
INFO:root:current mean train loss 1765.1391912813756
INFO:root:current train perplexity4.021758556365967
INFO:root:current mean train loss 1765.405036937122
INFO:root:current train perplexity4.024136543273926
INFO:root:current mean train loss 1766.0140480558237
INFO:root:current train perplexity4.024102687835693
INFO:root:current mean train loss 1765.8582804716686
INFO:root:current train perplexity4.026381492614746
INFO:root:current mean train loss 1765.0837585520771
INFO:root:current train perplexity4.025968551635742
INFO:root:current mean train loss 1766.2128735243416
INFO:root:current train perplexity4.029098987579346
INFO:root:current mean train loss 1768.511664503644
INFO:root:current train perplexity4.03188419342041


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.35s/it]
INFO:root:final mean train loss: 1768.2708941838143
INFO:root:final train perplexity: 4.033218860626221
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.57s/it]
INFO:root:eval mean loss: 2870.2454273120775
INFO:root:eval perplexity: 10.540719985961914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/72

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [10:43:07<4:10:48, 537.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1786.858833644701
INFO:root:current train perplexity4.018956661224365
INFO:root:current mean train loss 1775.4377034505208
INFO:root:current train perplexity4.0270819664001465
INFO:root:current mean train loss 1766.845886504169
INFO:root:current train perplexity4.015420913696289
INFO:root:current mean train loss 1766.0437374528346
INFO:root:current train perplexity4.01439905166626
INFO:root:current mean train loss 1765.7139237496306
INFO:root:current train perplexity4.0164079666137695
INFO:root:current mean train loss 1766.4121112422324
INFO:root:current train perplexity4.016491889953613
INFO:root:current mean train loss 1765.1914144794594
INFO:root:current train perplexity4.013576030731201
INFO:root:current mean train loss 1764.6069985966135
INFO:root:current train perplexity4.020468711853027
INFO:root:current mean train loss 1764.68734040382
INFO:root:current train perplexity4.021230697631836
INFO:root:current mean train loss 1765.739750854889
INFO:root:current train perplexity4.024085998535156
INFO:root:current mean train loss 1767.011687247984
INFO:root:current train perplexity4.02480936050415
INFO:root:current mean train loss 1766.869099753729
INFO:root:current train perplexity4.025115966796875
INFO:root:current mean train loss 1766.7206530192789
INFO:root:current train perplexity4.026345729827881
INFO:root:current mean train loss 1766.0736136577027
INFO:root:current train perplexity4.025455951690674
INFO:root:current mean train loss 1765.8081268289102
INFO:root:current train perplexity4.025563716888428
INFO:root:current mean train loss 1766.6202863065803
INFO:root:current train perplexity4.027455806732178
INFO:root:current mean train loss 1767.4317753310565
INFO:root:current train perplexity4.0282793045043945
INFO:root:current mean train loss 1767.5422038799513
INFO:root:current train perplexity4.028501033782959
INFO:root:current mean train loss 1767.633739578155
INFO:root:current train perplexity4.0269904136657715
INFO:root:current mean train loss 1767.3199930731605
INFO:root:current train perplexity4.027885437011719


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.66s/it]
INFO:root:final mean train loss: 1766.842470108471
INFO:root:final train perplexity: 4.028677940368652
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.59s/it]
INFO:root:eval mean loss: 2870.101146801098
INFO:root:eval perplexity: 10.539470672607422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/73

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [10:51:56<4:00:44, 535.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1749.0871002197266
INFO:root:current train perplexity4.035652160644531
INFO:root:current mean train loss 1754.4388148716519
INFO:root:current train perplexity4.00045108795166
INFO:root:current mean train loss 1752.1421895345052
INFO:root:current train perplexity3.9991016387939453
INFO:root:current mean train loss 1756.4751288918887
INFO:root:current train perplexity4.007364749908447
INFO:root:current mean train loss 1761.460249189897
INFO:root:current train perplexity4.012615203857422
INFO:root:current mean train loss 1762.059147813585
INFO:root:current train perplexity4.018685340881348
INFO:root:current mean train loss 1762.3540983200073
INFO:root:current train perplexity4.012888431549072
INFO:root:current mean train loss 1762.3720460633974
INFO:root:current train perplexity4.014155864715576
INFO:root:current mean train loss 1762.9059597923642
INFO:root:current train perplexity4.015133857727051
INFO:root:current mean train loss 1763.1193225617105
INFO:root:current train perplexity4.018712997436523
INFO:root:current mean train loss 1763.7650862473708
INFO:root:current train perplexity4.020754337310791
INFO:root:current mean train loss 1763.6319101434005
INFO:root:current train perplexity4.023162364959717
INFO:root:current mean train loss 1764.3829661707725
INFO:root:current train perplexity4.023822784423828
INFO:root:current mean train loss 1764.759653666482
INFO:root:current train perplexity4.023582458496094
INFO:root:current mean train loss 1763.7424574957954
INFO:root:current train perplexity4.020162105560303
INFO:root:current mean train loss 1763.4891713328175
INFO:root:current train perplexity4.020293712615967
INFO:root:current mean train loss 1764.0019311672304
INFO:root:current train perplexity4.02009391784668
INFO:root:current mean train loss 1764.1830369971265
INFO:root:current train perplexity4.019886016845703
INFO:root:current mean train loss 1764.6572101095448
INFO:root:current train perplexity4.021229267120361
INFO:root:current mean train loss 1765.2015698619725
INFO:root:current train perplexity4.021792888641357


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.72s/it]
INFO:root:final mean train loss: 1764.612653231176
INFO:root:final train perplexity: 4.021599292755127
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.69s/it]
INFO:root:eval mean loss: 2872.309845978791
INFO:root:eval perplexity: 10.55859088897705
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/74

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [11:00:47<3:51:22, 533.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1748.229766310307
INFO:root:current train perplexity3.969933032989502
INFO:root:current mean train loss 1769.2611519394407
INFO:root:current train perplexity4.021493434906006
INFO:root:current mean train loss 1766.3794586537877
INFO:root:current train perplexity4.006252765655518
INFO:root:current mean train loss 1761.4022822019433
INFO:root:current train perplexity4.0018486976623535
INFO:root:current mean train loss 1757.0547307721895
INFO:root:current train perplexity3.9962072372436523
INFO:root:current mean train loss 1759.889007184835
INFO:root:current train perplexity4.0058512687683105
INFO:root:current mean train loss 1760.5882651969177
INFO:root:current train perplexity4.002490520477295
INFO:root:current mean train loss 1759.0013482561199
INFO:root:current train perplexity4.001434803009033
INFO:root:current mean train loss 1759.4765743224457
INFO:root:current train perplexity4.005317211151123
INFO:root:current mean train loss 1758.880512680006
INFO:root:current train perplexity4.003891944885254
INFO:root:current mean train loss 1758.5115410147012
INFO:root:current train perplexity4.0021491050720215
INFO:root:current mean train loss 1760.4626215849855
INFO:root:current train perplexity4.002985954284668
INFO:root:current mean train loss 1759.0318013072108
INFO:root:current train perplexity4.002016544342041
INFO:root:current mean train loss 1760.0506475753616
INFO:root:current train perplexity4.006318092346191
INFO:root:current mean train loss 1760.42542006598
INFO:root:current train perplexity4.0079193115234375
INFO:root:current mean train loss 1760.6420637362264
INFO:root:current train perplexity4.0095086097717285
INFO:root:current mean train loss 1761.4074528751132
INFO:root:current train perplexity4.0115461349487305
INFO:root:current mean train loss 1761.3070825653858
INFO:root:current train perplexity4.011025905609131
INFO:root:current mean train loss 1763.1810167977164
INFO:root:current train perplexity4.016950607299805
INFO:root:current mean train loss 1762.7044942209657
INFO:root:current train perplexity4.015159606933594


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.27s/it]
INFO:root:final mean train loss: 1762.6575883412324
INFO:root:final train perplexity: 4.0154032707214355
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.73s/it]
INFO:root:eval mean loss: 2871.7544619815126
INFO:root:eval perplexity: 10.553780555725098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/75

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [11:09:40<3:42:22, 533.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1766.0660400390625
INFO:root:current train perplexity4.029503345489502
INFO:root:current mean train loss 1751.1979321008441
INFO:root:current train perplexity3.992767333984375
INFO:root:current mean train loss 1756.0502608918796
INFO:root:current train perplexity3.989250421524048
INFO:root:current mean train loss 1755.908412994548
INFO:root:current train perplexity3.9852001667022705
INFO:root:current mean train loss 1758.4182234494494
INFO:root:current train perplexity3.9938607215881348
INFO:root:current mean train loss 1756.7326560203207
INFO:root:current train perplexity3.9968717098236084
INFO:root:current mean train loss 1755.867605147093
INFO:root:current train perplexity3.994340181350708
INFO:root:current mean train loss 1757.9389538037992
INFO:root:current train perplexity3.9995179176330566
INFO:root:current mean train loss 1758.0953098183638
INFO:root:current train perplexity3.998523473739624
INFO:root:current mean train loss 1759.5701313997931
INFO:root:current train perplexity4.00098991394043
INFO:root:current mean train loss 1759.6094183042728
INFO:root:current train perplexity3.999513626098633
INFO:root:current mean train loss 1759.8025070788303
INFO:root:current train perplexity3.998492956161499
INFO:root:current mean train loss 1758.4411158299708
INFO:root:current train perplexity3.9978280067443848
INFO:root:current mean train loss 1760.5499200945858
INFO:root:current train perplexity4.003637313842773
INFO:root:current mean train loss 1759.65861836282
INFO:root:current train perplexity4.003087043762207
INFO:root:current mean train loss 1759.0582083831748
INFO:root:current train perplexity4.002835273742676
INFO:root:current mean train loss 1759.3923008780896
INFO:root:current train perplexity4.004006385803223
INFO:root:current mean train loss 1759.1308176068603
INFO:root:current train perplexity4.003640174865723
INFO:root:current mean train loss 1759.6296378902082
INFO:root:current train perplexity4.004478931427002
INFO:root:current mean train loss 1759.7232377227197
INFO:root:current train perplexity4.004987716674805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.01s/it]
INFO:root:final mean train loss: 1759.4319908923112
INFO:root:final train perplexity: 4.00520133972168
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.99s/it]
INFO:root:eval mean loss: 2873.993866425019
INFO:root:eval perplexity: 10.573188781738281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/76

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [11:18:27<3:32:40, 531.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1758.6519949776787
INFO:root:current train perplexity4.021687030792236
INFO:root:current mean train loss 1763.6857303000245
INFO:root:current train perplexity4.028984069824219
INFO:root:current mean train loss 1758.6829661995275
INFO:root:current train perplexity4.0115742683410645
INFO:root:current mean train loss 1757.804616942735
INFO:root:current train perplexity4.004472255706787
INFO:root:current mean train loss 1757.8099089270938
INFO:root:current train perplexity4.00371789932251
INFO:root:current mean train loss 1755.8781234302294
INFO:root:current train perplexity3.993727445602417
INFO:root:current mean train loss 1755.8794862164775
INFO:root:current train perplexity3.9940121173858643
INFO:root:current mean train loss 1757.823696980434
INFO:root:current train perplexity3.995039701461792
INFO:root:current mean train loss 1757.4188958541579
INFO:root:current train perplexity3.9959518909454346
INFO:root:current mean train loss 1757.2861499343703
INFO:root:current train perplexity3.997161388397217
INFO:root:current mean train loss 1758.2835851122106
INFO:root:current train perplexity3.9977171421051025
INFO:root:current mean train loss 1759.3121542878555
INFO:root:current train perplexity4.0000433921813965
INFO:root:current mean train loss 1758.2979890452532
INFO:root:current train perplexity3.9990453720092773
INFO:root:current mean train loss 1758.5172870342549
INFO:root:current train perplexity4.000274658203125
INFO:root:current mean train loss 1758.7192523631372
INFO:root:current train perplexity3.9996213912963867
INFO:root:current mean train loss 1759.0274190177413
INFO:root:current train perplexity4.000369071960449
INFO:root:current mean train loss 1758.3031253465035
INFO:root:current train perplexity3.9981465339660645
INFO:root:current mean train loss 1758.802376138505
INFO:root:current train perplexity4.0002360343933105
INFO:root:current mean train loss 1758.2938081367126
INFO:root:current train perplexity3.9999823570251465


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.30s/it]
INFO:root:final mean train loss: 1758.3873874589283
INFO:root:final train perplexity: 4.001903533935547
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.86s/it]
INFO:root:eval mean loss: 2876.3284798470345
INFO:root:eval perplexity: 10.593465805053711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/77

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [11:27:35<3:25:41, 536.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1712.680435180664
INFO:root:current train perplexity3.8886327743530273
INFO:root:current mean train loss 1746.6106556080006
INFO:root:current train perplexity3.978970766067505
INFO:root:current mean train loss 1752.5158133873572
INFO:root:current train perplexity3.9744927883148193
INFO:root:current mean train loss 1753.085373519303
INFO:root:current train perplexity3.978484630584717
INFO:root:current mean train loss 1754.098892211914
INFO:root:current train perplexity3.9763214588165283
INFO:root:current mean train loss 1752.1546455443374
INFO:root:current train perplexity3.974731922149658
INFO:root:current mean train loss 1752.091627422132
INFO:root:current train perplexity3.976735830307007
INFO:root:current mean train loss 1751.5811671025335
INFO:root:current train perplexity3.980173349380493
INFO:root:current mean train loss 1754.927049995649
INFO:root:current train perplexity3.9851489067077637
INFO:root:current mean train loss 1755.371907238393
INFO:root:current train perplexity3.9872772693634033
INFO:root:current mean train loss 1756.0948508126396
INFO:root:current train perplexity3.987065315246582
INFO:root:current mean train loss 1754.5268010438995
INFO:root:current train perplexity3.9865078926086426
INFO:root:current mean train loss 1753.6001057403766
INFO:root:current train perplexity3.9843897819519043
INFO:root:current mean train loss 1753.9685042728343
INFO:root:current train perplexity3.985558032989502
INFO:root:current mean train loss 1754.7661196101797
INFO:root:current train perplexity3.9889297485351562
INFO:root:current mean train loss 1755.03296351749
INFO:root:current train perplexity3.98954176902771
INFO:root:current mean train loss 1754.5489932387623
INFO:root:current train perplexity3.989839553833008
INFO:root:current mean train loss 1756.2166105533931
INFO:root:current train perplexity3.992046594619751
INFO:root:current mean train loss 1756.0220978323337
INFO:root:current train perplexity3.992302656173706
INFO:root:current mean train loss 1755.5847001625557
INFO:root:current train perplexity3.99235463142395


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.97s/it]
INFO:root:final mean train loss: 1756.0047441829772
INFO:root:final train perplexity: 3.9943907260894775
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.09s/it]
INFO:root:eval mean loss: 2875.847851269238
INFO:root:eval perplexity: 10.589288711547852
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/78

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [11:36:43<3:17:59, 539.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1757.3565625
INFO:root:current train perplexity4.01681661605835
INFO:root:current mean train loss 1742.47358984375
INFO:root:current train perplexity3.9657437801361084
INFO:root:current mean train loss 1752.1542317708333
INFO:root:current train perplexity3.9958560466766357
INFO:root:current mean train loss 1747.6580322265625
INFO:root:current train perplexity3.990140676498413
INFO:root:current mean train loss 1751.5865458409926
INFO:root:current train perplexity3.9903790950775146
INFO:root:current mean train loss 1751.61782203311
INFO:root:current train perplexity3.9895405769348145
INFO:root:current mean train loss 1752.770082421875
INFO:root:current train perplexity3.987464189529419
INFO:root:current mean train loss 1752.9645100350215
INFO:root:current train perplexity3.9851152896881104
INFO:root:current mean train loss 1752.6161999881629
INFO:root:current train perplexity3.987438917160034
INFO:root:current mean train loss 1750.9637825960726
INFO:root:current train perplexity3.9855189323425293
INFO:root:current mean train loss 1750.7492526915016
INFO:root:current train perplexity3.986480712890625
INFO:root:current mean train loss 1752.4964659288194
INFO:root:current train perplexity3.9879372119903564
INFO:root:current mean train loss 1753.032361188616
INFO:root:current train perplexity3.989069700241089
INFO:root:current mean train loss 1754.1938845076652
INFO:root:current train perplexity3.98991060256958
INFO:root:current mean train loss 1753.2104184655975
INFO:root:current train perplexity3.986997365951538
INFO:root:current mean train loss 1753.3518152055583
INFO:root:current train perplexity3.9871318340301514
INFO:root:current mean train loss 1753.4959657451923
INFO:root:current train perplexity3.9857821464538574
INFO:root:current mean train loss 1754.5837299026268
INFO:root:current train perplexity3.986884593963623
INFO:root:current mean train loss 1754.6069886424443
INFO:root:current train perplexity3.9907615184783936
INFO:root:current mean train loss 1754.8986219688516
INFO:root:current train perplexity3.990283489227295


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.59s/it]
INFO:root:final mean train loss: 1754.6486861343883
INFO:root:final train perplexity: 3.990121603012085
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.94s/it]
INFO:root:eval mean loss: 2875.906859984985
INFO:root:eval perplexity: 10.589801788330078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/79

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [11:45:54<3:10:08, 543.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1751.574215843564
INFO:root:current train perplexity3.9581940174102783
INFO:root:current mean train loss 1750.227715290768
INFO:root:current train perplexity3.976940631866455
INFO:root:current mean train loss 1749.2549211486312
INFO:root:current train perplexity3.9747655391693115
INFO:root:current mean train loss 1756.3017603110152
INFO:root:current train perplexity3.986517906188965
INFO:root:current mean train loss 1754.135620945719
INFO:root:current train perplexity3.976325750350952
INFO:root:current mean train loss 1755.346722479676
INFO:root:current train perplexity3.9783570766448975
INFO:root:current mean train loss 1755.3440994785583
INFO:root:current train perplexity3.9769084453582764
INFO:root:current mean train loss 1754.692368828704
INFO:root:current train perplexity3.9805164337158203
INFO:root:current mean train loss 1756.0543813093825
INFO:root:current train perplexity3.9880640506744385
INFO:root:current mean train loss 1757.2793825315568
INFO:root:current train perplexity3.991966724395752
INFO:root:current mean train loss 1755.59384852316
INFO:root:current train perplexity3.989999532699585
INFO:root:current mean train loss 1754.1075099537543
INFO:root:current train perplexity3.9868509769439697
INFO:root:current mean train loss 1754.6766343661936
INFO:root:current train perplexity3.986726999282837
INFO:root:current mean train loss 1754.2036345662375
INFO:root:current train perplexity3.9869801998138428
INFO:root:current mean train loss 1754.1797180599049
INFO:root:current train perplexity3.985776424407959
INFO:root:current mean train loss 1754.1429716473888
INFO:root:current train perplexity3.9856390953063965
INFO:root:current mean train loss 1755.1064386960215
INFO:root:current train perplexity3.987814426422119
INFO:root:current mean train loss 1754.46411490194
INFO:root:current train perplexity3.9873881340026855
INFO:root:current mean train loss 1753.1698355907727
INFO:root:current train perplexity3.9865405559539795
INFO:root:current mean train loss 1753.288157784239
INFO:root:current train perplexity3.9861040115356445


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.96s/it]
INFO:root:final mean train loss: 1752.9778500555503
INFO:root:final train perplexity: 3.984866142272949
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.50s/it]
INFO:root:eval mean loss: 2880.181142812735
INFO:root:eval perplexity: 10.6270112991333
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/80

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [11:54:43<2:59:39, 539.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1736.9900605799787
INFO:root:current train perplexity3.9961366653442383
INFO:root:current mean train loss 1752.3170089241844
INFO:root:current train perplexity3.9882802963256836
INFO:root:current mean train loss 1745.5705589971947
INFO:root:current train perplexity3.970149040222168
INFO:root:current mean train loss 1744.3566731317462
INFO:root:current train perplexity3.971250057220459
INFO:root:current mean train loss 1744.4031814874388
INFO:root:current train perplexity3.9658944606781006
INFO:root:current mean train loss 1744.2476068541062
INFO:root:current train perplexity3.959699869155884
INFO:root:current mean train loss 1745.0035739371917
INFO:root:current train perplexity3.9575536251068115
INFO:root:current mean train loss 1746.658582363204
INFO:root:current train perplexity3.9632341861724854
INFO:root:current mean train loss 1747.1459818830035
INFO:root:current train perplexity3.9665658473968506
INFO:root:current mean train loss 1746.5672612513442
INFO:root:current train perplexity3.9676990509033203
INFO:root:current mean train loss 1746.3340519228784
INFO:root:current train perplexity3.9679644107818604
INFO:root:current mean train loss 1747.9677975566558
INFO:root:current train perplexity3.969175100326538
INFO:root:current mean train loss 1749.3163784230105
INFO:root:current train perplexity3.972505569458008
INFO:root:current mean train loss 1749.4776475694443
INFO:root:current train perplexity3.974790334701538
INFO:root:current mean train loss 1749.8338372882217
INFO:root:current train perplexity3.9762110710144043
INFO:root:current mean train loss 1750.0850406473
INFO:root:current train perplexity3.9757120609283447
INFO:root:current mean train loss 1750.4753919053035
INFO:root:current train perplexity3.977559804916382
INFO:root:current mean train loss 1750.3449255253117
INFO:root:current train perplexity3.9770116806030273
INFO:root:current mean train loss 1750.4168690665554
INFO:root:current train perplexity3.976438045501709
INFO:root:current mean train loss 1750.7516219337233
INFO:root:current train perplexity3.9774465560913086


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.64s/it]
INFO:root:final mean train loss: 1750.768498115328
INFO:root:final train perplexity: 3.97792911529541
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.64s/it]
INFO:root:eval mean loss: 2879.8597855668168
INFO:root:eval perplexity: 10.624204635620117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/81

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [12:03:56<2:52:01, 543.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1754.2733507658306
INFO:root:current train perplexity4.017068862915039
INFO:root:current mean train loss 1757.058928749778
INFO:root:current train perplexity3.996776819229126
INFO:root:current mean train loss 1757.1425838746886
INFO:root:current train perplexity3.987334728240967
INFO:root:current mean train loss 1749.8511511620054
INFO:root:current train perplexity3.970432996749878
INFO:root:current mean train loss 1748.6869011886981
INFO:root:current train perplexity3.970181703567505
INFO:root:current mean train loss 1749.255873998006
INFO:root:current train perplexity3.9702441692352295
INFO:root:current mean train loss 1749.0295420990892
INFO:root:current train perplexity3.9693922996520996
INFO:root:current mean train loss 1747.926008873379
INFO:root:current train perplexity3.9702019691467285
INFO:root:current mean train loss 1749.8146654938998
INFO:root:current train perplexity3.9671614170074463
INFO:root:current mean train loss 1749.9816895781971
INFO:root:current train perplexity3.9678711891174316
INFO:root:current mean train loss 1747.664696221901
INFO:root:current train perplexity3.9657812118530273
INFO:root:current mean train loss 1747.537152867739
INFO:root:current train perplexity3.9682250022888184
INFO:root:current mean train loss 1749.2915916323288
INFO:root:current train perplexity3.9709110260009766
INFO:root:current mean train loss 1749.930315860482
INFO:root:current train perplexity3.9708826541900635
INFO:root:current mean train loss 1750.3465447154472
INFO:root:current train perplexity3.969895362854004
INFO:root:current mean train loss 1750.6588308266578
INFO:root:current train perplexity3.9709994792938232
INFO:root:current mean train loss 1751.2991182969122
INFO:root:current train perplexity3.971750259399414
INFO:root:current mean train loss 1750.137246003022
INFO:root:current train perplexity3.971095561981201
INFO:root:current mean train loss 1749.655909426431
INFO:root:current train perplexity3.972409963607788
INFO:root:current mean train loss 1749.7018025510224
INFO:root:current train perplexity3.972862720489502


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.88s/it]
INFO:root:final mean train loss: 1749.0122628955005
INFO:root:final train perplexity: 3.9724233150482178
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.31s/it]
INFO:root:eval mean loss: 2878.466841597457
INFO:root:eval perplexity: 10.612068176269531
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/82

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [12:13:12<2:44:05, 546.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1750.5495999243951
INFO:root:current train perplexity3.9721524715423584
INFO:root:current mean train loss 1760.251533152526
INFO:root:current train perplexity3.979947566986084
INFO:root:current mean train loss 1746.700721922995
INFO:root:current train perplexity3.9679861068725586
INFO:root:current mean train loss 1746.6383361039877
INFO:root:current train perplexity3.9679057598114014
INFO:root:current mean train loss 1745.880569674664
INFO:root:current train perplexity3.963923692703247
INFO:root:current mean train loss 1744.5131959448777
INFO:root:current train perplexity3.965402841567993
INFO:root:current mean train loss 1745.2302196772412
INFO:root:current train perplexity3.9687609672546387
INFO:root:current mean train loss 1744.8950050613769
INFO:root:current train perplexity3.9696927070617676
INFO:root:current mean train loss 1745.775723618596
INFO:root:current train perplexity3.974149227142334
INFO:root:current mean train loss 1747.8230828691464
INFO:root:current train perplexity3.976868152618408
INFO:root:current mean train loss 1747.2157105273973
INFO:root:current train perplexity3.9744203090667725
INFO:root:current mean train loss 1746.3746463746857
INFO:root:current train perplexity3.9719913005828857
INFO:root:current mean train loss 1746.4687668991385
INFO:root:current train perplexity3.9715936183929443
INFO:root:current mean train loss 1747.283785522198
INFO:root:current train perplexity3.970677137374878
INFO:root:current mean train loss 1747.183164500743
INFO:root:current train perplexity3.969514846801758
INFO:root:current mean train loss 1748.1826695252423
INFO:root:current train perplexity3.970802068710327
INFO:root:current mean train loss 1748.7579600947606
INFO:root:current train perplexity3.9711670875549316
INFO:root:current mean train loss 1748.570939531555
INFO:root:current train perplexity3.9719927310943604
INFO:root:current mean train loss 1749.1691084598274
INFO:root:current train perplexity3.971165180206299


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.18s/it]
INFO:root:final mean train loss: 1748.1639148829504
INFO:root:final train perplexity: 3.969766616821289
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.94s/it]
INFO:root:eval mean loss: 2878.207862647804
INFO:root:eval perplexity: 10.609814643859863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/83

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [12:22:24<2:35:22, 548.38s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1768.6714721679687
INFO:root:current train perplexity3.9669859409332275
INFO:root:current mean train loss 1747.9355934836647
INFO:root:current train perplexity3.948937177658081
INFO:root:current mean train loss 1750.1446742466517
INFO:root:current train perplexity3.950805902481079
INFO:root:current mean train loss 1748.5235123172884
INFO:root:current train perplexity3.955885410308838
INFO:root:current mean train loss 1743.9554571384338
INFO:root:current train perplexity3.9550225734710693
INFO:root:current mean train loss 1742.97092739928
INFO:root:current train perplexity3.9615478515625
INFO:root:current mean train loss 1744.0990352443007
INFO:root:current train perplexity3.9662888050079346
INFO:root:current mean train loss 1743.146991740482
INFO:root:current train perplexity3.9650144577026367
INFO:root:current mean train loss 1744.0598525812597
INFO:root:current train perplexity3.9646739959716797
INFO:root:current mean train loss 1744.6577313433636
INFO:root:current train perplexity3.963156223297119
INFO:root:current mean train loss 1744.1317223275062
INFO:root:current train perplexity3.960050582885742
INFO:root:current mean train loss 1744.68269185934
INFO:root:current train perplexity3.9629290103912354
INFO:root:current mean train loss 1745.5444536697767
INFO:root:current train perplexity3.9647114276885986
INFO:root:current mean train loss 1746.666610787661
INFO:root:current train perplexity3.9656143188476562
INFO:root:current mean train loss 1746.300319200881
INFO:root:current train perplexity3.966451644897461
INFO:root:current mean train loss 1747.2429533901593
INFO:root:current train perplexity3.9670629501342773
INFO:root:current mean train loss 1747.0983478048574
INFO:root:current train perplexity3.965505599975586
INFO:root:current mean train loss 1746.850099083973
INFO:root:current train perplexity3.9646403789520264
INFO:root:current mean train loss 1745.7105712216203
INFO:root:current train perplexity3.9645180702209473
INFO:root:current mean train loss 1746.384920993026
INFO:root:current train perplexity3.963758707046509


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.08s/it]
INFO:root:final mean train loss: 1746.018876945738
INFO:root:final train perplexity: 3.9630560874938965
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.43s/it]
INFO:root:eval mean loss: 2880.6048910238364
INFO:root:eval perplexity: 10.630706787109375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/84

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [12:31:38<2:26:44, 550.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1725.8845305266204
INFO:root:current train perplexity3.940873384475708
INFO:root:current mean train loss 1732.2867989127092
INFO:root:current train perplexity3.9511828422546387
INFO:root:current mean train loss 1738.0109546005988
INFO:root:current train perplexity3.956874370574951
INFO:root:current mean train loss 1741.348758242546
INFO:root:current train perplexity3.9541499614715576
INFO:root:current mean train loss 1740.5189820765331
INFO:root:current train perplexity3.946209669113159
INFO:root:current mean train loss 1739.4851720473346
INFO:root:current train perplexity3.950110912322998
INFO:root:current mean train loss 1739.508158073851
INFO:root:current train perplexity3.9530394077301025
INFO:root:current mean train loss 1739.5655314407454
INFO:root:current train perplexity3.9525527954101562
INFO:root:current mean train loss 1739.7149132725117
INFO:root:current train perplexity3.9523322582244873
INFO:root:current mean train loss 1741.1774779878388
INFO:root:current train perplexity3.9528415203094482
INFO:root:current mean train loss 1741.3724648123707
INFO:root:current train perplexity3.95206880569458
INFO:root:current mean train loss 1742.6701743558326
INFO:root:current train perplexity3.9535956382751465
INFO:root:current mean train loss 1743.4313653450042
INFO:root:current train perplexity3.954129695892334
INFO:root:current mean train loss 1743.9453226188655
INFO:root:current train perplexity3.955777406692505
INFO:root:current mean train loss 1745.3741072699502
INFO:root:current train perplexity3.9578773975372314
INFO:root:current mean train loss 1745.7579384874346
INFO:root:current train perplexity3.9575207233428955
INFO:root:current mean train loss 1745.9314353488014
INFO:root:current train perplexity3.9579038619995117
INFO:root:current mean train loss 1745.9488451173006
INFO:root:current train perplexity3.959322452545166
INFO:root:current mean train loss 1745.1693971797815
INFO:root:current train perplexity3.958580493927002
INFO:root:current mean train loss 1744.7882451926976
INFO:root:current train perplexity3.958125114440918


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.06s/it]
INFO:root:final mean train loss: 1744.643554225812
INFO:root:final train perplexity: 3.9587602615356445
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.95s/it]
INFO:root:eval mean loss: 2878.7102138759856
INFO:root:eval perplexity: 10.614189147949219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/85

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [12:40:55<2:18:03, 552.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1713.7753823020241
INFO:root:current train perplexity3.935640573501587
INFO:root:current mean train loss 1719.1755752563477
INFO:root:current train perplexity3.951925754547119
INFO:root:current mean train loss 1734.6019927478228
INFO:root:current train perplexity3.962798595428467
INFO:root:current mean train loss 1736.3031683633494
INFO:root:current train perplexity3.9519312381744385
INFO:root:current mean train loss 1739.7346224398227
INFO:root:current train perplexity3.9566853046417236
INFO:root:current mean train loss 1743.865307303036
INFO:root:current train perplexity3.959801435470581
INFO:root:current mean train loss 1746.2188745344647
INFO:root:current train perplexity3.956057548522949
INFO:root:current mean train loss 1744.3925882975261
INFO:root:current train perplexity3.9533143043518066
INFO:root:current mean train loss 1745.8772044972786
INFO:root:current train perplexity3.9551327228546143
INFO:root:current mean train loss 1743.9980803667488
INFO:root:current train perplexity3.952122211456299
INFO:root:current mean train loss 1742.9160774786353
INFO:root:current train perplexity3.9553582668304443
INFO:root:current mean train loss 1742.821972720273
INFO:root:current train perplexity3.9533631801605225
INFO:root:current mean train loss 1742.5954961746068
INFO:root:current train perplexity3.952942371368408
INFO:root:current mean train loss 1741.644578479585
INFO:root:current train perplexity3.9527218341827393
INFO:root:current mean train loss 1742.469322648405
INFO:root:current train perplexity3.953512668609619
INFO:root:current mean train loss 1742.5714981790652
INFO:root:current train perplexity3.952834129333496
INFO:root:current mean train loss 1743.395821601515
INFO:root:current train perplexity3.953953742980957
INFO:root:current mean train loss 1743.3894589625368
INFO:root:current train perplexity3.952603578567505
INFO:root:current mean train loss 1743.5752780608138
INFO:root:current train perplexity3.953707218170166
INFO:root:current mean train loss 1743.771861511984
INFO:root:current train perplexity3.9529240131378174


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 476.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 476.90s/it]
INFO:root:final mean train loss: 1742.7474906948319
INFO:root:final train perplexity: 3.9528448581695557
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.91s/it]
INFO:root:eval mean loss: 2882.521900807057
INFO:root:eval perplexity: 10.647442817687988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/86

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [12:50:16<2:09:26, 554.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1736.5056832735656
INFO:root:current train perplexity3.9323456287384033
INFO:root:current mean train loss 1724.0945044096952
INFO:root:current train perplexity3.9292566776275635
INFO:root:current mean train loss 1728.353152687979
INFO:root:current train perplexity3.9274322986602783
INFO:root:current mean train loss 1732.5063287201351
INFO:root:current train perplexity3.9344851970672607
INFO:root:current mean train loss 1732.708494769777
INFO:root:current train perplexity3.940232276916504
INFO:root:current mean train loss 1733.9188436960367
INFO:root:current train perplexity3.946396827697754
INFO:root:current mean train loss 1735.0175051782928
INFO:root:current train perplexity3.946286678314209
INFO:root:current mean train loss 1736.141661394598
INFO:root:current train perplexity3.9473891258239746
INFO:root:current mean train loss 1737.6494815485264
INFO:root:current train perplexity3.9479873180389404
INFO:root:current mean train loss 1738.1253110824093
INFO:root:current train perplexity3.9462039470672607
INFO:root:current mean train loss 1739.3280490655925
INFO:root:current train perplexity3.95001482963562
INFO:root:current mean train loss 1740.3695530985883
INFO:root:current train perplexity3.9495303630828857
INFO:root:current mean train loss 1739.796372391703
INFO:root:current train perplexity3.9462943077087402
INFO:root:current mean train loss 1740.2329663929038
INFO:root:current train perplexity3.9474925994873047
INFO:root:current mean train loss 1741.2715956670304
INFO:root:current train perplexity3.9517738819122314
INFO:root:current mean train loss 1741.5356948138963
INFO:root:current train perplexity3.950840950012207
INFO:root:current mean train loss 1741.2012254507122
INFO:root:current train perplexity3.948793649673462
INFO:root:current mean train loss 1741.2377174113165
INFO:root:current train perplexity3.9486169815063477
INFO:root:current mean train loss 1741.9938478792694
INFO:root:current train perplexity3.9494454860687256
INFO:root:current mean train loss 1742.4439300739418
INFO:root:current train perplexity3.9504852294921875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.86s/it]
INFO:root:final mean train loss: 1741.8375007140776
INFO:root:final train perplexity: 3.9500091075897217
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.45s/it]
INFO:root:eval mean loss: 2882.3974726679803
INFO:root:eval perplexity: 10.646353721618652
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/87

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [12:59:29<2:00:05, 554.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1745.8016639122595
INFO:root:current train perplexity3.957031011581421
INFO:root:current mean train loss 1743.6593435908972
INFO:root:current train perplexity3.933934211730957
INFO:root:current mean train loss 1746.4942771856734
INFO:root:current train perplexity3.9393436908721924
INFO:root:current mean train loss 1748.0621263615037
INFO:root:current train perplexity3.9495763778686523
INFO:root:current mean train loss 1748.3035280874085
INFO:root:current train perplexity3.9508936405181885
INFO:root:current mean train loss 1746.4258241224454
INFO:root:current train perplexity3.9507851600646973
INFO:root:current mean train loss 1744.7823900430956
INFO:root:current train perplexity3.948580741882324
INFO:root:current mean train loss 1741.8520107710576
INFO:root:current train perplexity3.9460554122924805
INFO:root:current mean train loss 1740.5524917637297
INFO:root:current train perplexity3.943035125732422
INFO:root:current mean train loss 1739.381429286091
INFO:root:current train perplexity3.941601276397705
INFO:root:current mean train loss 1739.9382868892408
INFO:root:current train perplexity3.9412291049957275
INFO:root:current mean train loss 1740.2271222825366
INFO:root:current train perplexity3.9386298656463623
INFO:root:current mean train loss 1740.523594242866
INFO:root:current train perplexity3.938843011856079
INFO:root:current mean train loss 1739.4441664741416
INFO:root:current train perplexity3.939258098602295
INFO:root:current mean train loss 1740.1427577616237
INFO:root:current train perplexity3.9430336952209473
INFO:root:current mean train loss 1740.6686337933945
INFO:root:current train perplexity3.943995952606201
INFO:root:current mean train loss 1741.838159863514
INFO:root:current train perplexity3.94686222076416
INFO:root:current mean train loss 1741.3001049887075
INFO:root:current train perplexity3.947348117828369
INFO:root:current mean train loss 1741.3703192730172
INFO:root:current train perplexity3.947601318359375
INFO:root:current mean train loss 1741.3453952955163
INFO:root:current train perplexity3.947216033935547


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:01<00:00, 481.22s/it]
INFO:root:final mean train loss: 1740.880673191611
INFO:root:final train perplexity: 3.9470295906066895
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.61s/it]
INFO:root:eval mean loss: 2881.8448915223817
INFO:root:eval perplexity: 10.64152717590332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/88

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [13:08:30<1:50:03, 550.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1758.0952161287007
INFO:root:current train perplexity3.9726505279541016
INFO:root:current mean train loss 1748.3365885416667
INFO:root:current train perplexity3.945605754852295
INFO:root:current mean train loss 1744.257664774232
INFO:root:current train perplexity3.944150686264038
INFO:root:current mean train loss 1739.3177963063686
INFO:root:current train perplexity3.9353089332580566
INFO:root:current mean train loss 1738.1099991615372
INFO:root:current train perplexity3.929764986038208
INFO:root:current mean train loss 1736.1402987952993
INFO:root:current train perplexity3.925727605819702
INFO:root:current mean train loss 1737.4543934774056
INFO:root:current train perplexity3.9340133666992188
INFO:root:current mean train loss 1739.7549517553557
INFO:root:current train perplexity3.9377331733703613
INFO:root:current mean train loss 1739.3317005008294
INFO:root:current train perplexity3.9402246475219727
INFO:root:current mean train loss 1738.6024698688757
INFO:root:current train perplexity3.9375877380371094
INFO:root:current mean train loss 1739.1273052894906
INFO:root:current train perplexity3.9379758834838867
INFO:root:current mean train loss 1738.3214580200706
INFO:root:current train perplexity3.9357030391693115
INFO:root:current mean train loss 1738.4182751040662
INFO:root:current train perplexity3.9358110427856445
INFO:root:current mean train loss 1737.1101373487904
INFO:root:current train perplexity3.936711311340332
INFO:root:current mean train loss 1737.6455889749686
INFO:root:current train perplexity3.9341959953308105
INFO:root:current mean train loss 1737.6377678658896
INFO:root:current train perplexity3.934908866882324
INFO:root:current mean train loss 1737.9961305511385
INFO:root:current train perplexity3.936523199081421
INFO:root:current mean train loss 1738.8063777827952
INFO:root:current train perplexity3.9402618408203125
INFO:root:current mean train loss 1739.2706144227202
INFO:root:current train perplexity3.941150188446045


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 476.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 476.28s/it]
INFO:root:final mean train loss: 1738.8820501607413
INFO:root:final train perplexity: 3.940812826156616
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.26s/it]
INFO:root:eval mean loss: 2881.72559620167
INFO:root:eval perplexity: 10.640486717224121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/89

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [13:17:26<1:40:07, 546.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1722.4751078287761
INFO:root:current train perplexity3.9050421714782715
INFO:root:current mean train loss 1745.8642480032784
INFO:root:current train perplexity3.9502880573272705
INFO:root:current mean train loss 1735.9281823500148
INFO:root:current train perplexity3.9354782104492188
INFO:root:current mean train loss 1734.0472893348108
INFO:root:current train perplexity3.933537483215332
INFO:root:current mean train loss 1736.6839389245488
INFO:root:current train perplexity3.9402496814727783
INFO:root:current mean train loss 1735.8212196826935
INFO:root:current train perplexity3.9373679161071777
INFO:root:current mean train loss 1733.9956174364277
INFO:root:current train perplexity3.935033082962036
INFO:root:current mean train loss 1733.0206832028507
INFO:root:current train perplexity3.931713819503784
INFO:root:current mean train loss 1732.6604638311076
INFO:root:current train perplexity3.927741289138794
INFO:root:current mean train loss 1732.8339903982062
INFO:root:current train perplexity3.9277656078338623
INFO:root:current mean train loss 1734.233658259094
INFO:root:current train perplexity3.928632974624634
INFO:root:current mean train loss 1734.2959382859924
INFO:root:current train perplexity3.9315037727355957
INFO:root:current mean train loss 1734.6603379454157
INFO:root:current train perplexity3.9335834980010986
INFO:root:current mean train loss 1736.3088236552912
INFO:root:current train perplexity3.9339730739593506
INFO:root:current mean train loss 1737.4553684310265
INFO:root:current train perplexity3.9344608783721924
INFO:root:current mean train loss 1737.6353900243366
INFO:root:current train perplexity3.9352900981903076
INFO:root:current mean train loss 1736.8341412035466
INFO:root:current train perplexity3.9350194931030273
INFO:root:current mean train loss 1737.4400087160484
INFO:root:current train perplexity3.9370577335357666
INFO:root:current mean train loss 1737.7800584670986
INFO:root:current train perplexity3.9376163482666016
INFO:root:current mean train loss 1738.9542146307654
INFO:root:current train perplexity3.9399542808532715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:58<00:00, 478.05s/it]
INFO:root:final mean train loss: 1738.7327194483184
INFO:root:final train perplexity: 3.9403491020202637
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.61s/it]
INFO:root:eval mean loss: 2883.599917300113
INFO:root:eval perplexity: 10.656862258911133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/90

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [13:26:25<1:30:38, 543.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1712.388356175916
INFO:root:current train perplexity3.9448437690734863
INFO:root:current mean train loss 1727.4882935516594
INFO:root:current train perplexity3.911346197128296
INFO:root:current mean train loss 1735.8992402855486
INFO:root:current train perplexity3.918388843536377
INFO:root:current mean train loss 1739.4959980231288
INFO:root:current train perplexity3.9267642498016357
INFO:root:current mean train loss 1742.8913486009433
INFO:root:current train perplexity3.9270718097686768
INFO:root:current mean train loss 1740.4439233444589
INFO:root:current train perplexity3.9278910160064697
INFO:root:current mean train loss 1741.240686753217
INFO:root:current train perplexity3.932605028152466
INFO:root:current mean train loss 1740.9885649085863
INFO:root:current train perplexity3.928018569946289
INFO:root:current mean train loss 1741.4421690053905
INFO:root:current train perplexity3.931309461593628
INFO:root:current mean train loss 1739.740818183825
INFO:root:current train perplexity3.930422782897949
INFO:root:current mean train loss 1739.6782162502277
INFO:root:current train perplexity3.930561065673828
INFO:root:current mean train loss 1737.100587018725
INFO:root:current train perplexity3.9275286197662354
INFO:root:current mean train loss 1737.7142021110913
INFO:root:current train perplexity3.9298057556152344
INFO:root:current mean train loss 1737.2792879654287
INFO:root:current train perplexity3.9321506023406982
INFO:root:current mean train loss 1736.6737692681454
INFO:root:current train perplexity3.9336819648742676
INFO:root:current mean train loss 1736.7240536317395
INFO:root:current train perplexity3.934297561645508
INFO:root:current mean train loss 1736.3924132663828
INFO:root:current train perplexity3.933037281036377
INFO:root:current mean train loss 1736.819602882469
INFO:root:current train perplexity3.9342381954193115
INFO:root:current mean train loss 1737.7487621442942
INFO:root:current train perplexity3.935192584991455
INFO:root:current mean train loss 1737.4895933951166
INFO:root:current train perplexity3.934497833251953


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.62s/it]
INFO:root:final mean train loss: 1736.9091186523438
INFO:root:final train perplexity: 3.934684991836548
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:09<00:00, 69.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:09<00:00, 69.10s/it]
INFO:root:eval mean loss: 2882.861678573104
INFO:root:eval perplexity: 10.650410652160645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/91

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [13:35:25<1:21:23, 542.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1742.4285411005435
INFO:root:current train perplexity3.9673595428466797
INFO:root:current mean train loss 1736.5140372498395
INFO:root:current train perplexity3.941397190093994
INFO:root:current mean train loss 1737.9207297224339
INFO:root:current train perplexity3.9410548210144043
INFO:root:current mean train loss 1735.1903725331917
INFO:root:current train perplexity3.932739496231079
INFO:root:current mean train loss 1735.9887577621391
INFO:root:current train perplexity3.9382894039154053
INFO:root:current mean train loss 1736.1822934552426
INFO:root:current train perplexity3.937685251235962
INFO:root:current mean train loss 1736.189196512795
INFO:root:current train perplexity3.9367620944976807
INFO:root:current mean train loss 1734.3805813623178
INFO:root:current train perplexity3.9332945346832275
INFO:root:current mean train loss 1733.3682561202534
INFO:root:current train perplexity3.9343111515045166
INFO:root:current mean train loss 1734.6546607632465
INFO:root:current train perplexity3.935643434524536
INFO:root:current mean train loss 1736.5414893184975
INFO:root:current train perplexity3.9390788078308105
INFO:root:current mean train loss 1736.762149617726
INFO:root:current train perplexity3.9387171268463135
INFO:root:current mean train loss 1736.4618688984438
INFO:root:current train perplexity3.9342896938323975
INFO:root:current mean train loss 1736.7147631255514
INFO:root:current train perplexity3.936711311340332
INFO:root:current mean train loss 1737.0851679336315
INFO:root:current train perplexity3.935080051422119
INFO:root:current mean train loss 1737.290075857303
INFO:root:current train perplexity3.9355969429016113
INFO:root:current mean train loss 1736.7466083586867
INFO:root:current train perplexity3.9350101947784424
INFO:root:current mean train loss 1736.6781364519572
INFO:root:current train perplexity3.9347023963928223
INFO:root:current mean train loss 1736.5551326664918
INFO:root:current train perplexity3.9335267543792725
INFO:root:current mean train loss 1736.3976468657663
INFO:root:current train perplexity3.93251633644104


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.82s/it]
INFO:root:final mean train loss: 1736.2601464868374
INFO:root:final train perplexity: 3.9326725006103516
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:09<00:00, 69.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:09<00:00, 69.66s/it]
INFO:root:eval mean loss: 2884.243459523977
INFO:root:eval perplexity: 10.662493705749512
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/92

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [13:44:26<1:12:18, 542.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1734.4287690662202
INFO:root:current train perplexity3.9254720211029053
INFO:root:current mean train loss 1732.652538463382
INFO:root:current train perplexity3.9025983810424805
INFO:root:current mean train loss 1733.0720892496436
INFO:root:current train perplexity3.923069715499878
INFO:root:current mean train loss 1731.1424493290504
INFO:root:current train perplexity3.9260172843933105
INFO:root:current mean train loss 1736.891283072354
INFO:root:current train perplexity3.9331042766571045
INFO:root:current mean train loss 1737.4508639889543
INFO:root:current train perplexity3.9344866275787354
INFO:root:current mean train loss 1737.5085405030402
INFO:root:current train perplexity3.9335923194885254
INFO:root:current mean train loss 1739.2604718089572
INFO:root:current train perplexity3.9322805404663086
INFO:root:current mean train loss 1739.7267274292983
INFO:root:current train perplexity3.9375853538513184
INFO:root:current mean train loss 1739.9417197285907
INFO:root:current train perplexity3.9385600090026855
INFO:root:current mean train loss 1740.1735168055106
INFO:root:current train perplexity3.939646005630493
INFO:root:current mean train loss 1738.4980942126706
INFO:root:current train perplexity3.936077356338501
INFO:root:current mean train loss 1737.3608346245917
INFO:root:current train perplexity3.932858943939209
INFO:root:current mean train loss 1736.8049321779852
INFO:root:current train perplexity3.929877519607544
INFO:root:current mean train loss 1735.7071985439006
INFO:root:current train perplexity3.929586410522461
INFO:root:current mean train loss 1735.8854556385706
INFO:root:current train perplexity3.9303596019744873
INFO:root:current mean train loss 1735.585922599054
INFO:root:current train perplexity3.928943395614624
INFO:root:current mean train loss 1735.2012021329276
INFO:root:current train perplexity3.9282426834106445
INFO:root:current mean train loss 1734.963457075806
INFO:root:current train perplexity3.9271292686462402
INFO:root:current mean train loss 1735.9901591304365
INFO:root:current train perplexity3.929825782775879


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 469.22s/it]
INFO:root:final mean train loss: 1735.4064954641306
INFO:root:final train perplexity: 3.930026054382324
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.79s/it]
INFO:root:eval mean loss: 2884.151417775197
INFO:root:eval perplexity: 10.661685943603516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/93

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [13:53:16<1:02:50, 538.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1723.8908462524414
INFO:root:current train perplexity3.921175718307495
INFO:root:current mean train loss 1730.9509711371527
INFO:root:current train perplexity3.9093029499053955
INFO:root:current mean train loss 1735.9097473144532
INFO:root:current train perplexity3.9153332710266113
INFO:root:current mean train loss 1734.994872083162
INFO:root:current train perplexity3.928380012512207
INFO:root:current mean train loss 1734.5715848286948
INFO:root:current train perplexity3.9278111457824707
INFO:root:current mean train loss 1734.361200161638
INFO:root:current train perplexity3.928223133087158
INFO:root:current mean train loss 1734.533464499081
INFO:root:current train perplexity3.928572416305542
INFO:root:current mean train loss 1734.1363317245093
INFO:root:current train perplexity3.9296517372131348
INFO:root:current mean train loss 1733.2775974620472
INFO:root:current train perplexity3.9260566234588623
INFO:root:current mean train loss 1733.257798549107
INFO:root:current train perplexity3.9266157150268555
INFO:root:current mean train loss 1733.2571882459852
INFO:root:current train perplexity3.926431894302368
INFO:root:current mean train loss 1732.4925306417174
INFO:root:current train perplexity3.9259872436523438
INFO:root:current mean train loss 1733.6915747642518
INFO:root:current train perplexity3.928570032119751
INFO:root:current mean train loss 1733.9998644842617
INFO:root:current train perplexity3.926586389541626
INFO:root:current mean train loss 1735.6099907127586
INFO:root:current train perplexity3.9281740188598633
INFO:root:current mean train loss 1735.6203065510038
INFO:root:current train perplexity3.927361488342285
INFO:root:current mean train loss 1735.0002960931688
INFO:root:current train perplexity3.9273293018341064
INFO:root:current mean train loss 1735.2744419055039
INFO:root:current train perplexity3.927031993865967
INFO:root:current mean train loss 1734.6605886905752
INFO:root:current train perplexity3.926218032836914
INFO:root:current mean train loss 1734.8335759326665
INFO:root:current train perplexity3.9269089698791504


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.31s/it]
INFO:root:final mean train loss: 1734.3860804509227
INFO:root:final train perplexity: 3.9268639087677
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.94s/it]
INFO:root:eval mean loss: 2884.4378966368713
INFO:root:eval perplexity: 10.66419506072998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/94

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [14:02:06<53:34, 535.82s/it]  

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1736.42534456548
INFO:root:current train perplexity3.9467926025390625
INFO:root:current mean train loss 1738.1689013176158
INFO:root:current train perplexity3.9453277587890625
INFO:root:current mean train loss 1738.6545163549558
INFO:root:current train perplexity3.932335376739502
INFO:root:current mean train loss 1738.4208907504526
INFO:root:current train perplexity3.939093828201294
INFO:root:current mean train loss 1737.1871217539613
INFO:root:current train perplexity3.933194637298584
INFO:root:current mean train loss 1738.0713377270467
INFO:root:current train perplexity3.9258482456207275
INFO:root:current mean train loss 1737.0146670019951
INFO:root:current train perplexity3.922499179840088
INFO:root:current mean train loss 1734.8771600471985
INFO:root:current train perplexity3.9222636222839355
INFO:root:current mean train loss 1735.1344788890485
INFO:root:current train perplexity3.9214487075805664
INFO:root:current mean train loss 1735.656935038514
INFO:root:current train perplexity3.92452073097229
INFO:root:current mean train loss 1736.4895018418486
INFO:root:current train perplexity3.9288039207458496
INFO:root:current mean train loss 1735.6301007442107
INFO:root:current train perplexity3.927361488342285
INFO:root:current mean train loss 1735.8979943951185
INFO:root:current train perplexity3.929225444793701
INFO:root:current mean train loss 1735.4719916352562
INFO:root:current train perplexity3.926403284072876
INFO:root:current mean train loss 1735.1673570937448
INFO:root:current train perplexity3.926392078399658
INFO:root:current mean train loss 1735.3808162643825
INFO:root:current train perplexity3.926862955093384
INFO:root:current mean train loss 1734.9619257875802
INFO:root:current train perplexity3.9268414974212646
INFO:root:current mean train loss 1734.7173651778571
INFO:root:current train perplexity3.927119493484497
INFO:root:current mean train loss 1734.998996668259
INFO:root:current train perplexity3.9283950328826904


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.71s/it]
INFO:root:final mean train loss: 1733.7797721058687
INFO:root:final train perplexity: 3.924987316131592
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:09<00:00, 69.54s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:09<00:00, 69.54s/it]
INFO:root:eval mean loss: 2885.4253809473535
INFO:root:eval perplexity: 10.67283821105957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/95

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [14:11:09<44:50, 538.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1702.5265241350446
INFO:root:current train perplexity3.8532521724700928
INFO:root:current mean train loss 1720.9923138534814
INFO:root:current train perplexity3.8818113803863525
INFO:root:current mean train loss 1727.3620114905812
INFO:root:current train perplexity3.8868534564971924
INFO:root:current mean train loss 1727.7438195101015
INFO:root:current train perplexity3.894700050354004
INFO:root:current mean train loss 1727.2464292959314
INFO:root:current train perplexity3.8961641788482666
INFO:root:current mean train loss 1728.9185976258511
INFO:root:current train perplexity3.902453660964966
INFO:root:current mean train loss 1730.519683738485
INFO:root:current train perplexity3.9128482341766357
INFO:root:current mean train loss 1732.540235332414
INFO:root:current train perplexity3.912698984146118
INFO:root:current mean train loss 1732.1064144200132
INFO:root:current train perplexity3.9138824939727783
INFO:root:current mean train loss 1732.4955461698237
INFO:root:current train perplexity3.914074182510376
INFO:root:current mean train loss 1732.6653315978642
INFO:root:current train perplexity3.912606716156006
INFO:root:current mean train loss 1733.5563246009594
INFO:root:current train perplexity3.9144890308380127
INFO:root:current mean train loss 1733.6428801836646
INFO:root:current train perplexity3.9163146018981934
INFO:root:current mean train loss 1733.0827068172089
INFO:root:current train perplexity3.9168448448181152
INFO:root:current mean train loss 1733.0564106424592
INFO:root:current train perplexity3.919092893600464
INFO:root:current mean train loss 1733.9747824020083
INFO:root:current train perplexity3.9191339015960693
INFO:root:current mean train loss 1733.96961855977
INFO:root:current train perplexity3.921192169189453
INFO:root:current mean train loss 1734.6044086469653
INFO:root:current train perplexity3.922170639038086
INFO:root:current mean train loss 1734.8266676258227
INFO:root:current train perplexity3.9220144748687744
INFO:root:current mean train loss 1734.791176153201
INFO:root:current train perplexity3.9229846000671387


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.73s/it]
INFO:root:final mean train loss: 1733.2508840402209
INFO:root:final train perplexity: 3.9233498573303223
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:58<00:00, 58.78s/it]
INFO:root:eval mean loss: 2885.2065290388045
INFO:root:eval perplexity: 10.67092227935791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/96

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [14:19:54<35:37, 534.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1756.3639664188509
INFO:root:current train perplexity3.992030382156372
INFO:root:current mean train loss 1742.276628101145
INFO:root:current train perplexity3.9725828170776367
INFO:root:current mean train loss 1737.4788025695009
INFO:root:current train perplexity3.947352886199951
INFO:root:current mean train loss 1737.950810458365
INFO:root:current train perplexity3.938847303390503
INFO:root:current mean train loss 1740.911909700823
INFO:root:current train perplexity3.939908504486084
INFO:root:current mean train loss 1739.5487798486051
INFO:root:current train perplexity3.935741424560547
INFO:root:current mean train loss 1738.064952626659
INFO:root:current train perplexity3.9298765659332275
INFO:root:current mean train loss 1737.2732544780267
INFO:root:current train perplexity3.9271676540374756
INFO:root:current mean train loss 1736.2643812342528
INFO:root:current train perplexity3.9260597229003906
INFO:root:current mean train loss 1734.738978532408
INFO:root:current train perplexity3.9236979484558105
INFO:root:current mean train loss 1733.5054235449124
INFO:root:current train perplexity3.922236442565918
INFO:root:current mean train loss 1733.4223315494446
INFO:root:current train perplexity3.92189884185791
INFO:root:current mean train loss 1733.7884042524497
INFO:root:current train perplexity3.921994209289551
INFO:root:current mean train loss 1733.6600301443052
INFO:root:current train perplexity3.9209811687469482
INFO:root:current mean train loss 1732.3086550837209
INFO:root:current train perplexity3.92118501663208
INFO:root:current mean train loss 1731.7745526374204
INFO:root:current train perplexity3.9211883544921875
INFO:root:current mean train loss 1733.3921407375651
INFO:root:current train perplexity3.9240810871124268
INFO:root:current mean train loss 1733.1553289368276
INFO:root:current train perplexity3.9216811656951904
INFO:root:current mean train loss 1732.8509890162052
INFO:root:current train perplexity3.9220573902130127
INFO:root:current mean train loss 1732.7914237482198
INFO:root:current train perplexity3.9211153984069824


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.53s/it]
INFO:root:final mean train loss: 1732.3279148396132
INFO:root:final train perplexity: 3.920494794845581
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:59<00:00, 59.67s/it]
INFO:root:eval mean loss: 2884.708103855809
INFO:root:eval perplexity: 10.666560173034668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/97

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [14:28:41<26:35, 531.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1734.0728912353516
INFO:root:current train perplexity3.9351587295532227
INFO:root:current mean train loss 1731.489836821685
INFO:root:current train perplexity3.9451944828033447
INFO:root:current mean train loss 1734.385546776556
INFO:root:current train perplexity3.9460458755493164
INFO:root:current mean train loss 1732.4344868276312
INFO:root:current train perplexity3.93035626411438
INFO:root:current mean train loss 1735.6023194449288
INFO:root:current train perplexity3.930964469909668
INFO:root:current mean train loss 1736.9865947639855
INFO:root:current train perplexity3.9240121841430664
INFO:root:current mean train loss 1738.123779108495
INFO:root:current train perplexity3.924402952194214
INFO:root:current mean train loss 1737.4970531769616
INFO:root:current train perplexity3.9214701652526855
INFO:root:current mean train loss 1735.4509059977981
INFO:root:current train perplexity3.9227237701416016
INFO:root:current mean train loss 1735.0310053443104
INFO:root:current train perplexity3.9217517375946045
INFO:root:current mean train loss 1735.0420058155787
INFO:root:current train perplexity3.923492193222046
INFO:root:current mean train loss 1733.388886455044
INFO:root:current train perplexity3.924194574356079
INFO:root:current mean train loss 1733.927790421706
INFO:root:current train perplexity3.9230175018310547
INFO:root:current mean train loss 1734.799406872305
INFO:root:current train perplexity3.923478603363037
INFO:root:current mean train loss 1734.4040791211207
INFO:root:current train perplexity3.923248052597046
INFO:root:current mean train loss 1733.3843409023236
INFO:root:current train perplexity3.920781135559082
INFO:root:current mean train loss 1733.3016287053672
INFO:root:current train perplexity3.9194722175598145
INFO:root:current mean train loss 1733.2371686503325
INFO:root:current train perplexity3.919680595397949
INFO:root:current mean train loss 1732.5894590435605
INFO:root:current train perplexity3.9204092025756836
INFO:root:current mean train loss 1732.160860911532
INFO:root:current train perplexity3.9199306964874268


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.52s/it]
INFO:root:final mean train loss: 1731.978213557918
INFO:root:final train perplexity: 3.9194142818450928
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.03s/it]
INFO:root:eval mean loss: 2885.035717113598
INFO:root:eval perplexity: 10.669425964355469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/98

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [14:37:29<17:41, 530.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1734.0520489032451
INFO:root:current train perplexity3.8925843238830566
INFO:root:current mean train loss 1728.3760520241478
INFO:root:current train perplexity3.912261962890625
INFO:root:current mean train loss 1728.497761276533
INFO:root:current train perplexity3.9179885387420654
INFO:root:current mean train loss 1727.593195834225
INFO:root:current train perplexity3.917646646499634
INFO:root:current mean train loss 1730.3721451297884
INFO:root:current train perplexity3.917387008666992
INFO:root:current mean train loss 1734.0579648178236
INFO:root:current train perplexity3.916872024536133
INFO:root:current mean train loss 1733.6006854293937
INFO:root:current train perplexity3.9133996963500977
INFO:root:current mean train loss 1734.130019882302
INFO:root:current train perplexity3.9135582447052
INFO:root:current mean train loss 1734.3465497143695
INFO:root:current train perplexity3.915818691253662
INFO:root:current mean train loss 1733.9986125728626
INFO:root:current train perplexity3.915715217590332
INFO:root:current mean train loss 1733.283428009463
INFO:root:current train perplexity3.9127259254455566
INFO:root:current mean train loss 1732.9168345962983
INFO:root:current train perplexity3.9155373573303223
INFO:root:current mean train loss 1733.0145210597825
INFO:root:current train perplexity3.9164083003997803
INFO:root:current mean train loss 1733.317608173077
INFO:root:current train perplexity3.9179747104644775
INFO:root:current mean train loss 1732.0596632192567
INFO:root:current train perplexity3.9160783290863037
INFO:root:current mean train loss 1731.5049126865765
INFO:root:current train perplexity3.915285348892212
INFO:root:current mean train loss 1731.1561656871716
INFO:root:current train perplexity3.9140052795410156
INFO:root:current mean train loss 1731.5357507635447
INFO:root:current train perplexity3.914463996887207
INFO:root:current mean train loss 1731.0082541785355
INFO:root:current train perplexity3.913668394088745
INFO:root:current mean train loss 1731.265856157065
INFO:root:current train perplexity3.9151737689971924


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.90s/it]
INFO:root:final mean train loss: 1730.760248242877
INFO:root:final train perplexity: 3.915651321411133
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:01<00:00, 61.52s/it]
INFO:root:eval mean loss: 2885.11486559802
INFO:root:eval perplexity: 10.670120239257812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/99

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [14:46:20<08:50, 530.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1726.4196375404915
INFO:root:current train perplexity3.8734488487243652
INFO:root:current mean train loss 1720.458768404447
INFO:root:current train perplexity3.884427309036255
INFO:root:current mean train loss 1724.580692805297
INFO:root:current train perplexity3.892550468444824
INFO:root:current mean train loss 1727.0198153350989
INFO:root:current train perplexity3.8936214447021484
INFO:root:current mean train loss 1727.7777826459576
INFO:root:current train perplexity3.894962787628174
INFO:root:current mean train loss 1728.3047560858972
INFO:root:current train perplexity3.9030990600585938
INFO:root:current mean train loss 1729.673121298513
INFO:root:current train perplexity3.9069581031799316
INFO:root:current mean train loss 1730.5129728585557
INFO:root:current train perplexity3.9095187187194824
INFO:root:current mean train loss 1730.0353933321376
INFO:root:current train perplexity3.909432888031006
INFO:root:current mean train loss 1730.1756683784688
INFO:root:current train perplexity3.909472703933716
INFO:root:current mean train loss 1729.8076920994108
INFO:root:current train perplexity3.908445119857788
INFO:root:current mean train loss 1729.9262090124657
INFO:root:current train perplexity3.908031463623047
INFO:root:current mean train loss 1730.042118542652
INFO:root:current train perplexity3.90852427482605
INFO:root:current mean train loss 1730.4466755890467
INFO:root:current train perplexity3.9100072383880615
INFO:root:current mean train loss 1732.3035438939144
INFO:root:current train perplexity3.9134840965270996
INFO:root:current mean train loss 1730.5664257719905
INFO:root:current train perplexity3.911396026611328
INFO:root:current mean train loss 1729.6836293840806
INFO:root:current train perplexity3.911574602127075
INFO:root:current mean train loss 1729.6050335576906
INFO:root:current train perplexity3.911731719970703
INFO:root:current mean train loss 1730.6922349271056
INFO:root:current train perplexity3.9147424697875977
INFO:root:current mean train loss 1731.426148877495
INFO:root:current train perplexity3.9162464141845703


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:48<00:00, 468.08s/it]
INFO:root:final mean train loss: 1730.9167737167288
INFO:root:final train perplexity: 3.916134834289551
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:00<00:00, 60.17s/it]
INFO:root:eval mean loss: 2885.2981976116744
INFO:root:eval perplexity: 10.67172622680664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_13/100

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [14:55:09<00:00, 530.30s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [14:55:09<00:00, 537.09s/it]
INFO:root:evaluating final model
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.85s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:57<00:00, 57.85s/it]
INFO:root:eval mean loss: 2885.2981976116744
INFO:root:eval perplexity: 10.67172622680664
INFO:root:evalaution complete
INFO:root:save model final: std_13/final
