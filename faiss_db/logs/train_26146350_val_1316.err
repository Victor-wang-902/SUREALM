INFO:root:Output: small_val_1316
INFO:root:Steps per epochs:992
INFO:root:Total steps:198400
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/multi-qa-MiniLM-L6-cos-v1 and are newly initialized: ['encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.query.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.key.weight', 'cls.predictions.decoder.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.query.bias', 'cls.predictions.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.key.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/200 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 24457.556798453283
INFO:root:current train perplexity15516.8388671875
INFO:root:current mean train loss 20541.40402697079
INFO:root:current train perplexity3280.026611328125
INFO:root:current mean train loss 17747.352493337166
INFO:root:current train perplexity1093.3536376953125
INFO:root:current mean train loss 15854.482507538378
INFO:root:current train perplexity514.0446166992188
INFO:root:current mean train loss 14480.832705449962
INFO:root:current train perplexity299.1175537109375
INFO:root:current mean train loss 13438.095802574604
INFO:root:current train perplexity198.9372100830078
INFO:root:current mean train loss 12626.87451171875
INFO:root:current train perplexity144.4754638671875
INFO:root:current mean train loss 11976.488798864792
INFO:root:current train perplexity112.06905364990234
INFO:root:current mean train loss 11444.048051437361
INFO:root:current train perplexity90.89579010009766


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.80s/it]
INFO:root:final mean train loss: 11014.683045910251
INFO:root:final train perplexity: 77.13916015625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.12s/it]
INFO:root:eval mean loss: 6415.156080313608
INFO:root:eval perplexity: 13.38454532623291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/1

  0%|          | 1/200 [02:40<8:52:09, 160.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 6822.238071986607
INFO:root:current train perplexity14.502758026123047
INFO:root:current mean train loss 6731.021625839661
INFO:root:current train perplexity14.398063659667969
INFO:root:current mean train loss 6702.3981237734
INFO:root:current train perplexity14.159761428833008
INFO:root:current mean train loss 6630.069135535424
INFO:root:current train perplexity13.736517906188965
INFO:root:current mean train loss 6576.334039561579
INFO:root:current train perplexity13.435643196105957
INFO:root:current mean train loss 6526.373059395032
INFO:root:current train perplexity13.16583251953125
INFO:root:current mean train loss 6483.689942210667
INFO:root:current train perplexity12.89544677734375
INFO:root:current mean train loss 6435.961938925478
INFO:root:current train perplexity12.653635025024414
INFO:root:current mean train loss 6391.786801400829
INFO:root:current train perplexity12.427873611450195
INFO:root:current mean train loss 6347.174222733772
INFO:root:current train perplexity12.2233247756958


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.59s/it]
INFO:root:final mean train loss: 6310.058299033873
INFO:root:final train perplexity: 12.055253028869629
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.39s/it]
INFO:root:eval mean loss: 5542.510018423094
INFO:root:eval perplexity: 9.404876708984375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/2

  1%|          | 2/200 [05:04<8:16:55, 150.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5986.012760416666
INFO:root:current train perplexity10.63294506072998
INFO:root:current mean train loss 5881.37080078125
INFO:root:current train perplexity10.239079475402832
INFO:root:current mean train loss 5860.105421057413
INFO:root:current train perplexity10.102447509765625
INFO:root:current mean train loss 5839.720540364583
INFO:root:current train perplexity9.988826751708984
INFO:root:current mean train loss 5815.559433829067
INFO:root:current train perplexity9.899809837341309
INFO:root:current mean train loss 5790.845972390776
INFO:root:current train perplexity9.816059112548828
INFO:root:current mean train loss 5766.317498729675
INFO:root:current train perplexity9.73686695098877
INFO:root:current mean train loss 5747.474776005245
INFO:root:current train perplexity9.658843994140625
INFO:root:current mean train loss 5734.435684672163
INFO:root:current train perplexity9.588423728942871
INFO:root:current mean train loss 5715.779160262978
INFO:root:current train perplexity9.505407333374023


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.74s/it]
INFO:root:final mean train loss: 5692.176655061783
INFO:root:final train perplexity: 9.447293281555176
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.35s/it]
INFO:root:eval mean loss: 5178.20272329344
INFO:root:eval perplexity: 8.11661434173584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/3

  2%|â–         | 3/200 [08:03<8:57:50, 163.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5565.078740658967
INFO:root:current train perplexity8.822108268737793
INFO:root:current mean train loss 5485.745486375762
INFO:root:current train perplexity8.718618392944336
INFO:root:current mean train loss 5484.262842015835
INFO:root:current train perplexity8.65674877166748
INFO:root:current mean train loss 5457.470683472813
INFO:root:current train perplexity8.57646369934082
INFO:root:current mean train loss 5444.8270930296985
INFO:root:current train perplexity8.551267623901367
INFO:root:current mean train loss 5428.116692683437
INFO:root:current train perplexity8.49631404876709
INFO:root:current mean train loss 5418.463629708818
INFO:root:current train perplexity8.464253425598145
INFO:root:current mean train loss 5408.902303228734
INFO:root:current train perplexity8.430255889892578
INFO:root:current mean train loss 5397.953628706903
INFO:root:current train perplexity8.393506050109863
INFO:root:current mean train loss 5387.151943285313
INFO:root:current train perplexity8.358172416687012


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.37s/it]
INFO:root:final mean train loss: 5375.851848602295
INFO:root:final train perplexity: 8.33888053894043
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.86s/it]
INFO:root:eval mean loss: 4956.801515403369
INFO:root:eval perplexity: 7.421528339385986
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/4

  2%|â–         | 4/200 [10:43<8:49:33, 162.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5319.501086819557
INFO:root:current train perplexity7.9658098220825195
INFO:root:current mean train loss 5240.115517652672
INFO:root:current train perplexity7.883181571960449
INFO:root:current mean train loss 5241.801170183982
INFO:root:current train perplexity7.903024196624756
INFO:root:current mean train loss 5230.903414723376
INFO:root:current train perplexity7.856125831604004
INFO:root:current mean train loss 5224.827474713602
INFO:root:current train perplexity7.825494289398193
INFO:root:current mean train loss 5215.062065972223
INFO:root:current train perplexity7.797818183898926
INFO:root:current mean train loss 5207.691595836222
INFO:root:current train perplexity7.77418327331543
INFO:root:current mean train loss 5199.594705855635
INFO:root:current train perplexity7.757654666900635
INFO:root:current mean train loss 5186.524352953896
INFO:root:current train perplexity7.733642101287842
INFO:root:current mean train loss 5177.96463081532
INFO:root:current train perplexity7.702536582946777


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.52s/it]
INFO:root:final mean train loss: 5168.393252957252
INFO:root:final train perplexity: 7.683541774749756
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.28s/it]
INFO:root:eval mean loss: 4817.013723819814
INFO:root:eval perplexity: 7.013654708862305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/5

  2%|â–Ž         | 5/200 [12:57<8:14:43, 152.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5078.061761318109
INFO:root:current train perplexity7.332365989685059
INFO:root:current mean train loss 5068.992865473247
INFO:root:current train perplexity7.390356540679932
INFO:root:current mean train loss 5077.811012683054
INFO:root:current train perplexity7.404026031494141
INFO:root:current mean train loss 5060.770395464602
INFO:root:current train perplexity7.342075824737549
INFO:root:current mean train loss 5058.004287754485
INFO:root:current train perplexity7.33064603805542
INFO:root:current mean train loss 5046.147768944225
INFO:root:current train perplexity7.308112621307373
INFO:root:current mean train loss 5038.121446779636
INFO:root:current train perplexity7.287356376647949
INFO:root:current mean train loss 5038.272731837787
INFO:root:current train perplexity7.283059120178223
INFO:root:current mean train loss 5034.240179086896
INFO:root:current train perplexity7.26627254486084
INFO:root:current mean train loss 5026.218444239217
INFO:root:current train perplexity7.250741004943848


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.05s/it]
INFO:root:final mean train loss: 5017.554627141645
INFO:root:final train perplexity: 7.2396321296691895
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.01s/it]
INFO:root:eval mean loss: 4701.060467226285
INFO:root:eval perplexity: 6.692388534545898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/6

  3%|â–Ž         | 6/200 [15:10<7:50:59, 145.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4892.128750415559
INFO:root:current train perplexity6.9339680671691895
INFO:root:current mean train loss 4941.2625126222365
INFO:root:current train perplexity6.997776985168457
INFO:root:current mean train loss 4923.708905301113
INFO:root:current train perplexity6.9824676513671875
INFO:root:current mean train loss 4923.936993425793
INFO:root:current train perplexity6.974758625030518
INFO:root:current mean train loss 4921.104098940856
INFO:root:current train perplexity6.964282512664795
INFO:root:current mean train loss 4912.657352426589
INFO:root:current train perplexity6.943752765655518
INFO:root:current mean train loss 4911.798552664944
INFO:root:current train perplexity6.9393744468688965
INFO:root:current mean train loss 4908.561144970507
INFO:root:current train perplexity6.926894187927246
INFO:root:current mean train loss 4905.069881867068
INFO:root:current train perplexity6.918470859527588
INFO:root:current mean train loss 4902.660284636517
INFO:root:current train perplexity6.907081604003906


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.88s/it]
INFO:root:final mean train loss: 4897.797302123039
INFO:root:final train perplexity: 6.905531406402588
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.94s/it]
INFO:root:eval mean loss: 4615.562590037677
INFO:root:eval perplexity: 6.464969158172607
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/7

  4%|â–Ž         | 7/200 [17:29<7:41:15, 143.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4790.708682528409
INFO:root:current train perplexity6.7078986167907715
INFO:root:current mean train loss 4843.094102822581
INFO:root:current train perplexity6.770064830780029
INFO:root:current mean train loss 4834.231673177083
INFO:root:current train perplexity6.7213053703308105
INFO:root:current mean train loss 4833.386044784331
INFO:root:current train perplexity6.713794708251953
INFO:root:current mean train loss 4827.291041380495
INFO:root:current train perplexity6.696087837219238
INFO:root:current mean train loss 4821.250289449606
INFO:root:current train perplexity6.678232192993164
INFO:root:current mean train loss 4819.61708089814
INFO:root:current train perplexity6.6756086349487305
INFO:root:current mean train loss 4821.42421939673
INFO:root:current train perplexity6.670989036560059
INFO:root:current mean train loss 4812.623774442617
INFO:root:current train perplexity6.654952526092529
INFO:root:current mean train loss 4805.5985484497705
INFO:root:current train perplexity6.647466659545898


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.23s/it]
INFO:root:final mean train loss: 4801.001207905431
INFO:root:final train perplexity: 6.646788597106934
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.24s/it]
INFO:root:eval mean loss: 4541.350856050532
INFO:root:eval perplexity: 6.273842811584473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/8

  4%|â–         | 8/200 [19:49<7:35:46, 142.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4748.0034257192465
INFO:root:current train perplexity6.4518327713012695
INFO:root:current mean train loss 4735.164204790548
INFO:root:current train perplexity6.469400405883789
INFO:root:current mean train loss 4727.979188636228
INFO:root:current train perplexity6.465064525604248
INFO:root:current mean train loss 4737.636587600077
INFO:root:current train perplexity6.462437629699707
INFO:root:current mean train loss 4741.649916580892
INFO:root:current train perplexity6.471199035644531
INFO:root:current mean train loss 4733.498365602104
INFO:root:current train perplexity6.457711696624756
INFO:root:current mean train loss 4730.625240458263
INFO:root:current train perplexity6.454799175262451
INFO:root:current mean train loss 4728.560759018164
INFO:root:current train perplexity6.447137832641602
INFO:root:current mean train loss 4723.436984843478
INFO:root:current train perplexity6.4380927085876465
INFO:root:current mean train loss 4720.08093325099
INFO:root:current train perplexity6.429259777069092


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:12<00:00, 132.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:12<00:00, 132.31s/it]
INFO:root:final mean train loss: 4717.930610287574
INFO:root:final train perplexity: 6.432479381561279
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.30s/it]
INFO:root:eval mean loss: 4484.370243586547
INFO:root:eval perplexity: 6.130938529968262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/9

  4%|â–         | 9/200 [22:14<7:35:24, 143.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4640.929247359155
INFO:root:current train perplexity6.211347579956055
INFO:root:current mean train loss 4652.891732913012
INFO:root:current train perplexity6.263853549957275
INFO:root:current mean train loss 4674.666098506688
INFO:root:current train perplexity6.298575401306152
INFO:root:current mean train loss 4668.638508675876
INFO:root:current train perplexity6.286041736602783
INFO:root:current mean train loss 4662.1835429521625
INFO:root:current train perplexity6.282355785369873
INFO:root:current mean train loss 4662.304814059764
INFO:root:current train perplexity6.277164459228516
INFO:root:current mean train loss 4663.899002916589
INFO:root:current train perplexity6.282560348510742
INFO:root:current mean train loss 4654.22301596952
INFO:root:current train perplexity6.268861770629883
INFO:root:current mean train loss 4656.85798247345
INFO:root:current train perplexity6.26668119430542
INFO:root:current mean train loss 4652.990835800721
INFO:root:current train perplexity6.260612964630127


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.97s/it]
INFO:root:final mean train loss: 4648.757411464568
INFO:root:final train perplexity: 6.25930643081665
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.78s/it]
INFO:root:eval mean loss: 4439.919227545988
INFO:root:eval perplexity: 6.021720886230469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/10

  5%|â–Œ         | 10/200 [24:32<7:28:40, 141.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4638.062462915348
INFO:root:current train perplexity6.144894123077393
INFO:root:current mean train loss 4599.016309684881
INFO:root:current train perplexity6.108523845672607
INFO:root:current mean train loss 4608.31051187276
INFO:root:current train perplexity6.1205668449401855
INFO:root:current mean train loss 4601.695718327424
INFO:root:current train perplexity6.121227741241455
INFO:root:current mean train loss 4606.717068029097
INFO:root:current train perplexity6.1230363845825195
INFO:root:current mean train loss 4599.58752082996
INFO:root:current train perplexity6.121116638183594
INFO:root:current mean train loss 4598.722929514912
INFO:root:current train perplexity6.117553234100342
INFO:root:current mean train loss 4596.816270860077
INFO:root:current train perplexity6.114367961883545
INFO:root:current mean train loss 4591.2664265811645
INFO:root:current train perplexity6.110167503356934
INFO:root:current mean train loss 4590.610904432537
INFO:root:current train perplexity6.110411167144775


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.33s/it]
INFO:root:final mean train loss: 4587.8032566193615
INFO:root:final train perplexity: 6.1105780601501465
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 11.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 11.00s/it]
INFO:root:eval mean loss: 4392.792835424978
INFO:root:eval perplexity: 5.908053398132324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/11

  6%|â–Œ         | 11/200 [27:16<7:47:03, 148.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4534.643349833872
INFO:root:current train perplexity5.965854644775391
INFO:root:current mean train loss 4556.117068693599
INFO:root:current train perplexity5.999477386474609
INFO:root:current mean train loss 4545.904860865364
INFO:root:current train perplexity5.979637622833252
INFO:root:current mean train loss 4545.978083489786
INFO:root:current train perplexity5.992339611053467
INFO:root:current mean train loss 4542.70091720675
INFO:root:current train perplexity5.989687919616699
INFO:root:current mean train loss 4539.330835917536
INFO:root:current train perplexity5.9836626052856445
INFO:root:current mean train loss 4538.384991286276
INFO:root:current train perplexity5.984058380126953
INFO:root:current mean train loss 4535.205835984653
INFO:root:current train perplexity5.97708797454834
INFO:root:current mean train loss 4536.328469604355
INFO:root:current train perplexity5.97896146774292
INFO:root:current mean train loss 4536.163883661427
INFO:root:current train perplexity5.9793219566345215


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.20s/it]
INFO:root:final mean train loss: 4532.779458815052
INFO:root:final train perplexity: 5.979353904724121
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.76s/it]
INFO:root:eval mean loss: 4356.115217060062
INFO:root:eval perplexity: 5.821077346801758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/12

  6%|â–Œ         | 12/200 [29:39<7:39:50, 146.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4500.6838147615135
INFO:root:current train perplexity5.889894485473633
INFO:root:current mean train loss 4484.196299078526
INFO:root:current train perplexity5.881087303161621
INFO:root:current mean train loss 4488.907957329185
INFO:root:current train perplexity5.8911967277526855
INFO:root:current mean train loss 4482.49657955894
INFO:root:current train perplexity5.876501560211182
INFO:root:current mean train loss 4488.463476069287
INFO:root:current train perplexity5.877702713012695
INFO:root:current mean train loss 4482.84417262999
INFO:root:current train perplexity5.87352180480957
INFO:root:current mean train loss 4480.344709349708
INFO:root:current train perplexity5.8695454597473145
INFO:root:current mean train loss 4484.400209438876
INFO:root:current train perplexity5.86414909362793
INFO:root:current mean train loss 4486.1359186779855
INFO:root:current train perplexity5.86669397354126


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.63s/it]
INFO:root:final mean train loss: 4485.377036433066
INFO:root:final train perplexity: 5.868569850921631
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.65s/it]
INFO:root:eval mean loss: 4323.06241342531
INFO:root:eval perplexity: 5.7437920570373535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/13

  6%|â–‹         | 13/200 [31:58<7:30:12, 144.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4713.881673177083
INFO:root:current train perplexity6.055849552154541
INFO:root:current mean train loss 4460.154488869084
INFO:root:current train perplexity5.765941619873047
INFO:root:current mean train loss 4457.833524957667
INFO:root:current train perplexity5.7651143074035645
INFO:root:current mean train loss 4456.210762653413
INFO:root:current train perplexity5.771507263183594
INFO:root:current mean train loss 4457.711884377908
INFO:root:current train perplexity5.7755351066589355
INFO:root:current mean train loss 4454.063317846825
INFO:root:current train perplexity5.778179168701172
INFO:root:current mean train loss 4450.167031865412
INFO:root:current train perplexity5.779048442840576
INFO:root:current mean train loss 4446.174508801565
INFO:root:current train perplexity5.771257400512695
INFO:root:current mean train loss 4444.769787248015
INFO:root:current train perplexity5.768782138824463
INFO:root:current mean train loss 4445.203848770158
INFO:root:current train perplexity5.7685627937316895


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.32s/it]
INFO:root:final mean train loss: 4441.476765540338
INFO:root:final train perplexity: 5.7678022384643555
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.28s/it]
INFO:root:eval mean loss: 4298.412769074135
INFO:root:eval perplexity: 5.686823844909668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/14

  7%|â–‹         | 14/200 [34:21<7:25:57, 143.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4369.324729225852
INFO:root:current train perplexity5.548128128051758
INFO:root:current mean train loss 4393.741980750282
INFO:root:current train perplexity5.6806817054748535
INFO:root:current mean train loss 4385.362817267106
INFO:root:current train perplexity5.677810192108154
INFO:root:current mean train loss 4389.838933129019
INFO:root:current train perplexity5.675708293914795
INFO:root:current mean train loss 4387.666240757109
INFO:root:current train perplexity5.671291828155518
INFO:root:current mean train loss 4391.1232790713675
INFO:root:current train perplexity5.675654411315918
INFO:root:current mean train loss 4398.4370396890345
INFO:root:current train perplexity5.680444717407227
INFO:root:current mean train loss 4399.6780502812935
INFO:root:current train perplexity5.677328586578369
INFO:root:current mean train loss 4401.539539040826
INFO:root:current train perplexity5.680379390716553
INFO:root:current mean train loss 4403.446504795983
INFO:root:current train perplexity5.675895690917969


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.16s/it]
INFO:root:final mean train loss: 4399.859422929825
INFO:root:final train perplexity: 5.673873424530029
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.65s/it]
INFO:root:eval mean loss: 4271.555996509309
INFO:root:eval perplexity: 5.625399589538574
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/15

  8%|â–Š         | 15/200 [36:45<7:23:40, 143.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4422.370387027138
INFO:root:current train perplexity5.665968894958496
INFO:root:current mean train loss 4363.804978827468
INFO:root:current train perplexity5.574032783508301
INFO:root:current mean train loss 4360.478973806721
INFO:root:current train perplexity5.585921287536621
INFO:root:current mean train loss 4357.818044823913
INFO:root:current train perplexity5.584104061126709
INFO:root:current mean train loss 4363.810248545645
INFO:root:current train perplexity5.5920610427856445
INFO:root:current mean train loss 4361.696104663415
INFO:root:current train perplexity5.588198184967041
INFO:root:current mean train loss 4360.396991193584
INFO:root:current train perplexity5.587468147277832
INFO:root:current mean train loss 4363.463034936218
INFO:root:current train perplexity5.590834617614746
INFO:root:current mean train loss 4363.083457937461
INFO:root:current train perplexity5.5913896560668945
INFO:root:current mean train loss 4363.27893929798
INFO:root:current train perplexity5.589155197143555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.28s/it]
INFO:root:final mean train loss: 4363.73379787322
INFO:root:final train perplexity: 5.593578338623047
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.00s/it]
INFO:root:eval mean loss: 4247.237718514517
INFO:root:eval perplexity: 5.570352077484131
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/16

  8%|â–Š         | 16/200 [39:34<7:44:32, 151.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4359.338568793402
INFO:root:current train perplexity5.5904974937438965
INFO:root:current mean train loss 4311.439568467027
INFO:root:current train perplexity5.526521682739258
INFO:root:current mean train loss 4324.571392311399
INFO:root:current train perplexity5.523952960968018
INFO:root:current mean train loss 4322.63602813814
INFO:root:current train perplexity5.5162553787231445
INFO:root:current mean train loss 4328.617678640039
INFO:root:current train perplexity5.518275260925293
INFO:root:current mean train loss 4328.268632979275
INFO:root:current train perplexity5.512462615966797
INFO:root:current mean train loss 4328.9310199548945
INFO:root:current train perplexity5.511229991912842
INFO:root:current mean train loss 4327.790130405348
INFO:root:current train perplexity5.516017436981201
INFO:root:current mean train loss 4327.673057325518
INFO:root:current train perplexity5.512190818786621
INFO:root:current mean train loss 4329.600211430522
INFO:root:current train perplexity5.516693115234375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.96s/it]
INFO:root:final mean train loss: 4330.370926518594
INFO:root:final train perplexity: 5.520434856414795
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.63s/it]
INFO:root:eval mean loss: 4226.606161347518
INFO:root:eval perplexity: 5.524073123931885
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/17

  8%|â–Š         | 17/200 [42:19<7:54:43, 155.65s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4259.608747209822
INFO:root:current train perplexity5.416342258453369
INFO:root:current mean train loss 4296.180356626158
INFO:root:current train perplexity5.440653324127197
INFO:root:current mean train loss 4292.335467918883
INFO:root:current train perplexity5.44702672958374
INFO:root:current mean train loss 4294.64707395639
INFO:root:current train perplexity5.444520950317383
INFO:root:current mean train loss 4295.004549434268
INFO:root:current train perplexity5.449369430541992
INFO:root:current mean train loss 4305.587422878943
INFO:root:current train perplexity5.451178073883057
INFO:root:current mean train loss 4300.950381782111
INFO:root:current train perplexity5.444576740264893
INFO:root:current mean train loss 4299.579154708758
INFO:root:current train perplexity5.441093921661377
INFO:root:current mean train loss 4300.557286501216
INFO:root:current train perplexity5.448571681976318
INFO:root:current mean train loss 4300.132314035344
INFO:root:current train perplexity5.4521684646606445


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.98s/it]
INFO:root:final mean train loss: 4299.012044845089
INFO:root:final train perplexity: 5.452556610107422
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.76s/it]
INFO:root:eval mean loss: 4210.456703997673
INFO:root:eval perplexity: 5.4881157875061035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/18

  9%|â–‰         | 18/200 [45:19<8:14:17, 162.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4261.357308321221
INFO:root:current train perplexity5.390012264251709
INFO:root:current mean train loss 4281.864592438811
INFO:root:current train perplexity5.405531883239746
INFO:root:current mean train loss 4275.446170508616
INFO:root:current train perplexity5.396546840667725
INFO:root:current mean train loss 4281.821180160122
INFO:root:current train perplexity5.41036319732666
INFO:root:current mean train loss 4282.623779847982
INFO:root:current train perplexity5.406428337097168
INFO:root:current mean train loss 4282.900969728361
INFO:root:current train perplexity5.404019355773926
INFO:root:current mean train loss 4278.719095897526
INFO:root:current train perplexity5.397762298583984
INFO:root:current mean train loss 4275.196185228802
INFO:root:current train perplexity5.392874240875244
INFO:root:current mean train loss 4271.595548763253
INFO:root:current train perplexity5.390289306640625
INFO:root:current mean train loss 4270.616896239975
INFO:root:current train perplexity5.387421607971191


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.76s/it]
INFO:root:final mean train loss: 4269.732052956858
INFO:root:final train perplexity: 5.389933109283447
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.14s/it]
INFO:root:eval mean loss: 4190.6984932541
INFO:root:eval perplexity: 5.444443225860596
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/19

 10%|â–‰         | 19/200 [47:42<7:53:45, 157.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4216.281685623469
INFO:root:current train perplexity5.257584095001221
INFO:root:current mean train loss 4212.113345923013
INFO:root:current train perplexity5.264171123504639
INFO:root:current mean train loss 4241.827846815861
INFO:root:current train perplexity5.293347358703613
INFO:root:current mean train loss 4233.854640341213
INFO:root:current train perplexity5.30442476272583
INFO:root:current mean train loss 4239.620165907359
INFO:root:current train perplexity5.308345794677734
INFO:root:current mean train loss 4237.731500698304
INFO:root:current train perplexity5.313047409057617
INFO:root:current mean train loss 4245.272126416091
INFO:root:current train perplexity5.3258514404296875
INFO:root:current mean train loss 4246.383227311501
INFO:root:current train perplexity5.326902866363525
INFO:root:current mean train loss 4246.17212229638
INFO:root:current train perplexity5.32972526550293
INFO:root:current mean train loss 4248.3986125829715
INFO:root:current train perplexity5.332703113555908


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.68s/it]
INFO:root:final mean train loss: 4241.960872157927
INFO:root:final train perplexity: 5.33120059967041
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.11s/it]
INFO:root:eval mean loss: 4175.663257355385
INFO:root:eval perplexity: 5.411441802978516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/20

 10%|â–ˆ         | 20/200 [50:08<7:40:46, 153.59s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4246.251609672934
INFO:root:current train perplexity5.2774271965026855
INFO:root:current mean train loss 4237.504878206073
INFO:root:current train perplexity5.273019790649414
INFO:root:current mean train loss 4230.082292357927
INFO:root:current train perplexity5.274594783782959
INFO:root:current mean train loss 4228.23757127002
INFO:root:current train perplexity5.284216403961182
INFO:root:current mean train loss 4223.814351532714
INFO:root:current train perplexity5.278547763824463
INFO:root:current mean train loss 4220.340743445327
INFO:root:current train perplexity5.274872779846191
INFO:root:current mean train loss 4222.784180057972
INFO:root:current train perplexity5.276922702789307
INFO:root:current mean train loss 4226.526630306118
INFO:root:current train perplexity5.286316394805908
INFO:root:current mean train loss 4224.536890529504
INFO:root:current train perplexity5.285196304321289
INFO:root:current mean train loss 4221.710887602646
INFO:root:current train perplexity5.281084060668945


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.41s/it]
INFO:root:final mean train loss: 4217.1389646222515
INFO:root:final train perplexity: 5.2792463302612305
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.07s/it]
INFO:root:eval mean loss: 4165.596535973515
INFO:root:eval perplexity: 5.389459133148193
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/21

 10%|â–ˆ         | 21/200 [52:51<7:47:13, 156.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4165.508934818097
INFO:root:current train perplexity5.208347797393799
INFO:root:current mean train loss 4180.31428646613
INFO:root:current train perplexity5.230991840362549
INFO:root:current mean train loss 4186.676786158415
INFO:root:current train perplexity5.222903728485107
INFO:root:current mean train loss 4184.293934003534
INFO:root:current train perplexity5.213982582092285
INFO:root:current mean train loss 4189.587301446232
INFO:root:current train perplexity5.2207441329956055
INFO:root:current mean train loss 4189.210491415895
INFO:root:current train perplexity5.215853214263916
INFO:root:current mean train loss 4191.168014137463
INFO:root:current train perplexity5.217285633087158
INFO:root:current mean train loss 4191.887242044899
INFO:root:current train perplexity5.216954231262207
INFO:root:current mean train loss 4193.4365682106945
INFO:root:current train perplexity5.218026161193848
INFO:root:current mean train loss 4192.637832404909
INFO:root:current train perplexity5.221764087677002


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.59s/it]
INFO:root:final mean train loss: 4190.967490473101
INFO:root:final train perplexity: 5.225016117095947
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.21s/it]
INFO:root:eval mean loss: 4143.719442597518
INFO:root:eval perplexity: 5.341991424560547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/22

 11%|â–ˆ         | 22/200 [55:46<8:00:27, 161.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4180.6849967447915
INFO:root:current train perplexity5.172339916229248
INFO:root:current mean train loss 4170.722045200893
INFO:root:current train perplexity5.178376197814941
INFO:root:current mean train loss 4162.731253551136
INFO:root:current train perplexity5.1577630043029785
INFO:root:current mean train loss 4163.182658203125
INFO:root:current train perplexity5.1653547286987305
INFO:root:current mean train loss 4165.233677528783
INFO:root:current train perplexity5.170743942260742
INFO:root:current mean train loss 4170.100718834919
INFO:root:current train perplexity5.175800323486328
INFO:root:current mean train loss 4168.1830045572915
INFO:root:current train perplexity5.178224563598633
INFO:root:current mean train loss 4172.319073840726
INFO:root:current train perplexity5.180495262145996
INFO:root:current mean train loss 4172.557348493304
INFO:root:current train perplexity5.180362701416016
INFO:root:current mean train loss 4174.574664212741
INFO:root:current train perplexity5.181873321533203


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.10s/it]
INFO:root:final mean train loss: 4169.473950785975
INFO:root:final train perplexity: 5.180896282196045
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.09s/it]
INFO:root:eval mean loss: 4136.173630734707
INFO:root:eval perplexity: 5.3257155418396
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/23

 12%|â–ˆâ–        | 23/200 [58:27<7:56:59, 161.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4152.443188770708
INFO:root:current train perplexity5.094977378845215
INFO:root:current mean train loss 4148.7295162013315
INFO:root:current train perplexity5.1148247718811035
INFO:root:current mean train loss 4148.683217618153
INFO:root:current train perplexity5.116751670837402
INFO:root:current mean train loss 4153.790422165674
INFO:root:current train perplexity5.125071048736572
INFO:root:current mean train loss 4156.345985681127
INFO:root:current train perplexity5.132020473480225
INFO:root:current mean train loss 4149.435827448274
INFO:root:current train perplexity5.1249895095825195
INFO:root:current mean train loss 4144.09806946605
INFO:root:current train perplexity5.118597984313965
INFO:root:current mean train loss 4149.6489691216675
INFO:root:current train perplexity5.130157947540283
INFO:root:current mean train loss 4148.908673157914
INFO:root:current train perplexity5.1331305503845215
INFO:root:current mean train loss 4149.634484478319
INFO:root:current train perplexity5.134218215942383


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.43s/it]
INFO:root:final mean train loss: 4146.434617811634
INFO:root:final train perplexity: 5.134016513824463
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.82s/it]
INFO:root:eval mean loss: 4127.166909075798
INFO:root:eval perplexity: 5.3063554763793945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/24

 12%|â–ˆâ–        | 24/200 [1:01:17<8:01:26, 164.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4096.438433636676
INFO:root:current train perplexity5.053893566131592
INFO:root:current mean train loss 4111.305356010716
INFO:root:current train perplexity5.076311111450195
INFO:root:current mean train loss 4108.970057117161
INFO:root:current train perplexity5.065956115722656
INFO:root:current mean train loss 4120.025353785366
INFO:root:current train perplexity5.086002826690674
INFO:root:current mean train loss 4120.677512112557
INFO:root:current train perplexity5.089858055114746
INFO:root:current mean train loss 4126.332940064509
INFO:root:current train perplexity5.093196392059326
INFO:root:current mean train loss 4128.5803547706
INFO:root:current train perplexity5.095904350280762
INFO:root:current mean train loss 4132.446005106273
INFO:root:current train perplexity5.096590518951416
INFO:root:current mean train loss 4130.971133590681
INFO:root:current train perplexity5.098642349243164
INFO:root:current mean train loss 4129.9289464556
INFO:root:current train perplexity5.094106674194336


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.85s/it]
INFO:root:final mean train loss: 4126.595829133064
INFO:root:final train perplexity: 5.093990802764893
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.96s/it]
INFO:root:eval mean loss: 4115.029599886414
INFO:root:eval perplexity: 5.2803754806518555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/25

 12%|â–ˆâ–Ž        | 25/200 [1:03:42<7:41:59, 158.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4081.773859197443
INFO:root:current train perplexity5.065289497375488
INFO:root:current mean train loss 4092.1721215943
INFO:root:current train perplexity5.036725044250488
INFO:root:current mean train loss 4105.7383375901445
INFO:root:current train perplexity5.047388553619385
INFO:root:current mean train loss 4111.9289458999065
INFO:root:current train perplexity5.056955814361572
INFO:root:current mean train loss 4110.873213223322
INFO:root:current train perplexity5.052855014801025
INFO:root:current mean train loss 4108.817653445847
INFO:root:current train perplexity5.0466718673706055
INFO:root:current mean train loss 4109.301363135954
INFO:root:current train perplexity5.048401355743408
INFO:root:current mean train loss 4112.291769741474
INFO:root:current train perplexity5.051088333129883
INFO:root:current mean train loss 4111.965706525045
INFO:root:current train perplexity5.055047035217285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.27s/it]
INFO:root:final mean train loss: 4106.250305729528
INFO:root:final train perplexity: 5.05326509475708
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.70s/it]
INFO:root:eval mean loss: 4107.724304632092
INFO:root:eval perplexity: 5.264800071716309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/26

 13%|â–ˆâ–Ž        | 26/200 [1:06:01<7:22:18, 152.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4155.212541852678
INFO:root:current train perplexity5.131297588348389
INFO:root:current mean train loss 4080.2335764091704
INFO:root:current train perplexity5.020907878875732
INFO:root:current mean train loss 4089.55729284609
INFO:root:current train perplexity5.028931617736816
INFO:root:current mean train loss 4092.4910224641185
INFO:root:current train perplexity5.027078151702881
INFO:root:current mean train loss 4099.384444703048
INFO:root:current train perplexity5.037968635559082
INFO:root:current mean train loss 4090.2835474258814
INFO:root:current train perplexity5.025545597076416
INFO:root:current mean train loss 4093.0009101980795
INFO:root:current train perplexity5.0191168785095215
INFO:root:current mean train loss 4093.7537584534125
INFO:root:current train perplexity5.021734237670898
INFO:root:current mean train loss 4091.5569836924956
INFO:root:current train perplexity5.018545150756836
INFO:root:current mean train loss 4089.0107540311465
INFO:root:current train perplexity5.01466703414917


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.30s/it]
INFO:root:final mean train loss: 4087.1610573184107
INFO:root:final train perplexity: 5.015350818634033
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.62s/it]
INFO:root:eval mean loss: 4096.468343098958
INFO:root:eval perplexity: 5.240891456604004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/27

 14%|â–ˆâ–Ž        | 27/200 [1:08:19<7:07:51, 148.39s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4100.883024088542
INFO:root:current train perplexity4.950514793395996
INFO:root:current mean train loss 4051.340446671196
INFO:root:current train perplexity4.962143421173096
INFO:root:current mean train loss 4049.294136082849
INFO:root:current train perplexity4.959287643432617
INFO:root:current mean train loss 4062.9345478360615
INFO:root:current train perplexity4.973849296569824
INFO:root:current mean train loss 4072.174807628953
INFO:root:current train perplexity4.9850568771362305
INFO:root:current mean train loss 4067.0223272527305
INFO:root:current train perplexity4.975025177001953
INFO:root:current mean train loss 4069.668797637195
INFO:root:current train perplexity4.975805282592773
INFO:root:current mean train loss 4070.7646624371723
INFO:root:current train perplexity4.97502326965332
INFO:root:current mean train loss 4073.673304795341
INFO:root:current train perplexity4.977740287780762
INFO:root:current mean train loss 4070.8446678620217
INFO:root:current train perplexity4.976919651031494


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.81s/it]
INFO:root:final mean train loss: 4069.7663014319637
INFO:root:final train perplexity: 4.981049537658691
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.24s/it]
INFO:root:eval mean loss: 4088.196437970966
INFO:root:eval perplexity: 5.223390102386475
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/28

 14%|â–ˆâ–        | 28/200 [1:10:39<6:58:04, 145.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4088.31982421875
INFO:root:current train perplexity4.966367244720459
INFO:root:current mean train loss 4054.743771436738
INFO:root:current train perplexity4.930330276489258
INFO:root:current mean train loss 4062.5356850388876
INFO:root:current train perplexity4.953213214874268
INFO:root:current mean train loss 4052.740119485294
INFO:root:current train perplexity4.943559169769287
INFO:root:current mean train loss 4064.7133708259457
INFO:root:current train perplexity4.953191757202148
INFO:root:current mean train loss 4065.385527922592
INFO:root:current train perplexity4.9522199630737305
INFO:root:current mean train loss 4058.153114967897
INFO:root:current train perplexity4.947749614715576
INFO:root:current mean train loss 4055.4920065050137
INFO:root:current train perplexity4.947195053100586
INFO:root:current mean train loss 4058.1837035094545
INFO:root:current train perplexity4.94824743270874
INFO:root:current mean train loss 4056.216611984104
INFO:root:current train perplexity4.947617053985596


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.23s/it]
INFO:root:final mean train loss: 4051.9195176401445
INFO:root:final train perplexity: 4.94610071182251
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.71s/it]
INFO:root:eval mean loss: 4083.3489496758643
INFO:root:eval perplexity: 5.213160991668701
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/29

 14%|â–ˆâ–        | 29/200 [1:12:59<6:50:28, 144.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4060.4165117817543
INFO:root:current train perplexity4.907332897186279
INFO:root:current mean train loss 4041.5398936963265
INFO:root:current train perplexity4.902817726135254
INFO:root:current mean train loss 4056.4887716450216
INFO:root:current train perplexity4.91624641418457
INFO:root:current mean train loss 4058.149223765578
INFO:root:current train perplexity4.915387153625488
INFO:root:current mean train loss 4055.1816151346793
INFO:root:current train perplexity4.911008834838867
INFO:root:current mean train loss 4050.9819575020597
INFO:root:current train perplexity4.912191390991211
INFO:root:current mean train loss 4045.444670228308
INFO:root:current train perplexity4.9082818031311035
INFO:root:current mean train loss 4045.4394504531465
INFO:root:current train perplexity4.911700248718262
INFO:root:current mean train loss 4042.3283218402153
INFO:root:current train perplexity4.90847635269165
INFO:root:current mean train loss 4037.216645303269
INFO:root:current train perplexity4.9105143547058105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.44s/it]
INFO:root:final mean train loss: 4034.16817222103
INFO:root:final train perplexity: 4.911581516265869
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.60s/it]
INFO:root:eval mean loss: 4074.030465633311
INFO:root:eval perplexity: 5.193554878234863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/30

 15%|â–ˆâ–Œ        | 30/200 [1:15:20<6:45:26, 143.10s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 4018.7621131310098
INFO:root:current train perplexity4.901172161102295
INFO:root:current mean train loss 4014.0553233194696
INFO:root:current train perplexity4.88677978515625
INFO:root:current mean train loss 4017.7108108328976
INFO:root:current train perplexity4.870617389678955
INFO:root:current mean train loss 4013.75927734375
INFO:root:current train perplexity4.867328643798828
INFO:root:current mean train loss 4020.5373396124005
INFO:root:current train perplexity4.87111759185791
INFO:root:current mean train loss 4018.74761793034
INFO:root:current train perplexity4.873542308807373
INFO:root:current mean train loss 4018.006148981563
INFO:root:current train perplexity4.8748626708984375
INFO:root:current mean train loss 4022.7283841392505
INFO:root:current train perplexity4.878904819488525
INFO:root:current mean train loss 4022.685080127011
INFO:root:current train perplexity4.882373809814453
INFO:root:current mean train loss 4021.7620247707832
INFO:root:current train perplexity4.881998538970947


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.94s/it]
INFO:root:final mean train loss: 4018.1951804622527
INFO:root:final train perplexity: 4.880727767944336
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.64s/it]
INFO:root:eval mean loss: 4066.870009834885
INFO:root:eval perplexity: 5.178538799285889
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/31

 16%|â–ˆâ–Œ        | 31/200 [1:17:39<6:39:56, 141.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3992.1905855219416
INFO:root:current train perplexity4.822140216827393
INFO:root:current mean train loss 3991.1648231558247
INFO:root:current train perplexity4.819125652313232
INFO:root:current mean train loss 3984.086890340334
INFO:root:current train perplexity4.807332515716553
INFO:root:current mean train loss 3995.9155885548003
INFO:root:current train perplexity4.822633743286133
INFO:root:current mean train loss 4000.5265862040337
INFO:root:current train perplexity4.831341743469238
INFO:root:current mean train loss 4001.8557003934816
INFO:root:current train perplexity4.840303897857666
INFO:root:current mean train loss 4005.9800174483194
INFO:root:current train perplexity4.846250534057617
INFO:root:current mean train loss 4001.405524114688
INFO:root:current train perplexity4.846331596374512
INFO:root:current mean train loss 4003.869126501162
INFO:root:current train perplexity4.850161075592041
INFO:root:current mean train loss 4003.820691730052
INFO:root:current train perplexity4.849119186401367


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.48s/it]
INFO:root:final mean train loss: 4002.5171719212685
INFO:root:final train perplexity: 4.850631237030029
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.86s/it]
INFO:root:eval mean loss: 4059.6878307153147
INFO:root:eval perplexity: 5.163519859313965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/32

 16%|â–ˆâ–Œ        | 32/200 [1:20:02<6:37:45, 142.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3978.5020463423293
INFO:root:current train perplexity4.743934154510498
INFO:root:current mean train loss 4000.3447281376007
INFO:root:current train perplexity4.806218147277832
INFO:root:current mean train loss 3980.8256232766544
INFO:root:current train perplexity4.797323226928711
INFO:root:current mean train loss 3974.329385590889
INFO:root:current train perplexity4.80375337600708
INFO:root:current mean train loss 3984.0282183636677
INFO:root:current train perplexity4.815423488616943
INFO:root:current mean train loss 3984.8881708368526
INFO:root:current train perplexity4.81547737121582
INFO:root:current mean train loss 3989.0626688484017
INFO:root:current train perplexity4.817407608032227
INFO:root:current mean train loss 3990.8435084462953
INFO:root:current train perplexity4.818020820617676
INFO:root:current mean train loss 3991.375359215095
INFO:root:current train perplexity4.818345546722412
INFO:root:current mean train loss 3990.7407341602584
INFO:root:current train perplexity4.822023391723633


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.61s/it]
INFO:root:final mean train loss: 3986.634295555853
INFO:root:final train perplexity: 4.820331573486328
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.87s/it]
INFO:root:eval mean loss: 4053.29732691988
INFO:root:eval perplexity: 5.150193214416504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/33

 16%|â–ˆâ–‹        | 33/200 [1:22:22<6:33:56, 141.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3919.6976492745534
INFO:root:current train perplexity4.73756742477417
INFO:root:current mean train loss 3950.523274240318
INFO:root:current train perplexity4.781897068023682
INFO:root:current mean train loss 3949.5582874138545
INFO:root:current train perplexity4.781093120574951
INFO:root:current mean train loss 3959.300904329158
INFO:root:current train perplexity4.78218936920166
INFO:root:current mean train loss 3968.8586378324107
INFO:root:current train perplexity4.784897327423096
INFO:root:current mean train loss 3965.5612311625778
INFO:root:current train perplexity4.778982162475586
INFO:root:current mean train loss 3968.782378644066
INFO:root:current train perplexity4.786322116851807
INFO:root:current mean train loss 3966.8169601260443
INFO:root:current train perplexity4.782247543334961
INFO:root:current mean train loss 3968.5564872945033
INFO:root:current train perplexity4.783337593078613
INFO:root:current mean train loss 3975.8652625158197
INFO:root:current train perplexity4.793994426727295


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.43s/it]
INFO:root:final mean train loss: 3972.679131231
INFO:root:final train perplexity: 4.793865203857422
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.88s/it]
INFO:root:eval mean loss: 4048.0106885111923
INFO:root:eval perplexity: 5.139196395874023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/34

 17%|â–ˆâ–‹        | 34/200 [1:24:42<6:30:24, 141.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3989.548260755942
INFO:root:current train perplexity4.769256591796875
INFO:root:current mean train loss 3955.2989980240313
INFO:root:current train perplexity4.7490434646606445
INFO:root:current mean train loss 3950.881230540821
INFO:root:current train perplexity4.751188278198242
INFO:root:current mean train loss 3952.63641077746
INFO:root:current train perplexity4.745697021484375
INFO:root:current mean train loss 3952.526410210158
INFO:root:current train perplexity4.7464094161987305
INFO:root:current mean train loss 3956.8506197152747
INFO:root:current train perplexity4.756590843200684
INFO:root:current mean train loss 3959.6973638634036
INFO:root:current train perplexity4.761374473571777
INFO:root:current mean train loss 3958.267731702436
INFO:root:current train perplexity4.760285377502441
INFO:root:current mean train loss 3961.976106453161
INFO:root:current train perplexity4.764413833618164
INFO:root:current mean train loss 3960.814754592157
INFO:root:current train perplexity4.766124725341797


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.37s/it]
INFO:root:final mean train loss: 3958.065667306223
INFO:root:final train perplexity: 4.766305446624756
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.53s/it]
INFO:root:eval mean loss: 4046.3441170766846
INFO:root:eval perplexity: 5.135733604431152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/35

 18%|â–ˆâ–Š        | 35/200 [1:27:29<6:49:05, 148.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3968.4088181121438
INFO:root:current train perplexity4.757059097290039
INFO:root:current mean train loss 3948.3541430254886
INFO:root:current train perplexity4.726648807525635
INFO:root:current mean train loss 3952.303192904346
INFO:root:current train perplexity4.739182472229004
INFO:root:current mean train loss 3950.0771703392975
INFO:root:current train perplexity4.735912799835205
INFO:root:current mean train loss 3948.100827019996
INFO:root:current train perplexity4.738227367401123
INFO:root:current mean train loss 3951.2878919743093
INFO:root:current train perplexity4.7372612953186035
INFO:root:current mean train loss 3951.460352856913
INFO:root:current train perplexity4.74022912979126
INFO:root:current mean train loss 3949.0621044859195
INFO:root:current train perplexity4.739828109741211
INFO:root:current mean train loss 3946.9262059269236
INFO:root:current train perplexity4.737831115722656
INFO:root:current mean train loss 3946.71621482779
INFO:root:current train perplexity4.739774703979492


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.25s/it]
INFO:root:final mean train loss: 3943.684376378213
INFO:root:final train perplexity: 4.739338397979736
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.88s/it]
INFO:root:eval mean loss: 4041.994923260195
INFO:root:eval perplexity: 5.126709938049316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/36

 18%|â–ˆâ–Š        | 36/200 [1:29:55<6:44:54, 148.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3899.3569644621048
INFO:root:current train perplexity4.68980073928833
INFO:root:current mean train loss 3908.6057089739306
INFO:root:current train perplexity4.6855149269104
INFO:root:current mean train loss 3919.214543465538
INFO:root:current train perplexity4.692706108093262
INFO:root:current mean train loss 3924.050173106428
INFO:root:current train perplexity4.700933456420898
INFO:root:current mean train loss 3920.128051005839
INFO:root:current train perplexity4.7036590576171875
INFO:root:current mean train loss 3921.983685001198
INFO:root:current train perplexity4.707526206970215
INFO:root:current mean train loss 3927.2244171187
INFO:root:current train perplexity4.710384845733643
INFO:root:current mean train loss 3930.2779691470773
INFO:root:current train perplexity4.712934494018555
INFO:root:current mean train loss 3931.527356135939
INFO:root:current train perplexity4.711233615875244
INFO:root:current mean train loss 3933.859354469431
INFO:root:current train perplexity4.715961933135986


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.31s/it]
INFO:root:final mean train loss: 3931.015585807062
INFO:root:final train perplexity: 4.715709686279297
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.05s/it]
INFO:root:eval mean loss: 4034.340517301086
INFO:root:eval perplexity: 5.110866069793701
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/37

 18%|â–ˆâ–Š        | 37/200 [1:32:15<6:35:57, 145.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3894.8241647820723
INFO:root:current train perplexity4.648067474365234
INFO:root:current mean train loss 3895.718310546875
INFO:root:current train perplexity4.655712127685547
INFO:root:current mean train loss 3904.07529296875
INFO:root:current train perplexity4.670395851135254
INFO:root:current mean train loss 3896.5852848101267
INFO:root:current train perplexity4.670260906219482
INFO:root:current mean train loss 3902.670050603693
INFO:root:current train perplexity4.6746344566345215
INFO:root:current mean train loss 3907.441622488839
INFO:root:current train perplexity4.678903579711914
INFO:root:current mean train loss 3908.4929438090153
INFO:root:current train perplexity4.67957878112793
INFO:root:current mean train loss 3914.728871855346
INFO:root:current train perplexity4.685747146606445
INFO:root:current mean train loss 3920.196696327252
INFO:root:current train perplexity4.689698219299316


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.84s/it]
INFO:root:final mean train loss: 3917.0057198309128
INFO:root:final train perplexity: 4.689716339111328
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.53s/it]
INFO:root:eval mean loss: 4033.1917889101287
INFO:root:eval perplexity: 5.108492851257324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/38

 19%|â–ˆâ–‰        | 38/200 [1:34:36<6:29:02, 144.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3834.1324869791665
INFO:root:current train perplexity4.496001243591309
INFO:root:current mean train loss 3908.2996458775788
INFO:root:current train perplexity4.653006553649902
INFO:root:current mean train loss 3900.849943715363
INFO:root:current train perplexity4.649723529815674
INFO:root:current mean train loss 3903.3675798976383
INFO:root:current train perplexity4.6498212814331055
INFO:root:current mean train loss 3899.2191383229297
INFO:root:current train perplexity4.647025108337402
INFO:root:current mean train loss 3901.161294925758
INFO:root:current train perplexity4.646100997924805
INFO:root:current mean train loss 3905.6876983895627
INFO:root:current train perplexity4.653697967529297
INFO:root:current mean train loss 3904.0427471828325
INFO:root:current train perplexity4.658911228179932
INFO:root:current mean train loss 3906.476208602506
INFO:root:current train perplexity4.6608076095581055
INFO:root:current mean train loss 3908.587597007371
INFO:root:current train perplexity4.664065837860107


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.81s/it]
INFO:root:final mean train loss: 3905.5460602544968
INFO:root:final train perplexity: 4.6685614585876465
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.36s/it]
INFO:root:eval mean loss: 4029.771617700022
INFO:root:eval perplexity: 5.1014323234558105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/39

 20%|â–ˆâ–‰        | 39/200 [1:36:55<6:22:34, 142.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3842.0480513139205
INFO:root:current train perplexity4.569801330566406
INFO:root:current mean train loss 3871.703905810107
INFO:root:current train perplexity4.604921817779541
INFO:root:current mean train loss 3882.8745429594933
INFO:root:current train perplexity4.614688873291016
INFO:root:current mean train loss 3884.212142502763
INFO:root:current train perplexity4.631149768829346
INFO:root:current mean train loss 3886.6281257128194
INFO:root:current train perplexity4.637455940246582
INFO:root:current mean train loss 3891.426842855614
INFO:root:current train perplexity4.64006233215332
INFO:root:current mean train loss 3890.414663861114
INFO:root:current train perplexity4.6371541023254395
INFO:root:current mean train loss 3893.3026341090895
INFO:root:current train perplexity4.643310546875
INFO:root:current mean train loss 3893.8338332546623
INFO:root:current train perplexity4.642265319824219
INFO:root:current mean train loss 3895.5473080749175
INFO:root:current train perplexity4.645000457763672


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.21s/it]
INFO:root:final mean train loss: 3893.156410832559
INFO:root:final train perplexity: 4.645796775817871
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.16s/it]
INFO:root:eval mean loss: 4025.924274850399
INFO:root:eval perplexity: 5.093501567840576
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/40

 20%|â–ˆâ–ˆ        | 40/200 [1:39:18<6:20:42, 142.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3888.5820184004933
INFO:root:current train perplexity4.632064342498779
INFO:root:current mean train loss 3878.1627761456143
INFO:root:current train perplexity4.621667385101318
INFO:root:current mean train loss 3874.473272732948
INFO:root:current train perplexity4.6157379150390625
INFO:root:current mean train loss 3883.880575437157
INFO:root:current train perplexity4.618476867675781
INFO:root:current mean train loss 3883.6652476599793
INFO:root:current train perplexity4.619524955749512
INFO:root:current mean train loss 3887.1988113785524
INFO:root:current train perplexity4.623079776763916
INFO:root:current mean train loss 3885.7898170089106
INFO:root:current train perplexity4.621519565582275
INFO:root:current mean train loss 3890.4991171549027
INFO:root:current train perplexity4.628807067871094
INFO:root:current mean train loss 3887.2553436689177
INFO:root:current train perplexity4.625405788421631
INFO:root:current mean train loss 3884.0061205178013
INFO:root:current train perplexity4.624417304992676


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.35s/it]
INFO:root:final mean train loss: 3880.7281232034006
INFO:root:final train perplexity: 4.623073101043701
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.74s/it]
INFO:root:eval mean loss: 4020.4527354138963
INFO:root:eval perplexity: 5.082244873046875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/41

 20%|â–ˆâ–ˆ        | 41/200 [1:41:38<6:16:05, 141.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3827.615632233796
INFO:root:current train perplexity4.580988883972168
INFO:root:current mean train loss 3851.3692540446605
INFO:root:current train perplexity4.573370456695557
INFO:root:current mean train loss 3856.3058200113574
INFO:root:current train perplexity4.5845947265625
INFO:root:current mean train loss 3858.1627999868597
INFO:root:current train perplexity4.5800676345825195
INFO:root:current mean train loss 3859.8609993642053
INFO:root:current train perplexity4.587243556976318
INFO:root:current mean train loss 3860.7249554339123
INFO:root:current train perplexity4.583769798278809
INFO:root:current mean train loss 3864.2243169513804
INFO:root:current train perplexity4.5853424072265625
INFO:root:current mean train loss 3869.21924298272
INFO:root:current train perplexity4.593594551086426
INFO:root:current mean train loss 3874.0539961126437
INFO:root:current train perplexity4.600907802581787
INFO:root:current mean train loss 3873.6206012548882
INFO:root:current train perplexity4.601521015167236


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.07s/it]
INFO:root:final mean train loss: 3869.9194754938926
INFO:root:final train perplexity: 4.603400707244873
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.62s/it]
INFO:root:eval mean loss: 4017.7006022135415
INFO:root:eval perplexity: 5.076591491699219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/42

 21%|â–ˆâ–ˆ        | 42/200 [1:43:57<6:11:52, 141.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3798.319321986607
INFO:root:current train perplexity4.543848037719727
INFO:root:current mean train loss 3821.6823423032406
INFO:root:current train perplexity4.554811477661133
INFO:root:current mean train loss 3839.6010014960107
INFO:root:current train perplexity4.558464050292969
INFO:root:current mean train loss 3851.7684745219217
INFO:root:current train perplexity4.571951389312744
INFO:root:current mean train loss 3854.8618057426365
INFO:root:current train perplexity4.572254657745361
INFO:root:current mean train loss 3857.615566588785
INFO:root:current train perplexity4.575134754180908
INFO:root:current mean train loss 3857.3330328032725
INFO:root:current train perplexity4.577587127685547
INFO:root:current mean train loss 3861.46366622821
INFO:root:current train perplexity4.579163551330566
INFO:root:current mean train loss 3858.6913062546782
INFO:root:current train perplexity4.57691764831543
INFO:root:current mean train loss 3858.8132856889206
INFO:root:current train perplexity4.577672481536865


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.26s/it]
INFO:root:final mean train loss: 3857.6370735168457
INFO:root:final train perplexity: 4.581147193908691
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.71s/it]
INFO:root:eval mean loss: 4012.72359645113
INFO:root:eval perplexity: 5.066384792327881
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/43

 22%|â–ˆâ–ˆâ–       | 43/200 [1:46:17<6:08:25, 140.80s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3888.9259742914246
INFO:root:current train perplexity4.5689849853515625
INFO:root:current mean train loss 3864.3135550972465
INFO:root:current train perplexity4.568970203399658
INFO:root:current mean train loss 3854.1071988329477
INFO:root:current train perplexity4.548680305480957
INFO:root:current mean train loss 3851.626324623041
INFO:root:current train perplexity4.550333499908447
INFO:root:current mean train loss 3851.689115296099
INFO:root:current train perplexity4.548597812652588
INFO:root:current mean train loss 3852.695948704391
INFO:root:current train perplexity4.55426549911499
INFO:root:current mean train loss 3851.521824956867
INFO:root:current train perplexity4.554598808288574
INFO:root:current mean train loss 3848.50631545466
INFO:root:current train perplexity4.5553436279296875
INFO:root:current mean train loss 3849.4980155971975
INFO:root:current train perplexity4.559544563293457
INFO:root:current mean train loss 3849.290986110651
INFO:root:current train perplexity4.560606956481934


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.44s/it]
INFO:root:final mean train loss: 3846.243838587115
INFO:root:final train perplexity: 4.560600757598877
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.15s/it]
INFO:root:eval mean loss: 4015.4174770057625
INFO:root:eval perplexity: 5.0719075202941895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/44

 22%|â–ˆâ–ˆâ–       | 44/200 [1:48:41<6:08:08, 141.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3789.5877565870096
INFO:root:current train perplexity4.4967217445373535
INFO:root:current mean train loss 3824.909685753829
INFO:root:current train perplexity4.51227331161499
INFO:root:current mean train loss 3828.0853256894297
INFO:root:current train perplexity4.523330211639404
INFO:root:current mean train loss 3827.6254959323805
INFO:root:current train perplexity4.52353572845459
INFO:root:current mean train loss 3834.0925466194913
INFO:root:current train perplexity4.523965835571289
INFO:root:current mean train loss 3837.5671984885435
INFO:root:current train perplexity4.533330917358398
INFO:root:current mean train loss 3833.1988801033267
INFO:root:current train perplexity4.5316386222839355
INFO:root:current mean train loss 3835.905833888149
INFO:root:current train perplexity4.535512447357178
INFO:root:current mean train loss 3834.638354291367
INFO:root:current train perplexity4.536810874938965
INFO:root:current mean train loss 3837.1028104154343
INFO:root:current train perplexity4.538275718688965


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.56s/it]
INFO:root:final mean train loss: 3834.968143832299
INFO:root:final train perplexity: 4.540358543395996
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.88s/it]
INFO:root:eval mean loss: 4008.6893925227173
INFO:root:eval perplexity: 5.058126926422119
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/45

 22%|â–ˆâ–ˆâ–Ž       | 45/200 [1:51:03<6:06:21, 141.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3819.995444087659
INFO:root:current train perplexity4.488419055938721
INFO:root:current mean train loss 3828.3451580311516
INFO:root:current train perplexity4.518864631652832
INFO:root:current mean train loss 3824.7737400835545
INFO:root:current train perplexity4.520181655883789
INFO:root:current mean train loss 3822.175417419264
INFO:root:current train perplexity4.516841411590576
INFO:root:current mean train loss 3822.361787151927
INFO:root:current train perplexity4.518657207489014
INFO:root:current mean train loss 3823.3568121785556
INFO:root:current train perplexity4.518507957458496
INFO:root:current mean train loss 3828.250844304225
INFO:root:current train perplexity4.520938396453857
INFO:root:current mean train loss 3831.222313037817
INFO:root:current train perplexity4.519570827484131
INFO:root:current mean train loss 3828.8186902011785
INFO:root:current train perplexity4.521406650543213
INFO:root:current mean train loss 3827.921024962933
INFO:root:current train perplexity4.5213541984558105


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.36s/it]
INFO:root:final mean train loss: 3824.128850013979
INFO:root:final train perplexity: 4.52098274230957
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.88s/it]
INFO:root:eval mean loss: 4006.034652385306
INFO:root:eval perplexity: 5.052700996398926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/46

 23%|â–ˆâ–ˆâ–Ž       | 46/200 [1:53:23<6:02:41, 141.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3831.840681844683
INFO:root:current train perplexity4.503674507141113
INFO:root:current mean train loss 3820.451810734001
INFO:root:current train perplexity4.482394218444824
INFO:root:current mean train loss 3813.886208523525
INFO:root:current train perplexity4.48748779296875
INFO:root:current mean train loss 3819.196789983183
INFO:root:current train perplexity4.495573997497559
INFO:root:current mean train loss 3824.3163769740363
INFO:root:current train perplexity4.499786376953125
INFO:root:current mean train loss 3821.917961430087
INFO:root:current train perplexity4.499321460723877
INFO:root:current mean train loss 3823.1111484052894
INFO:root:current train perplexity4.505812168121338
INFO:root:current mean train loss 3819.185302416069
INFO:root:current train perplexity4.502701282501221
INFO:root:current mean train loss 3818.638650755569
INFO:root:current train perplexity4.503098011016846
INFO:root:current mean train loss 3817.2980866141256
INFO:root:current train perplexity4.502333641052246


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.24s/it]
INFO:root:final mean train loss: 3813.4608602216167
INFO:root:final train perplexity: 4.501995086669922
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.69s/it]
INFO:root:eval mean loss: 4007.081113558289
INFO:root:eval perplexity: 5.05483865737915
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/47

 24%|â–ˆâ–ˆâ–Ž       | 47/200 [1:55:42<5:58:25, 140.56s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3801.633291015625
INFO:root:current train perplexity4.4280781745910645
INFO:root:current mean train loss 3794.6375027901786
INFO:root:current train perplexity4.465475082397461
INFO:root:current mean train loss 3795.5829829545455
INFO:root:current train perplexity4.465440273284912
INFO:root:current mean train loss 3803.413442057292
INFO:root:current train perplexity4.476749897003174
INFO:root:current mean train loss 3803.5559467516446
INFO:root:current train perplexity4.479354381561279
INFO:root:current mean train loss 3805.8566987941576
INFO:root:current train perplexity4.481590747833252
INFO:root:current mean train loss 3805.091286892361
INFO:root:current train perplexity4.483064651489258
INFO:root:current mean train loss 3804.982448966734
INFO:root:current train perplexity4.486433029174805
INFO:root:current mean train loss 3806.0687901785714
INFO:root:current train perplexity4.487814426422119
INFO:root:current mean train loss 3806.827559845753
INFO:root:current train perplexity4.486064434051514


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.43s/it]
INFO:root:final mean train loss: 3804.240172109296
INFO:root:final train perplexity: 4.485647678375244
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.98s/it]
INFO:root:eval mean loss: 4002.052091990802
INFO:root:eval perplexity: 5.04456901550293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/48

 24%|â–ˆâ–ˆâ–       | 48/200 [1:58:02<5:55:50, 140.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3800.893837067018
INFO:root:current train perplexity4.447981834411621
INFO:root:current mean train loss 3802.3025489348533
INFO:root:current train perplexity4.445370197296143
INFO:root:current mean train loss 3789.145619961904
INFO:root:current train perplexity4.439930438995361
INFO:root:current mean train loss 3787.929605907311
INFO:root:current train perplexity4.452173709869385
INFO:root:current mean train loss 3788.316158065638
INFO:root:current train perplexity4.456259250640869
INFO:root:current mean train loss 3793.0510898806015
INFO:root:current train perplexity4.452210903167725
INFO:root:current mean train loss 3794.3979745979364
INFO:root:current train perplexity4.45614767074585
INFO:root:current mean train loss 3793.4045534876877
INFO:root:current train perplexity4.45952033996582
INFO:root:current mean train loss 3793.8642055559
INFO:root:current train perplexity4.461086273193359
INFO:root:current mean train loss 3797.0988712407807
INFO:root:current train perplexity4.46889591217041


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.56s/it]
INFO:root:final mean train loss: 3794.54500579834
INFO:root:final train perplexity: 4.468522548675537
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.24s/it]
INFO:root:eval mean loss: 4002.1515559203235
INFO:root:eval perplexity: 5.044773101806641
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/49

 24%|â–ˆâ–ˆâ–       | 49/200 [2:00:22<5:52:54, 140.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3786.986880794986
INFO:root:current train perplexity4.40211296081543
INFO:root:current mean train loss 3782.0720329883834
INFO:root:current train perplexity4.418801784515381
INFO:root:current mean train loss 3772.486033646102
INFO:root:current train perplexity4.424994945526123
INFO:root:current mean train loss 3776.7029283138186
INFO:root:current train perplexity4.431219577789307
INFO:root:current mean train loss 3777.643346347537
INFO:root:current train perplexity4.434667110443115
INFO:root:current mean train loss 3780.6308387201248
INFO:root:current train perplexity4.438381671905518
INFO:root:current mean train loss 3778.45642142841
INFO:root:current train perplexity4.436174392700195
INFO:root:current mean train loss 3781.409526299285
INFO:root:current train perplexity4.439534664154053
INFO:root:current mean train loss 3780.6877244120897
INFO:root:current train perplexity4.440732479095459
INFO:root:current mean train loss 3785.5804690949008
INFO:root:current train perplexity4.447591781616211


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:11<00:00, 131.07s/it]
INFO:root:final mean train loss: 3782.702458781581
INFO:root:final train perplexity: 4.44769287109375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.56s/it]
INFO:root:eval mean loss: 4001.253625748005
INFO:root:eval perplexity: 5.042941093444824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/50

 25%|â–ˆâ–ˆâ–Œ       | 50/200 [2:02:44<5:52:13, 140.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3760.552759035669
INFO:root:current train perplexity4.382673740386963
INFO:root:current mean train loss 3767.585846714039
INFO:root:current train perplexity4.40211296081543
INFO:root:current mean train loss 3770.7850100922346
INFO:root:current train perplexity4.411406993865967
INFO:root:current mean train loss 3772.8883512492166
INFO:root:current train perplexity4.414148330688477
INFO:root:current mean train loss 3776.9461946353645
INFO:root:current train perplexity4.425796985626221
INFO:root:current mean train loss 3775.639451576195
INFO:root:current train perplexity4.430315971374512
INFO:root:current mean train loss 3770.92318162386
INFO:root:current train perplexity4.429583549499512
INFO:root:current mean train loss 3770.909367299945
INFO:root:current train perplexity4.42956018447876
INFO:root:current mean train loss 3772.495379523255
INFO:root:current train perplexity4.4306745529174805


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.33s/it]
INFO:root:final mean train loss: 3774.6531947351273
INFO:root:final train perplexity: 4.433590888977051
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.09s/it]
INFO:root:eval mean loss: 4000.7194685699246
INFO:root:eval perplexity: 5.0418524742126465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/51

 26%|â–ˆâ–ˆâ–Œ       | 51/200 [2:04:58<5:44:09, 138.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3720.584647042411
INFO:root:current train perplexity4.396777153015137
INFO:root:current mean train loss 3763.820006753797
INFO:root:current train perplexity4.396605014801025
INFO:root:current mean train loss 3761.901107714372
INFO:root:current train perplexity4.403302192687988
INFO:root:current mean train loss 3771.0765146261706
INFO:root:current train perplexity4.403652667999268
INFO:root:current mean train loss 3772.116985349163
INFO:root:current train perplexity4.40985107421875
INFO:root:current mean train loss 3768.7608076768984
INFO:root:current train perplexity4.407993793487549
INFO:root:current mean train loss 3765.156077050299
INFO:root:current train perplexity4.407875061035156
INFO:root:current mean train loss 3761.9949804411244
INFO:root:current train perplexity4.409571170806885
INFO:root:current mean train loss 3765.4739943342433
INFO:root:current train perplexity4.413722515106201
INFO:root:current mean train loss 3765.8777811035693
INFO:root:current train perplexity4.4127373695373535


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.06s/it]
INFO:root:final mean train loss: 3763.933038219329
INFO:root:final train perplexity: 4.414879322052002
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.10s/it]
INFO:root:eval mean loss: 3997.393840383976
INFO:root:eval perplexity: 5.035076141357422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/52

 26%|â–ˆâ–ˆâ–Œ       | 52/200 [2:07:09<5:36:12, 136.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3772.311344401042
INFO:root:current train perplexity4.470869541168213
INFO:root:current mean train loss 3735.828764011549
INFO:root:current train perplexity4.371877193450928
INFO:root:current mean train loss 3739.012669195131
INFO:root:current train perplexity4.376255035400391
INFO:root:current mean train loss 3739.7266996837798
INFO:root:current train perplexity4.38268518447876
INFO:root:current mean train loss 3745.82735257436
INFO:root:current train perplexity4.382983684539795
INFO:root:current mean train loss 3748.8729933062805
INFO:root:current train perplexity4.38679313659668
INFO:root:current mean train loss 3747.0728340955284
INFO:root:current train perplexity4.3920722007751465
INFO:root:current mean train loss 3751.0398068728146
INFO:root:current train perplexity4.395570278167725
INFO:root:current mean train loss 3756.6369485117907
INFO:root:current train perplexity4.397525787353516
INFO:root:current mean train loss 3757.818687030396
INFO:root:current train perplexity4.39890193939209


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.42s/it]
INFO:root:final mean train loss: 3755.7427386007002
INFO:root:final train perplexity: 4.400637149810791
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.80s/it]
INFO:root:eval mean loss: 3993.4586848265735
INFO:root:eval perplexity: 5.027071475982666
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/53

 26%|â–ˆâ–ˆâ–‹       | 53/200 [2:09:26<5:34:30, 136.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3744.151473335598
INFO:root:current train perplexity4.4298601150512695
INFO:root:current mean train loss 3747.730577918572
INFO:root:current train perplexity4.3894171714782715
INFO:root:current mean train loss 3738.060950856572
INFO:root:current train perplexity4.377917766571045
INFO:root:current mean train loss 3748.288694399429
INFO:root:current train perplexity4.384324550628662
INFO:root:current mean train loss 3743.3413893967936
INFO:root:current train perplexity4.382513523101807
INFO:root:current mean train loss 3749.6549471386534
INFO:root:current train perplexity4.3891072273254395
INFO:root:current mean train loss 3751.8986710598915
INFO:root:current train perplexity4.388585090637207
INFO:root:current mean train loss 3747.6805809939056
INFO:root:current train perplexity4.3830060958862305
INFO:root:current mean train loss 3750.4090417465636
INFO:root:current train perplexity4.3866353034973145
INFO:root:current mean train loss 3752.309100811298
INFO:root:current train perplexity4.387686252593994


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.30s/it]
INFO:root:final mean train loss: 3747.062025808519
INFO:root:final train perplexity: 4.38559103012085
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.85s/it]
INFO:root:eval mean loss: 3995.0507777870125
INFO:root:eval perplexity: 5.030307769775391
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/54

 27%|â–ˆâ–ˆâ–‹       | 54/200 [2:11:47<5:35:28, 137.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3717.6671496975805
INFO:root:current train perplexity4.371532917022705
INFO:root:current mean train loss 3725.2854973014073
INFO:root:current train perplexity4.347834587097168
INFO:root:current mean train loss 3735.9718614718613
INFO:root:current train perplexity4.361048698425293
INFO:root:current mean train loss 3727.31982864426
INFO:root:current train perplexity4.352802753448486
INFO:root:current mean train loss 3731.130147911833
INFO:root:current train perplexity4.360291004180908
INFO:root:current mean train loss 3734.315163937441
INFO:root:current train perplexity4.367003917694092
INFO:root:current mean train loss 3732.842106403526
INFO:root:current train perplexity4.368732929229736
INFO:root:current mean train loss 3733.940962722298
INFO:root:current train perplexity4.367833137512207
INFO:root:current mean train loss 3735.5281675409897
INFO:root:current train perplexity4.368141174316406
INFO:root:current mean train loss 3737.245930639937
INFO:root:current train perplexity4.36666202545166


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.74s/it]
INFO:root:final mean train loss: 3736.003388004918
INFO:root:final train perplexity: 4.366497993469238
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.68s/it]
INFO:root:eval mean loss: 3995.7085186031695
INFO:root:eval perplexity: 5.031645774841309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/55

 28%|â–ˆâ–ˆâ–Š       | 55/200 [2:14:04<5:32:43, 137.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3689.1881009615386
INFO:root:current train perplexity4.306840419769287
INFO:root:current mean train loss 3725.466735400742
INFO:root:current train perplexity4.331445217132568
INFO:root:current mean train loss 3727.0401064820867
INFO:root:current train perplexity4.334951400756836
INFO:root:current mean train loss 3722.7335359916574
INFO:root:current train perplexity4.3297224044799805
INFO:root:current mean train loss 3719.54866351082
INFO:root:current train perplexity4.330430030822754
INFO:root:current mean train loss 3717.746746905438
INFO:root:current train perplexity4.336702823638916
INFO:root:current mean train loss 3719.8079140533305
INFO:root:current train perplexity4.340386390686035
INFO:root:current mean train loss 3723.6651130645296
INFO:root:current train perplexity4.347538471221924
INFO:root:current mean train loss 3726.2188701788773
INFO:root:current train perplexity4.349397659301758
INFO:root:current mean train loss 3729.946869123985
INFO:root:current train perplexity4.351930141448975


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.63s/it]
INFO:root:final mean train loss: 3727.7656732989894
INFO:root:final train perplexity: 4.352330207824707
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.42s/it]
INFO:root:eval mean loss: 3991.364957335993
INFO:root:eval perplexity: 5.022816181182861
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/56

 28%|â–ˆâ–ˆâ–Š       | 56/200 [2:16:29<5:35:42, 139.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3723.3267744348404
INFO:root:current train perplexity4.336665630340576
INFO:root:current mean train loss 3707.126715627657
INFO:root:current train perplexity4.316311359405518
INFO:root:current mean train loss 3713.1116592469
INFO:root:current train perplexity4.318936824798584
INFO:root:current mean train loss 3714.433974384231
INFO:root:current train perplexity4.32000732421875
INFO:root:current mean train loss 3713.363597485843
INFO:root:current train perplexity4.326416492462158
INFO:root:current mean train loss 3715.972594210609
INFO:root:current train perplexity4.328075408935547
INFO:root:current mean train loss 3721.493069726864
INFO:root:current train perplexity4.333038806915283
INFO:root:current mean train loss 3721.906496101594
INFO:root:current train perplexity4.335233211517334
INFO:root:current mean train loss 3723.421751920842
INFO:root:current train perplexity4.337167739868164
INFO:root:current mean train loss 3723.419431531316
INFO:root:current train perplexity4.337493896484375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.14s/it]
INFO:root:final mean train loss: 3718.9645214696084
INFO:root:final train perplexity: 4.337244033813477
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.59s/it]
INFO:root:eval mean loss: 3992.6756167580897
INFO:root:eval perplexity: 5.025479793548584
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/57

 28%|â–ˆâ–ˆâ–Š       | 57/200 [2:18:46<5:31:43, 139.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3671.603662109375
INFO:root:current train perplexity4.251554489135742
INFO:root:current mean train loss 3686.731153918851
INFO:root:current train perplexity4.287049293518066
INFO:root:current mean train loss 3696.067743757659
INFO:root:current train perplexity4.291613578796387
INFO:root:current mean train loss 3694.746073806118
INFO:root:current train perplexity4.292629241943359
INFO:root:current mean train loss 3705.4358468191963
INFO:root:current train perplexity4.304492473602295
INFO:root:current mean train loss 3706.7160028681024
INFO:root:current train perplexity4.310685157775879
INFO:root:current mean train loss 3707.784154341603
INFO:root:current train perplexity4.3156328201293945
INFO:root:current mean train loss 3709.0213236625623
INFO:root:current train perplexity4.321493625640869
INFO:root:current mean train loss 3710.398754168951
INFO:root:current train perplexity4.320735931396484
INFO:root:current mean train loss 3713.0294758262435
INFO:root:current train perplexity4.322630405426025


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.13s/it]
INFO:root:final mean train loss: 3710.8294170748804
INFO:root:final train perplexity: 4.323345184326172
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.79s/it]
INFO:root:eval mean loss: 3991.7707796570257
INFO:root:eval perplexity: 5.0236406326293945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/58

 29%|â–ˆâ–ˆâ–‰       | 58/200 [2:21:04<5:28:23, 138.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3699.1325179811506
INFO:root:current train perplexity4.307973384857178
INFO:root:current mean train loss 3680.8740758603335
INFO:root:current train perplexity4.267752170562744
INFO:root:current mean train loss 3689.9799321975997
INFO:root:current train perplexity4.276120185852051
INFO:root:current mean train loss 3682.545074546961
INFO:root:current train perplexity4.277657508850098
INFO:root:current mean train loss 3689.8477843842807
INFO:root:current train perplexity4.287867069244385
INFO:root:current mean train loss 3693.0995213456094
INFO:root:current train perplexity4.290958881378174
INFO:root:current mean train loss 3695.437708789946
INFO:root:current train perplexity4.294277667999268
INFO:root:current mean train loss 3697.113328606242
INFO:root:current train perplexity4.300318717956543
INFO:root:current mean train loss 3699.476625020369
INFO:root:current train perplexity4.305161476135254
INFO:root:current mean train loss 3704.291584018854
INFO:root:current train perplexity4.3091325759887695


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.81s/it]
INFO:root:final mean train loss: 3703.2507480498284
INFO:root:final train perplexity: 4.310438632965088
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.39s/it]
INFO:root:eval mean loss: 3989.84173280973
INFO:root:eval perplexity: 5.019723415374756
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/59

 30%|â–ˆâ–ˆâ–‰       | 59/200 [2:23:26<5:28:25, 139.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3690.185811647227
INFO:root:current train perplexity4.273333549499512
INFO:root:current mean train loss 3676.0220611750733
INFO:root:current train perplexity4.255645275115967
INFO:root:current mean train loss 3690.1144190714367
INFO:root:current train perplexity4.271223068237305
INFO:root:current mean train loss 3693.7673070038745
INFO:root:current train perplexity4.28186559677124
INFO:root:current mean train loss 3691.30297903397
INFO:root:current train perplexity4.287624835968018
INFO:root:current mean train loss 3692.653871018498
INFO:root:current train perplexity4.2909932136535645
INFO:root:current mean train loss 3693.1439629226434
INFO:root:current train perplexity4.292050838470459
INFO:root:current mean train loss 3695.6615954447348
INFO:root:current train perplexity4.292132377624512
INFO:root:current mean train loss 3695.714511315119
INFO:root:current train perplexity4.292938709259033
INFO:root:current mean train loss 3695.47459655196
INFO:root:current train perplexity4.293491363525391


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.82s/it]
INFO:root:final mean train loss: 3693.800807645244
INFO:root:final train perplexity: 4.294397830963135
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.62s/it]
INFO:root:eval mean loss: 3989.8595897052305
INFO:root:eval perplexity: 5.019760608673096
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/60

 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [2:25:46<5:25:45, 139.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3679.5055163419697
INFO:root:current train perplexity4.275417327880859
INFO:root:current mean train loss 3690.9591057633556
INFO:root:current train perplexity4.281270980834961
INFO:root:current mean train loss 3687.3970365353384
INFO:root:current train perplexity4.283115863800049
INFO:root:current mean train loss 3677.845817143181
INFO:root:current train perplexity4.276564598083496
INFO:root:current mean train loss 3678.6903282595576
INFO:root:current train perplexity4.273190975189209
INFO:root:current mean train loss 3682.4575330243415
INFO:root:current train perplexity4.278365135192871
INFO:root:current mean train loss 3680.5161794401233
INFO:root:current train perplexity4.274263381958008
INFO:root:current mean train loss 3683.5622781109596
INFO:root:current train perplexity4.277513027191162
INFO:root:current mean train loss 3685.4024198529933
INFO:root:current train perplexity4.277622222900391
INFO:root:current mean train loss 3689.797836599847
INFO:root:current train perplexity4.2819414138793945


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.65s/it]
INFO:root:final mean train loss: 3686.564203508439
INFO:root:final train perplexity: 4.282154083251953
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.44s/it]
INFO:root:eval mean loss: 3988.6576871398493
INFO:root:eval perplexity: 5.01732063293457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/61

 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [2:28:02<5:21:34, 138.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3665.8471427128234
INFO:root:current train perplexity4.226640224456787
INFO:root:current mean train loss 3673.463549935244
INFO:root:current train perplexity4.252928256988525
INFO:root:current mean train loss 3677.4476271572844
INFO:root:current train perplexity4.257781028747559
INFO:root:current mean train loss 3680.09614913901
INFO:root:current train perplexity4.261548042297363
INFO:root:current mean train loss 3681.365318595996
INFO:root:current train perplexity4.265275478363037
INFO:root:current mean train loss 3682.079041671103
INFO:root:current train perplexity4.264612674713135
INFO:root:current mean train loss 3681.280745016262
INFO:root:current train perplexity4.264842987060547
INFO:root:current mean train loss 3680.4787861340533
INFO:root:current train perplexity4.2678937911987305
INFO:root:current mean train loss 3679.4478001470898
INFO:root:current train perplexity4.266738414764404
INFO:root:current mean train loss 3681.0106895006174
INFO:root:current train perplexity4.2679314613342285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.38s/it]
INFO:root:final mean train loss: 3678.1701108255693
INFO:root:final train perplexity: 4.267996788024902
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.31s/it]
INFO:root:eval mean loss: 3990.5604499113474
INFO:root:eval perplexity: 5.021182537078857
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/62

 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [2:30:22<5:19:49, 139.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3646.12515676398
INFO:root:current train perplexity4.220619201660156
INFO:root:current mean train loss 3659.9917455428686
INFO:root:current train perplexity4.239099025726318
INFO:root:current mean train loss 3664.4168663930086
INFO:root:current train perplexity4.2416462898254395
INFO:root:current mean train loss 3666.2688699070413
INFO:root:current train perplexity4.243217468261719
INFO:root:current mean train loss 3669.4043772687814
INFO:root:current train perplexity4.242009162902832
INFO:root:current mean train loss 3671.4991834624475
INFO:root:current train perplexity4.249493598937988
INFO:root:current mean train loss 3671.2141910690198
INFO:root:current train perplexity4.249020099639893
INFO:root:current mean train loss 3673.345612839033
INFO:root:current train perplexity4.255584716796875
INFO:root:current mean train loss 3673.240677101519
INFO:root:current train perplexity4.254943370819092


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.74s/it]
INFO:root:final mean train loss: 3670.0716192183954
INFO:root:final train perplexity: 4.2543816566467285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.64s/it]
INFO:root:eval mean loss: 3990.861546293218
INFO:root:eval perplexity: 5.021794319152832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/63

 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [2:32:42<5:18:19, 139.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3691.0665690104165
INFO:root:current train perplexity4.313753604888916
INFO:root:current mean train loss 3669.25547775713
INFO:root:current train perplexity4.236623287200928
INFO:root:current mean train loss 3655.8685801839592
INFO:root:current train perplexity4.225832462310791
INFO:root:current mean train loss 3655.2439335486283
INFO:root:current train perplexity4.233578205108643
INFO:root:current mean train loss 3662.72116717393
INFO:root:current train perplexity4.237730979919434
INFO:root:current mean train loss 3667.13058756834
INFO:root:current train perplexity4.235538005828857
INFO:root:current mean train loss 3667.660883813355
INFO:root:current train perplexity4.23567008972168
INFO:root:current mean train loss 3664.800354090727
INFO:root:current train perplexity4.234107971191406
INFO:root:current mean train loss 3665.236860491419
INFO:root:current train perplexity4.2357001304626465
INFO:root:current mean train loss 3665.061440705461
INFO:root:current train perplexity4.236423492431641


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.03s/it]
INFO:root:final mean train loss: 3661.418971277052
INFO:root:final train perplexity: 4.2398834228515625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.67s/it]
INFO:root:eval mean loss: 3988.85093743074
INFO:root:eval perplexity: 5.0177130699157715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/64

 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [2:35:00<5:14:42, 138.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3635.0844504616475
INFO:root:current train perplexity4.204356670379639
INFO:root:current mean train loss 3664.0167137352196
INFO:root:current train perplexity4.216496467590332
INFO:root:current mean train loss 3643.8794500703493
INFO:root:current train perplexity4.212128639221191
INFO:root:current mean train loss 3633.12208679788
INFO:root:current train perplexity4.206020355224609
INFO:root:current mean train loss 3639.376773138116
INFO:root:current train perplexity4.206568241119385
INFO:root:current mean train loss 3645.8203177554733
INFO:root:current train perplexity4.212193965911865
INFO:root:current mean train loss 3650.2070787994835
INFO:root:current train perplexity4.2180495262146
INFO:root:current mean train loss 3652.862806703806
INFO:root:current train perplexity4.222580909729004
INFO:root:current mean train loss 3656.929671545064
INFO:root:current train perplexity4.225993633270264
INFO:root:current mean train loss 3655.2742328999725
INFO:root:current train perplexity4.225224018096924


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.22s/it]
INFO:root:final mean train loss: 3653.4124047679284
INFO:root:final train perplexity: 4.226511001586914
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.11s/it]
INFO:root:eval mean loss: 3986.5712769420434
INFO:root:eval perplexity: 5.013089656829834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/65
##############best#########
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [2:37:47<5:31:11, 147.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3586.7684133429275
INFO:root:current train perplexity4.18628454208374
INFO:root:current mean train loss 3643.0567801339284
INFO:root:current train perplexity4.200725555419922
INFO:root:current mean train loss 3644.938929170234
INFO:root:current train perplexity4.2024736404418945
INFO:root:current mean train loss 3646.315774851832
INFO:root:current train perplexity4.20217227935791
INFO:root:current mean train loss 3648.5909286899614
INFO:root:current train perplexity4.208127021789551
INFO:root:current mean train loss 3644.823343795159
INFO:root:current train perplexity4.202423095703125
INFO:root:current mean train loss 3650.2252451660943
INFO:root:current train perplexity4.2100605964660645
INFO:root:current mean train loss 3648.5011055937066
INFO:root:current train perplexity4.212493419647217
INFO:root:current mean train loss 3646.8138390472377
INFO:root:current train perplexity4.208746910095215
INFO:root:current mean train loss 3647.954096780638
INFO:root:current train perplexity4.214486122131348


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.30s/it]
INFO:root:final mean train loss: 3647.8278836896343
INFO:root:final train perplexity: 4.217209815979004
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.67s/it]
INFO:root:eval mean loss: 3986.879101908799
INFO:root:eval perplexity: 5.01371431350708
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/66

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [2:40:30<5:39:36, 152.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3609.50623010706
INFO:root:current train perplexity4.116145133972168
INFO:root:current mean train loss 3625.2383658341537
INFO:root:current train perplexity4.171618461608887
INFO:root:current mean train loss 3639.167534244218
INFO:root:current train perplexity4.199102878570557
INFO:root:current mean train loss 3640.3711751302085
INFO:root:current train perplexity4.195980072021484
INFO:root:current mean train loss 3642.493748399078
INFO:root:current train perplexity4.193949222564697
INFO:root:current mean train loss 3636.694058905064
INFO:root:current train perplexity4.189492225646973
INFO:root:current mean train loss 3636.792880750349
INFO:root:current train perplexity4.1931023597717285
INFO:root:current mean train loss 3637.264536609676
INFO:root:current train perplexity4.197618007659912
INFO:root:current mean train loss 3637.920535916717
INFO:root:current train perplexity4.199462413787842
INFO:root:current mean train loss 3641.1339884308422
INFO:root:current train perplexity4.202075958251953


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.38s/it]
INFO:root:final mean train loss: 3639.5709743499756
INFO:root:final train perplexity: 4.203494548797607
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.34s/it]
INFO:root:eval mean loss: 3989.752122811392
INFO:root:eval perplexity: 5.019542694091797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/67

 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [2:42:57<5:33:35, 150.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3610.6322195870534
INFO:root:current train perplexity4.15633487701416
INFO:root:current mean train loss 3605.6207899305555
INFO:root:current train perplexity4.158918380737305
INFO:root:current mean train loss 3614.640477476729
INFO:root:current train perplexity4.167211532592773
INFO:root:current mean train loss 3624.1453372784513
INFO:root:current train perplexity4.173947811126709
INFO:root:current mean train loss 3623.7182662086925
INFO:root:current train perplexity4.173978328704834
INFO:root:current mean train loss 3631.5233412127627
INFO:root:current train perplexity4.180551052093506
INFO:root:current mean train loss 3631.652741679995
INFO:root:current train perplexity4.177847385406494
INFO:root:current mean train loss 3633.5434234826744
INFO:root:current train perplexity4.184110164642334
INFO:root:current mean train loss 3635.43105907326
INFO:root:current train perplexity4.188527584075928
INFO:root:current mean train loss 3637.1586391836563
INFO:root:current train perplexity4.190709114074707


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.83s/it]
INFO:root:final mean train loss: 3632.724548155262
INFO:root:final train perplexity: 4.192154884338379
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.89s/it]
INFO:root:eval mean loss: 3989.498391442265
INFO:root:eval perplexity: 5.0190277099609375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/68

 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [2:45:17<5:24:33, 147.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3617.533441587936
INFO:root:current train perplexity4.157242298126221
INFO:root:current mean train loss 3631.6802252922857
INFO:root:current train perplexity4.1771039962768555
INFO:root:current mean train loss 3630.4765253263245
INFO:root:current train perplexity4.177044868469238
INFO:root:current mean train loss 3628.424944908209
INFO:root:current train perplexity4.172069072723389
INFO:root:current mean train loss 3622.752089248554
INFO:root:current train perplexity4.168035984039307
INFO:root:current mean train loss 3625.271521243382
INFO:root:current train perplexity4.1711201667785645
INFO:root:current mean train loss 3628.9469501026683
INFO:root:current train perplexity4.174296855926514
INFO:root:current mean train loss 3629.803492098124
INFO:root:current train perplexity4.177409648895264
INFO:root:current mean train loss 3631.682425466155
INFO:root:current train perplexity4.181025505065918
INFO:root:current mean train loss 3628.692028122515
INFO:root:current train perplexity4.178798198699951


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.33s/it]
INFO:root:final mean train loss: 3625.2934566005583
INFO:root:final train perplexity: 4.179882049560547
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.70s/it]
INFO:root:eval mean loss: 3989.048346769725
INFO:root:eval perplexity: 5.018113136291504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/69

 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [2:47:36<5:16:26, 144.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3603.7016218596814
INFO:root:current train perplexity4.147122383117676
INFO:root:current mean train loss 3600.253700913183
INFO:root:current train perplexity4.152393341064453
INFO:root:current mean train loss 3604.5239744148407
INFO:root:current train perplexity4.149192810058594
INFO:root:current mean train loss 3613.8906507356214
INFO:root:current train perplexity4.160945415496826
INFO:root:current mean train loss 3606.426018353312
INFO:root:current train perplexity4.157838344573975
INFO:root:current mean train loss 3608.192888374121
INFO:root:current train perplexity4.162123203277588
INFO:root:current mean train loss 3612.464313466062
INFO:root:current train perplexity4.163960933685303
INFO:root:current mean train loss 3614.5342274753452
INFO:root:current train perplexity4.166241645812988
INFO:root:current mean train loss 3618.1215662524787
INFO:root:current train perplexity4.166869640350342
INFO:root:current mean train loss 3621.4145012343092
INFO:root:current train perplexity4.1691789627075195


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.47s/it]
INFO:root:final mean train loss: 3619.4138025468396
INFO:root:final train perplexity: 4.1701979637146
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.44s/it]
INFO:root:eval mean loss: 3989.6184688054077
INFO:root:eval perplexity: 5.019270420074463
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/70

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [2:49:53<5:08:41, 142.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3570.5981652211335
INFO:root:current train perplexity4.136480808258057
INFO:root:current mean train loss 3581.74000251818
INFO:root:current train perplexity4.133768558502197
INFO:root:current mean train loss 3597.6891863613055
INFO:root:current train perplexity4.142502307891846
INFO:root:current mean train loss 3598.243627181624
INFO:root:current train perplexity4.145366668701172
INFO:root:current mean train loss 3600.382684844771
INFO:root:current train perplexity4.141496181488037
INFO:root:current mean train loss 3601.078373508078
INFO:root:current train perplexity4.142714500427246
INFO:root:current mean train loss 3603.217383701631
INFO:root:current train perplexity4.144836902618408
INFO:root:current mean train loss 3604.4328391335225
INFO:root:current train perplexity4.14858341217041
INFO:root:current mean train loss 3607.2869848888604
INFO:root:current train perplexity4.151164531707764
INFO:root:current mean train loss 3612.908235711027
INFO:root:current train perplexity4.154315948486328


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.60s/it]
INFO:root:final mean train loss: 3611.2118034362793
INFO:root:final train perplexity: 4.1567254066467285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.83s/it]
INFO:root:eval mean loss: 3988.684930463209
INFO:root:eval perplexity: 5.017375946044922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/71

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [2:52:13<5:04:53, 141.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3576.661325938666
INFO:root:current train perplexity4.0856170654296875
INFO:root:current mean train loss 3581.657486784244
INFO:root:current train perplexity4.102113723754883
INFO:root:current mean train loss 3582.8792546304426
INFO:root:current train perplexity4.114081382751465
INFO:root:current mean train loss 3597.6213558519244
INFO:root:current train perplexity4.129384517669678
INFO:root:current mean train loss 3597.3833300572137
INFO:root:current train perplexity4.12842321395874
INFO:root:current mean train loss 3593.4725167410716
INFO:root:current train perplexity4.130604267120361
INFO:root:current mean train loss 3599.6758057738707
INFO:root:current train perplexity4.134466648101807
INFO:root:current mean train loss 3601.622746394231
INFO:root:current train perplexity4.138185024261475
INFO:root:current mean train loss 3601.2943719250106
INFO:root:current train perplexity4.139463901519775
INFO:root:current mean train loss 3607.685051272056
INFO:root:current train perplexity4.146932601928711


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.51s/it]
INFO:root:final mean train loss: 3605.074060809228
INFO:root:final train perplexity: 4.146671772003174
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.91s/it]
INFO:root:eval mean loss: 3991.3485445063166
INFO:root:eval perplexity: 5.022782802581787
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/72

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [2:54:33<5:00:53, 141.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3613.5996940104164
INFO:root:current train perplexity4.11799430847168
INFO:root:current mean train loss 3595.2553976004465
INFO:root:current train perplexity4.114651679992676
INFO:root:current mean train loss 3596.951875
INFO:root:current train perplexity4.117297172546387
INFO:root:current mean train loss 3594.371134114583
INFO:root:current train perplexity4.124927043914795
INFO:root:current mean train loss 3597.9671952097037
INFO:root:current train perplexity4.131041049957275
INFO:root:current mean train loss 3598.4052547554347
INFO:root:current train perplexity4.129632472991943
INFO:root:current mean train loss 3598.035806206597
INFO:root:current train perplexity4.129833698272705
INFO:root:current mean train loss 3599.616302923387
INFO:root:current train perplexity4.1338019371032715
INFO:root:current mean train loss 3601.1038521205355
INFO:root:current train perplexity4.134350299835205
INFO:root:current mean train loss 3601.424394781651
INFO:root:current train perplexity4.135870933532715


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.18s/it]
INFO:root:final mean train loss: 3598.1073493342246
INFO:root:final train perplexity: 4.135289669036865
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.64s/it]
INFO:root:eval mean loss: 3989.456357698914
INFO:root:eval perplexity: 5.018941879272461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/73

 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [2:56:51<4:57:01, 140.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3558.5402714373117
INFO:root:current train perplexity4.088235378265381
INFO:root:current mean train loss 3576.7216663464824
INFO:root:current train perplexity4.104985237121582
INFO:root:current mean train loss 3588.1346862577298
INFO:root:current train perplexity4.118337631225586
INFO:root:current mean train loss 3586.80452622695
INFO:root:current train perplexity4.113335132598877
INFO:root:current mean train loss 3588.177707079775
INFO:root:current train perplexity4.118777751922607
INFO:root:current mean train loss 3588.564042315475
INFO:root:current train perplexity4.121975421905518
INFO:root:current mean train loss 3590.798556817922
INFO:root:current train perplexity4.122854709625244
INFO:root:current mean train loss 3590.7240827421574
INFO:root:current train perplexity4.1213860511779785
INFO:root:current mean train loss 3592.0337928780614
INFO:root:current train perplexity4.12123966217041
INFO:root:current mean train loss 3593.089184098423
INFO:root:current train perplexity4.123442649841309


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.63s/it]
INFO:root:final mean train loss: 3591.0486953489244
INFO:root:final train perplexity: 4.123790264129639
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.91s/it]
INFO:root:eval mean loss: 3993.474238835328
INFO:root:eval perplexity: 5.027102470397949
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/74

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [2:59:11<4:54:05, 140.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3591.1842081258587
INFO:root:current train perplexity4.1073174476623535
INFO:root:current mean train loss 3573.083717226358
INFO:root:current train perplexity4.086845874786377
INFO:root:current mean train loss 3580.721928022981
INFO:root:current train perplexity4.096181869506836
INFO:root:current mean train loss 3577.3778922234656
INFO:root:current train perplexity4.0973687171936035
INFO:root:current mean train loss 3577.1447385955003
INFO:root:current train perplexity4.097213268280029
INFO:root:current mean train loss 3578.657941221182
INFO:root:current train perplexity4.095250129699707
INFO:root:current mean train loss 3580.2272161326428
INFO:root:current train perplexity4.101571083068848
INFO:root:current mean train loss 3581.758845236449
INFO:root:current train perplexity4.10590124130249
INFO:root:current mean train loss 3583.252364136153
INFO:root:current train perplexity4.108475208282471
INFO:root:current mean train loss 3587.019914582808
INFO:root:current train perplexity4.1127190589904785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.16s/it]
INFO:root:final mean train loss: 3584.240747882474
INFO:root:final train perplexity: 4.112728595733643
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.01s/it]
INFO:root:eval mean loss: 3989.0044655224956
INFO:root:eval perplexity: 5.018024444580078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/75

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [3:01:31<4:51:44, 140.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3565.550495186237
INFO:root:current train perplexity4.084646701812744
INFO:root:current mean train loss 3577.344026038395
INFO:root:current train perplexity4.087734222412109
INFO:root:current mean train loss 3576.5728665865386
INFO:root:current train perplexity4.094093322753906
INFO:root:current mean train loss 3574.7999962063363
INFO:root:current train perplexity4.09406852722168
INFO:root:current mean train loss 3579.0175795927794
INFO:root:current train perplexity4.096848487854004
INFO:root:current mean train loss 3578.851688849906
INFO:root:current train perplexity4.093792915344238
INFO:root:current mean train loss 3581.414508519425
INFO:root:current train perplexity4.100245475769043
INFO:root:current mean train loss 3578.987526216853
INFO:root:current train perplexity4.099432945251465
INFO:root:current mean train loss 3579.6049112186283
INFO:root:current train perplexity4.1018452644348145


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.92s/it]
INFO:root:final mean train loss: 3577.888090625886
INFO:root:final train perplexity: 4.102433681488037
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.60s/it]
INFO:root:eval mean loss: 3992.4651121315383
INFO:root:eval perplexity: 5.025052070617676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/76

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [3:03:50<4:48:59, 139.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3573.1592145647323
INFO:root:current train perplexity4.097287178039551
INFO:root:current mean train loss 3570.0390419648074
INFO:root:current train perplexity4.091843128204346
INFO:root:current mean train loss 3564.093399711277
INFO:root:current train perplexity4.0811991691589355
INFO:root:current mean train loss 3563.8282069103725
INFO:root:current train perplexity4.07589054107666
INFO:root:current mean train loss 3568.1015660991247
INFO:root:current train perplexity4.081079483032227
INFO:root:current mean train loss 3567.0448602379192
INFO:root:current train perplexity4.079962253570557
INFO:root:current mean train loss 3571.9618670040927
INFO:root:current train perplexity4.085468292236328
INFO:root:current mean train loss 3572.724311364591
INFO:root:current train perplexity4.088016986846924
INFO:root:current mean train loss 3572.697859488751
INFO:root:current train perplexity4.088016510009766
INFO:root:current mean train loss 3571.871435331536
INFO:root:current train perplexity4.087973117828369


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.75s/it]
INFO:root:final mean train loss: 3570.5515416053036
INFO:root:final train perplexity: 4.090576171875
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.37s/it]
INFO:root:eval mean loss: 3992.146415115248
INFO:root:eval perplexity: 5.024404048919678
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/77

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [3:06:07<4:44:53, 138.97s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3526.858121744792
INFO:root:current train perplexity4.0164079666137695
INFO:root:current mean train loss 3555.288051970109
INFO:root:current train perplexity4.049911022186279
INFO:root:current mean train loss 3561.0110431050143
INFO:root:current train perplexity4.057698726654053
INFO:root:current mean train loss 3557.184584263393
INFO:root:current train perplexity4.058690547943115
INFO:root:current mean train loss 3562.070005412274
INFO:root:current train perplexity4.068806171417236
INFO:root:current mean train loss 3563.5632291034585
INFO:root:current train perplexity4.072408676147461
INFO:root:current mean train loss 3559.519581269055
INFO:root:current train perplexity4.068384647369385
INFO:root:current mean train loss 3563.206407069493
INFO:root:current train perplexity4.073886871337891
INFO:root:current mean train loss 3564.316866372699
INFO:root:current train perplexity4.076522350311279
INFO:root:current mean train loss 3565.430613633453
INFO:root:current train perplexity4.077571868896484


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.04s/it]
INFO:root:final mean train loss: 3564.3886780277376
INFO:root:final train perplexity: 4.080642223358154
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.07s/it]
INFO:root:eval mean loss: 3992.236530709774
INFO:root:eval perplexity: 5.024587154388428
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/78

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [3:08:26<4:42:35, 138.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3555.9710321841035
INFO:root:current train perplexity4.067345142364502
INFO:root:current mean train loss 3552.697436324949
INFO:root:current train perplexity4.069004535675049
INFO:root:current mean train loss 3549.4985548626682
INFO:root:current train perplexity4.06809663772583
INFO:root:current mean train loss 3551.7735145970396
INFO:root:current train perplexity4.062113285064697
INFO:root:current mean train loss 3551.3569763039304
INFO:root:current train perplexity4.061572551727295
INFO:root:current mean train loss 3550.3832615693714
INFO:root:current train perplexity4.063188076019287
INFO:root:current mean train loss 3555.5647105895114
INFO:root:current train perplexity4.065971374511719
INFO:root:current mean train loss 3555.284093917488
INFO:root:current train perplexity4.063971519470215
INFO:root:current mean train loss 3557.49588580033
INFO:root:current train perplexity4.064735412597656
INFO:root:current mean train loss 3558.6019259336063
INFO:root:current train perplexity4.069276332855225


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.39s/it]
INFO:root:final mean train loss: 3558.3461680873747
INFO:root:final train perplexity: 4.070925712585449
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.02s/it]
INFO:root:eval mean loss: 3995.156201518174
INFO:root:eval perplexity: 5.030523300170898
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/79

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [3:10:45<4:40:26, 139.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3541.9083055065526
INFO:root:current train perplexity4.0296244621276855
INFO:root:current mean train loss 3549.617029088144
INFO:root:current train perplexity4.049445629119873
INFO:root:current mean train loss 3554.69188184862
INFO:root:current train perplexity4.05088996887207
INFO:root:current mean train loss 3557.9299434419845
INFO:root:current train perplexity4.052221298217773
INFO:root:current mean train loss 3555.6710049303942
INFO:root:current train perplexity4.056853771209717
INFO:root:current mean train loss 3555.0020101371233
INFO:root:current train perplexity4.059696197509766
INFO:root:current mean train loss 3555.0703345539073
INFO:root:current train perplexity4.0597381591796875
INFO:root:current mean train loss 3553.8402538795312
INFO:root:current train perplexity4.058355331420898
INFO:root:current mean train loss 3556.8895984929677
INFO:root:current train perplexity4.062473773956299
INFO:root:current mean train loss 3553.937113728098
INFO:root:current train perplexity4.061426639556885


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.76s/it]
INFO:root:final mean train loss: 3551.4631508857974
INFO:root:final train perplexity: 4.059886455535889
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.30s/it]
INFO:root:eval mean loss: 3994.142874210439
INFO:root:eval perplexity: 5.028461456298828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/80

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [3:13:05<4:38:43, 139.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3503.3719075520835
INFO:root:current train perplexity4.043832778930664
INFO:root:current mean train loss 3527.573651430418
INFO:root:current train perplexity4.026747703552246
INFO:root:current mean train loss 3530.202644890821
INFO:root:current train perplexity4.026879787445068
INFO:root:current mean train loss 3534.8385704738203
INFO:root:current train perplexity4.025915622711182
INFO:root:current mean train loss 3536.292435978431
INFO:root:current train perplexity4.035843372344971
INFO:root:current mean train loss 3537.1936315985913
INFO:root:current train perplexity4.038906574249268
INFO:root:current mean train loss 3544.162824603873
INFO:root:current train perplexity4.045472145080566
INFO:root:current mean train loss 3546.2184939661915
INFO:root:current train perplexity4.049893856048584
INFO:root:current mean train loss 3547.791570542964
INFO:root:current train perplexity4.051515579223633
INFO:root:current mean train loss 3547.8491283737685
INFO:root:current train perplexity4.051234722137451


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.94s/it]
INFO:root:final mean train loss: 3547.1402484524633
INFO:root:final train perplexity: 4.0529680252075195
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.43s/it]
INFO:root:eval mean loss: 3993.9664142148713
INFO:root:eval perplexity: 5.028102397918701
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/81

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [3:15:22<4:35:07, 138.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3548.6306879571143
INFO:root:current train perplexity4.079227447509766
INFO:root:current mean train loss 3554.766076743197
INFO:root:current train perplexity4.051787376403809
INFO:root:current mean train loss 3539.1606247627783
INFO:root:current train perplexity4.036404132843018
INFO:root:current mean train loss 3536.5121183807637
INFO:root:current train perplexity4.032164573669434
INFO:root:current mean train loss 3542.565984602209
INFO:root:current train perplexity4.033036231994629
INFO:root:current mean train loss 3536.9726004591807
INFO:root:current train perplexity4.033120632171631
INFO:root:current mean train loss 3539.7925751817284
INFO:root:current train perplexity4.036467552185059
INFO:root:current mean train loss 3543.152447027694
INFO:root:current train perplexity4.037094593048096
INFO:root:current mean train loss 3545.721226571724
INFO:root:current train perplexity4.04043436050415
INFO:root:current mean train loss 3543.228188987015
INFO:root:current train perplexity4.042825222015381


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.39s/it]
INFO:root:final mean train loss: 3540.2742737800845
INFO:root:final train perplexity: 4.042004108428955
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.00s/it]
INFO:root:eval mean loss: 3997.5655439660904
INFO:root:eval perplexity: 5.035425186157227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/82

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [3:17:44<4:34:20, 139.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3538.600066583807
INFO:root:current train perplexity4.0280375480651855
INFO:root:current mean train loss 3532.7251953125
INFO:root:current train perplexity4.026678085327148
INFO:root:current mean train loss 3526.610382199755
INFO:root:current train perplexity4.020916938781738
INFO:root:current mean train loss 3531.269421902509
INFO:root:current train perplexity4.029592990875244
INFO:root:current mean train loss 3528.9711361392515
INFO:root:current train perplexity4.033827781677246
INFO:root:current mean train loss 3531.63020349451
INFO:root:current train perplexity4.033914089202881
INFO:root:current mean train loss 3532.4282960848045
INFO:root:current train perplexity4.032812595367432
INFO:root:current mean train loss 3534.8765993636175
INFO:root:current train perplexity4.032861232757568
INFO:root:current mean train loss 3535.970097770468
INFO:root:current train perplexity4.032144546508789
INFO:root:current mean train loss 3539.0918403345877
INFO:root:current train perplexity4.034588813781738


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.51s/it]
INFO:root:final mean train loss: 3534.7212461040867
INFO:root:final train perplexity: 4.033158779144287
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.45s/it]
INFO:root:eval mean loss: 3995.7225315824467
INFO:root:eval perplexity: 5.031674861907959
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/83

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [3:20:02<4:31:00, 138.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3527.220489986359
INFO:root:current train perplexity3.9886631965637207
INFO:root:current mean train loss 3527.9420383195934
INFO:root:current train perplexity4.008620262145996
INFO:root:current mean train loss 3519.120603612167
INFO:root:current train perplexity4.015318870544434
INFO:root:current mean train loss 3519.3476031174673
INFO:root:current train perplexity4.017088890075684
INFO:root:current mean train loss 3522.404049570566
INFO:root:current train perplexity4.014949798583984
INFO:root:current mean train loss 3523.9339627796126
INFO:root:current train perplexity4.017252445220947
INFO:root:current mean train loss 3528.474179643312
INFO:root:current train perplexity4.021412372589111
INFO:root:current mean train loss 3531.718184284895
INFO:root:current train perplexity4.025097846984863
INFO:root:current mean train loss 3531.204166628947
INFO:root:current train perplexity4.023714065551758
INFO:root:current mean train loss 3531.172534661377
INFO:root:current train perplexity4.023935317993164


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.23s/it]
INFO:root:final mean train loss: 3529.165646522276
INFO:root:final train perplexity: 4.024327754974365
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.29s/it]
INFO:root:eval mean loss: 3997.703983820922
INFO:root:eval perplexity: 5.035707950592041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/84

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [3:22:20<4:28:20, 138.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3496.4724740041815
INFO:root:current train perplexity3.9912657737731934
INFO:root:current mean train loss 3509.3145644873903
INFO:root:current train perplexity3.993868827819824
INFO:root:current mean train loss 3505.7677952389877
INFO:root:current train perplexity3.9931256771087646
INFO:root:current mean train loss 3508.5062614502613
INFO:root:current train perplexity3.9991273880004883
INFO:root:current mean train loss 3512.0203885930864
INFO:root:current train perplexity4.0002288818359375
INFO:root:current mean train loss 3517.3248075094407
INFO:root:current train perplexity4.003762722015381
INFO:root:current mean train loss 3521.416701838441
INFO:root:current train perplexity4.007888317108154
INFO:root:current mean train loss 3525.202062940783
INFO:root:current train perplexity4.009641170501709
INFO:root:current mean train loss 3525.789488835121
INFO:root:current train perplexity4.0120649337768555
INFO:root:current mean train loss 3524.4388109672695
INFO:root:current train perplexity4.0125532150268555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.26s/it]
INFO:root:final mean train loss: 3521.4915630586684
INFO:root:final train perplexity: 4.012162208557129
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.19s/it]
INFO:root:eval mean loss: 3997.3016366079346
INFO:root:eval perplexity: 5.034889221191406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/85

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [3:24:42<4:28:02, 139.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3477.572602477255
INFO:root:current train perplexity4.0054521560668945
INFO:root:current mean train loss 3503.009454652584
INFO:root:current train perplexity4.000414848327637
INFO:root:current mean train loss 3515.6252765176973
INFO:root:current train perplexity4.001925945281982
INFO:root:current mean train loss 3518.301131034589
INFO:root:current train perplexity3.9985764026641846
INFO:root:current mean train loss 3518.22665067605
INFO:root:current train perplexity4.000195503234863
INFO:root:current mean train loss 3517.425750890544
INFO:root:current train perplexity4.002851963043213
INFO:root:current mean train loss 3516.155024263048
INFO:root:current train perplexity4.0038909912109375
INFO:root:current mean train loss 3518.7010079654406
INFO:root:current train perplexity4.0049872398376465
INFO:root:current mean train loss 3520.384170966208
INFO:root:current train perplexity4.005316734313965
INFO:root:current mean train loss 3521.019405563713
INFO:root:current train perplexity4.0056633949279785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.68s/it]
INFO:root:final mean train loss: 3517.7634166594476
INFO:root:final train perplexity: 4.006264686584473
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.50s/it]
INFO:root:eval mean loss: 3997.201592627992
INFO:root:eval perplexity: 5.03468656539917
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/86

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [3:27:01<4:25:14, 139.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3477.6692119028376
INFO:root:current train perplexity3.9617538452148438
INFO:root:current mean train loss 3485.92370670747
INFO:root:current train perplexity3.9667115211486816
INFO:root:current mean train loss 3490.947612695993
INFO:root:current train perplexity3.9835753440856934
INFO:root:current mean train loss 3495.9029424307573
INFO:root:current train perplexity3.9837989807128906
INFO:root:current mean train loss 3499.3906706197063
INFO:root:current train perplexity3.9836935997009277
INFO:root:current mean train loss 3505.77455339318
INFO:root:current train perplexity3.9879138469696045
INFO:root:current mean train loss 3506.6103146038026
INFO:root:current train perplexity3.9881181716918945
INFO:root:current mean train loss 3510.613593948539
INFO:root:current train perplexity3.993790626525879
INFO:root:current mean train loss 3511.7459057589663
INFO:root:current train perplexity3.9940478801727295
INFO:root:current mean train loss 3513.4661401441394
INFO:root:current train perplexity3.995025873184204


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.93s/it]
INFO:root:final mean train loss: 3510.87556845142
INFO:root:final train perplexity: 3.9953930377960205
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.52s/it]
INFO:root:eval mean loss: 3997.988272592531
INFO:root:eval perplexity: 5.036287307739258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/87

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [3:29:18<4:21:35, 138.90s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3498.9677991365133
INFO:root:current train perplexity3.959759473800659
INFO:root:current mean train loss 3514.632325470753
INFO:root:current train perplexity3.9775640964508057
INFO:root:current mean train loss 3512.6232686705507
INFO:root:current train perplexity3.983323574066162
INFO:root:current mean train loss 3504.12397337322
INFO:root:current train perplexity3.9792168140411377
INFO:root:current mean train loss 3503.8116644965276
INFO:root:current train perplexity3.9789793491363525
INFO:root:current mean train loss 3505.7365205652573
INFO:root:current train perplexity3.9774601459503174
INFO:root:current mean train loss 3504.71709932835
INFO:root:current train perplexity3.979170799255371
INFO:root:current mean train loss 3506.302336686812
INFO:root:current train perplexity3.983431816101074
INFO:root:current mean train loss 3508.304681225995
INFO:root:current train perplexity3.9871203899383545


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.89s/it]
INFO:root:final mean train loss: 3506.3963831009405
INFO:root:final train perplexity: 3.9883384704589844
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.62s/it]
INFO:root:eval mean loss: 3999.8137484070257
INFO:root:eval perplexity: 5.040006160736084
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/88

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [3:31:38<4:19:31, 139.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3698.9224446614585
INFO:root:current train perplexity4.08428955078125
INFO:root:current mean train loss 3512.6730174833133
INFO:root:current train perplexity3.977598190307617
INFO:root:current mean train loss 3498.9110570447197
INFO:root:current train perplexity3.9653480052948
INFO:root:current mean train loss 3493.9287471960088
INFO:root:current train perplexity3.9596588611602783
INFO:root:current mean train loss 3499.2558745202
INFO:root:current train perplexity3.9701428413391113
INFO:root:current mean train loss 3499.5521004830393
INFO:root:current train perplexity3.9733173847198486
INFO:root:current mean train loss 3500.4737542754974
INFO:root:current train perplexity3.9724531173706055
INFO:root:current mean train loss 3496.4763562133267
INFO:root:current train perplexity3.9705991744995117
INFO:root:current mean train loss 3498.9337466799307
INFO:root:current train perplexity3.9712862968444824
INFO:root:current mean train loss 3499.992906673934
INFO:root:current train perplexity3.9761807918548584


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.67s/it]
INFO:root:final mean train loss: 3499.3332336794947
INFO:root:final train perplexity: 3.9772398471832275
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.50s/it]
INFO:root:eval mean loss: 4000.783483626995
INFO:root:eval perplexity: 5.041983127593994
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/89

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [3:34:01<4:19:26, 140.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3491.044855291193
INFO:root:current train perplexity3.913058042526245
INFO:root:current mean train loss 3486.608809737472
INFO:root:current train perplexity3.957075834274292
INFO:root:current mean train loss 3484.524924327977
INFO:root:current train perplexity3.9568188190460205
INFO:root:current mean train loss 3481.657947209104
INFO:root:current train perplexity3.9558279514312744
INFO:root:current mean train loss 3481.1840155014447
INFO:root:current train perplexity3.9512007236480713
INFO:root:current mean train loss 3483.674485059167
INFO:root:current train perplexity3.9532346725463867
INFO:root:current mean train loss 3486.1926705068536
INFO:root:current train perplexity3.9602324962615967
INFO:root:current mean train loss 3492.2961975183503
INFO:root:current train perplexity3.961944103240967
INFO:root:current mean train loss 3491.891823426422
INFO:root:current train perplexity3.9629969596862793
INFO:root:current mean train loss 3494.631230275796
INFO:root:current train perplexity3.966771125793457


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.27s/it]
INFO:root:final mean train loss: 3494.357681766633
INFO:root:final train perplexity: 3.96943998336792
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.87s/it]
INFO:root:eval mean loss: 4003.8695890818926
INFO:root:eval perplexity: 5.04827880859375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/90

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [3:36:19<4:15:52, 139.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3448.2780247738488
INFO:root:current train perplexity3.9911916255950928
INFO:root:current mean train loss 3486.2264086298583
INFO:root:current train perplexity3.9402763843536377
INFO:root:current mean train loss 3501.0184465521547
INFO:root:current train perplexity3.9498066902160645
INFO:root:current mean train loss 3496.484958182308
INFO:root:current train perplexity3.9544293880462646
INFO:root:current mean train loss 3496.717617280728
INFO:root:current train perplexity3.9529104232788086
INFO:root:current mean train loss 3494.8817578501325
INFO:root:current train perplexity3.9538986682891846
INFO:root:current mean train loss 3491.441653545916
INFO:root:current train perplexity3.9545702934265137
INFO:root:current mean train loss 3488.632722517711
INFO:root:current train perplexity3.958442211151123
INFO:root:current mean train loss 3490.1690994281325
INFO:root:current train perplexity3.960203170776367
INFO:root:current mean train loss 3493.719871612316
INFO:root:current train perplexity3.963118076324463


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.97s/it]
INFO:root:final mean train loss: 3489.9104019903366
INFO:root:final train perplexity: 3.962482213973999
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.05s/it]
INFO:root:eval mean loss: 4003.5023634890294
INFO:root:eval perplexity: 5.0475287437438965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/91

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [3:38:38<4:13:10, 139.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3475.9518952546296
INFO:root:current train perplexity3.9754464626312256
INFO:root:current mean train loss 3477.870676596334
INFO:root:current train perplexity3.9434680938720703
INFO:root:current mean train loss 3477.445071585903
INFO:root:current train perplexity3.9471256732940674
INFO:root:current mean train loss 3479.234303325688
INFO:root:current train perplexity3.9464778900146484
INFO:root:current mean train loss 3474.132162983021
INFO:root:current train perplexity3.9447712898254395
INFO:root:current mean train loss 3480.3009007723554
INFO:root:current train perplexity3.9499456882476807
INFO:root:current mean train loss 3482.542812609026
INFO:root:current train perplexity3.9491212368011475
INFO:root:current mean train loss 3485.139372058223
INFO:root:current train perplexity3.9515812397003174
INFO:root:current mean train loss 3485.7698075687726
INFO:root:current train perplexity3.953423023223877
INFO:root:current mean train loss 3485.8419372492754
INFO:root:current train perplexity3.9532063007354736


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.14s/it]
INFO:root:final mean train loss: 3484.1772230209845
INFO:root:final train perplexity: 3.9535295963287354
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.68s/it]
INFO:root:eval mean loss: 4007.578916292664
INFO:root:eval perplexity: 5.055856704711914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/92

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [3:40:57<4:10:59, 139.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3464.513623046875
INFO:root:current train perplexity3.927600860595703
INFO:root:current mean train loss 3473.4469165943287
INFO:root:current train perplexity3.932863235473633
INFO:root:current mean train loss 3480.678771193484
INFO:root:current train perplexity3.94376802444458
INFO:root:current mean train loss 3483.0117938141325
INFO:root:current train perplexity3.944424867630005
INFO:root:current mean train loss 3486.085537895115
INFO:root:current train perplexity3.948108196258545
INFO:root:current mean train loss 3486.3583920487736
INFO:root:current train perplexity3.9490199089050293
INFO:root:current mean train loss 3481.898883873647
INFO:root:current train perplexity3.9432902336120605
INFO:root:current mean train loss 3478.842919921875
INFO:root:current train perplexity3.941923141479492
INFO:root:current mean train loss 3480.818164354884
INFO:root:current train perplexity3.9442741870880127
INFO:root:current mean train loss 3480.100660615809
INFO:root:current train perplexity3.9431746006011963


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.78s/it]
INFO:root:final mean train loss: 3479.87320955338
INFO:root:final train perplexity: 3.946821689605713
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.63s/it]
INFO:root:eval mean loss: 4004.101614444814
INFO:root:eval perplexity: 5.048753261566162
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/93

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [3:43:15<4:07:30, 138.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3433.4087141170057
INFO:root:current train perplexity3.9140267372131348
INFO:root:current mean train loss 3474.4933262538243
INFO:root:current train perplexity3.913822889328003
INFO:root:current mean train loss 3466.6034081227494
INFO:root:current train perplexity3.9264256954193115
INFO:root:current mean train loss 3467.667979426704
INFO:root:current train perplexity3.92685604095459
INFO:root:current mean train loss 3466.5932721897925
INFO:root:current train perplexity3.9264464378356934
INFO:root:current mean train loss 3467.2029595418967
INFO:root:current train perplexity3.9271724224090576
INFO:root:current mean train loss 3469.2816741136517
INFO:root:current train perplexity3.931812286376953
INFO:root:current mean train loss 3474.9558102182873
INFO:root:current train perplexity3.9345409870147705
INFO:root:current mean train loss 3475.3477787547263
INFO:root:current train perplexity3.9355788230895996
INFO:root:current mean train loss 3476.1462643118703
INFO:root:current train perplexity3.9367573261260986


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.04s/it]
INFO:root:final mean train loss: 3473.61672149166
INFO:root:final train perplexity: 3.937091588973999
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.77s/it]
INFO:root:eval mean loss: 4004.44467357879
INFO:root:eval perplexity: 5.049452781677246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/94

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [3:45:32<4:04:36, 138.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3455.903693704044
INFO:root:current train perplexity3.930556297302246
INFO:root:current mean train loss 3468.9583327943915
INFO:root:current train perplexity3.922234535217285
INFO:root:current mean train loss 3470.3220701179657
INFO:root:current train perplexity3.9256081581115723
INFO:root:current mean train loss 3469.7109715823094
INFO:root:current train perplexity3.9158029556274414
INFO:root:current mean train loss 3467.264410251524
INFO:root:current train perplexity3.9170312881469727
INFO:root:current mean train loss 3470.4898781335073
INFO:root:current train perplexity3.9242405891418457
INFO:root:current mean train loss 3470.308040214574
INFO:root:current train perplexity3.927619457244873
INFO:root:current mean train loss 3470.4020261396263
INFO:root:current train perplexity3.9265058040618896
INFO:root:current mean train loss 3470.2454278858513
INFO:root:current train perplexity3.927889823913574
INFO:root:current mean train loss 3471.5926692092207
INFO:root:current train perplexity3.9309732913970947


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.72s/it]
INFO:root:final mean train loss: 3467.954823032502
INFO:root:final train perplexity: 3.9283065795898438
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.93s/it]
INFO:root:eval mean loss: 4008.463553787123
INFO:root:eval perplexity: 5.057665824890137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/95

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [3:48:10<4:12:34, 144.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3433.5185629634534
INFO:root:current train perplexity3.8732428550720215
INFO:root:current mean train loss 3444.6624256829796
INFO:root:current train perplexity3.880216598510742
INFO:root:current mean train loss 3448.1146753966577
INFO:root:current train perplexity3.88895583152771
INFO:root:current mean train loss 3455.8077674801966
INFO:root:current train perplexity3.898144245147705
INFO:root:current mean train loss 3456.924179176879
INFO:root:current train perplexity3.9017889499664307
INFO:root:current mean train loss 3461.6820821745023
INFO:root:current train perplexity3.9065134525299072
INFO:root:current mean train loss 3461.077741191673
INFO:root:current train perplexity3.9091579914093018
INFO:root:current mean train loss 3463.952092790164
INFO:root:current train perplexity3.9131407737731934
INFO:root:current mean train loss 3466.6973372471625
INFO:root:current train perplexity3.9176878929138184
INFO:root:current mean train loss 3467.3655841656346
INFO:root:current train perplexity3.9199819564819336


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.50s/it]
INFO:root:final mean train loss: 3462.9822480601647
INFO:root:final train perplexity: 3.920607328414917
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.65s/it]
INFO:root:eval mean loss: 4006.547228224734
INFO:root:eval perplexity: 5.05374813079834
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/96

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [3:50:30<4:07:33, 142.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3467.0889473530783
INFO:root:current train perplexity3.9451217651367188
INFO:root:current mean train loss 3461.4723521706587
INFO:root:current train perplexity3.9161202907562256
INFO:root:current mean train loss 3468.449267212371
INFO:root:current train perplexity3.919895648956299
INFO:root:current mean train loss 3465.4977242368445
INFO:root:current train perplexity3.913367986679077
INFO:root:current mean train loss 3462.3554995943186
INFO:root:current train perplexity3.9117298126220703
INFO:root:current mean train loss 3459.5352561452823
INFO:root:current train perplexity3.910975456237793
INFO:root:current mean train loss 3460.3710706902407
INFO:root:current train perplexity3.9106881618499756
INFO:root:current mean train loss 3458.5701040096355
INFO:root:current train perplexity3.9130842685699463
INFO:root:current mean train loss 3462.5113445136785
INFO:root:current train perplexity3.915639638900757
INFO:root:current mean train loss 3462.156566852621
INFO:root:current train perplexity3.915940523147583


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.85s/it]
INFO:root:final mean train loss: 3459.729651727984
INFO:root:final train perplexity: 3.9155802726745605
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.78s/it]
INFO:root:eval mean loss: 4010.8685969359485
INFO:root:eval perplexity: 5.062586784362793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/97

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [3:53:14<4:16:04, 149.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3445.7581705729167
INFO:root:current train perplexity3.9150002002716064
INFO:root:current mean train loss 3444.81455078125
INFO:root:current train perplexity3.899251699447632
INFO:root:current mean train loss 3455.906405362216
INFO:root:current train perplexity3.8969485759735107
INFO:root:current mean train loss 3459.9360384114584
INFO:root:current train perplexity3.89864182472229
INFO:root:current mean train loss 3457.2973699629933
INFO:root:current train perplexity3.901639223098755
INFO:root:current mean train loss 3453.439312160326
INFO:root:current train perplexity3.9035658836364746
INFO:root:current mean train loss 3458.0110944733797
INFO:root:current train perplexity3.905517816543579
INFO:root:current mean train loss 3456.4150926159273
INFO:root:current train perplexity3.9051403999328613
INFO:root:current mean train loss 3458.026589285714
INFO:root:current train perplexity3.9066219329833984
INFO:root:current mean train loss 3456.698928786058
INFO:root:current train perplexity3.908013343811035


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.52s/it]
INFO:root:final mean train loss: 3455.057860528269
INFO:root:final train perplexity: 3.908369541168213
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.69s/it]
INFO:root:eval mean loss: 4008.817027856272
INFO:root:eval perplexity: 5.058387756347656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/98

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [3:55:52<4:18:27, 152.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3431.860922204443
INFO:root:current train perplexity3.874346971511841
INFO:root:current mean train loss 3435.770870688183
INFO:root:current train perplexity3.8872363567352295
INFO:root:current mean train loss 3450.229025473443
INFO:root:current train perplexity3.88930082321167
INFO:root:current mean train loss 3451.160583974176
INFO:root:current train perplexity3.887221574783325
INFO:root:current mean train loss 3451.001110005823
INFO:root:current train perplexity3.8900821208953857
INFO:root:current mean train loss 3450.664253876099
INFO:root:current train perplexity3.892042398452759
INFO:root:current mean train loss 3452.2092774867315
INFO:root:current train perplexity3.8957464694976807
INFO:root:current mean train loss 3449.8090458622687
INFO:root:current train perplexity3.8951234817504883
INFO:root:current mean train loss 3450.9054006228766
INFO:root:current train perplexity3.8956568241119385
INFO:root:current mean train loss 3451.357520971754
INFO:root:current train perplexity3.8980720043182373


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.53s/it]
INFO:root:final mean train loss: 3448.556406697919
INFO:root:final train perplexity: 3.898357391357422
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.46s/it]
INFO:root:eval mean loss: 4012.7599543578235
INFO:root:eval perplexity: 5.066459655761719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/99

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [3:58:11<4:09:16, 148.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3414.8514229910716
INFO:root:current train perplexity3.84470272064209
INFO:root:current mean train loss 3428.03672207338
INFO:root:current train perplexity3.8539798259735107
INFO:root:current mean train loss 3432.801991046499
INFO:root:current train perplexity3.86666202545166
INFO:root:current mean train loss 3438.365290571052
INFO:root:current train perplexity3.8747751712799072
INFO:root:current mean train loss 3439.66417835492
INFO:root:current train perplexity3.8777363300323486
INFO:root:current mean train loss 3440.040474880367
INFO:root:current train perplexity3.877648115158081
INFO:root:current mean train loss 3442.0927204402587
INFO:root:current train perplexity3.8811521530151367
INFO:root:current mean train loss 3443.280738878793
INFO:root:current train perplexity3.883976697921753
INFO:root:current mean train loss 3442.4361784621387
INFO:root:current train perplexity3.8859455585479736
INFO:root:current mean train loss 3446.440271772121
INFO:root:current train perplexity3.890990734100342


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.78s/it]
INFO:root:final mean train loss: 3443.7101010353335
INFO:root:final train perplexity: 3.8909108638763428
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.53s/it]
INFO:root:eval mean loss: 4012.3682783410904
INFO:root:eval perplexity: 5.065657615661621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/100

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [4:00:30<4:02:21, 145.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3421.521020754419
INFO:root:current train perplexity3.8536434173583984
INFO:root:current mean train loss 3425.6087235493874
INFO:root:current train perplexity3.8715569972991943
INFO:root:current mean train loss 3428.4834017035955
INFO:root:current train perplexity3.8726389408111572
INFO:root:current mean train loss 3426.1317723018483
INFO:root:current train perplexity3.868927240371704
INFO:root:current mean train loss 3432.172764963521
INFO:root:current train perplexity3.8722641468048096
INFO:root:current mean train loss 3434.2602722473653
INFO:root:current train perplexity3.8756442070007324
INFO:root:current mean train loss 3439.282946410609
INFO:root:current train perplexity3.8798203468322754
INFO:root:current mean train loss 3442.6101743390177
INFO:root:current train perplexity3.8822038173675537
INFO:root:current mean train loss 3442.3630878927975
INFO:root:current train perplexity3.883798599243164


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.10s/it]
INFO:root:final mean train loss: 3439.4797573704873
INFO:root:final train perplexity: 3.884422779083252
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.05s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.05s/it]
INFO:root:eval mean loss: 4012.75927734375
INFO:root:eval perplexity: 5.066457748413086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/101

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [4:03:02<4:02:46, 147.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3390.320975167411
INFO:root:current train perplexity3.8501675128936768
INFO:root:current mean train loss 3454.6862405081774
INFO:root:current train perplexity3.872943162918091
INFO:root:current mean train loss 3441.71157202974
INFO:root:current train perplexity3.8658273220062256
INFO:root:current mean train loss 3433.793423630904
INFO:root:current train perplexity3.872072219848633
INFO:root:current mean train loss 3439.910145452626
INFO:root:current train perplexity3.8757565021514893
INFO:root:current mean train loss 3439.0624200644106
INFO:root:current train perplexity3.8776798248291016
INFO:root:current mean train loss 3437.552746441258
INFO:root:current train perplexity3.8746237754821777
INFO:root:current mean train loss 3436.4798499381186
INFO:root:current train perplexity3.875166416168213
INFO:root:current mean train loss 3437.467450336896
INFO:root:current train perplexity3.876941204071045
INFO:root:current mean train loss 3436.8290576871727
INFO:root:current train perplexity3.8780484199523926


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:10<00:00, 130.47s/it]
INFO:root:final mean train loss: 3435.274212191182
INFO:root:final train perplexity: 3.8779826164245605
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.02s/it]
INFO:root:eval mean loss: 4017.475405862145
INFO:root:eval perplexity: 5.07612943649292
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/102

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [4:05:24<3:57:59, 145.71s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3419.090185546875
INFO:root:current train perplexity3.8290233612060547
INFO:root:current mean train loss 3409.524509595788
INFO:root:current train perplexity3.8210113048553467
INFO:root:current mean train loss 3410.824451535247
INFO:root:current train perplexity3.8351473808288574
INFO:root:current mean train loss 3427.43439437624
INFO:root:current train perplexity3.852423906326294
INFO:root:current mean train loss 3432.9733204301583
INFO:root:current train perplexity3.8576748371124268
INFO:root:current mean train loss 3428.697742528823
INFO:root:current train perplexity3.855374813079834
INFO:root:current mean train loss 3430.872596703506
INFO:root:current train perplexity3.8594398498535156
INFO:root:current mean train loss 3429.3145569274475
INFO:root:current train perplexity3.862220048904419
INFO:root:current mean train loss 3429.290930849789
INFO:root:current train perplexity3.864633083343506
INFO:root:current mean train loss 3430.1338421597507
INFO:root:current train perplexity3.866725206375122


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.27s/it]
INFO:root:final mean train loss: 3429.9433772179386
INFO:root:final train perplexity: 3.869835615158081
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.50s/it]
INFO:root:eval mean loss: 4013.655406762522
INFO:root:eval perplexity: 5.068295001983643
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/103

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [4:07:43<3:52:06, 143.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3370.572562839674
INFO:root:current train perplexity3.8199384212493896
INFO:root:current mean train loss 3414.1700747110012
INFO:root:current train perplexity3.8297312259674072
INFO:root:current mean train loss 3418.5675382742434
INFO:root:current train perplexity3.841723680496216
INFO:root:current mean train loss 3416.799924868179
INFO:root:current train perplexity3.8444533348083496
INFO:root:current mean train loss 3415.819136238549
INFO:root:current train perplexity3.8466999530792236
INFO:root:current mean train loss 3420.062995283371
INFO:root:current train perplexity3.854702949523926
INFO:root:current mean train loss 3423.446251050236
INFO:root:current train perplexity3.858992099761963
INFO:root:current mean train loss 3425.656896314186
INFO:root:current train perplexity3.8630034923553467
INFO:root:current mean train loss 3426.339190532921
INFO:root:current train perplexity3.8628993034362793
INFO:root:current mean train loss 3426.9036424829023
INFO:root:current train perplexity3.8613860607147217


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.23s/it]
INFO:root:final mean train loss: 3425.883816442182
INFO:root:final train perplexity: 3.8636422157287598
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.90s/it]
INFO:root:eval mean loss: 4015.3277613863033
INFO:root:eval perplexity: 5.071722984313965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/104

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [4:10:00<3:47:01, 141.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3373.6076423891127
INFO:root:current train perplexity3.811335563659668
INFO:root:current mean train loss 3393.987293505487
INFO:root:current train perplexity3.823604106903076
INFO:root:current mean train loss 3390.9531345119726
INFO:root:current train perplexity3.831047773361206
INFO:root:current mean train loss 3401.3224684608667
INFO:root:current train perplexity3.8413047790527344
INFO:root:current mean train loss 3403.1811291192357
INFO:root:current train perplexity3.841731548309326
INFO:root:current mean train loss 3408.53356910605
INFO:root:current train perplexity3.8449909687042236
INFO:root:current mean train loss 3413.8158316876734
INFO:root:current train perplexity3.8478851318359375
INFO:root:current mean train loss 3416.3106507433095
INFO:root:current train perplexity3.850238084793091
INFO:root:current mean train loss 3422.4777811465856
INFO:root:current train perplexity3.8562839031219482
INFO:root:current mean train loss 3422.168080462037
INFO:root:current train perplexity3.854292154312134


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.81s/it]
INFO:root:final mean train loss: 3420.9478119880923
INFO:root:final train perplexity: 3.8561253547668457
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.68s/it]
INFO:root:eval mean loss: 4015.669904560062
INFO:root:eval perplexity: 5.072425365447998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/105

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [4:12:18<3:42:29, 140.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3402.3414150140225
INFO:root:current train perplexity3.845386028289795
INFO:root:current mean train loss 3417.504278608363
INFO:root:current train perplexity3.841339111328125
INFO:root:current mean train loss 3413.684090203321
INFO:root:current train perplexity3.8446264266967773
INFO:root:current mean train loss 3424.1773483591446
INFO:root:current train perplexity3.8481204509735107
INFO:root:current mean train loss 3420.010954072644
INFO:root:current train perplexity3.8443644046783447
INFO:root:current mean train loss 3418.844163091373
INFO:root:current train perplexity3.844154119491577
INFO:root:current mean train loss 3421.3090296881114
INFO:root:current train perplexity3.84521746635437
INFO:root:current mean train loss 3422.1829938049727
INFO:root:current train perplexity3.8468568325042725
INFO:root:current mean train loss 3419.7221423616284
INFO:root:current train perplexity3.8462002277374268
INFO:root:current mean train loss 3419.188357482195
INFO:root:current train perplexity3.847775936126709


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.41s/it]
INFO:root:final mean train loss: 3415.920679584626
INFO:root:final train perplexity: 3.848485231399536
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.79s/it]
INFO:root:eval mean loss: 4018.2925047096633
INFO:root:eval perplexity: 5.077807426452637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/106

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [4:14:37<3:39:27, 140.08s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3345.9593999335107
INFO:root:current train perplexity3.797621726989746
INFO:root:current mean train loss 3392.8662258848854
INFO:root:current train perplexity3.8282206058502197
INFO:root:current mean train loss 3393.5162951511893
INFO:root:current train perplexity3.8229291439056396
INFO:root:current mean train loss 3397.127355570065
INFO:root:current train perplexity3.828483819961548
INFO:root:current mean train loss 3402.901897524294
INFO:root:current train perplexity3.827234983444214
INFO:root:current mean train loss 3409.9596056615633
INFO:root:current train perplexity3.833275318145752
INFO:root:current mean train loss 3412.1518543367224
INFO:root:current train perplexity3.8355329036712646
INFO:root:current mean train loss 3410.9482817337057
INFO:root:current train perplexity3.8361356258392334
INFO:root:current mean train loss 3413.687740105243
INFO:root:current train perplexity3.840930700302124
INFO:root:current mean train loss 3413.0336821252968
INFO:root:current train perplexity3.8409993648529053


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.84s/it]
INFO:root:final mean train loss: 3411.7025043733656
INFO:root:final train perplexity: 3.84208607673645
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.09s/it]
INFO:root:eval mean loss: 4020.6366650736923
INFO:root:eval perplexity: 5.08262300491333
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/107

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [4:16:57<3:36:59, 139.99s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3391.0288618607956
INFO:root:current train perplexity3.813795804977417
INFO:root:current mean train loss 3398.7636482484877
INFO:root:current train perplexity3.815410614013672
INFO:root:current mean train loss 3393.1649969362743
INFO:root:current train perplexity3.818918466567993
INFO:root:current mean train loss 3403.0505240426937
INFO:root:current train perplexity3.8253085613250732
INFO:root:current mean train loss 3406.6307783525067
INFO:root:current train perplexity3.8242685794830322
INFO:root:current mean train loss 3404.9752296241554
INFO:root:current train perplexity3.827575206756592
INFO:root:current mean train loss 3405.3410722805343
INFO:root:current train perplexity3.8304522037506104
INFO:root:current mean train loss 3408.2956381286217
INFO:root:current train perplexity3.829989194869995
INFO:root:current mean train loss 3407.4791172674527
INFO:root:current train perplexity3.8297953605651855
INFO:root:current mean train loss 3410.2823633323787
INFO:root:current train perplexity3.834685802459717


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.25s/it]
INFO:root:final mean train loss: 3406.4611436782343
INFO:root:final train perplexity: 3.834149122238159
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.85s/it]
INFO:root:eval mean loss: 4022.7919731410684
INFO:root:eval perplexity: 5.087055206298828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/108

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [4:19:17<3:34:37, 139.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3353.9045216393847
INFO:root:current train perplexity3.812326192855835
INFO:root:current mean train loss 3377.3373948547737
INFO:root:current train perplexity3.8233766555786133
INFO:root:current mean train loss 3384.25846601711
INFO:root:current train perplexity3.8174636363983154
INFO:root:current mean train loss 3392.7585711518595
INFO:root:current train perplexity3.824610948562622
INFO:root:current mean train loss 3397.015107717164
INFO:root:current train perplexity3.819312810897827
INFO:root:current mean train loss 3401.2458296618283
INFO:root:current train perplexity3.8236801624298096
INFO:root:current mean train loss 3403.9582604225584
INFO:root:current train perplexity3.8246757984161377
INFO:root:current mean train loss 3404.42729888956
INFO:root:current train perplexity3.8249740600585938
INFO:root:current mean train loss 3404.2878044543922
INFO:root:current train perplexity3.8270962238311768
INFO:root:current mean train loss 3406.3119397188148
INFO:root:current train perplexity3.8304455280303955


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.97s/it]
INFO:root:final mean train loss: 3403.8537947747013
INFO:root:final train perplexity: 3.8302066326141357
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.03s/it]
INFO:root:eval mean loss: 4020.041349803302
INFO:root:eval perplexity: 5.081400394439697
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/109

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [4:21:35<3:31:47, 139.64s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3379.7747407295333
INFO:root:current train perplexity3.790215492248535
INFO:root:current mean train loss 3379.627202976517
INFO:root:current train perplexity3.8055498600006104
INFO:root:current mean train loss 3382.003321573743
INFO:root:current train perplexity3.8075668811798096
INFO:root:current mean train loss 3386.971881712222
INFO:root:current train perplexity3.8038830757141113
INFO:root:current mean train loss 3391.144712152501
INFO:root:current train perplexity3.8127238750457764
INFO:root:current mean train loss 3395.05312474346
INFO:root:current train perplexity3.8191211223602295
INFO:root:current mean train loss 3396.344722196349
INFO:root:current train perplexity3.820235252380371
INFO:root:current mean train loss 3398.1465508724464
INFO:root:current train perplexity3.820953607559204
INFO:root:current mean train loss 3399.5375906487693
INFO:root:current train perplexity3.8220372200012207
INFO:root:current mean train loss 3401.6407932081133
INFO:root:current train perplexity3.824542999267578


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.86s/it]
INFO:root:final mean train loss: 3399.8439712524414
INFO:root:final train perplexity: 3.824152946472168
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.82s/it]
INFO:root:eval mean loss: 4024.005584067487
INFO:root:eval perplexity: 5.08955192565918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/110

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [4:23:54<3:28:57, 139.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3387.8572302709654
INFO:root:current train perplexity3.7936816215515137
INFO:root:current mean train loss 3392.5628164280724
INFO:root:current train perplexity3.7971768379211426
INFO:root:current mean train loss 3399.300809251792
INFO:root:current train perplexity3.8102030754089355
INFO:root:current mean train loss 3401.1279889511875
INFO:root:current train perplexity3.8148298263549805
INFO:root:current mean train loss 3402.65459759101
INFO:root:current train perplexity3.8122048377990723
INFO:root:current mean train loss 3398.689876049088
INFO:root:current train perplexity3.808401107788086
INFO:root:current mean train loss 3399.4274546380248
INFO:root:current train perplexity3.8099422454833984
INFO:root:current mean train loss 3396.30969692715
INFO:root:current train perplexity3.811403274536133
INFO:root:current mean train loss 3396.2205795270725
INFO:root:current train perplexity3.815197229385376
INFO:root:current mean train loss 3398.0066449142937
INFO:root:current train perplexity3.8179447650909424


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.58s/it]
INFO:root:final mean train loss: 3395.45415945976
INFO:root:final train perplexity: 3.8175346851348877
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.49s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.49s/it]
INFO:root:eval mean loss: 4023.514876994681
INFO:root:eval perplexity: 5.088542461395264
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/111

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [4:26:13<3:26:28, 139.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3399.2558397315015
INFO:root:current train perplexity3.797513961791992
INFO:root:current mean train loss 3393.770036503593
INFO:root:current train perplexity3.798651933670044
INFO:root:current mean train loss 3393.554274927864
INFO:root:current train perplexity3.805908203125
INFO:root:current mean train loss 3390.3687987019543
INFO:root:current train perplexity3.801374912261963
INFO:root:current mean train loss 3389.2041015625
INFO:root:current train perplexity3.8043365478515625
INFO:root:current mean train loss 3389.8738109062233
INFO:root:current train perplexity3.8080897331237793
INFO:root:current mean train loss 3393.57437013851
INFO:root:current train perplexity3.8113536834716797
INFO:root:current mean train loss 3391.250798808271
INFO:root:current train perplexity3.8111610412597656
INFO:root:current mean train loss 3393.1710971630146
INFO:root:current train perplexity3.8118717670440674
INFO:root:current mean train loss 3393.8577243917016
INFO:root:current train perplexity3.810868501663208


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:07<00:00, 127.78s/it]
INFO:root:final mean train loss: 3390.9452501112414
INFO:root:final train perplexity: 3.8107500076293945
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.59s/it]
INFO:root:eval mean loss: 4027.639312527704
INFO:root:eval perplexity: 5.097036361694336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/112

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [4:28:32<3:24:10, 139.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3373.0992238898025
INFO:root:current train perplexity3.784463405609131
INFO:root:current mean train loss 3361.812432391827
INFO:root:current train perplexity3.7897636890411377
INFO:root:current mean train loss 3369.3609093617583
INFO:root:current train perplexity3.7897112369537354
INFO:root:current mean train loss 3379.328082970728
INFO:root:current train perplexity3.7984752655029297
INFO:root:current mean train loss 3380.89209132339
INFO:root:current train perplexity3.7998390197753906
INFO:root:current mean train loss 3379.5731515066964
INFO:root:current train perplexity3.798292398452759
INFO:root:current mean train loss 3383.77618381857
INFO:root:current train perplexity3.802224636077881
INFO:root:current mean train loss 3387.108785684454
INFO:root:current train perplexity3.8048384189605713
INFO:root:current mean train loss 3388.095408519553
INFO:root:current train perplexity3.80613374710083


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.92s/it]
INFO:root:final mean train loss: 3387.939328162901
INFO:root:final train perplexity: 3.8062334060668945
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.64s/it]
INFO:root:eval mean loss: 4028.353203956117
INFO:root:eval perplexity: 5.098507404327393
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/113

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [4:30:54<3:22:49, 139.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3324.87060546875
INFO:root:current train perplexity3.8410208225250244
INFO:root:current mean train loss 3361.213141876517
INFO:root:current train perplexity3.7711169719696045
INFO:root:current mean train loss 3377.5762356161486
INFO:root:current train perplexity3.7892277240753174
INFO:root:current mean train loss 3375.8516616065904
INFO:root:current train perplexity3.788917064666748
INFO:root:current mean train loss 3376.0621419674703
INFO:root:current train perplexity3.7909533977508545
INFO:root:current mean train loss 3380.3588042060137
INFO:root:current train perplexity3.7943835258483887
INFO:root:current mean train loss 3381.20409306009
INFO:root:current train perplexity3.79435133934021
INFO:root:current mean train loss 3382.1120463082325
INFO:root:current train perplexity3.795443534851074
INFO:root:current mean train loss 3386.080291253989
INFO:root:current train perplexity3.7995100021362305
INFO:root:current mean train loss 3384.9479818249065
INFO:root:current train perplexity3.7970080375671387


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:08<00:00, 128.02s/it]
INFO:root:final mean train loss: 3382.48119495761
INFO:root:final train perplexity: 3.7980456352233887
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.11s/it]
INFO:root:eval mean loss: 4025.633376966977
INFO:root:eval perplexity: 5.092903137207031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/114

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [4:33:14<3:20:32, 139.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3349.702325994318
INFO:root:current train perplexity3.7834606170654297
INFO:root:current mean train loss 3374.352275126689
INFO:root:current train perplexity3.804180383682251
INFO:root:current mean train loss 3370.003680622408
INFO:root:current train perplexity3.796820640563965
INFO:root:current mean train loss 3377.1206894656852
INFO:root:current train perplexity3.7935354709625244
INFO:root:current mean train loss 3377.64659307995
INFO:root:current train perplexity3.7917773723602295
INFO:root:current mean train loss 3375.2489852158756
INFO:root:current train perplexity3.78950572013855
INFO:root:current mean train loss 3380.8113296433867
INFO:root:current train perplexity3.788771152496338
INFO:root:current mean train loss 3379.5779011185828
INFO:root:current train perplexity3.789149761199951
INFO:root:current mean train loss 3376.986501823077
INFO:root:current train perplexity3.786884069442749
INFO:root:current mean train loss 3378.6156122435855
INFO:root:current train perplexity3.788348436355591


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:09<00:00, 129.34s/it]
INFO:root:final mean train loss: 3378.325473723873
INFO:root:final train perplexity: 3.7918238639831543
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.86s/it]
INFO:root:eval mean loss: 4028.74469297152
INFO:root:eval perplexity: 5.099315166473389
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/115

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [4:35:35<3:18:40, 140.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3330.7809287623354
INFO:root:current train perplexity3.7468323707580566
INFO:root:current mean train loss 3345.5168108258927
INFO:root:current train perplexity3.770308256149292
INFO:root:current mean train loss 3361.135846978453
INFO:root:current train perplexity3.7733325958251953
INFO:root:current mean train loss 3368.412345862314
INFO:root:current train perplexity3.7780306339263916
INFO:root:current mean train loss 3368.6363982790126
INFO:root:current train perplexity3.7751705646514893
INFO:root:current mean train loss 3370.8557542863377
INFO:root:current train perplexity3.774683952331543
INFO:root:current mean train loss 3373.3753600975615
INFO:root:current train perplexity3.779646158218384
INFO:root:current mean train loss 3377.078948762387
INFO:root:current train perplexity3.782026767730713
INFO:root:current mean train loss 3377.5296715816735
INFO:root:current train perplexity3.783012866973877
INFO:root:current mean train loss 3375.7189128489695
INFO:root:current train perplexity3.784973382949829


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.33s/it]
INFO:root:final mean train loss: 3374.9436272036646
INFO:root:final train perplexity: 3.7867681980133057
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.67s/it]
INFO:root:eval mean loss: 4029.6663134419327
INFO:root:eval perplexity: 5.10121488571167
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/116

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [4:37:52<3:15:19, 139.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3384.39892578125
INFO:root:current train perplexity3.793304920196533
INFO:root:current mean train loss 3380.283864419291
INFO:root:current train perplexity3.7789413928985596
INFO:root:current mean train loss 3377.028527885807
INFO:root:current train perplexity3.7732467651367188
INFO:root:current mean train loss 3370.4533892990253
INFO:root:current train perplexity3.7715423107147217
INFO:root:current mean train loss 3373.4735939329626
INFO:root:current train perplexity3.7758123874664307
INFO:root:current mean train loss 3372.6328435387513
INFO:root:current train perplexity3.774184226989746
INFO:root:current mean train loss 3372.9552366022476
INFO:root:current train perplexity3.7743709087371826
INFO:root:current mean train loss 3372.99684766431
INFO:root:current train perplexity3.7762234210968018
INFO:root:current mean train loss 3372.2100559958812
INFO:root:current train perplexity3.776066541671753
INFO:root:current mean train loss 3372.7403668482843
INFO:root:current train perplexity3.7794010639190674


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.69s/it]
INFO:root:final mean train loss: 3369.9564314196186
INFO:root:final train perplexity: 3.7793242931365967
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.98s/it]
INFO:root:eval mean loss: 4030.891793758311
INFO:root:eval perplexity: 5.103744029998779
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/117

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [4:40:10<3:12:09, 138.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3365.5477120535716
INFO:root:current train perplexity3.752140760421753
INFO:root:current mean train loss 3365.513501880787
INFO:root:current train perplexity3.7556490898132324
INFO:root:current mean train loss 3361.911140084774
INFO:root:current train perplexity3.761946439743042
INFO:root:current mean train loss 3367.6223275711286
INFO:root:current train perplexity3.7666330337524414
INFO:root:current mean train loss 3371.1881538478806
INFO:root:current train perplexity3.7697415351867676
INFO:root:current mean train loss 3370.9793142158296
INFO:root:current train perplexity3.770847797393799
INFO:root:current mean train loss 3370.2777601347193
INFO:root:current train perplexity3.7738373279571533
INFO:root:current mean train loss 3371.7250441778274
INFO:root:current train perplexity3.773993968963623
INFO:root:current mean train loss 3371.111995637631
INFO:root:current train perplexity3.774906873703003
INFO:root:current mean train loss 3370.9478390290774
INFO:root:current train perplexity3.776764392852783


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 125.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 125.00s/it]
INFO:root:final mean train loss: 3367.9120463094405
INFO:root:final train perplexity: 3.7762773036956787
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.26s/it]
INFO:root:eval mean loss: 4031.5375595633864
INFO:root:eval perplexity: 5.105075836181641
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/118

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [4:42:26<3:08:41, 138.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3361.0340945221656
INFO:root:current train perplexity3.7563042640686035
INFO:root:current mean train loss 3348.997140310861
INFO:root:current train perplexity3.7422780990600586
INFO:root:current mean train loss 3348.939768598894
INFO:root:current train perplexity3.7481279373168945
INFO:root:current mean train loss 3353.271432415042
INFO:root:current train perplexity3.750831365585327
INFO:root:current mean train loss 3360.651754064969
INFO:root:current train perplexity3.754516124725342
INFO:root:current mean train loss 3361.8007259474275
INFO:root:current train perplexity3.756706714630127
INFO:root:current mean train loss 3364.035081830774
INFO:root:current train perplexity3.761526346206665
INFO:root:current mean train loss 3365.2061378201756
INFO:root:current train perplexity3.764406204223633
INFO:root:current mean train loss 3364.1383133387085
INFO:root:current train perplexity3.7686305046081543
INFO:root:current mean train loss 3364.9666542223126
INFO:root:current train perplexity3.7683770656585693


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.07s/it]
INFO:root:final mean train loss: 3362.710858621905
INFO:root:final train perplexity: 3.76853609085083
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.76s/it]
INFO:root:eval mean loss: 4032.9090480939717
INFO:root:eval perplexity: 5.107907772064209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/119

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [4:44:41<3:05:01, 137.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3363.347412109375
INFO:root:current train perplexity3.7590367794036865
INFO:root:current mean train loss 3350.6306168512006
INFO:root:current train perplexity3.7479381561279297
INFO:root:current mean train loss 3349.2712042455178
INFO:root:current train perplexity3.7534639835357666
INFO:root:current mean train loss 3343.862968944756
INFO:root:current train perplexity3.751744031906128
INFO:root:current mean train loss 3345.2741179540258
INFO:root:current train perplexity3.751035213470459
INFO:root:current mean train loss 3351.343619289502
INFO:root:current train perplexity3.7546751499176025
INFO:root:current mean train loss 3356.1558948522706
INFO:root:current train perplexity3.7585110664367676
INFO:root:current mean train loss 3360.1642842095957
INFO:root:current train perplexity3.7619831562042236
INFO:root:current mean train loss 3359.68246886705
INFO:root:current train perplexity3.762542963027954
INFO:root:current mean train loss 3361.4173713627924
INFO:root:current train perplexity3.763331651687622


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.99s/it]
INFO:root:final mean train loss: 3359.479013566048
INFO:root:final train perplexity: 3.7637345790863037
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.53s/it]
INFO:root:eval mean loss: 4034.449293204233
INFO:root:eval perplexity: 5.111090183258057
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/120

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [4:46:59<3:03:16, 137.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3341.984561208951
INFO:root:current train perplexity3.730661392211914
INFO:root:current mean train loss 3337.9058216022995
INFO:root:current train perplexity3.7314372062683105
INFO:root:current mean train loss 3338.7910118544883
INFO:root:current train perplexity3.728376626968384
INFO:root:current mean train loss 3345.87447703582
INFO:root:current train perplexity3.7402286529541016
INFO:root:current mean train loss 3348.727959792858
INFO:root:current train perplexity3.7458088397979736
INFO:root:current mean train loss 3347.175016072227
INFO:root:current train perplexity3.7491700649261475
INFO:root:current mean train loss 3352.8023338954617
INFO:root:current train perplexity3.7532663345336914
INFO:root:current mean train loss 3354.997290971879
INFO:root:current train perplexity3.755474090576172
INFO:root:current mean train loss 3356.6442731828433
INFO:root:current train perplexity3.7558460235595703
INFO:root:current mean train loss 3356.5797489552106
INFO:root:current train perplexity3.7559173107147217


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.14s/it]
INFO:root:final mean train loss: 3354.36923439272
INFO:root:final train perplexity: 3.7561545372009277
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.69s/it]
INFO:root:eval mean loss: 4035.036058358267
INFO:root:eval perplexity: 5.112303733825684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/121

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [4:49:15<3:00:16, 136.91s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3341.2553455865204
INFO:root:current train perplexity3.748120069503784
INFO:root:current mean train loss 3348.8263926249065
INFO:root:current train perplexity3.746635913848877
INFO:root:current mean train loss 3343.96054980103
INFO:root:current train perplexity3.7386586666107178
INFO:root:current mean train loss 3344.2095977201125
INFO:root:current train perplexity3.742516279220581
INFO:root:current mean train loss 3347.8315330358337
INFO:root:current train perplexity3.7412333488464355
INFO:root:current mean train loss 3347.646534322641
INFO:root:current train perplexity3.7423923015594482
INFO:root:current mean train loss 3350.6378783264618
INFO:root:current train perplexity3.744447708129883
INFO:root:current mean train loss 3350.3771803954123
INFO:root:current train perplexity3.7453575134277344
INFO:root:current mean train loss 3352.11931662026
INFO:root:current train perplexity3.7468628883361816
INFO:root:current mean train loss 3354.9575945154957
INFO:root:current train perplexity3.752100944519043


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.59s/it]
INFO:root:final mean train loss: 3352.7415973909438
INFO:root:final train perplexity: 3.7537436485290527
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.80s/it]
INFO:root:eval mean loss: 4035.9332509142287
INFO:root:eval perplexity: 5.1141581535339355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/122

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [4:51:31<2:57:42, 136.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3348.62712890625
INFO:root:current train perplexity3.7396838665008545
INFO:root:current mean train loss 3336.9668359375
INFO:root:current train perplexity3.7474467754364014
INFO:root:current mean train loss 3344.3277388139204
INFO:root:current train perplexity3.7476468086242676
INFO:root:current mean train loss 3345.7556966145835
INFO:root:current train perplexity3.745032548904419
INFO:root:current mean train loss 3350.3176773231908
INFO:root:current train perplexity3.748898506164551
INFO:root:current mean train loss 3350.5276592221467
INFO:root:current train perplexity3.745512008666992
INFO:root:current mean train loss 3351.5317827690974
INFO:root:current train perplexity3.7463693618774414
INFO:root:current mean train loss 3351.719265688004
INFO:root:current train perplexity3.746617555618286
INFO:root:current mean train loss 3350.370689453125
INFO:root:current train perplexity3.7459325790405273
INFO:root:current mean train loss 3349.9017059795674
INFO:root:current train perplexity3.7458906173706055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.56s/it]
INFO:root:final mean train loss: 3347.7396685077297
INFO:root:final train perplexity: 3.746342897415161
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.53s/it]
INFO:root:eval mean loss: 4036.094432208555
INFO:root:eval perplexity: 5.114491939544678
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/123

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [4:54:05<3:02:03, 141.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3328.6657979574547
INFO:root:current train perplexity3.7328927516937256
INFO:root:current mean train loss 3321.72432387722
INFO:root:current train perplexity3.728844165802002
INFO:root:current mean train loss 3327.7112230496355
INFO:root:current train perplexity3.7273168563842773
INFO:root:current mean train loss 3338.611538481152
INFO:root:current train perplexity3.738172769546509
INFO:root:current mean train loss 3340.4065987723216
INFO:root:current train perplexity3.7419464588165283
INFO:root:current mean train loss 3349.652717289344
INFO:root:current train perplexity3.7442333698272705
INFO:root:current mean train loss 3351.5072530855373
INFO:root:current train perplexity3.7450954914093018
INFO:root:current mean train loss 3349.3132595486113
INFO:root:current train perplexity3.7415318489074707
INFO:root:current mean train loss 3348.8903064835786
INFO:root:current train perplexity3.742840528488159
INFO:root:current mean train loss 3348.8903500623887
INFO:root:current train perplexity3.744016408920288


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.91s/it]
INFO:root:final mean train loss: 3346.1156626055317
INFO:root:final train perplexity: 3.743943214416504
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.62s/it]
INFO:root:eval mean loss: 4037.721987893395
INFO:root:eval perplexity: 5.117858409881592
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/124

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [4:56:18<2:56:27, 139.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3308.90873164921
INFO:root:current train perplexity3.67750883102417
INFO:root:current mean train loss 3335.5424242269305
INFO:root:current train perplexity3.718959331512451
INFO:root:current mean train loss 3337.0130317399594
INFO:root:current train perplexity3.720332622528076
INFO:root:current mean train loss 3338.3362796715155
INFO:root:current train perplexity3.719822645187378
INFO:root:current mean train loss 3337.6956506173624
INFO:root:current train perplexity3.721630573272705
INFO:root:current mean train loss 3340.915580633328
INFO:root:current train perplexity3.7284860610961914
INFO:root:current mean train loss 3342.612152055445
INFO:root:current train perplexity3.7303221225738525
INFO:root:current mean train loss 3345.690999760489
INFO:root:current train perplexity3.7320902347564697
INFO:root:current mean train loss 3343.8424860037003
INFO:root:current train perplexity3.734693765640259
INFO:root:current mean train loss 3343.4992545211594
INFO:root:current train perplexity3.7361538410186768


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.10s/it]
INFO:root:final mean train loss: 3340.796794768303
INFO:root:final train perplexity: 3.7360951900482178
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.21s/it]
INFO:root:eval mean loss: 4038.333587862921
INFO:root:eval perplexity: 5.119124412536621
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/125

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [4:58:33<2:52:33, 138.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3342.3226675939077
INFO:root:current train perplexity3.727114677429199
INFO:root:current mean train loss 3330.3958243365264
INFO:root:current train perplexity3.724736452102661
INFO:root:current mean train loss 3334.1369269635766
INFO:root:current train perplexity3.7265686988830566
INFO:root:current mean train loss 3334.9059715940243
INFO:root:current train perplexity3.726989269256592
INFO:root:current mean train loss 3334.171988997526
INFO:root:current train perplexity3.7239906787872314
INFO:root:current mean train loss 3336.6788128325857
INFO:root:current train perplexity3.7246108055114746
INFO:root:current mean train loss 3336.3320930710165
INFO:root:current train perplexity3.726395845413208
INFO:root:current mean train loss 3339.3582752977354
INFO:root:current train perplexity3.728686809539795
INFO:root:current mean train loss 3340.852944515173
INFO:root:current train perplexity3.732266902923584


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.70s/it]
INFO:root:final mean train loss: 3338.5022021262876
INFO:root:final train perplexity: 3.7327144145965576
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.08s/it]
INFO:root:eval mean loss: 4039.6686215231603
INFO:root:eval perplexity: 5.121889591217041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/126

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [5:00:56<2:51:57, 139.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3345.4852469308034
INFO:root:current train perplexity3.784421920776367
INFO:root:current mean train loss 3325.2579859082944
INFO:root:current train perplexity3.713144302368164
INFO:root:current mean train loss 3332.438662911383
INFO:root:current train perplexity3.717848062515259
INFO:root:current mean train loss 3330.6242954117465
INFO:root:current train perplexity3.717041254043579
INFO:root:current mean train loss 3324.2460757543768
INFO:root:current train perplexity3.7177700996398926
INFO:root:current mean train loss 3329.313139966254
INFO:root:current train perplexity3.721766233444214
INFO:root:current mean train loss 3331.189373487696
INFO:root:current train perplexity3.720850706100464
INFO:root:current mean train loss 3335.348250544223
INFO:root:current train perplexity3.725308418273926
INFO:root:current mean train loss 3336.3829737477736
INFO:root:current train perplexity3.726088047027588
INFO:root:current mean train loss 3336.192801916087
INFO:root:current train perplexity3.7242913246154785


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.10s/it]
INFO:root:final mean train loss: 3334.0282604463637
INFO:root:final train perplexity: 3.7261314392089844
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.03s/it]
INFO:root:eval mean loss: 4041.830126606826
INFO:root:eval perplexity: 5.126368522644043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/127

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [5:03:09<2:47:15, 137.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3300.7024739583335
INFO:root:current train perplexity3.7405238151550293
INFO:root:current mean train loss 3314.362512737772
INFO:root:current train perplexity3.7306973934173584
INFO:root:current mean train loss 3319.311622229288
INFO:root:current train perplexity3.726513147354126
INFO:root:current mean train loss 3325.3879286024307
INFO:root:current train perplexity3.719998836517334
INFO:root:current mean train loss 3327.8924863516568
INFO:root:current train perplexity3.718451738357544
INFO:root:current mean train loss 3326.7323408108314
INFO:root:current train perplexity3.718627691268921
INFO:root:current mean train loss 3328.4804659711635
INFO:root:current train perplexity3.7170801162719727
INFO:root:current mean train loss 3330.104618526005
INFO:root:current train perplexity3.718944787979126
INFO:root:current mean train loss 3329.384248286522
INFO:root:current train perplexity3.7172024250030518
INFO:root:current mean train loss 3331.989148949795
INFO:root:current train perplexity3.7207727432250977


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.34s/it]
INFO:root:final mean train loss: 3331.368646867814
INFO:root:final train perplexity: 3.722224235534668
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.17s/it]
INFO:root:eval mean loss: 4041.9217347490026
INFO:root:eval perplexity: 5.12655782699585
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/128

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [5:05:24<2:44:12, 136.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3288.630954908288
INFO:root:current train perplexity3.7052762508392334
INFO:root:current mean train loss 3331.4978999936484
INFO:root:current train perplexity3.711721420288086
INFO:root:current mean train loss 3328.5803627732626
INFO:root:current train perplexity3.710111141204834
INFO:root:current mean train loss 3329.1253333313175
INFO:root:current train perplexity3.7175347805023193
INFO:root:current mean train loss 3326.8053547022755
INFO:root:current train perplexity3.7111308574676514
INFO:root:current mean train loss 3325.810236914436
INFO:root:current train perplexity3.7135722637176514
INFO:root:current mean train loss 3326.9740435017056
INFO:root:current train perplexity3.7145326137542725
INFO:root:current mean train loss 3328.151118657071
INFO:root:current train perplexity3.7154343128204346
INFO:root:current mean train loss 3326.456761597718
INFO:root:current train perplexity3.7134392261505127
INFO:root:current mean train loss 3327.4023252344596
INFO:root:current train perplexity3.713361978530884


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.95s/it]
INFO:root:final mean train loss: 3326.3316294762394
INFO:root:final train perplexity: 3.714834213256836
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.35s/it]
INFO:root:eval mean loss: 4042.9706304022607
INFO:root:eval perplexity: 5.1287336349487305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/129

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [5:07:36<2:40:14, 135.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3327.399721207157
INFO:root:current train perplexity3.6829283237457275
INFO:root:current mean train loss 3318.9346467229248
INFO:root:current train perplexity3.7031121253967285
INFO:root:current mean train loss 3329.7211586427893
INFO:root:current train perplexity3.712756633758545
INFO:root:current mean train loss 3329.80957473801
INFO:root:current train perplexity3.713496208190918
INFO:root:current mean train loss 3326.779241929198
INFO:root:current train perplexity3.714463949203491
INFO:root:current mean train loss 3329.081594463571
INFO:root:current train perplexity3.7181153297424316
INFO:root:current mean train loss 3327.9194157958595
INFO:root:current train perplexity3.7138450145721436
INFO:root:current mean train loss 3328.6682980559594
INFO:root:current train perplexity3.7130532264709473
INFO:root:current mean train loss 3325.4227199439683
INFO:root:current train perplexity3.710543394088745
INFO:root:current mean train loss 3325.41520741726
INFO:root:current train perplexity3.7101922035217285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.63s/it]
INFO:root:final mean train loss: 3324.327287366313
INFO:root:final train perplexity: 3.711897611618042
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.13s/it]
INFO:root:eval mean loss: 4043.3953260056514
INFO:root:eval perplexity: 5.129613876342773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/130

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [5:09:49<2:36:59, 134.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3323.0020845853364
INFO:root:current train perplexity3.7041664123535156
INFO:root:current mean train loss 3325.312034552046
INFO:root:current train perplexity3.710134744644165
INFO:root:current mean train loss 3321.601084433839
INFO:root:current train perplexity3.7011353969573975
INFO:root:current mean train loss 3324.8651263481747
INFO:root:current train perplexity3.7058522701263428
INFO:root:current mean train loss 3324.9140091116174
INFO:root:current train perplexity3.708549976348877
INFO:root:current mean train loss 3318.3406413968287
INFO:root:current train perplexity3.7052512168884277
INFO:root:current mean train loss 3318.145442479093
INFO:root:current train perplexity3.7054083347320557
INFO:root:current mean train loss 3318.7220219468877
INFO:root:current train perplexity3.703723669052124
INFO:root:current mean train loss 3322.738081630848
INFO:root:current train perplexity3.7064452171325684
INFO:root:current mean train loss 3323.386756710097
INFO:root:current train perplexity3.7080118656158447


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.57s/it]
INFO:root:final mean train loss: 3321.3584744853356
INFO:root:final train perplexity: 3.7075531482696533
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.16s/it]
INFO:root:eval mean loss: 4046.8638509114585
INFO:root:eval perplexity: 5.136813640594482
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/131

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [5:12:09<2:36:43, 136.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3279.925251412899
INFO:root:current train perplexity3.690526247024536
INFO:root:current mean train loss 3313.573107661033
INFO:root:current train perplexity3.689121961593628
INFO:root:current mean train loss 3315.2318209134614
INFO:root:current train perplexity3.700961112976074
INFO:root:current mean train loss 3313.8600236964157
INFO:root:current train perplexity3.693718671798706
INFO:root:current mean train loss 3316.161983754544
INFO:root:current train perplexity3.6948235034942627
INFO:root:current mean train loss 3317.4210702732234
INFO:root:current train perplexity3.696542978286743
INFO:root:current mean train loss 3317.976504766591
INFO:root:current train perplexity3.699540376663208
INFO:root:current mean train loss 3318.895588212224
INFO:root:current train perplexity3.7010960578918457
INFO:root:current mean train loss 3318.149997463474
INFO:root:current train perplexity3.7004101276397705
INFO:root:current mean train loss 3319.7476880114837
INFO:root:current train perplexity3.7015492916107178


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.59s/it]
INFO:root:final mean train loss: 3318.1588180295885
INFO:root:final train perplexity: 3.7028756141662598
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.19s/it]
INFO:root:eval mean loss: 4045.5194498697915
INFO:root:eval perplexity: 5.134021759033203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/132

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [5:14:40<2:39:26, 140.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3283.6402210582387
INFO:root:current train perplexity3.672708511352539
INFO:root:current mean train loss 3287.3457314768143
INFO:root:current train perplexity3.6791608333587646
INFO:root:current mean train loss 3292.2433890548405
INFO:root:current train perplexity3.686267852783203
INFO:root:current mean train loss 3294.4037962147886
INFO:root:current train perplexity3.6813013553619385
INFO:root:current mean train loss 3299.7201703082073
INFO:root:current train perplexity3.6822164058685303
INFO:root:current mean train loss 3304.0559187605572
INFO:root:current train perplexity3.6855337619781494
INFO:root:current mean train loss 3306.4127761957297
INFO:root:current train perplexity3.6894397735595703
INFO:root:current mean train loss 3308.8651525636383
INFO:root:current train perplexity3.6911532878875732
INFO:root:current mean train loss 3312.088782095212
INFO:root:current train perplexity3.692640781402588
INFO:root:current mean train loss 3314.1822590293687
INFO:root:current train perplexity3.6952288150787354


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.18s/it]
INFO:root:final mean train loss: 3314.2400405022404
INFO:root:final train perplexity: 3.6971547603607178
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.03s/it]
INFO:root:eval mean loss: 4048.2952716367463
INFO:root:eval perplexity: 5.139787673950195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/133

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [5:16:53<2:34:26, 138.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3299.036392454117
INFO:root:current train perplexity3.6885299682617188
INFO:root:current mean train loss 3301.0647227281443
INFO:root:current train perplexity3.6874547004699707
INFO:root:current mean train loss 3307.704103419083
INFO:root:current train perplexity3.694549560546875
INFO:root:current mean train loss 3311.6242413481405
INFO:root:current train perplexity3.697730302810669
INFO:root:current mean train loss 3313.4245826935407
INFO:root:current train perplexity3.696099281311035
INFO:root:current mean train loss 3319.463694164215
INFO:root:current train perplexity3.697366237640381
INFO:root:current mean train loss 3316.962237742152
INFO:root:current train perplexity3.694749593734741
INFO:root:current mean train loss 3314.7913343197083
INFO:root:current train perplexity3.6931357383728027
INFO:root:current mean train loss 3314.581094576061
INFO:root:current train perplexity3.693786382675171
INFO:root:current mean train loss 3316.15470048027
INFO:root:current train perplexity3.695692300796509


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.32s/it]
INFO:root:final mean train loss: 3313.57214349316
INFO:root:final train perplexity: 3.696180820465088
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.41s/it]
INFO:root:eval mean loss: 4050.3846011330897
INFO:root:eval perplexity: 5.144132614135742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/134

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [5:19:05<2:30:13, 136.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3310.60244278169
INFO:root:current train perplexity3.6895620822906494
INFO:root:current mean train loss 3296.821359020925
INFO:root:current train perplexity3.6721131801605225
INFO:root:current mean train loss 3297.4529150931157
INFO:root:current train perplexity3.6741979122161865
INFO:root:current mean train loss 3300.452763066459
INFO:root:current train perplexity3.677460193634033
INFO:root:current mean train loss 3304.6666941389662
INFO:root:current train perplexity3.6818416118621826
INFO:root:current mean train loss 3310.5732896474115
INFO:root:current train perplexity3.684497833251953
INFO:root:current mean train loss 3314.634039752352
INFO:root:current train perplexity3.6911637783050537
INFO:root:current mean train loss 3312.90942699467
INFO:root:current train perplexity3.6903324127197266
INFO:root:current mean train loss 3313.669097514979
INFO:root:current train perplexity3.6918318271636963
INFO:root:current mean train loss 3311.8136301875484
INFO:root:current train perplexity3.6898531913757324


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.91s/it]
INFO:root:final mean train loss: 3309.743679231213
INFO:root:final train perplexity: 3.6906020641326904
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.10s/it]
INFO:root:eval mean loss: 4048.7926778590427
INFO:root:eval perplexity: 5.140821933746338
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/135

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [5:21:43<2:34:51, 142.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3313.6262361550635
INFO:root:current train perplexity3.6823010444641113
INFO:root:current mean train loss 3305.760976780726
INFO:root:current train perplexity3.6940805912017822
INFO:root:current mean train loss 3304.433569248432
INFO:root:current train perplexity3.6871042251586914
INFO:root:current mean train loss 3307.2383314953
INFO:root:current train perplexity3.686171770095825
INFO:root:current mean train loss 3309.9235381124413
INFO:root:current train perplexity3.6874630451202393
INFO:root:current mean train loss 3311.4720098465837
INFO:root:current train perplexity3.687511682510376
INFO:root:current mean train loss 3314.3593512691
INFO:root:current train perplexity3.6880428791046143
INFO:root:current mean train loss 3313.483172160823
INFO:root:current train perplexity3.6857142448425293
INFO:root:current mean train loss 3312.0555549074766
INFO:root:current train perplexity3.685727119445801
INFO:root:current mean train loss 3308.827088586887
INFO:root:current train perplexity3.68496036529541


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.64s/it]
INFO:root:final mean train loss: 3306.3227305258474
INFO:root:final train perplexity: 3.685624599456787
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.96s/it]
INFO:root:eval mean loss: 4051.010186377992
INFO:root:eval perplexity: 5.14543342590332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/136

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [5:24:19<2:36:37, 146.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3282.8035509832976
INFO:root:current train perplexity3.66683030128479
INFO:root:current mean train loss 3298.4351395387703
INFO:root:current train perplexity3.674748182296753
INFO:root:current mean train loss 3297.1007348037347
INFO:root:current train perplexity3.6718177795410156
INFO:root:current mean train loss 3305.3358580123545
INFO:root:current train perplexity3.6781322956085205
INFO:root:current mean train loss 3308.7416310398485
INFO:root:current train perplexity3.680168867111206
INFO:root:current mean train loss 3307.9052867466994
INFO:root:current train perplexity3.6782383918762207
INFO:root:current mean train loss 3307.4191716845207
INFO:root:current train perplexity3.678574800491333
INFO:root:current mean train loss 3304.685575414946
INFO:root:current train perplexity3.677171468734741
INFO:root:current mean train loss 3304.9641124290974
INFO:root:current train perplexity3.678483724594116
INFO:root:current mean train loss 3306.1945842831815
INFO:root:current train perplexity3.681915760040283


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.18s/it]
INFO:root:final mean train loss: 3303.8958350150815
INFO:root:final train perplexity: 3.6820969581604004
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.22s/it]
INFO:root:eval mean loss: 4051.28998884918
INFO:root:eval perplexity: 5.146015167236328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/137

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [5:26:44<2:33:40, 146.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3281.2671155427633
INFO:root:current train perplexity3.6557517051696777
INFO:root:current mean train loss 3294.0920485276442
INFO:root:current train perplexity3.661630153656006
INFO:root:current mean train loss 3297.2001771054024
INFO:root:current train perplexity3.668383836746216
INFO:root:current mean train loss 3297.299203298062
INFO:root:current train perplexity3.6717870235443115
INFO:root:current mean train loss 3296.66809994476
INFO:root:current train perplexity3.6732914447784424
INFO:root:current mean train loss 3299.5994403230043
INFO:root:current train perplexity3.676234722137451
INFO:root:current mean train loss 3297.8099419683003
INFO:root:current train perplexity3.6745657920837402
INFO:root:current mean train loss 3301.810519850629
INFO:root:current train perplexity3.6782569885253906
INFO:root:current mean train loss 3302.486384045478
INFO:root:current train perplexity3.677877187728882


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.73s/it]
INFO:root:final mean train loss: 3301.100561449605
INFO:root:final train perplexity: 3.678039073944092
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.25s/it]
INFO:root:eval mean loss: 4051.2584670046544
INFO:root:eval perplexity: 5.145949840545654
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/138

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [5:29:31<2:37:29, 152.41s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3356.705810546875
INFO:root:current train perplexity3.535550355911255
INFO:root:current mean train loss 3275.012036369842
INFO:root:current train perplexity3.639922857284546
INFO:root:current mean train loss 3279.453883880465
INFO:root:current train perplexity3.647913932800293
INFO:root:current mean train loss 3285.2410119185747
INFO:root:current train perplexity3.657167911529541
INFO:root:current mean train loss 3290.500706977939
INFO:root:current train perplexity3.656008005142212
INFO:root:current mean train loss 3292.010838290569
INFO:root:current train perplexity3.657102346420288
INFO:root:current mean train loss 3294.0614092622823
INFO:root:current train perplexity3.659780263900757
INFO:root:current mean train loss 3295.0927960109575
INFO:root:current train perplexity3.663402795791626
INFO:root:current mean train loss 3297.663459597311
INFO:root:current train perplexity3.66656494140625
INFO:root:current mean train loss 3297.953650591777
INFO:root:current train perplexity3.6688079833984375


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.83s/it]
INFO:root:final mean train loss: 3297.0125482005456
INFO:root:final train perplexity: 3.6721115112304688
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.58s/it]
INFO:root:eval mean loss: 4055.114848251884
INFO:root:eval perplexity: 5.1539812088012695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/139

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [5:32:24<2:41:23, 158.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3350.621004971591
INFO:root:current train perplexity3.6147260665893555
INFO:root:current mean train loss 3295.8449619052644
INFO:root:current train perplexity3.6697964668273926
INFO:root:current mean train loss 3289.177813055391
INFO:root:current train perplexity3.6557421684265137
INFO:root:current mean train loss 3280.080629992715
INFO:root:current train perplexity3.6464409828186035
INFO:root:current mean train loss 3284.58766252281
INFO:root:current train perplexity3.6512296199798584
INFO:root:current mean train loss 3286.2080307454744
INFO:root:current train perplexity3.658592939376831
INFO:root:current mean train loss 3289.150066569277
INFO:root:current train perplexity3.6598503589630127
INFO:root:current mean train loss 3291.7538746593705
INFO:root:current train perplexity3.6603691577911377
INFO:root:current mean train loss 3293.971123673031
INFO:root:current train perplexity3.665104627609253
INFO:root:current mean train loss 3296.3324506573304
INFO:root:current train perplexity3.666402816772461


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.40s/it]
INFO:root:final mean train loss: 3294.1079671305993
INFO:root:final train perplexity: 3.6679062843322754
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.10s/it]
INFO:root:eval mean loss: 4056.1400155141846
INFO:root:eval perplexity: 5.156117916107178
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/140

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [5:34:36<2:30:30, 150.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3286.4960038034537
INFO:root:current train perplexity3.6623027324676514
INFO:root:current mean train loss 3271.8081834296217
INFO:root:current train perplexity3.6464996337890625
INFO:root:current mean train loss 3272.424705470534
INFO:root:current train perplexity3.6573336124420166
INFO:root:current mean train loss 3279.936938246963
INFO:root:current train perplexity3.6575915813446045
INFO:root:current mean train loss 3284.417708877163
INFO:root:current train perplexity3.6598517894744873
INFO:root:current mean train loss 3287.5351487235066
INFO:root:current train perplexity3.661500930786133
INFO:root:current mean train loss 3286.324885699591
INFO:root:current train perplexity3.660572052001953
INFO:root:current mean train loss 3289.1865821806546
INFO:root:current train perplexity3.661694288253784
INFO:root:current mean train loss 3290.5423510950855
INFO:root:current train perplexity3.6620242595672607
INFO:root:current mean train loss 3292.313967765999
INFO:root:current train perplexity3.662299633026123


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.31s/it]
INFO:root:final mean train loss: 3292.408083454255
INFO:root:final train perplexity: 3.6654469966888428
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.41s/it]
INFO:root:eval mean loss: 4054.741269808289
INFO:root:eval perplexity: 5.153202056884766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/141

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [5:36:50<2:23:17, 145.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3238.9264322916665
INFO:root:current train perplexity3.6579959392547607
INFO:root:current mean train loss 3284.9783810593012
INFO:root:current train perplexity3.662092685699463
INFO:root:current mean train loss 3285.832162462142
INFO:root:current train perplexity3.661881923675537
INFO:root:current mean train loss 3285.2762126397647
INFO:root:current train perplexity3.6627790927886963
INFO:root:current mean train loss 3290.5222779749706
INFO:root:current train perplexity3.663579225540161
INFO:root:current mean train loss 3290.452585296341
INFO:root:current train perplexity3.6611835956573486
INFO:root:current mean train loss 3291.959133896531
INFO:root:current train perplexity3.663914203643799
INFO:root:current mean train loss 3291.85520815423
INFO:root:current train perplexity3.6638312339782715
INFO:root:current mean train loss 3292.54912156609
INFO:root:current train perplexity3.6650140285491943
INFO:root:current mean train loss 3291.7826766556263
INFO:root:current train perplexity3.662066698074341


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.85s/it]
INFO:root:final mean train loss: 3289.856999551096
INFO:root:final train perplexity: 3.661759376525879
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.14s/it]
INFO:root:eval mean loss: 4056.717233211436
INFO:root:eval perplexity: 5.157322883605957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/142

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [5:39:04<2:17:24, 142.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3343.8867257254465
INFO:root:current train perplexity3.654207468032837
INFO:root:current mean train loss 3308.2239185474536
INFO:root:current train perplexity3.639305591583252
INFO:root:current mean train loss 3297.0499948055185
INFO:root:current train perplexity3.6411471366882324
INFO:root:current mean train loss 3295.073686013293
INFO:root:current train perplexity3.6433045864105225
INFO:root:current mean train loss 3288.937931595726
INFO:root:current train perplexity3.6463449001312256
INFO:root:current mean train loss 3293.5987587616823
INFO:root:current train perplexity3.6512038707733154
INFO:root:current mean train loss 3289.7597079539864
INFO:root:current train perplexity3.6477243900299072
INFO:root:current mean train loss 3287.443358710672
INFO:root:current train perplexity3.6492066383361816
INFO:root:current mean train loss 3285.992431933009
INFO:root:current train perplexity3.65168833732605
INFO:root:current mean train loss 3286.6933301303475
INFO:root:current train perplexity3.6542911529541016


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.21s/it]
INFO:root:final mean train loss: 3285.560901518791
INFO:root:final train perplexity: 3.6555585861206055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.06s/it]
INFO:root:eval mean loss: 4058.254325271498
INFO:root:eval perplexity: 5.160528659820557
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/143

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [5:41:26<2:14:57, 142.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3279.6628701853197
INFO:root:current train perplexity3.631505250930786
INFO:root:current mean train loss 3272.843809754698
INFO:root:current train perplexity3.630871057510376
INFO:root:current mean train loss 3271.3853051456404
INFO:root:current train perplexity3.6339943408966064
INFO:root:current mean train loss 3276.395677216199
INFO:root:current train perplexity3.635331630706787
INFO:root:current mean train loss 3278.0739161919796
INFO:root:current train perplexity3.639505624771118
INFO:root:current mean train loss 3280.7091893991715
INFO:root:current train perplexity3.6436142921447754
INFO:root:current mean train loss 3283.0318104223365
INFO:root:current train perplexity3.645939826965332
INFO:root:current mean train loss 3280.5385982056487
INFO:root:current train perplexity3.6468377113342285
INFO:root:current mean train loss 3282.981292398799
INFO:root:current train perplexity3.649765968322754
INFO:root:current mean train loss 3284.5074616934817
INFO:root:current train perplexity3.653207540512085


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.62s/it]
INFO:root:final mean train loss: 3284.1086642972887
INFO:root:final train perplexity: 3.6534647941589355
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.48s/it]
INFO:root:eval mean loss: 4059.612162705009
INFO:root:eval perplexity: 5.163361549377441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/144

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [5:43:52<2:13:41, 143.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3282.249310661765
INFO:root:current train perplexity3.6235480308532715
INFO:root:current mean train loss 3276.9654662277526
INFO:root:current train perplexity3.637544631958008
INFO:root:current mean train loss 3276.9769904755976
INFO:root:current train perplexity3.635636329650879
INFO:root:current mean train loss 3272.126502403846
INFO:root:current train perplexity3.635324716567993
INFO:root:current mean train loss 3275.8600776486282
INFO:root:current train perplexity3.637197732925415
INFO:root:current mean train loss 3277.6921493059494
INFO:root:current train perplexity3.6420631408691406
INFO:root:current mean train loss 3282.0722825010803
INFO:root:current train perplexity3.645331859588623
INFO:root:current mean train loss 3284.1122533236935
INFO:root:current train perplexity3.6481382846832275
INFO:root:current mean train loss 3283.618226316925
INFO:root:current train perplexity3.6483476161956787
INFO:root:current mean train loss 3282.0766095824297
INFO:root:current train perplexity3.6482884883880615


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.07s/it]
INFO:root:final mean train loss: 3280.8407511557302
INFO:root:final train perplexity: 3.648757219314575
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.07s/it]
INFO:root:eval mean loss: 4060.5125966173537
INFO:root:eval perplexity: 5.165243148803711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/145

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [5:46:09<2:09:38, 141.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3280.963722358316
INFO:root:current train perplexity3.627723217010498
INFO:root:current mean train loss 3272.584726009729
INFO:root:current train perplexity3.6270945072174072
INFO:root:current mean train loss 3268.26940116735
INFO:root:current train perplexity3.6304268836975098
INFO:root:current mean train loss 3272.052171967488
INFO:root:current train perplexity3.637216329574585
INFO:root:current mean train loss 3274.692016335614
INFO:root:current train perplexity3.63826322555542
INFO:root:current mean train loss 3276.4690120471823
INFO:root:current train perplexity3.640601634979248
INFO:root:current mean train loss 3280.966418253272
INFO:root:current train perplexity3.642573833465576
INFO:root:current mean train loss 3280.873525828084
INFO:root:current train perplexity3.644562244415283
INFO:root:current mean train loss 3281.502202665709
INFO:root:current train perplexity3.645388603210449
INFO:root:current mean train loss 3280.8012051229307
INFO:root:current train perplexity3.645554304122925


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:06<00:00, 126.31s/it]
INFO:root:final mean train loss: 3278.9368566697644
INFO:root:final train perplexity: 3.646017074584961
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.46s/it]
INFO:root:eval mean loss: 4061.62392301086
INFO:root:eval perplexity: 5.167564868927002
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/146

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [5:49:00<2:15:08, 150.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3271.5093903043376
INFO:root:current train perplexity3.6319212913513184
INFO:root:current mean train loss 3283.676254912051
INFO:root:current train perplexity3.625859260559082
INFO:root:current mean train loss 3280.2493498727176
INFO:root:current train perplexity3.631988286972046
INFO:root:current mean train loss 3281.633900821696
INFO:root:current train perplexity3.6302998065948486
INFO:root:current mean train loss 3278.1781630587525
INFO:root:current train perplexity3.6315126419067383
INFO:root:current mean train loss 3275.3541537491733
INFO:root:current train perplexity3.6331818103790283
INFO:root:current mean train loss 3276.490273539988
INFO:root:current train perplexity3.6343705654144287
INFO:root:current mean train loss 3276.753871872963
INFO:root:current train perplexity3.6348981857299805
INFO:root:current mean train loss 3277.9639578602582
INFO:root:current train perplexity3.6386942863464355
INFO:root:current mean train loss 3278.747173573633
INFO:root:current train perplexity3.640695810317993


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.11s/it]
INFO:root:final mean train loss: 3275.554240380564
INFO:root:final train perplexity: 3.6411550045013428
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.14s/it]
INFO:root:eval mean loss: 4061.648858252992
INFO:root:eval perplexity: 5.167616844177246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/147

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [5:51:16<2:08:54, 145.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3250.4758984375
INFO:root:current train perplexity3.610377788543701
INFO:root:current mean train loss 3271.0243150111605
INFO:root:current train perplexity3.6344735622406006
INFO:root:current mean train loss 3275.956495028409
INFO:root:current train perplexity3.6392416954040527
INFO:root:current mean train loss 3270.7557884114585
INFO:root:current train perplexity3.634147882461548
INFO:root:current mean train loss 3269.7141627261512
INFO:root:current train perplexity3.6305599212646484
INFO:root:current mean train loss 3271.1310606317934
INFO:root:current train perplexity3.63070011138916
INFO:root:current mean train loss 3274.177111183449
INFO:root:current train perplexity3.6328916549682617
INFO:root:current mean train loss 3274.8814661038305
INFO:root:current train perplexity3.632563829421997
INFO:root:current mean train loss 3278.741666294643
INFO:root:current train perplexity3.637680768966675
INFO:root:current mean train loss 3277.2125858874197
INFO:root:current train perplexity3.638810634613037


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.50s/it]
INFO:root:final mean train loss: 3274.580844325404
INFO:root:final train perplexity: 3.6397571563720703
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.20s/it]
INFO:root:eval mean loss: 4062.0007116439497
INFO:root:eval perplexity: 5.168352127075195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/148

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [5:53:29<2:03:14, 142.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3276.1063541274475
INFO:root:current train perplexity3.6377358436584473
INFO:root:current mean train loss 3269.1972269360485
INFO:root:current train perplexity3.63549542427063
INFO:root:current mean train loss 3270.0743731711023
INFO:root:current train perplexity3.6318230628967285
INFO:root:current mean train loss 3272.4207830603377
INFO:root:current train perplexity3.631317377090454
INFO:root:current mean train loss 3272.61182348279
INFO:root:current train perplexity3.63038969039917
INFO:root:current mean train loss 3271.133806231909
INFO:root:current train perplexity3.6324901580810547
INFO:root:current mean train loss 3271.1663273243043
INFO:root:current train perplexity3.6318209171295166
INFO:root:current mean train loss 3271.1223453214798
INFO:root:current train perplexity3.631958484649658
INFO:root:current mean train loss 3272.1034420786737
INFO:root:current train perplexity3.63354229927063
INFO:root:current mean train loss 3274.1060042201807
INFO:root:current train perplexity3.6353137493133545


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.64s/it]
INFO:root:final mean train loss: 3271.8216411836684
INFO:root:final train perplexity: 3.635796546936035
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.25s/it]
INFO:root:eval mean loss: 4063.920654296875
INFO:root:eval perplexity: 5.172366142272949
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/149

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [5:56:20<2:08:08, 150.75s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3260.899711860405
INFO:root:current train perplexity3.6107017993927
INFO:root:current mean train loss 3256.8473775973494
INFO:root:current train perplexity3.610200881958008
INFO:root:current mean train loss 3260.7799705688894
INFO:root:current train perplexity3.6173717975616455
INFO:root:current mean train loss 3262.5682819493286
INFO:root:current train perplexity3.618227481842041
INFO:root:current mean train loss 3263.9358601307918
INFO:root:current train perplexity3.621300220489502
INFO:root:current mean train loss 3262.971188927665
INFO:root:current train perplexity3.6216607093811035
INFO:root:current mean train loss 3267.062408138115
INFO:root:current train perplexity3.624948740005493
INFO:root:current mean train loss 3267.2794836070834
INFO:root:current train perplexity3.6283719539642334
INFO:root:current mean train loss 3268.967955926452
INFO:root:current train perplexity3.6291375160217285
INFO:root:current mean train loss 3270.2912568093307
INFO:root:current train perplexity3.6299870014190674


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.08s/it]
INFO:root:final mean train loss: 3267.754114151001
INFO:root:final train perplexity: 3.629966974258423
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.41s/it]
INFO:root:eval mean loss: 4065.64449488863
INFO:root:eval perplexity: 5.1759724617004395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/150

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [5:58:45<2:04:18, 149.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3265.4173226404673
INFO:root:current train perplexity3.6406776905059814
INFO:root:current mean train loss 3266.4848227956186
INFO:root:current train perplexity3.6249732971191406
INFO:root:current mean train loss 3265.7699158327237
INFO:root:current train perplexity3.6236023902893066
INFO:root:current mean train loss 3263.457345145089
INFO:root:current train perplexity3.6214380264282227
INFO:root:current mean train loss 3264.8982745764965
INFO:root:current train perplexity3.621840000152588
INFO:root:current mean train loss 3266.5197961772224
INFO:root:current train perplexity3.6264774799346924
INFO:root:current mean train loss 3265.4828294745844
INFO:root:current train perplexity3.627863645553589
INFO:root:current mean train loss 3262.726796251662
INFO:root:current train perplexity3.6260037422180176
INFO:root:current mean train loss 3266.8025507942853
INFO:root:current train perplexity3.627274751663208


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.51s/it]
INFO:root:final mean train loss: 3266.949376813827
INFO:root:final train perplexity: 3.628814935684204
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.04s/it]
INFO:root:eval mean loss: 4066.027418204233
INFO:root:eval perplexity: 5.176774501800537
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/151

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [6:01:02<1:58:41, 145.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3254.651541573661
INFO:root:current train perplexity3.619553804397583
INFO:root:current mean train loss 3268.0334335754965
INFO:root:current train perplexity3.626652956008911
INFO:root:current mean train loss 3263.775039156854
INFO:root:current train perplexity3.62532639503479
INFO:root:current mean train loss 3261.578921041582
INFO:root:current train perplexity3.627906084060669
INFO:root:current mean train loss 3262.4025027113407
INFO:root:current train perplexity3.6274585723876953
INFO:root:current mean train loss 3263.5399056760048
INFO:root:current train perplexity3.623591184616089
INFO:root:current mean train loss 3263.181020017118
INFO:root:current train perplexity3.62392258644104
INFO:root:current mean train loss 3267.925125834291
INFO:root:current train perplexity3.624455213546753
INFO:root:current mean train loss 3268.6867796792712
INFO:root:current train perplexity3.6255252361297607
INFO:root:current mean train loss 3271.4543780039794
INFO:root:current train perplexity3.627870559692383


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.80s/it]
INFO:root:final mean train loss: 3265.622207518547
INFO:root:final train perplexity: 3.6269149780273438
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.09s/it]
INFO:root:eval mean loss: 4066.0306422456783
INFO:root:eval perplexity: 5.1767802238464355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/152

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [6:03:14<1:53:13, 141.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3285.1349283854165
INFO:root:current train perplexity3.626206874847412
INFO:root:current mean train loss 3260.4549189028535
INFO:root:current train perplexity3.613644599914551
INFO:root:current mean train loss 3260.0400799418603
INFO:root:current train perplexity3.616774320602417
INFO:root:current mean train loss 3254.6679268973216
INFO:root:current train perplexity3.613922357559204
INFO:root:current mean train loss 3259.6095603115587
INFO:root:current train perplexity3.615194320678711
INFO:root:current mean train loss 3262.291473566444
INFO:root:current train perplexity3.618842124938965
INFO:root:current mean train loss 3263.3711794969513
INFO:root:current train perplexity3.6162831783294678
INFO:root:current mean train loss 3266.0422267673734
INFO:root:current train perplexity3.620394706726074
INFO:root:current mean train loss 3264.7308944234087
INFO:root:current train perplexity3.6217808723449707
INFO:root:current mean train loss 3265.119034697319
INFO:root:current train perplexity3.62294340133667


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.26s/it]
INFO:root:final mean train loss: 3262.760364409416
INFO:root:final train perplexity: 3.6228222846984863
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.46s/it]
INFO:root:eval mean loss: 4066.386609665891
INFO:root:eval perplexity: 5.177525520324707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/153

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [6:05:27<1:48:45, 138.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3216.9048170006795
INFO:root:current train perplexity3.575751304626465
INFO:root:current mean train loss 3248.6089403105943
INFO:root:current train perplexity3.603248119354248
INFO:root:current mean train loss 3249.17590058331
INFO:root:current train perplexity3.5993130207061768
INFO:root:current mean train loss 3251.229573063806
INFO:root:current train perplexity3.6014363765716553
INFO:root:current mean train loss 3252.7499203512853
INFO:root:current train perplexity3.605602741241455
INFO:root:current mean train loss 3255.3469574383066
INFO:root:current train perplexity3.6070003509521484
INFO:root:current mean train loss 3255.560084065886
INFO:root:current train perplexity3.6104414463043213
INFO:root:current mean train loss 3259.0511054201243
INFO:root:current train perplexity3.6141304969787598
INFO:root:current mean train loss 3261.7099063544197
INFO:root:current train perplexity3.6149306297302246
INFO:root:current mean train loss 3262.1609503021737
INFO:root:current train perplexity3.6168041229248047


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.48s/it]
INFO:root:final mean train loss: 3259.655528591525
INFO:root:final train perplexity: 3.618387222290039
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.51s/it]
INFO:root:eval mean loss: 4066.9086896747563
INFO:root:eval perplexity: 5.178619384765625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/154

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [6:07:39<1:44:49, 136.72s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3283.9622999621974
INFO:root:current train perplexity3.6455469131469727
INFO:root:current mean train loss 3260.4719424648138
INFO:root:current train perplexity3.6240413188934326
INFO:root:current mean train loss 3256.1444340165044
INFO:root:current train perplexity3.6109812259674072
INFO:root:current mean train loss 3256.555106448263
INFO:root:current train perplexity3.6127591133117676
INFO:root:current mean train loss 3253.0170960747173
INFO:root:current train perplexity3.614837169647217
INFO:root:current mean train loss 3252.374819768126
INFO:root:current train perplexity3.614081859588623
INFO:root:current mean train loss 3256.7511820120594
INFO:root:current train perplexity3.617795467376709
INFO:root:current mean train loss 3259.76124215811
INFO:root:current train perplexity3.6205875873565674
INFO:root:current mean train loss 3262.247959618964
INFO:root:current train perplexity3.617894172668457
INFO:root:current mean train loss 3260.655746246895
INFO:root:current train perplexity3.617260694503784


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.40s/it]
INFO:root:final mean train loss: 3258.5227792801397
INFO:root:final train perplexity: 3.6167707443237305
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.09s/it]
INFO:root:eval mean loss: 4068.703604623781
INFO:root:eval perplexity: 5.182379722595215
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/155

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [6:09:51<1:41:32, 135.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3297.5780561398237
INFO:root:current train perplexity3.6178338527679443
INFO:root:current mean train loss 3254.3458770093303
INFO:root:current train perplexity3.5975863933563232
INFO:root:current mean train loss 3257.740327332309
INFO:root:current train perplexity3.605440616607666
INFO:root:current mean train loss 3255.74501204139
INFO:root:current train perplexity3.609807014465332
INFO:root:current mean train loss 3250.885251125605
INFO:root:current train perplexity3.6108787059783936
INFO:root:current mean train loss 3253.1460178354014
INFO:root:current train perplexity3.6096363067626953
INFO:root:current mean train loss 3253.1925849257873
INFO:root:current train perplexity3.6080238819122314
INFO:root:current mean train loss 3255.3006514160816
INFO:root:current train perplexity3.60847544670105
INFO:root:current mean train loss 3256.2224016337345
INFO:root:current train perplexity3.607811689376831
INFO:root:current mean train loss 3257.7050653849674
INFO:root:current train perplexity3.6119062900543213


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.17s/it]
INFO:root:final mean train loss: 3255.413470729705
INFO:root:final train perplexity: 3.6123366355895996
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.42s/it]
INFO:root:eval mean loss: 4069.1265115940823
INFO:root:eval perplexity: 5.183265209197998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/156

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [6:12:05<1:38:50, 134.79s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3241.9316614029253
INFO:root:current train perplexity3.5553605556488037
INFO:root:current mean train loss 3255.359076052296
INFO:root:current train perplexity3.587846040725708
INFO:root:current mean train loss 3246.8914829516702
INFO:root:current train perplexity3.590580463409424
INFO:root:current mean train loss 3249.134930965193
INFO:root:current train perplexity3.594400405883789
INFO:root:current mean train loss 3252.5670889698686
INFO:root:current train perplexity3.601013422012329
INFO:root:current mean train loss 3248.008863152708
INFO:root:current train perplexity3.6001172065734863
INFO:root:current mean train loss 3248.595042398208
INFO:root:current train perplexity3.602292776107788
INFO:root:current mean train loss 3251.5798973890355
INFO:root:current train perplexity3.604313850402832
INFO:root:current mean train loss 3254.960576621532
INFO:root:current train perplexity3.606645107269287
INFO:root:current mean train loss 3256.441370930818
INFO:root:current train perplexity3.6089181900024414


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.23s/it]
INFO:root:final mean train loss: 3253.639368241833
INFO:root:final train perplexity: 3.609808921813965
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.89s/it]
INFO:root:eval mean loss: 4069.595363752216
INFO:root:eval perplexity: 5.184248924255371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/157

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [6:14:16<1:35:59, 133.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3231.4511585582386
INFO:root:current train perplexity3.622856855392456
INFO:root:current mean train loss 3223.935813067036
INFO:root:current train perplexity3.595337390899658
INFO:root:current mean train loss 3238.5880447686886
INFO:root:current train perplexity3.6001720428466797
INFO:root:current mean train loss 3244.0411765514964
INFO:root:current train perplexity3.6038241386413574
INFO:root:current mean train loss 3245.4751684838598
INFO:root:current train perplexity3.603492021560669
INFO:root:current mean train loss 3249.0447058875284
INFO:root:current train perplexity3.603297472000122
INFO:root:current mean train loss 3252.7741401031726
INFO:root:current train perplexity3.6062324047088623
INFO:root:current mean train loss 3252.7235474441227
INFO:root:current train perplexity3.6056129932403564
INFO:root:current mean train loss 3254.5213938573647
INFO:root:current train perplexity3.607512950897217
INFO:root:current mean train loss 3253.48346132608
INFO:root:current train perplexity3.6056365966796875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.48s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.48s/it]
INFO:root:final mean train loss: 3250.9429843041203
INFO:root:final train perplexity: 3.605970621109009
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.22s/it]
INFO:root:eval mean loss: 4070.292470079787
INFO:root:eval perplexity: 5.185710430145264
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/158

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [6:16:29<1:33:27, 133.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3265.4792209201387
INFO:root:current train perplexity3.600736141204834
INFO:root:current mean train loss 3258.6753768452836
INFO:root:current train perplexity3.594943046569824
INFO:root:current mean train loss 3253.411960848384
INFO:root:current train perplexity3.593231439590454
INFO:root:current mean train loss 3246.0220143551996
INFO:root:current train perplexity3.5960676670074463
INFO:root:current mean train loss 3249.212086490112
INFO:root:current train perplexity3.6028459072113037
INFO:root:current mean train loss 3251.072171524617
INFO:root:current train perplexity3.6030666828155518
INFO:root:current mean train loss 3250.0025526135937
INFO:root:current train perplexity3.6061360836029053
INFO:root:current mean train loss 3253.863568587197
INFO:root:current train perplexity3.6056714057922363
INFO:root:current mean train loss 3252.118941182195
INFO:root:current train perplexity3.6046864986419678
INFO:root:current mean train loss 3252.1268801109813
INFO:root:current train perplexity3.6038858890533447


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.66s/it]
INFO:root:final mean train loss: 3249.7478845657843
INFO:root:final train perplexity: 3.604271411895752
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.14s/it]
INFO:root:eval mean loss: 4070.505365899269
INFO:root:eval perplexity: 5.186156749725342
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/159

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [6:19:16<1:38:06, 143.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3252.646209286972
INFO:root:current train perplexity3.6066322326660156
INFO:root:current mean train loss 3241.056632058662
INFO:root:current train perplexity3.588792562484741
INFO:root:current mean train loss 3242.0814781048202
INFO:root:current train perplexity3.589444160461426
INFO:root:current mean train loss 3238.6736761129127
INFO:root:current train perplexity3.5945394039154053
INFO:root:current mean train loss 3243.084463326035
INFO:root:current train perplexity3.596102476119995
INFO:root:current mean train loss 3242.6006791470554
INFO:root:current train perplexity3.5970816612243652
INFO:root:current mean train loss 3244.8315753510387
INFO:root:current train perplexity3.5951993465423584
INFO:root:current mean train loss 3246.954466348492
INFO:root:current train perplexity3.5964179039001465
INFO:root:current mean train loss 3248.1516430019374
INFO:root:current train perplexity3.599802255630493
INFO:root:current mean train loss 3248.304063445385
INFO:root:current train perplexity3.599623203277588


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.24s/it]
INFO:root:final mean train loss: 3246.592064519082
INFO:root:final train perplexity: 3.5997862815856934
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.47s/it]
INFO:root:eval mean loss: 4071.6623916084886
INFO:root:eval perplexity: 5.188582897186279
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/160

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [6:22:14<1:42:33, 153.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3242.8311226760284
INFO:root:current train perplexity3.583395004272461
INFO:root:current mean train loss 3238.2951987495635
INFO:root:current train perplexity3.5966739654541016
INFO:root:current mean train loss 3244.7137884324598
INFO:root:current train perplexity3.599592685699463
INFO:root:current mean train loss 3250.385548292175
INFO:root:current train perplexity3.598017454147339
INFO:root:current mean train loss 3248.0209043498826
INFO:root:current train perplexity3.596311569213867
INFO:root:current mean train loss 3249.5150865413157
INFO:root:current train perplexity3.5964295864105225
INFO:root:current mean train loss 3245.9676914580264
INFO:root:current train perplexity3.5976624488830566
INFO:root:current mean train loss 3247.261653248857
INFO:root:current train perplexity3.598208427429199
INFO:root:current mean train loss 3245.858940324143
INFO:root:current train perplexity3.5986759662628174
INFO:root:current mean train loss 3247.6353890688843
INFO:root:current train perplexity3.59883713722229


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.42s/it]
INFO:root:final mean train loss: 3245.623866973385
INFO:root:final train perplexity: 3.5984113216400146
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.58s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.58s/it]
INFO:root:eval mean loss: 4072.9673301750886
INFO:root:eval perplexity: 5.191321849822998
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/161

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [6:24:47<1:39:51, 153.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3234.669237158764
INFO:root:current train perplexity3.567779541015625
INFO:root:current mean train loss 3231.21008235503
INFO:root:current train perplexity3.5715742111206055
INFO:root:current mean train loss 3237.191476004464
INFO:root:current train perplexity3.5751771926879883
INFO:root:current mean train loss 3243.659666076187
INFO:root:current train perplexity3.5854618549346924
INFO:root:current mean train loss 3241.297572831109
INFO:root:current train perplexity3.5859944820404053
INFO:root:current mean train loss 3242.1473769231793
INFO:root:current train perplexity3.585136651992798
INFO:root:current mean train loss 3241.1227725277477
INFO:root:current train perplexity3.585695743560791
INFO:root:current mean train loss 3242.457372178268
INFO:root:current train perplexity3.588216781616211
INFO:root:current mean train loss 3242.895882418352
INFO:root:current train perplexity3.590487480163574
INFO:root:current mean train loss 3245.4348174214
INFO:root:current train perplexity3.5946567058563232


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.87s/it]
INFO:root:final mean train loss: 3242.614722590293
INFO:root:final train perplexity: 3.594142198562622
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.00s/it]
INFO:root:eval mean loss: 4073.1881787455673
INFO:root:eval perplexity: 5.191786289215088
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/162

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [6:27:00<1:33:19, 147.35s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3238.804322574013
INFO:root:current train perplexity3.592127799987793
INFO:root:current mean train loss 3247.340905448718
INFO:root:current train perplexity3.5996956825256348
INFO:root:current mean train loss 3244.0957486427437
INFO:root:current train perplexity3.5907084941864014
INFO:root:current mean train loss 3247.833027590981
INFO:root:current train perplexity3.588820695877075
INFO:root:current mean train loss 3250.203255701547
INFO:root:current train perplexity3.593064308166504
INFO:root:current mean train loss 3248.409931394433
INFO:root:current train perplexity3.591442584991455
INFO:root:current mean train loss 3247.1099258093527
INFO:root:current train perplexity3.589789867401123
INFO:root:current mean train loss 3244.983120516411
INFO:root:current train perplexity3.5909717082977295
INFO:root:current mean train loss 3245.3224833056915
INFO:root:current train perplexity3.592344284057617


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.20s/it]
INFO:root:final mean train loss: 3241.5400209119243
INFO:root:final train perplexity: 3.592617988586426
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.19s/it]
INFO:root:eval mean loss: 4073.574933856937
INFO:root:eval perplexity: 5.19259786605835
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/163

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [6:29:16<1:28:49, 144.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3248.6537272135415
INFO:root:current train perplexity3.5810258388519287
INFO:root:current mean train loss 3212.9313633002125
INFO:root:current train perplexity3.5850703716278076
INFO:root:current mean train loss 3237.24344789101
INFO:root:current train perplexity3.598017454147339
INFO:root:current mean train loss 3234.2843384191933
INFO:root:current train perplexity3.5929932594299316
INFO:root:current mean train loss 3234.2779447115386
INFO:root:current train perplexity3.595050096511841
INFO:root:current mean train loss 3236.775020773795
INFO:root:current train perplexity3.5944745540618896
INFO:root:current mean train loss 3239.315376243781
INFO:root:current train perplexity3.5921974182128906
INFO:root:current mean train loss 3238.6350896409363
INFO:root:current train perplexity3.589043617248535
INFO:root:current mean train loss 3238.962344272941
INFO:root:current train perplexity3.5896761417388916
INFO:root:current mean train loss 3243.300184011195
INFO:root:current train perplexity3.5915281772613525


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.80s/it]
INFO:root:final mean train loss: 3240.7788615072927
INFO:root:final train perplexity: 3.5915398597717285
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.50s/it]
INFO:root:eval mean loss: 4074.665830355164
INFO:root:eval perplexity: 5.194889068603516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/164

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [6:31:29<1:24:24, 140.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3256.1291725852275
INFO:root:current train perplexity3.575796365737915
INFO:root:current mean train loss 3239.7715965477196
INFO:root:current train perplexity3.5724024772644043
INFO:root:current mean train loss 3241.989645429132
INFO:root:current train perplexity3.5790460109710693
INFO:root:current mean train loss 3242.249997644946
INFO:root:current train perplexity3.587003469467163
INFO:root:current mean train loss 3246.588079522126
INFO:root:current train perplexity3.592808246612549
INFO:root:current mean train loss 3243.125300517521
INFO:root:current train perplexity3.592952013015747
INFO:root:current mean train loss 3240.313266385792
INFO:root:current train perplexity3.5893406867980957
INFO:root:current mean train loss 3238.7407590541493
INFO:root:current train perplexity3.5875930786132812
INFO:root:current mean train loss 3240.1035445245066
INFO:root:current train perplexity3.5874404907226562
INFO:root:current mean train loss 3240.0122129270717
INFO:root:current train perplexity3.5870821475982666


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.11s/it]
INFO:root:final mean train loss: 3237.0021258938696
INFO:root:final train perplexity: 3.5861923694610596
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.34s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.34s/it]
INFO:root:eval mean loss: 4075.5691454731827
INFO:root:eval perplexity: 5.196786880493164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/165

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [6:33:41<1:20:35, 138.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3249.5607396175988
INFO:root:current train perplexity3.5919392108917236
INFO:root:current mean train loss 3233.7636062237393
INFO:root:current train perplexity3.5791540145874023
INFO:root:current mean train loss 3241.3726767622716
INFO:root:current train perplexity3.591324806213379
INFO:root:current mean train loss 3241.0786040972766
INFO:root:current train perplexity3.5865626335144043
INFO:root:current mean train loss 3238.4353301200777
INFO:root:current train perplexity3.5867066383361816
INFO:root:current mean train loss 3236.707976765715
INFO:root:current train perplexity3.5865976810455322
INFO:root:current mean train loss 3238.7394546237633
INFO:root:current train perplexity3.5864980220794678
INFO:root:current mean train loss 3241.3778919968054
INFO:root:current train perplexity3.587106466293335
INFO:root:current mean train loss 3241.643289680155
INFO:root:current train perplexity3.588895320892334
INFO:root:current mean train loss 3240.2787081746465
INFO:root:current train perplexity3.586541175842285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.92s/it]
INFO:root:final mean train loss: 3236.955462117349
INFO:root:final train perplexity: 3.5861265659332275
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.02s/it]
INFO:root:eval mean loss: 4075.826952778701
INFO:root:eval perplexity: 5.197329044342041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/166

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [6:35:54<1:17:22, 136.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3231.538664641204
INFO:root:current train perplexity3.59018874168396
INFO:root:current mean train loss 3232.5242314376233
INFO:root:current train perplexity3.5720255374908447
INFO:root:current mean train loss 3237.695315726528
INFO:root:current train perplexity3.5813536643981934
INFO:root:current mean train loss 3233.1082394101204
INFO:root:current train perplexity3.5786471366882324
INFO:root:current mean train loss 3233.974281757721
INFO:root:current train perplexity3.5755176544189453
INFO:root:current mean train loss 3237.6674818585448
INFO:root:current train perplexity3.576145887374878
INFO:root:current mean train loss 3238.681347422623
INFO:root:current train perplexity3.579561948776245
INFO:root:current mean train loss 3239.4129804902423
INFO:root:current train perplexity3.580981969833374
INFO:root:current mean train loss 3236.766354174539
INFO:root:current train perplexity3.5817532539367676
INFO:root:current mean train loss 3237.3323917985604
INFO:root:current train perplexity3.5829124450683594


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.99s/it]
INFO:root:final mean train loss: 3234.9070405652446
INFO:root:final train perplexity: 3.5832293033599854
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.52s/it]
INFO:root:eval mean loss: 4076.005842060062
INFO:root:eval perplexity: 5.197704315185547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/167

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [6:38:10<1:15:03, 136.47s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3264.3156389508927
INFO:root:current train perplexity3.57608962059021
INFO:root:current mean train loss 3235.460129123264
INFO:root:current train perplexity3.580448627471924
INFO:root:current mean train loss 3223.898828125
INFO:root:current train perplexity3.5720276832580566
INFO:root:current mean train loss 3229.84141718167
INFO:root:current train perplexity3.572906732559204
INFO:root:current mean train loss 3232.2293361619973
INFO:root:current train perplexity3.5751664638519287
INFO:root:current mean train loss 3236.285671911507
INFO:root:current train perplexity3.577122449874878
INFO:root:current mean train loss 3235.478707861713
INFO:root:current train perplexity3.5788750648498535
INFO:root:current mean train loss 3236.30620482568
INFO:root:current train perplexity3.5777432918548584
INFO:root:current mean train loss 3236.758329727264
INFO:root:current train perplexity3.5786421298980713
INFO:root:current mean train loss 3236.307096267129
INFO:root:current train perplexity3.5804035663604736


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.61s/it]
INFO:root:final mean train loss: 3233.605000465147
INFO:root:final train perplexity: 3.5813891887664795
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.32s/it]
INFO:root:eval mean loss: 4075.556135028812
INFO:root:eval perplexity: 5.1967597007751465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/168

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [6:40:57<1:17:43, 145.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3235.5170387445496
INFO:root:current train perplexity3.5507760047912598
INFO:root:current mean train loss 3246.6137814821896
INFO:root:current train perplexity3.5815610885620117
INFO:root:current mean train loss 3231.511861416538
INFO:root:current train perplexity3.5774805545806885
INFO:root:current mean train loss 3226.930535230275
INFO:root:current train perplexity3.5717155933380127
INFO:root:current mean train loss 3228.560643869921
INFO:root:current train perplexity3.573146104812622
INFO:root:current mean train loss 3227.1809055054387
INFO:root:current train perplexity3.569629430770874
INFO:root:current mean train loss 3231.552945102911
INFO:root:current train perplexity3.570431709289551
INFO:root:current mean train loss 3233.112067447216
INFO:root:current train perplexity3.5751826763153076
INFO:root:current mean train loss 3234.9086027858098
INFO:root:current train perplexity3.5768840312957764
INFO:root:current mean train loss 3233.406859963216
INFO:root:current train perplexity3.5767569541931152


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.26s/it]
INFO:root:final mean train loss: 3230.0050558890066
INFO:root:final train perplexity: 3.5763063430786133
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.59s/it]
INFO:root:eval mean loss: 4077.8504560754654
INFO:root:eval perplexity: 5.201582431793213
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/169

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [6:43:10<1:13:16, 141.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3234.2024787454043
INFO:root:current train perplexity3.556452512741089
INFO:root:current mean train loss 3223.1840060404593
INFO:root:current train perplexity3.559932231903076
INFO:root:current mean train loss 3226.5815312966884
INFO:root:current train perplexity3.5722568035125732
INFO:root:current mean train loss 3226.4622924456908
INFO:root:current train perplexity3.5711097717285156
INFO:root:current mean train loss 3221.3768313253536
INFO:root:current train perplexity3.5667521953582764
INFO:root:current mean train loss 3222.0472511803823
INFO:root:current train perplexity3.5683517456054688
INFO:root:current mean train loss 3225.5662869923676
INFO:root:current train perplexity3.5699498653411865
INFO:root:current mean train loss 3228.5344124500666
INFO:root:current train perplexity3.573098659515381
INFO:root:current mean train loss 3229.875487994363
INFO:root:current train perplexity3.572352886199951
INFO:root:current mean train loss 3231.0491479979955
INFO:root:current train perplexity3.5741078853607178


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.24s/it]
INFO:root:final mean train loss: 3229.6714517531855
INFO:root:final train perplexity: 3.575835704803467
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.15s/it]
INFO:root:eval mean loss: 4078.9850260416665
INFO:root:eval perplexity: 5.203969955444336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/170

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [6:45:32<1:10:56, 141.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3217.7722499006886
INFO:root:current train perplexity3.5666446685791016
INFO:root:current mean train loss 3211.8908338246856
INFO:root:current train perplexity3.5525286197662354
INFO:root:current mean train loss 3211.5212015866314
INFO:root:current train perplexity3.5608112812042236
INFO:root:current mean train loss 3220.9727344566068
INFO:root:current train perplexity3.5703485012054443
INFO:root:current mean train loss 3221.2804170496324
INFO:root:current train perplexity3.5694777965545654
INFO:root:current mean train loss 3223.658496181099
INFO:root:current train perplexity3.5722720623016357
INFO:root:current mean train loss 3227.504353408929
INFO:root:current train perplexity3.5743064880371094
INFO:root:current mean train loss 3229.8141877547555
INFO:root:current train perplexity3.5751659870147705
INFO:root:current mean train loss 3230.28438432225
INFO:root:current train perplexity3.5752921104431152
INFO:root:current mean train loss 3230.3491847383343
INFO:root:current train perplexity3.5745396614074707


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.06s/it]
INFO:root:final mean train loss: 3228.7289853249827
INFO:root:final train perplexity: 3.5745058059692383
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.77s/it]
INFO:root:eval mean loss: 4077.716727615248
INFO:root:eval perplexity: 5.2013020515441895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/171

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [6:48:05<1:10:10, 145.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3254.425343983209
INFO:root:current train perplexity3.5627543926239014
INFO:root:current mean train loss 3243.119191792197
INFO:root:current train perplexity3.5784757137298584
INFO:root:current mean train loss 3235.112179416842
INFO:root:current train perplexity3.5825767517089844
INFO:root:current mean train loss 3235.329958383004
INFO:root:current train perplexity3.5840401649475098
INFO:root:current mean train loss 3225.7452923204964
INFO:root:current train perplexity3.5760791301727295
INFO:root:current mean train loss 3223.7256147865687
INFO:root:current train perplexity3.5713582038879395
INFO:root:current mean train loss 3223.6176545516305
INFO:root:current train perplexity3.5710182189941406
INFO:root:current mean train loss 3226.3376455294574
INFO:root:current train perplexity3.572014093399048
INFO:root:current mean train loss 3229.3206774437717
INFO:root:current train perplexity3.5726451873779297
INFO:root:current mean train loss 3229.5442414624
INFO:root:current train perplexity3.572709798812866


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.90s/it]
INFO:root:final mean train loss: 3227.2584133148193
INFO:root:final train perplexity: 3.572432518005371
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.20s/it]
INFO:root:eval mean loss: 4079.102331283245
INFO:root:eval perplexity: 5.204216957092285
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/172

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [6:50:18<1:06:02, 141.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3218.7598209635416
INFO:root:current train perplexity3.5773961544036865
INFO:root:current mean train loss 3219.955968191964
INFO:root:current train perplexity3.567142963409424
INFO:root:current mean train loss 3229.6178125
INFO:root:current train perplexity3.570571184158325
INFO:root:current mean train loss 3225.4010625
INFO:root:current train perplexity3.567011594772339
INFO:root:current mean train loss 3225.3195045230264
INFO:root:current train perplexity3.5669891834259033
INFO:root:current mean train loss 3226.316142578125
INFO:root:current train perplexity3.5665316581726074
INFO:root:current mean train loss 3224.097250434028
INFO:root:current train perplexity3.5669145584106445
INFO:root:current mean train loss 3225.8481700478833
INFO:root:current train perplexity3.5679450035095215
INFO:root:current mean train loss 3227.9100390625
INFO:root:current train perplexity3.5686988830566406
INFO:root:current mean train loss 3227.125009765625
INFO:root:current train perplexity3.56801176071167


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.22s/it]
INFO:root:final mean train loss: 3224.1919662721693
INFO:root:final train perplexity: 3.5681135654449463
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.31s/it]
INFO:root:eval mean loss: 4079.7139485677085
INFO:root:eval perplexity: 5.205504417419434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/173

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [6:52:31<1:02:34, 139.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3227.023390436747
INFO:root:current train perplexity3.5865840911865234
INFO:root:current mean train loss 3230.09580051443
INFO:root:current train perplexity3.5676026344299316
INFO:root:current mean train loss 3226.799455298973
INFO:root:current train perplexity3.5686652660369873
INFO:root:current mean train loss 3227.2123143766316
INFO:root:current train perplexity3.5637691020965576
INFO:root:current mean train loss 3234.3180909719526
INFO:root:current train perplexity3.5683088302612305
INFO:root:current mean train loss 3228.5456991048454
INFO:root:current train perplexity3.5671846866607666
INFO:root:current mean train loss 3226.9925392340774
INFO:root:current train perplexity3.5665643215179443
INFO:root:current mean train loss 3227.990796241419
INFO:root:current train perplexity3.567802667617798
INFO:root:current mean train loss 3229.3840235259768
INFO:root:current train perplexity3.5696170330047607
INFO:root:current mean train loss 3227.2435199663814
INFO:root:current train perplexity3.5687801837921143


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.71s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.71s/it]
INFO:root:final mean train loss: 3224.83651696482
INFO:root:final train perplexity: 3.569020986557007
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.36s/it]
INFO:root:eval mean loss: 4081.185654227615
INFO:root:eval perplexity: 5.208601951599121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/174

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [6:54:43<59:19, 136.90s/it]  

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3208.217094672905
INFO:root:current train perplexity3.5595176219940186
INFO:root:current mean train loss 3207.5498391995256
INFO:root:current train perplexity3.5514190196990967
INFO:root:current mean train loss 3217.058372261598
INFO:root:current train perplexity3.5583887100219727
INFO:root:current mean train loss 3222.0492346097744
INFO:root:current train perplexity3.5619163513183594
INFO:root:current mean train loss 3218.367378934095
INFO:root:current train perplexity3.5571444034576416
INFO:root:current mean train loss 3219.5510452193053
INFO:root:current train perplexity3.556892156600952
INFO:root:current mean train loss 3222.3745986342255
INFO:root:current train perplexity3.560183048248291
INFO:root:current mean train loss 3222.5753305003554
INFO:root:current train perplexity3.5609776973724365
INFO:root:current mean train loss 3225.3007596034126
INFO:root:current train perplexity3.564422130584717
INFO:root:current mean train loss 3225.9103525972027
INFO:root:current train perplexity3.5669963359832764


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.66s/it]
INFO:root:final mean train loss: 3223.381846889373
INFO:root:final train perplexity: 3.5669734477996826
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.13s/it]
INFO:root:eval mean loss: 4081.5383058372117
INFO:root:eval perplexity: 5.20934534072876
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/175

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [6:56:55<56:22, 135.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3216.6994135692867
INFO:root:current train perplexity3.565089702606201
INFO:root:current mean train loss 3217.6358145709014
INFO:root:current train perplexity3.557508707046509
INFO:root:current mean train loss 3219.5573501842077
INFO:root:current train perplexity3.559762477874756
INFO:root:current mean train loss 3220.3667561237075
INFO:root:current train perplexity3.5602095127105713
INFO:root:current mean train loss 3221.5793726124125
INFO:root:current train perplexity3.561598062515259
INFO:root:current mean train loss 3223.063614732236
INFO:root:current train perplexity3.5651376247406006
INFO:root:current mean train loss 3223.641599117601
INFO:root:current train perplexity3.5630338191986084
INFO:root:current mean train loss 3221.81000206557
INFO:root:current train perplexity3.5618271827697754
INFO:root:current mean train loss 3222.1980580636473
INFO:root:current train perplexity3.56260085105896


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.21s/it]
INFO:root:final mean train loss: 3221.692370076333
INFO:root:final train perplexity: 3.564596652984619
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.16s/it]
INFO:root:eval mean loss: 4081.5032534768397
INFO:root:eval perplexity: 5.2092719078063965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/176

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [6:59:10<54:06, 135.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3181.5006975446427
INFO:root:current train perplexity3.440687417984009
INFO:root:current mean train loss 3228.458308995327
INFO:root:current train perplexity3.55147385597229
INFO:root:current mean train loss 3221.9305319670893
INFO:root:current train perplexity3.549654245376587
INFO:root:current mean train loss 3219.272859355914
INFO:root:current train perplexity3.5522449016571045
INFO:root:current mean train loss 3220.900321641777
INFO:root:current train perplexity3.551251173019409
INFO:root:current mean train loss 3218.8236341608113
INFO:root:current train perplexity3.5526556968688965
INFO:root:current mean train loss 3217.6708907955363
INFO:root:current train perplexity3.5544676780700684
INFO:root:current mean train loss 3219.7443540322224
INFO:root:current train perplexity3.559255838394165
INFO:root:current mean train loss 3221.0430685844563
INFO:root:current train perplexity3.5607340335845947
INFO:root:current mean train loss 3224.187659620056
INFO:root:current train perplexity3.5651609897613525


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.12s/it]
INFO:root:final mean train loss: 3220.844665096652
INFO:root:final train perplexity: 3.563404083251953
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.95s/it]
INFO:root:eval mean loss: 4082.306656208444
INFO:root:eval perplexity: 5.210965156555176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/177

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [7:01:57<55:30, 144.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3224.4123372395834
INFO:root:current train perplexity3.5233240127563477
INFO:root:current mean train loss 3213.0451511548913
INFO:root:current train perplexity3.5347557067871094
INFO:root:current mean train loss 3215.847797056686
INFO:root:current train perplexity3.5581071376800537
INFO:root:current mean train loss 3213.438344029018
INFO:root:current train perplexity3.558856725692749
INFO:root:current mean train loss 3216.6118169945407
INFO:root:current train perplexity3.5563361644744873
INFO:root:current mean train loss 3216.418636699788
INFO:root:current train perplexity3.55495285987854
INFO:root:current mean train loss 3220.3509856929622
INFO:root:current train perplexity3.5575311183929443
INFO:root:current mean train loss 3222.445195380791
INFO:root:current train perplexity3.559483051300049
INFO:root:current mean train loss 3222.4397709571513
INFO:root:current train perplexity3.559450626373291
INFO:root:current mean train loss 3220.693836182975
INFO:root:current train perplexity3.5600736141204834


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.01s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.02s/it]
INFO:root:final mean train loss: 3218.953044768303
INFO:root:final train perplexity: 3.560746431350708
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.45s/it]
INFO:root:eval mean loss: 4082.2347749750666
INFO:root:eval perplexity: 5.210813522338867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/178

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [7:04:22<53:09, 144.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3235.7043244735055
INFO:root:current train perplexity3.5546438694000244
INFO:root:current mean train loss 3228.1475304084097
INFO:root:current train perplexity3.5467259883880615
INFO:root:current mean train loss 3222.1671695452633
INFO:root:current train perplexity3.5426695346832275
INFO:root:current mean train loss 3225.0700940583883
INFO:root:current train perplexity3.549499988555908
INFO:root:current mean train loss 3228.912038960919
INFO:root:current train perplexity3.5553321838378906
INFO:root:current mean train loss 3224.314583831262
INFO:root:current train perplexity3.5569183826446533
INFO:root:current mean train loss 3223.269168761913
INFO:root:current train perplexity3.5568127632141113
INFO:root:current mean train loss 3220.4062432464557
INFO:root:current train perplexity3.55790638923645
INFO:root:current mean train loss 3219.047553728736
INFO:root:current train perplexity3.556748390197754
INFO:root:current mean train loss 3219.453178430559
INFO:root:current train perplexity3.559598684310913


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.33s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.33s/it]
INFO:root:final mean train loss: 3218.2932331331313
INFO:root:final train perplexity: 3.559818983078003
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.47s/it]
INFO:root:eval mean loss: 4082.0567445146276
INFO:root:eval perplexity: 5.210438251495361
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/179

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [7:06:36<49:32, 141.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3199.5365974672377
INFO:root:current train perplexity3.5529377460479736
INFO:root:current mean train loss 3210.989555999523
INFO:root:current train perplexity3.5529873371124268
INFO:root:current mean train loss 3210.443586605452
INFO:root:current train perplexity3.560526132583618
INFO:root:current mean train loss 3210.59960494949
INFO:root:current train perplexity3.5592503547668457
INFO:root:current mean train loss 3213.2010874737166
INFO:root:current train perplexity3.557982921600342
INFO:root:current mean train loss 3214.8890944083983
INFO:root:current train perplexity3.554927349090576
INFO:root:current mean train loss 3216.6508197089192
INFO:root:current train perplexity3.5575637817382812
INFO:root:current mean train loss 3218.697021818357
INFO:root:current train perplexity3.5588953495025635
INFO:root:current mean train loss 3219.3447850269818
INFO:root:current train perplexity3.557786464691162
INFO:root:current mean train loss 3217.689312567132
INFO:root:current train perplexity3.5560073852539062


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.10s/it]
INFO:root:final mean train loss: 3217.031720253729
INFO:root:final train perplexity: 3.5580482482910156
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.44s/it]
INFO:root:eval mean loss: 4082.012837294991
INFO:root:eval perplexity: 5.21034574508667
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/180

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [7:09:18<49:17, 147.85s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3226.524689503205
INFO:root:current train perplexity3.5767931938171387
INFO:root:current mean train loss 3210.904913373988
INFO:root:current train perplexity3.5558907985687256
INFO:root:current mean train loss 3210.903667625523
INFO:root:current train perplexity3.5548903942108154
INFO:root:current mean train loss 3215.4886874308627
INFO:root:current train perplexity3.5525875091552734
INFO:root:current mean train loss 3215.483603092967
INFO:root:current train perplexity3.5552451610565186
INFO:root:current mean train loss 3215.190557419701
INFO:root:current train perplexity3.5539443492889404
INFO:root:current mean train loss 3214.150932013522
INFO:root:current train perplexity3.5523855686187744
INFO:root:current mean train loss 3216.8992875322438
INFO:root:current train perplexity3.554288864135742
INFO:root:current mean train loss 3218.7031794151335
INFO:root:current train perplexity3.5573089122772217
INFO:root:current mean train loss 3218.74858195637
INFO:root:current train perplexity3.5563833713531494


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.03s/it]
INFO:root:final mean train loss: 3216.294644263483
INFO:root:final train perplexity: 3.5570132732391357
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.22s/it]
INFO:root:eval mean loss: 4083.6399272080007
INFO:root:eval perplexity: 5.213774681091309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/181

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [7:11:47<46:55, 148.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3222.1290620844416
INFO:root:current train perplexity3.5343027114868164
INFO:root:current mean train loss 3214.5443555351826
INFO:root:current train perplexity3.558122396469116
INFO:root:current mean train loss 3217.1117768693066
INFO:root:current train perplexity3.5545802116394043
INFO:root:current mean train loss 3224.617473151567
INFO:root:current train perplexity3.5610015392303467
INFO:root:current mean train loss 3219.5674521768387
INFO:root:current train perplexity3.5551071166992188
INFO:root:current mean train loss 3216.8253899108777
INFO:root:current train perplexity3.554656982421875
INFO:root:current mean train loss 3219.2664826995992
INFO:root:current train perplexity3.555100679397583
INFO:root:current mean train loss 3217.599799915809
INFO:root:current train perplexity3.55474591255188
INFO:root:current mean train loss 3217.4818226207385
INFO:root:current train perplexity3.5546560287475586
INFO:root:current mean train loss 3217.463990160127
INFO:root:current train perplexity3.554875135421753


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.60s/it]
INFO:root:final mean train loss: 3214.2119666684057
INFO:root:final train perplexity: 3.5540921688079834
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.90s/it]
INFO:root:eval mean loss: 4083.7785177027927
INFO:root:eval perplexity: 5.214066505432129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/182

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [7:14:01<43:07, 143.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3211.59267578125
INFO:root:current train perplexity3.5720736980438232
INFO:root:current mean train loss 3205.510578377016
INFO:root:current train perplexity3.5613811016082764
INFO:root:current mean train loss 3204.3534457337623
INFO:root:current train perplexity3.546816110610962
INFO:root:current mean train loss 3210.6249456701144
INFO:root:current train perplexity3.5484278202056885
INFO:root:current mean train loss 3212.8192146720467
INFO:root:current train perplexity3.546914577484131
INFO:root:current mean train loss 3211.2131717166385
INFO:root:current train perplexity3.5504934787750244
INFO:root:current mean train loss 3212.7335848043895
INFO:root:current train perplexity3.549071788787842
INFO:root:current mean train loss 3214.161674448986
INFO:root:current train perplexity3.552156448364258
INFO:root:current mean train loss 3215.7803279765167
INFO:root:current train perplexity3.552525281906128
INFO:root:current mean train loss 3216.6463384019144
INFO:root:current train perplexity3.552896738052368


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.94s/it]
INFO:root:final mean train loss: 3213.0646530889694
INFO:root:final train perplexity: 3.552483320236206
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.21s/it]
INFO:root:eval mean loss: 4084.0043321974736
INFO:root:eval perplexity: 5.214542865753174
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/183

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [7:16:13<39:43, 140.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3203.2974291604664
INFO:root:current train perplexity3.556554079055786
INFO:root:current mean train loss 3222.108158790261
INFO:root:current train perplexity3.553514242172241
INFO:root:current mean train loss 3215.401441450808
INFO:root:current train perplexity3.5529942512512207
INFO:root:current mean train loss 3215.9715263429753
INFO:root:current train perplexity3.5557634830474854
INFO:root:current mean train loss 3215.4557673081467
INFO:root:current train perplexity3.5545742511749268
INFO:root:current mean train loss 3213.9140330123223
INFO:root:current train perplexity3.553492307662964
INFO:root:current mean train loss 3215.7268975949755
INFO:root:current train perplexity3.553516387939453
INFO:root:current mean train loss 3216.8454148278793
INFO:root:current train perplexity3.5520801544189453
INFO:root:current mean train loss 3214.055562785161
INFO:root:current train perplexity3.551231861114502
INFO:root:current mean train loss 3214.2460230176694
INFO:root:current train perplexity3.5521814823150635


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.60s/it]
INFO:root:final mean train loss: 3213.043377045662
INFO:root:final train perplexity: 3.5524537563323975
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.65s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.65s/it]
INFO:root:eval mean loss: 4083.9443809563386
INFO:root:eval perplexity: 5.21441650390625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/184

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [7:19:00<39:33, 148.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3214.7141182053256
INFO:root:current train perplexity3.5469882488250732
INFO:root:current mean train loss 3218.1344857913014
INFO:root:current train perplexity3.5429439544677734
INFO:root:current mean train loss 3215.0977580503345
INFO:root:current train perplexity3.541363000869751
INFO:root:current mean train loss 3212.4731873052137
INFO:root:current train perplexity3.5412111282348633
INFO:root:current mean train loss 3212.0627892366642
INFO:root:current train perplexity3.5418405532836914
INFO:root:current mean train loss 3212.4764299543017
INFO:root:current train perplexity3.543548822402954
INFO:root:current mean train loss 3212.62101042928
INFO:root:current train perplexity3.546015501022339
INFO:root:current mean train loss 3210.9428837599303
INFO:root:current train perplexity3.546146869659424
INFO:root:current mean train loss 3214.572901904241
INFO:root:current train perplexity3.547654628753662
INFO:root:current mean train loss 3213.3163748209804
INFO:root:current train perplexity3.548489570617676


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.24s/it]
INFO:root:final mean train loss: 3209.9355254634734
INFO:root:final train perplexity: 3.548100471496582
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.28s/it]
INFO:root:eval mean loss: 4084.7015943594856
INFO:root:eval perplexity: 5.216013431549072
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/185

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [7:21:17<36:11, 144.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3201.387874554984
INFO:root:current train perplexity3.53196382522583
INFO:root:current mean train loss 3197.7043798009777
INFO:root:current train perplexity3.5418503284454346
INFO:root:current mean train loss 3201.929195718526
INFO:root:current train perplexity3.5508716106414795
INFO:root:current mean train loss 3206.41329851377
INFO:root:current train perplexity3.5474555492401123
INFO:root:current mean train loss 3209.35591013994
INFO:root:current train perplexity3.5480599403381348
INFO:root:current mean train loss 3211.6219092387196
INFO:root:current train perplexity3.547152280807495
INFO:root:current mean train loss 3213.52116292917
INFO:root:current train perplexity3.5492913722991943
INFO:root:current mean train loss 3213.7215182851614
INFO:root:current train perplexity3.5503809452056885
INFO:root:current mean train loss 3214.8594599909343
INFO:root:current train perplexity3.5503742694854736
INFO:root:current mean train loss 3214.188020201577
INFO:root:current train perplexity3.549940347671509


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.70s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.70s/it]
INFO:root:final mean train loss: 3211.2486014827605
INFO:root:final train perplexity: 3.5499396324157715
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.45s/it]
INFO:root:eval mean loss: 4084.504856840093
INFO:root:eval perplexity: 5.2155985832214355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/186

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [7:23:33<33:13, 142.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3213.681884765625
INFO:root:current train perplexity3.558981418609619
INFO:root:current mean train loss 3212.0447417070523
INFO:root:current train perplexity3.554248094558716
INFO:root:current mean train loss 3214.432270967171
INFO:root:current train perplexity3.5469717979431152
INFO:root:current mean train loss 3215.047360757833
INFO:root:current train perplexity3.5455267429351807
INFO:root:current mean train loss 3215.120038480974
INFO:root:current train perplexity3.544297456741333
INFO:root:current mean train loss 3213.6234544692293
INFO:root:current train perplexity3.546032428741455
INFO:root:current mean train loss 3215.3662059622907
INFO:root:current train perplexity3.547642946243286
INFO:root:current mean train loss 3213.7801313582036
INFO:root:current train perplexity3.547844648361206
INFO:root:current mean train loss 3212.273634574056
INFO:root:current train perplexity3.547159433364868
INFO:root:current mean train loss 3212.0093743074026
INFO:root:current train perplexity3.5474977493286133


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.86s/it]
INFO:root:final mean train loss: 3209.0930297605455
INFO:root:final train perplexity: 3.5469210147857666
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.95s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.95s/it]
INFO:root:eval mean loss: 4086.6926061751997
INFO:root:eval perplexity: 5.220215320587158
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/187

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [7:26:08<31:36, 145.92s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3216.9752235814144
INFO:root:current train perplexity3.537409543991089
INFO:root:current mean train loss 3214.328737229567
INFO:root:current train perplexity3.547563314437866
INFO:root:current mean train loss 3212.143063923464
INFO:root:current train perplexity3.5468482971191406
INFO:root:current mean train loss 3210.450426473497
INFO:root:current train perplexity3.546520233154297
INFO:root:current mean train loss 3207.862827493687
INFO:root:current train perplexity3.543534517288208
INFO:root:current mean train loss 3211.0872903262866
INFO:root:current train perplexity3.5477664470672607
INFO:root:current mean train loss 3214.4583815759893
INFO:root:current train perplexity3.5501418113708496
INFO:root:current mean train loss 3212.9904435067806
INFO:root:current train perplexity3.5480878353118896
INFO:root:current mean train loss 3212.109152136435
INFO:root:current train perplexity3.548229455947876


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.30s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:05<00:00, 125.30s/it]
INFO:root:final mean train loss: 3209.0637135659495
INFO:root:final train perplexity: 3.5468804836273193
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.29s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.29s/it]
INFO:root:eval mean loss: 4085.767626606826
INFO:root:eval perplexity: 5.218263149261475
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/188

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [7:28:57<30:35, 152.94s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3167.6892903645835
INFO:root:current train perplexity3.4740607738494873
INFO:root:current mean train loss 3208.1976685755462
INFO:root:current train perplexity3.527768135070801
INFO:root:current mean train loss 3207.3027716575584
INFO:root:current train perplexity3.5381009578704834
INFO:root:current mean train loss 3211.2780391076217
INFO:root:current train perplexity3.545178174972534
INFO:root:current mean train loss 3208.3756167125466
INFO:root:current train perplexity3.5449702739715576
INFO:root:current mean train loss 3208.4504365409107
INFO:root:current train perplexity3.5464775562286377
INFO:root:current mean train loss 3204.7161276138836
INFO:root:current train perplexity3.5449445247650146
INFO:root:current mean train loss 3206.3074414618154
INFO:root:current train perplexity3.541810989379883
INFO:root:current mean train loss 3206.363791117781
INFO:root:current train perplexity3.5418355464935303
INFO:root:current mean train loss 3210.770098748529
INFO:root:current train perplexity3.5439417362213135


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.28s/it]
INFO:root:final mean train loss: 3207.8197115005987
INFO:root:final train perplexity: 3.545140027999878
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.61s/it]
INFO:root:eval mean loss: 4085.9120643561614
INFO:root:eval perplexity: 5.218566417694092
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/189

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [7:31:39<28:31, 155.55s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3192.9603382457385
INFO:root:current train perplexity3.5549070835113525
INFO:root:current mean train loss 3192.252093890766
INFO:root:current train perplexity3.5318212509155273
INFO:root:current mean train loss 3207.9657948570793
INFO:root:current train perplexity3.540177822113037
INFO:root:current mean train loss 3209.9141747575864
INFO:root:current train perplexity3.5428130626678467
INFO:root:current mean train loss 3205.297989968256
INFO:root:current train perplexity3.54311466217041
INFO:root:current mean train loss 3204.589171527183
INFO:root:current train perplexity3.5427606105804443
INFO:root:current mean train loss 3202.687517980897
INFO:root:current train perplexity3.540151596069336
INFO:root:current mean train loss 3204.5547578921633
INFO:root:current train perplexity3.5417966842651367
INFO:root:current mean train loss 3204.593739162685
INFO:root:current train perplexity3.5404067039489746
INFO:root:current mean train loss 3207.9956877422646
INFO:root:current train perplexity3.5426313877105713


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.68s/it]
INFO:root:final mean train loss: 3206.9310220287693
INFO:root:final train perplexity: 3.5438973903656006
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.75s/it]
INFO:root:eval mean loss: 4085.38515347961
INFO:root:eval perplexity: 5.217454433441162
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/190

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [7:33:50<24:42, 148.25s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3189.111456620066
INFO:root:current train perplexity3.547938823699951
INFO:root:current mean train loss 3226.471248851103
INFO:root:current train perplexity3.5519495010375977
INFO:root:current mean train loss 3221.4694445187642
INFO:root:current train perplexity3.5469954013824463
INFO:root:current mean train loss 3220.9576067789967
INFO:root:current train perplexity3.5479207038879395
INFO:root:current mean train loss 3213.9139791775433
INFO:root:current train perplexity3.54695725440979
INFO:root:current mean train loss 3214.112346553619
INFO:root:current train perplexity3.5464460849761963
INFO:root:current mean train loss 3210.5523166933813
INFO:root:current train perplexity3.5447640419006348
INFO:root:current mean train loss 3210.258443055133
INFO:root:current train perplexity3.544776201248169
INFO:root:current mean train loss 3207.9302261594744
INFO:root:current train perplexity3.5440189838409424
INFO:root:current mean train loss 3208.661744890846
INFO:root:current train perplexity3.5437326431274414


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.86s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:03<00:00, 123.86s/it]
INFO:root:final mean train loss: 3207.343838968585
INFO:root:final train perplexity: 3.5444748401641846
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.18s/it]
INFO:root:eval mean loss: 4086.7058226673316
INFO:root:eval perplexity: 5.220242023468018
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/191

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [7:36:05<21:38, 144.24s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3259.1522352430557
INFO:root:current train perplexity3.5559704303741455
INFO:root:current mean train loss 3222.7828148068406
INFO:root:current train perplexity3.5374951362609863
INFO:root:current mean train loss 3216.534248520099
INFO:root:current train perplexity3.5424578189849854
INFO:root:current mean train loss 3215.7196309967508
INFO:root:current train perplexity3.54258131980896
INFO:root:current mean train loss 3212.0774194507467
INFO:root:current train perplexity3.542046308517456
INFO:root:current mean train loss 3215.467634458017
INFO:root:current train perplexity3.5435826778411865
INFO:root:current mean train loss 3210.2865447754684
INFO:root:current train perplexity3.5412533283233643
INFO:root:current mean train loss 3208.314896070646
INFO:root:current train perplexity3.540428638458252
INFO:root:current mean train loss 3206.6386727606373
INFO:root:current train perplexity3.5403497219085693
INFO:root:current mean train loss 3207.1157492562534
INFO:root:current train perplexity3.5410819053649902


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.17s/it]
INFO:root:final mean train loss: 3205.77399235387
INFO:root:final train perplexity: 3.5422801971435547
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.97s/it]
INFO:root:eval mean loss: 4086.369433247451
INFO:root:eval perplexity: 5.219532012939453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/192

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [7:38:18<18:46, 140.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3191.9088797433037
INFO:root:current train perplexity3.5430264472961426
INFO:root:current mean train loss 3204.8577799479167
INFO:root:current train perplexity3.537370443344116
INFO:root:current mean train loss 3201.5327169215425
INFO:root:current train perplexity3.5389997959136963
INFO:root:current mean train loss 3204.9270682719216
INFO:root:current train perplexity3.541750192642212
INFO:root:current mean train loss 3209.411725484914
INFO:root:current train perplexity3.542125701904297
INFO:root:current mean train loss 3204.1730701482184
INFO:root:current train perplexity3.5376217365264893
INFO:root:current mean train loss 3206.9926869309793
INFO:root:current train perplexity3.5416576862335205
INFO:root:current mean train loss 3204.8958911298896
INFO:root:current train perplexity3.5407750606536865
INFO:root:current mean train loss 3204.9821967393336
INFO:root:current train perplexity3.53973126411438
INFO:root:current mean train loss 3206.265992124833
INFO:root:current train perplexity3.5406999588012695


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.82s/it]
INFO:root:final mean train loss: 3205.224842071533
INFO:root:final train perplexity: 3.5415124893188477
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.14s/it]
INFO:root:eval mean loss: 4086.444739375554
INFO:root:eval perplexity: 5.219691276550293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/193

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [7:40:29<16:06, 138.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3204.6786655159885
INFO:root:current train perplexity3.55743408203125
INFO:root:current mean train loss 3205.9746708369757
INFO:root:current train perplexity3.551957845687866
INFO:root:current mean train loss 3206.483974127122
INFO:root:current train perplexity3.543224811553955
INFO:root:current mean train loss 3201.4627432864886
INFO:root:current train perplexity3.542357921600342
INFO:root:current mean train loss 3206.855467647785
INFO:root:current train perplexity3.541278600692749
INFO:root:current mean train loss 3206.7156346217484
INFO:root:current train perplexity3.5391929149627686
INFO:root:current mean train loss 3206.173637140965
INFO:root:current train perplexity3.5400116443634033
INFO:root:current mean train loss 3205.162745520693
INFO:root:current train perplexity3.5382518768310547
INFO:root:current mean train loss 3208.223099641811
INFO:root:current train perplexity3.5401980876922607
INFO:root:current mean train loss 3208.0534116516437
INFO:root:current train perplexity3.5400116443634033


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.73s/it]
INFO:root:final mean train loss: 3204.526492088072
INFO:root:final train perplexity: 3.5405373573303223
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.32s/it]
INFO:root:eval mean loss: 4086.9021861840647
INFO:root:eval perplexity: 5.220657825469971
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/194

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [7:43:22<14:51, 148.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3173.2038430606617
INFO:root:current train perplexity3.503812789916992
INFO:root:current mean train loss 3190.95056233185
INFO:root:current train perplexity3.522897720336914
INFO:root:current mean train loss 3196.990337478212
INFO:root:current train perplexity3.534545421600342
INFO:root:current mean train loss 3197.9766904825497
INFO:root:current train perplexity3.5350990295410156
INFO:root:current mean train loss 3201.33390750589
INFO:root:current train perplexity3.5366644859313965
INFO:root:current mean train loss 3203.8491104596756
INFO:root:current train perplexity3.5397043228149414
INFO:root:current mean train loss 3207.801453668035
INFO:root:current train perplexity3.5429306030273438
INFO:root:current mean train loss 3205.5278824197944
INFO:root:current train perplexity3.5411641597747803
INFO:root:current mean train loss 3206.546187332458
INFO:root:current train perplexity3.541795492172241
INFO:root:current mean train loss 3207.2835206875166
INFO:root:current train perplexity3.542104959487915


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.10s/it]
INFO:root:final mean train loss: 3204.92488744182
INFO:root:final train perplexity: 3.5410938262939453
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.36s/it]
INFO:root:eval mean loss: 4086.239501953125
INFO:root:eval perplexity: 5.219257831573486
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/195

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [7:46:12<12:54, 154.81s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3217.7020408501057
INFO:root:current train perplexity3.5565273761749268
INFO:root:current mean train loss 3213.7001768867926
INFO:root:current train perplexity3.543997049331665
INFO:root:current mean train loss 3215.370987233048
INFO:root:current train perplexity3.542057991027832
INFO:root:current mean train loss 3211.668956873477
INFO:root:current train perplexity3.539104700088501
INFO:root:current mean train loss 3208.88836231107
INFO:root:current train perplexity3.5388529300689697
INFO:root:current mean train loss 3203.9516806832794
INFO:root:current train perplexity3.5375335216522217
INFO:root:current mean train loss 3202.838266282957
INFO:root:current train perplexity3.5378384590148926
INFO:root:current mean train loss 3203.688604583539
INFO:root:current train perplexity3.5384328365325928
INFO:root:current mean train loss 3205.6625877087276
INFO:root:current train perplexity3.538360595703125
INFO:root:current mean train loss 3205.3963463935415
INFO:root:current train perplexity3.538341999053955


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.80s/it]
INFO:root:final mean train loss: 3203.098416051557
INFO:root:final train perplexity: 3.5385429859161377
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.20s/it]
INFO:root:eval mean loss: 4086.363087322695
INFO:root:eval perplexity: 5.219519138336182
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/196

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [7:48:58<10:33, 158.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3216.5072476970618
INFO:root:current train perplexity3.5455005168914795
INFO:root:current mean train loss 3207.439507216037
INFO:root:current train perplexity3.5438315868377686
INFO:root:current mean train loss 3211.5401963366103
INFO:root:current train perplexity3.543283224105835
INFO:root:current mean train loss 3211.3220487589406
INFO:root:current train perplexity3.541857957839966
INFO:root:current mean train loss 3212.0050830391797
INFO:root:current train perplexity3.542740821838379
INFO:root:current mean train loss 3211.123379715746
INFO:root:current train perplexity3.5427939891815186
INFO:root:current mean train loss 3207.674714278603
INFO:root:current train perplexity3.5403006076812744
INFO:root:current mean train loss 3207.847215396329
INFO:root:current train perplexity3.541402816772461
INFO:root:current mean train loss 3206.4461147567945
INFO:root:current train perplexity3.5402133464813232
INFO:root:current mean train loss 3205.4548360041526
INFO:root:current train perplexity3.539189100265503


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:00<00:00, 120.97s/it]
INFO:root:final mean train loss: 3202.8206837561825
INFO:root:final train perplexity: 3.5381548404693604
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.12s/it]
INFO:root:eval mean loss: 4086.836695894282
INFO:root:eval perplexity: 5.220519065856934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/197

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [7:51:53<08:09, 163.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3199.5525520833335
INFO:root:current train perplexity3.5299670696258545
INFO:root:current mean train loss 3203.9024720982143
INFO:root:current train perplexity3.533073902130127
INFO:root:current mean train loss 3202.844986683239
INFO:root:current train perplexity3.5363993644714355
INFO:root:current mean train loss 3199.880139973958
INFO:root:current train perplexity3.535116672515869
INFO:root:current mean train loss 3202.598381476151
INFO:root:current train perplexity3.5331501960754395
INFO:root:current mean train loss 3203.5421204144022
INFO:root:current train perplexity3.5324456691741943
INFO:root:current mean train loss 3205.3038816550925
INFO:root:current train perplexity3.5351834297180176
INFO:root:current mean train loss 3203.116037046371
INFO:root:current train perplexity3.534348726272583
INFO:root:current mean train loss 3204.9635524553573
INFO:root:current train perplexity3.5350594520568848
INFO:root:current mean train loss 3204.4694986979166
INFO:root:current train perplexity3.5372421741485596


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:02<00:00, 122.03s/it]
INFO:root:final mean train loss: 3202.2066642392065
INFO:root:final train perplexity: 3.5372979640960693
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.91s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.91s/it]
INFO:root:eval mean loss: 4087.1176203734485
INFO:root:eval perplexity: 5.2211127281188965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/198

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [7:54:35<05:25, 162.86s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3200.910570994917
INFO:root:current train perplexity3.5443356037139893
INFO:root:current mean train loss 3211.959305893528
INFO:root:current train perplexity3.5436134338378906
INFO:root:current mean train loss 3213.9051863060404
INFO:root:current train perplexity3.5493035316467285
INFO:root:current mean train loss 3208.8581957306624
INFO:root:current train perplexity3.544245481491089
INFO:root:current mean train loss 3202.024470674819
INFO:root:current train perplexity3.542348861694336
INFO:root:current mean train loss 3206.22154610112
INFO:root:current train perplexity3.545949935913086
INFO:root:current mean train loss 3206.9804930568266
INFO:root:current train perplexity3.5422770977020264
INFO:root:current mean train loss 3206.3500695941093
INFO:root:current train perplexity3.539401054382324
INFO:root:current mean train loss 3206.1240206726006
INFO:root:current train perplexity3.5372164249420166
INFO:root:current mean train loss 3205.881255513654
INFO:root:current train perplexity3.538332462310791


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:04<00:00, 124.06s/it]
INFO:root:final mean train loss: 3202.7148249226234
INFO:root:final train perplexity: 3.5380072593688965
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.81s/it]
INFO:root:eval mean loss: 4087.1763353280144
INFO:root:eval perplexity: 5.221236228942871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/199

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [7:57:10<02:40, 160.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3199.639090401786
INFO:root:current train perplexity3.5429694652557373
INFO:root:current mean train loss 3199.9364250143162
INFO:root:current train perplexity3.5310351848602295
INFO:root:current mean train loss 3197.6325238939003
INFO:root:current train perplexity3.533656120300293
INFO:root:current mean train loss 3201.3446091751916
INFO:root:current train perplexity3.5343852043151855
INFO:root:current mean train loss 3204.0987422034113
INFO:root:current train perplexity3.53727126121521
INFO:root:current mean train loss 3203.589881341873
INFO:root:current train perplexity3.5394110679626465
INFO:root:current mean train loss 3202.6112140042737
INFO:root:current train perplexity3.537813663482666
INFO:root:current mean train loss 3204.101823924917
INFO:root:current train perplexity3.53737211227417
INFO:root:current mean train loss 3205.4227153808047
INFO:root:current train perplexity3.538607120513916
INFO:root:current mean train loss 3205.3032120628627
INFO:root:current train perplexity3.538073778152466


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.53s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [02:01<00:00, 121.53s/it]
INFO:root:final mean train loss: 3202.7409232354935
INFO:root:final train perplexity: 3.538043975830078
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.36s/it]
INFO:root:eval mean loss: 4087.143378075133
INFO:root:eval perplexity: 5.221165657043457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_val_1316/200

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [7:59:27<00:00, 153.41s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [7:59:27<00:00, 143.84s/it]
INFO:root:evaluating final model
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.75s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:14<00:00, 14.75s/it]
INFO:root:eval mean loss: 4087.143378075133
INFO:root:eval perplexity: 5.221165657043457
INFO:root:evalaution complete
INFO:root:save model final: small_val_1316/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x14e7a2317f06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x14e7a230f8e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x14e7a2234e09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x14e7a2318a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x14e7a2232948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x14e7a2318a3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x14e7a21edb46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x14e7a1c5246a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x14e89e46ea27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x14e89e46ebe0]
python(+0x24a989) [0x555e42e25989]
python(+0x24a9bd) [0x555e42e259bd]
python(+0x24aa14) [0x555e42e25a14]
python(+0x108f75) [0x555e42ce3f75]
python(Py_RunMain+0x313) [0x555e42e28983]
python(Py_BytesMain+0x39) [0x555e42e28bc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x14e89e44c0b3]
python(+0x1d6e13) [0x555e42db1e13]
/opt/slurm/data/slurmd/job26146350/slurm_script: line 139: 3701807 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path sentence-transformers/multi-qa-MiniLM-L6-cos-v1 --data_config data_config.json --data_folder fast_processed_data_1316_final  --output small_val_1316 --batch_size 128 --epochs 200 --save_head  --save_epochs 1 --external_embedding
"
