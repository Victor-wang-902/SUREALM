INFO:root:Output: pld_24
INFO:root:Steps per epochs:1983
INFO:root:Total steps:198300
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['encoder.layer.2.crossattention.self.key.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.dense.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.key.bias', 'cls.predictions.decoder.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.query.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'cls.predictions.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.query.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][A/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
INFO:root:current mean train loss 12228.6064453125
INFO:root:current train perplexity16574.189453125
INFO:root:current mean train loss 10549.36096743483
INFO:root:current train perplexity4129.12939453125
INFO:root:current mean train loss 9179.036769701086
INFO:root:current train perplexity1390.02734375
INFO:root:current mean train loss 8229.986441934916
INFO:root:current train perplexity656.9459838867188
INFO:root:current mean train loss 7537.363191715463
INFO:root:current train perplexity381.2288818359375
INFO:root:current mean train loss 7011.353341995774
INFO:root:current train perplexity251.73622131347656
INFO:root:current mean train loss 6601.093712278702
INFO:root:current train perplexity181.57464599609375
INFO:root:current mean train loss 6274.910967200211
INFO:root:current train perplexity139.9375762939453
INFO:root:current mean train loss 5997.536754162611
INFO:root:current train perplexity113.0090103149414
INFO:root:current mean train loss 5772.889766231075
INFO:root:current train perplexity94.17107391357422
INFO:root:current mean train loss 5573.183873212153
INFO:root:current train perplexity80.63690948486328
INFO:root:current mean train loss 5403.095082286997
INFO:root:current train perplexity70.55758666992188
INFO:root:current mean train loss 5256.04150390625
INFO:root:current train perplexity62.660396575927734
INFO:root:current mean train loss 5119.657059555653
INFO:root:current train perplexity56.41590118408203
INFO:root:current mean train loss 5000.381239836975
INFO:root:current train perplexity51.42479705810547
INFO:root:current mean train loss 4893.160946386169
INFO:root:current train perplexity47.2817268371582
INFO:root:current mean train loss 4796.79073512912
INFO:root:current train perplexity43.790924072265625
INFO:root:current mean train loss 4707.554376183383
INFO:root:current train perplexity40.86215591430664
INFO:root:current mean train loss 4624.263864204845
INFO:root:current train perplexity38.32352828979492

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.80s/it]
INFO:root:final mean train loss: 4559.507195561689
INFO:root:final train perplexity: 36.448551177978516
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.04s/it]
INFO:root:eval mean loss: 3475.783396677928
INFO:root:eval perplexity: 17.324716567993164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/1
  1%|          | 1/100 [05:24<8:54:49, 324.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3074.7909545898438
INFO:root:current train perplexity11.220738410949707
INFO:root:current mean train loss 3070.225766938308
INFO:root:current train perplexity11.282744407653809
INFO:root:current mean train loss 3049.5831411856193
INFO:root:current train perplexity11.195592880249023
INFO:root:current mean train loss 3047.7344483967067
INFO:root:current train perplexity11.17106819152832
INFO:root:current mean train loss 3039.9806049053486
INFO:root:current train perplexity11.07197093963623
INFO:root:current mean train loss 3029.5508550599566
INFO:root:current train perplexity10.932615280151367
INFO:root:current mean train loss 3010.8931646966316
INFO:root:current train perplexity10.79883098602295
INFO:root:current mean train loss 2999.155951643789
INFO:root:current train perplexity10.693673133850098
INFO:root:current mean train loss 2989.3523032992493
INFO:root:current train perplexity10.610295295715332
INFO:root:current mean train loss 2982.4435459453466
INFO:root:current train perplexity10.528472900390625
INFO:root:current mean train loss 2968.985877089613
INFO:root:current train perplexity10.436649322509766
INFO:root:current mean train loss 2959.630084294145
INFO:root:current train perplexity10.339486122131348
INFO:root:current mean train loss 2951.3144274259867
INFO:root:current train perplexity10.256988525390625
INFO:root:current mean train loss 2941.528444794536
INFO:root:current train perplexity10.170694351196289
INFO:root:current mean train loss 2931.591723253498
INFO:root:current train perplexity10.093725204467773
INFO:root:current mean train loss 2922.565067663671
INFO:root:current train perplexity10.015612602233887
INFO:root:current mean train loss 2912.3108142815013
INFO:root:current train perplexity9.937302589416504
INFO:root:current mean train loss 2903.772086474723
INFO:root:current train perplexity9.868603706359863
INFO:root:current mean train loss 2892.6664052282663
INFO:root:current train perplexity9.793024063110352
INFO:root:current mean train loss 2883.749006235525
INFO:root:current train perplexity9.717859268188477

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:51<00:00, 291.95s/it]
INFO:root:final mean train loss: 2877.426550976267
INFO:root:final train perplexity: 9.67273998260498
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.00s/it]
INFO:root:eval mean loss: 3262.484643334741
INFO:root:eval perplexity: 14.542954444885254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/2
  2%|â–         | 2/100 [10:49<8:50:47, 324.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2734.007449988163
INFO:root:current train perplexity8.615238189697266
INFO:root:current mean train loss 2680.285345321311
INFO:root:current train perplexity8.34776496887207
INFO:root:current mean train loss 2677.5126659737125
INFO:root:current train perplexity8.31088924407959
INFO:root:current mean train loss 2664.497018991648
INFO:root:current train perplexity8.238884925842285
INFO:root:current mean train loss 2665.984182168375
INFO:root:current train perplexity8.201148986816406
INFO:root:current mean train loss 2660.7531307714294
INFO:root:current train perplexity8.153480529785156
INFO:root:current mean train loss 2655.3472184939033
INFO:root:current train perplexity8.109743118286133
INFO:root:current mean train loss 2649.0248443894952
INFO:root:current train perplexity8.073036193847656
INFO:root:current mean train loss 2643.6279909424707
INFO:root:current train perplexity8.038153648376465
INFO:root:current mean train loss 2636.2405803063034
INFO:root:current train perplexity7.999937057495117
INFO:root:current mean train loss 2630.709167539554
INFO:root:current train perplexity7.965813636779785
INFO:root:current mean train loss 2624.7122665903576
INFO:root:current train perplexity7.936714172363281
INFO:root:current mean train loss 2618.71401866161
INFO:root:current train perplexity7.903005123138428
INFO:root:current mean train loss 2611.516924275014
INFO:root:current train perplexity7.861825942993164
INFO:root:current mean train loss 2609.5712253440115
INFO:root:current train perplexity7.839927673339844
INFO:root:current mean train loss 2607.647065184432
INFO:root:current train perplexity7.813793659210205
INFO:root:current mean train loss 2602.5304205497932
INFO:root:current train perplexity7.782387733459473
INFO:root:current mean train loss 2598.0842029463674
INFO:root:current train perplexity7.750284194946289
INFO:root:current mean train loss 2593.133657135992
INFO:root:current train perplexity7.716186046600342
INFO:root:current mean train loss 2587.6365191306218
INFO:root:current train perplexity7.687241554260254

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.26s/it]
INFO:root:final mean train loss: 2583.4279269912417
INFO:root:final train perplexity: 7.6709980964660645
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.29s/it]
INFO:root:eval mean loss: 3209.5259573538383
INFO:root:eval perplexity: 13.924506187438965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/3
  3%|â–Ž         | 3/100 [16:16<8:46:56, 325.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2493.7238232421873
INFO:root:current train perplexity7.107297897338867
INFO:root:current mean train loss 2481.2237174479164
INFO:root:current train perplexity7.070760250091553
INFO:root:current mean train loss 2474.35314453125
INFO:root:current train perplexity7.048912525177002
INFO:root:current mean train loss 2466.2306745256697
INFO:root:current train perplexity6.993439674377441
INFO:root:current mean train loss 2469.108126627604
INFO:root:current train perplexity6.980655193328857
INFO:root:current mean train loss 2460.5035826526987
INFO:root:current train perplexity6.9408278465271
INFO:root:current mean train loss 2456.300182166466
INFO:root:current train perplexity6.923748016357422
INFO:root:current mean train loss 2452.433878092448
INFO:root:current train perplexity6.905317306518555
INFO:root:current mean train loss 2449.6135295553768
INFO:root:current train perplexity6.898263931274414
INFO:root:current mean train loss 2446.086753829153
INFO:root:current train perplexity6.877111911773682
INFO:root:current mean train loss 2441.7169853283112
INFO:root:current train perplexity6.854837894439697
INFO:root:current mean train loss 2440.68044253142
INFO:root:current train perplexity6.845477104187012
INFO:root:current mean train loss 2436.7710043945312
INFO:root:current train perplexity6.828591346740723
INFO:root:current mean train loss 2433.7547587528934
INFO:root:current train perplexity6.811288833618164
INFO:root:current mean train loss 2432.5189666958513
INFO:root:current train perplexity6.802947044372559
INFO:root:current mean train loss 2428.8899228200603
INFO:root:current train perplexity6.786060810089111
INFO:root:current mean train loss 2426.7784794477984
INFO:root:current train perplexity6.772982597351074
INFO:root:current mean train loss 2423.423829031808
INFO:root:current train perplexity6.754340648651123
INFO:root:current mean train loss 2421.5413360430744
INFO:root:current train perplexity6.744251728057861
INFO:root:current mean train loss 2418.7492700821313
INFO:root:current train perplexity6.7317047119140625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:53<00:00, 293.93s/it]
INFO:root:final mean train loss: 2416.9536699149803
INFO:root:final train perplexity: 6.7271728515625
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.64s/it]
INFO:root:eval mean loss: 3177.727325714386
INFO:root:eval perplexity: 13.565873146057129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/4
  4%|â–         | 4/100 [21:45<8:43:00, 326.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2384.3168835995803
INFO:root:current train perplexity6.428565979003906
INFO:root:current mean train loss 2347.386177839633
INFO:root:current train perplexity6.340734004974365
INFO:root:current mean train loss 2344.7306360823386
INFO:root:current train perplexity6.34575891494751
INFO:root:current mean train loss 2343.6363744917617
INFO:root:current train perplexity6.346531867980957
INFO:root:current mean train loss 2343.9641366832006
INFO:root:current train perplexity6.352759838104248
INFO:root:current mean train loss 2337.756940784488
INFO:root:current train perplexity6.3167548179626465
INFO:root:current mean train loss 2338.104822893729
INFO:root:current train perplexity6.312023162841797
INFO:root:current mean train loss 2334.5634748118177
INFO:root:current train perplexity6.296273708343506
INFO:root:current mean train loss 2334.5311259585405
INFO:root:current train perplexity6.285803318023682
INFO:root:current mean train loss 2330.289886064342
INFO:root:current train perplexity6.2682414054870605
INFO:root:current mean train loss 2329.0308197221693
INFO:root:current train perplexity6.2607293128967285
INFO:root:current mean train loss 2327.837646065968
INFO:root:current train perplexity6.25167179107666
INFO:root:current mean train loss 2323.909918949937
INFO:root:current train perplexity6.236725807189941
INFO:root:current mean train loss 2322.933880664348
INFO:root:current train perplexity6.229765892028809
INFO:root:current mean train loss 2319.9475371419935
INFO:root:current train perplexity6.222629070281982
INFO:root:current mean train loss 2317.220181813876
INFO:root:current train perplexity6.215636253356934
INFO:root:current mean train loss 2313.3099729907535
INFO:root:current train perplexity6.199723720550537
INFO:root:current mean train loss 2311.4883902635556
INFO:root:current train perplexity6.187732219696045
INFO:root:current mean train loss 2308.894691765596
INFO:root:current train perplexity6.175726413726807
INFO:root:current mean train loss 2306.4775364560164
INFO:root:current train perplexity6.1623616218566895

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.56s/it]
INFO:root:final mean train loss: 2305.435256196223
INFO:root:final train perplexity: 6.1607890129089355
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.57s/it]
INFO:root:eval mean loss: 3157.2597509618995
INFO:root:eval perplexity: 13.339934349060059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/5
  5%|â–Œ         | 5/100 [27:14<8:39:16, 327.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2253.5603884742372
INFO:root:current train perplexity5.864606857299805
INFO:root:current mean train loss 2250.888287751571
INFO:root:current train perplexity5.8874969482421875
INFO:root:current mean train loss 2248.4815983302155
INFO:root:current train perplexity5.903691291809082
INFO:root:current mean train loss 2249.2993857065835
INFO:root:current train perplexity5.904696941375732
INFO:root:current mean train loss 2254.741451799377
INFO:root:current train perplexity5.914695739746094
INFO:root:current mean train loss 2248.283140208623
INFO:root:current train perplexity5.885087490081787
INFO:root:current mean train loss 2246.027232209144
INFO:root:current train perplexity5.8657612800598145
INFO:root:current mean train loss 2245.523534502302
INFO:root:current train perplexity5.868601322174072
INFO:root:current mean train loss 2243.389117486876
INFO:root:current train perplexity5.856155872344971
INFO:root:current mean train loss 2238.844215206984
INFO:root:current train perplexity5.838530540466309
INFO:root:current mean train loss 2237.6685998219846
INFO:root:current train perplexity5.835765361785889
INFO:root:current mean train loss 2235.4933099488953
INFO:root:current train perplexity5.82670783996582
INFO:root:current mean train loss 2233.7908091322283
INFO:root:current train perplexity5.819621562957764
INFO:root:current mean train loss 2233.3816967561756
INFO:root:current train perplexity5.815147876739502
INFO:root:current mean train loss 2233.4463733765638
INFO:root:current train perplexity5.8154120445251465
INFO:root:current mean train loss 2232.2130254880344
INFO:root:current train perplexity5.806286334991455
INFO:root:current mean train loss 2231.037377146814
INFO:root:current train perplexity5.799840450286865
INFO:root:current mean train loss 2227.4102559453167
INFO:root:current train perplexity5.791131019592285
INFO:root:current mean train loss 2226.5666299159866
INFO:root:current train perplexity5.78434419631958

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:54<00:00, 294.71s/it]
INFO:root:final mean train loss: 2223.7697308223414
INFO:root:final train perplexity: 5.776503562927246
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.58s/it]
INFO:root:eval mean loss: 3175.1388815573387
INFO:root:eval perplexity: 13.537088394165039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/6
  6%|â–Œ         | 6/100 [32:44<8:34:22, 328.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2305.62890625
INFO:root:current train perplexity5.421343803405762
INFO:root:current mean train loss 2156.018771029935
INFO:root:current train perplexity5.490410804748535
INFO:root:current mean train loss 2168.188725561645
INFO:root:current train perplexity5.542137622833252
INFO:root:current mean train loss 2177.9633947226694
INFO:root:current train perplexity5.559190273284912
INFO:root:current mean train loss 2175.221204496084
INFO:root:current train perplexity5.556405544281006
INFO:root:current mean train loss 2172.220401725845
INFO:root:current train perplexity5.554800033569336
INFO:root:current mean train loss 2169.607436702176
INFO:root:current train perplexity5.546810626983643
INFO:root:current mean train loss 2171.2249264791926
INFO:root:current train perplexity5.547331809997559
INFO:root:current mean train loss 2171.167880207114
INFO:root:current train perplexity5.545391082763672
INFO:root:current mean train loss 2170.1005874278144
INFO:root:current train perplexity5.538266181945801
INFO:root:current mean train loss 2166.8030663184472
INFO:root:current train perplexity5.52736234664917
INFO:root:current mean train loss 2165.2465202754242
INFO:root:current train perplexity5.518395900726318
INFO:root:current mean train loss 2164.74748602239
INFO:root:current train perplexity5.515082359313965
INFO:root:current mean train loss 2164.1313150040833
INFO:root:current train perplexity5.513342380523682
INFO:root:current mean train loss 2163.6219364795234
INFO:root:current train perplexity5.511684417724609
INFO:root:current mean train loss 2163.7910651525285
INFO:root:current train perplexity5.507787704467773
INFO:root:current mean train loss 2162.4789587684454
INFO:root:current train perplexity5.502194404602051
INFO:root:current mean train loss 2161.9968584656085
INFO:root:current train perplexity5.500815391540527
INFO:root:current mean train loss 2161.5411970020996
INFO:root:current train perplexity5.496378421783447
INFO:root:current mean train loss 2160.8820186255793
INFO:root:current train perplexity5.493391513824463

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.42s/it]
INFO:root:final mean train loss: 2159.3788436758837
INFO:root:final train perplexity: 5.490482807159424
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.32s/it]
INFO:root:eval mean loss: 3176.8166569890204
INFO:root:eval perplexity: 13.555733680725098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/7
  7%|â–‹         | 7/100 [38:15<8:30:32, 329.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2115.5535346137153
INFO:root:current train perplexity5.290622711181641
INFO:root:current mean train loss 2105.6773278187898
INFO:root:current train perplexity5.320253372192383
INFO:root:current mean train loss 2120.3061237860165
INFO:root:current train perplexity5.354278087615967
INFO:root:current mean train loss 2123.333607799602
INFO:root:current train perplexity5.353134632110596
INFO:root:current mean train loss 2122.345570833489
INFO:root:current train perplexity5.332423686981201
INFO:root:current mean train loss 2122.15824130143
INFO:root:current train perplexity5.329158306121826
INFO:root:current mean train loss 2120.9994623375555
INFO:root:current train perplexity5.320010662078857
INFO:root:current mean train loss 2121.851317339289
INFO:root:current train perplexity5.322478771209717
INFO:root:current mean train loss 2120.3459341333664
INFO:root:current train perplexity5.312582969665527
INFO:root:current mean train loss 2118.6954897546043
INFO:root:current train perplexity5.308500289916992
INFO:root:current mean train loss 2116.114120033729
INFO:root:current train perplexity5.301269054412842
INFO:root:current mean train loss 2116.3393409469686
INFO:root:current train perplexity5.2966437339782715
INFO:root:current mean train loss 2115.7221979351075
INFO:root:current train perplexity5.291893482208252
INFO:root:current mean train loss 2116.27933503355
INFO:root:current train perplexity5.297104835510254
INFO:root:current mean train loss 2116.04029757953
INFO:root:current train perplexity5.293456554412842
INFO:root:current mean train loss 2115.782877764997
INFO:root:current train perplexity5.289115905761719
INFO:root:current mean train loss 2113.96228540371
INFO:root:current train perplexity5.283998489379883
INFO:root:current mean train loss 2111.651275528185
INFO:root:current train perplexity5.2760186195373535
INFO:root:current mean train loss 2110.559652297017
INFO:root:current train perplexity5.2749128341674805
INFO:root:current mean train loss 2108.1875372957265
INFO:root:current train perplexity5.270744800567627

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.18s/it]
INFO:root:final mean train loss: 2107.5775051376645
INFO:root:final train perplexity: 5.270696640014648
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.51s/it]
INFO:root:eval mean loss: 3164.3475887997374
INFO:root:eval perplexity: 13.417745590209961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/8
  8%|â–Š         | 8/100 [43:46<8:25:34, 329.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2070.3229038783484
INFO:root:current train perplexity5.095056056976318
INFO:root:current mean train loss 2077.795863172743
INFO:root:current train perplexity5.110816955566406
INFO:root:current mean train loss 2069.2338456823472
INFO:root:current train perplexity5.109182357788086
INFO:root:current mean train loss 2070.82144101271
INFO:root:current train perplexity5.119887351989746
INFO:root:current mean train loss 2067.834909303161
INFO:root:current train perplexity5.121801853179932
INFO:root:current mean train loss 2066.4220648364485
INFO:root:current train perplexity5.110357761383057
INFO:root:current mean train loss 2069.353586752584
INFO:root:current train perplexity5.109114646911621
INFO:root:current mean train loss 2071.454756756218
INFO:root:current train perplexity5.1121625900268555
INFO:root:current mean train loss 2071.673133420659
INFO:root:current train perplexity5.114623069763184
INFO:root:current mean train loss 2073.2774275672627
INFO:root:current train perplexity5.117019176483154
INFO:root:current mean train loss 2071.6203049516907
INFO:root:current train perplexity5.114456653594971
INFO:root:current mean train loss 2068.5321673019344
INFO:root:current train perplexity5.106546401977539
INFO:root:current mean train loss 2066.195786646793
INFO:root:current train perplexity5.101171016693115
INFO:root:current mean train loss 2066.9897805660403
INFO:root:current train perplexity5.103057861328125
INFO:root:current mean train loss 2066.396829659598
INFO:root:current train perplexity5.101017475128174
INFO:root:current mean train loss 2066.8970676881872
INFO:root:current train perplexity5.099355697631836
INFO:root:current mean train loss 2065.879688395929
INFO:root:current train perplexity5.097470760345459
INFO:root:current mean train loss 2064.327015391413
INFO:root:current train perplexity5.092183589935303
INFO:root:current mean train loss 2062.646540653738
INFO:root:current train perplexity5.0863800048828125
INFO:root:current mean train loss 2062.6910744837087
INFO:root:current train perplexity5.086200714111328

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.12s/it]
INFO:root:final mean train loss: 2063.0238358444235
INFO:root:final train perplexity: 5.088712215423584
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.79s/it]
INFO:root:eval mean loss: 3162.599580781954
INFO:root:eval perplexity: 13.398516654968262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/9
  9%|â–‰         | 9/100 [49:17<8:21:00, 330.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2013.2885953463042
INFO:root:current train perplexity4.92449951171875
INFO:root:current mean train loss 2022.2394433272511
INFO:root:current train perplexity4.899397850036621
INFO:root:current mean train loss 2033.925001356337
INFO:root:current train perplexity4.949057579040527
INFO:root:current mean train loss 2028.4556999206543
INFO:root:current train perplexity4.949825286865234
INFO:root:current mean train loss 2034.5456826539166
INFO:root:current train perplexity4.963842868804932
INFO:root:current mean train loss 2036.396678979846
INFO:root:current train perplexity4.969356536865234
INFO:root:current mean train loss 2039.1091565091185
INFO:root:current train perplexity4.975974082946777
INFO:root:current mean train loss 2035.630647212901
INFO:root:current train perplexity4.967495918273926
INFO:root:current mean train loss 2034.708670029618
INFO:root:current train perplexity4.967188835144043
INFO:root:current mean train loss 2031.30600578244
INFO:root:current train perplexity4.959776878356934
INFO:root:current mean train loss 2032.1920149770526
INFO:root:current train perplexity4.961853504180908
INFO:root:current mean train loss 2031.2235150867039
INFO:root:current train perplexity4.954511642456055
INFO:root:current mean train loss 2030.7799071290622
INFO:root:current train perplexity4.9539313316345215
INFO:root:current mean train loss 2031.2453771286462
INFO:root:current train perplexity4.958289623260498
INFO:root:current mean train loss 2029.6820587914838
INFO:root:current train perplexity4.953378677368164
INFO:root:current mean train loss 2026.910828816522
INFO:root:current train perplexity4.9456586837768555
INFO:root:current mean train loss 2026.470640981457
INFO:root:current train perplexity4.941468715667725
INFO:root:current mean train loss 2027.8349403137486
INFO:root:current train perplexity4.944356441497803
INFO:root:current mean train loss 2025.8557134179266
INFO:root:current train perplexity4.939074516296387
INFO:root:current mean train loss 2025.800627661533
INFO:root:current train perplexity4.938608169555664

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.91s/it]
INFO:root:final mean train loss: 2024.916774332313
INFO:root:final train perplexity: 4.938053131103516
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.71s/it]
INFO:root:eval mean loss: 3173.9778748475037
INFO:root:eval perplexity: 13.524201393127441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/10
 10%|â–ˆ         | 10/100 [54:48<8:15:45, 330.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2014.2538231006567
INFO:root:current train perplexity4.853059768676758
INFO:root:current mean train loss 2013.0288851585615
INFO:root:current train perplexity4.831699848175049
INFO:root:current mean train loss 1995.673121115532
INFO:root:current train perplexity4.7993950843811035
INFO:root:current mean train loss 1995.7417551262915
INFO:root:current train perplexity4.806951999664307
INFO:root:current mean train loss 1997.1104642628097
INFO:root:current train perplexity4.809699535369873
INFO:root:current mean train loss 2000.5001769912265
INFO:root:current train perplexity4.819457530975342
INFO:root:current mean train loss 1996.3176399082702
INFO:root:current train perplexity4.8117570877075195
INFO:root:current mean train loss 1997.8620740396923
INFO:root:current train perplexity4.821549892425537
INFO:root:current mean train loss 1998.9102382857452
INFO:root:current train perplexity4.8177618980407715
INFO:root:current mean train loss 1997.9689371996742
INFO:root:current train perplexity4.818340301513672
INFO:root:current mean train loss 1996.4364005678497
INFO:root:current train perplexity4.818907737731934
INFO:root:current mean train loss 1995.9975688271893
INFO:root:current train perplexity4.817632675170898
INFO:root:current mean train loss 1994.8618099612454
INFO:root:current train perplexity4.813024520874023
INFO:root:current mean train loss 1995.5229453845473
INFO:root:current train perplexity4.815523624420166
INFO:root:current mean train loss 1996.1888923826796
INFO:root:current train perplexity4.816504001617432
INFO:root:current mean train loss 1994.1125431486266
INFO:root:current train perplexity4.812420845031738
INFO:root:current mean train loss 1993.0435170058793
INFO:root:current train perplexity4.810526371002197
INFO:root:current mean train loss 1991.8993669319045
INFO:root:current train perplexity4.809086799621582
INFO:root:current mean train loss 1991.0090855842864
INFO:root:current train perplexity4.808056354522705
INFO:root:current mean train loss 1992.3357919331672
INFO:root:current train perplexity4.811135768890381

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.95s/it]
INFO:root:final mean train loss: 1991.9540809712144
INFO:root:final train perplexity: 4.811336040496826
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.82s/it]
INFO:root:eval mean loss: 3173.4318041185716
INFO:root:eval perplexity: 13.51814079284668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/11
 11%|â–ˆ         | 11/100 [1:00:20<8:10:43, 330.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1996.588194381359
INFO:root:current train perplexity4.767088413238525
INFO:root:current mean train loss 1965.193572669901
INFO:root:current train perplexity4.7088775634765625
INFO:root:current mean train loss 1965.3641259253443
INFO:root:current train perplexity4.7049431800842285
INFO:root:current mean train loss 1974.709267413678
INFO:root:current train perplexity4.730841159820557
INFO:root:current mean train loss 1969.0788222575875
INFO:root:current train perplexity4.711085319519043
INFO:root:current mean train loss 1967.8788060523543
INFO:root:current train perplexity4.704358100891113
INFO:root:current mean train loss 1968.8906274912308
INFO:root:current train perplexity4.707442283630371
INFO:root:current mean train loss 1968.6638439848223
INFO:root:current train perplexity4.712502479553223
INFO:root:current mean train loss 1966.6176405103697
INFO:root:current train perplexity4.710165023803711
INFO:root:current mean train loss 1966.4243011784117
INFO:root:current train perplexity4.712057113647461
INFO:root:current mean train loss 1962.8783333288372
INFO:root:current train perplexity4.703495502471924
INFO:root:current mean train loss 1965.5583144086609
INFO:root:current train perplexity4.707090377807617
INFO:root:current mean train loss 1964.1317664542428
INFO:root:current train perplexity4.704524993896484
INFO:root:current mean train loss 1964.0346957120028
INFO:root:current train perplexity4.704844951629639
INFO:root:current mean train loss 1963.456631523122
INFO:root:current train perplexity4.702754974365234
INFO:root:current mean train loss 1962.8810553340263
INFO:root:current train perplexity4.6998772621154785
INFO:root:current mean train loss 1962.9062878664138
INFO:root:current train perplexity4.6998114585876465
INFO:root:current mean train loss 1963.092662507983
INFO:root:current train perplexity4.701227188110352
INFO:root:current mean train loss 1963.0406782811672
INFO:root:current train perplexity4.700885772705078

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.32s/it]
INFO:root:final mean train loss: 1962.7581198918838
INFO:root:final train perplexity: 4.701817035675049
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.61s/it]
INFO:root:eval mean loss: 3187.460237336946
INFO:root:eval perplexity: 13.67464828491211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/12
 12%|â–ˆâ–        | 12/100 [1:05:52<8:05:43, 331.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1852.5569254557292
INFO:root:current train perplexity4.3743109703063965
INFO:root:current mean train loss 1934.5482841417627
INFO:root:current train perplexity4.590498447418213
INFO:root:current mean train loss 1940.066476605796
INFO:root:current train perplexity4.6110944747924805
INFO:root:current mean train loss 1936.641114489867
INFO:root:current train perplexity4.608360767364502
INFO:root:current mean train loss 1932.1446887600807
INFO:root:current train perplexity4.603464126586914
INFO:root:current mean train loss 1935.399465996987
INFO:root:current train perplexity4.612293243408203
INFO:root:current mean train loss 1933.4317564197243
INFO:root:current train perplexity4.609871864318848
INFO:root:current mean train loss 1932.0335790598883
INFO:root:current train perplexity4.6064252853393555
INFO:root:current mean train loss 1931.719633375574
INFO:root:current train perplexity4.602205753326416
INFO:root:current mean train loss 1935.4213917205236
INFO:root:current train perplexity4.608347415924072
INFO:root:current mean train loss 1934.7573944426485
INFO:root:current train perplexity4.605044841766357
INFO:root:current mean train loss 1933.7987483310785
INFO:root:current train perplexity4.602700233459473
INFO:root:current mean train loss 1932.4938468647717
INFO:root:current train perplexity4.60302209854126
INFO:root:current mean train loss 1931.4528554709984
INFO:root:current train perplexity4.600428104400635
INFO:root:current mean train loss 1931.9020174751092
INFO:root:current train perplexity4.60050106048584
INFO:root:current mean train loss 1932.2196705222368
INFO:root:current train perplexity4.596800327301025
INFO:root:current mean train loss 1934.1295753902596
INFO:root:current train perplexity4.598201274871826
INFO:root:current mean train loss 1933.0173390019452
INFO:root:current train perplexity4.596500396728516
INFO:root:current mean train loss 1934.2582279317458
INFO:root:current train perplexity4.599548816680908
INFO:root:current mean train loss 1935.076719876408
INFO:root:current train perplexity4.6006999015808105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.14s/it]
INFO:root:final mean train loss: 1935.2927173762628
INFO:root:final train perplexity: 4.601067066192627
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.79s/it]
INFO:root:eval mean loss: 3182.5131945910753
INFO:root:eval perplexity: 13.619251251220703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/13
 13%|â–ˆâ–Ž        | 13/100 [1:11:23<8:00:28, 331.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1972.222314453125
INFO:root:current train perplexity4.5698957443237305
INFO:root:current mean train loss 1919.8373748779297
INFO:root:current train perplexity4.513018608093262
INFO:root:current mean train loss 1924.2880010431463
INFO:root:current train perplexity4.5303144454956055
INFO:root:current mean train loss 1914.887869644165
INFO:root:current train perplexity4.514323711395264
INFO:root:current mean train loss 1917.3605872744606
INFO:root:current train perplexity4.513657569885254
INFO:root:current mean train loss 1918.3310560960035
INFO:root:current train perplexity4.526289463043213
INFO:root:current mean train loss 1917.9163747479838
INFO:root:current train perplexity4.524543285369873
INFO:root:current mean train loss 1918.8874096340603
INFO:root:current train perplexity4.526448726654053
INFO:root:current mean train loss 1919.2685828232184
INFO:root:current train perplexity4.527936935424805
INFO:root:current mean train loss 1919.780896394149
INFO:root:current train perplexity4.528647422790527
INFO:root:current mean train loss 1917.3707338819318
INFO:root:current train perplexity4.526696681976318
INFO:root:current mean train loss 1917.8748209272112
INFO:root:current train perplexity4.52871561050415
INFO:root:current mean train loss 1915.2337077156442
INFO:root:current train perplexity4.52711296081543
INFO:root:current mean train loss 1913.8764204545455
INFO:root:current train perplexity4.5252838134765625
INFO:root:current mean train loss 1913.1827126086598
INFO:root:current train perplexity4.520048141479492
INFO:root:current mean train loss 1911.9521102102178
INFO:root:current train perplexity4.517614364624023
INFO:root:current mean train loss 1911.562953167197
INFO:root:current train perplexity4.514828205108643
INFO:root:current mean train loss 1911.1563966972883
INFO:root:current train perplexity4.513090133666992
INFO:root:current mean train loss 1911.5090714339372
INFO:root:current train perplexity4.514758110046387
INFO:root:current mean train loss 1912.3851654052735
INFO:root:current train perplexity4.515634059906006

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.59s/it]
INFO:root:final mean train loss: 1911.218659663044
INFO:root:final train perplexity: 4.514533996582031
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.18s/it]
INFO:root:eval mean loss: 3204.0092113597975
INFO:root:eval perplexity: 13.861610412597656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/14
 14%|â–ˆâ–        | 14/100 [1:16:55<7:55:01, 331.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1874.3283724398227
INFO:root:current train perplexity4.40802001953125
INFO:root:current mean train loss 1868.1058403070826
INFO:root:current train perplexity4.40766716003418
INFO:root:current mean train loss 1885.0559236550632
INFO:root:current train perplexity4.436407089233398
INFO:root:current mean train loss 1881.7020245560552
INFO:root:current train perplexity4.431403636932373
INFO:root:current mean train loss 1880.0753165448011
INFO:root:current train perplexity4.435294151306152
INFO:root:current mean train loss 1883.5687926450478
INFO:root:current train perplexity4.438870906829834
INFO:root:current mean train loss 1883.0408571443902
INFO:root:current train perplexity4.432096004486084
INFO:root:current mean train loss 1880.5137656223499
INFO:root:current train perplexity4.429917812347412
INFO:root:current mean train loss 1881.960748196218
INFO:root:current train perplexity4.43201208114624
INFO:root:current mean train loss 1882.8615024367161
INFO:root:current train perplexity4.434374809265137
INFO:root:current mean train loss 1883.4023237384733
INFO:root:current train perplexity4.435817718505859
INFO:root:current mean train loss 1885.7622998991658
INFO:root:current train perplexity4.437716007232666
INFO:root:current mean train loss 1887.5658798772863
INFO:root:current train perplexity4.4412970542907715
INFO:root:current mean train loss 1887.551752517004
INFO:root:current train perplexity4.440789222717285
INFO:root:current mean train loss 1887.701542927975
INFO:root:current train perplexity4.437044620513916
INFO:root:current mean train loss 1888.816098890137
INFO:root:current train perplexity4.441767692565918
INFO:root:current mean train loss 1888.9587003396791
INFO:root:current train perplexity4.441270351409912
INFO:root:current mean train loss 1889.7479045650502
INFO:root:current train perplexity4.439332485198975
INFO:root:current mean train loss 1889.696614937738
INFO:root:current train perplexity4.437641620635986
INFO:root:current mean train loss 1890.6863317927812
INFO:root:current train perplexity4.43904447555542

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.01s/it]
INFO:root:final mean train loss: 1889.6143082288318
INFO:root:final train perplexity: 4.438265323638916
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.86s/it]
INFO:root:eval mean loss: 3196.828420461477
INFO:root:eval perplexity: 13.780174255371094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/15
 15%|â–ˆâ–Œ        | 15/100 [1:22:26<7:49:10, 331.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1882.2126577871818
INFO:root:current train perplexity4.368710041046143
INFO:root:current mean train loss 1871.9671400986708
INFO:root:current train perplexity4.335297584533691
INFO:root:current mean train loss 1868.6778872031866
INFO:root:current train perplexity4.357176303863525
INFO:root:current mean train loss 1864.6733457058835
INFO:root:current train perplexity4.360686302185059
INFO:root:current mean train loss 1865.5360967829365
INFO:root:current train perplexity4.360853672027588
INFO:root:current mean train loss 1864.0221026589293
INFO:root:current train perplexity4.359341144561768
INFO:root:current mean train loss 1865.6478527197414
INFO:root:current train perplexity4.359569072723389
INFO:root:current mean train loss 1866.7481775258518
INFO:root:current train perplexity4.364260673522949
INFO:root:current mean train loss 1867.9685487412178
INFO:root:current train perplexity4.364538192749023
INFO:root:current mean train loss 1866.2058563552312
INFO:root:current train perplexity4.361637115478516
INFO:root:current mean train loss 1866.714145262282
INFO:root:current train perplexity4.361724376678467
INFO:root:current mean train loss 1865.9329496545643
INFO:root:current train perplexity4.3622822761535645
INFO:root:current mean train loss 1867.4947249855152
INFO:root:current train perplexity4.36514139175415
INFO:root:current mean train loss 1869.6609733277269
INFO:root:current train perplexity4.370297431945801
INFO:root:current mean train loss 1869.2344629006996
INFO:root:current train perplexity4.367587566375732
INFO:root:current mean train loss 1869.5242370841127
INFO:root:current train perplexity4.3691792488098145
INFO:root:current mean train loss 1868.6816221742272
INFO:root:current train perplexity4.36716365814209
INFO:root:current mean train loss 1868.627872828067
INFO:root:current train perplexity4.366308212280273
INFO:root:current mean train loss 1868.3135702550862
INFO:root:current train perplexity4.365810394287109
INFO:root:current mean train loss 1869.5915339302992
INFO:root:current train perplexity4.367055892944336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.96s/it]
INFO:root:final mean train loss: 1869.3905209662994
INFO:root:final train perplexity: 4.36803674697876
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.59s/it]
INFO:root:eval mean loss: 3207.383684221331
INFO:root:eval perplexity: 13.900046348571777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/16
 16%|â–ˆâ–Œ        | 16/100 [1:27:57<7:43:45, 331.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1869.7600768183318
INFO:root:current train perplexity4.377063751220703
INFO:root:current mean train loss 1845.1716051603619
INFO:root:current train perplexity4.309237480163574
INFO:root:current mean train loss 1842.8424752436001
INFO:root:current train perplexity4.310059547424316
INFO:root:current mean train loss 1844.2282971487534
INFO:root:current train perplexity4.305222511291504
INFO:root:current mean train loss 1846.2309207470807
INFO:root:current train perplexity4.3041253089904785
INFO:root:current mean train loss 1846.7233613076019
INFO:root:current train perplexity4.298470973968506
INFO:root:current mean train loss 1845.4732897057795
INFO:root:current train perplexity4.296292781829834
INFO:root:current mean train loss 1848.0694257090527
INFO:root:current train perplexity4.297242164611816
INFO:root:current mean train loss 1847.1176159373654
INFO:root:current train perplexity4.298227310180664
INFO:root:current mean train loss 1848.1548564372667
INFO:root:current train perplexity4.298286437988281
INFO:root:current mean train loss 1847.6350386020295
INFO:root:current train perplexity4.294922828674316
INFO:root:current mean train loss 1848.802954643634
INFO:root:current train perplexity4.29556941986084
INFO:root:current mean train loss 1847.7228512167462
INFO:root:current train perplexity4.2951202392578125
INFO:root:current mean train loss 1848.048322125302
INFO:root:current train perplexity4.298030376434326
INFO:root:current mean train loss 1847.8737861845948
INFO:root:current train perplexity4.298555850982666
INFO:root:current mean train loss 1848.686929432015
INFO:root:current train perplexity4.300861358642578
INFO:root:current mean train loss 1848.300264770581
INFO:root:current train perplexity4.296887397766113
INFO:root:current mean train loss 1849.1971526530958
INFO:root:current train perplexity4.299774646759033
INFO:root:current mean train loss 1849.1589029251988
INFO:root:current train perplexity4.3006134033203125
INFO:root:current mean train loss 1850.7471201067826
INFO:root:current train perplexity4.303218364715576

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.81s/it]
INFO:root:final mean train loss: 1850.5839550424212
INFO:root:final train perplexity: 4.303729057312012
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.89s/it]
INFO:root:eval mean loss: 3205.95787951037
INFO:root:eval perplexity: 13.883790969848633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/17
 17%|â–ˆâ–‹        | 17/100 [1:33:29<7:38:19, 331.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1817.6566120494497
INFO:root:current train perplexity4.206907272338867
INFO:root:current mean train loss 1823.1174452761386
INFO:root:current train perplexity4.215573310852051
INFO:root:current mean train loss 1830.9836633470322
INFO:root:current train perplexity4.228092670440674
INFO:root:current mean train loss 1824.0187711420747
INFO:root:current train perplexity4.221409797668457
INFO:root:current mean train loss 1828.3208633172708
INFO:root:current train perplexity4.237218856811523
INFO:root:current mean train loss 1830.257351414687
INFO:root:current train perplexity4.238678932189941
INFO:root:current mean train loss 1831.4240302152411
INFO:root:current train perplexity4.243659496307373
INFO:root:current mean train loss 1829.1244858485188
INFO:root:current train perplexity4.2402801513671875
INFO:root:current mean train loss 1829.9781135352882
INFO:root:current train perplexity4.240842819213867
INFO:root:current mean train loss 1833.5649575916862
INFO:root:current train perplexity4.244584083557129
INFO:root:current mean train loss 1834.6865542916692
INFO:root:current train perplexity4.243694305419922
INFO:root:current mean train loss 1834.2528043290984
INFO:root:current train perplexity4.239680290222168
INFO:root:current mean train loss 1831.8918943227447
INFO:root:current train perplexity4.2366042137146
INFO:root:current mean train loss 1830.9429290507644
INFO:root:current train perplexity4.234013080596924
INFO:root:current mean train loss 1831.304207258327
INFO:root:current train perplexity4.234478950500488
INFO:root:current mean train loss 1831.5284765133028
INFO:root:current train perplexity4.237475395202637
INFO:root:current mean train loss 1832.7130230365772
INFO:root:current train perplexity4.241251468658447
INFO:root:current mean train loss 1832.5857984299628
INFO:root:current train perplexity4.242623805999756
INFO:root:current mean train loss 1832.5770495139946
INFO:root:current train perplexity4.242980003356934

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.43s/it]
INFO:root:final mean train loss: 1832.7518875037429
INFO:root:final train perplexity: 4.243627071380615
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.19s/it]
INFO:root:eval mean loss: 3218.873727976023
INFO:root:eval perplexity: 14.031723022460938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/18
 18%|â–ˆâ–Š        | 18/100 [1:38:59<7:32:25, 331.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1838.4855712890626
INFO:root:current train perplexity4.255918502807617
INFO:root:current mean train loss 1813.4126057942708
INFO:root:current train perplexity4.186871528625488
INFO:root:current mean train loss 1817.3273788824315
INFO:root:current train perplexity4.188565731048584
INFO:root:current mean train loss 1821.5776659355788
INFO:root:current train perplexity4.201056003570557
INFO:root:current mean train loss 1817.2079399956597
INFO:root:current train perplexity4.194500923156738
INFO:root:current mean train loss 1815.3248602838798
INFO:root:current train perplexity4.189294338226318
INFO:root:current mean train loss 1819.2079842055139
INFO:root:current train perplexity4.196333885192871
INFO:root:current mean train loss 1819.1691324869792
INFO:root:current train perplexity4.199963092803955
INFO:root:current mean train loss 1819.6439868618984
INFO:root:current train perplexity4.197178363800049
INFO:root:current mean train loss 1821.2685866550846
INFO:root:current train perplexity4.201991558074951
INFO:root:current mean train loss 1823.7696700822062
INFO:root:current train perplexity4.207041263580322
INFO:root:current mean train loss 1821.3484192723063
INFO:root:current train perplexity4.199673652648926
INFO:root:current mean train loss 1820.3142750340378
INFO:root:current train perplexity4.196098804473877
INFO:root:current mean train loss 1819.2033163838003
INFO:root:current train perplexity4.194594383239746
INFO:root:current mean train loss 1818.4189888407752
INFO:root:current train perplexity4.191571235656738
INFO:root:current mean train loss 1816.8804650189472
INFO:root:current train perplexity4.189918041229248
INFO:root:current mean train loss 1815.851593302789
INFO:root:current train perplexity4.188195705413818
INFO:root:current mean train loss 1816.2945903162802
INFO:root:current train perplexity4.188622951507568
INFO:root:current mean train loss 1815.4794680439534
INFO:root:current train perplexity4.186824321746826
INFO:root:current mean train loss 1815.8585647222565
INFO:root:current train perplexity4.188129425048828

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.61s/it]
INFO:root:final mean train loss: 1816.66896304132
INFO:root:final train perplexity: 4.190141201019287
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.67s/it]
INFO:root:eval mean loss: 3210.8827516481324
INFO:root:eval perplexity: 13.940014839172363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/19
 19%|â–ˆâ–‰        | 19/100 [1:44:31<7:27:19, 331.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1763.7182783647017
INFO:root:current train perplexity4.064560890197754
INFO:root:current mean train loss 1787.693314349065
INFO:root:current train perplexity4.080710411071777
INFO:root:current mean train loss 1784.5108780044693
INFO:root:current train perplexity4.085965156555176
INFO:root:current mean train loss 1786.1959376364762
INFO:root:current train perplexity4.090378284454346
INFO:root:current mean train loss 1795.1181487313945
INFO:root:current train perplexity4.099337577819824
INFO:root:current mean train loss 1796.7462922896461
INFO:root:current train perplexity4.108656406402588
INFO:root:current mean train loss 1796.614656994197
INFO:root:current train perplexity4.113947868347168
INFO:root:current mean train loss 1795.551491016166
INFO:root:current train perplexity4.117258548736572
INFO:root:current mean train loss 1798.1258540466754
INFO:root:current train perplexity4.119751930236816
INFO:root:current mean train loss 1799.3759929797654
INFO:root:current train perplexity4.122202396392822
INFO:root:current mean train loss 1798.2769366897016
INFO:root:current train perplexity4.12369966506958
INFO:root:current mean train loss 1798.3799740932418
INFO:root:current train perplexity4.126065731048584
INFO:root:current mean train loss 1799.5583336263553
INFO:root:current train perplexity4.129153728485107
INFO:root:current mean train loss 1801.4307718204839
INFO:root:current train perplexity4.134403705596924
INFO:root:current mean train loss 1801.6672465435731
INFO:root:current train perplexity4.134137153625488
INFO:root:current mean train loss 1802.5121503271034
INFO:root:current train perplexity4.137030601501465
INFO:root:current mean train loss 1802.0010333078858
INFO:root:current train perplexity4.135713577270508
INFO:root:current mean train loss 1802.066694908718
INFO:root:current train perplexity4.138371467590332
INFO:root:current mean train loss 1802.517432069412
INFO:root:current train perplexity4.140056133270264
INFO:root:current mean train loss 1802.706103718864
INFO:root:current train perplexity4.140462398529053

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.11s/it]
INFO:root:final mean train loss: 1800.801980099892
INFO:root:final train perplexity: 4.138034343719482
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.61s/it]
INFO:root:eval mean loss: 3230.023583397851
INFO:root:eval perplexity: 14.160689353942871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/20
 20%|â–ˆâ–ˆ        | 20/100 [1:50:02<7:21:28, 331.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1770.7852188501602
INFO:root:current train perplexity4.068142890930176
INFO:root:current mean train loss 1796.8763375042154
INFO:root:current train perplexity4.083477973937988
INFO:root:current mean train loss 1793.3342632469273
INFO:root:current train perplexity4.081436634063721
INFO:root:current mean train loss 1792.0181729927176
INFO:root:current train perplexity4.080888271331787
INFO:root:current mean train loss 1790.5921044143295
INFO:root:current train perplexity4.083502292633057
INFO:root:current mean train loss 1791.0873516132306
INFO:root:current train perplexity4.090524196624756
INFO:root:current mean train loss 1789.0206061946767
INFO:root:current train perplexity4.093015670776367
INFO:root:current mean train loss 1790.3967146402445
INFO:root:current train perplexity4.094638347625732
INFO:root:current mean train loss 1789.04467904383
INFO:root:current train perplexity4.094746112823486
INFO:root:current mean train loss 1789.5059947053464
INFO:root:current train perplexity4.094181060791016
INFO:root:current mean train loss 1789.3093825662445
INFO:root:current train perplexity4.094372272491455
INFO:root:current mean train loss 1789.9055404060236
INFO:root:current train perplexity4.095685005187988
INFO:root:current mean train loss 1788.2925902236557
INFO:root:current train perplexity4.092073440551758
INFO:root:current mean train loss 1789.3797681265753
INFO:root:current train perplexity4.094009876251221
INFO:root:current mean train loss 1789.932368720547
INFO:root:current train perplexity4.09749174118042
INFO:root:current mean train loss 1790.908224858116
INFO:root:current train perplexity4.1004180908203125
INFO:root:current mean train loss 1789.4465603877888
INFO:root:current train perplexity4.097697734832764
INFO:root:current mean train loss 1789.6243987738778
INFO:root:current train perplexity4.098952770233154
INFO:root:current mean train loss 1789.4605779933047
INFO:root:current train perplexity4.09782075881958
INFO:root:current mean train loss 1788.4232074487695
INFO:root:current train perplexity4.096482276916504

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.24s/it]
INFO:root:final mean train loss: 1787.3865227172666
INFO:root:final train perplexity: 4.094483375549316
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.90s/it]
INFO:root:eval mean loss: 3220.974778733812
INFO:root:eval perplexity: 14.055941581726074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/21
 21%|â–ˆâ–ˆ        | 21/100 [1:55:32<7:15:52, 331.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1744.5453578404017
INFO:root:current train perplexity4.018573760986328
INFO:root:current mean train loss 1756.606477395082
INFO:root:current train perplexity4.028645992279053
INFO:root:current mean train loss 1763.0877451896667
INFO:root:current train perplexity4.04154109954834
INFO:root:current mean train loss 1767.3241697161386
INFO:root:current train perplexity4.047112464904785
INFO:root:current mean train loss 1767.8967844645183
INFO:root:current train perplexity4.045156955718994
INFO:root:current mean train loss 1767.8309517181176
INFO:root:current train perplexity4.036308765411377
INFO:root:current mean train loss 1767.4192998002216
INFO:root:current train perplexity4.038327693939209
INFO:root:current mean train loss 1768.8609220313017
INFO:root:current train perplexity4.038469314575195
INFO:root:current mean train loss 1769.4254371429158
INFO:root:current train perplexity4.041233062744141
INFO:root:current mean train loss 1771.218642230812
INFO:root:current train perplexity4.042599201202393
INFO:root:current mean train loss 1771.1792936614065
INFO:root:current train perplexity4.043213844299316
INFO:root:current mean train loss 1771.440754293158
INFO:root:current train perplexity4.0427680015563965
INFO:root:current mean train loss 1771.093272506811
INFO:root:current train perplexity4.040644645690918
INFO:root:current mean train loss 1772.3245545333818
INFO:root:current train perplexity4.044305324554443
INFO:root:current mean train loss 1772.577886057424
INFO:root:current train perplexity4.043284893035889
INFO:root:current mean train loss 1773.2048299833557
INFO:root:current train perplexity4.045075416564941
INFO:root:current mean train loss 1773.7924414003528
INFO:root:current train perplexity4.044901371002197
INFO:root:current mean train loss 1774.1968999006754
INFO:root:current train perplexity4.04688835144043
INFO:root:current mean train loss 1774.5089183018126
INFO:root:current train perplexity4.04813814163208
INFO:root:current mean train loss 1774.0910779956903
INFO:root:current train perplexity4.049663543701172

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.47s/it]
INFO:root:final mean train loss: 1773.7910363701817
INFO:root:final train perplexity: 4.050815582275391
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.69s/it]
INFO:root:eval mean loss: 3229.78711084131
INFO:root:eval perplexity: 14.157944679260254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/22
 22%|â–ˆâ–ˆâ–       | 22/100 [2:01:03<7:10:17, 331.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1753.4290420323202
INFO:root:current train perplexity4.003830909729004
INFO:root:current mean train loss 1758.7272377675667
INFO:root:current train perplexity3.9963924884796143
INFO:root:current mean train loss 1758.347380362151
INFO:root:current train perplexity3.997992992401123
INFO:root:current mean train loss 1756.7870828664334
INFO:root:current train perplexity4.001194000244141
INFO:root:current mean train loss 1754.666021044612
INFO:root:current train perplexity3.9883198738098145
INFO:root:current mean train loss 1756.6914301101658
INFO:root:current train perplexity3.994457721710205
INFO:root:current mean train loss 1757.4378932369057
INFO:root:current train perplexity3.998459577560425
INFO:root:current mean train loss 1755.5180836192694
INFO:root:current train perplexity3.9964563846588135
INFO:root:current mean train loss 1755.6179832642022
INFO:root:current train perplexity3.9968554973602295
INFO:root:current mean train loss 1758.548896875803
INFO:root:current train perplexity4.002179145812988
INFO:root:current mean train loss 1760.6263786095496
INFO:root:current train perplexity4.006957530975342
INFO:root:current mean train loss 1760.412234671382
INFO:root:current train perplexity4.006371974945068
INFO:root:current mean train loss 1760.0092848233135
INFO:root:current train perplexity4.006845951080322
INFO:root:current mean train loss 1759.1512770350623
INFO:root:current train perplexity4.005684852600098
INFO:root:current mean train loss 1759.890141773936
INFO:root:current train perplexity4.004924774169922
INFO:root:current mean train loss 1761.4749851311685
INFO:root:current train perplexity4.0105791091918945
INFO:root:current mean train loss 1761.6921401311733
INFO:root:current train perplexity4.009596347808838
INFO:root:current mean train loss 1760.9075097408393
INFO:root:current train perplexity4.007682800292969
INFO:root:current mean train loss 1760.875570660788
INFO:root:current train perplexity4.007472515106201
INFO:root:current mean train loss 1761.2543408896074
INFO:root:current train perplexity4.008981704711914

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.56s/it]
INFO:root:final mean train loss: 1760.4414185616806
INFO:root:final train perplexity: 4.008391380310059
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.84s/it]
INFO:root:eval mean loss: 3244.738016581034
INFO:root:eval perplexity: 14.332708358764648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/23
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [2:06:34<7:04:50, 331.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1763.2663940429688
INFO:root:current train perplexity3.9691226482391357
INFO:root:current mean train loss 1744.6925594932154
INFO:root:current train perplexity3.9349417686462402
INFO:root:current mean train loss 1746.1430579876078
INFO:root:current train perplexity3.9467177391052246
INFO:root:current mean train loss 1750.922361716246
INFO:root:current train perplexity3.9582693576812744
INFO:root:current mean train loss 1743.3721527722416
INFO:root:current train perplexity3.947936534881592
INFO:root:current mean train loss 1746.1178175069517
INFO:root:current train perplexity3.9548537731170654
INFO:root:current mean train loss 1748.583052040874
INFO:root:current train perplexity3.9622185230255127
INFO:root:current mean train loss 1749.4037851068038
INFO:root:current train perplexity3.9606871604919434
INFO:root:current mean train loss 1748.8359479239818
INFO:root:current train perplexity3.961623430252075
INFO:root:current mean train loss 1750.8517740885416
INFO:root:current train perplexity3.9684503078460693
INFO:root:current mean train loss 1748.9175998512758
INFO:root:current train perplexity3.9675893783569336
INFO:root:current mean train loss 1747.3738776711857
INFO:root:current train perplexity3.9612371921539307
INFO:root:current mean train loss 1746.351114814226
INFO:root:current train perplexity3.9576706886291504
INFO:root:current mean train loss 1746.2119246009443
INFO:root:current train perplexity3.95965313911438
INFO:root:current mean train loss 1746.4828013580118
INFO:root:current train perplexity3.9616622924804688
INFO:root:current mean train loss 1748.1822961963198
INFO:root:current train perplexity3.966261386871338
INFO:root:current mean train loss 1747.6238316643166
INFO:root:current train perplexity3.967294692993164
INFO:root:current mean train loss 1748.0161842729792
INFO:root:current train perplexity3.9686849117279053
INFO:root:current mean train loss 1748.667618233817
INFO:root:current train perplexity3.9703822135925293

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.11s/it]
INFO:root:final mean train loss: 1748.4494171219526
INFO:root:final train perplexity: 3.9706602096557617
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.70s/it]
INFO:root:eval mean loss: 3238.702391111815
INFO:root:eval perplexity: 14.2618989944458
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/24
 24%|â–ˆâ–ˆâ–       | 24/100 [2:12:06<6:59:30, 331.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1668.1344691685267
INFO:root:current train perplexity3.8285486698150635
INFO:root:current mean train loss 1710.2585631753798
INFO:root:current train perplexity3.8786933422088623
INFO:root:current mean train loss 1719.30720026136
INFO:root:current train perplexity3.894770622253418
INFO:root:current mean train loss 1724.8768950720175
INFO:root:current train perplexity3.9098143577575684
INFO:root:current mean train loss 1726.0506990699862
INFO:root:current train perplexity3.9099481105804443
INFO:root:current mean train loss 1725.4233882384892
INFO:root:current train perplexity3.9059746265411377
INFO:root:current mean train loss 1727.5006541923008
INFO:root:current train perplexity3.913893699645996
INFO:root:current mean train loss 1730.326766514542
INFO:root:current train perplexity3.9204862117767334
INFO:root:current mean train loss 1729.2671325002905
INFO:root:current train perplexity3.9177474975585938
INFO:root:current mean train loss 1730.7236909540381
INFO:root:current train perplexity3.920745611190796
INFO:root:current mean train loss 1731.2694871252793
INFO:root:current train perplexity3.9243364334106445
INFO:root:current mean train loss 1732.1474542109515
INFO:root:current train perplexity3.9239959716796875
INFO:root:current mean train loss 1735.584205254505
INFO:root:current train perplexity3.9331510066986084
INFO:root:current mean train loss 1735.1508289386775
INFO:root:current train perplexity3.9314935207366943
INFO:root:current mean train loss 1735.2928760043255
INFO:root:current train perplexity3.9319701194763184
INFO:root:current mean train loss 1736.3972361564004
INFO:root:current train perplexity3.9329981803894043
INFO:root:current mean train loss 1738.6441559996306
INFO:root:current train perplexity3.936884641647339
INFO:root:current mean train loss 1737.8122893268069
INFO:root:current train perplexity3.93636417388916
INFO:root:current mean train loss 1737.8010286332233
INFO:root:current train perplexity3.9365735054016113
INFO:root:current mean train loss 1737.3069819993977
INFO:root:current train perplexity3.9355061054229736

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.30s/it]
INFO:root:final mean train loss: 1736.6943083901149
INFO:root:final train perplexity: 3.934019088745117
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.15s/it]
INFO:root:eval mean loss: 3261.2671243020363
INFO:root:eval perplexity: 14.528436660766602
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/25
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [2:17:37<6:54:00, 331.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1701.8993835449219
INFO:root:current train perplexity3.844226360321045
INFO:root:current mean train loss 1698.7686265514742
INFO:root:current train perplexity3.875283718109131
INFO:root:current mean train loss 1713.4825984409877
INFO:root:current train perplexity3.8973138332366943
INFO:root:current mean train loss 1719.901134726442
INFO:root:current train perplexity3.8914430141448975
INFO:root:current mean train loss 1717.3224789601452
INFO:root:current train perplexity3.883413791656494
INFO:root:current mean train loss 1719.3994997912691
INFO:root:current train perplexity3.8847925662994385
INFO:root:current mean train loss 1723.138628054888
INFO:root:current train perplexity3.8934576511383057
INFO:root:current mean train loss 1724.7598435206967
INFO:root:current train perplexity3.897498369216919
INFO:root:current mean train loss 1725.891795926881
INFO:root:current train perplexity3.898158073425293
INFO:root:current mean train loss 1724.7229274733243
INFO:root:current train perplexity3.893455743789673
INFO:root:current mean train loss 1725.8638714551926
INFO:root:current train perplexity3.8996834754943848
INFO:root:current mean train loss 1726.240533143176
INFO:root:current train perplexity3.896925449371338
INFO:root:current mean train loss 1725.1641668182572
INFO:root:current train perplexity3.8934953212738037
INFO:root:current mean train loss 1725.1985706894059
INFO:root:current train perplexity3.895371913909912
INFO:root:current mean train loss 1726.3055396776522
INFO:root:current train perplexity3.8975586891174316
INFO:root:current mean train loss 1726.7323787018383
INFO:root:current train perplexity3.8986217975616455
INFO:root:current mean train loss 1727.435137668854
INFO:root:current train perplexity3.899378538131714
INFO:root:current mean train loss 1728.3530240866535
INFO:root:current train perplexity3.901618719100952
INFO:root:current mean train loss 1727.6001532705207
INFO:root:current train perplexity3.9028432369232178
INFO:root:current mean train loss 1727.8567277111283
INFO:root:current train perplexity3.9029688835144043

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.34s/it]
INFO:root:final mean train loss: 1726.3877707215433
INFO:root:final train perplexity: 3.9021718502044678
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.71s/it]
INFO:root:eval mean loss: 3253.610542182808
INFO:root:eval perplexity: 14.437443733215332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/26
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [2:23:08<6:48:24, 331.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1723.9977759384528
INFO:root:current train perplexity3.863649606704712
INFO:root:current mean train loss 1708.4780316724846
INFO:root:current train perplexity3.857893228530884
INFO:root:current mean train loss 1708.4881363864756
INFO:root:current train perplexity3.860600233078003
INFO:root:current mean train loss 1719.263504699528
INFO:root:current train perplexity3.8756895065307617
INFO:root:current mean train loss 1712.5976496067176
INFO:root:current train perplexity3.869044303894043
INFO:root:current mean train loss 1714.8632113021315
INFO:root:current train perplexity3.8713133335113525
INFO:root:current mean train loss 1715.2887979825834
INFO:root:current train perplexity3.8734705448150635
INFO:root:current mean train loss 1715.1507163105705
INFO:root:current train perplexity3.8748652935028076
INFO:root:current mean train loss 1719.433072665075
INFO:root:current train perplexity3.88230562210083
INFO:root:current mean train loss 1717.1848726992146
INFO:root:current train perplexity3.8754565715789795
INFO:root:current mean train loss 1715.1702629917522
INFO:root:current train perplexity3.8714537620544434
INFO:root:current mean train loss 1716.1274293169026
INFO:root:current train perplexity3.869645833969116
INFO:root:current mean train loss 1715.915075162262
INFO:root:current train perplexity3.8675765991210938
INFO:root:current mean train loss 1716.1610190258552
INFO:root:current train perplexity3.8688769340515137
INFO:root:current mean train loss 1716.4641149707506
INFO:root:current train perplexity3.870513677597046
INFO:root:current mean train loss 1716.1714124636244
INFO:root:current train perplexity3.870370626449585
INFO:root:current mean train loss 1715.4237274039742
INFO:root:current train perplexity3.8686790466308594
INFO:root:current mean train loss 1715.2064321168464
INFO:root:current train perplexity3.867802619934082
INFO:root:current mean train loss 1715.2979007619415
INFO:root:current train perplexity3.867223024368286
INFO:root:current mean train loss 1715.4718039589773
INFO:root:current train perplexity3.867652654647827

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.32s/it]
INFO:root:final mean train loss: 1715.1252232723266
INFO:root:final train perplexity: 3.8676645755767822
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.84s/it]
INFO:root:eval mean loss: 3251.549340600366
INFO:root:eval perplexity: 14.413045883178711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/27
 27%|â–ˆâ–ˆâ–‹       | 27/100 [2:28:52<6:47:26, 334.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1725.8593476394128
INFO:root:current train perplexity3.8405935764312744
INFO:root:current mean train loss 1699.5166695510284
INFO:root:current train perplexity3.8079185485839844
INFO:root:current mean train loss 1689.6535833787548
INFO:root:current train perplexity3.8115792274475098
INFO:root:current mean train loss 1689.606605231429
INFO:root:current train perplexity3.8083488941192627
INFO:root:current mean train loss 1692.991607532751
INFO:root:current train perplexity3.816537380218506
INFO:root:current mean train loss 1698.8059429866012
INFO:root:current train perplexity3.825765609741211
INFO:root:current mean train loss 1700.7604032475897
INFO:root:current train perplexity3.8290114402770996
INFO:root:current mean train loss 1702.5194278606325
INFO:root:current train perplexity3.832460641860962
INFO:root:current mean train loss 1702.9971710418488
INFO:root:current train perplexity3.8341286182403564
INFO:root:current mean train loss 1702.1522680613093
INFO:root:current train perplexity3.830634593963623
INFO:root:current mean train loss 1701.2343537703805
INFO:root:current train perplexity3.8286564350128174
INFO:root:current mean train loss 1702.5802287627173
INFO:root:current train perplexity3.829977035522461
INFO:root:current mean train loss 1703.9545189110008
INFO:root:current train perplexity3.832014799118042
INFO:root:current mean train loss 1703.3011431462285
INFO:root:current train perplexity3.8291900157928467
INFO:root:current mean train loss 1703.660000857339
INFO:root:current train perplexity3.830453634262085
INFO:root:current mean train loss 1704.430221459679
INFO:root:current train perplexity3.832103729248047
INFO:root:current mean train loss 1704.4091869763788
INFO:root:current train perplexity3.832233428955078
INFO:root:current mean train loss 1703.7677703961576
INFO:root:current train perplexity3.8306686878204346
INFO:root:current mean train loss 1704.6404974109005
INFO:root:current train perplexity3.8345842361450195
INFO:root:current mean train loss 1705.021041667498
INFO:root:current train perplexity3.8354642391204834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.64s/it]
INFO:root:final mean train loss: 1704.9738996989547
INFO:root:final train perplexity: 3.836824417114258
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.78s/it]
INFO:root:eval mean loss: 3263.881057326858
INFO:root:eval perplexity: 14.559627532958984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/28
 28%|â–ˆâ–ˆâ–Š       | 28/100 [2:34:25<6:41:14, 334.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1716.2344140625
INFO:root:current train perplexity3.844987630844116
INFO:root:current mean train loss 1700.8197698102679
INFO:root:current train perplexity3.7984254360198975
INFO:root:current mean train loss 1696.7503946200284
INFO:root:current train perplexity3.7988338470458984
INFO:root:current mean train loss 1698.2164384765624
INFO:root:current train perplexity3.80728816986084
INFO:root:current mean train loss 1699.0903058182566
INFO:root:current train perplexity3.8123416900634766
INFO:root:current mean train loss 1694.4449636973504
INFO:root:current train perplexity3.802048683166504
INFO:root:current mean train loss 1694.2268590856481
INFO:root:current train perplexity3.8027608394622803
INFO:root:current mean train loss 1698.0452335874495
INFO:root:current train perplexity3.8103108406066895
INFO:root:current mean train loss 1698.0791785714287
INFO:root:current train perplexity3.8089523315429688
INFO:root:current mean train loss 1699.1979559795673
INFO:root:current train perplexity3.809234857559204
INFO:root:current mean train loss 1699.9353348700945
INFO:root:current train perplexity3.8104074001312256
INFO:root:current mean train loss 1698.1786742644615
INFO:root:current train perplexity3.809811592102051
INFO:root:current mean train loss 1696.036510512408
INFO:root:current train perplexity3.806074619293213
INFO:root:current mean train loss 1695.017284534801
INFO:root:current train perplexity3.806654214859009
INFO:root:current mean train loss 1694.7913372285486
INFO:root:current train perplexity3.8048484325408936
INFO:root:current mean train loss 1696.4740037512402
INFO:root:current train perplexity3.807295322418213
INFO:root:current mean train loss 1696.9212314890392
INFO:root:current train perplexity3.8087871074676514
INFO:root:current mean train loss 1696.1875156800177
INFO:root:current train perplexity3.8080334663391113
INFO:root:current mean train loss 1696.347465950521
INFO:root:current train perplexity3.8090367317199707
INFO:root:current mean train loss 1695.8376378312896
INFO:root:current train perplexity3.8083157539367676

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.48s/it]
INFO:root:final mean train loss: 1695.5507462232688
INFO:root:final train perplexity: 3.808415651321411
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.83s/it]
INFO:root:eval mean loss: 3267.4671825145456
INFO:root:eval perplexity: 14.602540016174316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/29
 29%|â–ˆâ–ˆâ–‰       | 29/100 [2:40:08<6:38:46, 336.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1676.6676038659136
INFO:root:current train perplexity3.747429370880127
INFO:root:current mean train loss 1677.9622542063396
INFO:root:current train perplexity3.760571241378784
INFO:root:current mean train loss 1684.72053757759
INFO:root:current train perplexity3.762927293777466
INFO:root:current mean train loss 1685.6198895512796
INFO:root:current train perplexity3.764596939086914
INFO:root:current mean train loss 1692.6785573571678
INFO:root:current train perplexity3.7741589546203613
INFO:root:current mean train loss 1692.9458908905854
INFO:root:current train perplexity3.7797813415527344
INFO:root:current mean train loss 1692.3984001027366
INFO:root:current train perplexity3.7754874229431152
INFO:root:current mean train loss 1690.3598971896702
INFO:root:current train perplexity3.7742908000946045
INFO:root:current mean train loss 1691.659805913677
INFO:root:current train perplexity3.775702476501465
INFO:root:current mean train loss 1691.5114602119693
INFO:root:current train perplexity3.7777533531188965
INFO:root:current mean train loss 1690.3723885672432
INFO:root:current train perplexity3.775197982788086
INFO:root:current mean train loss 1690.0295421421129
INFO:root:current train perplexity3.776627540588379
INFO:root:current mean train loss 1689.707235802807
INFO:root:current train perplexity3.7768945693969727
INFO:root:current mean train loss 1689.2564438567765
INFO:root:current train perplexity3.7784197330474854
INFO:root:current mean train loss 1690.4719762725422
INFO:root:current train perplexity3.7811286449432373
INFO:root:current mean train loss 1689.744296279984
INFO:root:current train perplexity3.7804369926452637
INFO:root:current mean train loss 1688.589510365299
INFO:root:current train perplexity3.779231548309326
INFO:root:current mean train loss 1686.819997378758
INFO:root:current train perplexity3.7793116569519043
INFO:root:current mean train loss 1686.9276234665078
INFO:root:current train perplexity3.7811832427978516

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.10s/it]
INFO:root:final mean train loss: 1686.6395994985699
INFO:root:final train perplexity: 3.781744956970215
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.77s/it]
INFO:root:eval mean loss: 3270.983343450873
INFO:root:eval perplexity: 14.644730567932129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/30
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [2:45:39<6:30:55, 335.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1631.7604844835068
INFO:root:current train perplexity3.7647321224212646
INFO:root:current mean train loss 1665.1587496416284
INFO:root:current train perplexity3.7491726875305176
INFO:root:current mean train loss 1675.1938856207012
INFO:root:current train perplexity3.7552425861358643
INFO:root:current mean train loss 1675.3667798088593
INFO:root:current train perplexity3.7595999240875244
INFO:root:current mean train loss 1678.71621666794
INFO:root:current train perplexity3.755129337310791
INFO:root:current mean train loss 1673.348288425528
INFO:root:current train perplexity3.740278959274292
INFO:root:current mean train loss 1674.1374199026325
INFO:root:current train perplexity3.741229295730591
INFO:root:current mean train loss 1673.466514856422
INFO:root:current train perplexity3.7419283390045166
INFO:root:current mean train loss 1674.9731321582394
INFO:root:current train perplexity3.7430386543273926
INFO:root:current mean train loss 1675.7346015485336
INFO:root:current train perplexity3.745983362197876
INFO:root:current mean train loss 1677.2552683804743
INFO:root:current train perplexity3.7492434978485107
INFO:root:current mean train loss 1676.566549454217
INFO:root:current train perplexity3.7482664585113525
INFO:root:current mean train loss 1677.340576979619
INFO:root:current train perplexity3.7521488666534424
INFO:root:current mean train loss 1677.7989142922795
INFO:root:current train perplexity3.7526063919067383
INFO:root:current mean train loss 1678.4591940344437
INFO:root:current train perplexity3.7527804374694824
INFO:root:current mean train loss 1678.4567504640129
INFO:root:current train perplexity3.754002332687378
INFO:root:current mean train loss 1678.4901534247058
INFO:root:current train perplexity3.7540297508239746
INFO:root:current mean train loss 1678.4415784627113
INFO:root:current train perplexity3.755361795425415
INFO:root:current mean train loss 1678.026528800766
INFO:root:current train perplexity3.7549991607666016
INFO:root:current mean train loss 1677.8079426657036
INFO:root:current train perplexity3.7547078132629395

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.24s/it]
INFO:root:final mean train loss: 1677.4788064268942
INFO:root:final train perplexity: 3.754521131515503
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.75s/it]
INFO:root:eval mean loss: 3276.849947359469
INFO:root:eval perplexity: 14.715398788452148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/31
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [2:51:10<6:24:10, 334.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1665.253408578726
INFO:root:current train perplexity3.7311861515045166
INFO:root:current mean train loss 1662.6516956147693
INFO:root:current train perplexity3.70815372467041
INFO:root:current mean train loss 1664.2086883814989
INFO:root:current train perplexity3.706845998764038
INFO:root:current mean train loss 1655.9095882111533
INFO:root:current train perplexity3.6887154579162598
INFO:root:current mean train loss 1655.6207722408672
INFO:root:current train perplexity3.6890923976898193
INFO:root:current mean train loss 1657.8086772962215
INFO:root:current train perplexity3.6938371658325195
INFO:root:current mean train loss 1660.2678064705847
INFO:root:current train perplexity3.7011332511901855
INFO:root:current mean train loss 1663.0521238552965
INFO:root:current train perplexity3.7042622566223145
INFO:root:current mean train loss 1666.9796132233184
INFO:root:current train perplexity3.7115590572357178
INFO:root:current mean train loss 1665.0385386258943
INFO:root:current train perplexity3.7097556591033936
INFO:root:current mean train loss 1665.6561840867903
INFO:root:current train perplexity3.714871406555176
INFO:root:current mean train loss 1667.7852409186626
INFO:root:current train perplexity3.7215161323547363
INFO:root:current mean train loss 1667.8700804469247
INFO:root:current train perplexity3.723238706588745
INFO:root:current mean train loss 1669.0009863207604
INFO:root:current train perplexity3.7244813442230225
INFO:root:current mean train loss 1668.2568389336157
INFO:root:current train perplexity3.7256624698638916
INFO:root:current mean train loss 1667.1391986331964
INFO:root:current train perplexity3.725632667541504
INFO:root:current mean train loss 1668.255795111662
INFO:root:current train perplexity3.7276899814605713
INFO:root:current mean train loss 1669.2016953770008
INFO:root:current train perplexity3.72995924949646
INFO:root:current mean train loss 1669.0324727755126
INFO:root:current train perplexity3.729229688644409
INFO:root:current mean train loss 1669.3087887075708
INFO:root:current train perplexity3.730900764465332

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.17s/it]
INFO:root:final mean train loss: 1669.4355409038349
INFO:root:final train perplexity: 3.7307796478271484
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.03s/it]
INFO:root:eval mean loss: 3286.862009959178
INFO:root:eval perplexity: 14.836790084838867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/32
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [2:56:41<6:17:32, 333.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1632.0446096021076
INFO:root:current train perplexity3.6019818782806396
INFO:root:current mean train loss 1653.2178912396198
INFO:root:current train perplexity3.65564227104187
INFO:root:current mean train loss 1661.5899919423546
INFO:root:current train perplexity3.6832709312438965
INFO:root:current mean train loss 1661.9023152787902
INFO:root:current train perplexity3.69105863571167
INFO:root:current mean train loss 1657.591960829483
INFO:root:current train perplexity3.687502145767212
INFO:root:current mean train loss 1654.5834097677832
INFO:root:current train perplexity3.6852502822875977
INFO:root:current mean train loss 1651.735357447694
INFO:root:current train perplexity3.6848866939544678
INFO:root:current mean train loss 1653.7448567817862
INFO:root:current train perplexity3.6898603439331055
INFO:root:current mean train loss 1654.6567210494977
INFO:root:current train perplexity3.693288564682007
INFO:root:current mean train loss 1657.343730453216
INFO:root:current train perplexity3.696465492248535
INFO:root:current mean train loss 1658.1040611376814
INFO:root:current train perplexity3.6989529132843018
INFO:root:current mean train loss 1658.0442968920877
INFO:root:current train perplexity3.698763370513916
INFO:root:current mean train loss 1659.5408943403372
INFO:root:current train perplexity3.7003443241119385
INFO:root:current mean train loss 1660.1211813715795
INFO:root:current train perplexity3.7006726264953613
INFO:root:current mean train loss 1660.2388254484201
INFO:root:current train perplexity3.701242208480835
INFO:root:current mean train loss 1661.505693397349
INFO:root:current train perplexity3.7026336193084717
INFO:root:current mean train loss 1662.2516999201157
INFO:root:current train perplexity3.703641414642334
INFO:root:current mean train loss 1661.5370433323696
INFO:root:current train perplexity3.7036921977996826
INFO:root:current mean train loss 1661.1181216723753
INFO:root:current train perplexity3.7050435543060303
INFO:root:current mean train loss 1661.359270143926
INFO:root:current train perplexity3.705571413040161

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.05s/it]
INFO:root:final mean train loss: 1660.5589808600153
INFO:root:final train perplexity: 3.7047533988952637
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.84s/it]
INFO:root:eval mean loss: 3294.173241600976
INFO:root:eval perplexity: 14.92607593536377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/33
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [3:02:12<6:11:09, 332.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1625.2567626953125
INFO:root:current train perplexity3.626004457473755
INFO:root:current mean train loss 1634.9301254272461
INFO:root:current train perplexity3.659472703933716
INFO:root:current mean train loss 1638.3301241361178
INFO:root:current train perplexity3.6674203872680664
INFO:root:current mean train loss 1640.4121639675564
INFO:root:current train perplexity3.669989824295044
INFO:root:current mean train loss 1639.1718670388927
INFO:root:current train perplexity3.6698038578033447
INFO:root:current mean train loss 1640.7274656023299
INFO:root:current train perplexity3.66682767868042
INFO:root:current mean train loss 1643.382968602036
INFO:root:current train perplexity3.6721460819244385
INFO:root:current mean train loss 1646.3035679867394
INFO:root:current train perplexity3.6732940673828125
INFO:root:current mean train loss 1649.272687335347
INFO:root:current train perplexity3.6758711338043213
INFO:root:current mean train loss 1649.8890137990315
INFO:root:current train perplexity3.673070192337036
INFO:root:current mean train loss 1649.4436068552845
INFO:root:current train perplexity3.6720330715179443
INFO:root:current mean train loss 1648.8063597580483
INFO:root:current train perplexity3.671771287918091
INFO:root:current mean train loss 1649.5310466463604
INFO:root:current train perplexity3.673896551132202
INFO:root:current mean train loss 1648.9588799869314
INFO:root:current train perplexity3.6733579635620117
INFO:root:current mean train loss 1648.8195672022152
INFO:root:current train perplexity3.67256760597229
INFO:root:current mean train loss 1648.441188244942
INFO:root:current train perplexity3.6729962825775146
INFO:root:current mean train loss 1648.7614399737622
INFO:root:current train perplexity3.6734297275543213
INFO:root:current mean train loss 1650.921266451749
INFO:root:current train perplexity3.6768124103546143
INFO:root:current mean train loss 1652.3010800597488
INFO:root:current train perplexity3.680084466934204
INFO:root:current mean train loss 1653.7784431301818
INFO:root:current train perplexity3.6838135719299316

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.52s/it]
INFO:root:final mean train loss: 1653.0200318737097
INFO:root:final train perplexity: 3.6827914714813232
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.58s/it]
INFO:root:eval mean loss: 3283.943923171218
INFO:root:eval perplexity: 14.801310539245605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/34
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [3:07:43<6:05:05, 331.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1661.936845259233
INFO:root:current train perplexity3.6461174488067627
INFO:root:current mean train loss 1656.0521619548906
INFO:root:current train perplexity3.656635046005249
INFO:root:current mean train loss 1646.1239207574176
INFO:root:current train perplexity3.646976947784424
INFO:root:current mean train loss 1644.4781193012268
INFO:root:current train perplexity3.6489920616149902
INFO:root:current mean train loss 1641.8752630781578
INFO:root:current train perplexity3.6515355110168457
INFO:root:current mean train loss 1643.2809863958244
INFO:root:current train perplexity3.654040575027466
INFO:root:current mean train loss 1642.102653018833
INFO:root:current train perplexity3.6506285667419434
INFO:root:current mean train loss 1642.6318503911277
INFO:root:current train perplexity3.6476612091064453
INFO:root:current mean train loss 1641.5103356112368
INFO:root:current train perplexity3.645811080932617
INFO:root:current mean train loss 1641.683085102874
INFO:root:current train perplexity3.6467747688293457
INFO:root:current mean train loss 1642.5225694066635
INFO:root:current train perplexity3.6500537395477295
INFO:root:current mean train loss 1643.4205160473198
INFO:root:current train perplexity3.6516973972320557
INFO:root:current mean train loss 1645.0519107588586
INFO:root:current train perplexity3.656712293624878
INFO:root:current mean train loss 1645.1484683500137
INFO:root:current train perplexity3.656984329223633
INFO:root:current mean train loss 1644.6432445941944
INFO:root:current train perplexity3.657033681869507
INFO:root:current mean train loss 1644.7429504975082
INFO:root:current train perplexity3.6570000648498535
INFO:root:current mean train loss 1645.5834920902514
INFO:root:current train perplexity3.658761978149414
INFO:root:current mean train loss 1645.950758470869
INFO:root:current train perplexity3.660010576248169
INFO:root:current mean train loss 1646.239676506518
INFO:root:current train perplexity3.6612708568573
INFO:root:current mean train loss 1645.8470169399263
INFO:root:current train perplexity3.6609177589416504

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.61s/it]
INFO:root:final mean train loss: 1645.3876967283434
INFO:root:final train perplexity: 3.6606903076171875
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.77s/it]
INFO:root:eval mean loss: 3296.59105492211
INFO:root:eval perplexity: 14.955717086791992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/35
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [3:13:14<5:59:18, 331.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1657.9558806723737
INFO:root:current train perplexity3.6704094409942627
INFO:root:current mean train loss 1644.3879293854704
INFO:root:current train perplexity3.643505811691284
INFO:root:current mean train loss 1643.5204667071907
INFO:root:current train perplexity3.6371192932128906
INFO:root:current mean train loss 1639.367446512135
INFO:root:current train perplexity3.6288516521453857
INFO:root:current mean train loss 1637.7530584296717
INFO:root:current train perplexity3.6335456371307373
INFO:root:current mean train loss 1639.0938644666062
INFO:root:current train perplexity3.6348345279693604
INFO:root:current mean train loss 1638.4255536433943
INFO:root:current train perplexity3.6369271278381348
INFO:root:current mean train loss 1638.9774503539732
INFO:root:current train perplexity3.6350560188293457
INFO:root:current mean train loss 1638.7734952581009
INFO:root:current train perplexity3.636716365814209
INFO:root:current mean train loss 1636.7722766039597
INFO:root:current train perplexity3.6333653926849365
INFO:root:current mean train loss 1638.3931254329368
INFO:root:current train perplexity3.6355245113372803
INFO:root:current mean train loss 1639.2230718411392
INFO:root:current train perplexity3.6351706981658936
INFO:root:current mean train loss 1638.7995422457616
INFO:root:current train perplexity3.637441396713257
INFO:root:current mean train loss 1638.8275812004013
INFO:root:current train perplexity3.636934518814087
INFO:root:current mean train loss 1638.957169988548
INFO:root:current train perplexity3.6368465423583984
INFO:root:current mean train loss 1637.678487780103
INFO:root:current train perplexity3.6351478099823
INFO:root:current mean train loss 1637.4204474114752
INFO:root:current train perplexity3.635350227355957
INFO:root:current mean train loss 1638.1146704292084
INFO:root:current train perplexity3.6369833946228027
INFO:root:current mean train loss 1638.088772444438
INFO:root:current train perplexity3.637918472290039

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.13s/it]
INFO:root:final mean train loss: 1637.4591799460452
INFO:root:final train perplexity: 3.6378719806671143
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.67s/it]
INFO:root:eval mean loss: 3310.8179187488267
INFO:root:eval perplexity: 15.131335258483887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/36
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [3:18:44<5:53:23, 331.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1660.1676691228693
INFO:root:current train perplexity3.7021186351776123
INFO:root:current mean train loss 1615.8339194907799
INFO:root:current train perplexity3.6055421829223633
INFO:root:current mean train loss 1608.5193692609598
INFO:root:current train perplexity3.5775399208068848
INFO:root:current mean train loss 1615.8427667648464
INFO:root:current train perplexity3.5921823978424072
INFO:root:current mean train loss 1618.2294140743804
INFO:root:current train perplexity3.586411714553833
INFO:root:current mean train loss 1620.369247645548
INFO:root:current train perplexity3.592999219894409
INFO:root:current mean train loss 1624.763578374335
INFO:root:current train perplexity3.6029624938964844
INFO:root:current mean train loss 1625.1481009911217
INFO:root:current train perplexity3.602757453918457
INFO:root:current mean train loss 1623.855646211034
INFO:root:current train perplexity3.6038429737091064
INFO:root:current mean train loss 1623.146798595508
INFO:root:current train perplexity3.605045795440674
INFO:root:current mean train loss 1623.7140077313613
INFO:root:current train perplexity3.6063196659088135
INFO:root:current mean train loss 1623.3733081560108
INFO:root:current train perplexity3.6061511039733887
INFO:root:current mean train loss 1624.6858882888303
INFO:root:current train perplexity3.606767177581787
INFO:root:current mean train loss 1624.4400754880578
INFO:root:current train perplexity3.607419967651367
INFO:root:current mean train loss 1627.4747593026057
INFO:root:current train perplexity3.609872579574585
INFO:root:current mean train loss 1627.895112921906
INFO:root:current train perplexity3.6123034954071045
INFO:root:current mean train loss 1628.6768259324324
INFO:root:current train perplexity3.6134960651397705
INFO:root:current mean train loss 1629.831171977736
INFO:root:current train perplexity3.614412307739258
INFO:root:current mean train loss 1630.0449660252234
INFO:root:current train perplexity3.615528106689453
INFO:root:current mean train loss 1629.8268717831183
INFO:root:current train perplexity3.615288019180298

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.85s/it]
INFO:root:final mean train loss: 1630.4594827210487
INFO:root:final train perplexity: 3.617844581604004
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.17s/it]
INFO:root:eval mean loss: 3316.2983545068505
INFO:root:eval perplexity: 15.199535369873047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/37
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [3:24:16<5:48:00, 331.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1614.9313310895648
INFO:root:current train perplexity3.567063093185425
INFO:root:current mean train loss 1615.4735746383667
INFO:root:current train perplexity3.5752980709075928
INFO:root:current mean train loss 1616.0204071580317
INFO:root:current train perplexity3.5718257427215576
INFO:root:current mean train loss 1608.9645255484231
INFO:root:current train perplexity3.563528299331665
INFO:root:current mean train loss 1608.97889666691
INFO:root:current train perplexity3.5678136348724365
INFO:root:current mean train loss 1611.4181190259528
INFO:root:current train perplexity3.574220895767212
INFO:root:current mean train loss 1612.505977168964
INFO:root:current train perplexity3.575655698776245
INFO:root:current mean train loss 1612.1275695130066
INFO:root:current train perplexity3.577300548553467
INFO:root:current mean train loss 1613.1308667463957
INFO:root:current train perplexity3.581937789916992
INFO:root:current mean train loss 1613.0974132932465
INFO:root:current train perplexity3.5821406841278076
INFO:root:current mean train loss 1615.6749521693366
INFO:root:current train perplexity3.5850682258605957
INFO:root:current mean train loss 1617.091714412608
INFO:root:current train perplexity3.585949182510376
INFO:root:current mean train loss 1616.8730715276365
INFO:root:current train perplexity3.5875062942504883
INFO:root:current mean train loss 1617.8958833073996
INFO:root:current train perplexity3.5884194374084473
INFO:root:current mean train loss 1616.996087338744
INFO:root:current train perplexity3.586897850036621
INFO:root:current mean train loss 1619.0537202845069
INFO:root:current train perplexity3.5903236865997314
INFO:root:current mean train loss 1621.7289613915896
INFO:root:current train perplexity3.594386339187622
INFO:root:current mean train loss 1623.3719933121292
INFO:root:current train perplexity3.596318006515503
INFO:root:current mean train loss 1623.972109070492
INFO:root:current train perplexity3.597644805908203
INFO:root:current mean train loss 1623.6428988128282
INFO:root:current train perplexity3.5968544483184814

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.01s/it]
INFO:root:final mean train loss: 1623.3578668806929
INFO:root:final train perplexity: 3.5976383686065674
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.50s/it]
INFO:root:eval mean loss: 3324.7399044552367
INFO:root:eval perplexity: 15.305184364318848
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/38
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [3:29:46<5:42:06, 331.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1594.3906656901042
INFO:root:current train perplexity3.5485920906066895
INFO:root:current mean train loss 1618.7019884832973
INFO:root:current train perplexity3.570045232772827
INFO:root:current mean train loss 1620.5596266143175
INFO:root:current train perplexity3.5739853382110596
INFO:root:current mean train loss 1614.0417264634284
INFO:root:current train perplexity3.5677506923675537
INFO:root:current mean train loss 1615.2633347414853
INFO:root:current train perplexity3.5689306259155273
INFO:root:current mean train loss 1613.7407920907397
INFO:root:current train perplexity3.5672004222869873
INFO:root:current mean train loss 1614.3749242974807
INFO:root:current train perplexity3.566556692123413
INFO:root:current mean train loss 1612.0977414534395
INFO:root:current train perplexity3.561586618423462
INFO:root:current mean train loss 1612.669594524316
INFO:root:current train perplexity3.5606110095977783
INFO:root:current mean train loss 1613.2800163793815
INFO:root:current train perplexity3.562234401702881
INFO:root:current mean train loss 1613.7100745972264
INFO:root:current train perplexity3.5647594928741455
INFO:root:current mean train loss 1615.337452877661
INFO:root:current train perplexity3.5688328742980957
INFO:root:current mean train loss 1615.6770541148971
INFO:root:current train perplexity3.570319175720215
INFO:root:current mean train loss 1614.0991161927857
INFO:root:current train perplexity3.57073974609375
INFO:root:current mean train loss 1615.4430212106672
INFO:root:current train perplexity3.5716874599456787
INFO:root:current mean train loss 1615.4133367939673
INFO:root:current train perplexity3.5715081691741943
INFO:root:current mean train loss 1615.7807184561407
INFO:root:current train perplexity3.5723729133605957
INFO:root:current mean train loss 1616.5302721083676
INFO:root:current train perplexity3.574162483215332
INFO:root:current mean train loss 1616.893176765752
INFO:root:current train perplexity3.575899124145508
INFO:root:current mean train loss 1616.6645955926656
INFO:root:current train perplexity3.576282024383545

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.84s/it]
INFO:root:final mean train loss: 1616.290289482082
INFO:root:final train perplexity: 3.577641248703003
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.57s/it]
INFO:root:eval mean loss: 3320.1528049045137
INFO:root:eval perplexity: 15.247685432434082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/39
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [3:35:17<5:36:36, 331.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1594.385962701613
INFO:root:current train perplexity3.525756359100342
INFO:root:current mean train loss 1598.922708393615
INFO:root:current train perplexity3.53139328956604
INFO:root:current mean train loss 1605.9027668028386
INFO:root:current train perplexity3.5371620655059814
INFO:root:current mean train loss 1606.8018535803694
INFO:root:current train perplexity3.5412819385528564
INFO:root:current mean train loss 1603.7179034344563
INFO:root:current train perplexity3.5433428287506104
INFO:root:current mean train loss 1605.959869493369
INFO:root:current train perplexity3.5521864891052246
INFO:root:current mean train loss 1605.536310017289
INFO:root:current train perplexity3.552269220352173
INFO:root:current mean train loss 1605.2914576092417
INFO:root:current train perplexity3.55125093460083
INFO:root:current mean train loss 1607.3800346215198
INFO:root:current train perplexity3.5557072162628174
INFO:root:current mean train loss 1606.5157926246184
INFO:root:current train perplexity3.5548641681671143
INFO:root:current mean train loss 1607.8746824102886
INFO:root:current train perplexity3.554342269897461
INFO:root:current mean train loss 1607.8833892349533
INFO:root:current train perplexity3.5523910522460938
INFO:root:current mean train loss 1607.0934763574373
INFO:root:current train perplexity3.5516772270202637
INFO:root:current mean train loss 1608.191863072601
INFO:root:current train perplexity3.5545501708984375
INFO:root:current mean train loss 1607.9074146776943
INFO:root:current train perplexity3.5562100410461426
INFO:root:current mean train loss 1608.9975224884463
INFO:root:current train perplexity3.5578622817993164
INFO:root:current mean train loss 1610.1542743265127
INFO:root:current train perplexity3.5594472885131836
INFO:root:current mean train loss 1610.4018222146353
INFO:root:current train perplexity3.560403347015381
INFO:root:current mean train loss 1611.0152706551885
INFO:root:current train perplexity3.5611066818237305
INFO:root:current mean train loss 1611.1511555242976
INFO:root:current train perplexity3.561047315597534

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.57s/it]
INFO:root:final mean train loss: 1610.6102187810254
INFO:root:final train perplexity: 3.5616509914398193
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.86s/it]
INFO:root:eval mean loss: 3328.181523320195
INFO:root:eval perplexity: 15.348467826843262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/40
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [3:40:49<5:31:06, 331.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1600.096073971519
INFO:root:current train perplexity3.540580987930298
INFO:root:current mean train loss 1605.2303296307612
INFO:root:current train perplexity3.5373282432556152
INFO:root:current mean train loss 1602.2052802629369
INFO:root:current train perplexity3.53599214553833
INFO:root:current mean train loss 1602.6494936175586
INFO:root:current train perplexity3.5409696102142334
INFO:root:current mean train loss 1601.62971588963
INFO:root:current train perplexity3.5413196086883545
INFO:root:current mean train loss 1604.9897220591806
INFO:root:current train perplexity3.5411713123321533
INFO:root:current mean train loss 1605.1304331176937
INFO:root:current train perplexity3.5407278537750244
INFO:root:current mean train loss 1606.8083974032713
INFO:root:current train perplexity3.544656991958618
INFO:root:current mean train loss 1605.9849928507626
INFO:root:current train perplexity3.544452667236328
INFO:root:current mean train loss 1606.7655372191011
INFO:root:current train perplexity3.545870065689087
INFO:root:current mean train loss 1606.2404610931708
INFO:root:current train perplexity3.543442964553833
INFO:root:current mean train loss 1606.1249820880712
INFO:root:current train perplexity3.5456583499908447
INFO:root:current mean train loss 1606.2775585899324
INFO:root:current train perplexity3.543210029602051
INFO:root:current mean train loss 1607.336709225152
INFO:root:current train perplexity3.5469133853912354
INFO:root:current mean train loss 1607.689627110273
INFO:root:current train perplexity3.5475311279296875
INFO:root:current mean train loss 1606.2839254194457
INFO:root:current train perplexity3.5462191104888916
INFO:root:current mean train loss 1605.448256582927
INFO:root:current train perplexity3.543570041656494
INFO:root:current mean train loss 1604.328067910343
INFO:root:current train perplexity3.542524576187134
INFO:root:current mean train loss 1603.9110134707416
INFO:root:current train perplexity3.5424835681915283
INFO:root:current mean train loss 1604.171963946635
INFO:root:current train perplexity3.542372941970825

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.32s/it]
INFO:root:final mean train loss: 1603.713876359702
INFO:root:final train perplexity: 3.542332172393799
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.28s/it]
INFO:root:eval mean loss: 3329.923616243196
INFO:root:eval perplexity: 15.370429039001465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/41
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [3:46:20<5:25:38, 331.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1582.1635335286458
INFO:root:current train perplexity3.490743637084961
INFO:root:current mean train loss 1581.3639395577568
INFO:root:current train perplexity3.4885647296905518
INFO:root:current mean train loss 1588.5410642881652
INFO:root:current train perplexity3.505840539932251
INFO:root:current mean train loss 1589.8013536857836
INFO:root:current train perplexity3.5065267086029053
INFO:root:current mean train loss 1589.631373251638
INFO:root:current train perplexity3.511758804321289
INFO:root:current mean train loss 1591.841994727218
INFO:root:current train perplexity3.507758855819702
INFO:root:current mean train loss 1589.1091348933078
INFO:root:current train perplexity3.5050673484802246
INFO:root:current mean train loss 1590.3018231415867
INFO:root:current train perplexity3.5080721378326416
INFO:root:current mean train loss 1591.2742180143084
INFO:root:current train perplexity3.509183406829834
INFO:root:current mean train loss 1591.384007342848
INFO:root:current train perplexity3.5107829570770264
INFO:root:current mean train loss 1591.5664206177648
INFO:root:current train perplexity3.5079383850097656
INFO:root:current mean train loss 1592.9422304287402
INFO:root:current train perplexity3.5105578899383545
INFO:root:current mean train loss 1594.5812738677603
INFO:root:current train perplexity3.513169527053833
INFO:root:current mean train loss 1594.5333693539858
INFO:root:current train perplexity3.514881134033203
INFO:root:current mean train loss 1595.617966269427
INFO:root:current train perplexity3.518169403076172
INFO:root:current mean train loss 1597.6349775653734
INFO:root:current train perplexity3.520756244659424
INFO:root:current mean train loss 1598.0861008842037
INFO:root:current train perplexity3.522693395614624
INFO:root:current mean train loss 1598.019186313009
INFO:root:current train perplexity3.5235047340393066
INFO:root:current mean train loss 1598.219149496988
INFO:root:current train perplexity3.524216651916504

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.81s/it]
INFO:root:final mean train loss: 1597.6434767545622
INFO:root:final train perplexity: 3.5254135131835938
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.66s/it]
INFO:root:eval mean loss: 3337.2240859023086
INFO:root:eval perplexity: 15.46278190612793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/42
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [3:51:52<5:20:24, 331.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1605.4482046274038
INFO:root:current train perplexity3.580451250076294
INFO:root:current mean train loss 1575.7150490009678
INFO:root:current train perplexity3.5051145553588867
INFO:root:current mean train loss 1576.9289023529195
INFO:root:current train perplexity3.500687837600708
INFO:root:current mean train loss 1579.9465940432808
INFO:root:current train perplexity3.489049196243286
INFO:root:current mean train loss 1579.8828893481386
INFO:root:current train perplexity3.490253448486328
INFO:root:current mean train loss 1582.7413801226699
INFO:root:current train perplexity3.489135265350342
INFO:root:current mean train loss 1584.3479671011546
INFO:root:current train perplexity3.4956836700439453
INFO:root:current mean train loss 1587.641484457179
INFO:root:current train perplexity3.4975247383117676
INFO:root:current mean train loss 1587.2528996579028
INFO:root:current train perplexity3.4998021125793457
INFO:root:current mean train loss 1589.1602108005886
INFO:root:current train perplexity3.5002481937408447
INFO:root:current mean train loss 1590.4950530794977
INFO:root:current train perplexity3.5021440982818604
INFO:root:current mean train loss 1590.8411561429555
INFO:root:current train perplexity3.5045580863952637
INFO:root:current mean train loss 1590.7041763343402
INFO:root:current train perplexity3.5053908824920654
INFO:root:current mean train loss 1590.5875919106709
INFO:root:current train perplexity3.504706382751465
INFO:root:current mean train loss 1592.2182825389518
INFO:root:current train perplexity3.507474660873413
INFO:root:current mean train loss 1592.1636060070534
INFO:root:current train perplexity3.508230209350586
INFO:root:current mean train loss 1590.805721124506
INFO:root:current train perplexity3.5048062801361084
INFO:root:current mean train loss 1591.1307208433668
INFO:root:current train perplexity3.505999803543091
INFO:root:current mean train loss 1590.4542164957727
INFO:root:current train perplexity3.5047519207000732
INFO:root:current mean train loss 1591.2872800692426
INFO:root:current train perplexity3.506438732147217

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.38s/it]
INFO:root:final mean train loss: 1591.4246966525034
INFO:root:final train perplexity: 3.5081658363342285
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.77s/it]
INFO:root:eval mean loss: 3338.81323168872
INFO:root:eval perplexity: 15.482954025268555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/43
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [3:57:23<5:14:43, 331.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1603.8614705403645
INFO:root:current train perplexity3.5366556644439697
INFO:root:current mean train loss 1592.3922025240386
INFO:root:current train perplexity3.5006778240203857
INFO:root:current mean train loss 1597.729348887568
INFO:root:current train perplexity3.5079429149627686
INFO:root:current mean train loss 1593.600459798177
INFO:root:current train perplexity3.493670701980591
INFO:root:current mean train loss 1588.69726307004
INFO:root:current train perplexity3.4896233081817627
INFO:root:current mean train loss 1588.5530858453715
INFO:root:current train perplexity3.4855098724365234
INFO:root:current mean train loss 1585.8343542674231
INFO:root:current train perplexity3.4834253787994385
INFO:root:current mean train loss 1587.3850134444563
INFO:root:current train perplexity3.4879064559936523
INFO:root:current mean train loss 1588.4483760236258
INFO:root:current train perplexity3.4872887134552
INFO:root:current mean train loss 1588.4728763703376
INFO:root:current train perplexity3.488450288772583
INFO:root:current mean train loss 1587.6571245211999
INFO:root:current train perplexity3.4893112182617188
INFO:root:current mean train loss 1587.6489261053305
INFO:root:current train perplexity3.4896490573883057
INFO:root:current mean train loss 1588.1261784251144
INFO:root:current train perplexity3.492022752761841
INFO:root:current mean train loss 1587.5140591958411
INFO:root:current train perplexity3.4906938076019287
INFO:root:current mean train loss 1588.1010746455693
INFO:root:current train perplexity3.493525266647339
INFO:root:current mean train loss 1586.3480574863408
INFO:root:current train perplexity3.4911928176879883
INFO:root:current mean train loss 1586.4655980396856
INFO:root:current train perplexity3.4936623573303223
INFO:root:current mean train loss 1587.2195328729001
INFO:root:current train perplexity3.493976354598999
INFO:root:current mean train loss 1587.1378792184298
INFO:root:current train perplexity3.4949758052825928
INFO:root:current mean train loss 1586.4280663050517
INFO:root:current train perplexity3.4932637214660645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.36s/it]
INFO:root:final mean train loss: 1586.227817121805
INFO:root:final train perplexity: 3.493816375732422
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.56s/it]
INFO:root:eval mean loss: 3349.47193335914
INFO:root:eval perplexity: 15.61897087097168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/44
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [4:02:55<5:09:17, 331.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1564.2650224401596
INFO:root:current train perplexity3.4460136890411377
INFO:root:current mean train loss 1552.0082268747342
INFO:root:current train perplexity3.4256362915039062
INFO:root:current mean train loss 1564.504117278435
INFO:root:current train perplexity3.433485984802246
INFO:root:current mean train loss 1573.4860713200198
INFO:root:current train perplexity3.458695411682129
INFO:root:current mean train loss 1574.4988590385556
INFO:root:current train perplexity3.4604575634002686
INFO:root:current mean train loss 1575.6749434950582
INFO:root:current train perplexity3.464228868484497
INFO:root:current mean train loss 1575.753933984677
INFO:root:current train perplexity3.465898036956787
INFO:root:current mean train loss 1575.8162995406103
INFO:root:current train perplexity3.4601361751556396
INFO:root:current mean train loss 1578.893969611266
INFO:root:current train perplexity3.4671473503112793
INFO:root:current mean train loss 1579.1721721193985
INFO:root:current train perplexity3.466097593307495
INFO:root:current mean train loss 1579.0617961428113
INFO:root:current train perplexity3.4698965549468994
INFO:root:current mean train loss 1580.7044096649888
INFO:root:current train perplexity3.472414016723633
INFO:root:current mean train loss 1579.0795586164606
INFO:root:current train perplexity3.471086025238037
INFO:root:current mean train loss 1577.782582261072
INFO:root:current train perplexity3.469569683074951
INFO:root:current mean train loss 1578.7408588148433
INFO:root:current train perplexity3.471022605895996
INFO:root:current mean train loss 1579.9733317004686
INFO:root:current train perplexity3.4756572246551514
INFO:root:current mean train loss 1579.4700563821057
INFO:root:current train perplexity3.475353479385376
INFO:root:current mean train loss 1579.3781287592346
INFO:root:current train perplexity3.474513292312622
INFO:root:current mean train loss 1579.8935293085071
INFO:root:current train perplexity3.4759268760681152
INFO:root:current mean train loss 1580.942040426277
INFO:root:current train perplexity3.477924346923828

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.68s/it]
INFO:root:final mean train loss: 1580.4124937456663
INFO:root:final train perplexity: 3.4778289794921875
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.75s/it]
INFO:root:eval mean loss: 3349.7608250340186
INFO:root:eval perplexity: 15.622669219970703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/45
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [4:08:27<5:03:58, 331.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1568.786750793457
INFO:root:current train perplexity3.4447903633117676
INFO:root:current mean train loss 1576.4139590379668
INFO:root:current train perplexity3.454965591430664
INFO:root:current mean train loss 1576.1497483686967
INFO:root:current train perplexity3.4607739448547363
INFO:root:current mean train loss 1577.5469538091304
INFO:root:current train perplexity3.4738783836364746
INFO:root:current mean train loss 1576.631047215955
INFO:root:current train perplexity3.46771240234375
INFO:root:current mean train loss 1575.2587011891899
INFO:root:current train perplexity3.464576482772827
INFO:root:current mean train loss 1572.596489044557
INFO:root:current train perplexity3.4595580101013184
INFO:root:current mean train loss 1571.292385241124
INFO:root:current train perplexity3.4579694271087646
INFO:root:current mean train loss 1573.53375032213
INFO:root:current train perplexity3.461193323135376
INFO:root:current mean train loss 1574.6863432444973
INFO:root:current train perplexity3.463106155395508
INFO:root:current mean train loss 1573.3230379721276
INFO:root:current train perplexity3.462125301361084
INFO:root:current mean train loss 1574.6800481527532
INFO:root:current train perplexity3.4624972343444824
INFO:root:current mean train loss 1575.30455355101
INFO:root:current train perplexity3.462218999862671
INFO:root:current mean train loss 1575.943235246317
INFO:root:current train perplexity3.461411476135254
INFO:root:current mean train loss 1576.5772159764024
INFO:root:current train perplexity3.461090564727783
INFO:root:current mean train loss 1576.0969110279132
INFO:root:current train perplexity3.4602813720703125
INFO:root:current mean train loss 1575.0654258728027
INFO:root:current train perplexity3.4610157012939453
INFO:root:current mean train loss 1575.2672176577337
INFO:root:current train perplexity3.461336851119995
INFO:root:current mean train loss 1575.0145109774217
INFO:root:current train perplexity3.4619579315185547
INFO:root:current mean train loss 1574.869816984033
INFO:root:current train perplexity3.4611458778381348

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.06s/it]
INFO:root:final mean train loss: 1574.2202722161812
INFO:root:final train perplexity: 3.4608867168426514
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.50s/it]
INFO:root:eval mean loss: 3354.7185931048234
INFO:root:eval perplexity: 15.686357498168945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/46
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [4:13:58<4:58:20, 331.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1576.9830910011574
INFO:root:current train perplexity3.454017162322998
INFO:root:current mean train loss 1574.873217503669
INFO:root:current train perplexity3.4415719509124756
INFO:root:current mean train loss 1575.0352500834074
INFO:root:current train perplexity3.4425365924835205
INFO:root:current mean train loss 1573.1006618710014
INFO:root:current train perplexity3.436985969543457
INFO:root:current mean train loss 1568.8164973586115
INFO:root:current train perplexity3.4350452423095703
INFO:root:current mean train loss 1569.228661226939
INFO:root:current train perplexity3.4366672039031982
INFO:root:current mean train loss 1570.8401119103341
INFO:root:current train perplexity3.4445204734802246
INFO:root:current mean train loss 1572.4632848136403
INFO:root:current train perplexity3.4463534355163574
INFO:root:current mean train loss 1574.9382635976074
INFO:root:current train perplexity3.448575735092163
INFO:root:current mean train loss 1572.2637070899832
INFO:root:current train perplexity3.4464833736419678
INFO:root:current mean train loss 1571.517076292929
INFO:root:current train perplexity3.4449656009674072
INFO:root:current mean train loss 1571.9129835059339
INFO:root:current train perplexity3.446072578430176
INFO:root:current mean train loss 1572.6275749117206
INFO:root:current train perplexity3.449704647064209
INFO:root:current mean train loss 1572.1057435628904
INFO:root:current train perplexity3.4495151042938232
INFO:root:current mean train loss 1571.1439211457102
INFO:root:current train perplexity3.4486501216888428
INFO:root:current mean train loss 1569.597356903636
INFO:root:current train perplexity3.445831775665283
INFO:root:current mean train loss 1570.0600225753828
INFO:root:current train perplexity3.4457340240478516
INFO:root:current mean train loss 1570.1330091421823
INFO:root:current train perplexity3.446841239929199
INFO:root:current mean train loss 1569.156522695084
INFO:root:current train perplexity3.4461987018585205
INFO:root:current mean train loss 1569.6965190920187
INFO:root:current train perplexity3.447253465652466

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.48s/it]
INFO:root:final mean train loss: 1569.1739221862392
INFO:root:final train perplexity: 3.4471404552459717
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.42s/it]
INFO:root:eval mean loss: 3355.8300216720627
INFO:root:eval perplexity: 15.70067310333252
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/47
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [4:19:28<4:52:34, 331.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1560.9708040198502
INFO:root:current train perplexity3.400853157043457
INFO:root:current mean train loss 1557.848108156763
INFO:root:current train perplexity3.399456739425659
INFO:root:current mean train loss 1557.3973872037543
INFO:root:current train perplexity3.413963556289673
INFO:root:current mean train loss 1554.8051607524928
INFO:root:current train perplexity3.4115757942199707
INFO:root:current mean train loss 1556.577396990305
INFO:root:current train perplexity3.412797212600708
INFO:root:current mean train loss 1556.7546311190297
INFO:root:current train perplexity3.413210153579712
INFO:root:current mean train loss 1560.26426596218
INFO:root:current train perplexity3.4205563068389893
INFO:root:current mean train loss 1560.7759754305196
INFO:root:current train perplexity3.423804521560669
INFO:root:current mean train loss 1561.7596397484863
INFO:root:current train perplexity3.4265568256378174
INFO:root:current mean train loss 1560.3486920129321
INFO:root:current train perplexity3.4241747856140137
INFO:root:current mean train loss 1562.8113719057733
INFO:root:current train perplexity3.426137924194336
INFO:root:current mean train loss 1563.3963458995788
INFO:root:current train perplexity3.42811918258667
INFO:root:current mean train loss 1561.3881475745438
INFO:root:current train perplexity3.4252266883850098
INFO:root:current mean train loss 1561.9687229314757
INFO:root:current train perplexity3.427333116531372
INFO:root:current mean train loss 1562.0237233629214
INFO:root:current train perplexity3.4285409450531006
INFO:root:current mean train loss 1562.6034700968985
INFO:root:current train perplexity3.4308056831359863
INFO:root:current mean train loss 1563.2394994369524
INFO:root:current train perplexity3.432138442993164
INFO:root:current mean train loss 1563.2634982065576
INFO:root:current train perplexity3.4315640926361084
INFO:root:current mean train loss 1563.368861689834
INFO:root:current train perplexity3.431213855743408

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.58s/it]
INFO:root:final mean train loss: 1563.431075611201
INFO:root:final train perplexity: 3.431563138961792
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.90s/it]
INFO:root:eval mean loss: 3364.1553812112893
INFO:root:eval perplexity: 15.808298110961914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/48
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [4:25:00<4:47:02, 331.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1501.7448649088542
INFO:root:current train perplexity3.2549734115600586
INFO:root:current mean train loss 1554.8108844259511
INFO:root:current train perplexity3.404789924621582
INFO:root:current mean train loss 1560.3105241642443
INFO:root:current train perplexity3.4041876792907715
INFO:root:current mean train loss 1558.0386842757937
INFO:root:current train perplexity3.399693012237549
INFO:root:current mean train loss 1562.870505165192
INFO:root:current train perplexity3.4120044708251953
INFO:root:current mean train loss 1558.3355435565838
INFO:root:current train perplexity3.403562068939209
INFO:root:current mean train loss 1555.1812644896468
INFO:root:current train perplexity3.402097702026367
INFO:root:current mean train loss 1556.5645668296547
INFO:root:current train perplexity3.407555103302002
INFO:root:current mean train loss 1555.753555915692
INFO:root:current train perplexity3.4090230464935303
INFO:root:current mean train loss 1554.5390267460723
INFO:root:current train perplexity3.408942699432373
INFO:root:current mean train loss 1556.2430395868612
INFO:root:current train perplexity3.411562442779541
INFO:root:current mean train loss 1557.7689978629485
INFO:root:current train perplexity3.4116272926330566
INFO:root:current mean train loss 1558.5960175942
INFO:root:current train perplexity3.411564826965332
INFO:root:current mean train loss 1558.698249799489
INFO:root:current train perplexity3.412459135055542
INFO:root:current mean train loss 1557.94874522071
INFO:root:current train perplexity3.4131197929382324
INFO:root:current mean train loss 1557.3094817611643
INFO:root:current train perplexity3.4141483306884766
INFO:root:current mean train loss 1558.2781887184356
INFO:root:current train perplexity3.4156675338745117
INFO:root:current mean train loss 1558.0844993480093
INFO:root:current train perplexity3.416534900665283
INFO:root:current mean train loss 1558.8619712976713
INFO:root:current train perplexity3.417572021484375
INFO:root:current mean train loss 1558.7502157744166
INFO:root:current train perplexity3.4187533855438232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.81s/it]
INFO:root:final mean train loss: 1559.1930850091992
INFO:root:final train perplexity: 3.4201126098632812
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.64s/it]
INFO:root:eval mean loss: 3373.0374238985078
INFO:root:eval perplexity: 15.92393684387207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/49
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [4:30:30<4:41:15, 330.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1574.242073059082
INFO:root:current train perplexity3.440366268157959
INFO:root:current mean train loss 1552.1437266956675
INFO:root:current train perplexity3.3744280338287354
INFO:root:current mean train loss 1548.5907271812703
INFO:root:current train perplexity3.3727338314056396
INFO:root:current mean train loss 1550.5828191918063
INFO:root:current train perplexity3.3823676109313965
INFO:root:current mean train loss 1552.9440573233146
INFO:root:current train perplexity3.3905208110809326
INFO:root:current mean train loss 1549.913157527608
INFO:root:current train perplexity3.39149808883667
INFO:root:current mean train loss 1550.011662157276
INFO:root:current train perplexity3.3938119411468506
INFO:root:current mean train loss 1550.8885756529094
INFO:root:current train perplexity3.395721197128296
INFO:root:current mean train loss 1550.703177672166
INFO:root:current train perplexity3.3964414596557617
INFO:root:current mean train loss 1551.0717174873844
INFO:root:current train perplexity3.3980305194854736
INFO:root:current mean train loss 1550.40935415815
INFO:root:current train perplexity3.397097110748291
INFO:root:current mean train loss 1552.317896111694
INFO:root:current train perplexity3.399559736251831
INFO:root:current mean train loss 1553.083573774858
INFO:root:current train perplexity3.400879383087158
INFO:root:current mean train loss 1551.9745977361638
INFO:root:current train perplexity3.3990726470947266
INFO:root:current mean train loss 1551.3847110684358
INFO:root:current train perplexity3.398592472076416
INFO:root:current mean train loss 1551.186915624235
INFO:root:current train perplexity3.397663116455078
INFO:root:current mean train loss 1552.5114215028052
INFO:root:current train perplexity3.4001266956329346
INFO:root:current mean train loss 1552.1649618875622
INFO:root:current train perplexity3.40092134475708
INFO:root:current mean train loss 1553.5518636245395
INFO:root:current train perplexity3.4033396244049072
INFO:root:current mean train loss 1553.635436253518
INFO:root:current train perplexity3.404869556427002

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.79s/it]
INFO:root:final mean train loss: 1554.1762943392862
INFO:root:final train perplexity: 3.4066076278686523
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.60s/it]
INFO:root:eval mean loss: 3369.759377052834
INFO:root:eval perplexity: 15.881157875061035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/50
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [4:36:04<4:36:39, 331.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1526.2821219308037
INFO:root:current train perplexity3.352246046066284
INFO:root:current mean train loss 1535.2977778287543
INFO:root:current train perplexity3.338789701461792
INFO:root:current mean train loss 1537.7261889354293
INFO:root:current train perplexity3.357314348220825
INFO:root:current mean train loss 1539.7937802202723
INFO:root:current train perplexity3.3654122352600098
INFO:root:current mean train loss 1543.8367626300633
INFO:root:current train perplexity3.3669450283050537
INFO:root:current mean train loss 1544.0060481504013
INFO:root:current train perplexity3.3686866760253906
INFO:root:current mean train loss 1542.1394765233772
INFO:root:current train perplexity3.3691937923431396
INFO:root:current mean train loss 1544.8848845987359
INFO:root:current train perplexity3.3752834796905518
INFO:root:current mean train loss 1544.9255460238148
INFO:root:current train perplexity3.3757965564727783
INFO:root:current mean train loss 1547.103921454121
INFO:root:current train perplexity3.3811779022216797
INFO:root:current mean train loss 1547.924128006025
INFO:root:current train perplexity3.3852732181549072
INFO:root:current mean train loss 1547.679848135607
INFO:root:current train perplexity3.387298583984375
INFO:root:current mean train loss 1548.0081282799677
INFO:root:current train perplexity3.389894723892212
INFO:root:current mean train loss 1546.9204461710642
INFO:root:current train perplexity3.388897180557251
INFO:root:current mean train loss 1546.7555878549053
INFO:root:current train perplexity3.389047861099243
INFO:root:current mean train loss 1546.6037667005428
INFO:root:current train perplexity3.3888401985168457
INFO:root:current mean train loss 1546.8828568420965
INFO:root:current train perplexity3.3893649578094482
INFO:root:current mean train loss 1547.0788043083771
INFO:root:current train perplexity3.389885425567627
INFO:root:current mean train loss 1547.8721884876538
INFO:root:current train perplexity3.3906948566436768
INFO:root:current mean train loss 1549.3936517049008
INFO:root:current train perplexity3.392719030380249

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:59<00:00, 299.46s/it]
INFO:root:final mean train loss: 1548.7929625941597
INFO:root:final train perplexity: 3.3921749591827393
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.74s/it]
INFO:root:eval mean loss: 3369.831754850554
INFO:root:eval perplexity: 15.882104873657227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/51
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [4:41:38<4:31:35, 332.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1546.7424057469223
INFO:root:current train perplexity3.364583730697632
INFO:root:current mean train loss 1538.2087005247552
INFO:root:current train perplexity3.3661420345306396
INFO:root:current mean train loss 1541.1394341260866
INFO:root:current train perplexity3.3591012954711914
INFO:root:current mean train loss 1539.980397375555
INFO:root:current train perplexity3.3670613765716553
INFO:root:current mean train loss 1539.843133099601
INFO:root:current train perplexity3.3651113510131836
INFO:root:current mean train loss 1545.3479804049111
INFO:root:current train perplexity3.369142532348633
INFO:root:current mean train loss 1545.5968824048657
INFO:root:current train perplexity3.3693039417266846
INFO:root:current mean train loss 1543.1321957740086
INFO:root:current train perplexity3.3678627014160156
INFO:root:current mean train loss 1545.3012090599289
INFO:root:current train perplexity3.3727970123291016
INFO:root:current mean train loss 1543.8254620727791
INFO:root:current train perplexity3.3708362579345703
INFO:root:current mean train loss 1544.242621616843
INFO:root:current train perplexity3.376075029373169
INFO:root:current mean train loss 1543.3265711684578
INFO:root:current train perplexity3.374640464782715
INFO:root:current mean train loss 1544.1353176412235
INFO:root:current train perplexity3.375976800918579
INFO:root:current mean train loss 1543.5815731735565
INFO:root:current train perplexity3.3775269985198975
INFO:root:current mean train loss 1542.8529644767063
INFO:root:current train perplexity3.377023696899414
INFO:root:current mean train loss 1544.2212999131943
INFO:root:current train perplexity3.3796660900115967
INFO:root:current mean train loss 1544.1173170440052
INFO:root:current train perplexity3.3795831203460693
INFO:root:current mean train loss 1544.9660712271289
INFO:root:current train perplexity3.380317449569702
INFO:root:current mean train loss 1544.6889819178934
INFO:root:current train perplexity3.380289316177368
INFO:root:current mean train loss 1544.6846469324214
INFO:root:current train perplexity3.3801093101501465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.08s/it]
INFO:root:final mean train loss: 1544.673296752868
INFO:root:final train perplexity: 3.381171941757202
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.09s/it]
INFO:root:eval mean loss: 3383.78760792042
INFO:root:eval perplexity: 16.065027236938477
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/52
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [4:47:10<4:25:52, 332.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1537.0379123917546
INFO:root:current train perplexity3.367928981781006
INFO:root:current mean train loss 1535.0153708536118
INFO:root:current train perplexity3.3624868392944336
INFO:root:current mean train loss 1528.1857241573266
INFO:root:current train perplexity3.3443636894226074
INFO:root:current mean train loss 1531.0255241692844
INFO:root:current train perplexity3.3530561923980713
INFO:root:current mean train loss 1530.5067029996442
INFO:root:current train perplexity3.350584030151367
INFO:root:current mean train loss 1530.644987705028
INFO:root:current train perplexity3.3546438217163086
INFO:root:current mean train loss 1533.2422875869327
INFO:root:current train perplexity3.3570072650909424
INFO:root:current mean train loss 1533.4193779371708
INFO:root:current train perplexity3.354884147644043
INFO:root:current mean train loss 1534.8152360062907
INFO:root:current train perplexity3.355502128601074
INFO:root:current mean train loss 1535.439681618769
INFO:root:current train perplexity3.3579330444335938
INFO:root:current mean train loss 1535.3788248697917
INFO:root:current train perplexity3.3577866554260254
INFO:root:current mean train loss 1536.235130019845
INFO:root:current train perplexity3.3618102073669434
INFO:root:current mean train loss 1535.1696682199313
INFO:root:current train perplexity3.3619792461395264
INFO:root:current mean train loss 1536.47727815155
INFO:root:current train perplexity3.3642921447753906
INFO:root:current mean train loss 1537.7383195255868
INFO:root:current train perplexity3.364840030670166
INFO:root:current mean train loss 1538.9850269927304
INFO:root:current train perplexity3.366034984588623
INFO:root:current mean train loss 1538.990624158636
INFO:root:current train perplexity3.3650877475738525
INFO:root:current mean train loss 1539.899667240299
INFO:root:current train perplexity3.3669278621673584
INFO:root:current mean train loss 1540.097883405802
INFO:root:current train perplexity3.3678090572357178
INFO:root:current mean train loss 1540.0016955646431
INFO:root:current train perplexity3.36873722076416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.86s/it]
INFO:root:final mean train loss: 1540.0016955646431
INFO:root:final train perplexity: 3.36873722076416
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.44s/it]
INFO:root:eval mean loss: 3398.1745774094406
INFO:root:eval perplexity: 16.25581169128418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/53
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [4:52:43<4:20:29, 332.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1528.0092346191407
INFO:root:current train perplexity3.386021852493286
INFO:root:current mean train loss 1541.205802001953
INFO:root:current train perplexity3.3727567195892334
INFO:root:current mean train loss 1531.0495353190104
INFO:root:current train perplexity3.3578433990478516
INFO:root:current mean train loss 1530.95642578125
INFO:root:current train perplexity3.3535826206207275
INFO:root:current mean train loss 1530.4880219726563
INFO:root:current train perplexity3.3514018058776855
INFO:root:current mean train loss 1535.010840250651
INFO:root:current train perplexity3.357015371322632
INFO:root:current mean train loss 1533.225012032645
INFO:root:current train perplexity3.351663589477539
INFO:root:current mean train loss 1533.0281958007813
INFO:root:current train perplexity3.3532345294952393
INFO:root:current mean train loss 1534.5063910590277
INFO:root:current train perplexity3.355703115463257
INFO:root:current mean train loss 1533.8064932861328
INFO:root:current train perplexity3.3547163009643555
INFO:root:current mean train loss 1536.7990904651988
INFO:root:current train perplexity3.359222650527954
INFO:root:current mean train loss 1537.3138532511393
INFO:root:current train perplexity3.3599789142608643
INFO:root:current mean train loss 1538.0064598670372
INFO:root:current train perplexity3.3600943088531494
INFO:root:current mean train loss 1535.761513846261
INFO:root:current train perplexity3.3573544025421143
INFO:root:current mean train loss 1535.666565592448
INFO:root:current train perplexity3.357239007949829
INFO:root:current mean train loss 1536.0820266723633
INFO:root:current train perplexity3.3578829765319824
INFO:root:current mean train loss 1536.6984942267923
INFO:root:current train perplexity3.35789155960083
INFO:root:current mean train loss 1538.059861178928
INFO:root:current train perplexity3.3601062297821045
INFO:root:current mean train loss 1536.56503437243
INFO:root:current train perplexity3.3581836223602295

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:05<00:00, 305.61s/it]
INFO:root:final mean train loss: 1535.658699347284
INFO:root:final train perplexity: 3.3572182655334473
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.64s/it]
INFO:root:eval mean loss: 3392.034961230762
INFO:root:eval perplexity: 16.174116134643555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/54
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [4:58:23<4:16:39, 334.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1527.8527903837316
INFO:root:current train perplexity3.374969244003296
INFO:root:current mean train loss 1518.5915746444311
INFO:root:current train perplexity3.327016592025757
INFO:root:current mean train loss 1524.947039485527
INFO:root:current train perplexity3.327772855758667
INFO:root:current mean train loss 1523.4207189902897
INFO:root:current train perplexity3.3299262523651123
INFO:root:current mean train loss 1529.3358780748838
INFO:root:current train perplexity3.3412423133850098
INFO:root:current mean train loss 1528.044920694436
INFO:root:current train perplexity3.336961269378662
INFO:root:current mean train loss 1527.1385707762486
INFO:root:current train perplexity3.335780382156372
INFO:root:current mean train loss 1526.479327554317
INFO:root:current train perplexity3.337639570236206
INFO:root:current mean train loss 1526.9931727284463
INFO:root:current train perplexity3.3387646675109863
INFO:root:current mean train loss 1527.957728262166
INFO:root:current train perplexity3.34089994430542
INFO:root:current mean train loss 1528.4922407932338
INFO:root:current train perplexity3.342435598373413
INFO:root:current mean train loss 1529.2770817960707
INFO:root:current train perplexity3.3452696800231934
INFO:root:current mean train loss 1529.4019057211958
INFO:root:current train perplexity3.3460640907287598
INFO:root:current mean train loss 1528.3669397445367
INFO:root:current train perplexity3.3451433181762695
INFO:root:current mean train loss 1529.3316469481906
INFO:root:current train perplexity3.345865488052368
INFO:root:current mean train loss 1529.1257558381315
INFO:root:current train perplexity3.3437728881835938
INFO:root:current mean train loss 1529.9057138569206
INFO:root:current train perplexity3.3456010818481445
INFO:root:current mean train loss 1529.9380890941231
INFO:root:current train perplexity3.345266819000244
INFO:root:current mean train loss 1530.3320490533201
INFO:root:current train perplexity3.3449158668518066
INFO:root:current mean train loss 1530.7509619166096
INFO:root:current train perplexity3.3440730571746826

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:04<00:00, 304.99s/it]
INFO:root:final mean train loss: 1531.0467380941125
INFO:root:final train perplexity: 3.345029592514038
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.57s/it]
INFO:root:eval mean loss: 3393.2759265613267
INFO:root:eval perplexity: 16.190595626831055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/55
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [5:04:02<4:12:04, 336.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1513.6266443589154
INFO:root:current train perplexity3.322077512741089
INFO:root:current mean train loss 1522.5594400434352
INFO:root:current train perplexity3.3229823112487793
INFO:root:current mean train loss 1531.7180316631611
INFO:root:current train perplexity3.3331100940704346
INFO:root:current mean train loss 1532.037872862673
INFO:root:current train perplexity3.3339202404022217
INFO:root:current mean train loss 1531.694322717904
INFO:root:current train perplexity3.3358206748962402
INFO:root:current mean train loss 1530.487355207236
INFO:root:current train perplexity3.3331470489501953
INFO:root:current mean train loss 1527.7873985699675
INFO:root:current train perplexity3.327626943588257
INFO:root:current mean train loss 1527.636390789978
INFO:root:current train perplexity3.328035593032837
INFO:root:current mean train loss 1526.6948862784773
INFO:root:current train perplexity3.3278002738952637
INFO:root:current mean train loss 1524.1682726188185
INFO:root:current train perplexity3.325944185256958
INFO:root:current mean train loss 1522.876407468342
INFO:root:current train perplexity3.3263015747070312
INFO:root:current mean train loss 1523.0269053087454
INFO:root:current train perplexity3.3259224891662598
INFO:root:current mean train loss 1524.004267613737
INFO:root:current train perplexity3.32893705368042
INFO:root:current mean train loss 1524.1742958171792
INFO:root:current train perplexity3.3298585414886475
INFO:root:current mean train loss 1524.270349819125
INFO:root:current train perplexity3.3311455249786377
INFO:root:current mean train loss 1525.4617419385847
INFO:root:current train perplexity3.3323237895965576
INFO:root:current mean train loss 1526.1193193974957
INFO:root:current train perplexity3.3335635662078857
INFO:root:current mean train loss 1526.784575324845
INFO:root:current train perplexity3.3349292278289795
INFO:root:current mean train loss 1526.661938050581
INFO:root:current train perplexity3.334165573120117
INFO:root:current mean train loss 1527.608726398898
INFO:root:current train perplexity3.3348934650421143

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.13s/it]
INFO:root:final mean train loss: 1527.160248279812
INFO:root:final train perplexity: 3.3347928524017334
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.59s/it]
INFO:root:eval mean loss: 3398.831100876267
INFO:root:eval perplexity: 16.264564514160156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/56
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [5:09:34<4:05:25, 334.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1532.1730861289827
INFO:root:current train perplexity3.343982696533203
INFO:root:current mean train loss 1525.0694369890832
INFO:root:current train perplexity3.323267936706543
INFO:root:current mean train loss 1521.9090474041334
INFO:root:current train perplexity3.3233206272125244
INFO:root:current mean train loss 1521.1072674612715
INFO:root:current train perplexity3.317209005355835
INFO:root:current mean train loss 1521.0583601653443
INFO:root:current train perplexity3.3172378540039062
INFO:root:current mean train loss 1522.1312725530995
INFO:root:current train perplexity3.317355155944824
INFO:root:current mean train loss 1523.1230930029521
INFO:root:current train perplexity3.3197810649871826
INFO:root:current mean train loss 1521.0297170504432
INFO:root:current train perplexity3.318514823913574
INFO:root:current mean train loss 1520.1108797210084
INFO:root:current train perplexity3.31746244430542
INFO:root:current mean train loss 1519.7486436204078
INFO:root:current train perplexity3.3179385662078857
INFO:root:current mean train loss 1520.7304998773488
INFO:root:current train perplexity3.3200972080230713
INFO:root:current mean train loss 1522.0940804701074
INFO:root:current train perplexity3.3210995197296143
INFO:root:current mean train loss 1523.8297683142548
INFO:root:current train perplexity3.3230812549591064
INFO:root:current mean train loss 1524.9912881011173
INFO:root:current train perplexity3.325484275817871
INFO:root:current mean train loss 1524.9608686829665
INFO:root:current train perplexity3.3261051177978516
INFO:root:current mean train loss 1524.9957579976124
INFO:root:current train perplexity3.3268966674804688
INFO:root:current mean train loss 1524.6060823547991
INFO:root:current train perplexity3.3262531757354736
INFO:root:current mean train loss 1524.3804607467607
INFO:root:current train perplexity3.326045274734497
INFO:root:current mean train loss 1525.123404776451
INFO:root:current train perplexity3.3271405696868896
INFO:root:current mean train loss 1524.2985111551368
INFO:root:current train perplexity3.3261091709136963

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.07s/it]
INFO:root:final mean train loss: 1523.667939694434
INFO:root:final train perplexity: 3.325620651245117
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.09s/it]
INFO:root:eval mean loss: 3405.158648883258
INFO:root:eval perplexity: 16.349231719970703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/57
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [5:15:04<3:59:01, 333.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1499.4187442555146
INFO:root:current train perplexity3.2538933753967285
INFO:root:current mean train loss 1499.4709334600539
INFO:root:current train perplexity3.274324417114258
INFO:root:current mean train loss 1512.1528047020756
INFO:root:current train perplexity3.29191517829895
INFO:root:current mean train loss 1509.4815378603728
INFO:root:current train perplexity3.2907209396362305
INFO:root:current mean train loss 1511.3443997374966
INFO:root:current train perplexity3.292069435119629
INFO:root:current mean train loss 1512.98603412467
INFO:root:current train perplexity3.2964913845062256
INFO:root:current mean train loss 1512.3277132868052
INFO:root:current train perplexity3.2953009605407715
INFO:root:current mean train loss 1512.8535140355427
INFO:root:current train perplexity3.2966277599334717
INFO:root:current mean train loss 1514.2041769423242
INFO:root:current train perplexity3.2977640628814697
INFO:root:current mean train loss 1516.9982065248096
INFO:root:current train perplexity3.303548574447632
INFO:root:current mean train loss 1515.4162339342668
INFO:root:current train perplexity3.3025543689727783
INFO:root:current mean train loss 1515.614319892779
INFO:root:current train perplexity3.3047049045562744
INFO:root:current mean train loss 1517.2378832699749
INFO:root:current train perplexity3.3069334030151367
INFO:root:current mean train loss 1515.9023964865166
INFO:root:current train perplexity3.307041883468628
INFO:root:current mean train loss 1516.3736587233375
INFO:root:current train perplexity3.309290885925293
INFO:root:current mean train loss 1516.8997408029984
INFO:root:current train perplexity3.3095157146453857
INFO:root:current mean train loss 1517.2053369755367
INFO:root:current train perplexity3.309523344039917
INFO:root:current mean train loss 1517.8278923897722
INFO:root:current train perplexity3.3101892471313477
INFO:root:current mean train loss 1518.345485515717
INFO:root:current train perplexity3.3112199306488037
INFO:root:current mean train loss 1519.2897819581071
INFO:root:current train perplexity3.313560962677002

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.74s/it]
INFO:root:final mean train loss: 1519.0009372882391
INFO:root:final train perplexity: 3.3134021759033203
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.99s/it]
INFO:root:eval mean loss: 3401.449600723771
INFO:root:eval perplexity: 16.29955291748047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/58
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [5:20:37<3:53:13, 333.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1509.3425637637868
INFO:root:current train perplexity3.294001340866089
INFO:root:current mean train loss 1508.2555578283361
INFO:root:current train perplexity3.2841603755950928
INFO:root:current mean train loss 1503.0771792763157
INFO:root:current train perplexity3.270735740661621
INFO:root:current mean train loss 1502.666625342431
INFO:root:current train perplexity3.2700846195220947
INFO:root:current mean train loss 1505.496765514256
INFO:root:current train perplexity3.275594711303711
INFO:root:current mean train loss 1507.0004905765893
INFO:root:current train perplexity3.280522108078003
INFO:root:current mean train loss 1503.7594510934648
INFO:root:current train perplexity3.278172731399536
INFO:root:current mean train loss 1505.4958990595144
INFO:root:current train perplexity3.2790496349334717
INFO:root:current mean train loss 1507.3865997142038
INFO:root:current train perplexity3.2842884063720703
INFO:root:current mean train loss 1507.6754413120639
INFO:root:current train perplexity3.286566972732544
INFO:root:current mean train loss 1508.3978229856712
INFO:root:current train perplexity3.2863502502441406
INFO:root:current mean train loss 1509.8230386339662
INFO:root:current train perplexity3.2893261909484863
INFO:root:current mean train loss 1508.954185444279
INFO:root:current train perplexity3.2894885540008545
INFO:root:current mean train loss 1510.2618644411384
INFO:root:current train perplexity3.2906219959259033
INFO:root:current mean train loss 1510.3450659755104
INFO:root:current train perplexity3.291856527328491
INFO:root:current mean train loss 1510.9644575149102
INFO:root:current train perplexity3.295313596725464
INFO:root:current mean train loss 1511.0561207576038
INFO:root:current train perplexity3.29616379737854
INFO:root:current mean train loss 1513.0675589767156
INFO:root:current train perplexity3.2991533279418945
INFO:root:current mean train loss 1513.6134669134408
INFO:root:current train perplexity3.2999699115753174

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:00<00:00, 300.52s/it]
INFO:root:final mean train loss: 1514.57206445214
INFO:root:final train perplexity: 3.301848888397217
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.11s/it]
INFO:root:eval mean loss: 3418.22423619909
INFO:root:eval perplexity: 16.52546501159668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/59
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [5:26:12<3:48:06, 333.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1584.4143676757812
INFO:root:current train perplexity3.4631919860839844
INFO:root:current mean train loss 1511.3274799421722
INFO:root:current train perplexity3.2732207775115967
INFO:root:current mean train loss 1503.8856213258045
INFO:root:current train perplexity3.270453929901123
INFO:root:current mean train loss 1500.7922355197122
INFO:root:current train perplexity3.262580633163452
INFO:root:current mean train loss 1503.8317036035642
INFO:root:current train perplexity3.269484519958496
INFO:root:current mean train loss 1507.507480089408
INFO:root:current train perplexity3.2754383087158203
INFO:root:current mean train loss 1506.3573383318626
INFO:root:current train perplexity3.2758126258850098
INFO:root:current mean train loss 1510.515723421363
INFO:root:current train perplexity3.283475637435913
INFO:root:current mean train loss 1510.3876341251364
INFO:root:current train perplexity3.2888851165771484
INFO:root:current mean train loss 1509.402361749281
INFO:root:current train perplexity3.2892463207244873
INFO:root:current mean train loss 1508.9692526567958
INFO:root:current train perplexity3.289640426635742
INFO:root:current mean train loss 1509.6908849588108
INFO:root:current train perplexity3.289722442626953
INFO:root:current mean train loss 1509.2501405535045
INFO:root:current train perplexity3.2898333072662354
INFO:root:current mean train loss 1509.263153216806
INFO:root:current train perplexity3.2900946140289307
INFO:root:current mean train loss 1509.679172575729
INFO:root:current train perplexity3.29136323928833
INFO:root:current mean train loss 1511.265203686751
INFO:root:current train perplexity3.2917842864990234
INFO:root:current mean train loss 1511.7914901904846
INFO:root:current train perplexity3.292018413543701
INFO:root:current mean train loss 1511.7123648333072
INFO:root:current train perplexity3.2928216457366943
INFO:root:current mean train loss 1511.713960535386
INFO:root:current train perplexity3.2928168773651123
INFO:root:current mean train loss 1511.6914179307555
INFO:root:current train perplexity3.293809652328491

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.17s/it]
INFO:root:final mean train loss: 1511.7168681596304
INFO:root:final train perplexity: 3.294421911239624
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.54s/it]
INFO:root:eval mean loss: 3414.0851911481795
INFO:root:eval perplexity: 16.469436645507812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/60
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [5:31:42<3:41:50, 332.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1475.2945492393092
INFO:root:current train perplexity3.264559745788574
INFO:root:current mean train loss 1496.5678064682904
INFO:root:current train perplexity3.274930000305176
INFO:root:current mean train loss 1508.2039326706977
INFO:root:current train perplexity3.2819790840148926
INFO:root:current mean train loss 1508.4603302097619
INFO:root:current train perplexity3.284576416015625
INFO:root:current mean train loss 1508.7846688427617
INFO:root:current train perplexity3.2854645252227783
INFO:root:current mean train loss 1506.7616660645472
INFO:root:current train perplexity3.28590726852417
INFO:root:current mean train loss 1505.8600139463854
INFO:root:current train perplexity3.2832884788513184
INFO:root:current mean train loss 1502.58454633986
INFO:root:current train perplexity3.278721332550049
INFO:root:current mean train loss 1502.1600057115195
INFO:root:current train perplexity3.2777321338653564
INFO:root:current mean train loss 1501.870385104606
INFO:root:current train perplexity3.2753467559814453
INFO:root:current mean train loss 1504.6493145135014
INFO:root:current train perplexity3.2784199714660645
INFO:root:current mean train loss 1504.6135970619346
INFO:root:current train perplexity3.2796764373779297
INFO:root:current mean train loss 1504.9152963214276
INFO:root:current train perplexity3.279221773147583
INFO:root:current mean train loss 1504.0570132217233
INFO:root:current train perplexity3.2778868675231934
INFO:root:current mean train loss 1505.1651206147594
INFO:root:current train perplexity3.280238628387451
INFO:root:current mean train loss 1505.5926209902434
INFO:root:current train perplexity3.2812812328338623
INFO:root:current mean train loss 1505.7530086298207
INFO:root:current train perplexity3.280845880508423
INFO:root:current mean train loss 1507.0529940673403
INFO:root:current train perplexity3.282219886779785
INFO:root:current mean train loss 1507.5858286500568
INFO:root:current train perplexity3.2834160327911377
INFO:root:current mean train loss 1508.7338262879023
INFO:root:current train perplexity3.285231590270996

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.22s/it]
INFO:root:final mean train loss: 1508.4885314541277
INFO:root:final train perplexity: 3.2860450744628906
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.09s/it]
INFO:root:eval mean loss: 3411.674213031391
INFO:root:eval perplexity: 16.436880111694336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/61
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [5:37:14<3:36:08, 332.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1514.8187323676216
INFO:root:current train perplexity3.2629470825195312
INFO:root:current mean train loss 1493.669241512523
INFO:root:current train perplexity3.237884998321533
INFO:root:current mean train loss 1497.5611986063295
INFO:root:current train perplexity3.2504093647003174
INFO:root:current mean train loss 1499.6950091407411
INFO:root:current train perplexity3.264214038848877
INFO:root:current mean train loss 1501.6690699026126
INFO:root:current train perplexity3.2672741413116455
INFO:root:current mean train loss 1503.164442831011
INFO:root:current train perplexity3.2690939903259277
INFO:root:current mean train loss 1502.2866370243096
INFO:root:current train perplexity3.2687582969665527
INFO:root:current mean train loss 1503.4937520234482
INFO:root:current train perplexity3.2707760334014893
INFO:root:current mean train loss 1505.836377157549
INFO:root:current train perplexity3.2769575119018555
INFO:root:current mean train loss 1506.6785350049663
INFO:root:current train perplexity3.278621196746826
INFO:root:current mean train loss 1505.6002654440153
INFO:root:current train perplexity3.2761118412017822
INFO:root:current mean train loss 1505.345109106789
INFO:root:current train perplexity3.274427890777588
INFO:root:current mean train loss 1504.9116349204844
INFO:root:current train perplexity3.273242712020874
INFO:root:current mean train loss 1505.3970246457768
INFO:root:current train perplexity3.2741079330444336
INFO:root:current mean train loss 1504.785308922898
INFO:root:current train perplexity3.274564504623413
INFO:root:current mean train loss 1504.4002777735393
INFO:root:current train perplexity3.274623394012451
INFO:root:current mean train loss 1503.8112783268787
INFO:root:current train perplexity3.2739410400390625
INFO:root:current mean train loss 1504.042208482593
INFO:root:current train perplexity3.2741308212280273
INFO:root:current mean train loss 1504.1346582483363
INFO:root:current train perplexity3.273963689804077
INFO:root:current mean train loss 1504.430157558977
INFO:root:current train perplexity3.2744786739349365

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.96s/it]
INFO:root:final mean train loss: 1504.1184883829444
INFO:root:final train perplexity: 3.2747395038604736
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.69s/it]
INFO:root:eval mean loss: 3409.922235712275
INFO:root:eval perplexity: 16.413267135620117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/62
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [5:42:45<3:30:10, 331.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1498.8238755711968
INFO:root:current train perplexity3.236203908920288
INFO:root:current mean train loss 1490.3708025365095
INFO:root:current train perplexity3.2478930950164795
INFO:root:current mean train loss 1490.7962246016552
INFO:root:current train perplexity3.2442266941070557
INFO:root:current mean train loss 1494.2843349554046
INFO:root:current train perplexity3.251713752746582
INFO:root:current mean train loss 1493.7154185314052
INFO:root:current train perplexity3.250916004180908
INFO:root:current mean train loss 1495.748879513732
INFO:root:current train perplexity3.2545101642608643
INFO:root:current mean train loss 1496.5506118844517
INFO:root:current train perplexity3.2549350261688232
INFO:root:current mean train loss 1497.7387350014008
INFO:root:current train perplexity3.257469415664673
INFO:root:current mean train loss 1499.7012657532239
INFO:root:current train perplexity3.2594752311706543
INFO:root:current mean train loss 1500.0477844430418
INFO:root:current train perplexity3.259469985961914
INFO:root:current mean train loss 1500.8604205386025
INFO:root:current train perplexity3.26084303855896
INFO:root:current mean train loss 1500.9647713336135
INFO:root:current train perplexity3.262709856033325
INFO:root:current mean train loss 1500.4068537268367
INFO:root:current train perplexity3.2633705139160156
INFO:root:current mean train loss 1500.4806390890612
INFO:root:current train perplexity3.26318359375
INFO:root:current mean train loss 1501.5453433662303
INFO:root:current train perplexity3.265738010406494
INFO:root:current mean train loss 1502.240124409535
INFO:root:current train perplexity3.267758369445801
INFO:root:current mean train loss 1501.7866305462605
INFO:root:current train perplexity3.2675390243530273
INFO:root:current mean train loss 1501.4926057283496
INFO:root:current train perplexity3.2668440341949463
INFO:root:current mean train loss 1501.2668175077156
INFO:root:current train perplexity3.2667713165283203
INFO:root:current mean train loss 1501.270973467302
INFO:root:current train perplexity3.266136646270752

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.15s/it]
INFO:root:final mean train loss: 1500.75799015755
INFO:root:final train perplexity: 3.2660720348358154
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.89s/it]
INFO:root:eval mean loss: 3411.412256739161
INFO:root:eval perplexity: 16.433349609375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/63
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [5:48:15<3:24:25, 331.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1497.4329031808036
INFO:root:current train perplexity3.2573070526123047
INFO:root:current mean train loss 1496.0630586511948
INFO:root:current train perplexity3.255150079727173
INFO:root:current mean train loss 1496.6410843460649
INFO:root:current train perplexity3.251549005508423
INFO:root:current mean train loss 1493.5307851430532
INFO:root:current train perplexity3.2447001934051514
INFO:root:current mean train loss 1496.4324649891955
INFO:root:current train perplexity3.2555644512176514
INFO:root:current mean train loss 1495.6607445432428
INFO:root:current train perplexity3.2585818767547607
INFO:root:current mean train loss 1496.3757183928988
INFO:root:current train perplexity3.254094362258911
INFO:root:current mean train loss 1497.946842659294
INFO:root:current train perplexity3.2569849491119385
INFO:root:current mean train loss 1499.2568623159123
INFO:root:current train perplexity3.2579762935638428
INFO:root:current mean train loss 1499.7929328839803
INFO:root:current train perplexity3.2572076320648193
INFO:root:current mean train loss 1499.5781404013946
INFO:root:current train perplexity3.2564258575439453
INFO:root:current mean train loss 1498.8905836838942
INFO:root:current train perplexity3.2534396648406982
INFO:root:current mean train loss 1498.9842490849533
INFO:root:current train perplexity3.252791166305542
INFO:root:current mean train loss 1498.3655351847628
INFO:root:current train perplexity3.2528250217437744
INFO:root:current mean train loss 1498.0691445279283
INFO:root:current train perplexity3.2534639835357666
INFO:root:current mean train loss 1497.269789152692
INFO:root:current train perplexity3.252457618713379
INFO:root:current mean train loss 1497.4434024285413
INFO:root:current train perplexity3.2537288665771484
INFO:root:current mean train loss 1497.6453625005518
INFO:root:current train perplexity3.253856658935547
INFO:root:current mean train loss 1497.2083666469962
INFO:root:current train perplexity3.2541165351867676
INFO:root:current mean train loss 1497.3410013731361
INFO:root:current train perplexity3.255964994430542

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.72s/it]
INFO:root:final mean train loss: 1496.8579967689225
INFO:root:final train perplexity: 3.2560417652130127
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.58s/it]
INFO:root:eval mean loss: 3423.3000634912255
INFO:root:eval perplexity: 16.594440460205078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/64
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [5:53:45<3:18:36, 331.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1492.195451407597
INFO:root:current train perplexity3.2299392223358154
INFO:root:current mean train loss 1496.2828323445856
INFO:root:current train perplexity3.246203660964966
INFO:root:current mean train loss 1496.1303591844512
INFO:root:current train perplexity3.2421250343322754
INFO:root:current mean train loss 1488.3377814872013
INFO:root:current train perplexity3.237215280532837
INFO:root:current mean train loss 1487.708956050677
INFO:root:current train perplexity3.238901376724243
INFO:root:current mean train loss 1486.58454398524
INFO:root:current train perplexity3.237818479537964
INFO:root:current mean train loss 1486.595731199395
INFO:root:current train perplexity3.2365949153900146
INFO:root:current mean train loss 1486.039855879477
INFO:root:current train perplexity3.2345683574676514
INFO:root:current mean train loss 1489.1690211419725
INFO:root:current train perplexity3.2375550270080566
INFO:root:current mean train loss 1491.4173648297
INFO:root:current train perplexity3.2416882514953613
INFO:root:current mean train loss 1490.679613943372
INFO:root:current train perplexity3.2400403022766113
INFO:root:current mean train loss 1492.2865811920808
INFO:root:current train perplexity3.244568347930908
INFO:root:current mean train loss 1492.167239458133
INFO:root:current train perplexity3.244389533996582
INFO:root:current mean train loss 1492.9867202989817
INFO:root:current train perplexity3.2460744380950928
INFO:root:current mean train loss 1493.8988551003226
INFO:root:current train perplexity3.2468619346618652
INFO:root:current mean train loss 1494.6280781409992
INFO:root:current train perplexity3.2487082481384277
INFO:root:current mean train loss 1494.479573953625
INFO:root:current train perplexity3.250092029571533
INFO:root:current mean train loss 1494.1774242467297
INFO:root:current train perplexity3.2489123344421387
INFO:root:current mean train loss 1494.2421741738292
INFO:root:current train perplexity3.249030113220215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.32s/it]
INFO:root:final mean train loss: 1494.7016738837738
INFO:root:final train perplexity: 3.250509262084961
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.61s/it]
INFO:root:eval mean loss: 3431.7707790798613
INFO:root:eval perplexity: 16.71018409729004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/65
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [5:59:16<3:13:01, 330.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1470.07177734375
INFO:root:current train perplexity3.2264161109924316
INFO:root:current mean train loss 1478.3007037823018
INFO:root:current train perplexity3.216768503189087
INFO:root:current mean train loss 1494.6237003102021
INFO:root:current train perplexity3.2465908527374268
INFO:root:current mean train loss 1489.7101617110402
INFO:root:current train perplexity3.233039140701294
INFO:root:current mean train loss 1488.256747406308
INFO:root:current train perplexity3.2312326431274414
INFO:root:current mean train loss 1490.2362288217696
INFO:root:current train perplexity3.2347207069396973
INFO:root:current mean train loss 1490.0598952943915
INFO:root:current train perplexity3.233206272125244
INFO:root:current mean train loss 1489.5575422807174
INFO:root:current train perplexity3.2339375019073486
INFO:root:current mean train loss 1491.535832798896
INFO:root:current train perplexity3.238013982772827
INFO:root:current mean train loss 1491.1241852076707
INFO:root:current train perplexity3.2354822158813477
INFO:root:current mean train loss 1490.4068252137934
INFO:root:current train perplexity3.2330753803253174
INFO:root:current mean train loss 1489.3085487476294
INFO:root:current train perplexity3.2327773571014404
INFO:root:current mean train loss 1490.3467666778058
INFO:root:current train perplexity3.2356982231140137
INFO:root:current mean train loss 1490.738865951819
INFO:root:current train perplexity3.237028121948242
INFO:root:current mean train loss 1490.822954487597
INFO:root:current train perplexity3.238527297973633
INFO:root:current mean train loss 1490.5789157786269
INFO:root:current train perplexity3.2384276390075684
INFO:root:current mean train loss 1490.852275287124
INFO:root:current train perplexity3.2381913661956787
INFO:root:current mean train loss 1490.051133276711
INFO:root:current train perplexity3.2386014461517334
INFO:root:current mean train loss 1490.496591098557
INFO:root:current train perplexity3.24014949798584
INFO:root:current mean train loss 1491.1326094555254
INFO:root:current train perplexity3.240997552871704

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.35s/it]
INFO:root:final mean train loss: 1491.6208732478017
INFO:root:final train perplexity: 3.2426209449768066
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.46s/it]
INFO:root:eval mean loss: 3430.0052354600693
INFO:root:eval perplexity: 16.685985565185547
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/66
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [6:04:46<3:07:25, 330.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1453.5127011253721
INFO:root:current train perplexity3.155651330947876
INFO:root:current mean train loss 1489.8465959533187
INFO:root:current train perplexity3.2117645740509033
INFO:root:current mean train loss 1480.9671735806703
INFO:root:current train perplexity3.2147011756896973
INFO:root:current mean train loss 1486.5349889262072
INFO:root:current train perplexity3.2278878688812256
INFO:root:current mean train loss 1489.4955561767
INFO:root:current train perplexity3.234264373779297
INFO:root:current mean train loss 1490.2282733587751
INFO:root:current train perplexity3.2380311489105225
INFO:root:current mean train loss 1489.5657697545541
INFO:root:current train perplexity3.2355470657348633
INFO:root:current mean train loss 1488.5260791963744
INFO:root:current train perplexity3.2296254634857178
INFO:root:current mean train loss 1488.851011771087
INFO:root:current train perplexity3.229658842086792
INFO:root:current mean train loss 1489.6546349872337
INFO:root:current train perplexity3.2310240268707275
INFO:root:current mean train loss 1487.7369407481942
INFO:root:current train perplexity3.2289791107177734
INFO:root:current mean train loss 1487.3396464338482
INFO:root:current train perplexity3.2285401821136475
INFO:root:current mean train loss 1487.342881011338
INFO:root:current train perplexity3.2282915115356445
INFO:root:current mean train loss 1485.433703622522
INFO:root:current train perplexity3.227994918823242
INFO:root:current mean train loss 1486.1541804743854
INFO:root:current train perplexity3.2293808460235596
INFO:root:current mean train loss 1486.0383982962483
INFO:root:current train perplexity3.230285406112671
INFO:root:current mean train loss 1486.9256778554663
INFO:root:current train perplexity3.230952024459839
INFO:root:current mean train loss 1487.2829030207047
INFO:root:current train perplexity3.2327146530151367
INFO:root:current mean train loss 1488.3719510576477
INFO:root:current train perplexity3.233405113220215
INFO:root:current mean train loss 1487.7847468283323
INFO:root:current train perplexity3.232551097869873

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.50s/it]
INFO:root:final mean train loss: 1488.3527601802823
INFO:root:final train perplexity: 3.23427414894104
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.61s/it]
INFO:root:eval mean loss: 3429.0106608072915
INFO:root:eval perplexity: 16.672378540039062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/67
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [6:10:17<3:01:55, 330.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1477.4743523848683
INFO:root:current train perplexity3.2176287174224854
INFO:root:current mean train loss 1473.6848507203918
INFO:root:current train perplexity3.206141710281372
INFO:root:current mean train loss 1476.1453995905003
INFO:root:current train perplexity3.2085320949554443
INFO:root:current mean train loss 1476.1436012764655
INFO:root:current train perplexity3.2123734951019287
INFO:root:current mean train loss 1477.9054074918843
INFO:root:current train perplexity3.2140753269195557
INFO:root:current mean train loss 1482.5117677596422
INFO:root:current train perplexity3.219170331954956
INFO:root:current mean train loss 1485.3887017229133
INFO:root:current train perplexity3.2211978435516357
INFO:root:current mean train loss 1482.184072768462
INFO:root:current train perplexity3.218257188796997
INFO:root:current mean train loss 1483.195803548954
INFO:root:current train perplexity3.218998432159424
INFO:root:current mean train loss 1485.107778325518
INFO:root:current train perplexity3.2209887504577637
INFO:root:current mean train loss 1485.366859509536
INFO:root:current train perplexity3.2231860160827637
INFO:root:current mean train loss 1486.8593830450557
INFO:root:current train perplexity3.2241244316101074
INFO:root:current mean train loss 1486.5936825556594
INFO:root:current train perplexity3.2239112854003906
INFO:root:current mean train loss 1485.4141618531917
INFO:root:current train perplexity3.223128080368042
INFO:root:current mean train loss 1485.5803041842782
INFO:root:current train perplexity3.2239561080932617
INFO:root:current mean train loss 1486.4468321087147
INFO:root:current train perplexity3.2252588272094727
INFO:root:current mean train loss 1486.1087326776415
INFO:root:current train perplexity3.2252066135406494
INFO:root:current mean train loss 1486.4775968667964
INFO:root:current train perplexity3.2266042232513428
INFO:root:current mean train loss 1486.9582718111355
INFO:root:current train perplexity3.2275290489196777
INFO:root:current mean train loss 1485.6707082774
INFO:root:current train perplexity3.226485252380371

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.30s/it]
INFO:root:final mean train loss: 1485.4119696989844
INFO:root:final train perplexity: 3.2267818450927734
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.47s/it]
INFO:root:eval mean loss: 3437.1184001384195
INFO:root:eval perplexity: 16.78367042541504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/68
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [6:15:47<2:56:20, 330.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1467.3726806640625
INFO:root:current train perplexity3.197601318359375
INFO:root:current mean train loss 1486.7506859564012
INFO:root:current train perplexity3.210407257080078
INFO:root:current mean train loss 1484.736958582261
INFO:root:current train perplexity3.215898036956787
INFO:root:current mean train loss 1486.837118659221
INFO:root:current train perplexity3.2213940620422363
INFO:root:current mean train loss 1485.424452159169
INFO:root:current train perplexity3.2223715782165527
INFO:root:current mean train loss 1483.1963968362895
INFO:root:current train perplexity3.217621088027954
INFO:root:current mean train loss 1483.074238691257
INFO:root:current train perplexity3.21783709526062
INFO:root:current mean train loss 1482.8066684343958
INFO:root:current train perplexity3.213876962661743
INFO:root:current mean train loss 1481.4599119666027
INFO:root:current train perplexity3.212535858154297
INFO:root:current mean train loss 1481.5967203349967
INFO:root:current train perplexity3.2126078605651855
INFO:root:current mean train loss 1481.171826403288
INFO:root:current train perplexity3.2126598358154297
INFO:root:current mean train loss 1482.9876770283752
INFO:root:current train perplexity3.2158620357513428
INFO:root:current mean train loss 1483.5335823697399
INFO:root:current train perplexity3.2170629501342773
INFO:root:current mean train loss 1483.2599273343808
INFO:root:current train perplexity3.2174465656280518
INFO:root:current mean train loss 1483.91811800298
INFO:root:current train perplexity3.21874737739563
INFO:root:current mean train loss 1484.2247498147358
INFO:root:current train perplexity3.21893048286438
INFO:root:current mean train loss 1485.085340129933
INFO:root:current train perplexity3.2208385467529297
INFO:root:current mean train loss 1484.2247523120325
INFO:root:current train perplexity3.220181941986084
INFO:root:current mean train loss 1483.6073256664843
INFO:root:current train perplexity3.2195701599121094
INFO:root:current mean train loss 1483.1087456042198
INFO:root:current train perplexity3.2194128036499023

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.76s/it]
INFO:root:final mean train loss: 1482.722692323224
INFO:root:final train perplexity: 3.219944715499878
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.56s/it]
INFO:root:eval mean loss: 3440.303434538054
INFO:root:eval perplexity: 16.827592849731445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/69
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [6:21:19<2:51:02, 331.05s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1459.3455997043186
INFO:root:current train perplexity3.1826467514038086
INFO:root:current mean train loss 1468.2934300622276
INFO:root:current train perplexity3.1977691650390625
INFO:root:current mean train loss 1468.5326856725355
INFO:root:current train perplexity3.198730230331421
INFO:root:current mean train loss 1466.9812592537173
INFO:root:current train perplexity3.1925852298736572
INFO:root:current mean train loss 1471.2200842388606
INFO:root:current train perplexity3.194531202316284
INFO:root:current mean train loss 1474.0628391079135
INFO:root:current train perplexity3.201934576034546
INFO:root:current mean train loss 1475.2542435782295
INFO:root:current train perplexity3.2050986289978027
INFO:root:current mean train loss 1474.595745027374
INFO:root:current train perplexity3.20390248298645
INFO:root:current mean train loss 1473.0979778044814
INFO:root:current train perplexity3.2034988403320312
INFO:root:current mean train loss 1473.8851937502009
INFO:root:current train perplexity3.2048497200012207
INFO:root:current mean train loss 1473.9818151673273
INFO:root:current train perplexity3.2052161693573
INFO:root:current mean train loss 1475.2474303782597
INFO:root:current train perplexity3.206460475921631
INFO:root:current mean train loss 1475.1882107332817
INFO:root:current train perplexity3.2053980827331543
INFO:root:current mean train loss 1474.5678447578807
INFO:root:current train perplexity3.205470323562622
INFO:root:current mean train loss 1475.5427843176801
INFO:root:current train perplexity3.206962823867798
INFO:root:current mean train loss 1475.608043874493
INFO:root:current train perplexity3.2070634365081787
INFO:root:current mean train loss 1477.2712384821696
INFO:root:current train perplexity3.2085022926330566
INFO:root:current mean train loss 1477.8997992866464
INFO:root:current train perplexity3.2088422775268555
INFO:root:current mean train loss 1478.9392496744792
INFO:root:current train perplexity3.2096829414367676
INFO:root:current mean train loss 1479.239710747833
INFO:root:current train perplexity3.2103323936462402

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.73s/it]
INFO:root:final mean train loss: 1479.156005243791
INFO:root:final train perplexity: 3.2109010219573975
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.06s/it]
INFO:root:eval mean loss: 3441.887738568647
INFO:root:eval perplexity: 16.849485397338867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/70
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [6:26:51<2:45:34, 331.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1463.8238264791082
INFO:root:current train perplexity3.205108404159546
INFO:root:current mean train loss 1456.9263367022156
INFO:root:current train perplexity3.183241844177246
INFO:root:current mean train loss 1463.5676239964046
INFO:root:current train perplexity3.1870973110198975
INFO:root:current mean train loss 1462.993598996827
INFO:root:current train perplexity3.1855318546295166
INFO:root:current mean train loss 1468.6799893057419
INFO:root:current train perplexity3.1938281059265137
INFO:root:current mean train loss 1468.6903235754457
INFO:root:current train perplexity3.194702386856079
INFO:root:current mean train loss 1469.24266904878
INFO:root:current train perplexity3.193140745162964
INFO:root:current mean train loss 1469.3379692203343
INFO:root:current train perplexity3.191838502883911
INFO:root:current mean train loss 1471.2527819398551
INFO:root:current train perplexity3.1945784091949463
INFO:root:current mean train loss 1473.73850761699
INFO:root:current train perplexity3.196131944656372
INFO:root:current mean train loss 1471.959290167298
INFO:root:current train perplexity3.1948471069335938
INFO:root:current mean train loss 1471.4485920744848
INFO:root:current train perplexity3.195638418197632
INFO:root:current mean train loss 1472.2501735879619
INFO:root:current train perplexity3.1973836421966553
INFO:root:current mean train loss 1472.3696297850859
INFO:root:current train perplexity3.1982357501983643
INFO:root:current mean train loss 1472.9324833938465
INFO:root:current train perplexity3.1995279788970947
INFO:root:current mean train loss 1472.7427479940213
INFO:root:current train perplexity3.1996219158172607
INFO:root:current mean train loss 1473.8632375966733
INFO:root:current train perplexity3.2000153064727783
INFO:root:current mean train loss 1474.6359986784473
INFO:root:current train perplexity3.199824810028076
INFO:root:current mean train loss 1475.6767046288753
INFO:root:current train perplexity3.2007718086242676

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.22s/it]
INFO:root:final mean train loss: 1475.904190625197
INFO:root:final train perplexity: 3.202676773071289
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.70s/it]
INFO:root:eval mean loss: 3449.3804290129974
INFO:root:eval perplexity: 16.953399658203125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/71
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [6:32:20<2:39:49, 330.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1498.9461263020833
INFO:root:current train perplexity3.1800336837768555
INFO:root:current mean train loss 1471.353772433299
INFO:root:current train perplexity3.1769683361053467
INFO:root:current mean train loss 1462.3708822009633
INFO:root:current train perplexity3.167983055114746
INFO:root:current mean train loss 1462.1168300653594
INFO:root:current train perplexity3.1656877994537354
INFO:root:current mean train loss 1464.7190888503503
INFO:root:current train perplexity3.1747782230377197
INFO:root:current mean train loss 1463.1242909789557
INFO:root:current train perplexity3.1724159717559814
INFO:root:current mean train loss 1465.8805070631574
INFO:root:current train perplexity3.178614377975464
INFO:root:current mean train loss 1468.863335196087
INFO:root:current train perplexity3.184633255004883
INFO:root:current mean train loss 1470.1539271806664
INFO:root:current train perplexity3.1856861114501953
INFO:root:current mean train loss 1469.9732385765901
INFO:root:current train perplexity3.185245990753174
INFO:root:current mean train loss 1471.1204837624643
INFO:root:current train perplexity3.189241886138916
INFO:root:current mean train loss 1467.1027445732793
INFO:root:current train perplexity3.184969663619995
INFO:root:current mean train loss 1468.901539462518
INFO:root:current train perplexity3.186476469039917
INFO:root:current mean train loss 1471.0049043103345
INFO:root:current train perplexity3.1893274784088135
INFO:root:current mean train loss 1471.5290625451469
INFO:root:current train perplexity3.1916604042053223
INFO:root:current mean train loss 1471.786200170023
INFO:root:current train perplexity3.191007614135742
INFO:root:current mean train loss 1471.6132994921388
INFO:root:current train perplexity3.1924047470092773
INFO:root:current mean train loss 1470.8819637320944
INFO:root:current train perplexity3.19191575050354
INFO:root:current mean train loss 1471.6877228492915
INFO:root:current train perplexity3.19364333152771
INFO:root:current mean train loss 1473.7140551604105
INFO:root:current train perplexity3.1957619190216064

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.85s/it]
INFO:root:final mean train loss: 1473.6799200060868
INFO:root:final train perplexity: 3.1970632076263428
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.81s/it]
INFO:root:eval mean loss: 3446.5689605621246
INFO:root:eval perplexity: 16.914335250854492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/72
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [6:37:54<2:34:41, 331.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1493.527683423913
INFO:root:current train perplexity3.198467493057251
INFO:root:current mean train loss 1477.6682486185214
INFO:root:current train perplexity3.188040256500244
INFO:root:current mean train loss 1469.3441693087864
INFO:root:current train perplexity3.177421808242798
INFO:root:current mean train loss 1468.886808696546
INFO:root:current train perplexity3.1772730350494385
INFO:root:current mean train loss 1468.9499537691156
INFO:root:current train perplexity3.1794402599334717
INFO:root:current mean train loss 1470.7185938526977
INFO:root:current train perplexity3.182469129562378
INFO:root:current mean train loss 1469.515457079843
INFO:root:current train perplexity3.1800780296325684
INFO:root:current mean train loss 1469.891599367598
INFO:root:current train perplexity3.186790943145752
INFO:root:current mean train loss 1469.8441627845439
INFO:root:current train perplexity3.1870064735412598
INFO:root:current mean train loss 1470.4417417780421
INFO:root:current train perplexity3.188189744949341
INFO:root:current mean train loss 1471.6636323304238
INFO:root:current train perplexity3.1890757083892822
INFO:root:current mean train loss 1471.6018246848564
INFO:root:current train perplexity3.1894214153289795
INFO:root:current mean train loss 1471.1337289755595
INFO:root:current train perplexity3.1893670558929443
INFO:root:current mean train loss 1470.557788990162
INFO:root:current train perplexity3.1886866092681885
INFO:root:current mean train loss 1470.3115584372804
INFO:root:current train perplexity3.1886940002441406
INFO:root:current mean train loss 1471.0277954021412
INFO:root:current train perplexity3.190042734146118
INFO:root:current mean train loss 1471.6643058884974
INFO:root:current train perplexity3.1904876232147217
INFO:root:current mean train loss 1471.5402195820336
INFO:root:current train perplexity3.1900901794433594
INFO:root:current mean train loss 1471.5873395341214
INFO:root:current train perplexity3.189021110534668
INFO:root:current mean train loss 1471.3209142184046
INFO:root:current train perplexity3.1895978450775146

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.56s/it]
INFO:root:final mean train loss: 1470.94035415534
INFO:root:final train perplexity: 3.1901628971099854
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.54s/it]
INFO:root:eval mean loss: 3452.8930722714904
INFO:root:eval perplexity: 17.002334594726562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/73
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [6:43:26<2:29:19, 331.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1461.0109313964845
INFO:root:current train perplexity3.2071497440338135
INFO:root:current mean train loss 1464.249960763114
INFO:root:current train perplexity3.1806693077087402
INFO:root:current mean train loss 1459.4725438435873
INFO:root:current train perplexity3.1725857257843018
INFO:root:current mean train loss 1462.2050741756664
INFO:root:current train perplexity3.175844192504883
INFO:root:current mean train loss 1466.0647341641513
INFO:root:current train perplexity3.1785800457000732
INFO:root:current mean train loss 1467.078273066768
INFO:root:current train perplexity3.1838762760162354
INFO:root:current mean train loss 1467.0837408065795
INFO:root:current train perplexity3.1794495582580566
INFO:root:current mean train loss 1466.4403618889885
INFO:root:current train perplexity3.178635358810425
INFO:root:current mean train loss 1467.2179299490792
INFO:root:current train perplexity3.180115222930908
INFO:root:current mean train loss 1467.0845190169964
INFO:root:current train perplexity3.1816930770874023
INFO:root:current mean train loss 1467.79506249061
INFO:root:current train perplexity3.1834733486175537
INFO:root:current mean train loss 1467.6491347998904
INFO:root:current train perplexity3.184971570968628
INFO:root:current mean train loss 1468.5442632859754
INFO:root:current train perplexity3.186086416244507
INFO:root:current mean train loss 1468.5750262360075
INFO:root:current train perplexity3.1852166652679443
INFO:root:current mean train loss 1467.5966501871744
INFO:root:current train perplexity3.1826324462890625
INFO:root:current mean train loss 1467.5274202421115
INFO:root:current train perplexity3.183074474334717
INFO:root:current mean train loss 1468.0822611738995
INFO:root:current train perplexity3.1832644939422607
INFO:root:current mean train loss 1468.4245548642914
INFO:root:current train perplexity3.183608293533325
INFO:root:current mean train loss 1468.8537230781888
INFO:root:current train perplexity3.1845803260803223
INFO:root:current mean train loss 1469.251528773357
INFO:root:current train perplexity3.1848132610321045

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.92s/it]
INFO:root:final mean train loss: 1468.7054500916481
INFO:root:final train perplexity: 3.1845450401306152
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.56s/it]
INFO:root:eval mean loss: 3454.676790071321
INFO:root:eval perplexity: 17.027238845825195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/74
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [6:48:57<2:23:34, 331.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1454.4134671395286
INFO:root:current train perplexity3.1488254070281982
INFO:root:current mean train loss 1470.7284300980295
INFO:root:current train perplexity3.179854393005371
INFO:root:current mean train loss 1468.2403759195647
INFO:root:current train perplexity3.169603109359741
INFO:root:current mean train loss 1464.45726273908
INFO:root:current train perplexity3.1675899028778076
INFO:root:current mean train loss 1461.441500273523
INFO:root:current train perplexity3.165370464324951
INFO:root:current mean train loss 1464.496205519945
INFO:root:current train perplexity3.1734676361083984
INFO:root:current mean train loss 1464.8969334525423
INFO:root:current train perplexity3.1707985401153564
INFO:root:current mean train loss 1463.5825980626134
INFO:root:current train perplexity3.1701183319091797
INFO:root:current mean train loss 1463.9498328049792
INFO:root:current train perplexity3.172606945037842
INFO:root:current mean train loss 1463.3147009647255
INFO:root:current train perplexity3.1713194847106934
INFO:root:current mean train loss 1462.354616798538
INFO:root:current train perplexity3.1685385704040527
INFO:root:current mean train loss 1464.4702980878958
INFO:root:current train perplexity3.1703217029571533
INFO:root:current mean train loss 1463.2094461445593
INFO:root:current train perplexity3.169506072998047
INFO:root:current mean train loss 1464.570664857711
INFO:root:current train perplexity3.1736249923706055
INFO:root:current mean train loss 1465.00248505665
INFO:root:current train perplexity3.174980401992798
INFO:root:current mean train loss 1465.1813430149125
INFO:root:current train perplexity3.176025152206421
INFO:root:current mean train loss 1465.7905652098577
INFO:root:current train perplexity3.1772987842559814
INFO:root:current mean train loss 1465.6386630514771
INFO:root:current train perplexity3.1767842769622803
INFO:root:current mean train loss 1467.2871694569956
INFO:root:current train perplexity3.1809122562408447
INFO:root:current mean train loss 1466.8922319992137
INFO:root:current train perplexity3.1797358989715576

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.10s/it]
INFO:root:final mean train loss: 1466.79425091919
INFO:root:final train perplexity: 3.179748773574829
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.11s/it]
INFO:root:eval mean loss: 3464.170025983014
INFO:root:eval perplexity: 17.160404205322266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/75
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [6:54:28<2:18:06, 331.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1469.1907167176942
INFO:root:current train perplexity3.1879305839538574
INFO:root:current mean train loss 1456.5943442158316
INFO:root:current train perplexity3.1631648540496826
INFO:root:current mean train loss 1462.6173910990249
INFO:root:current train perplexity3.165799856185913
INFO:root:current mean train loss 1463.7729890384776
INFO:root:current train perplexity3.1662964820861816
INFO:root:current mean train loss 1465.773767913947
INFO:root:current train perplexity3.1718029975891113
INFO:root:current mean train loss 1463.7096914896151
INFO:root:current train perplexity3.172147035598755
INFO:root:current mean train loss 1462.4362666189493
INFO:root:current train perplexity3.169090986251831
INFO:root:current mean train loss 1463.863798235122
INFO:root:current train perplexity3.1717679500579834
INFO:root:current mean train loss 1462.7492483038652
INFO:root:current train perplexity3.1680006980895996
INFO:root:current mean train loss 1464.6457979488177
INFO:root:current train perplexity3.171299457550049
INFO:root:current mean train loss 1464.1830863739526
INFO:root:current train perplexity3.1690878868103027
INFO:root:current mean train loss 1464.4724367521894
INFO:root:current train perplexity3.168736219406128
INFO:root:current mean train loss 1463.27091867396
INFO:root:current train perplexity3.1681265830993652
INFO:root:current mean train loss 1465.2895620643137
INFO:root:current train perplexity3.172616481781006
INFO:root:current mean train loss 1464.4593688053872
INFO:root:current train perplexity3.172032117843628
INFO:root:current mean train loss 1464.0344356163635
INFO:root:current train perplexity3.172053337097168
INFO:root:current mean train loss 1464.1699517727468
INFO:root:current train perplexity3.172468900680542
INFO:root:current mean train loss 1463.9866608250907
INFO:root:current train perplexity3.1723132133483887
INFO:root:current mean train loss 1464.381844405558
INFO:root:current train perplexity3.172816514968872
INFO:root:current mean train loss 1464.5488414203987
INFO:root:current train perplexity3.173374891281128

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.49s/it]
INFO:root:final mean train loss: 1464.324270274383
INFO:root:final train perplexity: 3.173560619354248
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.71s/it]
INFO:root:eval mean loss: 3463.069558083474
INFO:root:eval perplexity: 17.144912719726562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/76
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [6:59:59<2:12:30, 331.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1458.8886852893202
INFO:root:current train perplexity3.1723899841308594
INFO:root:current mean train loss 1464.8417917621073
INFO:root:current train perplexity3.181628942489624
INFO:root:current mean train loss 1458.9239887879887
INFO:root:current train perplexity3.165794849395752
INFO:root:current mean train loss 1459.83529717721
INFO:root:current train perplexity3.165239095687866
INFO:root:current mean train loss 1461.3019059874619
INFO:root:current train perplexity3.1683974266052246
INFO:root:current mean train loss 1459.0070844156487
INFO:root:current train perplexity3.160106658935547
INFO:root:current mean train loss 1459.036099424238
INFO:root:current train perplexity3.160362958908081
INFO:root:current mean train loss 1461.5913894595449
INFO:root:current train perplexity3.1633801460266113
INFO:root:current mean train loss 1461.11976673199
INFO:root:current train perplexity3.1636440753936768
INFO:root:current mean train loss 1461.2463032773476
INFO:root:current train perplexity3.165031671524048
INFO:root:current mean train loss 1461.7325615118011
INFO:root:current train perplexity3.164541482925415
INFO:root:current mean train loss 1462.5833363056583
INFO:root:current train perplexity3.1660618782043457
INFO:root:current mean train loss 1461.6967358341706
INFO:root:current train perplexity3.1652960777282715
INFO:root:current mean train loss 1462.1778543391388
INFO:root:current train perplexity3.166851043701172
INFO:root:current mean train loss 1462.3086459021054
INFO:root:current train perplexity3.166328191757202
INFO:root:current mean train loss 1462.7548197441174
INFO:root:current train perplexity3.16729474067688
INFO:root:current mean train loss 1462.061714158828
INFO:root:current train perplexity3.165604829788208
INFO:root:current mean train loss 1462.3118973502494
INFO:root:current train perplexity3.1665682792663574
INFO:root:current mean train loss 1461.9296153293974
INFO:root:current train perplexity3.1665029525756836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.94s/it]
INFO:root:final mean train loss: 1461.9671853700793
INFO:root:final train perplexity: 3.1676669120788574
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.63s/it]
INFO:root:eval mean loss: 3470.4308502838776
INFO:root:eval perplexity: 17.248783111572266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/77
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [7:05:30<2:06:58, 331.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1409.2890625
INFO:root:current train perplexity3.057157278060913
INFO:root:current mean train loss 1446.0444381148727
INFO:root:current train perplexity3.1373207569122314
INFO:root:current mean train loss 1453.8418807983398
INFO:root:current train perplexity3.1415839195251465
INFO:root:current mean train loss 1457.6310016582538
INFO:root:current train perplexity3.1524264812469482
INFO:root:current mean train loss 1457.650192559934
INFO:root:current train perplexity3.148959159851074
INFO:root:current mean train loss 1456.7741348386749
INFO:root:current train perplexity3.149747610092163
INFO:root:current mean train loss 1457.2002306486431
INFO:root:current train perplexity3.1522560119628906
INFO:root:current mean train loss 1456.4245300292969
INFO:root:current train perplexity3.153648614883423
INFO:root:current mean train loss 1459.1773716388363
INFO:root:current train perplexity3.156853675842285
INFO:root:current mean train loss 1459.8445797554723
INFO:root:current train perplexity3.1589951515197754
INFO:root:current mean train loss 1460.312125917465
INFO:root:current train perplexity3.1585230827331543
INFO:root:current mean train loss 1458.6493495018474
INFO:root:current train perplexity3.1572625637054443
INFO:root:current mean train loss 1457.804747120434
INFO:root:current train perplexity3.1556835174560547
INFO:root:current mean train loss 1457.918196371936
INFO:root:current train perplexity3.155973196029663
INFO:root:current mean train loss 1458.539480902932
INFO:root:current train perplexity3.158088207244873
INFO:root:current mean train loss 1458.6849736787913
INFO:root:current train perplexity3.15830135345459
INFO:root:current mean train loss 1458.4295412130023
INFO:root:current train perplexity3.158862352371216
INFO:root:current mean train loss 1460.0317002593495
INFO:root:current train perplexity3.160853385925293
INFO:root:current mean train loss 1459.9853000472078
INFO:root:current train perplexity3.161308765411377
INFO:root:current mean train loss 1459.544861351669
INFO:root:current train perplexity3.16115140914917

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.91s/it]
INFO:root:final mean train loss: 1459.8983906540557
INFO:root:final train perplexity: 3.1625027656555176
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.49s/it]
INFO:root:eval mean loss: 3468.269063497091
INFO:root:eval perplexity: 17.218217849731445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/78
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [7:11:01<2:01:26, 331.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1460.76853515625
INFO:root:current train perplexity3.1766197681427
INFO:root:current mean train loss 1448.179275390625
INFO:root:current train perplexity3.142468214035034
INFO:root:current mean train loss 1456.8132210286458
INFO:root:current train perplexity3.163757562637329
INFO:root:current mean train loss 1453.0698411207932
INFO:root:current train perplexity3.159982442855835
INFO:root:current mean train loss 1456.118125
INFO:root:current train perplexity3.159595251083374
INFO:root:current mean train loss 1454.8906459263392
INFO:root:current train perplexity3.155916213989258
INFO:root:current mean train loss 1455.7948794921874
INFO:root:current train perplexity3.154420852661133
INFO:root:current mean train loss 1456.0764271282328
INFO:root:current train perplexity3.1531763076782227
INFO:root:current mean train loss 1455.3804255445075
INFO:root:current train perplexity3.1536905765533447
INFO:root:current mean train loss 1453.695313951647
INFO:root:current train perplexity3.1516501903533936
INFO:root:current mean train loss 1453.0123214796113
INFO:root:current train perplexity3.1510255336761475
INFO:root:current mean train loss 1455.0367058376737
INFO:root:current train perplexity3.1534101963043213
INFO:root:current mean train loss 1456.0054510124362
INFO:root:current train perplexity3.1554572582244873
INFO:root:current mean train loss 1456.9258612175709
INFO:root:current train perplexity3.1558997631073
INFO:root:current mean train loss 1456.3354092139527
INFO:root:current train perplexity3.1545491218566895
INFO:root:current mean train loss 1456.7238357293802
INFO:root:current train perplexity3.1553118228912354
INFO:root:current mean train loss 1456.794370267428
INFO:root:current train perplexity3.154301881790161
INFO:root:current mean train loss 1457.9953848222374
INFO:root:current train perplexity3.1557655334472656
INFO:root:current mean train loss 1457.9133688061859
INFO:root:current train perplexity3.15806245803833
INFO:root:current mean train loss 1458.5526209288757
INFO:root:current train perplexity3.158738136291504

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.34s/it]
INFO:root:final mean train loss: 1458.5051894349037
INFO:root:final train perplexity: 3.159029960632324
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.05s/it]
INFO:root:eval mean loss: 3472.0004772839247
INFO:root:eval perplexity: 17.271020889282227
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/79
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [7:16:32<1:55:53, 331.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1453.7637561616443
INFO:root:current train perplexity3.1326212882995605
INFO:root:current mean train loss 1452.0173314054248
INFO:root:current train perplexity3.1433708667755127
INFO:root:current mean train loss 1451.774320744286
INFO:root:current train perplexity3.143343448638916
INFO:root:current mean train loss 1459.9688367341694
INFO:root:current train perplexity3.156881093978882
INFO:root:current mean train loss 1458.4021531877474
INFO:root:current train perplexity3.1507506370544434
INFO:root:current mean train loss 1459.7397053285717
INFO:root:current train perplexity3.1529080867767334
INFO:root:current mean train loss 1459.5242237316857
INFO:root:current train perplexity3.15142560005188
INFO:root:current mean train loss 1458.0572712119379
INFO:root:current train perplexity3.151505947113037
INFO:root:current mean train loss 1458.7437568718917
INFO:root:current train perplexity3.1553637981414795
INFO:root:current mean train loss 1459.8512701532643
INFO:root:current train perplexity3.1581521034240723
INFO:root:current mean train loss 1458.1068978629964
INFO:root:current train perplexity3.1560027599334717
INFO:root:current mean train loss 1456.4612297418864
INFO:root:current train perplexity3.152912139892578
INFO:root:current mean train loss 1457.257161360048
INFO:root:current train perplexity3.1536343097686768
INFO:root:current mean train loss 1456.6401761960344
INFO:root:current train perplexity3.1532440185546875
INFO:root:current mean train loss 1456.8570595581225
INFO:root:current train perplexity3.153041362762451
INFO:root:current mean train loss 1457.1580576222539
INFO:root:current train perplexity3.153775215148926
INFO:root:current mean train loss 1458.3841549017252
INFO:root:current train perplexity3.156263589859009
INFO:root:current mean train loss 1457.6747679683015
INFO:root:current train perplexity3.1555469036102295
INFO:root:current mean train loss 1456.309363813535
INFO:root:current train perplexity3.1542677879333496
INFO:root:current mean train loss 1456.215089776366
INFO:root:current train perplexity3.1535019874572754

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.33s/it]
INFO:root:final mean train loss: 1455.901445766801
INFO:root:final train perplexity: 3.1525495052337646
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.46s/it]
INFO:root:eval mean loss: 3471.7486964503564
INFO:root:eval perplexity: 17.267452239990234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/80
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [7:22:03<1:50:18, 330.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1438.3068040750795
INFO:root:current train perplexity3.1490938663482666
INFO:root:current mean train loss 1456.9599916470127
INFO:root:current train perplexity3.1587982177734375
INFO:root:current mean train loss 1448.1583360355332
INFO:root:current train perplexity3.1389284133911133
INFO:root:current mean train loss 1445.4038602781163
INFO:root:current train perplexity3.1353161334991455
INFO:root:current mean train loss 1446.0294817091333
INFO:root:current train perplexity3.1332647800445557
INFO:root:current mean train loss 1446.7110892689932
INFO:root:current train perplexity3.131208896636963
INFO:root:current mean train loss 1447.4323748992317
INFO:root:current train perplexity3.1300337314605713
INFO:root:current mean train loss 1448.465803586133
INFO:root:current train perplexity3.1329216957092285
INFO:root:current mean train loss 1448.9803586167145
INFO:root:current train perplexity3.13537859916687
INFO:root:current mean train loss 1448.92328014513
INFO:root:current train perplexity3.1371679306030273
INFO:root:current mean train loss 1448.4676542489228
INFO:root:current train perplexity3.136693239212036
INFO:root:current mean train loss 1450.1299072476272
INFO:root:current train perplexity3.138247013092041
INFO:root:current mean train loss 1451.5825199190826
INFO:root:current train perplexity3.1412577629089355
INFO:root:current mean train loss 1451.955539010043
INFO:root:current train perplexity3.1433510780334473
INFO:root:current mean train loss 1452.4281922014222
INFO:root:current train perplexity3.1447224617004395
INFO:root:current mean train loss 1453.0804024452273
INFO:root:current train perplexity3.145494222640991
INFO:root:current mean train loss 1453.3629661040395
INFO:root:current train perplexity3.1466052532196045
INFO:root:current mean train loss 1453.191481754548
INFO:root:current train perplexity3.1460888385772705
INFO:root:current mean train loss 1453.3223398258892
INFO:root:current train perplexity3.1458888053894043
INFO:root:current mean train loss 1453.6326994650092
INFO:root:current train perplexity3.1466314792633057

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:58<00:00, 298.15s/it]
INFO:root:final mean train loss: 1453.6356890625984
INFO:root:final train perplexity: 3.146921157836914
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.56s/it]
INFO:root:eval mean loss: 3468.8428350225226
INFO:root:eval perplexity: 17.226327896118164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/81
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [7:27:35<1:44:55, 331.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1454.1785374691613
INFO:root:current train perplexity3.1666603088378906
INFO:root:current mean train loss 1458.555404663086
INFO:root:current train perplexity3.158541202545166
INFO:root:current mean train loss 1458.7705029473789
INFO:root:current train perplexity3.1527068614959717
INFO:root:current mean train loss 1452.80359860684
INFO:root:current train perplexity3.14182186126709
INFO:root:current mean train loss 1452.3203009597394
INFO:root:current train perplexity3.142854928970337
INFO:root:current mean train loss 1452.6021010080974
INFO:root:current train perplexity3.142423391342163
INFO:root:current mean train loss 1452.0085122373682
INFO:root:current train perplexity3.1408586502075195
INFO:root:current mean train loss 1450.5984132117833
INFO:root:current train perplexity3.140167236328125
INFO:root:current mean train loss 1452.2231379818154
INFO:root:current train perplexity3.138312816619873
INFO:root:current mean train loss 1452.9711814004868
INFO:root:current train perplexity3.140285015106201
INFO:root:current mean train loss 1450.6231680377266
INFO:root:current train perplexity3.1378629207611084
INFO:root:current mean train loss 1450.4506996829493
INFO:root:current train perplexity3.1393022537231445
INFO:root:current mean train loss 1452.0561084328774
INFO:root:current train perplexity3.1414356231689453
INFO:root:current mean train loss 1452.70645265801
INFO:root:current train perplexity3.141714334487915
INFO:root:current mean train loss 1453.0367444046144
INFO:root:current train perplexity3.1410281658172607
INFO:root:current mean train loss 1453.4655994086097
INFO:root:current train perplexity3.1421735286712646
INFO:root:current mean train loss 1454.087591494467
INFO:root:current train perplexity3.142890214920044
INFO:root:current mean train loss 1453.3365077113247
INFO:root:current train perplexity3.14298939704895
INFO:root:current mean train loss 1453.092438199627
INFO:root:current train perplexity3.1442387104034424
INFO:root:current mean train loss 1452.9326876126802
INFO:root:current train perplexity3.144045352935791

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.36s/it]
INFO:root:final mean train loss: 1452.2806515907675
INFO:root:final train perplexity: 3.143559694290161
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.60s/it]
INFO:root:eval mean loss: 3473.187966286599
INFO:root:eval perplexity: 17.28785514831543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/82
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [7:33:06<1:39:20, 331.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1451.3429978893648
INFO:root:current train perplexity3.1379027366638184
INFO:root:current mean train loss 1459.8428107543314
INFO:root:current train perplexity3.1441328525543213
INFO:root:current mean train loss 1447.7027696212403
INFO:root:current train perplexity3.1340627670288086
INFO:root:current mean train loss 1448.2697005332577
INFO:root:current train perplexity3.135540246963501
INFO:root:current mean train loss 1447.7315819916328
INFO:root:current train perplexity3.1331539154052734
INFO:root:current mean train loss 1447.2717451896474
INFO:root:current train perplexity3.135791540145874
INFO:root:current mean train loss 1448.4267532326614
INFO:root:current train perplexity3.1393837928771973
INFO:root:current mean train loss 1448.0385508206573
INFO:root:current train perplexity3.1397223472595215
INFO:root:current mean train loss 1448.8206560192557
INFO:root:current train perplexity3.1427738666534424
INFO:root:current mean train loss 1451.0896280063964
INFO:root:current train perplexity3.145975112915039
INFO:root:current mean train loss 1450.527121611069
INFO:root:current train perplexity3.1442220211029053
INFO:root:current mean train loss 1449.5413634179524
INFO:root:current train perplexity3.1419131755828857
INFO:root:current mean train loss 1449.4308612820537
INFO:root:current train perplexity3.1411843299865723
INFO:root:current mean train loss 1450.0189790855786
INFO:root:current train perplexity3.1403632164001465
INFO:root:current mean train loss 1450.1629169359353
INFO:root:current train perplexity3.1401641368865967
INFO:root:current mean train loss 1450.8504836375207
INFO:root:current train perplexity3.140657901763916
INFO:root:current mean train loss 1450.9503692969442
INFO:root:current train perplexity3.1399619579315186
INFO:root:current mean train loss 1450.7239649826365
INFO:root:current train perplexity3.1403274536132812
INFO:root:current mean train loss 1451.221115442791
INFO:root:current train perplexity3.139786720275879

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.80s/it]
INFO:root:final mean train loss: 1450.270840166316
INFO:root:final train perplexity: 3.1385810375213623
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.76s/it]
INFO:root:eval mean loss: 3480.984810494088
INFO:root:eval perplexity: 17.39881134033203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/83
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [7:38:37<1:33:49, 331.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1465.93740234375
INFO:root:current train perplexity3.1334683895111084
INFO:root:current mean train loss 1450.8119273792613
INFO:root:current train perplexity3.1267075538635254
INFO:root:current mean train loss 1454.1435064406621
INFO:root:current train perplexity3.1316161155700684
INFO:root:current mean train loss 1452.251769625756
INFO:root:current train perplexity3.133617877960205
INFO:root:current mean train loss 1447.1250363233612
INFO:root:current train perplexity3.1297597885131836
INFO:root:current mean train loss 1446.3253183402267
INFO:root:current train perplexity3.134087324142456
INFO:root:current mean train loss 1446.8743852459017
INFO:root:current train perplexity3.136240243911743
INFO:root:current mean train loss 1445.5880484567563
INFO:root:current train perplexity3.134173631668091
INFO:root:current mean train loss 1446.248944317853
INFO:root:current train perplexity3.1337130069732666
INFO:root:current mean train loss 1446.9470444228623
INFO:root:current train perplexity3.13321852684021
INFO:root:current mean train loss 1446.4341715897665
INFO:root:current train perplexity3.130992889404297
INFO:root:current mean train loss 1447.1000390405054
INFO:root:current train perplexity3.133396625518799
INFO:root:current mean train loss 1447.996353325962
INFO:root:current train perplexity3.135014057159424
INFO:root:current mean train loss 1449.118032021559
INFO:root:current train perplexity3.136078357696533
INFO:root:current mean train loss 1449.028871100676
INFO:root:current train perplexity3.137159585952759
INFO:root:current mean train loss 1450.1313002832678
INFO:root:current train perplexity3.1383533477783203
INFO:root:current mean train loss 1450.1979639278436
INFO:root:current train perplexity3.1377928256988525
INFO:root:current mean train loss 1450.0829784014072
INFO:root:current train perplexity3.1374499797821045
INFO:root:current mean train loss 1448.876174775013
INFO:root:current train perplexity3.136723518371582
INFO:root:current mean train loss 1449.4426566079026
INFO:root:current train perplexity3.1362411975860596

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.33s/it]
INFO:root:final mean train loss: 1449.257850696989
INFO:root:final train perplexity: 3.136075019836426
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.53s/it]
INFO:root:eval mean loss: 3471.9522408150337
INFO:root:eval perplexity: 17.270334243774414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/84
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [7:44:08<1:28:19, 331.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1431.5505913628472
INFO:root:current train perplexity3.119030475616455
INFO:root:current mean train loss 1432.3512751061146
INFO:root:current train perplexity3.114636182785034
INFO:root:current mean train loss 1439.0248189917745
INFO:root:current train perplexity3.1231372356414795
INFO:root:current mean train loss 1442.9453069004444
INFO:root:current train perplexity3.124208927154541
INFO:root:current mean train loss 1442.7732968475557
INFO:root:current train perplexity3.1202781200408936
INFO:root:current mean train loss 1441.616499319927
INFO:root:current train perplexity3.1220946311950684
INFO:root:current mean train loss 1442.4606655187774
INFO:root:current train perplexity3.1260509490966797
INFO:root:current mean train loss 1442.54605492929
INFO:root:current train perplexity3.1258251667022705
INFO:root:current mean train loss 1442.2604832862569
INFO:root:current train perplexity3.1246697902679443
INFO:root:current mean train loss 1444.058844343101
INFO:root:current train perplexity3.1264493465423584
INFO:root:current mean train loss 1444.0844625530597
INFO:root:current train perplexity3.1256062984466553
INFO:root:current mean train loss 1445.680662654413
INFO:root:current train perplexity3.1278913021087646
INFO:root:current mean train loss 1446.8171334985611
INFO:root:current train perplexity3.1294867992401123
INFO:root:current mean train loss 1447.0657674736246
INFO:root:current train perplexity3.1301302909851074
INFO:root:current mean train loss 1448.2377709841178
INFO:root:current train perplexity3.1314754486083984
INFO:root:current mean train loss 1448.6304915652372
INFO:root:current train perplexity3.1314244270324707
INFO:root:current mean train loss 1448.636025417635
INFO:root:current train perplexity3.1313343048095703
INFO:root:current mean train loss 1448.2824926149935
INFO:root:current train perplexity3.131357431411743
INFO:root:current mean train loss 1447.310431953852
INFO:root:current train perplexity3.1300673484802246
INFO:root:current mean train loss 1447.065481885703
INFO:root:current train perplexity3.1299445629119873

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.75s/it]
INFO:root:final mean train loss: 1447.0256716391082
INFO:root:final train perplexity: 3.130558729171753
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.85s/it]
INFO:root:eval mean loss: 3478.3127485395553
INFO:root:eval perplexity: 17.360706329345703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/85
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [7:49:39<1:22:44, 330.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1417.2365805886009
INFO:root:current train perplexity3.10497784614563
INFO:root:current mean train loss 1421.5208265516494
INFO:root:current train perplexity3.1151463985443115
INFO:root:current mean train loss 1437.9640047667456
INFO:root:current train perplexity3.13138484954834
INFO:root:current mean train loss 1439.0692653212436
INFO:root:current train perplexity3.1235101222991943
INFO:root:current mean train loss 1442.322073721671
INFO:root:current train perplexity3.127634286880493
INFO:root:current mean train loss 1445.920119566076
INFO:root:current train perplexity3.1301050186157227
INFO:root:current mean train loss 1448.8927176339287
INFO:root:current train perplexity3.130167007446289
INFO:root:current mean train loss 1446.4760115428637
INFO:root:current train perplexity3.126145601272583
INFO:root:current mean train loss 1447.546237023521
INFO:root:current train perplexity3.126941680908203
INFO:root:current mean train loss 1446.2374823618743
INFO:root:current train perplexity3.125581741333008
INFO:root:current mean train loss 1444.7780949968944
INFO:root:current train perplexity3.126317262649536
INFO:root:current mean train loss 1445.0873963682802
INFO:root:current train perplexity3.125964879989624
INFO:root:current mean train loss 1444.9682740827848
INFO:root:current train perplexity3.1258575916290283
INFO:root:current mean train loss 1443.9169409615654
INFO:root:current train perplexity3.1250650882720947
INFO:root:current mean train loss 1444.7446736259144
INFO:root:current train perplexity3.125938653945923
INFO:root:current mean train loss 1445.0246308479902
INFO:root:current train perplexity3.125974416732788
INFO:root:current mean train loss 1445.8291723246703
INFO:root:current train perplexity3.127007246017456
INFO:root:current mean train loss 1445.7199717530416
INFO:root:current train perplexity3.125865936279297
INFO:root:current mean train loss 1445.558720652814
INFO:root:current train perplexity3.12581205368042
INFO:root:current mean train loss 1445.8993343777126
INFO:root:current train perplexity3.125736713409424

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.09s/it]
INFO:root:final mean train loss: 1444.9508393980673
INFO:root:final train perplexity: 3.1254401206970215
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.47s/it]
INFO:root:eval mean loss: 3481.4420719547675
INFO:root:eval perplexity: 17.405345916748047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/86
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [7:55:09<1:17:10, 330.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1442.5628341924948
INFO:root:current train perplexity3.118842124938965
INFO:root:current mean train loss 1426.3922574061044
INFO:root:current train perplexity3.1023430824279785
INFO:root:current mean train loss 1430.3949255230782
INFO:root:current train perplexity3.102328062057495
INFO:root:current mean train loss 1434.8977957009608
INFO:root:current train perplexity3.109557628631592
INFO:root:current mean train loss 1435.800751857799
INFO:root:current train perplexity3.115131139755249
INFO:root:current mean train loss 1436.1295133376505
INFO:root:current train perplexity3.117504835128784
INFO:root:current mean train loss 1436.507304643178
INFO:root:current train perplexity3.1161205768585205
INFO:root:current mean train loss 1437.523852154084
INFO:root:current train perplexity3.1170527935028076
INFO:root:current mean train loss 1439.1695328379064
INFO:root:current train perplexity3.118422746658325
INFO:root:current mean train loss 1439.2745371490066
INFO:root:current train perplexity3.116544485092163
INFO:root:current mean train loss 1440.4505543902053
INFO:root:current train perplexity3.1194794178009033
INFO:root:current mean train loss 1441.418208579787
INFO:root:current train perplexity3.1194217205047607
INFO:root:current mean train loss 1440.7506702734686
INFO:root:current train perplexity3.116830825805664
INFO:root:current mean train loss 1441.3115479233159
INFO:root:current train perplexity3.118104934692383
INFO:root:current mean train loss 1442.1791223503808
INFO:root:current train perplexity3.1209237575531006
INFO:root:current mean train loss 1442.7823993064592
INFO:root:current train perplexity3.121259927749634
INFO:root:current mean train loss 1442.4309135680455
INFO:root:current train perplexity3.1197361946105957
INFO:root:current mean train loss 1442.5951191145612
INFO:root:current train perplexity3.119950532913208
INFO:root:current mean train loss 1443.2783097518766
INFO:root:current train perplexity3.1206326484680176
INFO:root:current mean train loss 1443.7427104539497
INFO:root:current train perplexity3.1215384006500244

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.03s/it]
INFO:root:final mean train loss: 1443.2924805303085
INFO:root:final train perplexity: 3.1213552951812744
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.50s/it]
INFO:root:eval mean loss: 3484.2316615932336
INFO:root:eval perplexity: 17.445234298706055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/87
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [8:00:41<1:11:45, 331.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1444.5034743088943
INFO:root:current train perplexity3.120849609375
INFO:root:current mean train loss 1442.7561323187324
INFO:root:current train perplexity3.1058311462402344
INFO:root:current mean train loss 1444.3343264353362
INFO:root:current train perplexity3.1074905395507812
INFO:root:current mean train loss 1446.354443101025
INFO:root:current train perplexity3.115936279296875
INFO:root:current mean train loss 1447.295334564592
INFO:root:current train perplexity3.118612289428711
INFO:root:current mean train loss 1445.9146052693825
INFO:root:current train perplexity3.118967294692993
INFO:root:current mean train loss 1444.5193620079738
INFO:root:current train perplexity3.1174418926239014
INFO:root:current mean train loss 1442.0828254915448
INFO:root:current train perplexity3.11576509475708
INFO:root:current mean train loss 1440.9022775706505
INFO:root:current train perplexity3.1135334968566895
INFO:root:current mean train loss 1439.7040629942724
INFO:root:current train perplexity3.1120352745056152
INFO:root:current mean train loss 1440.3837265552527
INFO:root:current train perplexity3.112328290939331
INFO:root:current mean train loss 1441.1285245989295
INFO:root:current train perplexity3.111868143081665
INFO:root:current mean train loss 1441.2747018542461
INFO:root:current train perplexity3.111764669418335
INFO:root:current mean train loss 1440.120503861603
INFO:root:current train perplexity3.1113972663879395
INFO:root:current mean train loss 1440.8160812522465
INFO:root:current train perplexity3.11415433883667
INFO:root:current mean train loss 1441.1541392201857
INFO:root:current train perplexity3.1145436763763428
INFO:root:current mean train loss 1442.28641761898
INFO:root:current train perplexity3.1168212890625
INFO:root:current mean train loss 1442.1247023077194
INFO:root:current train perplexity3.1178364753723145
INFO:root:current mean train loss 1442.2591048333084
INFO:root:current train perplexity3.118189573287964
INFO:root:current mean train loss 1442.331144543099
INFO:root:current train perplexity3.1181654930114746

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.61s/it]
INFO:root:final mean train loss: 1441.9376672849592
INFO:root:final train perplexity: 3.1180219650268555
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.90s/it]
INFO:root:eval mean loss: 3488.701067033831
INFO:root:eval perplexity: 17.509328842163086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/88
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [8:06:12<1:06:13, 331.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1464.8644955283717
INFO:root:current train perplexity3.156170129776001
INFO:root:current mean train loss 1453.987227689303
INFO:root:current train perplexity3.131498336791992
INFO:root:current mean train loss 1449.8631455243644
INFO:root:current train perplexity3.1287355422973633
INFO:root:current mean train loss 1445.1611819496638
INFO:root:current train perplexity3.1214396953582764
INFO:root:current mean train loss 1443.3260199652777
INFO:root:current train perplexity3.1157450675964355
INFO:root:current mean train loss 1441.4800918707326
INFO:root:current train perplexity3.1125705242156982
INFO:root:current mean train loss 1442.4436152835544
INFO:root:current train perplexity3.117710828781128
INFO:root:current mean train loss 1444.479726808176
INFO:root:current train perplexity3.1204679012298584
INFO:root:current mean train loss 1444.2140414957228
INFO:root:current train perplexity3.1223180294036865
INFO:root:current mean train loss 1442.7607630437342
INFO:root:current train perplexity3.1184985637664795
INFO:root:current mean train loss 1443.3140245968893
INFO:root:current train perplexity3.1190428733825684
INFO:root:current mean train loss 1442.130862030923
INFO:root:current train perplexity3.1162848472595215
INFO:root:current mean train loss 1441.9023027456865
INFO:root:current train perplexity3.1155974864959717
INFO:root:current mean train loss 1440.3276854593694
INFO:root:current train perplexity3.114985227584839
INFO:root:current mean train loss 1440.817194930367
INFO:root:current train perplexity3.1134467124938965
INFO:root:current mean train loss 1440.9172903605015
INFO:root:current train perplexity3.114176034927368
INFO:root:current mean train loss 1441.0236014847208
INFO:root:current train perplexity3.1147663593292236
INFO:root:current mean train loss 1441.5308784846143
INFO:root:current train perplexity3.1168148517608643
INFO:root:current mean train loss 1442.1079772788175
INFO:root:current train perplexity3.117870330810547

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.75s/it]
INFO:root:final mean train loss: 1441.9543872242675
INFO:root:final train perplexity: 3.11806321144104
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.99s/it]
INFO:root:eval mean loss: 3484.105912308793
INFO:root:eval perplexity: 17.44342803955078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/89
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [8:11:43<1:00:40, 330.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1429.8556823730469
INFO:root:current train perplexity3.098264455795288
INFO:root:current mean train loss 1445.9354531424385
INFO:root:current train perplexity3.1198344230651855
INFO:root:current mean train loss 1437.1729782392395
INFO:root:current train perplexity3.1088359355926514
INFO:root:current mean train loss 1436.358153905624
INFO:root:current train perplexity3.109389066696167
INFO:root:current mean train loss 1438.2951787559732
INFO:root:current train perplexity3.113176107406616
INFO:root:current mean train loss 1437.3527376651764
INFO:root:current train perplexity3.1107311248779297
INFO:root:current mean train loss 1435.323583665237
INFO:root:current train perplexity3.1079323291778564
INFO:root:current mean train loss 1435.0122001733673
INFO:root:current train perplexity3.106977939605713
INFO:root:current mean train loss 1434.2966015444601
INFO:root:current train perplexity3.103355884552002
INFO:root:current mean train loss 1434.0389465867427
INFO:root:current train perplexity3.102388381958008
INFO:root:current mean train loss 1435.4746121493254
INFO:root:current train perplexity3.1036345958709717
INFO:root:current mean train loss 1435.6773310599567
INFO:root:current train perplexity3.105881929397583
INFO:root:current mean train loss 1436.2135645296707
INFO:root:current train perplexity3.1078174114227295
INFO:root:current mean train loss 1437.7504146855051
INFO:root:current train perplexity3.108494281768799
INFO:root:current mean train loss 1439.1930465049852
INFO:root:current train perplexity3.110022783279419
INFO:root:current mean train loss 1438.8601054035166
INFO:root:current train perplexity3.1093838214874268
INFO:root:current mean train loss 1438.1004499336034
INFO:root:current train perplexity3.108971357345581
INFO:root:current mean train loss 1438.6671635280145
INFO:root:current train perplexity3.1104629039764404
INFO:root:current mean train loss 1438.8648062531258
INFO:root:current train perplexity3.1106228828430176
INFO:root:current mean train loss 1440.0197242513361
INFO:root:current train perplexity3.112600326538086

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.99s/it]
INFO:root:final mean train loss: 1439.9571077670946
INFO:root:final train perplexity: 3.1131553649902344
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.20s/it]
INFO:root:eval mean loss: 3489.2070202526747
INFO:root:eval perplexity: 17.516597747802734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/90
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [8:17:13<55:08, 330.89s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1419.7740731074891
INFO:root:current train perplexity3.120181083679199
INFO:root:current mean train loss 1430.9757874954578
INFO:root:current train perplexity3.094975233078003
INFO:root:current mean train loss 1439.9241250383802
INFO:root:current train perplexity3.1044251918792725
INFO:root:current mean train loss 1443.2722809858235
INFO:root:current train perplexity3.11082124710083
INFO:root:current mean train loss 1445.5244706871904
INFO:root:current train perplexity3.10964298248291
INFO:root:current mean train loss 1443.0283196202297
INFO:root:current train perplexity3.109042167663574
INFO:root:current mean train loss 1444.2101922694753
INFO:root:current train perplexity3.113410711288452
INFO:root:current mean train loss 1443.946937759881
INFO:root:current train perplexity3.110266923904419
INFO:root:current mean train loss 1444.3633819690515
INFO:root:current train perplexity3.1125264167785645
INFO:root:current mean train loss 1442.8530432431126
INFO:root:current train perplexity3.111701250076294
INFO:root:current mean train loss 1443.0018860990267
INFO:root:current train perplexity3.11228346824646
INFO:root:current mean train loss 1440.6787641337744
INFO:root:current train perplexity3.1098382472991943
INFO:root:current mean train loss 1440.7377014905094
INFO:root:current train perplexity3.1102311611175537
INFO:root:current mean train loss 1439.4433426580724
INFO:root:current train perplexity3.109480857849121
INFO:root:current mean train loss 1438.945867069957
INFO:root:current train perplexity3.1104936599731445
INFO:root:current mean train loss 1439.1950767422284
INFO:root:current train perplexity3.1114072799682617
INFO:root:current mean train loss 1438.590773102987
INFO:root:current train perplexity3.1097726821899414
INFO:root:current mean train loss 1438.9668378945787
INFO:root:current train perplexity3.1106131076812744
INFO:root:current mean train loss 1439.6034201178281
INFO:root:current train perplexity3.110912799835205
INFO:root:current mean train loss 1439.014509787394
INFO:root:current train perplexity3.109539747238159

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.53s/it]
INFO:root:final mean train loss: 1438.401363370879
INFO:root:final train perplexity: 3.1093382835388184
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.40s/it]
INFO:root:eval mean loss: 3483.3192985465935
INFO:root:eval perplexity: 17.432178497314453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/91
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [8:22:43<49:34, 330.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1448.4551046620245
INFO:root:current train perplexity3.144310712814331
INFO:root:current mean train loss 1437.434054440015
INFO:root:current train perplexity3.1121556758880615
INFO:root:current mean train loss 1438.025365813961
INFO:root:current train perplexity3.110525369644165
INFO:root:current mean train loss 1436.1221546327447
INFO:root:current train perplexity3.1059656143188477
INFO:root:current mean train loss 1436.4251418862107
INFO:root:current train perplexity3.1087143421173096
INFO:root:current mean train loss 1436.877177144145
INFO:root:current train perplexity3.1090362071990967
INFO:root:current mean train loss 1436.6523242867768
INFO:root:current train perplexity3.107867479324341
INFO:root:current mean train loss 1435.1365786800436
INFO:root:current train perplexity3.1055548191070557
INFO:root:current mean train loss 1434.342394240359
INFO:root:current train perplexity3.10632586479187
INFO:root:current mean train loss 1435.4867943406862
INFO:root:current train perplexity3.1073925495147705
INFO:root:current mean train loss 1437.4138515027485
INFO:root:current train perplexity3.11053466796875
INFO:root:current mean train loss 1437.6110296598904
INFO:root:current train perplexity3.1103343963623047
INFO:root:current mean train loss 1437.5652516764585
INFO:root:current train perplexity3.1079370975494385
INFO:root:current mean train loss 1438.0850839147242
INFO:root:current train perplexity3.1102824211120605
INFO:root:current mean train loss 1438.5859385130316
INFO:root:current train perplexity3.1096911430358887
INFO:root:current mean train loss 1438.7179061672512
INFO:root:current train perplexity3.1099376678466797
INFO:root:current mean train loss 1438.276630091059
INFO:root:current train perplexity3.109574794769287
INFO:root:current mean train loss 1438.5490577234573
INFO:root:current train perplexity3.110180377960205
INFO:root:current mean train loss 1438.5016433203336
INFO:root:current train perplexity3.109544038772583
INFO:root:current mean train loss 1438.3631811347798
INFO:root:current train perplexity3.1088624000549316

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.18s/it]
INFO:root:final mean train loss: 1438.2027939696895
INFO:root:final train perplexity: 3.1088507175445557
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.87s/it]
INFO:root:eval mean loss: 3487.0264368372277
INFO:root:eval perplexity: 17.485288619995117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/92
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [8:28:14<44:04, 330.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1432.2134564112102
INFO:root:current train perplexity3.0932090282440186
INFO:root:current mean train loss 1433.1769592659605
INFO:root:current train perplexity3.084202766418457
INFO:root:current mean train loss 1436.6340499123694
INFO:root:current train perplexity3.1051862239837646
INFO:root:current mean train loss 1434.2651948955106
INFO:root:current train perplexity3.105231761932373
INFO:root:current mean train loss 1440.4906891726005
INFO:root:current train perplexity3.1134634017944336
INFO:root:current mean train loss 1440.0243206125806
INFO:root:current train perplexity3.1120874881744385
INFO:root:current mean train loss 1439.7088727994203
INFO:root:current train perplexity3.1106109619140625
INFO:root:current mean train loss 1440.772594846873
INFO:root:current train perplexity3.1088011264801025
INFO:root:current mean train loss 1441.2402834577329
INFO:root:current train perplexity3.1124749183654785
INFO:root:current mean train loss 1441.7126894561673
INFO:root:current train perplexity3.113835334777832
INFO:root:current mean train loss 1441.303782365284
INFO:root:current train perplexity3.113071918487549
INFO:root:current mean train loss 1439.864339682529
INFO:root:current train perplexity3.110609531402588
INFO:root:current mean train loss 1438.6590955044103
INFO:root:current train perplexity3.1078574657440186
INFO:root:current mean train loss 1438.1270892562363
INFO:root:current train perplexity3.1057305335998535
INFO:root:current mean train loss 1437.1773768416513
INFO:root:current train perplexity3.105440616607666
INFO:root:current mean train loss 1437.4250100124211
INFO:root:current train perplexity3.106191873550415
INFO:root:current mean train loss 1436.8712428328652
INFO:root:current train perplexity3.1045162677764893
INFO:root:current mean train loss 1436.5087074284113
INFO:root:current train perplexity3.103949785232544
INFO:root:current mean train loss 1436.0603550221417
INFO:root:current train perplexity3.102606773376465
INFO:root:current mean train loss 1437.1565050231031
INFO:root:current train perplexity3.1049726009368896

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:57<00:00, 297.08s/it]
INFO:root:final mean train loss: 1436.7225252844983
INFO:root:final train perplexity: 3.1052238941192627
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.60s/it]
INFO:root:eval mean loss: 3488.0714730844124
INFO:root:eval perplexity: 17.500280380249023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/93
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [8:33:45<38:35, 330.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1418.7001190185547
INFO:root:current train perplexity3.0786497592926025
INFO:root:current mean train loss 1428.211383734809
INFO:root:current train perplexity3.079941511154175
INFO:root:current mean train loss 1434.2694658551898
INFO:root:current train perplexity3.0886330604553223
INFO:root:current mean train loss 1434.865521561472
INFO:root:current train perplexity3.100438117980957
INFO:root:current mean train loss 1434.7920003255208
INFO:root:current train perplexity3.1007425785064697
INFO:root:current mean train loss 1435.8164228768185
INFO:root:current train perplexity3.103945016860962
INFO:root:current mean train loss 1435.8203284768497
INFO:root:current train perplexity3.1038334369659424
INFO:root:current mean train loss 1435.1427903395434
INFO:root:current train perplexity3.103685140609741
INFO:root:current mean train loss 1434.272903026234
INFO:root:current train perplexity3.100945472717285
INFO:root:current mean train loss 1434.0790108816964
INFO:root:current train perplexity3.1008760929107666
INFO:root:current mean train loss 1434.342764960395
INFO:root:current train perplexity3.101402759552002
INFO:root:current mean train loss 1433.6682517876059
INFO:root:current train perplexity3.10101056098938
INFO:root:current mean train loss 1435.0720388412476
INFO:root:current train perplexity3.1037063598632812
INFO:root:current mean train loss 1435.7107528907666
INFO:root:current train perplexity3.1033477783203125
INFO:root:current mean train loss 1437.3567420753272
INFO:root:current train perplexity3.1051526069641113
INFO:root:current mean train loss 1437.4683352699763
INFO:root:current train perplexity3.104871988296509
INFO:root:current mean train loss 1436.866923086984
INFO:root:current train perplexity3.1046366691589355
INFO:root:current mean train loss 1436.8393881808506
INFO:root:current train perplexity3.103818655014038
INFO:root:current mean train loss 1436.36879149092
INFO:root:current train perplexity3.1033785343170166
INFO:root:current mean train loss 1436.2681326201468
INFO:root:current train perplexity3.103233814239502

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.47s/it]
INFO:root:final mean train loss: 1435.8789968639687
INFO:root:final train perplexity: 3.103159189224243
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.56s/it]
INFO:root:eval mean loss: 3489.7256423904373
INFO:root:eval perplexity: 17.524051666259766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/94
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [8:39:16<33:04, 330.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1437.6788720199743
INFO:root:current train perplexity3.1164655685424805
INFO:root:current mean train loss 1438.1052407201776
INFO:root:current train perplexity3.113006591796875
INFO:root:current mean train loss 1438.4534233940972
INFO:root:current train perplexity3.104391574859619
INFO:root:current mean train loss 1438.1168800181044
INFO:root:current train perplexity3.1084539890289307
INFO:root:current mean train loss 1437.8437961754905
INFO:root:current train perplexity3.1064324378967285
INFO:root:current mean train loss 1439.3414940506568
INFO:root:current train perplexity3.103499174118042
INFO:root:current mean train loss 1438.2727141852358
INFO:root:current train perplexity3.1008338928222656
INFO:root:current mean train loss 1436.1087076720808
INFO:root:current train perplexity3.0997159481048584
INFO:root:current mean train loss 1436.0925914887735
INFO:root:current train perplexity3.0986242294311523
INFO:root:current mean train loss 1436.5900400175135
INFO:root:current train perplexity3.100792407989502
INFO:root:current mean train loss 1437.1972216707854
INFO:root:current train perplexity3.1033928394317627
INFO:root:current mean train loss 1437.0446776323947
INFO:root:current train perplexity3.103815793991089
INFO:root:current mean train loss 1437.15110855279
INFO:root:current train perplexity3.104753255844116
INFO:root:current mean train loss 1436.8797890534124
INFO:root:current train perplexity3.1031057834625244
INFO:root:current mean train loss 1436.712786901929
INFO:root:current train perplexity3.103307008743286
INFO:root:current mean train loss 1436.6620884311894
INFO:root:current train perplexity3.1030592918395996
INFO:root:current mean train loss 1436.183010373315
INFO:root:current train perplexity3.1027214527130127
INFO:root:current mean train loss 1436.1863702552214
INFO:root:current train perplexity3.1034066677093506
INFO:root:current mean train loss 1436.259406235071
INFO:root:current train perplexity3.103849411010742

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:55<00:00, 295.52s/it]
INFO:root:final mean train loss: 1435.1103145659
INFO:root:final train perplexity: 3.101278305053711
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.28s/it]
INFO:root:eval mean loss: 3489.023853198902
INFO:root:eval perplexity: 17.513967514038086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/95
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [8:44:45<27:31, 330.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1404.8086635044642
INFO:root:current train perplexity3.0435800552368164
INFO:root:current mean train loss 1424.0943260862116
INFO:root:current train perplexity3.0719687938690186
INFO:root:current mean train loss 1429.159479159061
INFO:root:current train perplexity3.0747733116149902
INFO:root:current mean train loss 1428.6988622580363
INFO:root:current train perplexity3.078026533126831
INFO:root:current mean train loss 1428.271875648683
INFO:root:current train perplexity3.0789456367492676
INFO:root:current mean train loss 1431.7063760126612
INFO:root:current train perplexity3.088041067123413
INFO:root:current mean train loss 1432.498427599183
INFO:root:current train perplexity3.093547821044922
INFO:root:current mean train loss 1433.6669944100688
INFO:root:current train perplexity3.0922234058380127
INFO:root:current mean train loss 1433.278701669754
INFO:root:current train perplexity3.092925786972046
INFO:root:current mean train loss 1433.7851063000035
INFO:root:current train perplexity3.0935001373291016
INFO:root:current mean train loss 1433.676953317616
INFO:root:current train perplexity3.091935157775879
INFO:root:current mean train loss 1434.8440647091002
INFO:root:current train perplexity3.094212532043457
INFO:root:current mean train loss 1434.9262680229676
INFO:root:current train perplexity3.095432758331299
INFO:root:current mean train loss 1434.2353100362977
INFO:root:current train perplexity3.0952258110046387
INFO:root:current mean train loss 1434.3336630555493
INFO:root:current train perplexity3.0969886779785156
INFO:root:current mean train loss 1435.5427917722352
INFO:root:current train perplexity3.098111152648926
INFO:root:current mean train loss 1435.2361427505664
INFO:root:current train perplexity3.0987191200256348
INFO:root:current mean train loss 1435.5303201575261
INFO:root:current train perplexity3.098794937133789
INFO:root:current mean train loss 1435.7688305233385
INFO:root:current train perplexity3.0988268852233887
INFO:root:current mean train loss 1435.7291698555464
INFO:root:current train perplexity3.099435806274414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.94s/it]
INFO:root:final mean train loss: 1434.3149808036278
INFO:root:final train perplexity: 3.0993335247039795
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.57s/it]
INFO:root:eval mean loss: 3490.7606102195946
INFO:root:eval perplexity: 17.53894805908203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/96
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [8:50:16<22:02, 330.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1457.9802758001513
INFO:root:current train perplexity3.155431032180786
INFO:root:current mean train loss 1443.1398553047472
INFO:root:current train perplexity3.1348462104797363
INFO:root:current mean train loss 1439.004175227442
INFO:root:current train perplexity3.1179487705230713
INFO:root:current mean train loss 1437.8390360944582
INFO:root:current train perplexity3.10856556892395
INFO:root:current mean train loss 1441.516548032827
INFO:root:current train perplexity3.1122660636901855
INFO:root:current mean train loss 1439.6475754215219
INFO:root:current train perplexity3.1077277660369873
INFO:root:current mean train loss 1438.6638659493858
INFO:root:current train perplexity3.104491949081421
INFO:root:current mean train loss 1438.3867880512034
INFO:root:current train perplexity3.103644371032715
INFO:root:current mean train loss 1437.2984003647714
INFO:root:current train perplexity3.1023008823394775
INFO:root:current mean train loss 1435.932861983712
INFO:root:current train perplexity3.1005048751831055
INFO:root:current mean train loss 1434.4589556038206
INFO:root:current train perplexity3.098442554473877
INFO:root:current mean train loss 1434.350215733104
INFO:root:current train perplexity3.0981240272521973
INFO:root:current mean train loss 1434.6597976746548
INFO:root:current train perplexity3.098203182220459
INFO:root:current mean train loss 1434.1690164819684
INFO:root:current train perplexity3.096602201461792
INFO:root:current mean train loss 1432.5291771932052
INFO:root:current train perplexity3.0954606533050537
INFO:root:current mean train loss 1432.4811756575052
INFO:root:current train perplexity3.0964245796203613
INFO:root:current mean train loss 1434.1594703061533
INFO:root:current train perplexity3.0991454124450684
INFO:root:current mean train loss 1434.3419038540087
INFO:root:current train perplexity3.098501205444336
INFO:root:current mean train loss 1433.9220845395917
INFO:root:current train perplexity3.098337173461914
INFO:root:current mean train loss 1434.0117595876084
INFO:root:current train perplexity3.0980606079101562

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.34s/it]
INFO:root:final mean train loss: 1433.5312184205395
INFO:root:final train perplexity: 3.0974180698394775
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.51s/it]
INFO:root:eval mean loss: 3489.417284716357
INFO:root:eval perplexity: 17.519622802734375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/97
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [8:55:47<16:31, 330.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1440.9189046223958
INFO:root:current train perplexity3.1216254234313965
INFO:root:current mean train loss 1433.8992276578335
INFO:root:current train perplexity3.116178035736084
INFO:root:current mean train loss 1436.934556038149
INFO:root:current train perplexity3.1183080673217773
INFO:root:current mean train loss 1435.0731762414691
INFO:root:current train perplexity3.1074302196502686
INFO:root:current mean train loss 1437.4555655888148
INFO:root:current train perplexity3.107236623764038
INFO:root:current mean train loss 1437.3354919879105
INFO:root:current train perplexity3.0995936393737793
INFO:root:current mean train loss 1439.292202796465
INFO:root:current train perplexity3.1023261547088623
INFO:root:current mean train loss 1438.5860917198468
INFO:root:current train perplexity3.099949836730957
INFO:root:current mean train loss 1436.703392460661
INFO:root:current train perplexity3.1003098487854004
INFO:root:current mean train loss 1436.6280339880834
INFO:root:current train perplexity3.100338935852051
INFO:root:current mean train loss 1436.2010569099252
INFO:root:current train perplexity3.1004128456115723
INFO:root:current mean train loss 1434.106055708297
INFO:root:current train perplexity3.099095582962036
INFO:root:current mean train loss 1434.9052948584924
INFO:root:current train perplexity3.099189281463623
INFO:root:current mean train loss 1435.6516739027436
INFO:root:current train perplexity3.099552631378174
INFO:root:current mean train loss 1435.264514058993
INFO:root:current train perplexity3.099255084991455
INFO:root:current mean train loss 1434.3715216269482
INFO:root:current train perplexity3.097522020339966
INFO:root:current mean train loss 1434.5077434650902
INFO:root:current train perplexity3.0971662998199463
INFO:root:current mean train loss 1434.4627852450792
INFO:root:current train perplexity3.097322702407837
INFO:root:current mean train loss 1433.768094347669
INFO:root:current train perplexity3.097412109375
INFO:root:current mean train loss 1433.3836592844625
INFO:root:current train perplexity3.0970263481140137

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.12s/it]
INFO:root:final mean train loss: 1433.389871463593
INFO:root:final train perplexity: 3.0970728397369385
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.91s/it]
INFO:root:eval mean loss: 3491.182721295514
INFO:root:eval perplexity: 17.545015335083008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/98
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [9:01:17<11:01, 330.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1434.2040395883414
INFO:root:current train perplexity3.077340602874756
INFO:root:current mean train loss 1429.6668989701705
INFO:root:current train perplexity3.090585470199585
INFO:root:current mean train loss 1428.9741749889445
INFO:root:current train perplexity3.0923879146575928
INFO:root:current mean train loss 1429.1113558834547
INFO:root:current train perplexity3.0943286418914795
INFO:root:current mean train loss 1432.5401758337534
INFO:root:current train perplexity3.096918821334839
INFO:root:current mean train loss 1435.1820608493501
INFO:root:current train perplexity3.095583438873291
INFO:root:current mean train loss 1433.7732409025493
INFO:root:current train perplexity3.0908050537109375
INFO:root:current mean train loss 1435.1691620072509
INFO:root:current train perplexity3.0932390689849854
INFO:root:current mean train loss 1435.3018158135387
INFO:root:current train perplexity3.0946044921875
INFO:root:current mean train loss 1435.1135024945354
INFO:root:current train perplexity3.0947790145874023
INFO:root:current mean train loss 1434.9371626733055
INFO:root:current train perplexity3.0938358306884766
INFO:root:current mean train loss 1434.5341077026892
INFO:root:current train perplexity3.095432758331299
INFO:root:current mean train loss 1434.2803108788291
INFO:root:current train perplexity3.095186710357666
INFO:root:current mean train loss 1434.6771252754406
INFO:root:current train perplexity3.096567392349243
INFO:root:current mean train loss 1433.4779813486562
INFO:root:current train perplexity3.0949418544769287
INFO:root:current mean train loss 1433.4574221870007
INFO:root:current train perplexity3.0954926013946533
INFO:root:current mean train loss 1433.2391117680181
INFO:root:current train perplexity3.09482741355896
INFO:root:current mean train loss 1433.4745454696354
INFO:root:current train perplexity3.094935178756714
INFO:root:current mean train loss 1432.9412881723358
INFO:root:current train perplexity3.0941789150238037
INFO:root:current mean train loss 1433.0955586906607
INFO:root:current train perplexity3.095020055770874

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.84s/it]
INFO:root:final mean train loss: 1432.617797328316
INFO:root:final train perplexity: 3.0951879024505615
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.59s/it]
INFO:root:eval mean loss: 3492.1242829743805
INFO:root:eval perplexity: 17.558574676513672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/99
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [9:06:48<05:30, 330.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1430.7745882359948
INFO:root:current train perplexity3.0717618465423584
INFO:root:current mean train loss 1423.1785982572114
INFO:root:current train perplexity3.0725326538085938
INFO:root:current mean train loss 1427.3765120269559
INFO:root:current train perplexity3.079758644104004
INFO:root:current mean train loss 1427.918837941754
INFO:root:current train perplexity3.076882839202881
INFO:root:current mean train loss 1430.344232456318
INFO:root:current train perplexity3.0821187496185303
INFO:root:current mean train loss 1430.3578856163417
INFO:root:current train perplexity3.0864193439483643
INFO:root:current mean train loss 1432.4084753668553
INFO:root:current train perplexity3.0911803245544434
INFO:root:current mean train loss 1433.088579494935
INFO:root:current train perplexity3.0928211212158203
INFO:root:current mean train loss 1432.1323250491603
INFO:root:current train perplexity3.091398239135742
INFO:root:current mean train loss 1432.6905220482354
INFO:root:current train perplexity3.092500686645508
INFO:root:current mean train loss 1432.4749630630126
INFO:root:current train perplexity3.0920443534851074
INFO:root:current mean train loss 1432.5411397608
INFO:root:current train perplexity3.09169602394104
INFO:root:current mean train loss 1432.5594208192156
INFO:root:current train perplexity3.0918290615081787
INFO:root:current mean train loss 1432.495955780515
INFO:root:current train perplexity3.091830253601074
INFO:root:current mean train loss 1434.1145390190093
INFO:root:current train perplexity3.094304323196411
INFO:root:current mean train loss 1432.353289385963
INFO:root:current train perplexity3.0921502113342285
INFO:root:current mean train loss 1431.1351112973534
INFO:root:current train perplexity3.091078281402588
INFO:root:current mean train loss 1430.8880076809764
INFO:root:current train perplexity3.0907371044158936
INFO:root:current mean train loss 1431.9320882377665
INFO:root:current train perplexity3.0930569171905518
INFO:root:current mean train loss 1432.5464715274384
INFO:root:current train perplexity3.0940582752227783

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:56<00:00, 296.12s/it]
INFO:root:final mean train loss: 1432.1056195065282
INFO:root:final train perplexity: 3.093937635421753
INFO:root:epoch finished
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.62s/it]
INFO:root:eval mean loss: 3491.480126366601
INFO:root:eval perplexity: 17.549304962158203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: pld_24/100
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [9:12:19<00:00, 330.59s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [9:12:19<00:00, 331.39s/it]
INFO:root:evaluating final model
INFO:root:start evaluating
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.44s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.44s/it]
INFO:root:eval mean loss: 3491.480126366601
INFO:root:eval perplexity: 17.549304962158203
INFO:root:evalaution complete
INFO:root:save model final: pld_24/final
