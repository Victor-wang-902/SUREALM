INFO:root:Output: small_multiqa_allmini_not_cross
INFO:root:Steps per epochs:1983
INFO:root:Total steps:396600
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at nreimers/MiniLM-L6-H384-uncased and are newly initialized: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 12543.962969539141
INFO:root:current train perplexity21276.384765625
INFO:root:current mean train loss 10639.713678254555
INFO:root:current train perplexity4494.18505859375
INFO:root:current mean train loss 9182.7888191759
INFO:root:current train perplexity1383.788330078125
INFO:root:current mean train loss 8193.317641026395
INFO:root:current train perplexity640.636962890625
INFO:root:current mean train loss 7504.0361807599575
INFO:root:current train perplexity371.8311462402344
INFO:root:current mean train loss 6985.962889809839
INFO:root:current train perplexity247.5245819091797
INFO:root:current mean train loss 6583.61665555984
INFO:root:current train perplexity180.8723602294922
INFO:root:current mean train loss 6258.417263522763
INFO:root:current train perplexity140.00718688964844
INFO:root:current mean train loss 5998.897645604491
INFO:root:current train perplexity113.6238021850586
INFO:root:current mean train loss 5776.010129269895
INFO:root:current train perplexity95.39883422851562
INFO:root:current mean train loss 5584.254785955983
INFO:root:current train perplexity82.11318969726562
INFO:root:current mean train loss 5420.335563246064
INFO:root:current train perplexity72.13402557373047
INFO:root:current mean train loss 5275.800057097707
INFO:root:current train perplexity64.32372283935547
INFO:root:current mean train loss 5150.441760506947
INFO:root:current train perplexity58.10887145996094
INFO:root:current mean train loss 5037.040227664797
INFO:root:current train perplexity53.088321685791016
INFO:root:current mean train loss 4936.476736711666
INFO:root:current train perplexity48.96714401245117
INFO:root:current mean train loss 4844.473268541467
INFO:root:current train perplexity45.515743255615234
INFO:root:current mean train loss 4758.218712951422
INFO:root:current train perplexity42.56309509277344
INFO:root:current mean train loss 4678.538633357606
INFO:root:current train perplexity40.02763748168945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:15<00:00, 375.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:15<00:00, 375.25s/it]
INFO:root:final mean train loss: 4616.503590024486
INFO:root:final train perplexity: 38.124332427978516
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.55s/it]
INFO:root:eval mean loss: 3009.711040523881
INFO:root:eval perplexity: 11.405295372009277
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.65s/it]
INFO:root:eval mean loss: 3293.655570821559
INFO:root:eval perplexity: 14.785429000854492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/1
  0%|          | 1/200 [07:15<24:03:24, 435.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3269.0521697998047
INFO:root:current train perplexity12.680383682250977
INFO:root:current mean train loss 3202.889938880657
INFO:root:current train perplexity12.418113708496094
INFO:root:current mean train loss 3189.8874523021555
INFO:root:current train perplexity12.249046325683594
INFO:root:current mean train loss 3165.334310410898
INFO:root:current train perplexity12.117663383483887
INFO:root:current mean train loss 3158.105077303373
INFO:root:current train perplexity12.063108444213867
INFO:root:current mean train loss 3147.892447538154
INFO:root:current train perplexity11.966079711914062
INFO:root:current mean train loss 3131.8865300958805
INFO:root:current train perplexity11.842844009399414
INFO:root:current mean train loss 3120.8593047584236
INFO:root:current train perplexity11.742697715759277
INFO:root:current mean train loss 3108.337813433479
INFO:root:current train perplexity11.637483596801758
INFO:root:current mean train loss 3101.3566428105382
INFO:root:current train perplexity11.568562507629395
INFO:root:current mean train loss 3088.6572195939193
INFO:root:current train perplexity11.469310760498047
INFO:root:current mean train loss 3076.781720123838
INFO:root:current train perplexity11.369490623474121
INFO:root:current mean train loss 3069.019719374807
INFO:root:current train perplexity11.278790473937988
INFO:root:current mean train loss 3061.1336302597833
INFO:root:current train perplexity11.190226554870605
INFO:root:current mean train loss 3052.2439816577285
INFO:root:current train perplexity11.104476928710938
INFO:root:current mean train loss 3043.420799074198
INFO:root:current train perplexity11.032713890075684
INFO:root:current mean train loss 3036.364954429098
INFO:root:current train perplexity10.971132278442383
INFO:root:current mean train loss 3029.692830403646
INFO:root:current train perplexity10.909205436706543
INFO:root:current mean train loss 3022.191693948754
INFO:root:current train perplexity10.84786319732666
INFO:root:current mean train loss 3015.8210134486317
INFO:root:current train perplexity10.781723976135254

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.13s/it]
INFO:root:final mean train loss: 3010.3495574812664
INFO:root:final train perplexity: 10.741799354553223
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.74s/it]
INFO:root:eval mean loss: 2682.7141416292666
INFO:root:eval perplexity: 8.754971504211426
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.93s/it]
INFO:root:eval mean loss: 3015.4467388180133
INFO:root:eval perplexity: 11.77660846710205
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/2
  1%|          | 2/200 [14:24<23:44:13, 431.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2866.9722419507575
INFO:root:current train perplexity9.527965545654297
INFO:root:current mean train loss 2856.367150787124
INFO:root:current train perplexity9.390331268310547
INFO:root:current mean train loss 2841.5536292080205
INFO:root:current train perplexity9.336024284362793
INFO:root:current mean train loss 2838.523248346002
INFO:root:current train perplexity9.325183868408203
INFO:root:current mean train loss 2840.4497916065243
INFO:root:current train perplexity9.335198402404785
INFO:root:current mean train loss 2834.759757838151
INFO:root:current train perplexity9.277259826660156
INFO:root:current mean train loss 2829.441731385145
INFO:root:current train perplexity9.236483573913574
INFO:root:current mean train loss 2824.9858085351298
INFO:root:current train perplexity9.211195945739746
INFO:root:current mean train loss 2819.6946580389967
INFO:root:current train perplexity9.188774108886719
INFO:root:current mean train loss 2812.0313630426044
INFO:root:current train perplexity9.145875930786133
INFO:root:current mean train loss 2806.0924465773987
INFO:root:current train perplexity9.112153053283691
INFO:root:current mean train loss 2802.7851508629606
INFO:root:current train perplexity9.089836120605469
INFO:root:current mean train loss 2795.7132886157997
INFO:root:current train perplexity9.053069114685059
INFO:root:current mean train loss 2789.228879729698
INFO:root:current train perplexity9.018651008605957
INFO:root:current mean train loss 2786.02211968581
INFO:root:current train perplexity8.984515190124512
INFO:root:current mean train loss 2781.2726702008927
INFO:root:current train perplexity8.949658393859863
INFO:root:current mean train loss 2777.2776098677664
INFO:root:current train perplexity8.924904823303223
INFO:root:current mean train loss 2773.0873834661716
INFO:root:current train perplexity8.902052879333496
INFO:root:current mean train loss 2768.687568993368
INFO:root:current train perplexity8.873706817626953
INFO:root:current mean train loss 2764.2062102908367
INFO:root:current train perplexity8.839513778686523

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:07<00:00, 367.83s/it]
INFO:root:final mean train loss: 2760.7848956732814
INFO:root:final train perplexity: 8.822638511657715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.51s/it]
INFO:root:eval mean loss: 2535.3984236480496
INFO:root:eval perplexity: 7.771640777587891
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.45s/it]
INFO:root:eval mean loss: 2891.6371853875776
INFO:root:eval perplexity: 10.642549514770508
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/3
  2%|â–         | 3/200 [21:30<23:28:52, 429.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2694.9422021484374
INFO:root:current train perplexity8.327234268188477
INFO:root:current mean train loss 2666.704523111979
INFO:root:current train perplexity8.236520767211914
INFO:root:current mean train loss 2657.019779296875
INFO:root:current train perplexity8.196907043457031
INFO:root:current mean train loss 2665.7001339285716
INFO:root:current train perplexity8.188127517700195
INFO:root:current mean train loss 2660.274189453125
INFO:root:current train perplexity8.155945777893066
INFO:root:current mean train loss 2666.9829279119317
INFO:root:current train perplexity8.169647216796875
INFO:root:current mean train loss 2664.9281197415867
INFO:root:current train perplexity8.155430793762207
INFO:root:current mean train loss 2663.3639827473958
INFO:root:current train perplexity8.146233558654785
INFO:root:current mean train loss 2662.4603033088233
INFO:root:current train perplexity8.126409530639648
INFO:root:current mean train loss 2659.05902318051
INFO:root:current train perplexity8.097071647644043
INFO:root:current mean train loss 2655.4177411179317
INFO:root:current train perplexity8.079480171203613
INFO:root:current mean train loss 2651.407705078125
INFO:root:current train perplexity8.05849552154541
INFO:root:current mean train loss 2648.113886328125
INFO:root:current train perplexity8.039347648620605
INFO:root:current mean train loss 2643.964349500868
INFO:root:current train perplexity8.020426750183105
INFO:root:current mean train loss 2641.0980573141164
INFO:root:current train perplexity8.00835132598877
INFO:root:current mean train loss 2638.811734816028
INFO:root:current train perplexity7.998252868652344
INFO:root:current mean train loss 2635.7795763790245
INFO:root:current train perplexity7.984348297119141
INFO:root:current mean train loss 2632.2689203404016
INFO:root:current train perplexity7.964871406555176
INFO:root:current mean train loss 2630.1645666173986
INFO:root:current train perplexity7.950315952301025
INFO:root:current mean train loss 2628.001079351963
INFO:root:current train perplexity7.938432693481445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.51s/it]
INFO:root:final mean train loss: 2626.259230805598
INFO:root:final train perplexity: 7.934544086456299
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.28s/it]
INFO:root:eval mean loss: 2448.7453829717974
INFO:root:eval perplexity: 7.245652675628662
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.06s/it]
INFO:root:eval mean loss: 2816.792351039589
INFO:root:eval perplexity: 10.010656356811523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/4
  2%|â–         | 4/200 [28:24<23:02:19, 423.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2568.469569875233
INFO:root:current train perplexity7.6870012283325195
INFO:root:current mean train loss 2564.105373725206
INFO:root:current train perplexity7.650359153747559
INFO:root:current mean train loss 2550.7114998463835
INFO:root:current train perplexity7.546530246734619
INFO:root:current mean train loss 2551.347159320717
INFO:root:current train perplexity7.514578819274902
INFO:root:current mean train loss 2552.6051901055607
INFO:root:current train perplexity7.496573448181152
INFO:root:current mean train loss 2551.003084912712
INFO:root:current train perplexity7.488129138946533
INFO:root:current mean train loss 2551.5408324280243
INFO:root:current train perplexity7.475334167480469
INFO:root:current mean train loss 2550.840068951424
INFO:root:current train perplexity7.473878383636475
INFO:root:current mean train loss 2551.990572426696
INFO:root:current train perplexity7.46914005279541
INFO:root:current mean train loss 2550.0869952323146
INFO:root:current train perplexity7.459197521209717
INFO:root:current mean train loss 2548.928800974366
INFO:root:current train perplexity7.458144664764404
INFO:root:current mean train loss 2547.233509838428
INFO:root:current train perplexity7.450953483581543
INFO:root:current mean train loss 2546.642917166381
INFO:root:current train perplexity7.450285911560059
INFO:root:current mean train loss 2544.8555883199697
INFO:root:current train perplexity7.445375919342041
INFO:root:current mean train loss 2544.801268615931
INFO:root:current train perplexity7.437817573547363
INFO:root:current mean train loss 2542.279254886552
INFO:root:current train perplexity7.425655841827393
INFO:root:current mean train loss 2540.2005801964606
INFO:root:current train perplexity7.411896228790283
INFO:root:current mean train loss 2539.7172239483853
INFO:root:current train perplexity7.404547214508057
INFO:root:current mean train loss 2537.5165683478676
INFO:root:current train perplexity7.391700744628906
INFO:root:current mean train loss 2535.628113506649
INFO:root:current train perplexity7.3848185539245605

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.43s/it]
INFO:root:final mean train loss: 2535.221723578641
INFO:root:final train perplexity: 7.384832859039307
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.23s/it]
INFO:root:eval mean loss: 2380.814808081228
INFO:root:eval perplexity: 6.8583245277404785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.40s/it]
INFO:root:eval mean loss: 2758.596243351064
INFO:root:eval perplexity: 9.545366287231445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/5
  2%|â–Ž         | 5/200 [36:41<24:21:22, 449.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2464.7071213495165
INFO:root:current train perplexity7.027784824371338
INFO:root:current mean train loss 2481.7115757154384
INFO:root:current train perplexity7.102672100067139
INFO:root:current mean train loss 2483.424229581591
INFO:root:current train perplexity7.079358100891113
INFO:root:current mean train loss 2486.228628794352
INFO:root:current train perplexity7.09116268157959
INFO:root:current mean train loss 2481.922643740315
INFO:root:current train perplexity7.063185691833496
INFO:root:current mean train loss 2482.0196491398224
INFO:root:current train perplexity7.0770182609558105
INFO:root:current mean train loss 2482.8955877649855
INFO:root:current train perplexity7.071239948272705
INFO:root:current mean train loss 2485.3466061961894
INFO:root:current train perplexity7.080170154571533
INFO:root:current mean train loss 2482.1834883884067
INFO:root:current train perplexity7.062808036804199
INFO:root:current mean train loss 2480.4433242673795
INFO:root:current train perplexity7.0566792488098145
INFO:root:current mean train loss 2481.9418122126167
INFO:root:current train perplexity7.06777811050415
INFO:root:current mean train loss 2478.914842657141
INFO:root:current train perplexity7.061470985412598
INFO:root:current mean train loss 2479.157085763331
INFO:root:current train perplexity7.056661605834961
INFO:root:current mean train loss 2477.2108176347147
INFO:root:current train perplexity7.051851749420166
INFO:root:current mean train loss 2476.3320134823534
INFO:root:current train perplexity7.046829700469971
INFO:root:current mean train loss 2474.2677365697996
INFO:root:current train perplexity7.037240982055664
INFO:root:current mean train loss 2471.9344095334304
INFO:root:current train perplexity7.032074451446533
INFO:root:current mean train loss 2469.927524994307
INFO:root:current train perplexity7.0232648849487305
INFO:root:current mean train loss 2469.870813843551
INFO:root:current train perplexity7.016574859619141

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.10s/it]
INFO:root:final mean train loss: 2469.4844178754274
INFO:root:final train perplexity: 7.011726379394531
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.18s/it]
INFO:root:eval mean loss: 2333.7693957606107
INFO:root:eval perplexity: 6.602284908294678
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it]
INFO:root:eval mean loss: 2715.88065982034
INFO:root:eval perplexity: 9.217667579650879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/6
  3%|â–Ž         | 6/200 [45:08<25:16:58, 469.17s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2582.0244140625
INFO:root:current train perplexity7.082040786743164
INFO:root:current mean train loss 2473.1165275951425
INFO:root:current train perplexity6.86149263381958
INFO:root:current mean train loss 2450.21117860405
INFO:root:current train perplexity6.8166961669921875
INFO:root:current mean train loss 2457.257735851199
INFO:root:current train perplexity6.853492259979248
INFO:root:current mean train loss 2448.07324797138
INFO:root:current train perplexity6.847839832305908
INFO:root:current mean train loss 2450.7059316425743
INFO:root:current train perplexity6.835409641265869
INFO:root:current mean train loss 2441.923550267783
INFO:root:current train perplexity6.814282417297363
INFO:root:current mean train loss 2439.741811189094
INFO:root:current train perplexity6.8054094314575195
INFO:root:current mean train loss 2436.248669418354
INFO:root:current train perplexity6.797083854675293
INFO:root:current mean train loss 2434.3586932488206
INFO:root:current train perplexity6.788563251495361
INFO:root:current mean train loss 2431.013971624079
INFO:root:current train perplexity6.778352737426758
INFO:root:current mean train loss 2427.4720189564882
INFO:root:current train perplexity6.7634429931640625
INFO:root:current mean train loss 2424.890096265807
INFO:root:current train perplexity6.757378101348877
INFO:root:current mean train loss 2424.7603351613543
INFO:root:current train perplexity6.748140335083008
INFO:root:current mean train loss 2422.867217647272
INFO:root:current train perplexity6.7430100440979
INFO:root:current mean train loss 2422.4735398568923
INFO:root:current train perplexity6.741547107696533
INFO:root:current mean train loss 2420.618836783529
INFO:root:current train perplexity6.737341403961182
INFO:root:current mean train loss 2419.8728921521347
INFO:root:current train perplexity6.735333442687988
INFO:root:current mean train loss 2419.33234567764
INFO:root:current train perplexity6.732508659362793
INFO:root:current mean train loss 2418.7287112200406
INFO:root:current train perplexity6.728633403778076

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.19s/it]
INFO:root:final mean train loss: 2416.274650262091
INFO:root:final train perplexity: 6.72357177734375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.57s/it]
INFO:root:eval mean loss: 2302.0258447092474
INFO:root:eval perplexity: 6.434946537017822
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.74s/it]
INFO:root:eval mean loss: 2691.387183656084
INFO:root:eval perplexity: 9.03486156463623
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/7
  4%|â–Ž         | 7/200 [52:22<24:32:41, 457.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2397.596733940972
INFO:root:current train perplexity6.56464147567749
INFO:root:current mean train loss 2382.447254245564
INFO:root:current train perplexity6.575960159301758
INFO:root:current mean train loss 2384.032006499964
INFO:root:current train perplexity6.555033206939697
INFO:root:current mean train loss 2384.5756191037735
INFO:root:current train perplexity6.545495986938477
INFO:root:current mean train loss 2383.4817408511512
INFO:root:current train perplexity6.543299674987793
INFO:root:current mean train loss 2384.1776245588503
INFO:root:current train perplexity6.557502746582031
INFO:root:current mean train loss 2383.795246803259
INFO:root:current train perplexity6.548655033111572
INFO:root:current mean train loss 2383.4707830317507
INFO:root:current train perplexity6.543910503387451
INFO:root:current mean train loss 2379.3150649688646
INFO:root:current train perplexity6.532475471496582
INFO:root:current mean train loss 2378.9627998036235
INFO:root:current train perplexity6.537143707275391
INFO:root:current mean train loss 2377.7715264640765
INFO:root:current train perplexity6.532588005065918
INFO:root:current mean train loss 2375.0624038068468
INFO:root:current train perplexity6.522369384765625
INFO:root:current mean train loss 2375.24434557885
INFO:root:current train perplexity6.5227580070495605
INFO:root:current mean train loss 2374.616402471192
INFO:root:current train perplexity6.515602111816406
INFO:root:current mean train loss 2374.6154723174145
INFO:root:current train perplexity6.511739730834961
INFO:root:current mean train loss 2375.8783885367775
INFO:root:current train perplexity6.512269973754883
INFO:root:current mean train loss 2376.4990521821164
INFO:root:current train perplexity6.513418197631836
INFO:root:current mean train loss 2376.016641423644
INFO:root:current train perplexity6.508074760437012
INFO:root:current mean train loss 2374.9618079727893
INFO:root:current train perplexity6.504490375518799
INFO:root:current mean train loss 2374.5746361948277
INFO:root:current train perplexity6.504927158355713

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.04s/it]
INFO:root:final mean train loss: 2373.9147500457993
INFO:root:final train perplexity: 6.502664566040039
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.92s/it]
INFO:root:eval mean loss: 2270.8578157898382
INFO:root:eval perplexity: 6.274767875671387
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.83s/it]
INFO:root:eval mean loss: 2662.9184488066544
INFO:root:eval perplexity: 8.826934814453125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/8
  4%|â–         | 8/200 [59:22<23:46:34, 445.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2330.5867047991073
INFO:root:current train perplexity6.307485580444336
INFO:root:current mean train loss 2337.1381627965857
INFO:root:current train perplexity6.316318035125732
INFO:root:current mean train loss 2335.037391435339
INFO:root:current train perplexity6.338705539703369
INFO:root:current mean train loss 2330.0491382200325
INFO:root:current train perplexity6.336978912353516
INFO:root:current mean train loss 2325.277736619971
INFO:root:current train perplexity6.331300735473633
INFO:root:current mean train loss 2329.0454199675087
INFO:root:current train perplexity6.331300258636475
INFO:root:current mean train loss 2334.584503990834
INFO:root:current train perplexity6.341001510620117
INFO:root:current mean train loss 2334.3265518707485
INFO:root:current train perplexity6.346370697021484
INFO:root:current mean train loss 2335.954181383327
INFO:root:current train perplexity6.343471527099609
INFO:root:current mean train loss 2339.9525343624664
INFO:root:current train perplexity6.34609842300415
INFO:root:current mean train loss 2341.5826572878923
INFO:root:current train perplexity6.350964546203613
INFO:root:current mean train loss 2340.2342922933303
INFO:root:current train perplexity6.346347808837891
INFO:root:current mean train loss 2342.9555558301176
INFO:root:current train perplexity6.349681377410889
INFO:root:current mean train loss 2341.9540041805653
INFO:root:current train perplexity6.343292236328125
INFO:root:current mean train loss 2340.2577652030704
INFO:root:current train perplexity6.337958335876465
INFO:root:current mean train loss 2341.421913171824
INFO:root:current train perplexity6.34014892578125
INFO:root:current mean train loss 2343.3048872921445
INFO:root:current train perplexity6.3421950340271
INFO:root:current mean train loss 2342.8516503765536
INFO:root:current train perplexity6.339181423187256
INFO:root:current mean train loss 2341.4475590594134
INFO:root:current train perplexity6.332178115844727
INFO:root:current mean train loss 2339.0545259382066
INFO:root:current train perplexity6.321789741516113

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.81s/it]
INFO:root:final mean train loss: 2337.9143755244777
INFO:root:final train perplexity: 6.320636749267578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.06s/it]
INFO:root:eval mean loss: 2253.009355693844
INFO:root:eval perplexity: 6.184842586517334
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.45s/it]
INFO:root:eval mean loss: 2654.3378698470747
INFO:root:eval perplexity: 8.765209197998047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/9
  4%|â–         | 9/200 [1:06:14<23:05:04, 435.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2285.669482891376
INFO:root:current train perplexity6.094766616821289
INFO:root:current mean train loss 2294.007280048571
INFO:root:current train perplexity6.142887115478516
INFO:root:current mean train loss 2300.80623953683
INFO:root:current train perplexity6.148580551147461
INFO:root:current mean train loss 2301.1933444630017
INFO:root:current train perplexity6.135687351226807
INFO:root:current mean train loss 2305.2422957968924
INFO:root:current train perplexity6.157838344573975
INFO:root:current mean train loss 2312.8518280913863
INFO:root:current train perplexity6.176543712615967
INFO:root:current mean train loss 2312.923536429376
INFO:root:current train perplexity6.177404403686523
INFO:root:current mean train loss 2311.848325851116
INFO:root:current train perplexity6.173873424530029
INFO:root:current mean train loss 2308.394029357624
INFO:root:current train perplexity6.167327404022217
INFO:root:current mean train loss 2311.0622388054344
INFO:root:current train perplexity6.1707377433776855
INFO:root:current mean train loss 2307.8569775715528
INFO:root:current train perplexity6.164112567901611
INFO:root:current mean train loss 2309.6971474753486
INFO:root:current train perplexity6.169970512390137
INFO:root:current mean train loss 2308.1255193838297
INFO:root:current train perplexity6.165987968444824
INFO:root:current mean train loss 2309.462113149067
INFO:root:current train perplexity6.169393062591553
INFO:root:current mean train loss 2307.50555983194
INFO:root:current train perplexity6.165106296539307
INFO:root:current mean train loss 2308.1573084408474
INFO:root:current train perplexity6.16666316986084
INFO:root:current mean train loss 2307.122432089891
INFO:root:current train perplexity6.162749767303467
INFO:root:current mean train loss 2307.0471337723407
INFO:root:current train perplexity6.162208080291748
INFO:root:current mean train loss 2307.240536782448
INFO:root:current train perplexity6.162726879119873
INFO:root:current mean train loss 2306.9382204149592
INFO:root:current train perplexity6.162997722625732

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:12<00:00, 372.26s/it]
INFO:root:final mean train loss: 2306.089739223832
INFO:root:final train perplexity: 6.163969993591309
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.05s/it]
INFO:root:eval mean loss: 2225.311429936835
INFO:root:eval perplexity: 6.047840118408203
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.93s/it]
INFO:root:eval mean loss: 2624.079220169825
INFO:root:eval perplexity: 8.55096435546875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/10
  5%|â–Œ         | 10/200 [1:13:24<22:53:17, 433.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2293.0674482704935
INFO:root:current train perplexity6.042708396911621
INFO:root:current mean train loss 2292.3956298828125
INFO:root:current train perplexity6.065704345703125
INFO:root:current mean train loss 2284.1592999426407
INFO:root:current train perplexity6.039231777191162
INFO:root:current mean train loss 2286.2284511162984
INFO:root:current train perplexity6.034419536590576
INFO:root:current mean train loss 2285.789262653668
INFO:root:current train perplexity6.044698238372803
INFO:root:current mean train loss 2283.7991550760653
INFO:root:current train perplexity6.049907684326172
INFO:root:current mean train loss 2283.5626554617434
INFO:root:current train perplexity6.041142463684082
INFO:root:current mean train loss 2281.5635248191643
INFO:root:current train perplexity6.038382053375244
INFO:root:current mean train loss 2282.7580324794126
INFO:root:current train perplexity6.042707920074463
INFO:root:current mean train loss 2282.6362935825027
INFO:root:current train perplexity6.047169208526611
INFO:root:current mean train loss 2280.99720734185
INFO:root:current train perplexity6.048899173736572
INFO:root:current mean train loss 2279.4316963868023
INFO:root:current train perplexity6.045238971710205
INFO:root:current mean train loss 2280.8356272740284
INFO:root:current train perplexity6.04563570022583
INFO:root:current mean train loss 2281.61035477253
INFO:root:current train perplexity6.045279026031494
INFO:root:current mean train loss 2282.6378079927886
INFO:root:current train perplexity6.047223091125488
INFO:root:current mean train loss 2280.6219826303827
INFO:root:current train perplexity6.039700984954834
INFO:root:current mean train loss 2280.4891672654376
INFO:root:current train perplexity6.040091037750244
INFO:root:current mean train loss 2280.092312620345
INFO:root:current train perplexity6.039819240570068
INFO:root:current mean train loss 2279.7049108579745
INFO:root:current train perplexity6.038516044616699
INFO:root:current mean train loss 2279.5789693868237
INFO:root:current train perplexity6.034548282623291

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.42s/it]
INFO:root:final mean train loss: 2278.968596473344
INFO:root:final train perplexity: 6.033527374267578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.41s/it]
INFO:root:eval mean loss: 2213.2832316946474
INFO:root:eval perplexity: 5.989293575286865
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.43s/it]
INFO:root:eval mean loss: 2619.1520130346853
INFO:root:eval perplexity: 8.51657485961914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/11
  6%|â–Œ         | 11/200 [1:20:14<22:22:43, 426.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2264.3717764920966
INFO:root:current train perplexity5.905766487121582
INFO:root:current mean train loss 2272.4312593193463
INFO:root:current train perplexity5.910556316375732
INFO:root:current mean train loss 2261.052520965363
INFO:root:current train perplexity5.9154157638549805
INFO:root:current mean train loss 2266.1638901468386
INFO:root:current train perplexity5.9365997314453125
INFO:root:current mean train loss 2257.814164777842
INFO:root:current train perplexity5.919865131378174
INFO:root:current mean train loss 2257.380443169395
INFO:root:current train perplexity5.924437522888184
INFO:root:current mean train loss 2255.8147760952875
INFO:root:current train perplexity5.920896053314209
INFO:root:current mean train loss 2252.3766974917503
INFO:root:current train perplexity5.910141944885254
INFO:root:current mean train loss 2251.083529435754
INFO:root:current train perplexity5.9089674949646
INFO:root:current mean train loss 2250.3904506845843
INFO:root:current train perplexity5.912144660949707
INFO:root:current mean train loss 2251.6435463696334
INFO:root:current train perplexity5.915346622467041
INFO:root:current mean train loss 2251.2198166228063
INFO:root:current train perplexity5.916238784790039
INFO:root:current mean train loss 2252.9967221368343
INFO:root:current train perplexity5.91874361038208
INFO:root:current mean train loss 2255.499719132593
INFO:root:current train perplexity5.9239044189453125
INFO:root:current mean train loss 2255.5830909451756
INFO:root:current train perplexity5.921727657318115
INFO:root:current mean train loss 2254.8525966341226
INFO:root:current train perplexity5.919132709503174
INFO:root:current mean train loss 2254.242161073153
INFO:root:current train perplexity5.9155073165893555
INFO:root:current mean train loss 2254.2849976132725
INFO:root:current train perplexity5.917111873626709
INFO:root:current mean train loss 2254.957875839347
INFO:root:current train perplexity5.9181389808654785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.25s/it]
INFO:root:final mean train loss: 2254.42896683578
INFO:root:final train perplexity: 5.917880058288574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.35s/it]
INFO:root:eval mean loss: 2191.6658792698636
INFO:root:eval perplexity: 5.885493755340576
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it]
INFO:root:eval mean loss: 2601.7793193844195
INFO:root:eval perplexity: 8.396430015563965
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/12
  6%|â–Œ         | 12/200 [1:27:04<22:00:01, 421.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2239.594767252604
INFO:root:current train perplexity6.048649787902832
INFO:root:current mean train loss 2218.348513112485
INFO:root:current train perplexity5.783109664916992
INFO:root:current mean train loss 2233.5807907029325
INFO:root:current train perplexity5.816978454589844
INFO:root:current mean train loss 2224.0846881929406
INFO:root:current train perplexity5.8137311935424805
INFO:root:current mean train loss 2226.9608202761515
INFO:root:current train perplexity5.810741424560547
INFO:root:current mean train loss 2227.617949044017
INFO:root:current train perplexity5.807173728942871
INFO:root:current mean train loss 2225.096048282351
INFO:root:current train perplexity5.798521041870117
INFO:root:current mean train loss 2227.643185003723
INFO:root:current train perplexity5.80910062789917
INFO:root:current mean train loss 2228.1437174985895
INFO:root:current train perplexity5.811065673828125
INFO:root:current mean train loss 2229.5380334864685
INFO:root:current train perplexity5.808719635009766
INFO:root:current mean train loss 2227.5599601342456
INFO:root:current train perplexity5.801716327667236
INFO:root:current mean train loss 2226.207570772007
INFO:root:current train perplexity5.797698974609375
INFO:root:current mean train loss 2229.191329638956
INFO:root:current train perplexity5.806421756744385
INFO:root:current mean train loss 2230.5352987434344
INFO:root:current train perplexity5.806876182556152
INFO:root:current mean train loss 2230.3346156081557
INFO:root:current train perplexity5.808128356933594
INFO:root:current mean train loss 2232.3597751599664
INFO:root:current train perplexity5.812590599060059
INFO:root:current mean train loss 2232.7902212922304
INFO:root:current train perplexity5.813485145568848
INFO:root:current mean train loss 2231.8352090205017
INFO:root:current train perplexity5.814916133880615
INFO:root:current mean train loss 2231.5692494117875
INFO:root:current train perplexity5.813537120819092
INFO:root:current mean train loss 2231.123051044506
INFO:root:current train perplexity5.809435844421387

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.77s/it]
INFO:root:final mean train loss: 2231.01893120947
INFO:root:final train perplexity: 5.809624195098877
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.81s/it]
INFO:root:eval mean loss: 2180.6486431148883
INFO:root:eval perplexity: 5.833285808563232
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.16s/it]
INFO:root:eval mean loss: 2593.0291332488364
INFO:root:eval perplexity: 8.336559295654297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/13
  6%|â–‹         | 13/200 [1:33:57<21:45:09, 418.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2256.893231201172
INFO:root:current train perplexity5.8463568687438965
INFO:root:current mean train loss 2219.0114023844403
INFO:root:current train perplexity5.7451395988464355
INFO:root:current mean train loss 2213.9825123180044
INFO:root:current train perplexity5.723888397216797
INFO:root:current mean train loss 2221.752638626099
INFO:root:current train perplexity5.742393970489502
INFO:root:current mean train loss 2219.884670875186
INFO:root:current train perplexity5.7358856201171875
INFO:root:current mean train loss 2219.760696411133
INFO:root:current train perplexity5.739803314208984
INFO:root:current mean train loss 2218.732055270287
INFO:root:current train perplexity5.731006145477295
INFO:root:current mean train loss 2217.6176342434355
INFO:root:current train perplexity5.728213310241699
INFO:root:current mean train loss 2216.896616865949
INFO:root:current train perplexity5.73248815536499
INFO:root:current mean train loss 2216.672892694888
INFO:root:current train perplexity5.731907844543457
INFO:root:current mean train loss 2214.968612132353
INFO:root:current train perplexity5.728198051452637
INFO:root:current mean train loss 2215.432244655064
INFO:root:current train perplexity5.727970123291016
INFO:root:current mean train loss 2215.2579833984373
INFO:root:current train perplexity5.729357719421387
INFO:root:current mean train loss 2215.27934847745
INFO:root:current train perplexity5.7283854484558105
INFO:root:current mean train loss 2214.7844251176
INFO:root:current train perplexity5.729777812957764
INFO:root:current mean train loss 2214.0133328086454
INFO:root:current train perplexity5.731341361999512
INFO:root:current mean train loss 2213.7875265992716
INFO:root:current train perplexity5.730482578277588
INFO:root:current mean train loss 2212.541970115484
INFO:root:current train perplexity5.724227428436279
INFO:root:current mean train loss 2212.682770714393
INFO:root:current train perplexity5.722620010375977
INFO:root:current mean train loss 2212.436038525899
INFO:root:current train perplexity5.718420505523682

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.63s/it]
INFO:root:final mean train loss: 2211.1427318363317
INFO:root:final train perplexity: 5.719264507293701
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.73s/it]
INFO:root:eval mean loss: 2166.992095730829
INFO:root:eval perplexity: 5.769215106964111
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.78s/it]
INFO:root:eval mean loss: 2580.91870809785
INFO:root:eval perplexity: 8.254396438598633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/14
  7%|â–‹         | 14/200 [1:40:48<21:31:14, 416.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2153.5602070576438
INFO:root:current train perplexity5.5525054931640625
INFO:root:current mean train loss 2189.081009245267
INFO:root:current train perplexity5.609875202178955
INFO:root:current mean train loss 2192.387630414359
INFO:root:current train perplexity5.6275739669799805
INFO:root:current mean train loss 2188.4311939997915
INFO:root:current train perplexity5.621664047241211
INFO:root:current mean train loss 2188.6686098286436
INFO:root:current train perplexity5.614349842071533
INFO:root:current mean train loss 2190.8524183561017
INFO:root:current train perplexity5.61855936050415
INFO:root:current mean train loss 2193.9190166000294
INFO:root:current train perplexity5.627143859863281
INFO:root:current mean train loss 2196.8965840850788
INFO:root:current train perplexity5.634181022644043
INFO:root:current mean train loss 2198.6501060859564
INFO:root:current train perplexity5.636373043060303
INFO:root:current mean train loss 2198.788383361751
INFO:root:current train perplexity5.639886856079102
INFO:root:current mean train loss 2196.5468901852173
INFO:root:current train perplexity5.637160778045654
INFO:root:current mean train loss 2194.6301936247733
INFO:root:current train perplexity5.635408401489258
INFO:root:current mean train loss 2195.2866897768035
INFO:root:current train perplexity5.640562534332275
INFO:root:current mean train loss 2195.5649155678816
INFO:root:current train perplexity5.63881254196167
INFO:root:current mean train loss 2195.970174748282
INFO:root:current train perplexity5.6397199630737305
INFO:root:current mean train loss 2196.732846301643
INFO:root:current train perplexity5.642088413238525
INFO:root:current mean train loss 2196.6921992968987
INFO:root:current train perplexity5.641442775726318
INFO:root:current mean train loss 2195.6852032931015
INFO:root:current train perplexity5.64271879196167
INFO:root:current mean train loss 2194.5438862376454
INFO:root:current train perplexity5.639117240905762
INFO:root:current mean train loss 2194.3215601127913
INFO:root:current train perplexity5.641898155212402

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.32s/it]
INFO:root:final mean train loss: 2193.64518447699
INFO:root:final train perplexity: 5.64088249206543
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.19s/it]
INFO:root:eval mean loss: 2158.7430995643563
INFO:root:eval perplexity: 5.7308549880981445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.49s/it]
INFO:root:eval mean loss: 2577.0834406859485
INFO:root:eval perplexity: 8.228547096252441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/15
  8%|â–Š         | 15/200 [1:47:42<21:22:09, 415.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2179.0175509982637
INFO:root:current train perplexity5.561328411102295
INFO:root:current mean train loss 2171.1872003728695
INFO:root:current train perplexity5.478209972381592
INFO:root:current mean train loss 2174.3502677857405
INFO:root:current train perplexity5.503147602081299
INFO:root:current mean train loss 2174.5970962438205
INFO:root:current train perplexity5.526353359222412
INFO:root:current mean train loss 2179.091786388784
INFO:root:current train perplexity5.5386786460876465
INFO:root:current mean train loss 2179.709247905855
INFO:root:current train perplexity5.551267147064209
INFO:root:current mean train loss 2178.9382271956233
INFO:root:current train perplexity5.5582098960876465
INFO:root:current mean train loss 2178.323370248
INFO:root:current train perplexity5.5571746826171875
INFO:root:current mean train loss 2175.903841898648
INFO:root:current train perplexity5.5548481941223145
INFO:root:current mean train loss 2175.2538028613076
INFO:root:current train perplexity5.556515216827393
INFO:root:current mean train loss 2175.7223067166005
INFO:root:current train perplexity5.559659481048584
INFO:root:current mean train loss 2177.815485433648
INFO:root:current train perplexity5.5600810050964355
INFO:root:current mean train loss 2177.6911541271056
INFO:root:current train perplexity5.563937187194824
INFO:root:current mean train loss 2176.0781121979435
INFO:root:current train perplexity5.561779975891113
INFO:root:current mean train loss 2176.0349857377546
INFO:root:current train perplexity5.561917304992676
INFO:root:current mean train loss 2175.876851556844
INFO:root:current train perplexity5.561619281768799
INFO:root:current mean train loss 2176.3180873368065
INFO:root:current train perplexity5.5615410804748535
INFO:root:current mean train loss 2177.584693899992
INFO:root:current train perplexity5.564935207366943
INFO:root:current mean train loss 2176.6043898696653
INFO:root:current train perplexity5.56336784362793
INFO:root:current mean train loss 2176.5538231997066
INFO:root:current train perplexity5.563333034515381

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.76s/it]
INFO:root:final mean train loss: 2176.340107158405
INFO:root:final train perplexity: 5.564418792724609
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.80s/it]
INFO:root:eval mean loss: 2153.907958984375
INFO:root:eval perplexity: 5.7084879875183105
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 2575.3221110891786
INFO:root:eval perplexity: 8.216704368591309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/16
  8%|â–Š         | 16/200 [1:54:35<21:12:54, 415.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2174.0001908423196
INFO:root:current train perplexity5.502546787261963
INFO:root:current mean train loss 2169.0748026886877
INFO:root:current train perplexity5.512473106384277
INFO:root:current mean train loss 2160.011460195168
INFO:root:current train perplexity5.5054731369018555
INFO:root:current mean train loss 2160.4903439421537
INFO:root:current train perplexity5.505011081695557
INFO:root:current mean train loss 2163.888091069118
INFO:root:current train perplexity5.506162166595459
INFO:root:current mean train loss 2166.8926589351195
INFO:root:current train perplexity5.517536640167236
INFO:root:current mean train loss 2165.090207232093
INFO:root:current train perplexity5.511828422546387
INFO:root:current mean train loss 2162.6458540742037
INFO:root:current train perplexity5.500916957855225
INFO:root:current mean train loss 2161.4011315960015
INFO:root:current train perplexity5.497724533081055
INFO:root:current mean train loss 2160.5768002039617
INFO:root:current train perplexity5.499759674072266
INFO:root:current mean train loss 2159.1370792620432
INFO:root:current train perplexity5.497926235198975
INFO:root:current mean train loss 2160.656597029949
INFO:root:current train perplexity5.500189304351807
INFO:root:current mean train loss 2159.6666095532555
INFO:root:current train perplexity5.500326633453369
INFO:root:current mean train loss 2159.4776120731904
INFO:root:current train perplexity5.49835729598999
INFO:root:current mean train loss 2158.923518675513
INFO:root:current train perplexity5.4950714111328125
INFO:root:current mean train loss 2159.8192081172174
INFO:root:current train perplexity5.4969162940979
INFO:root:current mean train loss 2159.721060423563
INFO:root:current train perplexity5.494169235229492
INFO:root:current mean train loss 2160.9861658700506
INFO:root:current train perplexity5.496531963348389
INFO:root:current mean train loss 2159.9772016891243
INFO:root:current train perplexity5.493642330169678
INFO:root:current mean train loss 2160.950161992445
INFO:root:current train perplexity5.494713306427002

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.10s/it]
INFO:root:final mean train loss: 2160.2928780129146
INFO:root:final train perplexity: 5.49444055557251
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.90s/it]
INFO:root:eval mean loss: 2148.111799957059
INFO:root:eval perplexity: 5.68179178237915
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.31s/it]
INFO:root:eval mean loss: 2570.2397300774323
INFO:root:eval perplexity: 8.182621955871582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/17
  8%|â–Š         | 17/200 [2:01:35<21:10:03, 416.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2158.700013594194
INFO:root:current train perplexity5.487765789031982
INFO:root:current mean train loss 2144.19012840758
INFO:root:current train perplexity5.453669548034668
INFO:root:current mean train loss 2150.1750022040474
INFO:root:current train perplexity5.4411301612854
INFO:root:current mean train loss 2153.788371921815
INFO:root:current train perplexity5.4468255043029785
INFO:root:current mean train loss 2153.836025800861
INFO:root:current train perplexity5.444718360900879
INFO:root:current mean train loss 2154.1564380879304
INFO:root:current train perplexity5.438931465148926
INFO:root:current mean train loss 2149.139841656352
INFO:root:current train perplexity5.434106826782227
INFO:root:current mean train loss 2150.7691153124506
INFO:root:current train perplexity5.437894821166992
INFO:root:current mean train loss 2150.9886225794885
INFO:root:current train perplexity5.43694543838501
INFO:root:current mean train loss 2148.8129304584704
INFO:root:current train perplexity5.431936264038086
INFO:root:current mean train loss 2145.341252270867
INFO:root:current train perplexity5.424862861633301
INFO:root:current mean train loss 2144.230130898832
INFO:root:current train perplexity5.425984859466553
INFO:root:current mean train loss 2143.2053369557634
INFO:root:current train perplexity5.425614356994629
INFO:root:current mean train loss 2143.9254853086445
INFO:root:current train perplexity5.427847385406494
INFO:root:current mean train loss 2144.099747278357
INFO:root:current train perplexity5.4288554191589355
INFO:root:current mean train loss 2144.4709348126084
INFO:root:current train perplexity5.429356098175049
INFO:root:current mean train loss 2146.040255650525
INFO:root:current train perplexity5.432107448577881
INFO:root:current mean train loss 2145.881992758254
INFO:root:current train perplexity5.429305553436279
INFO:root:current mean train loss 2145.4964311244125
INFO:root:current train perplexity5.427979469299316

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.16s/it]
INFO:root:final mean train loss: 2145.018207959797
INFO:root:final train perplexity: 5.428648948669434
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.37s/it]
INFO:root:eval mean loss: 2135.6097325534683
INFO:root:eval perplexity: 5.624632358551025
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it]
INFO:root:eval mean loss: 2562.632341533688
INFO:root:eval perplexity: 8.131871223449707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/18
  9%|â–‰         | 18/200 [2:09:59<22:23:03, 442.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2124.4047607421876
INFO:root:current train perplexity5.393707275390625
INFO:root:current mean train loss 2142.2526925223215
INFO:root:current train perplexity5.364465236663818
INFO:root:current mean train loss 2134.075173875762
INFO:root:current train perplexity5.361612796783447
INFO:root:current mean train loss 2131.1919909868084
INFO:root:current train perplexity5.3355207443237305
INFO:root:current mean train loss 2127.740086383584
INFO:root:current train perplexity5.329712867736816
INFO:root:current mean train loss 2132.3995948715965
INFO:root:current train perplexity5.361385822296143
INFO:root:current mean train loss 2128.206421907283
INFO:root:current train perplexity5.355037212371826
INFO:root:current mean train loss 2128.849711186835
INFO:root:current train perplexity5.355945110321045
INFO:root:current mean train loss 2127.0811716020476
INFO:root:current train perplexity5.356907844543457
INFO:root:current mean train loss 2127.319966926364
INFO:root:current train perplexity5.357615947723389
INFO:root:current mean train loss 2129.0358964455068
INFO:root:current train perplexity5.354600429534912
INFO:root:current mean train loss 2130.2923155357394
INFO:root:current train perplexity5.357812404632568
INFO:root:current mean train loss 2131.0809655407156
INFO:root:current train perplexity5.3602495193481445
INFO:root:current mean train loss 2130.285369241649
INFO:root:current train perplexity5.361149311065674
INFO:root:current mean train loss 2131.359889432968
INFO:root:current train perplexity5.358377456665039
INFO:root:current mean train loss 2132.7939847318835
INFO:root:current train perplexity5.361199855804443
INFO:root:current mean train loss 2133.6108590859862
INFO:root:current train perplexity5.365968227386475
INFO:root:current mean train loss 2133.8114154714995
INFO:root:current train perplexity5.365799903869629
INFO:root:current mean train loss 2133.2424704596606
INFO:root:current train perplexity5.368082046508789
INFO:root:current mean train loss 2133.8930031603713
INFO:root:current train perplexity5.371744632720947

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:05<00:00, 365.36s/it]
INFO:root:final mean train loss: 2131.4606816324995
INFO:root:final train perplexity: 5.370915412902832
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.31s/it]
INFO:root:eval mean loss: 2134.4180882230717
INFO:root:eval perplexity: 5.61921501159668
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.76s/it]
INFO:root:eval mean loss: 2561.408261995789
INFO:root:eval perplexity: 8.123734474182129
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/19
 10%|â–‰         | 19/200 [2:18:32<23:19:38, 463.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2056.4756081321025
INFO:root:current train perplexity5.218500137329102
INFO:root:current mean train loss 2100.118844454406
INFO:root:current train perplexity5.274807929992676
INFO:root:current mean train loss 2107.0480764578056
INFO:root:current train perplexity5.305039882659912
INFO:root:current mean train loss 2122.5871172602874
INFO:root:current train perplexity5.321599960327148
INFO:root:current mean train loss 2125.39502329171
INFO:root:current train perplexity5.327891826629639
INFO:root:current mean train loss 2121.3216947942856
INFO:root:current train perplexity5.32563591003418
INFO:root:current mean train loss 2117.441063197096
INFO:root:current train perplexity5.320321559906006
INFO:root:current mean train loss 2114.2009037260864
INFO:root:current train perplexity5.313194274902344
INFO:root:current mean train loss 2116.0963130310506
INFO:root:current train perplexity5.311389446258545
INFO:root:current mean train loss 2115.4788090174216
INFO:root:current train perplexity5.307985305786133
INFO:root:current mean train loss 2113.4057500133777
INFO:root:current train perplexity5.302677631378174
INFO:root:current mean train loss 2112.560357459301
INFO:root:current train perplexity5.301596164703369
INFO:root:current mean train loss 2113.9744685246396
INFO:root:current train perplexity5.302628040313721
INFO:root:current mean train loss 2114.733707214448
INFO:root:current train perplexity5.304721355438232
INFO:root:current mean train loss 2116.168103782772
INFO:root:current train perplexity5.308815956115723
INFO:root:current mean train loss 2116.574618646569
INFO:root:current train perplexity5.30895471572876
INFO:root:current mean train loss 2117.249177116648
INFO:root:current train perplexity5.311474323272705
INFO:root:current mean train loss 2117.3641460210465
INFO:root:current train perplexity5.313451290130615
INFO:root:current mean train loss 2118.375645793492
INFO:root:current train perplexity5.313584327697754
INFO:root:current mean train loss 2119.4728357352774
INFO:root:current train perplexity5.316450595855713

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.29s/it]
INFO:root:final mean train loss: 2118.608396929319
INFO:root:final train perplexity: 5.316749095916748
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.25s/it]
INFO:root:eval mean loss: 2117.870828398576
INFO:root:eval perplexity: 5.544517517089844
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.40s/it]
INFO:root:eval mean loss: 2543.234886656416
INFO:root:eval perplexity: 8.003888130187988
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/20
 10%|â–ˆ         | 20/200 [2:27:02<23:53:01, 477.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2102.3631810897436
INFO:root:current train perplexity5.1714982986450195
INFO:root:current mean train loss 2107.2574603403214
INFO:root:current train perplexity5.208697319030762
INFO:root:current mean train loss 2105.144125200216
INFO:root:current train perplexity5.215248107910156
INFO:root:current mean train loss 2105.821438499608
INFO:root:current train perplexity5.241759300231934
INFO:root:current mean train loss 2105.0036212338946
INFO:root:current train perplexity5.2515716552734375
INFO:root:current mean train loss 2106.4019240908365
INFO:root:current train perplexity5.253767013549805
INFO:root:current mean train loss 2110.8131351858983
INFO:root:current train perplexity5.259814739227295
INFO:root:current mean train loss 2110.2859634998204
INFO:root:current train perplexity5.261307239532471
INFO:root:current mean train loss 2107.44945838028
INFO:root:current train perplexity5.253535747528076
INFO:root:current mean train loss 2108.771551455172
INFO:root:current train perplexity5.260887145996094
INFO:root:current mean train loss 2110.159523458178
INFO:root:current train perplexity5.264522075653076
INFO:root:current mean train loss 2112.379391423226
INFO:root:current train perplexity5.269951343536377
INFO:root:current mean train loss 2111.104742436567
INFO:root:current train perplexity5.266712665557861
INFO:root:current mean train loss 2110.83274908543
INFO:root:current train perplexity5.269545078277588
INFO:root:current mean train loss 2110.115525935573
INFO:root:current train perplexity5.273690223693848
INFO:root:current mean train loss 2109.368304613893
INFO:root:current train perplexity5.273002624511719
INFO:root:current mean train loss 2110.3915217215144
INFO:root:current train perplexity5.275592803955078
INFO:root:current mean train loss 2109.2161755027137
INFO:root:current train perplexity5.269713878631592
INFO:root:current mean train loss 2107.9443862525063
INFO:root:current train perplexity5.2664690017700195
INFO:root:current mean train loss 2107.077041728279
INFO:root:current train perplexity5.263967514038086

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.14s/it]
INFO:root:final mean train loss: 2105.5804703443628
INFO:root:final train perplexity: 5.262401103973389
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.38s/it]
INFO:root:eval mean loss: 2113.244224602449
INFO:root:eval perplexity: 5.523809909820557
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.03s/it]
INFO:root:eval mean loss: 2543.061670181599
INFO:root:eval perplexity: 8.002755165100098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/21
 10%|â–ˆ         | 21/200 [2:33:58<22:49:39, 459.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2068.903058733259
INFO:root:current train perplexity5.200786590576172
INFO:root:current mean train loss 2084.771950746194
INFO:root:current train perplexity5.19718074798584
INFO:root:current mean train loss 2094.7829880714417
INFO:root:current train perplexity5.201271057128906
INFO:root:current mean train loss 2089.606037954266
INFO:root:current train perplexity5.17930793762207
INFO:root:current mean train loss 2085.838857014974
INFO:root:current train perplexity5.180068492889404
INFO:root:current mean train loss 2091.678128029803
INFO:root:current train perplexity5.193222999572754
INFO:root:current mean train loss 2095.282215583615
INFO:root:current train perplexity5.205386161804199
INFO:root:current mean train loss 2098.5620167242787
INFO:root:current train perplexity5.201838970184326
INFO:root:current mean train loss 2099.010421039902
INFO:root:current train perplexity5.202960968017578
INFO:root:current mean train loss 2099.0164599558298
INFO:root:current train perplexity5.204723358154297
INFO:root:current mean train loss 2097.2866472186465
INFO:root:current train perplexity5.208282947540283
INFO:root:current mean train loss 2098.5141228804537
INFO:root:current train perplexity5.213162422180176
INFO:root:current mean train loss 2098.448244422864
INFO:root:current train perplexity5.214738845825195
INFO:root:current mean train loss 2096.8808635160285
INFO:root:current train perplexity5.21360445022583
INFO:root:current mean train loss 2097.124827793666
INFO:root:current train perplexity5.2146992683410645
INFO:root:current mean train loss 2096.8570063181587
INFO:root:current train perplexity5.214645862579346
INFO:root:current mean train loss 2094.4045936473904
INFO:root:current train perplexity5.209620475769043
INFO:root:current mean train loss 2094.5533926231715
INFO:root:current train perplexity5.210226058959961
INFO:root:current mean train loss 2093.587790916706
INFO:root:current train perplexity5.211058616638184
INFO:root:current mean train loss 2094.1057548913
INFO:root:current train perplexity5.213995933532715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.78s/it]
INFO:root:final mean train loss: 2093.6297983543714
INFO:root:final train perplexity: 5.213036060333252
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.82s/it]
INFO:root:eval mean loss: 2105.514250193927
INFO:root:eval perplexity: 5.48938512802124
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.00s/it]
INFO:root:eval mean loss: 2537.448727871509
INFO:root:eval perplexity: 7.966100215911865
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/22
 11%|â–ˆ         | 22/200 [2:40:58<22:07:03, 447.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2072.7843469071063
INFO:root:current train perplexity5.148232460021973
INFO:root:current mean train loss 2073.9253353052745
INFO:root:current train perplexity5.152767658233643
INFO:root:current mean train loss 2079.583471053686
INFO:root:current train perplexity5.14259147644043
INFO:root:current mean train loss 2084.390517656669
INFO:root:current train perplexity5.156342506408691
INFO:root:current mean train loss 2079.4315185546875
INFO:root:current train perplexity5.1450629234313965
INFO:root:current mean train loss 2078.128492531768
INFO:root:current train perplexity5.137500762939453
INFO:root:current mean train loss 2080.6965063585394
INFO:root:current train perplexity5.142971038818359
INFO:root:current mean train loss 2078.9536540239933
INFO:root:current train perplexity5.142221450805664
INFO:root:current mean train loss 2079.306560922734
INFO:root:current train perplexity5.146252632141113
INFO:root:current mean train loss 2077.9723914088595
INFO:root:current train perplexity5.147726058959961
INFO:root:current mean train loss 2078.613284435432
INFO:root:current train perplexity5.147347927093506
INFO:root:current mean train loss 2078.744632028253
INFO:root:current train perplexity5.1502814292907715
INFO:root:current mean train loss 2080.6582202896393
INFO:root:current train perplexity5.155397891998291
INFO:root:current mean train loss 2081.307848436504
INFO:root:current train perplexity5.154969692230225
INFO:root:current mean train loss 2081.6251230647754
INFO:root:current train perplexity5.1545891761779785
INFO:root:current mean train loss 2082.496313445521
INFO:root:current train perplexity5.159236431121826
INFO:root:current mean train loss 2083.5745878065695
INFO:root:current train perplexity5.16447639465332
INFO:root:current mean train loss 2082.7362821334777
INFO:root:current train perplexity5.163817882537842
INFO:root:current mean train loss 2082.7980518412346
INFO:root:current train perplexity5.163949966430664
INFO:root:current mean train loss 2083.1686536554025
INFO:root:current train perplexity5.167828559875488

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.82s/it]
INFO:root:final mean train loss: 2082.2641987533684
INFO:root:final train perplexity: 5.16651725769043
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.18s/it]
INFO:root:eval mean loss: 2102.650402312583
INFO:root:eval perplexity: 5.476686477661133
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.14s/it]
INFO:root:eval mean loss: 2535.1546466367463
INFO:root:eval perplexity: 7.951170921325684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/23
 12%|â–ˆâ–        | 23/200 [2:47:52<21:30:27, 437.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2082.5272637261287
INFO:root:current train perplexity5.116292476654053
INFO:root:current mean train loss 2075.5681955437913
INFO:root:current train perplexity5.111983776092529
INFO:root:current mean train loss 2070.293116076239
INFO:root:current train perplexity5.103859901428223
INFO:root:current mean train loss 2071.6907774313904
INFO:root:current train perplexity5.103113651275635
INFO:root:current mean train loss 2072.2259778081157
INFO:root:current train perplexity5.104891300201416
INFO:root:current mean train loss 2070.217900059587
INFO:root:current train perplexity5.1045145988464355
INFO:root:current mean train loss 2071.387332109092
INFO:root:current train perplexity5.111515522003174
INFO:root:current mean train loss 2072.203374703323
INFO:root:current train perplexity5.119830131530762
INFO:root:current mean train loss 2072.4648875032917
INFO:root:current train perplexity5.1231465339660645
INFO:root:current mean train loss 2073.191465435606
INFO:root:current train perplexity5.12224006652832
INFO:root:current mean train loss 2071.6991404682126
INFO:root:current train perplexity5.121401309967041
INFO:root:current mean train loss 2071.0868491293
INFO:root:current train perplexity5.118804454803467
INFO:root:current mean train loss 2072.1873739553052
INFO:root:current train perplexity5.119526386260986
INFO:root:current mean train loss 2071.8376963663445
INFO:root:current train perplexity5.116774559020996
INFO:root:current mean train loss 2072.968975952968
INFO:root:current train perplexity5.123714923858643
INFO:root:current mean train loss 2071.953901029383
INFO:root:current train perplexity5.123109817504883
INFO:root:current mean train loss 2071.781133202547
INFO:root:current train perplexity5.123135089874268
INFO:root:current mean train loss 2071.913815358764
INFO:root:current train perplexity5.1228227615356445
INFO:root:current mean train loss 2072.17462926794
INFO:root:current train perplexity5.123049259185791

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.93s/it]
INFO:root:final mean train loss: 2071.585665165627
INFO:root:final train perplexity: 5.123189449310303
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.39s/it]
INFO:root:eval mean loss: 2094.420846059813
INFO:root:eval perplexity: 5.440356731414795
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.43s/it]
INFO:root:eval mean loss: 2528.590589590952
INFO:root:eval perplexity: 7.9086012840271
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/24
 12%|â–ˆâ–        | 24/200 [2:54:42<20:58:59, 429.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2084.0373883928573
INFO:root:current train perplexity4.858345985412598
INFO:root:current mean train loss 2056.866914838274
INFO:root:current train perplexity5.078222274780273
INFO:root:current mean train loss 2048.8119380047933
INFO:root:current train perplexity5.055206298828125
INFO:root:current mean train loss 2051.5879391350263
INFO:root:current train perplexity5.0692458152771
INFO:root:current mean train loss 2055.6379838423295
INFO:root:current train perplexity5.067915916442871
INFO:root:current mean train loss 2062.1552057811728
INFO:root:current train perplexity5.0742974281311035
INFO:root:current mean train loss 2059.542533962495
INFO:root:current train perplexity5.066835403442383
INFO:root:current mean train loss 2055.0922730700804
INFO:root:current train perplexity5.057500839233398
INFO:root:current mean train loss 2058.8149504821095
INFO:root:current train perplexity5.065976619720459
INFO:root:current mean train loss 2058.580856441006
INFO:root:current train perplexity5.067291259765625
INFO:root:current mean train loss 2057.329735431084
INFO:root:current train perplexity5.070286750793457
INFO:root:current mean train loss 2056.4191972823864
INFO:root:current train perplexity5.067886829376221
INFO:root:current mean train loss 2057.5782268432517
INFO:root:current train perplexity5.069369792938232
INFO:root:current mean train loss 2056.5063125388533
INFO:root:current train perplexity5.067492961883545
INFO:root:current mean train loss 2058.49726291811
INFO:root:current train perplexity5.073187351226807
INFO:root:current mean train loss 2059.5524532163704
INFO:root:current train perplexity5.075462341308594
INFO:root:current mean train loss 2059.6364302477928
INFO:root:current train perplexity5.075839519500732
INFO:root:current mean train loss 2060.0908036502956
INFO:root:current train perplexity5.073060512542725
INFO:root:current mean train loss 2060.4327513500016
INFO:root:current train perplexity5.076875686645508
INFO:root:current mean train loss 2061.2514187553256
INFO:root:current train perplexity5.078711986541748

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.29s/it]
INFO:root:final mean train loss: 2060.8476856749166
INFO:root:final train perplexity: 5.079985618591309
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.99s/it]
INFO:root:eval mean loss: 2093.246600211935
INFO:root:eval perplexity: 5.435193061828613
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.18s/it]
INFO:root:eval mean loss: 2529.2982169076904
INFO:root:eval perplexity: 7.91317892074585
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/25
 12%|â–ˆâ–Ž        | 25/200 [3:01:57<20:56:28, 430.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2033.8460337320964
INFO:root:current train perplexity5.052833080291748
INFO:root:current mean train loss 2037.445060483871
INFO:root:current train perplexity4.946567058563232
INFO:root:current mean train loss 2032.6518211364746
INFO:root:current train perplexity4.953011512756348
INFO:root:current mean train loss 2040.4158683117525
INFO:root:current train perplexity4.977472305297852
INFO:root:current mean train loss 2044.8389515426923
INFO:root:current train perplexity5.001519203186035
INFO:root:current mean train loss 2042.3353141027553
INFO:root:current train perplexity4.9975504875183105
INFO:root:current mean train loss 2042.4947466728015
INFO:root:current train perplexity5.00309944152832
INFO:root:current mean train loss 2045.0192326498295
INFO:root:current train perplexity5.013686180114746
INFO:root:current mean train loss 2045.0437528739856
INFO:root:current train perplexity5.015730857849121
INFO:root:current mean train loss 2046.9552765553133
INFO:root:current train perplexity5.0214996337890625
INFO:root:current mean train loss 2047.953997015953
INFO:root:current train perplexity5.030052661895752
INFO:root:current mean train loss 2048.612607799815
INFO:root:current train perplexity5.031071662902832
INFO:root:current mean train loss 2048.963942783331
INFO:root:current train perplexity5.0319342613220215
INFO:root:current mean train loss 2050.6165836945042
INFO:root:current train perplexity5.037552356719971
INFO:root:current mean train loss 2051.057784091221
INFO:root:current train perplexity5.038761615753174
INFO:root:current mean train loss 2050.81299004342
INFO:root:current train perplexity5.037998676300049
INFO:root:current mean train loss 2050.545053040453
INFO:root:current train perplexity5.039524555206299
INFO:root:current mean train loss 2050.792337156504
INFO:root:current train perplexity5.037690162658691
INFO:root:current mean train loss 2050.4756880643076
INFO:root:current train perplexity5.03515625
INFO:root:current mean train loss 2052.0823582512426
INFO:root:current train perplexity5.0403947830200195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:56<00:00, 356.01s/it]
INFO:root:final mean train loss: 2051.3958953842034
INFO:root:final train perplexity: 5.042259216308594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.04s/it]
INFO:root:eval mean loss: 2092.590622489334
INFO:root:eval perplexity: 5.432310104370117
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it]
INFO:root:eval mean loss: 2529.4907490615306
INFO:root:eval perplexity: 7.914424419403076
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/26
 13%|â–ˆâ–Ž        | 26/200 [3:09:35<21:13:04, 438.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2063.258407964939
INFO:root:current train perplexity5.034397125244141
INFO:root:current mean train loss 2052.743346735095
INFO:root:current train perplexity5.014149188995361
INFO:root:current mean train loss 2048.2703381297006
INFO:root:current train perplexity5.003427505493164
INFO:root:current mean train loss 2051.539294827369
INFO:root:current train perplexity5.004805564880371
INFO:root:current mean train loss 2054.3206986407845
INFO:root:current train perplexity5.005492687225342
INFO:root:current mean train loss 2047.4789055279575
INFO:root:current train perplexity5.004799842834473
INFO:root:current mean train loss 2045.1184108692473
INFO:root:current train perplexity4.996169567108154
INFO:root:current mean train loss 2043.4381345679403
INFO:root:current train perplexity4.993352890014648
INFO:root:current mean train loss 2043.0847677441755
INFO:root:current train perplexity4.992446422576904
INFO:root:current mean train loss 2042.2695907933298
INFO:root:current train perplexity4.991976737976074
INFO:root:current mean train loss 2043.5630245153773
INFO:root:current train perplexity4.997603893280029
INFO:root:current mean train loss 2043.341991588382
INFO:root:current train perplexity4.996399402618408
INFO:root:current mean train loss 2043.277513822176
INFO:root:current train perplexity5.000968933105469
INFO:root:current mean train loss 2042.7172671324454
INFO:root:current train perplexity5.001791954040527
INFO:root:current mean train loss 2043.8945873294913
INFO:root:current train perplexity5.00423526763916
INFO:root:current mean train loss 2043.6464167253914
INFO:root:current train perplexity5.003082275390625
INFO:root:current mean train loss 2042.4635688925864
INFO:root:current train perplexity5.001974105834961
INFO:root:current mean train loss 2043.1503125869426
INFO:root:current train perplexity5.0021233558654785
INFO:root:current mean train loss 2043.5739407930473
INFO:root:current train perplexity5.005074501037598
INFO:root:current mean train loss 2043.2825311408221
INFO:root:current train perplexity5.005331039428711

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.31s/it]
INFO:root:final mean train loss: 2041.8743629936491
INFO:root:final train perplexity: 5.004537105560303
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.35s/it]
INFO:root:eval mean loss: 2082.052682430186
INFO:root:eval perplexity: 5.386209011077881
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.67s/it]
INFO:root:eval mean loss: 2520.205133099928
INFO:root:eval perplexity: 7.854550838470459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/27
 14%|â–ˆâ–Ž        | 27/200 [3:16:50<21:02:43, 437.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2028.8816717739762
INFO:root:current train perplexity4.892769813537598
INFO:root:current mean train loss 2027.902507540546
INFO:root:current train perplexity4.900108337402344
INFO:root:current mean train loss 2036.647220582001
INFO:root:current train perplexity4.927013874053955
INFO:root:current mean train loss 2036.4806119609812
INFO:root:current train perplexity4.93435525894165
INFO:root:current mean train loss 2038.3740871379468
INFO:root:current train perplexity4.943026542663574
INFO:root:current mean train loss 2039.1529359441504
INFO:root:current train perplexity4.954399108886719
INFO:root:current mean train loss 2035.6034686891503
INFO:root:current train perplexity4.952378749847412
INFO:root:current mean train loss 2033.5546865337442
INFO:root:current train perplexity4.951769828796387
INFO:root:current mean train loss 2030.8790684413243
INFO:root:current train perplexity4.949643135070801
INFO:root:current mean train loss 2031.8453311800708
INFO:root:current train perplexity4.955733299255371
INFO:root:current mean train loss 2031.0679918949004
INFO:root:current train perplexity4.95738410949707
INFO:root:current mean train loss 2032.1627909869521
INFO:root:current train perplexity4.960620403289795
INFO:root:current mean train loss 2031.798583111058
INFO:root:current train perplexity4.964291095733643
INFO:root:current mean train loss 2032.2361295584901
INFO:root:current train perplexity4.967711925506592
INFO:root:current mean train loss 2031.7338461123704
INFO:root:current train perplexity4.966834545135498
INFO:root:current mean train loss 2032.1982262039674
INFO:root:current train perplexity4.967388153076172
INFO:root:current mean train loss 2032.8874596387543
INFO:root:current train perplexity4.968729496002197
INFO:root:current mean train loss 2032.2579674140313
INFO:root:current train perplexity4.966550827026367
INFO:root:current mean train loss 2033.0016698272673
INFO:root:current train perplexity4.9667582511901855
INFO:root:current mean train loss 2032.451993387006
INFO:root:current train perplexity4.965122699737549

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.68s/it]
INFO:root:final mean train loss: 2032.0498854213452
INFO:root:final train perplexity: 4.965910911560059
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.61s/it]
INFO:root:eval mean loss: 2082.4096164568095
INFO:root:eval perplexity: 5.3877644538879395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.66s/it]
INFO:root:eval mean loss: 2523.2586873372397
INFO:root:eval perplexity: 7.874189853668213
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/28
 14%|â–ˆâ–        | 28/200 [3:23:51<20:41:02, 432.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2025.0833333333333
INFO:root:current train perplexity4.955520153045654
INFO:root:current mean train loss 2019.4759284319196
INFO:root:current train perplexity4.935884475708008
INFO:root:current mean train loss 2014.242811168324
INFO:root:current train perplexity4.9074296951293945
INFO:root:current mean train loss 2021.1439680989583
INFO:root:current train perplexity4.9268670082092285
INFO:root:current mean train loss 2021.814990234375
INFO:root:current train perplexity4.935650825500488
INFO:root:current mean train loss 2017.6639357591712
INFO:root:current train perplexity4.9313788414001465
INFO:root:current mean train loss 2020.8037263093172
INFO:root:current train perplexity4.94114351272583
INFO:root:current mean train loss 2020.7160940650201
INFO:root:current train perplexity4.942800521850586
INFO:root:current mean train loss 2020.0075433872769
INFO:root:current train perplexity4.9307756423950195
INFO:root:current mean train loss 2022.1784162159456
INFO:root:current train perplexity4.934524059295654
INFO:root:current mean train loss 2023.6015052688954
INFO:root:current train perplexity4.937126159667969
INFO:root:current mean train loss 2022.588716235871
INFO:root:current train perplexity4.933583736419678
INFO:root:current mean train loss 2020.7228059895833
INFO:root:current train perplexity4.933125019073486
INFO:root:current mean train loss 2021.194966796875
INFO:root:current train perplexity4.930325984954834
INFO:root:current mean train loss 2023.1877411612818
INFO:root:current train perplexity4.933670520782471
INFO:root:current mean train loss 2022.712605406746
INFO:root:current train perplexity4.931142330169678
INFO:root:current mean train loss 2022.5672318097015
INFO:root:current train perplexity4.933819770812988
INFO:root:current mean train loss 2023.3204673057878
INFO:root:current train perplexity4.932007312774658
INFO:root:current mean train loss 2023.6917919270834
INFO:root:current train perplexity4.931424140930176
INFO:root:current mean train loss 2024.2258938637262
INFO:root:current train perplexity4.932933330535889

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.04s/it]
INFO:root:final mean train loss: 2023.8936722948283
INFO:root:final train perplexity: 4.934070587158203
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.55s/it]
INFO:root:eval mean loss: 2075.369997281555
INFO:root:eval perplexity: 5.357178211212158
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it]
INFO:root:eval mean loss: 2518.1998866737313
INFO:root:eval perplexity: 7.841681003570557
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/29
 14%|â–ˆâ–        | 29/200 [3:30:52<20:23:04, 429.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2016.8610800038214
INFO:root:current train perplexity4.842806816101074
INFO:root:current mean train loss 2018.2556139628093
INFO:root:current train perplexity4.872586250305176
INFO:root:current mean train loss 2018.739335151568
INFO:root:current train perplexity4.87556266784668
INFO:root:current mean train loss 2019.4537026541573
INFO:root:current train perplexity4.878679275512695
INFO:root:current mean train loss 2016.9604814731008
INFO:root:current train perplexity4.887519836425781
INFO:root:current mean train loss 2019.5009330543312
INFO:root:current train perplexity4.89436149597168
INFO:root:current mean train loss 2021.1255616645592
INFO:root:current train perplexity4.899078845977783
INFO:root:current mean train loss 2016.8932402639678
INFO:root:current train perplexity4.893530368804932
INFO:root:current mean train loss 2015.897537984121
INFO:root:current train perplexity4.896049499511719
INFO:root:current mean train loss 2016.306120349515
INFO:root:current train perplexity4.898301601409912
INFO:root:current mean train loss 2016.841539543627
INFO:root:current train perplexity4.901226043701172
INFO:root:current mean train loss 2016.2192142153747
INFO:root:current train perplexity4.89907169342041
INFO:root:current mean train loss 2017.403476490694
INFO:root:current train perplexity4.900450706481934
INFO:root:current mean train loss 2016.6775925734948
INFO:root:current train perplexity4.895609378814697
INFO:root:current mean train loss 2017.3836728011636
INFO:root:current train perplexity4.8970417976379395
INFO:root:current mean train loss 2016.766799696726
INFO:root:current train perplexity4.897189140319824
INFO:root:current mean train loss 2015.6392811443789
INFO:root:current train perplexity4.896446228027344
INFO:root:current mean train loss 2015.4114637374878
INFO:root:current train perplexity4.89900541305542
INFO:root:current mean train loss 2015.5077905634746
INFO:root:current train perplexity4.8997721672058105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.99s/it]
INFO:root:final mean train loss: 2014.415377079689
INFO:root:final train perplexity: 4.8973259925842285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.50s/it]
INFO:root:eval mean loss: 2077.3514884786405
INFO:root:eval perplexity: 5.365769863128662
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it]
INFO:root:eval mean loss: 2520.811553305768
INFO:root:eval perplexity: 7.858447074890137
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/30
 15%|â–ˆâ–Œ        | 30/200 [3:37:54<20:10:21, 427.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1917.9267171223958
INFO:root:current train perplexity4.731468677520752
INFO:root:current mean train loss 2003.2652307912845
INFO:root:current train perplexity4.829681873321533
INFO:root:current mean train loss 2004.8276431435033
INFO:root:current train perplexity4.84928035736084
INFO:root:current mean train loss 2013.066913098579
INFO:root:current train perplexity4.8583245277404785
INFO:root:current mean train loss 2005.0029147644789
INFO:root:current train perplexity4.8454976081848145
INFO:root:current mean train loss 2009.3073116519831
INFO:root:current train perplexity4.862971305847168
INFO:root:current mean train loss 2006.9382905505952
INFO:root:current train perplexity4.858145236968994
INFO:root:current mean train loss 2008.5404255897943
INFO:root:current train perplexity4.860851764678955
INFO:root:current mean train loss 2007.5662745227037
INFO:root:current train perplexity4.8644819259643555
INFO:root:current mean train loss 2008.5158402681088
INFO:root:current train perplexity4.865065097808838
INFO:root:current mean train loss 2009.0743475952754
INFO:root:current train perplexity4.866281032562256
INFO:root:current mean train loss 2010.0151045776038
INFO:root:current train perplexity4.868990898132324
INFO:root:current mean train loss 2009.7285876151843
INFO:root:current train perplexity4.870936870574951
INFO:root:current mean train loss 2008.0856923335741
INFO:root:current train perplexity4.8676629066467285
INFO:root:current mean train loss 2006.6247354998836
INFO:root:current train perplexity4.863237380981445
INFO:root:current mean train loss 2006.8715906869977
INFO:root:current train perplexity4.86435079574585
INFO:root:current mean train loss 2007.8102628282318
INFO:root:current train perplexity4.866754531860352
INFO:root:current mean train loss 2007.0254784813396
INFO:root:current train perplexity4.867060661315918
INFO:root:current mean train loss 2006.5630189843966
INFO:root:current train perplexity4.8651227951049805
INFO:root:current mean train loss 2005.93481976053
INFO:root:current train perplexity4.864030838012695

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.32s/it]
INFO:root:final mean train loss: 2006.1990404153075
INFO:root:final train perplexity: 4.86569356918335
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.48s/it]
INFO:root:eval mean loss: 2067.7591656624004
INFO:root:eval perplexity: 5.324304580688477
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.23s/it]
INFO:root:eval mean loss: 2514.2093492873173
INFO:root:eval perplexity: 7.816129684448242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/31
 16%|â–ˆâ–Œ        | 31/200 [3:44:46<19:49:45, 422.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1959.7416194035457
INFO:root:current train perplexity4.759357452392578
INFO:root:current mean train loss 1963.9664887927827
INFO:root:current train perplexity4.7660441398620605
INFO:root:current mean train loss 1971.74910985896
INFO:root:current train perplexity4.78299617767334
INFO:root:current mean train loss 1983.195048139139
INFO:root:current train perplexity4.80099630355835
INFO:root:current mean train loss 1986.2839822545297
INFO:root:current train perplexity4.810930252075195
INFO:root:current mean train loss 1987.2597280292002
INFO:root:current train perplexity4.811814308166504
INFO:root:current mean train loss 1988.711546486559
INFO:root:current train perplexity4.816246032714844
INFO:root:current mean train loss 1989.370085577006
INFO:root:current train perplexity4.8175554275512695
INFO:root:current mean train loss 1992.6868417661358
INFO:root:current train perplexity4.823730945587158
INFO:root:current mean train loss 1992.9535084800639
INFO:root:current train perplexity4.827931880950928
INFO:root:current mean train loss 1994.1478599860654
INFO:root:current train perplexity4.827534198760986
INFO:root:current mean train loss 1993.9270194072283
INFO:root:current train perplexity4.829079627990723
INFO:root:current mean train loss 1994.061508303171
INFO:root:current train perplexity4.831672668457031
INFO:root:current mean train loss 1996.4483253168305
INFO:root:current train perplexity4.834041118621826
INFO:root:current mean train loss 1997.8307982199992
INFO:root:current train perplexity4.8325629234313965
INFO:root:current mean train loss 1997.3876210783912
INFO:root:current train perplexity4.8314127922058105
INFO:root:current mean train loss 1998.0186968776427
INFO:root:current train perplexity4.831864833831787
INFO:root:current mean train loss 1998.0703989959397
INFO:root:current train perplexity4.834220886230469
INFO:root:current mean train loss 1999.1271166430638
INFO:root:current train perplexity4.834692001342773
INFO:root:current mean train loss 1999.035670517142
INFO:root:current train perplexity4.835954666137695

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.51s/it]
INFO:root:final mean train loss: 1998.4418415294654
INFO:root:final train perplexity: 4.836017608642578
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.90s/it]
INFO:root:eval mean loss: 2070.5962740850787
INFO:root:eval perplexity: 5.336535453796387
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.06s/it]
INFO:root:eval mean loss: 2517.468650439107
INFO:root:eval perplexity: 7.836991786956787
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/32
 16%|â–ˆâ–Œ        | 32/200 [3:51:37<19:33:50, 419.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1946.462271756904
INFO:root:current train perplexity4.689494609832764
INFO:root:current mean train loss 1966.723007949082
INFO:root:current train perplexity4.727837085723877
INFO:root:current mean train loss 1978.7464609656315
INFO:root:current train perplexity4.775015830993652
INFO:root:current mean train loss 1978.608837961803
INFO:root:current train perplexity4.783233642578125
INFO:root:current mean train loss 1978.0406350852672
INFO:root:current train perplexity4.7717719078063965
INFO:root:current mean train loss 1982.8585596242663
INFO:root:current train perplexity4.782645225524902
INFO:root:current mean train loss 1982.4256109590665
INFO:root:current train perplexity4.781752109527588
INFO:root:current mean train loss 1981.0492025506287
INFO:root:current train perplexity4.77993631362915
INFO:root:current mean train loss 1979.8987741707906
INFO:root:current train perplexity4.778829574584961
INFO:root:current mean train loss 1983.0894220054845
INFO:root:current train perplexity4.782476425170898
INFO:root:current mean train loss 1986.5055262857293
INFO:root:current train perplexity4.789226055145264
INFO:root:current mean train loss 1986.7910903837217
INFO:root:current train perplexity4.788644790649414
INFO:root:current mean train loss 1987.492729500044
INFO:root:current train perplexity4.791316032409668
INFO:root:current mean train loss 1988.4166548807764
INFO:root:current train perplexity4.794312953948975
INFO:root:current mean train loss 1989.9686395191766
INFO:root:current train perplexity4.797461986541748
INFO:root:current mean train loss 1990.3412205417358
INFO:root:current train perplexity4.79942512512207
INFO:root:current mean train loss 1990.2417093231702
INFO:root:current train perplexity4.801941394805908
INFO:root:current mean train loss 1991.58885486141
INFO:root:current train perplexity4.806795597076416
INFO:root:current mean train loss 1991.7546199274916
INFO:root:current train perplexity4.808393478393555
INFO:root:current mean train loss 1992.1003878481047
INFO:root:current train perplexity4.808979034423828

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.29s/it]
INFO:root:final mean train loss: 1991.362096620099
INFO:root:final train perplexity: 4.809090614318848
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.94s/it]
INFO:root:eval mean loss: 2063.702222891733
INFO:root:eval perplexity: 5.306864261627197
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.29s/it]
INFO:root:eval mean loss: 2510.798166261497
INFO:root:eval perplexity: 7.794355392456055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/33
 16%|â–ˆâ–‹        | 33/200 [3:58:28<19:19:47, 416.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1977.6810607910156
INFO:root:current train perplexity4.727597236633301
INFO:root:current mean train loss 1985.1867362976075
INFO:root:current train perplexity4.742546558380127
INFO:root:current mean train loss 1991.2993596003605
INFO:root:current train perplexity4.753085613250732
INFO:root:current mean train loss 1986.3069332546659
INFO:root:current train perplexity4.756789684295654
INFO:root:current mean train loss 1985.1262644892154
INFO:root:current train perplexity4.758716583251953
INFO:root:current mean train loss 1983.406180027553
INFO:root:current train perplexity4.754694938659668
INFO:root:current mean train loss 1981.6944208318537
INFO:root:current train perplexity4.757681369781494
INFO:root:current mean train loss 1981.71161836323
INFO:root:current train perplexity4.75806999206543
INFO:root:current mean train loss 1983.651309417015
INFO:root:current train perplexity4.766850471496582
INFO:root:current mean train loss 1982.9295101165771
INFO:root:current train perplexity4.770181655883789
INFO:root:current mean train loss 1983.6928999990787
INFO:root:current train perplexity4.77351713180542
INFO:root:current mean train loss 1983.8570177801723
INFO:root:current train perplexity4.769465446472168
INFO:root:current mean train loss 1984.5781253875248
INFO:root:current train perplexity4.772550106048584
INFO:root:current mean train loss 1985.0911734188305
INFO:root:current train perplexity4.775735855102539
INFO:root:current mean train loss 1986.810469535932
INFO:root:current train perplexity4.780040740966797
INFO:root:current mean train loss 1986.2124151767828
INFO:root:current train perplexity4.779803276062012
INFO:root:current mean train loss 1985.9001325124718
INFO:root:current train perplexity4.780477046966553
INFO:root:current mean train loss 1984.9687538840553
INFO:root:current train perplexity4.779148101806641
INFO:root:current mean train loss 1984.2626630885627
INFO:root:current train perplexity4.778229713439941
INFO:root:current mean train loss 1983.8475758455238
INFO:root:current train perplexity4.779041767120361

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.65s/it]
INFO:root:final mean train loss: 1983.608129704293
INFO:root:final train perplexity: 4.77977180480957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.14s/it]
INFO:root:eval mean loss: 2062.7660106902426
INFO:root:eval perplexity: 5.302847862243652
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.70s/it]
INFO:root:eval mean loss: 2511.281941731771
INFO:root:eval perplexity: 7.797441005706787
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/34
 17%|â–ˆâ–‹        | 34/200 [4:05:17<19:06:11, 414.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1971.0714174741274
INFO:root:current train perplexity4.758902549743652
INFO:root:current mean train loss 1979.9098245222017
INFO:root:current train perplexity4.758247375488281
INFO:root:current mean train loss 1979.0533742525947
INFO:root:current train perplexity4.766925811767578
INFO:root:current mean train loss 1972.770287632626
INFO:root:current train perplexity4.752148628234863
INFO:root:current mean train loss 1975.1771467996593
INFO:root:current train perplexity4.76105260848999
INFO:root:current mean train loss 1973.732412989466
INFO:root:current train perplexity4.756036281585693
INFO:root:current mean train loss 1974.71382030673
INFO:root:current train perplexity4.7554121017456055
INFO:root:current mean train loss 1973.8937292307653
INFO:root:current train perplexity4.751366138458252
INFO:root:current mean train loss 1977.311591223409
INFO:root:current train perplexity4.759809970855713
INFO:root:current mean train loss 1977.2818673484278
INFO:root:current train perplexity4.753140449523926
INFO:root:current mean train loss 1975.8372861672688
INFO:root:current train perplexity4.748114585876465
INFO:root:current mean train loss 1973.8165593305278
INFO:root:current train perplexity4.745148181915283
INFO:root:current mean train loss 1974.6429643145557
INFO:root:current train perplexity4.747034072875977
INFO:root:current mean train loss 1975.3455214822475
INFO:root:current train perplexity4.7465667724609375
INFO:root:current mean train loss 1974.898977353271
INFO:root:current train perplexity4.7435808181762695
INFO:root:current mean train loss 1975.4330900648235
INFO:root:current train perplexity4.746176242828369
INFO:root:current mean train loss 1975.5874192312351
INFO:root:current train perplexity4.746666431427002
INFO:root:current mean train loss 1975.4268524736653
INFO:root:current train perplexity4.747732639312744
INFO:root:current mean train loss 1975.8246968858218
INFO:root:current train perplexity4.749879360198975
INFO:root:current mean train loss 1976.512304403472
INFO:root:current train perplexity4.751101016998291

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.17s/it]
INFO:root:final mean train loss: 1975.8046777429931
INFO:root:final train perplexity: 4.75044584274292
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.01s/it]
INFO:root:eval mean loss: 2062.37809288079
INFO:root:eval perplexity: 5.301185131072998
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.89s/it]
INFO:root:eval mean loss: 2512.2327201248063
INFO:root:eval perplexity: 7.8035054206848145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/35
 18%|â–ˆâ–Š        | 35/200 [4:12:06<18:55:09, 412.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1957.9660112096908
INFO:root:current train perplexity4.6877546310424805
INFO:root:current mean train loss 1960.5200251943058
INFO:root:current train perplexity4.694316864013672
INFO:root:current mean train loss 1962.8003236939307
INFO:root:current train perplexity4.696205139160156
INFO:root:current mean train loss 1966.4560804028197
INFO:root:current train perplexity4.700112342834473
INFO:root:current mean train loss 1968.51103599641
INFO:root:current train perplexity4.698190689086914
INFO:root:current mean train loss 1970.690155954072
INFO:root:current train perplexity4.701326370239258
INFO:root:current mean train loss 1969.7589711126059
INFO:root:current train perplexity4.70465612411499
INFO:root:current mean train loss 1968.4837445083733
INFO:root:current train perplexity4.70572566986084
INFO:root:current mean train loss 1968.0657803324245
INFO:root:current train perplexity4.710071563720703
INFO:root:current mean train loss 1970.5034285301654
INFO:root:current train perplexity4.714725494384766
INFO:root:current mean train loss 1970.4959879706066
INFO:root:current train perplexity4.718432426452637
INFO:root:current mean train loss 1970.8785940199043
INFO:root:current train perplexity4.717598915100098
INFO:root:current mean train loss 1971.5817339984121
INFO:root:current train perplexity4.720991134643555
INFO:root:current mean train loss 1970.723262048007
INFO:root:current train perplexity4.721993923187256
INFO:root:current mean train loss 1968.7136740320657
INFO:root:current train perplexity4.722742080688477
INFO:root:current mean train loss 1968.5337273227974
INFO:root:current train perplexity4.7228569984436035
INFO:root:current mean train loss 1968.4497326847513
INFO:root:current train perplexity4.720448017120361
INFO:root:current mean train loss 1968.7425854873231
INFO:root:current train perplexity4.72041130065918
INFO:root:current mean train loss 1968.710141271573
INFO:root:current train perplexity4.721993446350098

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.59s/it]
INFO:root:final mean train loss: 1969.4181388050874
INFO:root:final train perplexity: 4.726579189300537
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.58s/it]
INFO:root:eval mean loss: 2063.8172113946143
INFO:root:eval perplexity: 5.307356834411621
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.91s/it]
INFO:root:eval mean loss: 2517.400295392841
INFO:root:eval perplexity: 7.836556434631348
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/36
 18%|â–ˆâ–Š        | 36/200 [4:19:05<18:53:38, 414.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1950.8286798650568
INFO:root:current train perplexity4.700207710266113
INFO:root:current mean train loss 1954.1808532164978
INFO:root:current train perplexity4.69885778427124
INFO:root:current mean train loss 1956.2689880081828
INFO:root:current train perplexity4.686638832092285
INFO:root:current mean train loss 1958.1872535043208
INFO:root:current train perplexity4.687279224395752
INFO:root:current mean train loss 1967.6512864013077
INFO:root:current train perplexity4.694950103759766
INFO:root:current mean train loss 1966.0268891515564
INFO:root:current train perplexity4.692088603973389
INFO:root:current mean train loss 1964.506169445581
INFO:root:current train perplexity4.694141387939453
INFO:root:current mean train loss 1962.3131467494616
INFO:root:current train perplexity4.694929599761963
INFO:root:current mean train loss 1961.7418103012292
INFO:root:current train perplexity4.694563388824463
INFO:root:current mean train loss 1960.1894558049191
INFO:root:current train perplexity4.69746208190918
INFO:root:current mean train loss 1960.1705831797494
INFO:root:current train perplexity4.694876194000244
INFO:root:current mean train loss 1959.6091822805327
INFO:root:current train perplexity4.696583271026611
INFO:root:current mean train loss 1962.226536190874
INFO:root:current train perplexity4.700351715087891
INFO:root:current mean train loss 1961.7164768477962
INFO:root:current train perplexity4.69701623916626
INFO:root:current mean train loss 1962.4855843698783
INFO:root:current train perplexity4.698297023773193
INFO:root:current mean train loss 1962.1525076683747
INFO:root:current train perplexity4.697866916656494
INFO:root:current mean train loss 1961.808620649417
INFO:root:current train perplexity4.697432994842529
INFO:root:current mean train loss 1962.150277686774
INFO:root:current train perplexity4.6965436935424805
INFO:root:current mean train loss 1961.723868460105
INFO:root:current train perplexity4.694610595703125
INFO:root:current mean train loss 1961.9508420104821
INFO:root:current train perplexity4.695937156677246

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.18s/it]
INFO:root:final mean train loss: 1961.7822381970382
INFO:root:final train perplexity: 4.698200702667236
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.51s/it]
INFO:root:eval mean loss: 2059.296582810422
INFO:root:eval perplexity: 5.287989616394043
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.33s/it]
INFO:root:eval mean loss: 2512.9548673156305
INFO:root:eval perplexity: 7.8081135749816895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/37
 18%|â–ˆâ–Š        | 37/200 [4:26:03<18:48:45, 415.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1972.8898271833148
INFO:root:current train perplexity4.6846604347229
INFO:root:current mean train loss 1946.3774862289429
INFO:root:current train perplexity4.643073081970215
INFO:root:current mean train loss 1955.30843420196
INFO:root:current train perplexity4.670236587524414
INFO:root:current mean train loss 1952.5018533846228
INFO:root:current train perplexity4.660595893859863
INFO:root:current mean train loss 1958.3610503294758
INFO:root:current train perplexity4.673687934875488
INFO:root:current mean train loss 1956.6177437522194
INFO:root:current train perplexity4.667123317718506
INFO:root:current mean train loss 1958.6235598424437
INFO:root:current train perplexity4.676328182220459
INFO:root:current mean train loss 1957.4046022184602
INFO:root:current train perplexity4.677483081817627
INFO:root:current mean train loss 1958.1273976201596
INFO:root:current train perplexity4.677811622619629
INFO:root:current mean train loss 1958.1409521431758
INFO:root:current train perplexity4.676825046539307
INFO:root:current mean train loss 1958.2704858445936
INFO:root:current train perplexity4.675876617431641
INFO:root:current mean train loss 1958.0690225371231
INFO:root:current train perplexity4.675059795379639
INFO:root:current mean train loss 1960.5057927731193
INFO:root:current train perplexity4.680238246917725
INFO:root:current mean train loss 1960.2327606936535
INFO:root:current train perplexity4.680934429168701
INFO:root:current mean train loss 1960.0587624942555
INFO:root:current train perplexity4.679996490478516
INFO:root:current mean train loss 1958.9755462326927
INFO:root:current train perplexity4.676506042480469
INFO:root:current mean train loss 1957.6516216756086
INFO:root:current train perplexity4.674915790557861
INFO:root:current mean train loss 1957.3829419877793
INFO:root:current train perplexity4.675221920013428
INFO:root:current mean train loss 1956.3732545547987
INFO:root:current train perplexity4.674663066864014
INFO:root:current mean train loss 1955.682706967429
INFO:root:current train perplexity4.675549507141113

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.78s/it]
INFO:root:final mean train loss: 1955.123300926528
INFO:root:final train perplexity: 4.673591613769531
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.49s/it]
INFO:root:eval mean loss: 2061.6233446919327
INFO:root:eval perplexity: 5.297948837280273
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.18s/it]
INFO:root:eval mean loss: 2519.5989379882812
INFO:root:eval perplexity: 7.850656509399414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/38
 19%|â–ˆâ–‰        | 38/200 [4:33:06<18:48:28, 417.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1917.2902262369792
INFO:root:current train perplexity4.600573539733887
INFO:root:current mean train loss 1930.262458748653
INFO:root:current train perplexity4.616376876831055
INFO:root:current mean train loss 1931.5523297991072
INFO:root:current train perplexity4.603084564208984
INFO:root:current mean train loss 1933.4655874943387
INFO:root:current train perplexity4.608372688293457
INFO:root:current mean train loss 1933.4004139418012
INFO:root:current train perplexity4.617974281311035
INFO:root:current mean train loss 1935.7530394387902
INFO:root:current train perplexity4.6167120933532715
INFO:root:current mean train loss 1936.1231244700823
INFO:root:current train perplexity4.616322994232178
INFO:root:current mean train loss 1939.9754017669882
INFO:root:current train perplexity4.621601581573486
INFO:root:current mean train loss 1941.5750599516919
INFO:root:current train perplexity4.622429847717285
INFO:root:current mean train loss 1942.7319541325644
INFO:root:current train perplexity4.629027366638184
INFO:root:current mean train loss 1943.0194569564892
INFO:root:current train perplexity4.630545616149902
INFO:root:current mean train loss 1945.6501005347639
INFO:root:current train perplexity4.6356611251831055
INFO:root:current mean train loss 1947.4601690943462
INFO:root:current train perplexity4.645629405975342
INFO:root:current mean train loss 1947.1033840250348
INFO:root:current train perplexity4.647716045379639
INFO:root:current mean train loss 1947.7566727265355
INFO:root:current train perplexity4.6494975090026855
INFO:root:current mean train loss 1949.0065258235993
INFO:root:current train perplexity4.651223659515381
INFO:root:current mean train loss 1949.0229624275742
INFO:root:current train perplexity4.652329921722412
INFO:root:current mean train loss 1950.643825830498
INFO:root:current train perplexity4.652818202972412
INFO:root:current mean train loss 1949.6858481140964
INFO:root:current train perplexity4.650415897369385
INFO:root:current mean train loss 1949.5350827567681
INFO:root:current train perplexity4.65172004699707

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.06s/it]
INFO:root:final mean train loss: 1948.9799374086474
INFO:root:final train perplexity: 4.651002407073975
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.11s/it]
INFO:root:eval mean loss: 2058.164010555186
INFO:root:eval perplexity: 5.283149242401123
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.32s/it]
INFO:root:eval mean loss: 2516.1533787504154
INFO:root:eval perplexity: 7.82856559753418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/39
 20%|â–ˆâ–‰        | 39/200 [4:40:05<18:42:08, 418.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1931.7271078786541
INFO:root:current train perplexity4.611521244049072
INFO:root:current mean train loss 1936.8791210033276
INFO:root:current train perplexity4.613026142120361
INFO:root:current mean train loss 1940.4992992604962
INFO:root:current train perplexity4.626650333404541
INFO:root:current mean train loss 1938.6134818904309
INFO:root:current train perplexity4.619725704193115
INFO:root:current mean train loss 1945.4627883712967
INFO:root:current train perplexity4.618867874145508
INFO:root:current mean train loss 1943.2224490345584
INFO:root:current train perplexity4.608981609344482
INFO:root:current mean train loss 1945.870762943141
INFO:root:current train perplexity4.612359523773193
INFO:root:current mean train loss 1944.830364717899
INFO:root:current train perplexity4.61378812789917
INFO:root:current mean train loss 1945.0787480967228
INFO:root:current train perplexity4.614052772521973
INFO:root:current mean train loss 1946.0842198869543
INFO:root:current train perplexity4.615039825439453
INFO:root:current mean train loss 1944.2717170212452
INFO:root:current train perplexity4.6164774894714355
INFO:root:current mean train loss 1944.8111433597112
INFO:root:current train perplexity4.619691371917725
INFO:root:current mean train loss 1945.5452543279825
INFO:root:current train perplexity4.622315883636475
INFO:root:current mean train loss 1944.9200250342728
INFO:root:current train perplexity4.61992073059082
INFO:root:current mean train loss 1944.1884711352973
INFO:root:current train perplexity4.620529651641846
INFO:root:current mean train loss 1944.4354609881411
INFO:root:current train perplexity4.62307071685791
INFO:root:current mean train loss 1944.2194531161863
INFO:root:current train perplexity4.624816417694092
INFO:root:current mean train loss 1943.0266577453267
INFO:root:current train perplexity4.6238017082214355
INFO:root:current mean train loss 1942.5448177677733
INFO:root:current train perplexity4.625955104827881
INFO:root:current mean train loss 1943.1207607630924
INFO:root:current train perplexity4.627783298492432

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.13s/it]
INFO:root:final mean train loss: 1942.43798326424
INFO:root:final train perplexity: 4.627068042755127
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.65s/it]
INFO:root:eval mean loss: 2055.476358616606
INFO:root:eval perplexity: 5.271677017211914
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it]
INFO:root:eval mean loss: 2513.268710954815
INFO:root:eval perplexity: 7.810118675231934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/40
 20%|â–ˆâ–ˆ        | 40/200 [4:47:02<18:34:05, 417.79s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1935.3339859201938
INFO:root:current train perplexity4.591068744659424
INFO:root:current mean train loss 1931.0821546842267
INFO:root:current train perplexity4.560929775238037
INFO:root:current mean train loss 1935.9389355293738
INFO:root:current train perplexity4.572042465209961
INFO:root:current mean train loss 1934.4346385945746
INFO:root:current train perplexity4.580846309661865
INFO:root:current mean train loss 1931.8544243989757
INFO:root:current train perplexity4.575862407684326
INFO:root:current mean train loss 1931.887710913887
INFO:root:current train perplexity4.578682899475098
INFO:root:current mean train loss 1932.1486564714885
INFO:root:current train perplexity4.580820083618164
INFO:root:current mean train loss 1933.0249371314385
INFO:root:current train perplexity4.583243370056152
INFO:root:current mean train loss 1935.4391521848781
INFO:root:current train perplexity4.587523460388184
INFO:root:current mean train loss 1936.569534940788
INFO:root:current train perplexity4.588852405548096
INFO:root:current mean train loss 1936.2189284104568
INFO:root:current train perplexity4.592261791229248
INFO:root:current mean train loss 1938.1081254100072
INFO:root:current train perplexity4.597277641296387
INFO:root:current mean train loss 1937.716221168882
INFO:root:current train perplexity4.598921298980713
INFO:root:current mean train loss 1939.4212913817473
INFO:root:current train perplexity4.603780269622803
INFO:root:current mean train loss 1937.7949761009604
INFO:root:current train perplexity4.602627277374268
INFO:root:current mean train loss 1937.5149882088892
INFO:root:current train perplexity4.603001594543457
INFO:root:current mean train loss 1937.73065814438
INFO:root:current train perplexity4.603384971618652
INFO:root:current mean train loss 1936.5351707968837
INFO:root:current train perplexity4.601293087005615
INFO:root:current mean train loss 1936.4653876417808
INFO:root:current train perplexity4.602807521820068
INFO:root:current mean train loss 1936.7420706727278
INFO:root:current train perplexity4.604743003845215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.77s/it]
INFO:root:final mean train loss: 1936.35862851203
INFO:root:final train perplexity: 4.6049370765686035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.11s/it]
INFO:root:eval mean loss: 2052.2667206026986
INFO:root:eval perplexity: 5.258011817932129
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.76s/it]
INFO:root:eval mean loss: 2511.2010065173426
INFO:root:eval perplexity: 7.796922206878662
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/41
 20%|â–ˆâ–ˆ        | 41/200 [4:53:49<18:18:26, 414.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1905.5083859761555
INFO:root:current train perplexity4.502112865447998
INFO:root:current mean train loss 1912.009008913624
INFO:root:current train perplexity4.530322551727295
INFO:root:current mean train loss 1913.5239938272011
INFO:root:current train perplexity4.519135475158691
INFO:root:current mean train loss 1917.9424792973682
INFO:root:current train perplexity4.537313461303711
INFO:root:current mean train loss 1920.9309330601845
INFO:root:current train perplexity4.538086891174316
INFO:root:current mean train loss 1921.0221578098783
INFO:root:current train perplexity4.545420169830322
INFO:root:current mean train loss 1923.8318719973508
INFO:root:current train perplexity4.5501604080200195
INFO:root:current mean train loss 1920.5816685662198
INFO:root:current train perplexity4.550710201263428
INFO:root:current mean train loss 1921.2595934186663
INFO:root:current train perplexity4.550595760345459
INFO:root:current mean train loss 1924.7619576205211
INFO:root:current train perplexity4.557423114776611
INFO:root:current mean train loss 1925.216428102368
INFO:root:current train perplexity4.558561325073242
INFO:root:current mean train loss 1926.181094982951
INFO:root:current train perplexity4.561972618103027
INFO:root:current mean train loss 1926.6375864287954
INFO:root:current train perplexity4.563529968261719
INFO:root:current mean train loss 1926.652491703416
INFO:root:current train perplexity4.566143989562988
INFO:root:current mean train loss 1927.961548912334
INFO:root:current train perplexity4.570149898529053
INFO:root:current mean train loss 1928.6163998558409
INFO:root:current train perplexity4.574375152587891
INFO:root:current mean train loss 1929.5678546113788
INFO:root:current train perplexity4.576421737670898
INFO:root:current mean train loss 1930.1129229233366
INFO:root:current train perplexity4.579692840576172
INFO:root:current mean train loss 1930.6894846727073
INFO:root:current train perplexity4.581855297088623

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.52s/it]
INFO:root:final mean train loss: 1930.120312696987
INFO:root:final train perplexity: 4.582335948944092
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.52s/it]
INFO:root:eval mean loss: 2053.262002282109
INFO:root:eval perplexity: 5.262245178222656
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.98s/it]
INFO:root:eval mean loss: 2514.605095180214
INFO:root:eval perplexity: 7.81865930557251
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/42
 21%|â–ˆâ–ˆ        | 42/200 [5:00:40<18:08:56, 413.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1861.174532376803
INFO:root:current train perplexity4.391417503356934
INFO:root:current mean train loss 1900.3232983614491
INFO:root:current train perplexity4.516597270965576
INFO:root:current mean train loss 1901.2096652178698
INFO:root:current train perplexity4.504830837249756
INFO:root:current mean train loss 1909.4868437063199
INFO:root:current train perplexity4.512270450592041
INFO:root:current mean train loss 1910.595431496387
INFO:root:current train perplexity4.523565292358398
INFO:root:current mean train loss 1913.495051750198
INFO:root:current train perplexity4.527397632598877
INFO:root:current mean train loss 1914.7233522300035
INFO:root:current train perplexity4.529833793640137
INFO:root:current mean train loss 1915.2249351811777
INFO:root:current train perplexity4.528176784515381
INFO:root:current mean train loss 1915.6828880544665
INFO:root:current train perplexity4.531594276428223
INFO:root:current mean train loss 1915.2042245687294
INFO:root:current train perplexity4.530429840087891
INFO:root:current mean train loss 1916.7366556542295
INFO:root:current train perplexity4.534762382507324
INFO:root:current mean train loss 1919.939446105683
INFO:root:current train perplexity4.536087989807129
INFO:root:current mean train loss 1920.2365110795163
INFO:root:current train perplexity4.541286945343018
INFO:root:current mean train loss 1921.0176447848737
INFO:root:current train perplexity4.5440216064453125
INFO:root:current mean train loss 1920.6556078565939
INFO:root:current train perplexity4.545528411865234
INFO:root:current mean train loss 1921.3066812075294
INFO:root:current train perplexity4.54797887802124
INFO:root:current mean train loss 1922.2496048039852
INFO:root:current train perplexity4.550146579742432
INFO:root:current mean train loss 1923.036727344092
INFO:root:current train perplexity4.553045272827148
INFO:root:current mean train loss 1923.4667666435769
INFO:root:current train perplexity4.555344104766846
INFO:root:current mean train loss 1924.776373696215
INFO:root:current train perplexity4.560125350952148

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.11s/it]
INFO:root:final mean train loss: 1924.1172742357894
INFO:root:final train perplexity: 4.560693264007568
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.82s/it]
INFO:root:eval mean loss: 2057.6500192195813
INFO:root:eval perplexity: 5.280951976776123
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.90s/it]
INFO:root:eval mean loss: 2520.549622014905
INFO:root:eval perplexity: 7.856764793395996
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/43
 22%|â–ˆâ–ˆâ–       | 43/200 [5:07:36<18:04:04, 414.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1925.0297688802084
INFO:root:current train perplexity4.497045040130615
INFO:root:current mean train loss 1914.9235107421875
INFO:root:current train perplexity4.497797966003418
INFO:root:current mean train loss 1911.0952488111413
INFO:root:current train perplexity4.501649379730225
INFO:root:current mean train loss 1909.116356312145
INFO:root:current train perplexity4.50192403793335
INFO:root:current mean train loss 1908.611701716933
INFO:root:current train perplexity4.506300926208496
INFO:root:current mean train loss 1911.1921322228773
INFO:root:current train perplexity4.514093399047852
INFO:root:current mean train loss 1913.6442380874876
INFO:root:current train perplexity4.512322902679443
INFO:root:current mean train loss 1914.847631668718
INFO:root:current train perplexity4.517045497894287
INFO:root:current mean train loss 1915.5342674898814
INFO:root:current train perplexity4.516917705535889
INFO:root:current mean train loss 1917.6150537634408
INFO:root:current train perplexity4.522260665893555
INFO:root:current mean train loss 1918.6202439984072
INFO:root:current train perplexity4.52630090713501
INFO:root:current mean train loss 1918.881040535986
INFO:root:current train perplexity4.527592182159424
INFO:root:current mean train loss 1919.5591239122841
INFO:root:current train perplexity4.526514053344727
INFO:root:current mean train loss 1919.7272819805862
INFO:root:current train perplexity4.526983737945557
INFO:root:current mean train loss 1919.4876073877294
INFO:root:current train perplexity4.529714107513428
INFO:root:current mean train loss 1919.0625808217167
INFO:root:current train perplexity4.532083988189697
INFO:root:current mean train loss 1918.6997202867378
INFO:root:current train perplexity4.531740665435791
INFO:root:current mean train loss 1919.6279036505373
INFO:root:current train perplexity4.535042762756348
INFO:root:current mean train loss 1919.2076610127433
INFO:root:current train perplexity4.5378570556640625
INFO:root:current mean train loss 1918.8487350859173
INFO:root:current train perplexity4.538093566894531

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.24s/it]
INFO:root:final mean train loss: 1918.1042215152033
INFO:root:final train perplexity: 4.539116382598877
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.99s/it]
INFO:root:eval mean loss: 2054.473125051945
INFO:root:eval perplexity: 5.267402172088623
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.29s/it]
INFO:root:eval mean loss: 2517.303490172041
INFO:root:eval perplexity: 7.83593225479126
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/44
 22%|â–ˆâ–ˆâ–       | 44/200 [5:14:40<18:04:32, 417.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1916.5543836228392
INFO:root:current train perplexity4.497881889343262
INFO:root:current mean train loss 1904.3708031063989
INFO:root:current train perplexity4.477994441986084
INFO:root:current mean train loss 1911.536744152486
INFO:root:current train perplexity4.493243217468262
INFO:root:current mean train loss 1909.0367533659041
INFO:root:current train perplexity4.49076509475708
INFO:root:current mean train loss 1907.3345884455398
INFO:root:current train perplexity4.493466854095459
INFO:root:current mean train loss 1906.5144391103463
INFO:root:current train perplexity4.4929704666137695
INFO:root:current mean train loss 1905.074892683781
INFO:root:current train perplexity4.4941840171813965
INFO:root:current mean train loss 1904.7300002418528
INFO:root:current train perplexity4.493229389190674
INFO:root:current mean train loss 1903.0391117893116
INFO:root:current train perplexity4.492886066436768
INFO:root:current mean train loss 1906.0991011139206
INFO:root:current train perplexity4.500669002532959
INFO:root:current mean train loss 1909.618345943768
INFO:root:current train perplexity4.504981994628906
INFO:root:current mean train loss 1910.1800490282053
INFO:root:current train perplexity4.506577968597412
INFO:root:current mean train loss 1909.916400239481
INFO:root:current train perplexity4.505251407623291
INFO:root:current mean train loss 1910.6757679282955
INFO:root:current train perplexity4.508103370666504
INFO:root:current mean train loss 1911.935517348663
INFO:root:current train perplexity4.512478828430176
INFO:root:current mean train loss 1912.1932853595165
INFO:root:current train perplexity4.513556003570557
INFO:root:current mean train loss 1911.1816496672454
INFO:root:current train perplexity4.512588024139404
INFO:root:current mean train loss 1912.706816596308
INFO:root:current train perplexity4.516251564025879
INFO:root:current mean train loss 1912.2686643326806
INFO:root:current train perplexity4.515420913696289
INFO:root:current mean train loss 1912.9385555602369
INFO:root:current train perplexity4.518405914306641

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.31s/it]
INFO:root:final mean train loss: 1912.3782014370686
INFO:root:final train perplexity: 4.5186638832092285
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.96s/it]
INFO:root:eval mean loss: 2049.4695651007037
INFO:root:eval perplexity: 5.246129035949707
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it]
INFO:root:eval mean loss: 2513.91207301363
INFO:root:eval perplexity: 7.8142313957214355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [5:21:36<17:56:35, 416.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1894.1488361358643
INFO:root:current train perplexity4.456403732299805
INFO:root:current mean train loss 1883.2582159274962
INFO:root:current train perplexity4.4429030418396
INFO:root:current mean train loss 1887.9851800167198
INFO:root:current train perplexity4.460391521453857
INFO:root:current mean train loss 1892.481657594115
INFO:root:current train perplexity4.471400260925293
INFO:root:current mean train loss 1894.2029563640726
INFO:root:current train perplexity4.475550174713135
INFO:root:current mean train loss 1895.8079286399463
INFO:root:current train perplexity4.472167015075684
INFO:root:current mean train loss 1901.5803476356598
INFO:root:current train perplexity4.4847283363342285
INFO:root:current mean train loss 1901.209363368169
INFO:root:current train perplexity4.486598968505859
INFO:root:current mean train loss 1903.8208875302914
INFO:root:current train perplexity4.487593650817871
INFO:root:current mean train loss 1903.5089612778786
INFO:root:current train perplexity4.483898162841797
INFO:root:current mean train loss 1906.024096037212
INFO:root:current train perplexity4.490837574005127
INFO:root:current mean train loss 1906.0404254087468
INFO:root:current train perplexity4.490916728973389
INFO:root:current mean train loss 1905.4534283408636
INFO:root:current train perplexity4.492109775543213
INFO:root:current mean train loss 1905.4769364074527
INFO:root:current train perplexity4.49216890335083
INFO:root:current mean train loss 1904.4754594479753
INFO:root:current train perplexity4.492624282836914
INFO:root:current mean train loss 1904.9375416006883
INFO:root:current train perplexity4.492873668670654
INFO:root:current mean train loss 1905.4362650651199
INFO:root:current train perplexity4.493281364440918
INFO:root:current mean train loss 1905.5903589503835
INFO:root:current train perplexity4.4933977127075195
INFO:root:current mean train loss 1905.7198634986714
INFO:root:current train perplexity4.49390172958374
INFO:root:current mean train loss 1906.9265449974541
INFO:root:current train perplexity4.4973602294921875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.25s/it]
INFO:root:final mean train loss: 1906.3480042396502
INFO:root:final train perplexity: 4.497226238250732
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.90s/it]
INFO:root:eval mean loss: 2053.707851545185
INFO:root:eval perplexity: 5.264142990112305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.59s/it]
INFO:root:eval mean loss: 2519.631910391733
INFO:root:eval perplexity: 7.850870132446289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [5:28:26<17:44:25, 414.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1900.6067527488426
INFO:root:current train perplexity4.456943988800049
INFO:root:current mean train loss 1896.2049614500604
INFO:root:current train perplexity4.4481892585754395
INFO:root:current mean train loss 1895.1639069798155
INFO:root:current train perplexity4.462216854095459
INFO:root:current mean train loss 1896.3993060895464
INFO:root:current train perplexity4.461453914642334
INFO:root:current mean train loss 1899.4647686298076
INFO:root:current train perplexity4.471705436706543
INFO:root:current mean train loss 1899.7723527340388
INFO:root:current train perplexity4.470713138580322
INFO:root:current mean train loss 1900.1038872134843
INFO:root:current train perplexity4.468465328216553
INFO:root:current mean train loss 1900.0375599879462
INFO:root:current train perplexity4.469930171966553
INFO:root:current mean train loss 1901.700542125204
INFO:root:current train perplexity4.468123912811279
INFO:root:current mean train loss 1902.222748704885
INFO:root:current train perplexity4.471700191497803
INFO:root:current mean train loss 1902.3843418230733
INFO:root:current train perplexity4.472175121307373
INFO:root:current mean train loss 1903.2182954147042
INFO:root:current train perplexity4.476492881774902
INFO:root:current mean train loss 1902.7914837994304
INFO:root:current train perplexity4.477663516998291
INFO:root:current mean train loss 1902.9595587507354
INFO:root:current train perplexity4.476146697998047
INFO:root:current mean train loss 1901.1512395947627
INFO:root:current train perplexity4.472182273864746
INFO:root:current mean train loss 1900.7191579819932
INFO:root:current train perplexity4.473080635070801
INFO:root:current mean train loss 1900.4089396860825
INFO:root:current train perplexity4.473119258880615
INFO:root:current mean train loss 1900.2582732280407
INFO:root:current train perplexity4.4733710289001465
INFO:root:current mean train loss 1901.0197628007045
INFO:root:current train perplexity4.476700782775879
INFO:root:current mean train loss 1901.6382641934313
INFO:root:current train perplexity4.4788408279418945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.32s/it]
INFO:root:final mean train loss: 1901.1740673101735
INFO:root:final train perplexity: 4.478911876678467
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.81s/it]
INFO:root:eval mean loss: 2047.550074800532
INFO:root:eval perplexity: 5.237992286682129
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it]
INFO:root:eval mean loss: 2514.979715117326
INFO:root:eval perplexity: 7.821054935455322
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [5:35:22<17:38:42, 415.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1886.8261307696907
INFO:root:current train perplexity4.393752098083496
INFO:root:current mean train loss 1899.6111968069365
INFO:root:current train perplexity4.432741165161133
INFO:root:current mean train loss 1892.031884110214
INFO:root:current train perplexity4.438377857208252
INFO:root:current mean train loss 1889.556975551586
INFO:root:current train perplexity4.433827877044678
INFO:root:current mean train loss 1886.9299404649848
INFO:root:current train perplexity4.429146766662598
INFO:root:current mean train loss 1889.6045985397288
INFO:root:current train perplexity4.435720920562744
INFO:root:current mean train loss 1890.9049714096639
INFO:root:current train perplexity4.440685272216797
INFO:root:current mean train loss 1890.6186095120613
INFO:root:current train perplexity4.4391889572143555
INFO:root:current mean train loss 1890.3702789510544
INFO:root:current train perplexity4.436619758605957
INFO:root:current mean train loss 1891.9569620197426
INFO:root:current train perplexity4.4417924880981445
INFO:root:current mean train loss 1893.9097982660235
INFO:root:current train perplexity4.443868160247803
INFO:root:current mean train loss 1893.2932563998265
INFO:root:current train perplexity4.441111087799072
INFO:root:current mean train loss 1893.2544413656226
INFO:root:current train perplexity4.443850994110107
INFO:root:current mean train loss 1894.562001502565
INFO:root:current train perplexity4.446147918701172
INFO:root:current mean train loss 1894.574627742589
INFO:root:current train perplexity4.449557304382324
INFO:root:current mean train loss 1894.6787530280772
INFO:root:current train perplexity4.452262878417969
INFO:root:current mean train loss 1895.4320509767927
INFO:root:current train perplexity4.453752040863037
INFO:root:current mean train loss 1895.3047999975015
INFO:root:current train perplexity4.453627109527588
INFO:root:current mean train loss 1895.6911327816288
INFO:root:current train perplexity4.456085681915283

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.90s/it]
INFO:root:final mean train loss: 1895.4191607361302
INFO:root:final train perplexity: 4.458629608154297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.85s/it]
INFO:root:eval mean loss: 2047.2015870006371
INFO:root:eval perplexity: 5.236516952514648
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.68s/it]
INFO:root:eval mean loss: 2512.3620285142397
INFO:root:eval perplexity: 7.8043317794799805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/48
 24%|â–ˆâ–ˆâ–       | 48/200 [5:42:06<17:23:01, 411.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1838.8444010416667
INFO:root:current train perplexity4.364192485809326
INFO:root:current mean train loss 1881.1268257472825
INFO:root:current train perplexity4.4073967933654785
INFO:root:current mean train loss 1885.7284463571948
INFO:root:current train perplexity4.415252208709717
INFO:root:current mean train loss 1883.7129770430308
INFO:root:current train perplexity4.41594123840332
INFO:root:current mean train loss 1888.279184217338
INFO:root:current train perplexity4.426841735839844
INFO:root:current mean train loss 1892.3200714407615
INFO:root:current train perplexity4.4370951652526855
INFO:root:current mean train loss 1888.3665386417047
INFO:root:current train perplexity4.4258341789245605
INFO:root:current mean train loss 1886.7937790237106
INFO:root:current train perplexity4.429006576538086
INFO:root:current mean train loss 1888.3238085038822
INFO:root:current train perplexity4.429730415344238
INFO:root:current mean train loss 1891.658448066086
INFO:root:current train perplexity4.4350481033325195
INFO:root:current mean train loss 1891.0072179033252
INFO:root:current train perplexity4.434973239898682
INFO:root:current mean train loss 1890.0818026555494
INFO:root:current train perplexity4.431779861450195
INFO:root:current mean train loss 1889.8437211652843
INFO:root:current train perplexity4.429765224456787
INFO:root:current mean train loss 1891.6954059789389
INFO:root:current train perplexity4.434952259063721
INFO:root:current mean train loss 1890.7718343674082
INFO:root:current train perplexity4.435129165649414
INFO:root:current mean train loss 1891.3472874606796
INFO:root:current train perplexity4.438589096069336
INFO:root:current mean train loss 1891.211592068982
INFO:root:current train perplexity4.440828800201416
INFO:root:current mean train loss 1890.9487380847986
INFO:root:current train perplexity4.439903259277344
INFO:root:current mean train loss 1890.6558498918519
INFO:root:current train perplexity4.440098285675049
INFO:root:current mean train loss 1890.9255385754936
INFO:root:current train perplexity4.441408634185791

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.20s/it]
INFO:root:final mean train loss: 1890.4985503303963
INFO:root:final train perplexity: 4.441360950469971
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.98s/it]
INFO:root:eval mean loss: 2052.533968445257
INFO:root:eval perplexity: 5.259147644042969
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.55s/it]
INFO:root:eval mean loss: 2522.7104016026706
INFO:root:eval perplexity: 7.870659351348877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/49
 24%|â–ˆâ–ˆâ–       | 49/200 [5:48:54<17:13:18, 410.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1888.0881538391113
INFO:root:current train perplexity4.375277042388916
INFO:root:current mean train loss 1883.6858557498817
INFO:root:current train perplexity4.390293121337891
INFO:root:current mean train loss 1875.1924775222253
INFO:root:current train perplexity4.374154090881348
INFO:root:current mean train loss 1877.7221915003765
INFO:root:current train perplexity4.386624813079834
INFO:root:current mean train loss 1880.4562711362485
INFO:root:current train perplexity4.38961935043335
INFO:root:current mean train loss 1882.0967742231555
INFO:root:current train perplexity4.393787384033203
INFO:root:current mean train loss 1878.3031776524797
INFO:root:current train perplexity4.393531799316406
INFO:root:current mean train loss 1876.812336239007
INFO:root:current train perplexity4.391855239868164
INFO:root:current mean train loss 1877.6317662459153
INFO:root:current train perplexity4.396851539611816
INFO:root:current mean train loss 1878.8227988312685
INFO:root:current train perplexity4.399868488311768
INFO:root:current mean train loss 1879.8514713021211
INFO:root:current train perplexity4.4063520431518555
INFO:root:current mean train loss 1881.3727794418066
INFO:root:current train perplexity4.409491539001465
INFO:root:current mean train loss 1882.2424385764382
INFO:root:current train perplexity4.4105000495910645
INFO:root:current mean train loss 1882.0485640059005
INFO:root:current train perplexity4.410475254058838
INFO:root:current mean train loss 1882.8470453869697
INFO:root:current train perplexity4.4127020835876465
INFO:root:current mean train loss 1884.9719561783513
INFO:root:current train perplexity4.416796684265137
INFO:root:current mean train loss 1886.1812693277996
INFO:root:current train perplexity4.419766426086426
INFO:root:current mean train loss 1885.2017156940135
INFO:root:current train perplexity4.418308734893799
INFO:root:current mean train loss 1885.420158286282
INFO:root:current train perplexity4.419958591461182
INFO:root:current mean train loss 1885.3087138616274
INFO:root:current train perplexity4.420063495635986

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.74s/it]
INFO:root:final mean train loss: 1885.0000780252753
INFO:root:final train perplexity: 4.422142505645752
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.85s/it]
INFO:root:eval mean loss: 2052.25152890902
INFO:root:eval perplexity: 5.257946491241455
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.66s/it]
INFO:root:eval mean loss: 2523.413451715564
INFO:root:eval perplexity: 7.875186443328857
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [5:55:43<17:05:37, 410.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1866.8584258410394
INFO:root:current train perplexity4.3948564529418945
INFO:root:current mean train loss 1880.0179181194947
INFO:root:current train perplexity4.382740020751953
INFO:root:current mean train loss 1882.0444698716742
INFO:root:current train perplexity4.398461818695068
INFO:root:current mean train loss 1879.1415270611344
INFO:root:current train perplexity4.39504337310791
INFO:root:current mean train loss 1878.8484966048684
INFO:root:current train perplexity4.400695323944092
INFO:root:current mean train loss 1876.9889736488217
INFO:root:current train perplexity4.396754264831543
INFO:root:current mean train loss 1872.684072062488
INFO:root:current train perplexity4.382873058319092
INFO:root:current mean train loss 1874.0395820729723
INFO:root:current train perplexity4.384866714477539
INFO:root:current mean train loss 1876.3227139350522
INFO:root:current train perplexity4.387263774871826
INFO:root:current mean train loss 1876.8310564883266
INFO:root:current train perplexity4.386621952056885
INFO:root:current mean train loss 1878.7119483911388
INFO:root:current train perplexity4.391391754150391
INFO:root:current mean train loss 1880.5735893813915
INFO:root:current train perplexity4.394557476043701
INFO:root:current mean train loss 1880.1285748325222
INFO:root:current train perplexity4.396334171295166
INFO:root:current mean train loss 1880.9730614619048
INFO:root:current train perplexity4.400189399719238
INFO:root:current mean train loss 1881.74769608081
INFO:root:current train perplexity4.402188777923584
INFO:root:current mean train loss 1882.0908338671118
INFO:root:current train perplexity4.404904842376709
INFO:root:current mean train loss 1882.324352664612
INFO:root:current train perplexity4.40472412109375
INFO:root:current mean train loss 1882.0333457148504
INFO:root:current train perplexity4.406506538391113
INFO:root:current mean train loss 1881.4040713519132
INFO:root:current train perplexity4.405609607696533
INFO:root:current mean train loss 1880.5905336445574
INFO:root:current train perplexity4.404597282409668

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.20s/it]
INFO:root:final mean train loss: 1880.3601332456249
INFO:root:final train perplexity: 4.4059906005859375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.41s/it]
INFO:root:eval mean loss: 2054.8996508442765
INFO:root:eval perplexity: 5.269218921661377
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.67s/it]
INFO:root:eval mean loss: 2526.502109392315
INFO:root:eval perplexity: 7.895106792449951
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [6:02:30<16:56:01, 409.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1845.454434481534
INFO:root:current train perplexity4.347009181976318
INFO:root:current mean train loss 1847.4318479974586
INFO:root:current train perplexity4.353517055511475
INFO:root:current mean train loss 1861.5897620638511
INFO:root:current train perplexity4.3709821701049805
INFO:root:current mean train loss 1865.9261391228015
INFO:root:current train perplexity4.36899995803833
INFO:root:current mean train loss 1865.2129710447123
INFO:root:current train perplexity4.37333345413208
INFO:root:current mean train loss 1865.6785263223278
INFO:root:current train perplexity4.370149612426758
INFO:root:current mean train loss 1867.6360578107403
INFO:root:current train perplexity4.3715033531188965
INFO:root:current mean train loss 1868.3887756188296
INFO:root:current train perplexity4.3692121505737305
INFO:root:current mean train loss 1869.3735826593625
INFO:root:current train perplexity4.371506214141846
INFO:root:current mean train loss 1870.6036074936512
INFO:root:current train perplexity4.374069690704346
INFO:root:current mean train loss 1870.6999939995455
INFO:root:current train perplexity4.373976707458496
INFO:root:current mean train loss 1871.428040911771
INFO:root:current train perplexity4.375795364379883
INFO:root:current mean train loss 1872.5119615407164
INFO:root:current train perplexity4.382114410400391
INFO:root:current mean train loss 1874.9005934797653
INFO:root:current train perplexity4.385606288909912
INFO:root:current mean train loss 1874.5237834769089
INFO:root:current train perplexity4.386199474334717
INFO:root:current mean train loss 1874.247897210249
INFO:root:current train perplexity4.387268543243408
INFO:root:current mean train loss 1875.3280655768167
INFO:root:current train perplexity4.38776969909668
INFO:root:current mean train loss 1875.0886898883202
INFO:root:current train perplexity4.388370990753174
INFO:root:current mean train loss 1874.275850645599
INFO:root:current train perplexity4.386374473571777
INFO:root:current mean train loss 1875.243050746976
INFO:root:current train perplexity4.387397766113281

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.21s/it]
INFO:root:final mean train loss: 1875.0819712305574
INFO:root:final train perplexity: 4.387687683105469
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.52s/it]
INFO:root:eval mean loss: 2044.9224918446641
INFO:root:eval perplexity: 5.226873874664307
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.27s/it]
INFO:root:eval mean loss: 2518.120409377078
INFO:root:eval perplexity: 7.841170787811279
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [6:09:24<16:52:56, 410.65s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1850.3758280191078
INFO:root:current train perplexity4.295329570770264
INFO:root:current mean train loss 1846.098526084358
INFO:root:current train perplexity4.29592227935791
INFO:root:current mean train loss 1854.749740330996
INFO:root:current train perplexity4.331272602081299
INFO:root:current mean train loss 1855.5228032443292
INFO:root:current train perplexity4.328363418579102
INFO:root:current mean train loss 1857.2487813187436
INFO:root:current train perplexity4.338151454925537
INFO:root:current mean train loss 1855.4529108011498
INFO:root:current train perplexity4.335559368133545
INFO:root:current mean train loss 1853.2133134922904
INFO:root:current train perplexity4.3323893547058105
INFO:root:current mean train loss 1856.6515104603188
INFO:root:current train perplexity4.3438849449157715
INFO:root:current mean train loss 1858.0203027952027
INFO:root:current train perplexity4.350410461425781
INFO:root:current mean train loss 1862.4438055587566
INFO:root:current train perplexity4.35543155670166
INFO:root:current mean train loss 1861.2616912475473
INFO:root:current train perplexity4.353679656982422
INFO:root:current mean train loss 1864.0655350415059
INFO:root:current train perplexity4.3578596115112305
INFO:root:current mean train loss 1865.4371257969299
INFO:root:current train perplexity4.359228610992432
INFO:root:current mean train loss 1865.229081491069
INFO:root:current train perplexity4.35801887512207
INFO:root:current mean train loss 1867.1411024159222
INFO:root:current train perplexity4.360966205596924
INFO:root:current mean train loss 1868.5739477739558
INFO:root:current train perplexity4.361865520477295
INFO:root:current mean train loss 1868.5664415002507
INFO:root:current train perplexity4.362181663513184
INFO:root:current mean train loss 1869.2765674430602
INFO:root:current train perplexity4.363790988922119
INFO:root:current mean train loss 1869.7979973597028
INFO:root:current train perplexity4.367797374725342
INFO:root:current mean train loss 1870.003586115527
INFO:root:current train perplexity4.370149612426758

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.37s/it]
INFO:root:final mean train loss: 1870.003586115527
INFO:root:final train perplexity: 4.370149612426758
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.47s/it]
INFO:root:eval mean loss: 2050.594375502133
INFO:root:eval perplexity: 5.2509050369262695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.63s/it]
INFO:root:eval mean loss: 2523.768498846825
INFO:root:eval perplexity: 7.877473831176758
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [6:16:13<16:45:22, 410.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1856.0474829101563
INFO:root:current train perplexity4.318989276885986
INFO:root:current mean train loss 1857.4368634033203
INFO:root:current train perplexity4.308961391448975
INFO:root:current mean train loss 1864.4568668619793
INFO:root:current train perplexity4.329587459564209
INFO:root:current mean train loss 1862.084616394043
INFO:root:current train perplexity4.331737995147705
INFO:root:current mean train loss 1858.1048669433594
INFO:root:current train perplexity4.329739093780518
INFO:root:current mean train loss 1857.044829305013
INFO:root:current train perplexity4.33544921875
INFO:root:current mean train loss 1856.303345249721
INFO:root:current train perplexity4.331943035125732
INFO:root:current mean train loss 1857.5448283386231
INFO:root:current train perplexity4.331722736358643
INFO:root:current mean train loss 1858.4669066026477
INFO:root:current train perplexity4.333357334136963
INFO:root:current mean train loss 1860.1767161865234
INFO:root:current train perplexity4.337593078613281
INFO:root:current mean train loss 1860.763369362571
INFO:root:current train perplexity4.341230392456055
INFO:root:current mean train loss 1860.3639723714193
INFO:root:current train perplexity4.339173793792725
INFO:root:current mean train loss 1860.4709107384315
INFO:root:current train perplexity4.33840799331665
INFO:root:current mean train loss 1861.3953159877233
INFO:root:current train perplexity4.342860221862793
INFO:root:current mean train loss 1863.9585298665365
INFO:root:current train perplexity4.347358703613281
INFO:root:current mean train loss 1865.0269692993163
INFO:root:current train perplexity4.350430011749268
INFO:root:current mean train loss 1864.9013636690026
INFO:root:current train perplexity4.350378513336182
INFO:root:current mean train loss 1865.0623817952473
INFO:root:current train perplexity4.351529121398926
INFO:root:current mean train loss 1865.6182766241777
INFO:root:current train perplexity4.351215362548828

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.21s/it]
INFO:root:final mean train loss: 1865.026113259089
INFO:root:final train perplexity: 4.353028297424316
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.58s/it]
INFO:root:eval mean loss: 2048.302005848986
INFO:root:eval perplexity: 5.241177558898926
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.04s/it]
INFO:root:eval mean loss: 2520.878056086547
INFO:root:eval perplexity: 7.858874320983887
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [6:23:00<16:36:05, 409.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1864.6441578584559
INFO:root:current train perplexity4.356636047363281
INFO:root:current mean train loss 1858.3983801165198
INFO:root:current train perplexity4.334955215454102
INFO:root:current mean train loss 1858.6647251674108
INFO:root:current train perplexity4.326892852783203
INFO:root:current mean train loss 1856.3570964825267
INFO:root:current train perplexity4.316806316375732
INFO:root:current mean train loss 1853.3755728815386
INFO:root:current train perplexity4.318765640258789
INFO:root:current mean train loss 1854.5363132026716
INFO:root:current train perplexity4.32342004776001
INFO:root:current mean train loss 1853.249221282415
INFO:root:current train perplexity4.321268558502197
INFO:root:current mean train loss 1856.2293849290663
INFO:root:current train perplexity4.329836368560791
INFO:root:current mean train loss 1855.0884788634582
INFO:root:current train perplexity4.325223445892334
INFO:root:current mean train loss 1855.3960034153063
INFO:root:current train perplexity4.323878765106201
INFO:root:current mean train loss 1855.892191148906
INFO:root:current train perplexity4.328579902648926
INFO:root:current mean train loss 1857.130226620202
INFO:root:current train perplexity4.330122470855713
INFO:root:current mean train loss 1856.4438285984363
INFO:root:current train perplexity4.328789710998535
INFO:root:current mean train loss 1859.3354025966032
INFO:root:current train perplexity4.331648826599121
INFO:root:current mean train loss 1859.4217612859475
INFO:root:current train perplexity4.3338847160339355
INFO:root:current mean train loss 1860.2129644143715
INFO:root:current train perplexity4.336272716522217
INFO:root:current mean train loss 1861.1541018795658
INFO:root:current train perplexity4.338379859924316
INFO:root:current mean train loss 1861.9059115872524
INFO:root:current train perplexity4.338915824890137
INFO:root:current mean train loss 1862.359818672176
INFO:root:current train perplexity4.339338779449463
INFO:root:current mean train loss 1861.4473118550713
INFO:root:current train perplexity4.337932109832764

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.95s/it]
INFO:root:final mean train loss: 1860.4230953337747
INFO:root:final train perplexity: 4.337254524230957
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.28s/it]
INFO:root:eval mean loss: 2050.8071180844136
INFO:root:eval perplexity: 5.251808166503906
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.96s/it]
INFO:root:eval mean loss: 2529.3401658078456
INFO:root:eval perplexity: 7.913450717926025
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [6:30:01<16:37:18, 412.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1875.868070714614
INFO:root:current train perplexity4.329510688781738
INFO:root:current mean train loss 1871.0120266586987
INFO:root:current train perplexity4.316240310668945
INFO:root:current mean train loss 1859.6655951605903
INFO:root:current train perplexity4.309041500091553
INFO:root:current mean train loss 1852.2413841750094
INFO:root:current train perplexity4.299264430999756
INFO:root:current mean train loss 1855.6966375535535
INFO:root:current train perplexity4.3051605224609375
INFO:root:current mean train loss 1854.5129024205582
INFO:root:current train perplexity4.3072614669799805
INFO:root:current mean train loss 1853.1860311129117
INFO:root:current train perplexity4.306605339050293
INFO:root:current mean train loss 1853.1530028299026
INFO:root:current train perplexity4.307057857513428
INFO:root:current mean train loss 1854.0302270390719
INFO:root:current train perplexity4.313889980316162
INFO:root:current mean train loss 1854.4225722645795
INFO:root:current train perplexity4.318116664886475
INFO:root:current mean train loss 1853.6702460578608
INFO:root:current train perplexity4.316399097442627
INFO:root:current mean train loss 1854.4949115840636
INFO:root:current train perplexity4.314197540283203
INFO:root:current mean train loss 1853.4211293225158
INFO:root:current train perplexity4.310821056365967
INFO:root:current mean train loss 1855.9268909551572
INFO:root:current train perplexity4.314703464508057
INFO:root:current mean train loss 1855.15155846504
INFO:root:current train perplexity4.314624786376953
INFO:root:current mean train loss 1855.010737651641
INFO:root:current train perplexity4.314075946807861
INFO:root:current mean train loss 1855.0690359911691
INFO:root:current train perplexity4.314218997955322
INFO:root:current mean train loss 1855.0664993866917
INFO:root:current train perplexity4.3169264793396
INFO:root:current mean train loss 1856.2721073063276
INFO:root:current train perplexity4.320457458496094
INFO:root:current mean train loss 1856.0109283857532
INFO:root:current train perplexity4.320250511169434

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:09<00:00, 369.44s/it]
INFO:root:final mean train loss: 1855.6606159989303
INFO:root:final train perplexity: 4.320993900299072
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.54s/it]
INFO:root:eval mean loss: 2050.228019552028
INFO:root:eval perplexity: 5.249349117279053
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.38s/it]
INFO:root:eval mean loss: 2526.8958415579286
INFO:root:eval perplexity: 7.897646427154541
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [6:37:12<16:43:20, 418.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1827.9339599609375
INFO:root:current train perplexity4.260121822357178
INFO:root:current mean train loss 1823.2480193889694
INFO:root:current train perplexity4.241700172424316
INFO:root:current mean train loss 1838.8861064530938
INFO:root:current train perplexity4.27551794052124
INFO:root:current mean train loss 1840.7100913545005
INFO:root:current train perplexity4.279346942901611
INFO:root:current mean train loss 1841.249205866304
INFO:root:current train perplexity4.284297466278076
INFO:root:current mean train loss 1843.8614958332153
INFO:root:current train perplexity4.29235315322876
INFO:root:current mean train loss 1845.7092840191772
INFO:root:current train perplexity4.295281410217285
INFO:root:current mean train loss 1847.4588169549975
INFO:root:current train perplexity4.296638488769531
INFO:root:current mean train loss 1847.7952462004719
INFO:root:current train perplexity4.29581880569458
INFO:root:current mean train loss 1849.6293191839593
INFO:root:current train perplexity4.299515247344971
INFO:root:current mean train loss 1849.5100098817718
INFO:root:current train perplexity4.298789978027344
INFO:root:current mean train loss 1848.8339278472185
INFO:root:current train perplexity4.295781135559082
INFO:root:current mean train loss 1850.1358995811163
INFO:root:current train perplexity4.2997941970825195
INFO:root:current mean train loss 1850.654357955334
INFO:root:current train perplexity4.300527095794678
INFO:root:current mean train loss 1851.3206482564556
INFO:root:current train perplexity4.299834251403809
INFO:root:current mean train loss 1852.7747408426017
INFO:root:current train perplexity4.303009986877441
INFO:root:current mean train loss 1853.0336820901632
INFO:root:current train perplexity4.304144859313965
INFO:root:current mean train loss 1851.4791832122717
INFO:root:current train perplexity4.305075645446777
INFO:root:current mean train loss 1851.2495159394416
INFO:root:current train perplexity4.304418563842773
INFO:root:current mean train loss 1851.7399874813798
INFO:root:current train perplexity4.30709171295166

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.16s/it]
INFO:root:final mean train loss: 1851.9023138326163
INFO:root:final train perplexity: 4.308206081390381
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.10s/it]
INFO:root:eval mean loss: 2050.3080626142787
INFO:root:eval perplexity: 5.249688625335693
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.43s/it]
INFO:root:eval mean loss: 2529.9984221762797
INFO:root:eval perplexity: 7.917710304260254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [6:44:12<16:38:25, 418.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1860.1635939654182
INFO:root:current train perplexity4.2627787590026855
INFO:root:current mean train loss 1844.7325766427177
INFO:root:current train perplexity4.2618865966796875
INFO:root:current mean train loss 1841.773354146018
INFO:root:current train perplexity4.248673439025879
INFO:root:current mean train loss 1843.2208334881327
INFO:root:current train perplexity4.2632832527160645
INFO:root:current mean train loss 1844.0714426937266
INFO:root:current train perplexity4.269897937774658
INFO:root:current mean train loss 1845.9542496372276
INFO:root:current train perplexity4.271999835968018
INFO:root:current mean train loss 1844.4375425784174
INFO:root:current train perplexity4.270749568939209
INFO:root:current mean train loss 1843.8248432477315
INFO:root:current train perplexity4.268695831298828
INFO:root:current mean train loss 1843.0326549336658
INFO:root:current train perplexity4.268813610076904
INFO:root:current mean train loss 1843.9250470626453
INFO:root:current train perplexity4.27335262298584
INFO:root:current mean train loss 1844.3042162491588
INFO:root:current train perplexity4.2757062911987305
INFO:root:current mean train loss 1846.603118373923
INFO:root:current train perplexity4.28102970123291
INFO:root:current mean train loss 1848.0655442487555
INFO:root:current train perplexity4.284215450286865
INFO:root:current mean train loss 1846.285423591123
INFO:root:current train perplexity4.2848029136657715
INFO:root:current mean train loss 1846.4468319760356
INFO:root:current train perplexity4.283684730529785
INFO:root:current mean train loss 1846.4898527495716
INFO:root:current train perplexity4.284014701843262
INFO:root:current mean train loss 1845.9919720473622
INFO:root:current train perplexity4.282598972320557
INFO:root:current mean train loss 1846.2848474148711
INFO:root:current train perplexity4.283964157104492
INFO:root:current mean train loss 1846.9371873091834
INFO:root:current train perplexity4.288173198699951
INFO:root:current mean train loss 1846.4115650208016
INFO:root:current train perplexity4.287484645843506

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.26s/it]
INFO:root:final mean train loss: 1845.8944461762876
INFO:root:final train perplexity: 4.287841320037842
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it]
INFO:root:eval mean loss: 2049.236804718667
INFO:root:eval perplexity: 5.245142459869385
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.34s/it]
INFO:root:eval mean loss: 2531.229332890071
INFO:root:eval perplexity: 7.925685882568359
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [6:51:01<16:23:47, 415.68s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1832.388525390625
INFO:root:current train perplexity4.214348316192627
INFO:root:current mean train loss 1833.0222359322213
INFO:root:current train perplexity4.233399391174316
INFO:root:current mean train loss 1838.9130131236293
INFO:root:current train perplexity4.234990119934082
INFO:root:current mean train loss 1836.3034236759333
INFO:root:current train perplexity4.245907306671143
INFO:root:current mean train loss 1837.972040109536
INFO:root:current train perplexity4.255098342895508
INFO:root:current mean train loss 1832.2391908303284
INFO:root:current train perplexity4.2464165687561035
INFO:root:current mean train loss 1831.9970186330977
INFO:root:current train perplexity4.247247219085693
INFO:root:current mean train loss 1835.336130168939
INFO:root:current train perplexity4.254729270935059
INFO:root:current mean train loss 1836.2388856704627
INFO:root:current train perplexity4.258993148803711
INFO:root:current mean train loss 1838.3360841083042
INFO:root:current train perplexity4.262707233428955
INFO:root:current mean train loss 1839.8597275975662
INFO:root:current train perplexity4.267819881439209
INFO:root:current mean train loss 1840.039445399031
INFO:root:current train perplexity4.267247676849365
INFO:root:current mean train loss 1840.631975392145
INFO:root:current train perplexity4.267275333404541
INFO:root:current mean train loss 1840.9427737900496
INFO:root:current train perplexity4.2708353996276855
INFO:root:current mean train loss 1841.3529583760785
INFO:root:current train perplexity4.27201509475708
INFO:root:current mean train loss 1840.981275954382
INFO:root:current train perplexity4.27349328994751
INFO:root:current mean train loss 1841.1423457929573
INFO:root:current train perplexity4.273796558380127
INFO:root:current mean train loss 1842.3511028727899
INFO:root:current train perplexity4.274186611175537
INFO:root:current mean train loss 1841.6275860126202
INFO:root:current train perplexity4.2743940353393555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:57<00:00, 357.55s/it]
INFO:root:final mean train loss: 1842.4549274300302
INFO:root:final train perplexity: 4.276226043701172
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.57s/it]
INFO:root:eval mean loss: 2048.278664014018
INFO:root:eval perplexity: 5.241079807281494
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2528.878836990248
INFO:root:eval perplexity: 7.91046667098999
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [6:57:54<16:15:20, 415.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1836.2990112304688
INFO:root:current train perplexity4.43932580947876
INFO:root:current mean train loss 1822.0570858226104
INFO:root:current train perplexity4.232715129852295
INFO:root:current mean train loss 1828.843386810605
INFO:root:current train perplexity4.261581897735596
INFO:root:current mean train loss 1833.2437513743016
INFO:root:current train perplexity4.262490272521973
INFO:root:current mean train loss 1833.9571408703553
INFO:root:current train perplexity4.254210472106934
INFO:root:current mean train loss 1831.8378609585097
INFO:root:current train perplexity4.247663497924805
INFO:root:current mean train loss 1831.2809048776214
INFO:root:current train perplexity4.246438026428223
INFO:root:current mean train loss 1831.2302832100806
INFO:root:current train perplexity4.24587869644165
INFO:root:current mean train loss 1834.8333151191844
INFO:root:current train perplexity4.248698711395264
INFO:root:current mean train loss 1833.0174017861782
INFO:root:current train perplexity4.245675086975098
INFO:root:current mean train loss 1833.5567651318456
INFO:root:current train perplexity4.250460147857666
INFO:root:current mean train loss 1835.3833583824864
INFO:root:current train perplexity4.255206108093262
INFO:root:current mean train loss 1835.858168413159
INFO:root:current train perplexity4.255139350891113
INFO:root:current mean train loss 1836.8640323293191
INFO:root:current train perplexity4.258713722229004
INFO:root:current mean train loss 1836.4474754605585
INFO:root:current train perplexity4.255925178527832
INFO:root:current mean train loss 1836.4871441756045
INFO:root:current train perplexity4.258918285369873
INFO:root:current mean train loss 1837.6386054297363
INFO:root:current train perplexity4.260533809661865
INFO:root:current mean train loss 1838.286103836938
INFO:root:current train perplexity4.260837078094482
INFO:root:current mean train loss 1838.052283758064
INFO:root:current train perplexity4.260049343109131
INFO:root:current mean train loss 1837.499918106352
INFO:root:current train perplexity4.25791597366333

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.15s/it]
INFO:root:final mean train loss: 1837.3878004234725
INFO:root:final train perplexity: 4.259171009063721
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.31s/it]
INFO:root:eval mean loss: 2051.6835751364415
INFO:root:eval perplexity: 5.255531311035156
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.25s/it]
INFO:root:eval mean loss: 2535.861530709774
INFO:root:eval perplexity: 7.955769062042236
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [7:04:51<16:09:43, 415.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1844.5609966077302
INFO:root:current train perplexity4.304274082183838
INFO:root:current mean train loss 1816.854116744354
INFO:root:current train perplexity4.225065231323242
INFO:root:current mean train loss 1818.3155645779823
INFO:root:current train perplexity4.224799633026123
INFO:root:current mean train loss 1821.5716422628086
INFO:root:current train perplexity4.227558135986328
INFO:root:current mean train loss 1826.1637621312836
INFO:root:current train perplexity4.232999324798584
INFO:root:current mean train loss 1828.9285030181238
INFO:root:current train perplexity4.232595920562744
INFO:root:current mean train loss 1827.613676844583
INFO:root:current train perplexity4.2336554527282715
INFO:root:current mean train loss 1825.9014940115937
INFO:root:current train perplexity4.2252936363220215
INFO:root:current mean train loss 1826.8836115463312
INFO:root:current train perplexity4.229639530181885
INFO:root:current mean train loss 1828.7314089172164
INFO:root:current train perplexity4.231656551361084
INFO:root:current mean train loss 1828.8736592630644
INFO:root:current train perplexity4.2335920333862305
INFO:root:current mean train loss 1830.3041102023292
INFO:root:current train perplexity4.235279560089111
INFO:root:current mean train loss 1831.8957127984966
INFO:root:current train perplexity4.238059043884277
INFO:root:current mean train loss 1832.1423661909473
INFO:root:current train perplexity4.237655162811279
INFO:root:current mean train loss 1832.8699176941564
INFO:root:current train perplexity4.238578796386719
INFO:root:current mean train loss 1832.6645204846682
INFO:root:current train perplexity4.238772869110107
INFO:root:current mean train loss 1832.5394766644388
INFO:root:current train perplexity4.2390666007995605
INFO:root:current mean train loss 1832.9570643417776
INFO:root:current train perplexity4.240110874176025
INFO:root:current mean train loss 1833.9201046113722
INFO:root:current train perplexity4.2443647384643555
INFO:root:current mean train loss 1833.8358191827613
INFO:root:current train perplexity4.245603084564209

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.73s/it]
INFO:root:final mean train loss: 1833.1679614861084
INFO:root:final train perplexity: 4.245019435882568
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.42s/it]
INFO:root:eval mean loss: 2052.4981585563496
INFO:root:eval perplexity: 5.258995532989502
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.61s/it]
INFO:root:eval mean loss: 2538.4692365497563
INFO:root:eval perplexity: 7.972752571105957
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [7:11:35<15:54:43, 412.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1815.210456000434
INFO:root:current train perplexity4.206989288330078
INFO:root:current mean train loss 1826.6121709487018
INFO:root:current train perplexity4.2302470207214355
INFO:root:current mean train loss 1814.6333871615136
INFO:root:current train perplexity4.198746204376221
INFO:root:current mean train loss 1817.4817661103748
INFO:root:current train perplexity4.202489852905273
INFO:root:current mean train loss 1819.2052491914242
INFO:root:current train perplexity4.205751895904541
INFO:root:current mean train loss 1817.3919069660244
INFO:root:current train perplexity4.206509590148926
INFO:root:current mean train loss 1821.5709017387726
INFO:root:current train perplexity4.209664344787598
INFO:root:current mean train loss 1822.591476606286
INFO:root:current train perplexity4.212109565734863
INFO:root:current mean train loss 1823.8443606435967
INFO:root:current train perplexity4.213466644287109
INFO:root:current mean train loss 1823.9440631051348
INFO:root:current train perplexity4.214818954467773
INFO:root:current mean train loss 1826.8974436167125
INFO:root:current train perplexity4.219559192657471
INFO:root:current mean train loss 1827.8239920172894
INFO:root:current train perplexity4.2193603515625
INFO:root:current mean train loss 1827.4603322840817
INFO:root:current train perplexity4.217567443847656
INFO:root:current mean train loss 1827.1856692194224
INFO:root:current train perplexity4.218381404876709
INFO:root:current mean train loss 1827.132103540107
INFO:root:current train perplexity4.21908712387085
INFO:root:current mean train loss 1827.4760944843292
INFO:root:current train perplexity4.223072528839111
INFO:root:current mean train loss 1828.5686708930652
INFO:root:current train perplexity4.226151466369629
INFO:root:current mean train loss 1828.9458352365803
INFO:root:current train perplexity4.22713565826416
INFO:root:current mean train loss 1829.2532324697456
INFO:root:current train perplexity4.228402137756348
INFO:root:current mean train loss 1829.7529674561556
INFO:root:current train perplexity4.230383396148682

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.52s/it]
INFO:root:final mean train loss: 1829.1504236203039
INFO:root:final train perplexity: 4.231590747833252
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.84s/it]
INFO:root:eval mean loss: 2046.9942579337046
INFO:root:eval perplexity: 5.23563814163208
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.44s/it]
INFO:root:eval mean loss: 2532.735508262688
INFO:root:eval perplexity: 7.93545389175415
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [7:18:24<15:45:45, 411.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1804.8795004790684
INFO:root:current train perplexity4.186410427093506
INFO:root:current mean train loss 1798.579829995149
INFO:root:current train perplexity4.170287609100342
INFO:root:current mean train loss 1808.926264223845
INFO:root:current train perplexity4.181068420410156
INFO:root:current mean train loss 1808.0949938722779
INFO:root:current train perplexity4.189239501953125
INFO:root:current mean train loss 1809.3186886684257
INFO:root:current train perplexity4.19182014465332
INFO:root:current mean train loss 1812.9802208567614
INFO:root:current train perplexity4.195765018463135
INFO:root:current mean train loss 1812.522994083796
INFO:root:current train perplexity4.195285797119141
INFO:root:current mean train loss 1814.8260755804906
INFO:root:current train perplexity4.196681976318359
INFO:root:current mean train loss 1814.6699585104045
INFO:root:current train perplexity4.20099401473999
INFO:root:current mean train loss 1817.2136431570943
INFO:root:current train perplexity4.20490837097168
INFO:root:current mean train loss 1817.680992017784
INFO:root:current train perplexity4.205934047698975
INFO:root:current mean train loss 1819.2397524460646
INFO:root:current train perplexity4.206244468688965
INFO:root:current mean train loss 1820.017330866857
INFO:root:current train perplexity4.207854747772217
INFO:root:current mean train loss 1821.501880225656
INFO:root:current train perplexity4.211627006530762
INFO:root:current mean train loss 1822.9055487468008
INFO:root:current train perplexity4.213343620300293
INFO:root:current mean train loss 1824.7632214017476
INFO:root:current train perplexity4.217469692230225
INFO:root:current mean train loss 1825.0819328848117
INFO:root:current train perplexity4.2155303955078125
INFO:root:current mean train loss 1825.00693676911
INFO:root:current train perplexity4.215278148651123
INFO:root:current mean train loss 1825.5157973345588
INFO:root:current train perplexity4.216454982757568
INFO:root:current mean train loss 1825.2920813182043
INFO:root:current train perplexity4.218155384063721

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.67s/it]
INFO:root:final mean train loss: 1825.3409952922595
INFO:root:final train perplexity: 4.218897819519043
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.62s/it]
INFO:root:eval mean loss: 2052.292202563996
INFO:root:eval perplexity: 5.258120059967041
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.78s/it]
INFO:root:eval mean loss: 2538.0954910170103
INFO:root:eval perplexity: 7.970317840576172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [7:25:09<15:34:51, 409.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1799.1545375279018
INFO:root:current train perplexity4.142210006713867
INFO:root:current mean train loss 1810.507275390625
INFO:root:current train perplexity4.1707258224487305
INFO:root:current mean train loss 1815.7709142614294
INFO:root:current train perplexity4.179358959197998
INFO:root:current mean train loss 1814.4390463339316
INFO:root:current train perplexity4.175980091094971
INFO:root:current mean train loss 1813.1835547913897
INFO:root:current train perplexity4.180790901184082
INFO:root:current mean train loss 1814.8688527960526
INFO:root:current train perplexity4.177850723266602
INFO:root:current mean train loss 1814.101833423216
INFO:root:current train perplexity4.181624889373779
INFO:root:current mean train loss 1812.736066387226
INFO:root:current train perplexity4.181712627410889
INFO:root:current mean train loss 1812.654488820043
INFO:root:current train perplexity4.180297374725342
INFO:root:current mean train loss 1811.8733655162694
INFO:root:current train perplexity4.1819987297058105
INFO:root:current mean train loss 1813.9606882255769
INFO:root:current train perplexity4.185639381408691
INFO:root:current mean train loss 1813.8728469718217
INFO:root:current train perplexity4.1875386238098145
INFO:root:current mean train loss 1816.23527495617
INFO:root:current train perplexity4.189349174499512
INFO:root:current mean train loss 1817.1852312742358
INFO:root:current train perplexity4.190206527709961
INFO:root:current mean train loss 1819.1069516136533
INFO:root:current train perplexity4.1950883865356445
INFO:root:current mean train loss 1819.726836419561
INFO:root:current train perplexity4.197565078735352
INFO:root:current mean train loss 1819.5444482129492
INFO:root:current train perplexity4.19761848449707
INFO:root:current mean train loss 1820.9292610125353
INFO:root:current train perplexity4.201135635375977
INFO:root:current mean train loss 1821.204515165441
INFO:root:current train perplexity4.203343868255615
INFO:root:current mean train loss 1821.0458326310675
INFO:root:current train perplexity4.202861785888672

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.35s/it]
INFO:root:final mean train loss: 1820.4365244224343
INFO:root:final train perplexity: 4.202609539031982
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.13s/it]
INFO:root:eval mean loss: 2049.4018810082835
INFO:root:eval perplexity: 5.245843410491943
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.05s/it]
INFO:root:eval mean loss: 2536.248087132231
INFO:root:eval perplexity: 7.958282947540283
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [7:32:06<15:33:00, 411.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1812.7318451980066
INFO:root:current train perplexity4.20078706741333
INFO:root:current mean train loss 1811.8492744976186
INFO:root:current train perplexity4.180544376373291
INFO:root:current mean train loss 1815.6771469913708
INFO:root:current train perplexity4.175588607788086
INFO:root:current mean train loss 1814.3182751559473
INFO:root:current train perplexity4.170198917388916
INFO:root:current mean train loss 1816.283536750433
INFO:root:current train perplexity4.1772074699401855
INFO:root:current mean train loss 1815.9399312163944
INFO:root:current train perplexity4.177948474884033
INFO:root:current mean train loss 1815.7403162882665
INFO:root:current train perplexity4.175149440765381
INFO:root:current mean train loss 1815.4378705539727
INFO:root:current train perplexity4.17778205871582
INFO:root:current mean train loss 1814.800717118359
INFO:root:current train perplexity4.182387351989746
INFO:root:current mean train loss 1815.4923083335311
INFO:root:current train perplexity4.184835433959961
INFO:root:current mean train loss 1814.5868245592442
INFO:root:current train perplexity4.182666778564453
INFO:root:current mean train loss 1815.1502917963815
INFO:root:current train perplexity4.182549476623535
INFO:root:current mean train loss 1814.7501948192867
INFO:root:current train perplexity4.182267665863037
INFO:root:current mean train loss 1813.7862050689719
INFO:root:current train perplexity4.180217742919922
INFO:root:current mean train loss 1814.8200195969234
INFO:root:current train perplexity4.183741092681885
INFO:root:current mean train loss 1816.4114220276072
INFO:root:current train perplexity4.188117027282715
INFO:root:current mean train loss 1816.2888800095861
INFO:root:current train perplexity4.188408374786377
INFO:root:current mean train loss 1815.7673883592875
INFO:root:current train perplexity4.18842077255249
INFO:root:current mean train loss 1816.2482668861992
INFO:root:current train perplexity4.189085960388184

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.32s/it]
INFO:root:final mean train loss: 1816.9561278496615
INFO:root:final train perplexity: 4.191090106964111
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.98s/it]
INFO:root:eval mean loss: 2054.215308656084
INFO:root:eval perplexity: 5.266304016113281
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.93s/it]
INFO:root:eval mean loss: 2541.1176714525154
INFO:root:eval perplexity: 7.990040302276611
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [7:38:51<15:21:17, 409.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1791.3692016601562
INFO:root:current train perplexity4.179680824279785
INFO:root:current mean train loss 1801.4629880464995
INFO:root:current train perplexity4.158092021942139
INFO:root:current mean train loss 1799.1987005495557
INFO:root:current train perplexity4.1556396484375
INFO:root:current mean train loss 1799.6756290636565
INFO:root:current train perplexity4.141848564147949
INFO:root:current mean train loss 1799.563601654355
INFO:root:current train perplexity4.146815299987793
INFO:root:current mean train loss 1803.0302240280878
INFO:root:current train perplexity4.162774085998535
INFO:root:current mean train loss 1804.0319013785054
INFO:root:current train perplexity4.159830093383789
INFO:root:current mean train loss 1803.81029475819
INFO:root:current train perplexity4.165030479431152
INFO:root:current mean train loss 1806.2510899785739
INFO:root:current train perplexity4.164667129516602
INFO:root:current mean train loss 1806.2669562955873
INFO:root:current train perplexity4.167327404022217
INFO:root:current mean train loss 1806.758135548626
INFO:root:current train perplexity4.1695990562438965
INFO:root:current mean train loss 1806.2881342569988
INFO:root:current train perplexity4.1725053787231445
INFO:root:current mean train loss 1810.1194185275967
INFO:root:current train perplexity4.177466869354248
INFO:root:current mean train loss 1810.7401166108489
INFO:root:current train perplexity4.176028728485107
INFO:root:current mean train loss 1809.4986690510373
INFO:root:current train perplexity4.173707485198975
INFO:root:current mean train loss 1810.6622645601312
INFO:root:current train perplexity4.174429893493652
INFO:root:current mean train loss 1810.7306776546184
INFO:root:current train perplexity4.1757636070251465
INFO:root:current mean train loss 1811.435921754076
INFO:root:current train perplexity4.175328731536865
INFO:root:current mean train loss 1812.0542807568468
INFO:root:current train perplexity4.175925254821777
INFO:root:current mean train loss 1812.2548149172999
INFO:root:current train perplexity4.176427841186523

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.66s/it]
INFO:root:final mean train loss: 1812.5598580056949
INFO:root:final train perplexity: 4.176584243774414
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.16s/it]
INFO:root:eval mean loss: 2049.860823394559
INFO:root:eval perplexity: 5.247790336608887
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.08s/it]
INFO:root:eval mean loss: 2539.533250308206
INFO:root:eval perplexity: 7.9796953201293945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [7:45:47<15:18:54, 411.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1790.2948811848958
INFO:root:current train perplexity4.176210880279541
INFO:root:current mean train loss 1798.5619834710744
INFO:root:current train perplexity4.132899284362793
INFO:root:current mean train loss 1797.8302836008202
INFO:root:current train perplexity4.10872220993042
INFO:root:current mean train loss 1797.6949668242553
INFO:root:current train perplexity4.119664669036865
INFO:root:current mean train loss 1799.765727063539
INFO:root:current train perplexity4.133683681488037
INFO:root:current mean train loss 1801.7742720766855
INFO:root:current train perplexity4.137373924255371
INFO:root:current mean train loss 1801.5182922658137
INFO:root:current train perplexity4.142610549926758
INFO:root:current mean train loss 1805.668488183729
INFO:root:current train perplexity4.146384239196777
INFO:root:current mean train loss 1806.651768042022
INFO:root:current train perplexity4.1442952156066895
INFO:root:current mean train loss 1805.7452063876306
INFO:root:current train perplexity4.143930912017822
INFO:root:current mean train loss 1807.4214839206736
INFO:root:current train perplexity4.149641036987305
INFO:root:current mean train loss 1806.890576542115
INFO:root:current train perplexity4.152254581451416
INFO:root:current mean train loss 1807.1516115280763
INFO:root:current train perplexity4.150002956390381
INFO:root:current mean train loss 1805.9636929993553
INFO:root:current train perplexity4.1511640548706055
INFO:root:current mean train loss 1807.2429048026809
INFO:root:current train perplexity4.154287815093994
INFO:root:current mean train loss 1807.420468823836
INFO:root:current train perplexity4.156806468963623
INFO:root:current mean train loss 1808.0574355504896
INFO:root:current train perplexity4.158176422119141
INFO:root:current mean train loss 1808.4266349619588
INFO:root:current train perplexity4.160468578338623
INFO:root:current mean train loss 1809.3464647740338
INFO:root:current train perplexity4.162336349487305
INFO:root:current mean train loss 1809.4601244392773
INFO:root:current train perplexity4.163985252380371

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.62s/it]
INFO:root:final mean train loss: 1809.082679767772
INFO:root:final train perplexity: 4.165146827697754
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.39s/it]
INFO:root:eval mean loss: 2050.5505522599456
INFO:root:eval perplexity: 5.25071907043457
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2539.474665215675
INFO:root:eval perplexity: 7.97930908203125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [7:52:35<15:10:01, 410.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1806.8707082648027
INFO:root:current train perplexity4.1569013595581055
INFO:root:current mean train loss 1794.1801288991735
INFO:root:current train perplexity4.127912521362305
INFO:root:current mean train loss 1795.7266768768054
INFO:root:current train perplexity4.128843784332275
INFO:root:current mean train loss 1795.8856139775564
INFO:root:current train perplexity4.125183582305908
INFO:root:current mean train loss 1796.5791765326235
INFO:root:current train perplexity4.130117893218994
INFO:root:current mean train loss 1797.0385172677306
INFO:root:current train perplexity4.131157875061035
INFO:root:current mean train loss 1799.0182453023976
INFO:root:current train perplexity4.132687568664551
INFO:root:current mean train loss 1798.6622498054815
INFO:root:current train perplexity4.134010314941406
INFO:root:current mean train loss 1797.4470412953087
INFO:root:current train perplexity4.132241725921631
INFO:root:current mean train loss 1797.583676856718
INFO:root:current train perplexity4.134875297546387
INFO:root:current mean train loss 1797.3554854494068
INFO:root:current train perplexity4.134995460510254
INFO:root:current mean train loss 1799.0525180166342
INFO:root:current train perplexity4.1378984451293945
INFO:root:current mean train loss 1799.4610171710924
INFO:root:current train perplexity4.137389659881592
INFO:root:current mean train loss 1800.4419998146136
INFO:root:current train perplexity4.13744592666626
INFO:root:current mean train loss 1801.9569478041606
INFO:root:current train perplexity4.141190528869629
INFO:root:current mean train loss 1802.565586283551
INFO:root:current train perplexity4.1415534019470215
INFO:root:current mean train loss 1803.6493737450157
INFO:root:current train perplexity4.144958972930908
INFO:root:current mean train loss 1804.449532073167
INFO:root:current train perplexity4.145796775817871
INFO:root:current mean train loss 1805.350509626951
INFO:root:current train perplexity4.149518013000488
INFO:root:current mean train loss 1804.8703744295826
INFO:root:current train perplexity4.151422023773193

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.62s/it]
INFO:root:final mean train loss: 1804.905632692338
INFO:root:final train perplexity: 4.151447772979736
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.69s/it]
INFO:root:eval mean loss: 2054.01283210051
INFO:root:eval perplexity: 5.265441417694092
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.99s/it]
INFO:root:eval mean loss: 2546.7047080182015
INFO:root:eval perplexity: 8.026632308959961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [7:59:25<15:02:30, 410.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1786.9903564453125
INFO:root:current train perplexity4.093082427978516
INFO:root:current mean train loss 1793.0229523689516
INFO:root:current train perplexity4.106960296630859
INFO:root:current mean train loss 1795.2647039675246
INFO:root:current train perplexity4.126838684082031
INFO:root:current mean train loss 1795.1510876292914
INFO:root:current train perplexity4.119626522064209
INFO:root:current mean train loss 1795.3142942994505
INFO:root:current train perplexity4.118171215057373
INFO:root:current mean train loss 1798.3466741888374
INFO:root:current train perplexity4.128183364868164
INFO:root:current mean train loss 1798.2693385466364
INFO:root:current train perplexity4.1300201416015625
INFO:root:current mean train loss 1798.0227674875828
INFO:root:current train perplexity4.135111331939697
INFO:root:current mean train loss 1796.5355872795596
INFO:root:current train perplexity4.130349636077881
INFO:root:current mean train loss 1798.1300263569617
INFO:root:current train perplexity4.13132905960083
INFO:root:current mean train loss 1796.4753979145069
INFO:root:current train perplexity4.130453586578369
INFO:root:current mean train loss 1795.6308632854775
INFO:root:current train perplexity4.12749719619751
INFO:root:current mean train loss 1796.312250996016
INFO:root:current train perplexity4.128615856170654
INFO:root:current mean train loss 1797.5428688415302
INFO:root:current train perplexity4.132762432098389
INFO:root:current mean train loss 1797.612833574957
INFO:root:current train perplexity4.133389949798584
INFO:root:current mean train loss 1798.1015434240605
INFO:root:current train perplexity4.135745048522949
INFO:root:current mean train loss 1799.0861720520204
INFO:root:current train perplexity4.135931015014648
INFO:root:current mean train loss 1800.0832988336895
INFO:root:current train perplexity4.138211250305176
INFO:root:current mean train loss 1800.573130514551
INFO:root:current train perplexity4.139377117156982
INFO:root:current mean train loss 1801.3924082256035
INFO:root:current train perplexity4.139583110809326

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.56s/it]
INFO:root:final mean train loss: 1801.1037058712434
INFO:root:final train perplexity: 4.139019012451172
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.42s/it]
INFO:root:eval mean loss: 2052.1526164602724
INFO:root:eval perplexity: 5.25752592086792
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.74s/it]
INFO:root:eval mean loss: 2544.344736951463
INFO:root:eval perplexity: 8.011154174804688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [8:06:12<14:54:09, 409.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1780.2860717773438
INFO:root:current train perplexity4.087604522705078
INFO:root:current mean train loss 1771.9760082156158
INFO:root:current train perplexity4.069418430328369
INFO:root:current mean train loss 1778.2579969518324
INFO:root:current train perplexity4.086266040802002
INFO:root:current mean train loss 1784.691865326256
INFO:root:current train perplexity4.096468925476074
INFO:root:current mean train loss 1787.0310718083786
INFO:root:current train perplexity4.10126256942749
INFO:root:current mean train loss 1785.3834258392974
INFO:root:current train perplexity4.103869438171387
INFO:root:current mean train loss 1788.4270945957728
INFO:root:current train perplexity4.110208511352539
INFO:root:current mean train loss 1787.9603856536392
INFO:root:current train perplexity4.111513614654541
INFO:root:current mean train loss 1786.1876910848355
INFO:root:current train perplexity4.1072258949279785
INFO:root:current mean train loss 1789.0420179327818
INFO:root:current train perplexity4.109175205230713
INFO:root:current mean train loss 1791.8480320261485
INFO:root:current train perplexity4.110049247741699
INFO:root:current mean train loss 1792.159243639012
INFO:root:current train perplexity4.112971305847168
INFO:root:current mean train loss 1793.5619374401165
INFO:root:current train perplexity4.117619037628174
INFO:root:current mean train loss 1795.1794406012266
INFO:root:current train perplexity4.120101451873779
INFO:root:current mean train loss 1795.9428148684294
INFO:root:current train perplexity4.122129917144775
INFO:root:current mean train loss 1795.9545492312986
INFO:root:current train perplexity4.121585845947266
INFO:root:current mean train loss 1797.1691195109245
INFO:root:current train perplexity4.12409782409668
INFO:root:current mean train loss 1797.557008971479
INFO:root:current train perplexity4.124020099639893
INFO:root:current mean train loss 1797.4699758545964
INFO:root:current train perplexity4.1245856285095215
INFO:root:current mean train loss 1797.7333652581453
INFO:root:current train perplexity4.126564979553223

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.41s/it]
INFO:root:final mean train loss: 1797.3994008582226
INFO:root:final train perplexity: 4.126944541931152
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.98s/it]
INFO:root:eval mean loss: 2055.486946701158
INFO:root:eval perplexity: 5.271722316741943
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it]
INFO:root:eval mean loss: 2547.1374334240636
INFO:root:eval perplexity: 8.029473304748535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [8:13:11<14:52:53, 412.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1776.148178272033
INFO:root:current train perplexity4.070468425750732
INFO:root:current mean train loss 1787.3041895306299
INFO:root:current train perplexity4.095782279968262
INFO:root:current mean train loss 1792.3088978698097
INFO:root:current train perplexity4.104446887969971
INFO:root:current mean train loss 1795.0006423597165
INFO:root:current train perplexity4.110990047454834
INFO:root:current mean train loss 1792.7452799479167
INFO:root:current train perplexity4.112470626831055
INFO:root:current mean train loss 1791.3967921414076
INFO:root:current train perplexity4.113121509552002
INFO:root:current mean train loss 1794.316921992641
INFO:root:current train perplexity4.111515045166016
INFO:root:current mean train loss 1793.6685073136982
INFO:root:current train perplexity4.111128330230713
INFO:root:current mean train loss 1794.0828728348654
INFO:root:current train perplexity4.114095211029053
INFO:root:current mean train loss 1795.6455533574397
INFO:root:current train perplexity4.116209983825684
INFO:root:current mean train loss 1795.1431107954545
INFO:root:current train perplexity4.117331504821777
INFO:root:current mean train loss 1796.0722835916145
INFO:root:current train perplexity4.1173906326293945
INFO:root:current mean train loss 1794.7408260703548
INFO:root:current train perplexity4.11382532119751
INFO:root:current mean train loss 1794.110808469307
INFO:root:current train perplexity4.11435079574585
INFO:root:current mean train loss 1794.228662699641
INFO:root:current train perplexity4.1161909103393555
INFO:root:current mean train loss 1795.5179493293738
INFO:root:current train perplexity4.115971088409424
INFO:root:current mean train loss 1794.9584050288631
INFO:root:current train perplexity4.1151227951049805
INFO:root:current mean train loss 1794.1206935586179
INFO:root:current train perplexity4.113062858581543
INFO:root:current mean train loss 1794.6761671705433
INFO:root:current train perplexity4.114292144775391

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.51s/it]
INFO:root:final mean train loss: 1793.8425991964411
INFO:root:final train perplexity: 4.115384101867676
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.30s/it]
INFO:root:eval mean loss: 2052.1629725246567
INFO:root:eval perplexity: 5.257569789886475
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.91s/it]
INFO:root:eval mean loss: 2545.7654925407246
INFO:root:eval perplexity: 8.020468711853027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [8:19:55<14:41:24, 409.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1766.4807535807292
INFO:root:current train perplexity3.9503426551818848
INFO:root:current mean train loss 1768.4977509120724
INFO:root:current train perplexity4.035832405090332
INFO:root:current mean train loss 1768.6279427241352
INFO:root:current train perplexity4.060377597808838
INFO:root:current mean train loss 1767.3472972196691
INFO:root:current train perplexity4.057636737823486
INFO:root:current mean train loss 1767.9704884496227
INFO:root:current train perplexity4.070176124572754
INFO:root:current mean train loss 1773.2755783141365
INFO:root:current train perplexity4.072119235992432
INFO:root:current mean train loss 1775.1794618915017
INFO:root:current train perplexity4.074955463409424
INFO:root:current mean train loss 1779.7912423023083
INFO:root:current train perplexity4.081782817840576
INFO:root:current mean train loss 1782.0589478447775
INFO:root:current train perplexity4.085079669952393
INFO:root:current mean train loss 1784.6493081604408
INFO:root:current train perplexity4.089606761932373
INFO:root:current mean train loss 1783.5688390409496
INFO:root:current train perplexity4.087996006011963
INFO:root:current mean train loss 1786.2357155660177
INFO:root:current train perplexity4.0945353507995605
INFO:root:current mean train loss 1788.087879592111
INFO:root:current train perplexity4.095811367034912
INFO:root:current mean train loss 1788.113164413943
INFO:root:current train perplexity4.097428321838379
INFO:root:current mean train loss 1787.8163293266025
INFO:root:current train perplexity4.096954822540283
INFO:root:current mean train loss 1788.1758417988203
INFO:root:current train perplexity4.099042892456055
INFO:root:current mean train loss 1788.4157872182197
INFO:root:current train perplexity4.099582672119141
INFO:root:current mean train loss 1789.7389087744084
INFO:root:current train perplexity4.100584506988525
INFO:root:current mean train loss 1789.1909224973829
INFO:root:current train perplexity4.09969425201416
INFO:root:current mean train loss 1789.7421115422924
INFO:root:current train perplexity4.102048873901367

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.12s/it]
INFO:root:final mean train loss: 1790.2716877331832
INFO:root:final train perplexity: 4.1038103103637695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.24s/it]
INFO:root:eval mean loss: 2056.116105749252
INFO:root:eval perplexity: 5.274405479431152
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.10s/it]
INFO:root:eval mean loss: 2549.180763623393
INFO:root:eval perplexity: 8.042903900146484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [8:26:50<14:37:37, 411.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1789.6779413637908
INFO:root:current train perplexity4.030066967010498
INFO:root:current mean train loss 1779.8487270944486
INFO:root:current train perplexity4.061581611633301
INFO:root:current mean train loss 1780.6970368115892
INFO:root:current train perplexity4.081803321838379
INFO:root:current mean train loss 1783.2756857857246
INFO:root:current train perplexity4.085009574890137
INFO:root:current mean train loss 1777.4486219618057
INFO:root:current train perplexity4.0688862800598145
INFO:root:current mean train loss 1776.795869495399
INFO:root:current train perplexity4.068606853485107
INFO:root:current mean train loss 1778.3883842358046
INFO:root:current train perplexity4.065929412841797
INFO:root:current mean train loss 1776.2035351089753
INFO:root:current train perplexity4.059229373931885
INFO:root:current mean train loss 1778.9197050259152
INFO:root:current train perplexity4.066556453704834
INFO:root:current mean train loss 1779.877854435054
INFO:root:current train perplexity4.068787097930908
INFO:root:current mean train loss 1780.1013666863316
INFO:root:current train perplexity4.069161415100098
INFO:root:current mean train loss 1778.8014131242
INFO:root:current train perplexity4.069292068481445
INFO:root:current mean train loss 1779.1215931104034
INFO:root:current train perplexity4.068674087524414
INFO:root:current mean train loss 1780.3278869490505
INFO:root:current train perplexity4.073715686798096
INFO:root:current mean train loss 1780.525226692205
INFO:root:current train perplexity4.075634956359863
INFO:root:current mean train loss 1781.9740765296701
INFO:root:current train perplexity4.076509952545166
INFO:root:current mean train loss 1783.3341197579714
INFO:root:current train perplexity4.081453800201416
INFO:root:current mean train loss 1784.2592560894877
INFO:root:current train perplexity4.083442211151123
INFO:root:current mean train loss 1785.4179077483243
INFO:root:current train perplexity4.084737777709961
INFO:root:current mean train loss 1785.957178584995
INFO:root:current train perplexity4.088423728942871

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.97s/it]
INFO:root:final mean train loss: 1785.935833829494
INFO:root:final train perplexity: 4.08980131149292
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.39s/it]
INFO:root:eval mean loss: 2059.7366874099625
INFO:root:eval perplexity: 5.289872646331787
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.35s/it]
INFO:root:eval mean loss: 2555.5318200943316
INFO:root:eval perplexity: 8.084789276123047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [8:33:40<14:29:51, 410.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1773.5776947021484
INFO:root:current train perplexity4.032682418823242
INFO:root:current mean train loss 1768.8911158970425
INFO:root:current train perplexity4.034090995788574
INFO:root:current mean train loss 1776.6932520548503
INFO:root:current train perplexity4.0513081550598145
INFO:root:current mean train loss 1780.1092170266545
INFO:root:current train perplexity4.048361778259277
INFO:root:current mean train loss 1777.5774591619318
INFO:root:current train perplexity4.050624847412109
INFO:root:current mean train loss 1780.1866658528645
INFO:root:current train perplexity4.049615383148193
INFO:root:current mean train loss 1783.3676452636719
INFO:root:current train perplexity4.0571770668029785
INFO:root:current mean train loss 1781.6319172627218
INFO:root:current train perplexity4.062139511108398
INFO:root:current mean train loss 1781.653111194429
INFO:root:current train perplexity4.066549777984619
INFO:root:current mean train loss 1782.7265309435256
INFO:root:current train perplexity4.067187786102295
INFO:root:current mean train loss 1781.852117567796
INFO:root:current train perplexity4.066844940185547
INFO:root:current mean train loss 1779.997092584978
INFO:root:current train perplexity4.0676751136779785
INFO:root:current mean train loss 1781.1503518381426
INFO:root:current train perplexity4.069070339202881
INFO:root:current mean train loss 1781.877491327542
INFO:root:current train perplexity4.073492527008057
INFO:root:current mean train loss 1781.5610790676542
INFO:root:current train perplexity4.073541164398193
INFO:root:current mean train loss 1782.0298469840707
INFO:root:current train perplexity4.075736999511719
INFO:root:current mean train loss 1782.636968547542
INFO:root:current train perplexity4.077073097229004
INFO:root:current mean train loss 1781.8169060367277
INFO:root:current train perplexity4.07645320892334
INFO:root:current mean train loss 1782.4232386713443
INFO:root:current train perplexity4.077487468719482
INFO:root:current mean train loss 1782.4261239907175
INFO:root:current train perplexity4.077730178833008

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.17s/it]
INFO:root:final mean train loss: 1782.7540550674385
INFO:root:final train perplexity: 4.0795512199401855
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.30s/it]
INFO:root:eval mean loss: 2059.896067517869
INFO:root:eval perplexity: 5.290554046630859
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.59s/it]
INFO:root:eval mean loss: 2558.310268970246
INFO:root:eval perplexity: 8.103179931640625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [8:40:30<14:22:34, 410.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1779.8260390967653
INFO:root:current train perplexity4.034980773925781
INFO:root:current mean train loss 1790.1418674736267
INFO:root:current train perplexity4.064035892486572
INFO:root:current mean train loss 1783.1175494361016
INFO:root:current train perplexity4.056283473968506
INFO:root:current mean train loss 1780.0346088142287
INFO:root:current train perplexity4.049417018890381
INFO:root:current mean train loss 1780.7627623576825
INFO:root:current train perplexity4.056938171386719
INFO:root:current mean train loss 1780.3275264829022
INFO:root:current train perplexity4.052741050720215
INFO:root:current mean train loss 1779.8738339219462
INFO:root:current train perplexity4.055141448974609
INFO:root:current mean train loss 1778.8243021190244
INFO:root:current train perplexity4.0528154373168945
INFO:root:current mean train loss 1777.8650425095263
INFO:root:current train perplexity4.051070690155029
INFO:root:current mean train loss 1777.0883874524475
INFO:root:current train perplexity4.052150726318359
INFO:root:current mean train loss 1778.9131595030526
INFO:root:current train perplexity4.055602550506592
INFO:root:current mean train loss 1779.2196958602865
INFO:root:current train perplexity4.0546441078186035
INFO:root:current mean train loss 1778.8551108907307
INFO:root:current train perplexity4.056981086730957
INFO:root:current mean train loss 1778.9206696793535
INFO:root:current train perplexity4.057724952697754
INFO:root:current mean train loss 1779.5318299387118
INFO:root:current train perplexity4.0615553855896
INFO:root:current mean train loss 1779.8693287089304
INFO:root:current train perplexity4.062586784362793
INFO:root:current mean train loss 1779.640760330817
INFO:root:current train perplexity4.061432361602783
INFO:root:current mean train loss 1778.6065036728087
INFO:root:current train perplexity4.060708522796631
INFO:root:current mean train loss 1778.8615403183057
INFO:root:current train perplexity4.063685417175293
INFO:root:current mean train loss 1778.4205995305315
INFO:root:current train perplexity4.063271999359131

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.53s/it]
INFO:root:final mean train loss: 1778.2234988306366
INFO:root:final train perplexity: 4.065001010894775
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it]
INFO:root:eval mean loss: 2054.385669897634
INFO:root:eval perplexity: 5.267029285430908
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.86s/it]
INFO:root:eval mean loss: 2552.787278195645
INFO:root:eval perplexity: 8.06666374206543
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [8:47:18<14:13:58, 409.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1770.0024645006336
INFO:root:current train perplexity4.024493217468262
INFO:root:current mean train loss 1771.9378227146192
INFO:root:current train perplexity4.0195088386535645
INFO:root:current mean train loss 1771.4587429074475
INFO:root:current train perplexity4.0332512855529785
INFO:root:current mean train loss 1769.8242814171124
INFO:root:current train perplexity4.026768207550049
INFO:root:current mean train loss 1769.2030106556567
INFO:root:current train perplexity4.036703586578369
INFO:root:current mean train loss 1767.067262868848
INFO:root:current train perplexity4.039791584014893
INFO:root:current mean train loss 1769.2030994630354
INFO:root:current train perplexity4.038625240325928
INFO:root:current mean train loss 1769.4478005894703
INFO:root:current train perplexity4.0370917320251465
INFO:root:current mean train loss 1770.1224504902925
INFO:root:current train perplexity4.0388312339782715
INFO:root:current mean train loss 1773.54135401293
INFO:root:current train perplexity4.05014181137085
INFO:root:current mean train loss 1773.6866287998646
INFO:root:current train perplexity4.050337791442871
INFO:root:current mean train loss 1772.4724855179275
INFO:root:current train perplexity4.0471062660217285
INFO:root:current mean train loss 1773.304507364845
INFO:root:current train perplexity4.047811508178711
INFO:root:current mean train loss 1773.8697516873067
INFO:root:current train perplexity4.048564910888672
INFO:root:current mean train loss 1774.3112345764077
INFO:root:current train perplexity4.0501813888549805
INFO:root:current mean train loss 1774.2997219371675
INFO:root:current train perplexity4.052639961242676
INFO:root:current mean train loss 1774.7291203616198
INFO:root:current train perplexity4.052870750427246
INFO:root:current mean train loss 1774.8372493774002
INFO:root:current train perplexity4.055663108825684
INFO:root:current mean train loss 1775.6784852311857
INFO:root:current train perplexity4.056684970855713
INFO:root:current mean train loss 1775.9622680293028
INFO:root:current train perplexity4.056038856506348

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.21s/it]
INFO:root:final mean train loss: 1775.516870326486
INFO:root:final train perplexity: 4.056332588195801
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.76s/it]
INFO:root:eval mean loss: 2058.3099334933236
INFO:root:eval perplexity: 5.283771514892578
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.62s/it]
INFO:root:eval mean loss: 2556.432113322806
INFO:root:eval perplexity: 8.090742111206055
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [8:54:18<14:13:17, 412.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1760.063467172476
INFO:root:current train perplexity4.003276348114014
INFO:root:current mean train loss 1758.253672974272
INFO:root:current train perplexity4.0071702003479
INFO:root:current mean train loss 1761.5884095286995
INFO:root:current train perplexity4.01397180557251
INFO:root:current mean train loss 1762.586679600084
INFO:root:current train perplexity4.02151346206665
INFO:root:current mean train loss 1765.101212697699
INFO:root:current train perplexity4.023616313934326
INFO:root:current mean train loss 1761.4474401586956
INFO:root:current train perplexity4.015386581420898
INFO:root:current mean train loss 1763.5324648734284
INFO:root:current train perplexity4.020291328430176
INFO:root:current mean train loss 1763.2596105293437
INFO:root:current train perplexity4.020226001739502
INFO:root:current mean train loss 1765.252742814429
INFO:root:current train perplexity4.028153896331787
INFO:root:current mean train loss 1767.5499745512345
INFO:root:current train perplexity4.03267765045166
INFO:root:current mean train loss 1765.5321427580416
INFO:root:current train perplexity4.029636383056641
INFO:root:current mean train loss 1766.7646298860923
INFO:root:current train perplexity4.031013011932373
INFO:root:current mean train loss 1767.0532240745727
INFO:root:current train perplexity4.030482292175293
INFO:root:current mean train loss 1767.3604761777724
INFO:root:current train perplexity4.032589912414551
INFO:root:current mean train loss 1768.7560817378228
INFO:root:current train perplexity4.036410331726074
INFO:root:current mean train loss 1770.0566629521281
INFO:root:current train perplexity4.038287162780762
INFO:root:current mean train loss 1769.3019722115705
INFO:root:current train perplexity4.039181709289551
INFO:root:current mean train loss 1770.4795862450271
INFO:root:current train perplexity4.042811393737793
INFO:root:current mean train loss 1771.155070740101
INFO:root:current train perplexity4.0429911613464355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.81s/it]
INFO:root:final mean train loss: 1771.9994309233464
INFO:root:final train perplexity: 4.045096397399902
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.81s/it]
INFO:root:eval mean loss: 2053.8411990767677
INFO:root:eval perplexity: 5.264710426330566
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.49s/it]
INFO:root:eval mean loss: 2554.7518033507868
INFO:root:eval perplexity: 8.079630851745605
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [9:01:16<14:09:44, 414.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1700.4977416992188
INFO:root:current train perplexity3.9451067447662354
INFO:root:current mean train loss 1772.3668823242188
INFO:root:current train perplexity4.036020755767822
INFO:root:current mean train loss 1768.4493971604568
INFO:root:current train perplexity4.033924579620361
INFO:root:current mean train loss 1769.3491698426085
INFO:root:current train perplexity4.0252485275268555
INFO:root:current mean train loss 1768.9232976576861
INFO:root:current train perplexity4.021177291870117
INFO:root:current mean train loss 1770.2151376318743
INFO:root:current train perplexity4.019820213317871
INFO:root:current mean train loss 1767.3340301513672
INFO:root:current train perplexity4.019366264343262
INFO:root:current mean train loss 1768.421026369946
INFO:root:current train perplexity4.024722099304199
INFO:root:current mean train loss 1767.5893831158628
INFO:root:current train perplexity4.0238189697265625
INFO:root:current mean train loss 1767.494897918029
INFO:root:current train perplexity4.026242256164551
INFO:root:current mean train loss 1768.1012538122752
INFO:root:current train perplexity4.028162956237793
INFO:root:current mean train loss 1768.061722628046
INFO:root:current train perplexity4.030683517456055
INFO:root:current mean train loss 1767.6203422293759
INFO:root:current train perplexity4.0307536125183105
INFO:root:current mean train loss 1766.8235906665113
INFO:root:current train perplexity4.030398845672607
INFO:root:current mean train loss 1767.0850863890214
INFO:root:current train perplexity4.031265735626221
INFO:root:current mean train loss 1767.2714500528432
INFO:root:current train perplexity4.03159761428833
INFO:root:current mean train loss 1767.8951134373299
INFO:root:current train perplexity4.034004211425781
INFO:root:current mean train loss 1767.945228237179
INFO:root:current train perplexity4.034329891204834
INFO:root:current mean train loss 1768.6174155716346
INFO:root:current train perplexity4.03425931930542
INFO:root:current mean train loss 1768.9673222635777
INFO:root:current train perplexity4.0349578857421875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.68s/it]
INFO:root:final mean train loss: 1768.8749919666284
INFO:root:final train perplexity: 4.0351409912109375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.20s/it]
INFO:root:eval mean loss: 2055.7547087973735
INFO:root:eval perplexity: 5.27286434173584
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.54s/it]
INFO:root:eval mean loss: 2557.9627347905584
INFO:root:eval perplexity: 8.100874900817871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [9:08:08<14:01:07, 413.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1760.7112939453125
INFO:root:current train perplexity4.000020503997803
INFO:root:current mean train loss 1766.9476162109374
INFO:root:current train perplexity3.9929118156433105
INFO:root:current mean train loss 1764.2704144965278
INFO:root:current train perplexity3.9996261596679688
INFO:root:current mean train loss 1763.865174278846
INFO:root:current train perplexity4.002763748168945
INFO:root:current mean train loss 1761.9939157284007
INFO:root:current train perplexity4.007719993591309
INFO:root:current mean train loss 1762.2885653831845
INFO:root:current train perplexity4.009113311767578
INFO:root:current mean train loss 1761.171304296875
INFO:root:current train perplexity4.009007930755615
INFO:root:current mean train loss 1760.7686228785021
INFO:root:current train perplexity4.008321762084961
INFO:root:current mean train loss 1760.4870237038351
INFO:root:current train perplexity4.006525039672852
INFO:root:current mean train loss 1763.518888038429
INFO:root:current train perplexity4.008110046386719
INFO:root:current mean train loss 1765.3932937547638
INFO:root:current train perplexity4.010448455810547
INFO:root:current mean train loss 1764.9406159939235
INFO:root:current train perplexity4.010348320007324
INFO:root:current mean train loss 1765.1038271285076
INFO:root:current train perplexity4.013681411743164
INFO:root:current mean train loss 1765.9858859080189
INFO:root:current train perplexity4.018357276916504
INFO:root:current mean train loss 1765.8963603344298
INFO:root:current train perplexity4.021170616149902
INFO:root:current mean train loss 1765.7461455398309
INFO:root:current train perplexity4.0220770835876465
INFO:root:current mean train loss 1766.1923249699519
INFO:root:current train perplexity4.020527362823486
INFO:root:current mean train loss 1766.4583715466486
INFO:root:current train perplexity4.021084308624268
INFO:root:current mean train loss 1765.3707758320847
INFO:root:current train perplexity4.020025253295898
INFO:root:current mean train loss 1765.617671595982
INFO:root:current train perplexity4.021605968475342

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.36s/it]
INFO:root:final mean train loss: 1764.611214518968
INFO:root:final train perplexity: 4.021595001220703
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.69s/it]
INFO:root:eval mean loss: 2057.063378300227
INFO:root:eval perplexity: 5.27844762802124
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.52s/it]
INFO:root:eval mean loss: 2559.5078774310173
INFO:root:eval perplexity: 8.11111831665039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [9:14:57<13:51:17, 412.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1749.6045532226562
INFO:root:current train perplexity4.022441864013672
INFO:root:current mean train loss 1740.828828193772
INFO:root:current train perplexity3.9879305362701416
INFO:root:current mean train loss 1753.3088419260073
INFO:root:current train perplexity3.9980854988098145
INFO:root:current mean train loss 1753.5160169099506
INFO:root:current train perplexity4.001421928405762
INFO:root:current mean train loss 1756.5375769429618
INFO:root:current train perplexity4.008882999420166
INFO:root:current mean train loss 1755.6842212184329
INFO:root:current train perplexity4.001976490020752
INFO:root:current mean train loss 1755.6828502999658
INFO:root:current train perplexity4.004901885986328
INFO:root:current mean train loss 1754.5416216991662
INFO:root:current train perplexity3.9998207092285156
INFO:root:current mean train loss 1756.4985816937444
INFO:root:current train perplexity4.003260135650635
INFO:root:current mean train loss 1757.2182801200072
INFO:root:current train perplexity4.004470348358154
INFO:root:current mean train loss 1757.5595369247467
INFO:root:current train perplexity4.006743431091309
INFO:root:current mean train loss 1759.3501400922519
INFO:root:current train perplexity4.007934093475342
INFO:root:current mean train loss 1758.2471001912238
INFO:root:current train perplexity4.003818988800049
INFO:root:current mean train loss 1759.352699882405
INFO:root:current train perplexity4.004892826080322
INFO:root:current mean train loss 1759.6939424681432
INFO:root:current train perplexity4.0053887367248535
INFO:root:current mean train loss 1759.2490004800482
INFO:root:current train perplexity4.005461692810059
INFO:root:current mean train loss 1760.4109571412769
INFO:root:current train perplexity4.008832931518555
INFO:root:current mean train loss 1760.7370495451305
INFO:root:current train perplexity4.009491443634033
INFO:root:current mean train loss 1760.4148043985606
INFO:root:current train perplexity4.008983135223389
INFO:root:current mean train loss 1762.2822859633472
INFO:root:current train perplexity4.011867046356201

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:48<00:00, 348.55s/it]
INFO:root:final mean train loss: 1761.8834362712944
INFO:root:final train perplexity: 4.0129523277282715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.90s/it]
INFO:root:eval mean loss: 2058.5424982165614
INFO:root:eval perplexity: 5.284765243530273
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.58s/it]
INFO:root:eval mean loss: 2562.689881669714
INFO:root:eval perplexity: 8.132255554199219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [9:21:41<13:39:37, 409.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1740.4214363744704
INFO:root:current train perplexity3.9719791412353516
INFO:root:current mean train loss 1744.839041463984
INFO:root:current train perplexity3.986396551132202
INFO:root:current mean train loss 1750.124077638604
INFO:root:current train perplexity3.9811148643493652
INFO:root:current mean train loss 1752.1586026587527
INFO:root:current train perplexity3.9790964126586914
INFO:root:current mean train loss 1750.7339383127382
INFO:root:current train perplexity3.982646942138672
INFO:root:current mean train loss 1751.906499818314
INFO:root:current train perplexity3.988626003265381
INFO:root:current mean train loss 1751.67197317491
INFO:root:current train perplexity3.993605375289917
INFO:root:current mean train loss 1752.9689290042922
INFO:root:current train perplexity3.996267557144165
INFO:root:current mean train loss 1755.0772328493342
INFO:root:current train perplexity3.995166301727295
INFO:root:current mean train loss 1755.133707342854
INFO:root:current train perplexity3.9953930377960205
INFO:root:current mean train loss 1755.7286726219459
INFO:root:current train perplexity3.999464511871338
INFO:root:current mean train loss 1756.5418437862313
INFO:root:current train perplexity3.9984042644500732
INFO:root:current mean train loss 1757.5555868838117
INFO:root:current train perplexity4.001552104949951
INFO:root:current mean train loss 1758.1860634506934
INFO:root:current train perplexity4.0026068687438965
INFO:root:current mean train loss 1758.8431076039346
INFO:root:current train perplexity4.003654479980469
INFO:root:current mean train loss 1757.9171666407753
INFO:root:current train perplexity4.004212379455566
INFO:root:current mean train loss 1758.4951702391547
INFO:root:current train perplexity4.0044026374816895
INFO:root:current mean train loss 1759.4984486174894
INFO:root:current train perplexity4.005169868469238
INFO:root:current mean train loss 1760.6222917332068
INFO:root:current train perplexity4.006031036376953
INFO:root:current mean train loss 1759.6286776875158
INFO:root:current train perplexity4.004405975341797

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.30s/it]
INFO:root:final mean train loss: 1759.0423494109107
INFO:root:final train perplexity: 4.003970623016357
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.58s/it]
INFO:root:eval mean loss: 2055.896672242077
INFO:root:eval perplexity: 5.273469924926758
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it]
INFO:root:eval mean loss: 2560.3755726915724
INFO:root:eval perplexity: 8.116877555847168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [9:28:39<13:37:17, 412.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1728.5523247969777
INFO:root:current train perplexity3.9490435123443604
INFO:root:current mean train loss 1744.8325112082741
INFO:root:current train perplexity3.9520010948181152
INFO:root:current mean train loss 1749.9842967157779
INFO:root:current train perplexity3.961010456085205
INFO:root:current mean train loss 1751.5571821496842
INFO:root:current train perplexity3.9740729331970215
INFO:root:current mean train loss 1752.7214304178704
INFO:root:current train perplexity3.97887921333313
INFO:root:current mean train loss 1754.7764116923015
INFO:root:current train perplexity3.9839842319488525
INFO:root:current mean train loss 1754.1456044214012
INFO:root:current train perplexity3.97914719581604
INFO:root:current mean train loss 1755.1742805402303
INFO:root:current train perplexity3.9780590534210205
INFO:root:current mean train loss 1755.148200605558
INFO:root:current train perplexity3.9780192375183105
INFO:root:current mean train loss 1755.182288373103
INFO:root:current train perplexity3.9797890186309814
INFO:root:current mean train loss 1756.9251091825918
INFO:root:current train perplexity3.986294984817505
INFO:root:current mean train loss 1756.1268560707974
INFO:root:current train perplexity3.985405445098877
INFO:root:current mean train loss 1755.7788621669279
INFO:root:current train perplexity3.9849421977996826
INFO:root:current mean train loss 1755.9572917139808
INFO:root:current train perplexity3.985114336013794
INFO:root:current mean train loss 1756.1146005356538
INFO:root:current train perplexity3.9864442348480225
INFO:root:current mean train loss 1756.2295471811053
INFO:root:current train perplexity3.9875648021698
INFO:root:current mean train loss 1756.1169792666924
INFO:root:current train perplexity3.9866232872009277
INFO:root:current mean train loss 1755.8488229287636
INFO:root:current train perplexity3.9872260093688965
INFO:root:current mean train loss 1755.8621627710013
INFO:root:current train perplexity3.988168716430664
INFO:root:current mean train loss 1755.4254572941707
INFO:root:current train perplexity3.990504503250122

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.91s/it]
INFO:root:final mean train loss: 1754.9519058973935
INFO:root:final train perplexity: 3.991075038909912
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.66s/it]
INFO:root:eval mean loss: 2058.752735760195
INFO:root:eval perplexity: 5.285665035247803
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.20s/it]
INFO:root:eval mean loss: 2564.2253569474456
INFO:root:eval perplexity: 8.142472267150879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [9:35:38<13:34:30, 414.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1760.9474769510248
INFO:root:current train perplexity3.9311068058013916
INFO:root:current mean train loss 1754.3878395199158
INFO:root:current train perplexity3.935546875
INFO:root:current mean train loss 1748.3876494840551
INFO:root:current train perplexity3.9437971115112305
INFO:root:current mean train loss 1747.3959668962707
INFO:root:current train perplexity3.950505018234253
INFO:root:current mean train loss 1745.193675074084
INFO:root:current train perplexity3.944632053375244
INFO:root:current mean train loss 1745.183971900361
INFO:root:current train perplexity3.9439964294433594
INFO:root:current mean train loss 1744.3359086117875
INFO:root:current train perplexity3.9460482597351074
INFO:root:current mean train loss 1746.1460051759043
INFO:root:current train perplexity3.952449083328247
INFO:root:current mean train loss 1747.2482141919793
INFO:root:current train perplexity3.955624580383301
INFO:root:current mean train loss 1746.1051900658122
INFO:root:current train perplexity3.9578664302825928
INFO:root:current mean train loss 1747.276618587567
INFO:root:current train perplexity3.9619903564453125
INFO:root:current mean train loss 1749.1299002072637
INFO:root:current train perplexity3.9667999744415283
INFO:root:current mean train loss 1748.1787941114717
INFO:root:current train perplexity3.968252420425415
INFO:root:current mean train loss 1749.277089619414
INFO:root:current train perplexity3.974226951599121
INFO:root:current mean train loss 1750.5079352244065
INFO:root:current train perplexity3.9774014949798584
INFO:root:current mean train loss 1750.5292590968054
INFO:root:current train perplexity3.977358818054199
INFO:root:current mean train loss 1752.598539439166
INFO:root:current train perplexity3.9813740253448486
INFO:root:current mean train loss 1753.4393313950955
INFO:root:current train perplexity3.9826090335845947
INFO:root:current mean train loss 1753.4403947365706
INFO:root:current train perplexity3.9826366901397705

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.84s/it]
INFO:root:final mean train loss: 1751.9838700364228
INFO:root:final train perplexity: 3.981743574142456
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.57s/it]
INFO:root:eval mean loss: 2064.861783940741
INFO:root:eval perplexity: 5.311843395233154
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it]
INFO:root:eval mean loss: 2570.6288391546154
INFO:root:eval perplexity: 8.185226440429688
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [9:42:27<13:24:51, 412.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1798.3405395507812
INFO:root:current train perplexity4.034681797027588
INFO:root:current mean train loss 1739.069874156605
INFO:root:current train perplexity3.9495980739593506
INFO:root:current mean train loss 1736.8933617001487
INFO:root:current train perplexity3.948305368423462
INFO:root:current mean train loss 1739.2852724136844
INFO:root:current train perplexity3.948914051055908
INFO:root:current mean train loss 1740.1516997546685
INFO:root:current train perplexity3.9508860111236572
INFO:root:current mean train loss 1743.9136357326133
INFO:root:current train perplexity3.9565773010253906
INFO:root:current mean train loss 1740.7434960537269
INFO:root:current train perplexity3.9533538818359375
INFO:root:current mean train loss 1742.9221700319101
INFO:root:current train perplexity3.9584860801696777
INFO:root:current mean train loss 1742.1018043800636
INFO:root:current train perplexity3.956552267074585
INFO:root:current mean train loss 1745.4460290929774
INFO:root:current train perplexity3.9600274562835693
INFO:root:current mean train loss 1745.1065131159112
INFO:root:current train perplexity3.959775924682617
INFO:root:current mean train loss 1745.9597195462063
INFO:root:current train perplexity3.961919069290161
INFO:root:current mean train loss 1746.4360688516917
INFO:root:current train perplexity3.9643521308898926
INFO:root:current mean train loss 1746.8696293721673
INFO:root:current train perplexity3.9678590297698975
INFO:root:current mean train loss 1748.0477943366302
INFO:root:current train perplexity3.9698081016540527
INFO:root:current mean train loss 1749.0625335491256
INFO:root:current train perplexity3.9718072414398193
INFO:root:current mean train loss 1749.8631361303862
INFO:root:current train perplexity3.9736745357513428
INFO:root:current mean train loss 1749.6456847787601
INFO:root:current train perplexity3.972484827041626
INFO:root:current mean train loss 1749.875420299551
INFO:root:current train perplexity3.973325490951538
INFO:root:current mean train loss 1750.255828697644
INFO:root:current train perplexity3.9743595123291016

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.74s/it]
INFO:root:final mean train loss: 1749.5062133050362
INFO:root:final train perplexity: 3.973970651626587
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.85s/it]
INFO:root:eval mean loss: 2067.0409013464096
INFO:root:eval perplexity: 5.321212291717529
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.51s/it]
INFO:root:eval mean loss: 2575.275950330369
INFO:root:eval perplexity: 8.21639347076416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [9:49:12<13:13:40, 410.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1764.9495307074653
INFO:root:current train perplexity4.025332927703857
INFO:root:current mean train loss 1749.5394258273868
INFO:root:current train perplexity3.9637765884399414
INFO:root:current mean train loss 1742.9672561174973
INFO:root:current train perplexity3.964308261871338
INFO:root:current mean train loss 1741.9549344030725
INFO:root:current train perplexity3.954716444015503
INFO:root:current mean train loss 1743.6635416285494
INFO:root:current train perplexity3.9480795860290527
INFO:root:current mean train loss 1743.566841487414
INFO:root:current train perplexity3.9519519805908203
INFO:root:current mean train loss 1743.4965656773325
INFO:root:current train perplexity3.9515199661254883
INFO:root:current mean train loss 1745.221676833036
INFO:root:current train perplexity3.9543068408966064
INFO:root:current mean train loss 1746.6731835288033
INFO:root:current train perplexity3.9543182849884033
INFO:root:current mean train loss 1745.33465622261
INFO:root:current train perplexity3.9557509422302246
INFO:root:current mean train loss 1745.4465506757015
INFO:root:current train perplexity3.9550018310546875
INFO:root:current mean train loss 1745.0343837518024
INFO:root:current train perplexity3.9531376361846924
INFO:root:current mean train loss 1743.9984095044124
INFO:root:current train perplexity3.9525136947631836
INFO:root:current mean train loss 1745.1722939210272
INFO:root:current train perplexity3.9546053409576416
INFO:root:current mean train loss 1745.3557554056533
INFO:root:current train perplexity3.9556915760040283
INFO:root:current mean train loss 1745.4121208865422
INFO:root:current train perplexity3.9555275440216064
INFO:root:current mean train loss 1745.9303408425208
INFO:root:current train perplexity3.9570796489715576
INFO:root:current mean train loss 1746.2076606154096
INFO:root:current train perplexity3.9586706161499023
INFO:root:current mean train loss 1746.083537184742
INFO:root:current train perplexity3.9594063758850098
INFO:root:current mean train loss 1746.2850476093222
INFO:root:current train perplexity3.959587574005127

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.83s/it]
INFO:root:final mean train loss: 1745.607396328263
INFO:root:final train perplexity: 3.96177077293396
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.47s/it]
INFO:root:eval mean loss: 2067.0382638484875
INFO:root:eval perplexity: 5.321202278137207
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.04s/it]
INFO:root:eval mean loss: 2575.0918514170544
INFO:root:eval perplexity: 8.215157508850098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [9:56:11<13:11:29, 412.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1730.4382601651278
INFO:root:current train perplexity3.907379150390625
INFO:root:current mean train loss 1740.4659457736545
INFO:root:current train perplexity3.931450366973877
INFO:root:current mean train loss 1741.5290462306289
INFO:root:current train perplexity3.9428446292877197
INFO:root:current mean train loss 1743.2813830708349
INFO:root:current train perplexity3.946338415145874
INFO:root:current mean train loss 1743.2399674149246
INFO:root:current train perplexity3.941330671310425
INFO:root:current mean train loss 1743.4098044002758
INFO:root:current train perplexity3.9413869380950928
INFO:root:current mean train loss 1745.111663439259
INFO:root:current train perplexity3.950185775756836
INFO:root:current mean train loss 1742.2780290829237
INFO:root:current train perplexity3.943493366241455
INFO:root:current mean train loss 1743.433979052503
INFO:root:current train perplexity3.9425504207611084
INFO:root:current mean train loss 1742.2652078402245
INFO:root:current train perplexity3.9442710876464844
INFO:root:current mean train loss 1741.6547579125884
INFO:root:current train perplexity3.9432432651519775
INFO:root:current mean train loss 1744.0782401344993
INFO:root:current train perplexity3.9491255283355713
INFO:root:current mean train loss 1745.5607521572297
INFO:root:current train perplexity3.952353000640869
INFO:root:current mean train loss 1743.2992726280577
INFO:root:current train perplexity3.9478254318237305
INFO:root:current mean train loss 1744.311498583849
INFO:root:current train perplexity3.9489970207214355
INFO:root:current mean train loss 1743.1634442423292
INFO:root:current train perplexity3.9483120441436768
INFO:root:current mean train loss 1742.7515405065533
INFO:root:current train perplexity3.949779987335205
INFO:root:current mean train loss 1743.288314819336
INFO:root:current train perplexity3.9513025283813477
INFO:root:current mean train loss 1743.4145300610721
INFO:root:current train perplexity3.9541983604431152
INFO:root:current mean train loss 1743.634409649382
INFO:root:current train perplexity3.953888416290283

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:55<00:00, 355.92s/it]
INFO:root:final mean train loss: 1743.008696417104
INFO:root:final train perplexity: 3.9536592960357666
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.41s/it]
INFO:root:eval mean loss: 2065.6890838839486
INFO:root:eval perplexity: 5.315398693084717
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it]
INFO:root:eval mean loss: 2574.8934235268453
INFO:root:eval perplexity: 8.213823318481445
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [10:03:03<13:04:03, 412.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1739.8730048507941
INFO:root:current train perplexity3.9230666160583496
INFO:root:current mean train loss 1734.2564879233794
INFO:root:current train perplexity3.9147915840148926
INFO:root:current mean train loss 1737.1212653967611
INFO:root:current train perplexity3.921379566192627
INFO:root:current mean train loss 1733.1948925240217
INFO:root:current train perplexity3.914371967315674
INFO:root:current mean train loss 1732.2855780678044
INFO:root:current train perplexity3.9222593307495117
INFO:root:current mean train loss 1735.434822504108
INFO:root:current train perplexity3.9266161918640137
INFO:root:current mean train loss 1733.8752428478986
INFO:root:current train perplexity3.9247279167175293
INFO:root:current mean train loss 1735.0194914688732
INFO:root:current train perplexity3.92702579498291
INFO:root:current mean train loss 1734.8357173197498
INFO:root:current train perplexity3.9247851371765137
INFO:root:current mean train loss 1734.686970435866
INFO:root:current train perplexity3.924264430999756
INFO:root:current mean train loss 1736.3559168780557
INFO:root:current train perplexity3.9289541244506836
INFO:root:current mean train loss 1737.1018904391083
INFO:root:current train perplexity3.93070912361145
INFO:root:current mean train loss 1737.5309038275675
INFO:root:current train perplexity3.9321796894073486
INFO:root:current mean train loss 1737.6162368583819
INFO:root:current train perplexity3.9337470531463623
INFO:root:current mean train loss 1737.6077032800736
INFO:root:current train perplexity3.933941602706909
INFO:root:current mean train loss 1737.9593791289637
INFO:root:current train perplexity3.935445547103882
INFO:root:current mean train loss 1738.0953660904106
INFO:root:current train perplexity3.935760259628296
INFO:root:current mean train loss 1739.3415360978759
INFO:root:current train perplexity3.9390885829925537
INFO:root:current mean train loss 1739.108582428487
INFO:root:current train perplexity3.940594434738159
INFO:root:current mean train loss 1740.1108018096036
INFO:root:current train perplexity3.9429397583007812

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.51s/it]
INFO:root:final mean train loss: 1739.6568127669173
INFO:root:final train perplexity: 3.9432215690612793
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.24s/it]
INFO:root:eval mean loss: 2063.910603841146
INFO:root:eval perplexity: 5.3077592849731445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.31s/it]
INFO:root:eval mean loss: 2572.17430385292
INFO:root:eval perplexity: 8.195578575134277
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [10:09:49<12:53:35, 410.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1722.6482230944512
INFO:root:current train perplexity3.9033939838409424
INFO:root:current mean train loss 1728.8273603460761
INFO:root:current train perplexity3.901658773422241
INFO:root:current mean train loss 1725.9846244098471
INFO:root:current train perplexity3.9087469577789307
INFO:root:current mean train loss 1729.990099387194
INFO:root:current train perplexity3.9123599529266357
INFO:root:current mean train loss 1731.5440165627451
INFO:root:current train perplexity3.9106061458587646
INFO:root:current mean train loss 1732.2659295421984
INFO:root:current train perplexity3.9067587852478027
INFO:root:current mean train loss 1733.0573548623595
INFO:root:current train perplexity3.912177085876465
INFO:root:current mean train loss 1734.8574182662376
INFO:root:current train perplexity3.9136388301849365
INFO:root:current mean train loss 1733.5731594633132
INFO:root:current train perplexity3.9147019386291504
INFO:root:current mean train loss 1731.7099163780915
INFO:root:current train perplexity3.9142534732818604
INFO:root:current mean train loss 1733.6866519623652
INFO:root:current train perplexity3.9222869873046875
INFO:root:current mean train loss 1732.7355110414567
INFO:root:current train perplexity3.9237143993377686
INFO:root:current mean train loss 1732.7070803455717
INFO:root:current train perplexity3.926516056060791
INFO:root:current mean train loss 1732.7357290237494
INFO:root:current train perplexity3.9253008365631104
INFO:root:current mean train loss 1733.1284806557373
INFO:root:current train perplexity3.926490306854248
INFO:root:current mean train loss 1734.085114879149
INFO:root:current train perplexity3.930000066757202
INFO:root:current mean train loss 1734.342048945103
INFO:root:current train perplexity3.930347442626953
INFO:root:current mean train loss 1735.322646391003
INFO:root:current train perplexity3.930637836456299
INFO:root:current mean train loss 1736.4696133322102
INFO:root:current train perplexity3.932157278060913
INFO:root:current mean train loss 1736.8925743604455
INFO:root:current train perplexity3.9332377910614014

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.70s/it]
INFO:root:final mean train loss: 1736.4371517641162
INFO:root:final train perplexity: 3.9332213401794434
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.12s/it]
INFO:root:eval mean loss: 2064.4744388228614
INFO:root:eval perplexity: 5.310180187225342
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.04s/it]
INFO:root:eval mean loss: 2574.649246107602
INFO:root:eval perplexity: 8.21218204498291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [10:16:48<12:51:24, 413.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1718.6357254831414
INFO:root:current train perplexity3.910994052886963
INFO:root:current mean train loss 1725.7059125851363
INFO:root:current train perplexity3.897580862045288
INFO:root:current mean train loss 1719.6732852224577
INFO:root:current train perplexity3.887599229812622
INFO:root:current mean train loss 1722.402704089201
INFO:root:current train perplexity3.8927721977233887
INFO:root:current mean train loss 1724.6394506589331
INFO:root:current train perplexity3.895923614501953
INFO:root:current mean train loss 1723.4413949661896
INFO:root:current train perplexity3.8965699672698975
INFO:root:current mean train loss 1726.2641443485836
INFO:root:current train perplexity3.9030120372772217
INFO:root:current mean train loss 1726.1730622297564
INFO:root:current train perplexity3.9055984020233154
INFO:root:current mean train loss 1727.529335064595
INFO:root:current train perplexity3.9068076610565186
INFO:root:current mean train loss 1726.7720138779837
INFO:root:current train perplexity3.9048192501068115
INFO:root:current mean train loss 1728.8449797329838
INFO:root:current train perplexity3.910642623901367
INFO:root:current mean train loss 1728.7971192427758
INFO:root:current train perplexity3.911769151687622
INFO:root:current mean train loss 1728.6694764833192
INFO:root:current train perplexity3.9125804901123047
INFO:root:current mean train loss 1728.8862001918123
INFO:root:current train perplexity3.9125735759735107
INFO:root:current mean train loss 1730.2637794928407
INFO:root:current train perplexity3.915522336959839
INFO:root:current mean train loss 1731.1313057926382
INFO:root:current train perplexity3.9167428016662598
INFO:root:current mean train loss 1732.4755347327848
INFO:root:current train perplexity3.9192092418670654
INFO:root:current mean train loss 1733.4815757475192
INFO:root:current train perplexity3.92238187789917
INFO:root:current mean train loss 1733.990822760348
INFO:root:current train perplexity3.9236066341400146

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:54<00:00, 354.77s/it]
INFO:root:final mean train loss: 1733.4925054491498
INFO:root:final train perplexity: 3.924097776412964
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.19s/it]
INFO:root:eval mean loss: 2065.891641819731
INFO:root:eval perplexity: 5.316269397735596
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.21s/it]
INFO:root:eval mean loss: 2577.9716060990136
INFO:root:eval perplexity: 8.234527587890625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [10:23:41<12:44:02, 413.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1636.4775288899739
INFO:root:current train perplexity3.7584662437438965
INFO:root:current mean train loss 1715.0260118756976
INFO:root:current train perplexity3.8903307914733887
INFO:root:current mean train loss 1721.5165174952094
INFO:root:current train perplexity3.886862277984619
INFO:root:current mean train loss 1725.0226628230168
INFO:root:current train perplexity3.8986780643463135
INFO:root:current mean train loss 1726.244170846291
INFO:root:current train perplexity3.903123617172241
INFO:root:current mean train loss 1726.816731452942
INFO:root:current train perplexity3.901252269744873
INFO:root:current mean train loss 1727.857239367915
INFO:root:current train perplexity3.8995885848999023
INFO:root:current mean train loss 1728.1495280748004
INFO:root:current train perplexity3.899817943572998
INFO:root:current mean train loss 1730.707124757062
INFO:root:current train perplexity3.901010036468506
INFO:root:current mean train loss 1730.3049387346234
INFO:root:current train perplexity3.9057347774505615
INFO:root:current mean train loss 1729.8400628010745
INFO:root:current train perplexity3.9075894355773926
INFO:root:current mean train loss 1730.0904465270557
INFO:root:current train perplexity3.9103152751922607
INFO:root:current mean train loss 1729.3279499519776
INFO:root:current train perplexity3.9113125801086426
INFO:root:current mean train loss 1728.6390009624201
INFO:root:current train perplexity3.911080837249756
INFO:root:current mean train loss 1728.9419697445446
INFO:root:current train perplexity3.9148125648498535
INFO:root:current mean train loss 1729.6202637203155
INFO:root:current train perplexity3.914527416229248
INFO:root:current mean train loss 1730.970426952277
INFO:root:current train perplexity3.9158737659454346
INFO:root:current mean train loss 1730.9262716703327
INFO:root:current train perplexity3.9161059856414795
INFO:root:current mean train loss 1730.715544913252
INFO:root:current train perplexity3.9145846366882324
INFO:root:current mean train loss 1730.727814742212
INFO:root:current train perplexity3.915083169937134

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.79s/it]
INFO:root:final mean train loss: 1730.5563611190726
INFO:root:final train perplexity: 3.9150216579437256
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.20s/it]
INFO:root:eval mean loss: 2065.2443726451684
INFO:root:eval perplexity: 5.313488006591797
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.07s/it]
INFO:root:eval mean loss: 2576.2553676307625
INFO:root:eval perplexity: 8.222977638244629
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [10:30:31<12:35:39, 412.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1755.5944361193426
INFO:root:current train perplexity3.9656989574432373
INFO:root:current mean train loss 1738.1410432564196
INFO:root:current train perplexity3.9194657802581787
INFO:root:current mean train loss 1730.6216033535754
INFO:root:current train perplexity3.9118010997772217
INFO:root:current mean train loss 1722.6808091369444
INFO:root:current train perplexity3.903019428253174
INFO:root:current mean train loss 1720.9406712672094
INFO:root:current train perplexity3.89745831489563
INFO:root:current mean train loss 1723.2796077043213
INFO:root:current train perplexity3.8975303173065186
INFO:root:current mean train loss 1726.2749609530256
INFO:root:current train perplexity3.9010002613067627
INFO:root:current mean train loss 1727.2492617174105
INFO:root:current train perplexity3.897810459136963
INFO:root:current mean train loss 1727.3284415876622
INFO:root:current train perplexity3.9006645679473877
INFO:root:current mean train loss 1727.0448007244854
INFO:root:current train perplexity3.8972041606903076
INFO:root:current mean train loss 1726.479512235977
INFO:root:current train perplexity3.8976497650146484
INFO:root:current mean train loss 1728.7697245730458
INFO:root:current train perplexity3.902479410171509
INFO:root:current mean train loss 1728.1320751118797
INFO:root:current train perplexity3.9014933109283447
INFO:root:current mean train loss 1727.932284043013
INFO:root:current train perplexity3.8990094661712646
INFO:root:current mean train loss 1727.1675950217864
INFO:root:current train perplexity3.901144027709961
INFO:root:current mean train loss 1727.2628141095079
INFO:root:current train perplexity3.9022536277770996
INFO:root:current mean train loss 1727.2937892962996
INFO:root:current train perplexity3.903489351272583
INFO:root:current mean train loss 1728.0236939959198
INFO:root:current train perplexity3.9057934284210205
INFO:root:current mean train loss 1727.39614459372
INFO:root:current train perplexity3.9048569202423096
INFO:root:current mean train loss 1728.2692879320366
INFO:root:current train perplexity3.9062652587890625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:49<00:00, 349.26s/it]
INFO:root:final mean train loss: 1727.9995737080615
INFO:root:final train perplexity: 3.907134771347046
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.71s/it]
INFO:root:eval mean loss: 2069.0624562797816
INFO:root:eval perplexity: 5.329920291900635
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.57s/it]
INFO:root:eval mean loss: 2580.6292668335827
INFO:root:eval perplexity: 8.25244426727295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [10:37:16<12:25:02, 410.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1711.12939453125
INFO:root:current train perplexity3.8655881881713867
INFO:root:current mean train loss 1714.481963693279
INFO:root:current train perplexity3.8554906845092773
INFO:root:current mean train loss 1721.1452850093685
INFO:root:current train perplexity3.874133586883545
INFO:root:current mean train loss 1723.6604617785856
INFO:root:current train perplexity3.8854451179504395
INFO:root:current mean train loss 1721.419664870463
INFO:root:current train perplexity3.8816592693328857
INFO:root:current mean train loss 1720.0083586863982
INFO:root:current train perplexity3.87988543510437
INFO:root:current mean train loss 1715.9756785295326
INFO:root:current train perplexity3.8778023719787598
INFO:root:current mean train loss 1717.6282405904408
INFO:root:current train perplexity3.879859209060669
INFO:root:current mean train loss 1720.0714169044584
INFO:root:current train perplexity3.8838002681732178
INFO:root:current mean train loss 1722.727004198393
INFO:root:current train perplexity3.89005708694458
INFO:root:current mean train loss 1724.7161733361093
INFO:root:current train perplexity3.8916127681732178
INFO:root:current mean train loss 1723.5579325890667
INFO:root:current train perplexity3.8906614780426025
INFO:root:current mean train loss 1723.3116678449162
INFO:root:current train perplexity3.888632297515869
INFO:root:current mean train loss 1724.9737948776178
INFO:root:current train perplexity3.8905816078186035
INFO:root:current mean train loss 1724.9978824261973
INFO:root:current train perplexity3.892864227294922
INFO:root:current mean train loss 1725.3416698302829
INFO:root:current train perplexity3.894392967224121
INFO:root:current mean train loss 1725.535377326307
INFO:root:current train perplexity3.8942649364471436
INFO:root:current mean train loss 1725.299061358999
INFO:root:current train perplexity3.8954145908355713
INFO:root:current mean train loss 1724.8448130565243
INFO:root:current train perplexity3.894949197769165
INFO:root:current mean train loss 1724.0856706515367
INFO:root:current train perplexity3.8952696323394775

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.70s/it]
INFO:root:final mean train loss: 1724.2978806488452
INFO:root:final train perplexity: 3.8957457542419434
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.56s/it]
INFO:root:eval mean loss: 2069.3815519725176
INFO:root:eval perplexity: 5.331295967102051
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.79s/it]
INFO:root:eval mean loss: 2582.9476781533963
INFO:root:eval perplexity: 8.268106460571289
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [10:44:03<12:16:09, 408.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1726.5472334604415
INFO:root:current train perplexity3.859314203262329
INFO:root:current mean train loss 1723.1289721529909
INFO:root:current train perplexity3.858549118041992
INFO:root:current mean train loss 1723.1430603723563
INFO:root:current train perplexity3.8690223693847656
INFO:root:current mean train loss 1719.3522589397169
INFO:root:current train perplexity3.8612680435180664
INFO:root:current mean train loss 1719.162124139444
INFO:root:current train perplexity3.8675613403320312
INFO:root:current mean train loss 1718.3761068720166
INFO:root:current train perplexity3.8689677715301514
INFO:root:current mean train loss 1718.7797435455552
INFO:root:current train perplexity3.876455068588257
INFO:root:current mean train loss 1718.7363124462443
INFO:root:current train perplexity3.87451434135437
INFO:root:current mean train loss 1717.6629872062392
INFO:root:current train perplexity3.8742427825927734
INFO:root:current mean train loss 1716.4221299152632
INFO:root:current train perplexity3.876877546310425
INFO:root:current mean train loss 1719.0370065970794
INFO:root:current train perplexity3.8804492950439453
INFO:root:current mean train loss 1719.9229058276346
INFO:root:current train perplexity3.8817379474639893
INFO:root:current mean train loss 1719.682105709991
INFO:root:current train perplexity3.881685495376587
INFO:root:current mean train loss 1721.4145240028029
INFO:root:current train perplexity3.8834428787231445
INFO:root:current mean train loss 1720.6695901241028
INFO:root:current train perplexity3.881099224090576
INFO:root:current mean train loss 1720.3892035798544
INFO:root:current train perplexity3.8804779052734375
INFO:root:current mean train loss 1720.6701294605946
INFO:root:current train perplexity3.883204936981201
INFO:root:current mean train loss 1721.3801849070965
INFO:root:current train perplexity3.884795904159546
INFO:root:current mean train loss 1722.2752431970864
INFO:root:current train perplexity3.88667893409729
INFO:root:current mean train loss 1722.4034063151705
INFO:root:current train perplexity3.888498306274414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.13s/it]
INFO:root:final mean train loss: 1721.893774851127
INFO:root:final train perplexity: 3.8883652687072754
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.64s/it]
INFO:root:eval mean loss: 2069.405065658245
INFO:root:eval perplexity: 5.331397533416748
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.88s/it]
INFO:root:eval mean loss: 2582.214755010943
INFO:root:eval perplexity: 8.263154029846191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [10:51:00<12:13:33, 411.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1712.0703674316405
INFO:root:current train perplexity3.8402247428894043
INFO:root:current mean train loss 1703.8820353190104
INFO:root:current train perplexity3.8451027870178223
INFO:root:current mean train loss 1708.6241141183036
INFO:root:current train perplexity3.8458058834075928
INFO:root:current mean train loss 1709.5382539447985
INFO:root:current train perplexity3.8494207859039307
INFO:root:current mean train loss 1709.2497830708821
INFO:root:current train perplexity3.849069833755493
INFO:root:current mean train loss 1710.5829983415274
INFO:root:current train perplexity3.852304458618164
INFO:root:current mean train loss 1711.553284588982
INFO:root:current train perplexity3.8561620712280273
INFO:root:current mean train loss 1711.719280849359
INFO:root:current train perplexity3.8555963039398193
INFO:root:current mean train loss 1712.7287107987838
INFO:root:current train perplexity3.8600881099700928
INFO:root:current mean train loss 1712.4573609644053
INFO:root:current train perplexity3.8623476028442383
INFO:root:current mean train loss 1714.0064887152778
INFO:root:current train perplexity3.865208387374878
INFO:root:current mean train loss 1713.6460856809454
INFO:root:current train perplexity3.8654379844665527
INFO:root:current mean train loss 1714.9023621559143
INFO:root:current train perplexity3.866185426712036
INFO:root:current mean train loss 1716.1559945369113
INFO:root:current train perplexity3.869027853012085
INFO:root:current mean train loss 1717.4502791946
INFO:root:current train perplexity3.872241497039795
INFO:root:current mean train loss 1717.2634791893295
INFO:root:current train perplexity3.8744616508483887
INFO:root:current mean train loss 1718.452228655134
INFO:root:current train perplexity3.8765146732330322
INFO:root:current mean train loss 1719.1867740245348
INFO:root:current train perplexity3.877307891845703
INFO:root:current mean train loss 1719.421638456304
INFO:root:current train perplexity3.8793952465057373
INFO:root:current mean train loss 1719.5497510505445
INFO:root:current train perplexity3.8797388076782227

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.08s/it]
INFO:root:final mean train loss: 1719.090735608138
INFO:root:final train perplexity: 3.8797800540924072
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.13s/it]
INFO:root:eval mean loss: 2072.0544922740746
INFO:root:eval perplexity: 5.342833518981934
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.46s/it]
INFO:root:eval mean loss: 2589.3782824793607
INFO:root:eval perplexity: 8.311705589294434
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [10:57:49<12:05:55, 410.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1714.7669589642396
INFO:root:current train perplexity3.825308322906494
INFO:root:current mean train loss 1705.7857151709231
INFO:root:current train perplexity3.8295888900756836
INFO:root:current mean train loss 1708.175501762416
INFO:root:current train perplexity3.8374698162078857
INFO:root:current mean train loss 1710.7237124503108
INFO:root:current train perplexity3.850861072540283
INFO:root:current mean train loss 1712.372317646111
INFO:root:current train perplexity3.8533895015716553
INFO:root:current mean train loss 1713.5279823188207
INFO:root:current train perplexity3.8521506786346436
INFO:root:current mean train loss 1715.4349832849489
INFO:root:current train perplexity3.857189178466797
INFO:root:current mean train loss 1713.5146233188912
INFO:root:current train perplexity3.8540899753570557
INFO:root:current mean train loss 1713.9045312173391
INFO:root:current train perplexity3.8579397201538086
INFO:root:current mean train loss 1714.0469967029996
INFO:root:current train perplexity3.857917308807373
INFO:root:current mean train loss 1715.0284748755485
INFO:root:current train perplexity3.8616926670074463
INFO:root:current mean train loss 1715.4432816660792
INFO:root:current train perplexity3.8634884357452393
INFO:root:current mean train loss 1716.1112756074715
INFO:root:current train perplexity3.8672261238098145
INFO:root:current mean train loss 1716.9881280722923
INFO:root:current train perplexity3.8676817417144775
INFO:root:current mean train loss 1716.930390566289
INFO:root:current train perplexity3.8699347972869873
INFO:root:current mean train loss 1717.912968912047
INFO:root:current train perplexity3.871462821960449
INFO:root:current mean train loss 1718.208304032622
INFO:root:current train perplexity3.872739791870117
INFO:root:current mean train loss 1718.4765228967767
INFO:root:current train perplexity3.873933792114258
INFO:root:current mean train loss 1717.2981335404174
INFO:root:current train perplexity3.8728342056274414

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:00<00:00, 360.66s/it]
INFO:root:final mean train loss: 1716.7842712248448
INFO:root:final train perplexity: 3.8727290630340576
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.29s/it]
INFO:root:eval mean loss: 2069.5738577335437
INFO:root:eval perplexity: 5.332124710083008
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.53s/it]
INFO:root:eval mean loss: 2584.4100406727894
INFO:root:eval perplexity: 8.278000831604004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [11:04:47<12:02:39, 412.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1701.19819859096
INFO:root:current train perplexity3.8264644145965576
INFO:root:current mean train loss 1713.0838880037006
INFO:root:current train perplexity3.8735790252685547
INFO:root:current mean train loss 1711.638205840209
INFO:root:current train perplexity3.8546142578125
INFO:root:current mean train loss 1708.922769145601
INFO:root:current train perplexity3.850755453109741
INFO:root:current mean train loss 1707.9830469693538
INFO:root:current train perplexity3.852764368057251
INFO:root:current mean train loss 1707.6995270131627
INFO:root:current train perplexity3.8539674282073975
INFO:root:current mean train loss 1706.919263013411
INFO:root:current train perplexity3.8528785705566406
INFO:root:current mean train loss 1708.6147267744989
INFO:root:current train perplexity3.8526058197021484
INFO:root:current mean train loss 1712.3362152324555
INFO:root:current train perplexity3.8581936359405518
INFO:root:current mean train loss 1711.534440923311
INFO:root:current train perplexity3.8558413982391357
INFO:root:current mean train loss 1711.0904400165264
INFO:root:current train perplexity3.8570854663848877
INFO:root:current mean train loss 1710.4743271010996
INFO:root:current train perplexity3.8560574054718018
INFO:root:current mean train loss 1710.5291338799616
INFO:root:current train perplexity3.857940673828125
INFO:root:current mean train loss 1711.55915412148
INFO:root:current train perplexity3.8584907054901123
INFO:root:current mean train loss 1711.4915028184948
INFO:root:current train perplexity3.8605105876922607
INFO:root:current mean train loss 1712.626914907478
INFO:root:current train perplexity3.8623905181884766
INFO:root:current mean train loss 1712.3813602111893
INFO:root:current train perplexity3.8635780811309814
INFO:root:current mean train loss 1712.2955021719115
INFO:root:current train perplexity3.864259958267212
INFO:root:current mean train loss 1713.050735625043
INFO:root:current train perplexity3.864417314529419
INFO:root:current mean train loss 1713.929056101832
INFO:root:current train perplexity3.863619565963745

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.23s/it]
INFO:root:final mean train loss: 1714.360069963587
INFO:root:final train perplexity: 3.8653314113616943
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.51s/it]
INFO:root:eval mean loss: 2071.932049690409
INFO:root:eval perplexity: 5.342303276062012
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.60s/it]
INFO:root:eval mean loss: 2588.7403322043992
INFO:root:eval perplexity: 8.307368278503418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [11:11:34<11:52:27, 411.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1730.2729216544858
INFO:root:current train perplexity3.9147140979766846
INFO:root:current mean train loss 1726.886203445551
INFO:root:current train perplexity3.854907989501953
INFO:root:current mean train loss 1716.9793162160106
INFO:root:current train perplexity3.8515560626983643
INFO:root:current mean train loss 1719.469128012297
INFO:root:current train perplexity3.8517708778381348
INFO:root:current mean train loss 1715.9184677938297
INFO:root:current train perplexity3.856255531311035
INFO:root:current mean train loss 1713.7983527174554
INFO:root:current train perplexity3.8491666316986084
INFO:root:current mean train loss 1710.7971700193764
INFO:root:current train perplexity3.8481552600860596
INFO:root:current mean train loss 1707.3111794363458
INFO:root:current train perplexity3.8468289375305176
INFO:root:current mean train loss 1708.6923437382484
INFO:root:current train perplexity3.8500123023986816
INFO:root:current mean train loss 1709.2204309252484
INFO:root:current train perplexity3.8502767086029053
INFO:root:current mean train loss 1711.0078508615725
INFO:root:current train perplexity3.8540894985198975
INFO:root:current mean train loss 1710.4178863984098
INFO:root:current train perplexity3.8521432876586914
INFO:root:current mean train loss 1710.9197672790478
INFO:root:current train perplexity3.851968765258789
INFO:root:current mean train loss 1711.374833081917
INFO:root:current train perplexity3.8522889614105225
INFO:root:current mean train loss 1711.3602950058144
INFO:root:current train perplexity3.8526103496551514
INFO:root:current mean train loss 1711.4450717878685
INFO:root:current train perplexity3.85263991355896
INFO:root:current mean train loss 1712.1636115658291
INFO:root:current train perplexity3.852196216583252
INFO:root:current mean train loss 1712.0050249810442
INFO:root:current train perplexity3.854280710220337
INFO:root:current mean train loss 1711.5347217703568
INFO:root:current train perplexity3.8556056022644043
INFO:root:current mean train loss 1711.4740192525933
INFO:root:current train perplexity3.8553802967071533

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.62s/it]
INFO:root:final mean train loss: 1711.296068277133
INFO:root:final train perplexity: 3.8560023307800293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.80s/it]
INFO:root:eval mean loss: 2071.670351285461
INFO:root:eval perplexity: 5.3411736488342285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.08s/it]
INFO:root:eval mean loss: 2589.8037351784133
INFO:root:eval perplexity: 8.314597129821777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [11:18:16<11:41:19, 408.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1687.130874633789
INFO:root:current train perplexity3.8056836128234863
INFO:root:current mean train loss 1695.7794065733215
INFO:root:current train perplexity3.8234498500823975
INFO:root:current mean train loss 1700.8874959638042
INFO:root:current train perplexity3.8199400901794434
INFO:root:current mean train loss 1704.6834148538524
INFO:root:current train perplexity3.828235626220703
INFO:root:current mean train loss 1705.874316079276
INFO:root:current train perplexity3.833270311355591
INFO:root:current mean train loss 1702.9615623307054
INFO:root:current train perplexity3.834367513656616
INFO:root:current mean train loss 1703.7101269003786
INFO:root:current train perplexity3.8340466022491455
INFO:root:current mean train loss 1704.5670764943495
INFO:root:current train perplexity3.8362298011779785
INFO:root:current mean train loss 1703.7806937739533
INFO:root:current train perplexity3.8369486331939697
INFO:root:current mean train loss 1702.6428757035783
INFO:root:current train perplexity3.834343433380127
INFO:root:current mean train loss 1702.7228963138493
INFO:root:current train perplexity3.8377866744995117
INFO:root:current mean train loss 1702.7598335718028
INFO:root:current train perplexity3.8381307125091553
INFO:root:current mean train loss 1703.3297412578877
INFO:root:current train perplexity3.8389782905578613
INFO:root:current mean train loss 1705.3296239835927
INFO:root:current train perplexity3.84053373336792
INFO:root:current mean train loss 1706.367337390204
INFO:root:current train perplexity3.84403133392334
INFO:root:current mean train loss 1706.8501221018553
INFO:root:current train perplexity3.8438913822174072
INFO:root:current mean train loss 1707.8107012406135
INFO:root:current train perplexity3.844097137451172
INFO:root:current mean train loss 1708.177167111185
INFO:root:current train perplexity3.844585657119751
INFO:root:current mean train loss 1709.6721246892755
INFO:root:current train perplexity3.8471264839172363
INFO:root:current mean train loss 1709.2415794670214
INFO:root:current train perplexity3.8476829528808594

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:58<00:00, 358.43s/it]
INFO:root:final mean train loss: 1708.790344361398
INFO:root:final train perplexity: 3.8483903408050537
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.42s/it]
INFO:root:eval mean loss: 2071.232611040697
INFO:root:eval perplexity: 5.339282989501953
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.19s/it]
INFO:root:eval mean loss: 2588.5005467191654
INFO:root:eval perplexity: 8.30573844909668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [11:25:12<11:37:56, 410.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1707.1838529146635
INFO:root:current train perplexity3.837705373764038
INFO:root:current mean train loss 1711.5923354640152
INFO:root:current train perplexity3.846205234527588
INFO:root:current mean train loss 1700.8817170916864
INFO:root:current train perplexity3.831024408340454
INFO:root:current mean train loss 1701.2421470328552
INFO:root:current train perplexity3.8203587532043457
INFO:root:current mean train loss 1701.892848517305
INFO:root:current train perplexity3.8241140842437744
INFO:root:current mean train loss 1701.7271201344718
INFO:root:current train perplexity3.825399398803711
INFO:root:current mean train loss 1703.8109233655427
INFO:root:current train perplexity3.825697183609009
INFO:root:current mean train loss 1703.9209064159518
INFO:root:current train perplexity3.8258864879608154
INFO:root:current mean train loss 1704.2925158903088
INFO:root:current train perplexity3.8227317333221436
INFO:root:current mean train loss 1702.8800505484942
INFO:root:current train perplexity3.824849843978882
INFO:root:current mean train loss 1705.523545472051
INFO:root:current train perplexity3.8300325870513916
INFO:root:current mean train loss 1706.0754505599516
INFO:root:current train perplexity3.8291690349578857
INFO:root:current mean train loss 1706.7039912649766
INFO:root:current train perplexity3.8296337127685547
INFO:root:current mean train loss 1706.621272965316
INFO:root:current train perplexity3.8320868015289307
INFO:root:current mean train loss 1705.60478665609
INFO:root:current train perplexity3.8331642150878906
INFO:root:current mean train loss 1705.1286897214457
INFO:root:current train perplexity3.835146188735962
INFO:root:current mean train loss 1705.9598987659535
INFO:root:current train perplexity3.835416793823242
INFO:root:current mean train loss 1705.7774797218042
INFO:root:current train perplexity3.836378812789917
INFO:root:current mean train loss 1705.9570394971097
INFO:root:current train perplexity3.8369803428649902
INFO:root:current mean train loss 1706.5593167914083
INFO:root:current train perplexity3.839599370956421

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:50<00:00, 350.81s/it]
INFO:root:final mean train loss: 1705.8635257291962
INFO:root:final train perplexity: 3.83951735496521
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.39s/it]
INFO:root:eval mean loss: 2075.0345835584276
INFO:root:eval perplexity: 5.355725288391113
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.60s/it]
INFO:root:eval mean loss: 2594.4137906554743
INFO:root:eval perplexity: 8.346003532409668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [11:31:58<11:28:48, 409.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1709.9177186547256
INFO:root:current train perplexity3.7916462421417236
INFO:root:current mean train loss 1701.103032709478
INFO:root:current train perplexity3.808082103729248
INFO:root:current mean train loss 1699.553794914949
INFO:root:current train perplexity3.8021719455718994
INFO:root:current mean train loss 1694.6601926793603
INFO:root:current train perplexity3.803117036819458
INFO:root:current mean train loss 1696.4287357567753
INFO:root:current train perplexity3.8119730949401855
INFO:root:current mean train loss 1697.7647019219153
INFO:root:current train perplexity3.812481164932251
INFO:root:current mean train loss 1699.2246449937568
INFO:root:current train perplexity3.8146955966949463
INFO:root:current mean train loss 1696.831424644841
INFO:root:current train perplexity3.8152003288269043
INFO:root:current mean train loss 1698.517016075636
INFO:root:current train perplexity3.8181240558624268
INFO:root:current mean train loss 1696.9068019268711
INFO:root:current train perplexity3.8175837993621826
INFO:root:current mean train loss 1698.0869412519135
INFO:root:current train perplexity3.817171096801758
INFO:root:current mean train loss 1700.0093892931736
INFO:root:current train perplexity3.820465326309204
INFO:root:current mean train loss 1700.8521243852683
INFO:root:current train perplexity3.821281909942627
INFO:root:current mean train loss 1700.8765107746924
INFO:root:current train perplexity3.8223602771759033
INFO:root:current mean train loss 1701.7131668070228
INFO:root:current train perplexity3.825610637664795
INFO:root:current mean train loss 1702.009426652255
INFO:root:current train perplexity3.825856924057007
INFO:root:current mean train loss 1703.3512460025963
INFO:root:current train perplexity3.8286356925964355
INFO:root:current mean train loss 1703.5195650899184
INFO:root:current train perplexity3.8299906253814697
INFO:root:current mean train loss 1703.3939160337864
INFO:root:current train perplexity3.8313510417938232
INFO:root:current mean train loss 1703.3586350026212
INFO:root:current train perplexity3.8304412364959717

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:47<00:00, 347.26s/it]
INFO:root:final mean train loss: 1702.8638972341564
INFO:root:final train perplexity: 3.8304450511932373
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.78s/it]
INFO:root:eval mean loss: 2075.3895726846463
INFO:root:eval perplexity: 5.357263565063477
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.60s/it]
INFO:root:eval mean loss: 2596.665246408882
INFO:root:eval perplexity: 8.361385345458984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [11:38:41<11:18:48, 407.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1686.2256870462436
INFO:root:current train perplexity3.793071985244751
INFO:root:current mean train loss 1683.2137113791614
INFO:root:current train perplexity3.7851479053497314
INFO:root:current mean train loss 1682.205926084997
INFO:root:current train perplexity3.7862937450408936
INFO:root:current mean train loss 1681.5067291642192
INFO:root:current train perplexity3.78688645362854
INFO:root:current mean train loss 1688.7385307724824
INFO:root:current train perplexity3.801028251647949
INFO:root:current mean train loss 1690.0217945436405
INFO:root:current train perplexity3.8071069717407227
INFO:root:current mean train loss 1691.4235871278165
INFO:root:current train perplexity3.8036534786224365
INFO:root:current mean train loss 1693.3856740481265
INFO:root:current train perplexity3.8084261417388916
INFO:root:current mean train loss 1694.3217648515713
INFO:root:current train perplexity3.8089020252227783
INFO:root:current mean train loss 1694.9333207719437
INFO:root:current train perplexity3.81083083152771
INFO:root:current mean train loss 1697.043187010386
INFO:root:current train perplexity3.8144822120666504
INFO:root:current mean train loss 1697.1563724775528
INFO:root:current train perplexity3.8168039321899414
INFO:root:current mean train loss 1697.6224027873004
INFO:root:current train perplexity3.8165335655212402
INFO:root:current mean train loss 1698.043440889
INFO:root:current train perplexity3.8153932094573975
INFO:root:current mean train loss 1698.4413625196746
INFO:root:current train perplexity3.820441961288452
INFO:root:current mean train loss 1697.6510885404452
INFO:root:current train perplexity3.8183388710021973
INFO:root:current mean train loss 1697.8876233923218
INFO:root:current train perplexity3.8174073696136475
INFO:root:current mean train loss 1698.1616427393474
INFO:root:current train perplexity3.8187386989593506
INFO:root:current mean train loss 1699.5509550668114
INFO:root:current train perplexity3.8205294609069824

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.81s/it]
INFO:root:final mean train loss: 1699.904035928931
INFO:root:final train perplexity: 3.8215138912200928
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.34s/it]
INFO:root:eval mean loss: 2076.342029328042
INFO:root:eval perplexity: 5.361392021179199
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.83s/it]
INFO:root:eval mean loss: 2597.529729315575
INFO:root:eval perplexity: 8.367300033569336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [11:45:30<11:12:58, 407.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1703.5277252197266
INFO:root:current train perplexity3.8343734741210938
INFO:root:current mean train loss 1685.7176808324352
INFO:root:current train perplexity3.7874534130096436
INFO:root:current mean train loss 1692.0620331940827
INFO:root:current train perplexity3.804112434387207
INFO:root:current mean train loss 1692.2749355654173
INFO:root:current train perplexity3.8100268840789795
INFO:root:current mean train loss 1695.9251685509314
INFO:root:current train perplexity3.810718536376953
INFO:root:current mean train loss 1690.6206120927204
INFO:root:current train perplexity3.8062217235565186
INFO:root:current mean train loss 1692.2360576282847
INFO:root:current train perplexity3.8073227405548096
INFO:root:current mean train loss 1693.0429141934358
INFO:root:current train perplexity3.80983829498291
INFO:root:current mean train loss 1694.270419401281
INFO:root:current train perplexity3.808519124984741
INFO:root:current mean train loss 1695.7062416576402
INFO:root:current train perplexity3.807965040206909
INFO:root:current mean train loss 1697.1730883741004
INFO:root:current train perplexity3.8110461235046387
INFO:root:current mean train loss 1695.701676782314
INFO:root:current train perplexity3.8131415843963623
INFO:root:current mean train loss 1694.9015761927556
INFO:root:current train perplexity3.8116445541381836
INFO:root:current mean train loss 1695.7205341188378
INFO:root:current train perplexity3.8149380683898926
INFO:root:current mean train loss 1697.1006707660222
INFO:root:current train perplexity3.8158457279205322
INFO:root:current mean train loss 1696.6925850015202
INFO:root:current train perplexity3.8143763542175293
INFO:root:current mean train loss 1696.7249511869827
INFO:root:current train perplexity3.8143351078033447
INFO:root:current mean train loss 1697.4500198186417
INFO:root:current train perplexity3.814462661743164
INFO:root:current mean train loss 1698.259231231286
INFO:root:current train perplexity3.81520676612854
INFO:root:current mean train loss 1698.2338641013382
INFO:root:current train perplexity3.815668821334839

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:01<00:00, 361.63s/it]
INFO:root:final mean train loss: 1697.777537135722
INFO:root:final train perplexity: 3.815109968185425
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.65s/it]
INFO:root:eval mean loss: 2080.295793249252
INFO:root:eval perplexity: 5.378562927246094
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.85s/it]
INFO:root:eval mean loss: 2603.7091679133423
INFO:root:eval perplexity: 8.409690856933594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [11:52:29<11:11:47, 411.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1693.3655044093277
INFO:root:current train perplexity3.7555086612701416
INFO:root:current mean train loss 1686.7215548637218
INFO:root:current train perplexity3.7853479385375977
INFO:root:current mean train loss 1690.9969031861924
INFO:root:current train perplexity3.7916958332061768
INFO:root:current mean train loss 1693.6419890349334
INFO:root:current train perplexity3.7935378551483154
INFO:root:current mean train loss 1691.205332978493
INFO:root:current train perplexity3.795362949371338
INFO:root:current mean train loss 1691.3625213451278
INFO:root:current train perplexity3.797489643096924
INFO:root:current mean train loss 1690.6990949440906
INFO:root:current train perplexity3.79986572265625
INFO:root:current mean train loss 1691.291782852735
INFO:root:current train perplexity3.7964816093444824
INFO:root:current mean train loss 1692.427810430813
INFO:root:current train perplexity3.798628807067871
INFO:root:current mean train loss 1693.2689171041834
INFO:root:current train perplexity3.7959706783294678
INFO:root:current mean train loss 1692.5051612226223
INFO:root:current train perplexity3.795985698699951
INFO:root:current mean train loss 1693.7367111435003
INFO:root:current train perplexity3.7969672679901123
INFO:root:current mean train loss 1693.9640094543606
INFO:root:current train perplexity3.7980926036834717
INFO:root:current mean train loss 1693.6420264734152
INFO:root:current train perplexity3.7970378398895264
INFO:root:current mean train loss 1693.0723013175757
INFO:root:current train perplexity3.7957329750061035
INFO:root:current mean train loss 1693.5727097921254
INFO:root:current train perplexity3.798036575317383
INFO:root:current mean train loss 1693.9019397892107
INFO:root:current train perplexity3.7997469902038574
INFO:root:current mean train loss 1694.602750026485
INFO:root:current train perplexity3.80196213722229
INFO:root:current mean train loss 1694.7995072701428
INFO:root:current train perplexity3.803576946258545
INFO:root:current mean train loss 1695.0562788977625
INFO:root:current train perplexity3.8057966232299805

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.68s/it]
INFO:root:final mean train loss: 1694.9569628278355
INFO:root:final train perplexity: 3.8066322803497314
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.16s/it]
INFO:root:eval mean loss: 2076.269692278923
INFO:root:eval perplexity: 5.36107873916626
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.44s/it]
INFO:root:eval mean loss: 2599.164935605746
INFO:root:eval perplexity: 8.378497123718262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [11:59:18<11:03:35, 410.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1685.25326171875
INFO:root:current train perplexity3.775369882583618
INFO:root:current mean train loss 1687.5813435872396
INFO:root:current train perplexity3.7844481468200684
INFO:root:current mean train loss 1682.8349819335938
INFO:root:current train perplexity3.780048370361328
INFO:root:current mean train loss 1687.4929827008928
INFO:root:current train perplexity3.792045831680298
INFO:root:current mean train loss 1685.7213208007813
INFO:root:current train perplexity3.7897424697875977
INFO:root:current mean train loss 1684.0498657226562
INFO:root:current train perplexity3.7858424186706543
INFO:root:current mean train loss 1686.039780085637
INFO:root:current train perplexity3.788141965866089
INFO:root:current mean train loss 1687.4976455078124
INFO:root:current train perplexity3.791934013366699
INFO:root:current mean train loss 1686.9264925608916
INFO:root:current train perplexity3.7939624786376953
INFO:root:current mean train loss 1689.5161887078536
INFO:root:current train perplexity3.7960498332977295
INFO:root:current mean train loss 1690.4389107840402
INFO:root:current train perplexity3.7969532012939453
INFO:root:current mean train loss 1690.7283666992187
INFO:root:current train perplexity3.7957892417907715
INFO:root:current mean train loss 1692.2293893554688
INFO:root:current train perplexity3.7978856563568115
INFO:root:current mean train loss 1692.8272824435765
INFO:root:current train perplexity3.7962841987609863
INFO:root:current mean train loss 1693.4641701744342
INFO:root:current train perplexity3.79681658744812
INFO:root:current mean train loss 1692.7963308026713
INFO:root:current train perplexity3.7966060638427734
INFO:root:current mean train loss 1692.7811265980113
INFO:root:current train perplexity3.7970948219299316
INFO:root:current mean train loss 1692.9686323939732
INFO:root:current train perplexity3.7991299629211426
INFO:root:current mean train loss 1691.9319114231419
INFO:root:current train perplexity3.7978503704071045
INFO:root:current mean train loss 1692.5677232947717
INFO:root:current train perplexity3.7995259761810303

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:03<00:00, 363.35s/it]
INFO:root:final mean train loss: 1692.8163712848273
INFO:root:final train perplexity: 3.8002121448516846
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.80s/it]
INFO:root:eval mean loss: 2080.7266365213595
INFO:root:eval perplexity: 5.380435943603516
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.36s/it]
INFO:root:eval mean loss: 2602.742075385777
INFO:root:eval perplexity: 8.403042793273926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [12:06:18<11:01:41, 413.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1686.1757976475046
INFO:root:current train perplexity3.7844040393829346
INFO:root:current mean train loss 1680.216943797951
INFO:root:current train perplexity3.767650842666626
INFO:root:current mean train loss 1686.1382855476065
INFO:root:current train perplexity3.771409273147583
INFO:root:current mean train loss 1688.5296640837876
INFO:root:current train perplexity3.7737176418304443
INFO:root:current mean train loss 1687.5387663422612
INFO:root:current train perplexity3.77533221244812
INFO:root:current mean train loss 1685.0432667135142
INFO:root:current train perplexity3.772962808609009
INFO:root:current mean train loss 1685.459151649761
INFO:root:current train perplexity3.7738916873931885
INFO:root:current mean train loss 1686.731670673077
INFO:root:current train perplexity3.778481960296631
INFO:root:current mean train loss 1686.5032383127884
INFO:root:current train perplexity3.780486583709717
INFO:root:current mean train loss 1687.1641464470092
INFO:root:current train perplexity3.780852794647217
INFO:root:current mean train loss 1687.6502834273592
INFO:root:current train perplexity3.781165599822998
INFO:root:current mean train loss 1689.0043252848516
INFO:root:current train perplexity3.784893035888672
INFO:root:current mean train loss 1690.4515877040992
INFO:root:current train perplexity3.7865610122680664
INFO:root:current mean train loss 1690.698702964978
INFO:root:current train perplexity3.78822660446167
INFO:root:current mean train loss 1691.2481823422588
INFO:root:current train perplexity3.789020538330078
INFO:root:current mean train loss 1691.0042571145102
INFO:root:current train perplexity3.790954113006592
INFO:root:current mean train loss 1691.0671250515522
INFO:root:current train perplexity3.7913718223571777
INFO:root:current mean train loss 1691.6931880482457
INFO:root:current train perplexity3.793046236038208
INFO:root:current mean train loss 1690.6187994558031
INFO:root:current train perplexity3.7911720275878906
INFO:root:current mean train loss 1690.7887505287438
INFO:root:current train perplexity3.7923545837402344

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:51<00:00, 351.69s/it]
INFO:root:final mean train loss: 1690.420494983729
INFO:root:final train perplexity: 3.7930381298065186
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.16s/it]
INFO:root:eval mean loss: 2077.453650075493
INFO:root:eval perplexity: 5.366213798522949
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.43s/it]
INFO:root:eval mean loss: 2600.801673835051
INFO:root:eval perplexity: 8.389720916748047
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [12:13:06<10:51:55, 411.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1706.1984965006511
INFO:root:current train perplexity3.7770769596099854
INFO:root:current mean train loss 1690.894247967264
INFO:root:current train perplexity3.7721102237701416
INFO:root:current mean train loss 1679.5430031360036
INFO:root:current train perplexity3.7709429264068604
INFO:root:current mean train loss 1684.09601910909
INFO:root:current train perplexity3.779144287109375
INFO:root:current mean train loss 1687.5837258583258
INFO:root:current train perplexity3.7851529121398926
INFO:root:current mean train loss 1685.4049412975573
INFO:root:current train perplexity3.779620409011841
INFO:root:current mean train loss 1687.7056479649236
INFO:root:current train perplexity3.7811872959136963
INFO:root:current mean train loss 1686.2561855705417
INFO:root:current train perplexity3.780555486679077
INFO:root:current mean train loss 1685.8019635644973
INFO:root:current train perplexity3.7805895805358887
INFO:root:current mean train loss 1685.4663481673574
INFO:root:current train perplexity3.782090663909912
INFO:root:current mean train loss 1687.0399273523985
INFO:root:current train perplexity3.7815439701080322
INFO:root:current mean train loss 1687.1507939519108
INFO:root:current train perplexity3.7835192680358887
INFO:root:current mean train loss 1688.2506659677094
INFO:root:current train perplexity3.784271717071533
INFO:root:current mean train loss 1688.480874386826
INFO:root:current train perplexity3.7841968536376953
INFO:root:current mean train loss 1689.6955039957463
INFO:root:current train perplexity3.7874999046325684
INFO:root:current mean train loss 1688.6564791900944
INFO:root:current train perplexity3.7861452102661133
INFO:root:current mean train loss 1688.4435886555216
INFO:root:current train perplexity3.786156177520752
INFO:root:current mean train loss 1688.735134723475
INFO:root:current train perplexity3.787264823913574
INFO:root:current mean train loss 1689.457565793566
INFO:root:current train perplexity3.7870304584503174

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:59<00:00, 359.22s/it]
INFO:root:final mean train loss: 1688.4471076661387
INFO:root:final train perplexity: 3.787139654159546
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.65s/it]
INFO:root:eval mean loss: 2079.3296318324747
INFO:root:eval perplexity: 5.374361991882324
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.56s/it]
INFO:root:eval mean loss: 2604.1271730247117
INFO:root:eval perplexity: 8.412567138671875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [12:20:02<10:47:21, 413.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1809.0003662109375
INFO:root:current train perplexity3.933058738708496
INFO:root:current mean train loss 1692.4232830387532
INFO:root:current train perplexity3.7821543216705322
INFO:root:current mean train loss 1688.1683944778063
INFO:root:current train perplexity3.757403612136841
INFO:root:current mean train loss 1688.142474709951
INFO:root:current train perplexity3.760509490966797
INFO:root:current mean train loss 1689.9017881930915
INFO:root:current train perplexity3.764716386795044
INFO:root:current mean train loss 1687.4197737337824
INFO:root:current train perplexity3.769136667251587
INFO:root:current mean train loss 1688.8174492301243
INFO:root:current train perplexity3.770787477493286
INFO:root:current mean train loss 1685.8450616028442
INFO:root:current train perplexity3.7658138275146484
INFO:root:current mean train loss 1683.6724504525594
INFO:root:current train perplexity3.7641243934631348
INFO:root:current mean train loss 1681.328819757561
INFO:root:current train perplexity3.7608542442321777
INFO:root:current mean train loss 1681.4105916056599
INFO:root:current train perplexity3.7625348567962646
INFO:root:current mean train loss 1683.3079261883727
INFO:root:current train perplexity3.7656378746032715
INFO:root:current mean train loss 1683.4279536136878
INFO:root:current train perplexity3.7661356925964355
INFO:root:current mean train loss 1683.7606211492962
INFO:root:current train perplexity3.770303726196289
INFO:root:current mean train loss 1684.1565655879172
INFO:root:current train perplexity3.772657871246338
INFO:root:current mean train loss 1685.663447675508
INFO:root:current train perplexity3.7734014987945557
INFO:root:current mean train loss 1687.0545106848504
INFO:root:current train perplexity3.777070999145508
INFO:root:current mean train loss 1687.4780223202804
INFO:root:current train perplexity3.779139757156372
INFO:root:current mean train loss 1687.301022815016
INFO:root:current train perplexity3.7794113159179688
INFO:root:current mean train loss 1686.9204769385356
INFO:root:current train perplexity3.7795333862304688

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:53<00:00, 353.91s/it]
INFO:root:final mean train loss: 1685.9391023960009
INFO:root:final train perplexity: 3.7796554565429688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.29s/it]
INFO:root:eval mean loss: 2082.7501164429577
INFO:root:eval perplexity: 5.389248847961426
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.27s/it]
INFO:root:eval mean loss: 2606.004159048094
INFO:root:eval perplexity: 8.425491333007812
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [12:26:59<10:42:02, 414.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1677.1683281792534
INFO:root:current train perplexity3.797419548034668
INFO:root:current mean train loss 1685.0734708107125
INFO:root:current train perplexity3.7712788581848145
INFO:root:current mean train loss 1682.0096984303325
INFO:root:current train perplexity3.758608818054199
INFO:root:current mean train loss 1682.318107556997
INFO:root:current train perplexity3.7587730884552
INFO:root:current mean train loss 1679.6836439798894
INFO:root:current train perplexity3.754431962966919
INFO:root:current mean train loss 1682.6608318785443
INFO:root:current train perplexity3.758077383041382
INFO:root:current mean train loss 1681.416423118616
INFO:root:current train perplexity3.757261276245117
INFO:root:current mean train loss 1682.6849968785364
INFO:root:current train perplexity3.7574682235717773
INFO:root:current mean train loss 1684.0432485566455
INFO:root:current train perplexity3.7596192359924316
INFO:root:current mean train loss 1683.2781196544372
INFO:root:current train perplexity3.761911153793335
INFO:root:current mean train loss 1682.93193560827
INFO:root:current train perplexity3.763275623321533
INFO:root:current mean train loss 1681.9372758404727
INFO:root:current train perplexity3.763679265975952
INFO:root:current mean train loss 1681.2654075184087
INFO:root:current train perplexity3.7638511657714844
INFO:root:current mean train loss 1681.7611561892427
INFO:root:current train perplexity3.7658026218414307
INFO:root:current mean train loss 1683.4955379771245
INFO:root:current train perplexity3.767242908477783
INFO:root:current mean train loss 1683.2178510381927
INFO:root:current train perplexity3.7663040161132812
INFO:root:current mean train loss 1681.9915082669818
INFO:root:current train perplexity3.764617919921875
INFO:root:current mean train loss 1683.1637544820694
INFO:root:current train perplexity3.7673251628875732
INFO:root:current mean train loss 1683.3881423664827
INFO:root:current train perplexity3.7686798572540283
INFO:root:current mean train loss 1683.3605727910747
INFO:root:current train perplexity3.770953893661499

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:04<00:00, 364.17s/it]
INFO:root:final mean train loss: 1683.5503391683312
INFO:root:final train perplexity: 3.7725419998168945
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:28<00:00, 28.50s/it]
INFO:root:eval mean loss: 2082.2503337454286
INFO:root:eval perplexity: 5.387070178985596
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.37s/it]
INFO:root:eval mean loss: 2606.960102054244
INFO:root:eval perplexity: 8.43208122253418
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [12:34:04<10:39:54, 417.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1672.9452357700893
INFO:root:current train perplexity3.768176317214966
INFO:root:current mean train loss 1676.0291078920718
INFO:root:current train perplexity3.721447706222534
INFO:root:current mean train loss 1671.8155922747674
INFO:root:current train perplexity3.728502035140991
INFO:root:current mean train loss 1674.1247398262594
INFO:root:current train perplexity3.741602659225464
INFO:root:current mean train loss 1675.2267230154455
INFO:root:current train perplexity3.73335337638855
INFO:root:current mean train loss 1677.0539662583967
INFO:root:current train perplexity3.739588499069214
INFO:root:current mean train loss 1678.694417445866
INFO:root:current train perplexity3.746734142303467
INFO:root:current mean train loss 1679.10134460034
INFO:root:current train perplexity3.751573085784912
INFO:root:current mean train loss 1679.8293240667103
INFO:root:current train perplexity3.7527849674224854
INFO:root:current mean train loss 1679.4478984322777
INFO:root:current train perplexity3.752532958984375
INFO:root:current mean train loss 1679.716266842165
INFO:root:current train perplexity3.7539455890655518
INFO:root:current mean train loss 1679.5462045274642
INFO:root:current train perplexity3.7539501190185547
INFO:root:current mean train loss 1678.9887278197748
INFO:root:current train perplexity3.755260944366455
INFO:root:current mean train loss 1681.0330096412688
INFO:root:current train perplexity3.757636070251465
INFO:root:current mean train loss 1681.3483866302809
INFO:root:current train perplexity3.760051727294922
INFO:root:current mean train loss 1680.8229834143424
INFO:root:current train perplexity3.760608196258545
INFO:root:current mean train loss 1680.8019047448395
INFO:root:current train perplexity3.762803077697754
INFO:root:current mean train loss 1681.2806876322722
INFO:root:current train perplexity3.763145923614502
INFO:root:current mean train loss 1682.071147766945
INFO:root:current train perplexity3.765117645263672
INFO:root:current mean train loss 1682.219637044271
INFO:root:current train perplexity3.766038179397583

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:52<00:00, 352.10s/it]
INFO:root:final mean train loss: 1681.4459289458443
INFO:root:final train perplexity: 3.766286611557007
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:27<00:00, 27.55s/it]
INFO:root:eval mean loss: 2082.069725956477
INFO:root:eval perplexity: 5.3862833976745605
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:26<00:00, 26.87s/it]
INFO:root:eval mean loss: 2608.0266814536235
INFO:root:eval perplexity: 8.439437866210938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: small_multiqa_allmini_not_cross/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [12:40:51<10:28:36, 414.47s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1667.3278339092549
INFO:root:current train perplexity3.6978354454040527
INFO:root:current mean train loss 1672.9802551269531
INFO:root:current train perplexity3.7068936824798584
INFO:root:current mean train loss 1674.2735295371403
INFO:root:current train perplexity3.7245585918426514
INFO:root:current mean train loss 1675.521756952459
INFO:root:current train perplexity3.7254462242126465
INFO:root:current mean train loss 1679.4593216887617
INFO:root:current train perplexity3.735858678817749
INFO:root:current mean train loss 1679.5333408963852
INFO:root:current train perplexity3.737098217010498
INFO:root:current mean train loss 1681.9906194956025
INFO:root:current train perplexity3.7445905208587646
INFO:root:current mean train loss 1682.3217060819586
INFO:root:current train perplexity3.748511791229248
INFO:root:current mean train loss 1681.7860969937462
INFO:root:current train perplexity3.7458744049072266
INFO:root:current mean train loss 1680.5483685661766
INFO:root:current train perplexity3.7478058338165283
INFO:root:current mean train loss 1680.837249871896
INFO:root:current train perplexity3.753575563430786
INFO:root:current mean train loss 1679.807328330146
INFO:root:current train perplexity3.7540175914764404
INFO:root:current mean train loss 1679.2739063787003
INFO:root:current train perplexity3.7546379566192627
INFO:root:current mean train loss 1680.3967801607573
INFO:root:current train perplexity3.7576680183410645
INFO:root:current mean train loss 1680.128340455783
INFO:root:current train perplexity3.7582597732543945
INFO:root:current mean train loss 1679.4011738570696
INFO:root:current train perplexity3.759216785430908
INFO:root:current mean train loss 1679.9865325114918
INFO:root:current train perplexity3.7590670585632324
INFO:root:current mean train loss 1679.795206357355
INFO:root:current train perplexity3.7596986293792725
INFO:root:current mean train loss 1678.8933195110017
INFO:root:current train perplexity3.7582955360412598
INFO:root:current mean train loss 1679.284447404205
INFO:root:current train perplexity3.75901198387146

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [06:02<00:00, 362.16s/it]
INFO:root:final mean train loss: 1679.2708816874585
INFO:root:final train perplexity: 3.7598307132720947
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][Aslurmstepd: error: *** JOB 26290821 ON gr015 CANCELLED AT 2022-10-26T13:08:53 ***
