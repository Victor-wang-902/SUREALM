INFO:root:Output: allminil16_minilml12_real
INFO:root:Steps per epochs:1983
INFO:root:Total steps:396600
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'cls.predictions.decoder.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.7.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.8.crossattention.self.key.weight', 'cls.predictions.bias', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.7.crossattention.self.key.weight', 'cls.predictions.transform.dense.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.11.crossattention.output.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.self.key.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.self.query.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/200 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
INFO:root:current mean train loss 11416.770566998106
INFO:root:current train perplexity8511.5234375
INFO:root:current mean train loss 9455.352664199905
INFO:root:current train perplexity1787.6513671875
INFO:root:current mean train loss 8303.339956430289
INFO:root:current train perplexity717.791748046875
INFO:root:current mean train loss 7522.907508027883
INFO:root:current train perplexity381.20904541015625
INFO:root:current mean train loss 6940.011201113164
INFO:root:current train perplexity240.5162353515625
INFO:root:current mean train loss 6491.224147178892
INFO:root:current train perplexity168.78759765625
INFO:root:current mean train loss 6136.950522928961
INFO:root:current train perplexity127.29607391357422
INFO:root:current mean train loss 5856.122437898447
INFO:root:current train perplexity101.44205474853516
INFO:root:current mean train loss 5617.937426947911
INFO:root:current train perplexity84.12336730957031
INFO:root:current mean train loss 5414.083311094298
INFO:root:current train perplexity71.70890808105469
INFO:root:current mean train loss 5240.586539743162
INFO:root:current train perplexity62.41872787475586
INFO:root:current mean train loss 5089.86985757174
INFO:root:current train perplexity55.4238166809082
INFO:root:current mean train loss 4956.137028295504
INFO:root:current train perplexity49.85478973388672
INFO:root:current mean train loss 4837.8912401506095
INFO:root:current train perplexity45.42331314086914
INFO:root:current mean train loss 4730.9379055438
INFO:root:current train perplexity41.77655792236328
INFO:root:current mean train loss 4635.449298145325
INFO:root:current train perplexity38.70866012573242
INFO:root:current mean train loss 4547.768215419686
INFO:root:current train perplexity36.11588668823242
INFO:root:current mean train loss 4469.474564591005
INFO:root:current train perplexity33.94227600097656
INFO:root:current mean train loss 4397.045918364724
INFO:root:current train perplexity32.047786712646484

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.23s/it]
INFO:root:final mean train loss: 4338.591458611578
INFO:root:final train perplexity: 30.620624542236328
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.72s/it]
INFO:root:eval mean loss: 2833.4515900307515
INFO:root:eval perplexity: 9.89005184173584
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it]
INFO:root:eval mean loss: 3127.492787029726
INFO:root:eval perplexity: 12.90673828125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/1
  0%|          | 1/200 [10:34<35:04:33, 634.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2991.697235107422
INFO:root:current train perplexity10.585646629333496
INFO:root:current mean train loss 3028.3260350720634
INFO:root:current train perplexity10.751497268676758
INFO:root:current mean train loss 3007.3361805103445
INFO:root:current train perplexity10.610664367675781
INFO:root:current mean train loss 2990.910826091525
INFO:root:current train perplexity10.478468894958496
INFO:root:current mean train loss 2969.880984379695
INFO:root:current train perplexity10.31486701965332
INFO:root:current mean train loss 2954.8283085786097
INFO:root:current train perplexity10.224369049072266
INFO:root:current mean train loss 2943.035912451806
INFO:root:current train perplexity10.143346786499023
INFO:root:current mean train loss 2928.7784014653894
INFO:root:current train perplexity10.042895317077637
INFO:root:current mean train loss 2914.6037920783547
INFO:root:current train perplexity9.943936347961426
INFO:root:current mean train loss 2907.9910718093274
INFO:root:current train perplexity9.878544807434082
INFO:root:current mean train loss 2894.919271153728
INFO:root:current train perplexity9.781408309936523
INFO:root:current mean train loss 2883.8231406810037
INFO:root:current train perplexity9.702183723449707
INFO:root:current mean train loss 2873.8501926221347
INFO:root:current train perplexity9.634923934936523
INFO:root:current mean train loss 2865.2881221133525
INFO:root:current train perplexity9.565658569335938
INFO:root:current mean train loss 2858.91329783639
INFO:root:current train perplexity9.507023811340332
INFO:root:current mean train loss 2848.8767920823716
INFO:root:current train perplexity9.44296932220459
INFO:root:current mean train loss 2839.7725488643837
INFO:root:current train perplexity9.3814115524292
INFO:root:current mean train loss 2831.9209630294836
INFO:root:current train perplexity9.31606388092041
INFO:root:current mean train loss 2822.1868037421273
INFO:root:current train perplexity9.24785327911377
INFO:root:current mean train loss 2814.910286220479
INFO:root:current train perplexity9.19926929473877

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.75s/it]
INFO:root:final mean train loss: 2808.9525793463185
INFO:root:final train perplexity: 9.164239883422852
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:46<00:00, 46.97s/it]
INFO:root:eval mean loss: 2506.5870270424703
INFO:root:eval perplexity: 7.592646598815918
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.79s/it]
INFO:root:eval mean loss: 2843.594783701795
INFO:root:eval perplexity: 10.232512474060059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/2
  1%|          | 2/200 [21:36<35:46:38, 650.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2619.3462431936555
INFO:root:current train perplexity7.94281530380249
INFO:root:current mean train loss 2634.0974506578946
INFO:root:current train perplexity7.984971046447754
INFO:root:current mean train loss 2624.5416265004696
INFO:root:current train perplexity7.959085464477539
INFO:root:current mean train loss 2627.5440472210494
INFO:root:current train perplexity7.930954456329346
INFO:root:current mean train loss 2625.614027767754
INFO:root:current train perplexity7.92720365524292
INFO:root:current mean train loss 2622.1488172234112
INFO:root:current train perplexity7.896486759185791
INFO:root:current mean train loss 2615.93810977303
INFO:root:current train perplexity7.86834192276001
INFO:root:current mean train loss 2613.968654075716
INFO:root:current train perplexity7.845309257507324
INFO:root:current mean train loss 2610.313724220157
INFO:root:current train perplexity7.822317123413086
INFO:root:current mean train loss 2604.3395048838593
INFO:root:current train perplexity7.790767669677734
INFO:root:current mean train loss 2597.5371133928033
INFO:root:current train perplexity7.756702423095703
INFO:root:current mean train loss 2591.4636577394085
INFO:root:current train perplexity7.721653461456299
INFO:root:current mean train loss 2587.768025617143
INFO:root:current train perplexity7.701763153076172
INFO:root:current mean train loss 2583.7128281704213
INFO:root:current train perplexity7.673614025115967
INFO:root:current mean train loss 2580.091215741942
INFO:root:current train perplexity7.648752689361572
INFO:root:current mean train loss 2574.9368621766453
INFO:root:current train perplexity7.618907451629639
INFO:root:current mean train loss 2571.5992798673838
INFO:root:current train perplexity7.593931674957275
INFO:root:current mean train loss 2568.462297671803
INFO:root:current train perplexity7.574475288391113
INFO:root:current mean train loss 2566.023313365214
INFO:root:current train perplexity7.5607757568359375
INFO:root:current mean train loss 2563.166075365567
INFO:root:current train perplexity7.542582035064697

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:38<00:00, 578.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:38<00:00, 578.33s/it]
INFO:root:final mean train loss: 2560.8820400651634
INFO:root:final train perplexity: 7.5358052253723145
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it]
INFO:root:eval mean loss: 2364.9798960584276
INFO:root:eval perplexity: 6.771054267883301
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 2722.5241041251106
INFO:root:eval perplexity: 9.267884254455566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/3
  2%|â–         | 3/200 [32:29<35:39:22, 651.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2442.636301269531
INFO:root:current train perplexity6.948802471160889
INFO:root:current mean train loss 2456.623946126302
INFO:root:current train perplexity7.014362812042236
INFO:root:current mean train loss 2468.2761840820312
INFO:root:current train perplexity7.0090651512146
INFO:root:current mean train loss 2472.0365942382814
INFO:root:current train perplexity6.988941669464111
INFO:root:current mean train loss 2471.0773727756077
INFO:root:current train perplexity6.986349582672119
INFO:root:current mean train loss 2464.672028808594
INFO:root:current train perplexity6.967536926269531
INFO:root:current mean train loss 2460.34026949369
INFO:root:current train perplexity6.9584527015686035
INFO:root:current mean train loss 2455.2037732747394
INFO:root:current train perplexity6.94680643081665
INFO:root:current mean train loss 2453.8428890452665
INFO:root:current train perplexity6.9261016845703125
INFO:root:current mean train loss 2450.242203047903
INFO:root:current train perplexity6.906031131744385
INFO:root:current mean train loss 2444.6217188662577
INFO:root:current train perplexity6.892615795135498
INFO:root:current mean train loss 2444.4259227454145
INFO:root:current train perplexity6.888634204864502
INFO:root:current mean train loss 2444.4033120117188
INFO:root:current train perplexity6.882620334625244
INFO:root:current mean train loss 2442.34888192636
INFO:root:current train perplexity6.868836879730225
INFO:root:current mean train loss 2441.114485200027
INFO:root:current train perplexity6.853710174560547
INFO:root:current mean train loss 2439.1857591198336
INFO:root:current train perplexity6.847683906555176
INFO:root:current mean train loss 2437.6370655036694
INFO:root:current train perplexity6.835182189941406
INFO:root:current mean train loss 2435.9426268833704
INFO:root:current train perplexity6.823935031890869
INFO:root:current mean train loss 2433.2692782675254
INFO:root:current train perplexity6.814358234405518
INFO:root:current mean train loss 2431.2768863932292
INFO:root:current train perplexity6.800688743591309

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.10s/it]
INFO:root:final mean train loss: 2429.894425123314
INFO:root:final train perplexity: 6.7961812019348145
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it]
INFO:root:eval mean loss: 2276.38922162428
INFO:root:eval perplexity: 6.302900791168213
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.86s/it]
INFO:root:eval mean loss: 2642.2759105060118
INFO:root:eval perplexity: 8.679169654846191
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/4
  2%|â–         | 4/200 [42:58<34:59:56, 642.84s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2384.2033800722947
INFO:root:current train perplexity6.488060474395752
INFO:root:current mean train loss 2364.5079528443116
INFO:root:current train perplexity6.411616325378418
INFO:root:current mean train loss 2362.8295962444404
INFO:root:current train perplexity6.4323577880859375
INFO:root:current mean train loss 2357.776038229628
INFO:root:current train perplexity6.414532661437988
INFO:root:current mean train loss 2359.550052749013
INFO:root:current train perplexity6.433526992797852
INFO:root:current mean train loss 2361.4302793364886
INFO:root:current train perplexity6.4289093017578125
INFO:root:current mean train loss 2358.4613364704364
INFO:root:current train perplexity6.424065589904785
INFO:root:current mean train loss 2361.4524659476347
INFO:root:current train perplexity6.427404403686523
INFO:root:current mean train loss 2359.248131352725
INFO:root:current train perplexity6.42433500289917
INFO:root:current mean train loss 2357.916800561094
INFO:root:current train perplexity6.414162635803223
INFO:root:current mean train loss 2357.5064182442375
INFO:root:current train perplexity6.410755634307861
INFO:root:current mean train loss 2355.139196034671
INFO:root:current train perplexity6.397471904754639
INFO:root:current mean train loss 2355.5645457134533
INFO:root:current train perplexity6.393866539001465
INFO:root:current mean train loss 2352.8802149116163
INFO:root:current train perplexity6.387656211853027
INFO:root:current mean train loss 2350.671904373429
INFO:root:current train perplexity6.375065326690674
INFO:root:current mean train loss 2350.123335496894
INFO:root:current train perplexity6.369635581970215
INFO:root:current mean train loss 2346.9706692206482
INFO:root:current train perplexity6.361833095550537
INFO:root:current mean train loss 2347.3524190646885
INFO:root:current train perplexity6.357469081878662
INFO:root:current mean train loss 2345.9003844789854
INFO:root:current train perplexity6.354681491851807
INFO:root:current mean train loss 2344.363170722686
INFO:root:current train perplexity6.3486409187316895

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.80s/it]
INFO:root:final mean train loss: 2343.1789025688076
INFO:root:final train perplexity: 6.3469343185424805
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it]
INFO:root:eval mean loss: 2221.8307521089596
INFO:root:eval perplexity: 6.030839920043945
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it]
INFO:root:eval mean loss: 2598.530107646969
INFO:root:eval perplexity: 8.374147415161133
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/5
  2%|â–Ž         | 5/200 [53:34<34:41:12, 640.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2292.141902378627
INFO:root:current train perplexity6.151139259338379
INFO:root:current mean train loss 2309.5170613164487
INFO:root:current train perplexity6.1481709480285645
INFO:root:current mean train loss 2299.977274290273
INFO:root:current train perplexity6.1233296394348145
INFO:root:current mean train loss 2299.0489002863565
INFO:root:current train perplexity6.130037307739258
INFO:root:current mean train loss 2293.6431710739766
INFO:root:current train perplexity6.11927604675293
INFO:root:current mean train loss 2297.857075521391
INFO:root:current train perplexity6.119861125946045
INFO:root:current mean train loss 2293.2951315718087
INFO:root:current train perplexity6.110568046569824
INFO:root:current mean train loss 2290.6167179029817
INFO:root:current train perplexity6.09837532043457
INFO:root:current mean train loss 2290.2923657171327
INFO:root:current train perplexity6.091473579406738
INFO:root:current mean train loss 2287.653804996149
INFO:root:current train perplexity6.084867477416992
INFO:root:current mean train loss 2287.1485161024707
INFO:root:current train perplexity6.079038619995117
INFO:root:current mean train loss 2286.750192487562
INFO:root:current train perplexity6.072516918182373
INFO:root:current mean train loss 2286.2333147756035
INFO:root:current train perplexity6.064518928527832
INFO:root:current mean train loss 2285.2158606203993
INFO:root:current train perplexity6.059991836547852
INFO:root:current mean train loss 2282.6634814321515
INFO:root:current train perplexity6.056634902954102
INFO:root:current mean train loss 2280.9989939217617
INFO:root:current train perplexity6.050315856933594
INFO:root:current mean train loss 2280.7754596338705
INFO:root:current train perplexity6.045868873596191
INFO:root:current mean train loss 2280.5785327449507
INFO:root:current train perplexity6.041189193725586
INFO:root:current mean train loss 2279.597604545059
INFO:root:current train perplexity6.037591934204102

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.84s/it]
INFO:root:final mean train loss: 2279.665014900827
INFO:root:final train perplexity: 6.03684139251709
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it]
INFO:root:eval mean loss: 2177.4498658958055
INFO:root:eval perplexity: 5.818215370178223
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 2558.998871066046
INFO:root:eval perplexity: 8.107744216918945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/6
  3%|â–Ž         | 6/200 [1:04:00<34:14:46, 635.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2308.5712890625
INFO:root:current train perplexity6.140551567077637
INFO:root:current mean train loss 2219.258757638459
INFO:root:current train perplexity5.788381576538086
INFO:root:current mean train loss 2225.898972544504
INFO:root:current train perplexity5.819278240203857
INFO:root:current mean train loss 2228.5682604209924
INFO:root:current train perplexity5.809294700622559
INFO:root:current mean train loss 2231.1485909250314
INFO:root:current train perplexity5.820699691772461
INFO:root:current mean train loss 2236.712308049916
INFO:root:current train perplexity5.823731422424316
INFO:root:current mean train loss 2237.9724834016874
INFO:root:current train perplexity5.825826168060303
INFO:root:current mean train loss 2239.6661913296293
INFO:root:current train perplexity5.832393646240234
INFO:root:current mean train loss 2238.3906053407363
INFO:root:current train perplexity5.82659387588501
INFO:root:current mean train loss 2238.726616422291
INFO:root:current train perplexity5.828258037567139
INFO:root:current mean train loss 2236.2063643143965
INFO:root:current train perplexity5.826754093170166
INFO:root:current mean train loss 2236.67210239892
INFO:root:current train perplexity5.8253936767578125
INFO:root:current mean train loss 2235.757803047428
INFO:root:current train perplexity5.82471227645874
INFO:root:current mean train loss 2234.1677967631567
INFO:root:current train perplexity5.818451881408691
INFO:root:current mean train loss 2234.532272393324
INFO:root:current train perplexity5.818906307220459
INFO:root:current mean train loss 2233.7944927177455
INFO:root:current train perplexity5.818863868713379
INFO:root:current mean train loss 2233.03727795555
INFO:root:current train perplexity5.816457748413086
INFO:root:current mean train loss 2230.6322648700443
INFO:root:current train perplexity5.810300350189209
INFO:root:current mean train loss 2230.2360420968384
INFO:root:current train perplexity5.807495594024658
INFO:root:current mean train loss 2231.0468705050384
INFO:root:current train perplexity5.805553436279297

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.02s/it]
INFO:root:final mean train loss: 2229.484987444548
INFO:root:final train perplexity: 5.802600383758545
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 2146.3038511884974
INFO:root:eval perplexity: 5.673490524291992
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 2533.2213277613864
INFO:root:eval perplexity: 7.938608646392822
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/7
  4%|â–Ž         | 7/200 [1:14:38<34:06:39, 636.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2285.5792778862847
INFO:root:current train perplexity5.6927032470703125
INFO:root:current mean train loss 2204.892918473583
INFO:root:current train perplexity5.663891315460205
INFO:root:current mean train loss 2201.417316961726
INFO:root:current train perplexity5.630193710327148
INFO:root:current mean train loss 2189.558845951872
INFO:root:current train perplexity5.608457565307617
INFO:root:current mean train loss 2199.6929061378587
INFO:root:current train perplexity5.64259147644043
INFO:root:current mean train loss 2197.821063774433
INFO:root:current train perplexity5.631313323974609
INFO:root:current mean train loss 2198.763898238395
INFO:root:current train perplexity5.633624076843262
INFO:root:current mean train loss 2199.775066917653
INFO:root:current train perplexity5.638230323791504
INFO:root:current mean train loss 2194.695400545824
INFO:root:current train perplexity5.633967399597168
INFO:root:current mean train loss 2196.100948292186
INFO:root:current train perplexity5.634555816650391
INFO:root:current mean train loss 2194.9722912381817
INFO:root:current train perplexity5.63338041305542
INFO:root:current mean train loss 2193.706306907913
INFO:root:current train perplexity5.633971691131592
INFO:root:current mean train loss 2191.6516788777067
INFO:root:current train perplexity5.6302103996276855
INFO:root:current mean train loss 2193.007204649119
INFO:root:current train perplexity5.631877899169922
INFO:root:current mean train loss 2193.2022148960905
INFO:root:current train perplexity5.6335530281066895
INFO:root:current mean train loss 2192.470470403337
INFO:root:current train perplexity5.6319379806518555
INFO:root:current mean train loss 2190.9920979465633
INFO:root:current train perplexity5.625514030456543
INFO:root:current mean train loss 2191.6346113673467
INFO:root:current train perplexity5.6264328956604
INFO:root:current mean train loss 2190.5579247805153
INFO:root:current train perplexity5.624346733093262
INFO:root:current mean train loss 2189.352745207308
INFO:root:current train perplexity5.621004581451416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.44s/it]
INFO:root:final mean train loss: 2188.448809201947
INFO:root:final train perplexity: 5.617812633514404
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it]
INFO:root:eval mean loss: 2124.3173979630706
INFO:root:eval perplexity: 5.57349967956543
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.98s/it]
INFO:root:eval mean loss: 2514.7843818394003
INFO:root:eval perplexity: 7.81980562210083
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/8
  4%|â–         | 8/200 [1:25:07<33:48:29, 633.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2105.390611049107
INFO:root:current train perplexity5.2923359870910645
INFO:root:current mean train loss 2141.847804542824
INFO:root:current train perplexity5.434048175811768
INFO:root:current mean train loss 2136.912389876995
INFO:root:current train perplexity5.438000679016113
INFO:root:current mean train loss 2149.3515023758164
INFO:root:current train perplexity5.451802730560303
INFO:root:current mean train loss 2156.1947265625
INFO:root:current train perplexity5.476565837860107
INFO:root:current mean train loss 2154.0541971652306
INFO:root:current train perplexity5.463569641113281
INFO:root:current mean train loss 2153.993905711737
INFO:root:current train perplexity5.457324981689453
INFO:root:current mean train loss 2153.0637848107995
INFO:root:current train perplexity5.459348678588867
INFO:root:current mean train loss 2151.5997001602263
INFO:root:current train perplexity5.459295272827148
INFO:root:current mean train loss 2154.636511817973
INFO:root:current train perplexity5.460298538208008
INFO:root:current mean train loss 2155.4290720769172
INFO:root:current train perplexity5.462188243865967
INFO:root:current mean train loss 2155.8231669018446
INFO:root:current train perplexity5.4663286209106445
INFO:root:current mean train loss 2153.2886462748293
INFO:root:current train perplexity5.464084625244141
INFO:root:current mean train loss 2151.707201599807
INFO:root:current train perplexity5.461170196533203
INFO:root:current mean train loss 2152.2569181116614
INFO:root:current train perplexity5.460461616516113
INFO:root:current mean train loss 2153.2544215696253
INFO:root:current train perplexity5.463744640350342
INFO:root:current mean train loss 2154.0857958685733
INFO:root:current train perplexity5.465108394622803
INFO:root:current mean train loss 2154.0211152090465
INFO:root:current train perplexity5.465857028961182
INFO:root:current mean train loss 2153.347062662317
INFO:root:current train perplexity5.46399450302124
INFO:root:current mean train loss 2154.035336989765
INFO:root:current train perplexity5.4643402099609375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.54s/it]
INFO:root:final mean train loss: 2153.0322037243327
INFO:root:final train perplexity: 5.463069438934326
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 2098.961057405945
INFO:root:eval perplexity: 5.460370063781738
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it]
INFO:root:eval mean loss: 2495.2489563421154
INFO:root:eval perplexity: 7.695865631103516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/9
  4%|â–         | 9/200 [1:35:36<33:33:04, 632.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2090.6089454064004
INFO:root:current train perplexity5.326630115509033
INFO:root:current mean train loss 2125.9021212929174
INFO:root:current train perplexity5.38605260848999
INFO:root:current mean train loss 2137.1730041503906
INFO:root:current train perplexity5.382852554321289
INFO:root:current mean train loss 2130.130298267711
INFO:root:current train perplexity5.3698015213012695
INFO:root:current mean train loss 2127.905566190196
INFO:root:current train perplexity5.365365028381348
INFO:root:current mean train loss 2124.8877952686253
INFO:root:current train perplexity5.3538408279418945
INFO:root:current mean train loss 2124.6706162903206
INFO:root:current train perplexity5.352348327636719
INFO:root:current mean train loss 2124.172603201359
INFO:root:current train perplexity5.348334789276123
INFO:root:current mean train loss 2127.045186790502
INFO:root:current train perplexity5.349886894226074
INFO:root:current mean train loss 2125.1001742066455
INFO:root:current train perplexity5.345527648925781
INFO:root:current mean train loss 2125.2401342355706
INFO:root:current train perplexity5.3434529304504395
INFO:root:current mean train loss 2126.580906867981
INFO:root:current train perplexity5.346399784088135
INFO:root:current mean train loss 2124.5381815852447
INFO:root:current train perplexity5.344720840454102
INFO:root:current mean train loss 2125.4022636639297
INFO:root:current train perplexity5.341395378112793
INFO:root:current mean train loss 2125.7406300105995
INFO:root:current train perplexity5.341215133666992
INFO:root:current mean train loss 2125.071978539536
INFO:root:current train perplexity5.340022087097168
INFO:root:current mean train loss 2126.0454097128954
INFO:root:current train perplexity5.341623306274414
INFO:root:current mean train loss 2126.1413165227464
INFO:root:current train perplexity5.34152889251709
INFO:root:current mean train loss 2124.975321693503
INFO:root:current train perplexity5.3386993408203125
INFO:root:current mean train loss 2125.1918012900433
INFO:root:current train perplexity5.338681697845459

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.33s/it]
INFO:root:final mean train loss: 2123.3261165955546
INFO:root:final train perplexity: 5.336567401885986
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it]
INFO:root:eval mean loss: 2083.363429725593
INFO:root:eval perplexity: 5.391922950744629
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.08s/it]
INFO:root:eval mean loss: 2482.5354739791114
INFO:root:eval perplexity: 7.616262912750244
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/10
  5%|â–Œ         | 10/200 [1:46:17<33:31:19, 635.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2106.023140285326
INFO:root:current train perplexity5.248019218444824
INFO:root:current mean train loss 2115.8933040460893
INFO:root:current train perplexity5.259279251098633
INFO:root:current mean train loss 2112.7438347685293
INFO:root:current train perplexity5.247998237609863
INFO:root:current mean train loss 2107.215427967268
INFO:root:current train perplexity5.234874725341797
INFO:root:current mean train loss 2105.1201689827926
INFO:root:current train perplexity5.233555316925049
INFO:root:current mean train loss 2100.7953537335925
INFO:root:current train perplexity5.23171854019165
INFO:root:current mean train loss 2098.417820769397
INFO:root:current train perplexity5.2231316566467285
INFO:root:current mean train loss 2100.3963518279115
INFO:root:current train perplexity5.232641220092773
INFO:root:current mean train loss 2099.068143750225
INFO:root:current train perplexity5.231778621673584
INFO:root:current mean train loss 2098.707835603917
INFO:root:current train perplexity5.231235980987549
INFO:root:current mean train loss 2097.6006018100666
INFO:root:current train perplexity5.228119373321533
INFO:root:current mean train loss 2099.27706097292
INFO:root:current train perplexity5.228293418884277
INFO:root:current mean train loss 2098.9785237053043
INFO:root:current train perplexity5.230865001678467
INFO:root:current mean train loss 2098.929127706412
INFO:root:current train perplexity5.227454662322998
INFO:root:current mean train loss 2099.519975323349
INFO:root:current train perplexity5.231466770172119
INFO:root:current mean train loss 2098.7432858994084
INFO:root:current train perplexity5.229420185089111
INFO:root:current mean train loss 2097.7129350939936
INFO:root:current train perplexity5.226574897766113
INFO:root:current mean train loss 2097.7995834566227
INFO:root:current train perplexity5.225061416625977
INFO:root:current mean train loss 2097.1915678347796
INFO:root:current train perplexity5.222470283508301
INFO:root:current mean train loss 2097.7376105142403
INFO:root:current train perplexity5.228069305419922

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.67s/it]
INFO:root:final mean train loss: 2097.1086036732145
INFO:root:final train perplexity: 5.227358818054199
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.00s/it]
INFO:root:eval mean loss: 2068.560294942653
INFO:root:eval perplexity: 5.327755928039551
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.87s/it]
INFO:root:eval mean loss: 2470.834730215952
INFO:root:eval perplexity: 7.543727397918701
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/11
  6%|â–Œ         | 11/200 [1:56:45<33:13:39, 632.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2077.3940756154616
INFO:root:current train perplexity5.084664344787598
INFO:root:current mean train loss 2063.1366301505795
INFO:root:current train perplexity5.086848735809326
INFO:root:current mean train loss 2063.7881298998855
INFO:root:current train perplexity5.091422080993652
INFO:root:current mean train loss 2067.024457071729
INFO:root:current train perplexity5.104804515838623
INFO:root:current mean train loss 2062.5773830335324
INFO:root:current train perplexity5.112115383148193
INFO:root:current mean train loss 2067.1726172124972
INFO:root:current train perplexity5.116578102111816
INFO:root:current mean train loss 2069.032706124442
INFO:root:current train perplexity5.109804153442383
INFO:root:current mean train loss 2069.5615953440583
INFO:root:current train perplexity5.108375549316406
INFO:root:current mean train loss 2070.05595077618
INFO:root:current train perplexity5.110495090484619
INFO:root:current mean train loss 2072.0260119950794
INFO:root:current train perplexity5.114846706390381
INFO:root:current mean train loss 2073.2826190758806
INFO:root:current train perplexity5.12123966217041
INFO:root:current mean train loss 2074.023682978664
INFO:root:current train perplexity5.12315559387207
INFO:root:current mean train loss 2074.0108103418424
INFO:root:current train perplexity5.123124599456787
INFO:root:current mean train loss 2073.787487475903
INFO:root:current train perplexity5.1253204345703125
INFO:root:current mean train loss 2072.4016751562763
INFO:root:current train perplexity5.126524448394775
INFO:root:current mean train loss 2074.0566069902416
INFO:root:current train perplexity5.129116535186768
INFO:root:current mean train loss 2073.1923835365233
INFO:root:current train perplexity5.129736423492432
INFO:root:current mean train loss 2073.597952813878
INFO:root:current train perplexity5.130875110626221
INFO:root:current mean train loss 2073.4046507235676
INFO:root:current train perplexity5.13211727142334

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.28s/it]
INFO:root:final mean train loss: 2073.6930312994928
INFO:root:final train perplexity: 5.131710052490234
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.97s/it]
INFO:root:eval mean loss: 2055.983449516567
INFO:root:eval perplexity: 5.273838996887207
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it]
INFO:root:eval mean loss: 2460.202444522939
INFO:root:eval perplexity: 7.478418350219727
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/12
  6%|â–Œ         | 12/200 [2:07:14<32:59:31, 631.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2097.619425455729
INFO:root:current train perplexity4.862329006195068
INFO:root:current mean train loss 2054.173491542779
INFO:root:current train perplexity5.055777549743652
INFO:root:current mean train loss 2045.675317623345
INFO:root:current train perplexity5.020996570587158
INFO:root:current mean train loss 2049.890693085422
INFO:root:current train perplexity5.024860382080078
INFO:root:current mean train loss 2049.031338447968
INFO:root:current train perplexity5.025051593780518
INFO:root:current mean train loss 2049.3203751126057
INFO:root:current train perplexity5.028910160064697
INFO:root:current mean train loss 2053.0283014857355
INFO:root:current train perplexity5.04587984085083
INFO:root:current mean train loss 2050.5135070887604
INFO:root:current train perplexity5.034761905670166
INFO:root:current mean train loss 2050.5931474013464
INFO:root:current train perplexity5.035257339477539
INFO:root:current mean train loss 2051.262024669288
INFO:root:current train perplexity5.039895534515381
INFO:root:current mean train loss 2050.115273077253
INFO:root:current train perplexity5.034731864929199
INFO:root:current mean train loss 2050.193862818202
INFO:root:current train perplexity5.040514945983887
INFO:root:current mean train loss 2048.8426655732087
INFO:root:current train perplexity5.038907051086426
INFO:root:current mean train loss 2049.469303204294
INFO:root:current train perplexity5.040695667266846
INFO:root:current mean train loss 2050.676370371943
INFO:root:current train perplexity5.039639949798584
INFO:root:current mean train loss 2050.4091502866663
INFO:root:current train perplexity5.0378618240356445
INFO:root:current mean train loss 2051.622966992431
INFO:root:current train perplexity5.043259620666504
INFO:root:current mean train loss 2052.244069160466
INFO:root:current train perplexity5.044928073883057
INFO:root:current mean train loss 2052.3338499825595
INFO:root:current train perplexity5.044136047363281
INFO:root:current mean train loss 2053.3124932004976
INFO:root:current train perplexity5.046182155609131

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.31s/it]
INFO:root:final mean train loss: 2052.144420567992
INFO:root:final train perplexity: 5.045236110687256
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.70s/it]
INFO:root:eval mean loss: 2045.7737967849623
INFO:root:eval perplexity: 5.230473518371582
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.42s/it]
INFO:root:eval mean loss: 2454.221207855441
INFO:root:eval perplexity: 7.441924095153809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/13
  6%|â–‹         | 13/200 [2:17:52<32:54:36, 633.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1992.045098876953
INFO:root:current train perplexity4.879665374755859
INFO:root:current mean train loss 2016.57067972819
INFO:root:current train perplexity4.894037246704102
INFO:root:current mean train loss 2019.283213667436
INFO:root:current train perplexity4.935645580291748
INFO:root:current mean train loss 2022.4230026245118
INFO:root:current train perplexity4.931190013885498
INFO:root:current mean train loss 2023.9053992861793
INFO:root:current train perplexity4.934483051300049
INFO:root:current mean train loss 2029.1727884145882
INFO:root:current train perplexity4.943310260772705
INFO:root:current mean train loss 2026.0109233240928
INFO:root:current train perplexity4.935379981994629
INFO:root:current mean train loss 2025.0267856174046
INFO:root:current train perplexity4.937796592712402
INFO:root:current mean train loss 2024.3034394054878
INFO:root:current train perplexity4.943378925323486
INFO:root:current mean train loss 2024.306671009893
INFO:root:current train perplexity4.947662353515625
INFO:root:current mean train loss 2026.1231484805837
INFO:root:current train perplexity4.951109886169434
INFO:root:current mean train loss 2026.9692468915666
INFO:root:current train perplexity4.954850673675537
INFO:root:current mean train loss 2027.46387479188
INFO:root:current train perplexity4.952429294586182
INFO:root:current mean train loss 2029.6690287272136
INFO:root:current train perplexity4.954347610473633
INFO:root:current mean train loss 2030.1664198324713
INFO:root:current train perplexity4.96005392074585
INFO:root:current mean train loss 2029.2498478939658
INFO:root:current train perplexity4.96140193939209
INFO:root:current mean train loss 2029.903990342882
INFO:root:current train perplexity4.9628777503967285
INFO:root:current mean train loss 2031.7071257835212
INFO:root:current train perplexity4.963909149169922
INFO:root:current mean train loss 2031.0936398013607
INFO:root:current train perplexity4.963901996612549
INFO:root:current mean train loss 2031.7804314931234
INFO:root:current train perplexity4.9672651290893555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.16s/it]
INFO:root:final mean train loss: 2032.6507150685613
INFO:root:final train perplexity: 4.968265056610107
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.80s/it]
INFO:root:eval mean loss: 2036.8121731805463
INFO:root:eval perplexity: 5.192702293395996
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.84s/it]
INFO:root:eval mean loss: 2448.72314582987
INFO:root:eval perplexity: 7.408535957336426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/14
  7%|â–‹         | 14/200 [2:28:37<32:54:54, 637.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2041.208750131968
INFO:root:current train perplexity4.813864231109619
INFO:root:current mean train loss 2023.2783915944342
INFO:root:current train perplexity4.867636203765869
INFO:root:current mean train loss 2012.7924310225474
INFO:root:current train perplexity4.862231254577637
INFO:root:current mean train loss 2011.0677403300028
INFO:root:current train perplexity4.855902194976807
INFO:root:current mean train loss 2012.2780747751895
INFO:root:current train perplexity4.862680435180664
INFO:root:current mean train loss 2015.074051897841
INFO:root:current train perplexity4.874624729156494
INFO:root:current mean train loss 2012.4603601093381
INFO:root:current train perplexity4.8739542961120605
INFO:root:current mean train loss 2011.5461207147855
INFO:root:current train perplexity4.875493049621582
INFO:root:current mean train loss 2011.9638997104148
INFO:root:current train perplexity4.87456750869751
INFO:root:current mean train loss 2009.7218889136707
INFO:root:current train perplexity4.872154235839844
INFO:root:current mean train loss 2009.0482818103228
INFO:root:current train perplexity4.874344825744629
INFO:root:current mean train loss 2009.8185361998062
INFO:root:current train perplexity4.878265857696533
INFO:root:current mean train loss 2010.3550092840542
INFO:root:current train perplexity4.880242824554443
INFO:root:current mean train loss 2011.6862963702845
INFO:root:current train perplexity4.884310245513916
INFO:root:current mean train loss 2010.7459346423484
INFO:root:current train perplexity4.881374359130859
INFO:root:current mean train loss 2012.6793428916162
INFO:root:current train perplexity4.886183261871338
INFO:root:current mean train loss 2013.0725926123673
INFO:root:current train perplexity4.887933254241943
INFO:root:current mean train loss 2013.544543787331
INFO:root:current train perplexity4.890431880950928
INFO:root:current mean train loss 2013.5719208777048
INFO:root:current train perplexity4.891683578491211
INFO:root:current mean train loss 2014.1194645493192
INFO:root:current train perplexity4.8950629234313965

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.20s/it]
INFO:root:final mean train loss: 2014.6217852355371
INFO:root:final train perplexity: 4.898122787475586
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it]
INFO:root:eval mean loss: 2027.2957988766068
INFO:root:eval perplexity: 5.152890205383301
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.38s/it]
INFO:root:eval mean loss: 2439.841200375388
INFO:root:eval perplexity: 7.354918956756592
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/15
  8%|â–Š         | 15/200 [2:39:05<32:36:19, 634.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1968.3849464699074
INFO:root:current train perplexity4.779449462890625
INFO:root:current mean train loss 1985.9072796710125
INFO:root:current train perplexity4.824466705322266
INFO:root:current mean train loss 1994.5563157449558
INFO:root:current train perplexity4.835211277008057
INFO:root:current mean train loss 1991.2794265316031
INFO:root:current train perplexity4.824982166290283
INFO:root:current mean train loss 1992.4902752443556
INFO:root:current train perplexity4.816380977630615
INFO:root:current mean train loss 1997.2135512148861
INFO:root:current train perplexity4.831390380859375
INFO:root:current mean train loss 2000.9420048424956
INFO:root:current train perplexity4.83827543258667
INFO:root:current mean train loss 1998.1432929001057
INFO:root:current train perplexity4.827883720397949
INFO:root:current mean train loss 1998.3635332522963
INFO:root:current train perplexity4.831600189208984
INFO:root:current mean train loss 1998.122617837518
INFO:root:current train perplexity4.833247661590576
INFO:root:current mean train loss 2001.1443820786883
INFO:root:current train perplexity4.836330413818359
INFO:root:current mean train loss 1998.5672176896596
INFO:root:current train perplexity4.832503795623779
INFO:root:current mean train loss 1999.6746777499502
INFO:root:current train perplexity4.836038112640381
INFO:root:current mean train loss 2001.0151663798524
INFO:root:current train perplexity4.834888935089111
INFO:root:current mean train loss 2001.0849375980592
INFO:root:current train perplexity4.8352766036987305
INFO:root:current mean train loss 2000.1839957022453
INFO:root:current train perplexity4.835291862487793
INFO:root:current mean train loss 1998.7906984193148
INFO:root:current train perplexity4.8326005935668945
INFO:root:current mean train loss 1998.9618819094303
INFO:root:current train perplexity4.83455753326416
INFO:root:current mean train loss 1999.5168823110505
INFO:root:current train perplexity4.835946083068848
INFO:root:current mean train loss 1998.322051533413
INFO:root:current train perplexity4.833739757537842

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.71s/it]
INFO:root:final mean train loss: 1997.8901239761606
INFO:root:final train perplexity: 4.833913803100586
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.51s/it]
INFO:root:eval mean loss: 2023.8101105385638
INFO:root:eval perplexity: 5.138384819030762
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 2438.479336785932
INFO:root:eval perplexity: 7.346730709075928
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/16
  8%|â–Š         | 16/200 [2:49:41<32:27:05, 634.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2003.4975843832526
INFO:root:current train perplexity4.772529602050781
INFO:root:current mean train loss 1986.071077759503
INFO:root:current train perplexity4.764932632446289
INFO:root:current mean train loss 1984.1557211787938
INFO:root:current train perplexity4.77285623550415
INFO:root:current mean train loss 1983.5529762124115
INFO:root:current train perplexity4.767772197723389
INFO:root:current mean train loss 1982.102780352226
INFO:root:current train perplexity4.77404260635376
INFO:root:current mean train loss 1981.0952360083052
INFO:root:current train perplexity4.769791126251221
INFO:root:current mean train loss 1980.9817083731139
INFO:root:current train perplexity4.763514995574951
INFO:root:current mean train loss 1981.9133107622001
INFO:root:current train perplexity4.768244743347168
INFO:root:current mean train loss 1981.5289385124408
INFO:root:current train perplexity4.768470287322998
INFO:root:current mean train loss 1980.9123747616422
INFO:root:current train perplexity4.769197463989258
INFO:root:current mean train loss 1980.4782613403434
INFO:root:current train perplexity4.770903587341309
INFO:root:current mean train loss 1980.1452971343604
INFO:root:current train perplexity4.769036769866943
INFO:root:current mean train loss 1979.9689455430025
INFO:root:current train perplexity4.766044616699219
INFO:root:current mean train loss 1981.3203433959873
INFO:root:current train perplexity4.7695746421813965
INFO:root:current mean train loss 1982.1962860750552
INFO:root:current train perplexity4.77253532409668
INFO:root:current mean train loss 1981.8954527992719
INFO:root:current train perplexity4.774383544921875
INFO:root:current mean train loss 1981.8500191981318
INFO:root:current train perplexity4.774819374084473
INFO:root:current mean train loss 1981.07632868469
INFO:root:current train perplexity4.771453857421875
INFO:root:current mean train loss 1981.3337484550375
INFO:root:current train perplexity4.772572994232178
INFO:root:current mean train loss 1982.4506507072274
INFO:root:current train perplexity4.773136138916016

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.15s/it]
INFO:root:final mean train loss: 1982.2239168737492
INFO:root:final train perplexity: 4.774556636810303
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 2015.9998164616577
INFO:root:eval perplexity: 5.106029987335205
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it]
INFO:root:eval mean loss: 2433.9656159962324
INFO:root:eval perplexity: 7.319659233093262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/17
  8%|â–Š         | 17/200 [3:00:18<32:17:47, 635.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1976.9963115345347
INFO:root:current train perplexity4.726513385772705
INFO:root:current mean train loss 1951.996799550158
INFO:root:current train perplexity4.680652141571045
INFO:root:current mean train loss 1956.0548040601943
INFO:root:current train perplexity4.693875312805176
INFO:root:current mean train loss 1964.9613534199823
INFO:root:current train perplexity4.704032897949219
INFO:root:current mean train loss 1960.1315395167617
INFO:root:current train perplexity4.690833568572998
INFO:root:current mean train loss 1964.8648503102413
INFO:root:current train perplexity4.703188419342041
INFO:root:current mean train loss 1961.6968710256178
INFO:root:current train perplexity4.69954776763916
INFO:root:current mean train loss 1961.5523312951102
INFO:root:current train perplexity4.7022480964660645
INFO:root:current mean train loss 1963.2855320835972
INFO:root:current train perplexity4.708574295043945
INFO:root:current mean train loss 1963.0724510779748
INFO:root:current train perplexity4.708101272583008
INFO:root:current mean train loss 1963.214620253619
INFO:root:current train perplexity4.708282470703125
INFO:root:current mean train loss 1964.5539268211082
INFO:root:current train perplexity4.711953163146973
INFO:root:current mean train loss 1965.7379429977132
INFO:root:current train perplexity4.715317726135254
INFO:root:current mean train loss 1965.4985883641311
INFO:root:current train perplexity4.71672248840332
INFO:root:current mean train loss 1965.3145622335455
INFO:root:current train perplexity4.716752529144287
INFO:root:current mean train loss 1964.829894481438
INFO:root:current train perplexity4.7153401374816895
INFO:root:current mean train loss 1964.9709780001526
INFO:root:current train perplexity4.716287136077881
INFO:root:current mean train loss 1965.8669602225557
INFO:root:current train perplexity4.715468883514404
INFO:root:current mean train loss 1968.0736638085316
INFO:root:current train perplexity4.718849182128906

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.22s/it]
INFO:root:final mean train loss: 1967.246620720706
INFO:root:final train perplexity: 4.7184906005859375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it]
INFO:root:eval mean loss: 2010.7292861397384
INFO:root:eval perplexity: 5.084312915802002
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.06s/it]
INFO:root:eval mean loss: 2432.1721576663617
INFO:root:eval perplexity: 7.308932781219482
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/18
  9%|â–‰         | 18/200 [3:10:45<31:59:48, 632.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1874.80361328125
INFO:root:current train perplexity4.44793701171875
INFO:root:current mean train loss 1923.6082484654019
INFO:root:current train perplexity4.632536888122559
INFO:root:current mean train loss 1933.3730831983612
INFO:root:current train perplexity4.624233245849609
INFO:root:current mean train loss 1943.4408299180327
INFO:root:current train perplexity4.637933254241943
INFO:root:current mean train loss 1939.3869110484181
INFO:root:current train perplexity4.637110710144043
INFO:root:current mean train loss 1941.5604272219214
INFO:root:current train perplexity4.63476037979126
INFO:root:current mean train loss 1940.2604800894242
INFO:root:current train perplexity4.631464958190918
INFO:root:current mean train loss 1942.594993039395
INFO:root:current train perplexity4.6364336013793945
INFO:root:current mean train loss 1945.160207201087
INFO:root:current train perplexity4.645389556884766
INFO:root:current mean train loss 1949.519343491022
INFO:root:current train perplexity4.653790473937988
INFO:root:current mean train loss 1949.5257397096548
INFO:root:current train perplexity4.6538310050964355
INFO:root:current mean train loss 1950.1014725767109
INFO:root:current train perplexity4.655176639556885
INFO:root:current mean train loss 1950.2097197346668
INFO:root:current train perplexity4.657058238983154
INFO:root:current mean train loss 1949.889762463332
INFO:root:current train perplexity4.65623664855957
INFO:root:current mean train loss 1950.7748840114825
INFO:root:current train perplexity4.655916213989258
INFO:root:current mean train loss 1952.011218707823
INFO:root:current train perplexity4.657933235168457
INFO:root:current mean train loss 1952.8915367625584
INFO:root:current train perplexity4.6601433753967285
INFO:root:current mean train loss 1953.657827964626
INFO:root:current train perplexity4.663355827331543
INFO:root:current mean train loss 1953.8111923260042
INFO:root:current train perplexity4.665745258331299
INFO:root:current mean train loss 1954.6981354961245
INFO:root:current train perplexity4.669192314147949

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.04s/it]
INFO:root:final mean train loss: 1953.971565311988
INFO:root:final train perplexity: 4.669347763061523
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.18s/it]
INFO:root:eval mean loss: 2008.0048429881426
INFO:root:eval perplexity: 5.073122024536133
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.25s/it]
INFO:root:eval mean loss: 2429.583335064827
INFO:root:eval perplexity: 7.293473720550537
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/19
 10%|â–‰         | 19/200 [3:21:23<31:53:38, 634.36s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1912.1369185014205
INFO:root:current train perplexity4.626618385314941
INFO:root:current mean train loss 1924.8535776607325
INFO:root:current train perplexity4.6030449867248535
INFO:root:current mean train loss 1942.9757118568764
INFO:root:current train perplexity4.636252403259277
INFO:root:current mean train loss 1933.0518741963072
INFO:root:current train perplexity4.60996675491333
INFO:root:current mean train loss 1930.3986032495002
INFO:root:current train perplexity4.6006269454956055
INFO:root:current mean train loss 1936.3359877780022
INFO:root:current train perplexity4.613105773925781
INFO:root:current mean train loss 1935.004088374196
INFO:root:current train perplexity4.607335567474365
INFO:root:current mean train loss 1937.6640763639414
INFO:root:current train perplexity4.616800785064697
INFO:root:current mean train loss 1935.8877915431112
INFO:root:current train perplexity4.616168022155762
INFO:root:current mean train loss 1937.2288761428536
INFO:root:current train perplexity4.615551471710205
INFO:root:current mean train loss 1938.3060647923419
INFO:root:current train perplexity4.61484956741333
INFO:root:current mean train loss 1940.007940336557
INFO:root:current train perplexity4.616451740264893
INFO:root:current mean train loss 1940.0522772606382
INFO:root:current train perplexity4.6142354011535645
INFO:root:current mean train loss 1939.5056168964518
INFO:root:current train perplexity4.612839221954346
INFO:root:current mean train loss 1938.7648433036106
INFO:root:current train perplexity4.610224723815918
INFO:root:current mean train loss 1938.7714870217283
INFO:root:current train perplexity4.610743522644043
INFO:root:current mean train loss 1940.0884160090022
INFO:root:current train perplexity4.614011764526367
INFO:root:current mean train loss 1939.759668507504
INFO:root:current train perplexity4.614062309265137
INFO:root:current mean train loss 1940.42419326397
INFO:root:current train perplexity4.61586856842041
INFO:root:current mean train loss 1940.6267904069248
INFO:root:current train perplexity4.618342399597168

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.91s/it]
INFO:root:final mean train loss: 1940.1178594407443
INFO:root:final train perplexity: 4.6186089515686035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it]
INFO:root:eval mean loss: 2004.7155731417608
INFO:root:eval perplexity: 5.05964469909668
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it]
INFO:root:eval mean loss: 2429.548228595274
INFO:root:eval perplexity: 7.293265342712402
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/20
 10%|â–ˆ         | 20/200 [3:31:51<31:37:34, 632.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1885.5745599208733
INFO:root:current train perplexity4.475383281707764
INFO:root:current mean train loss 1913.4943803746066
INFO:root:current train perplexity4.530337333679199
INFO:root:current mean train loss 1923.3492109865324
INFO:root:current train perplexity4.536683082580566
INFO:root:current mean train loss 1922.4599404124033
INFO:root:current train perplexity4.529911518096924
INFO:root:current mean train loss 1924.8616498456186
INFO:root:current train perplexity4.552651405334473
INFO:root:current mean train loss 1920.1179581962401
INFO:root:current train perplexity4.547314167022705
INFO:root:current mean train loss 1923.5496230147814
INFO:root:current train perplexity4.553204536437988
INFO:root:current mean train loss 1922.8699586117218
INFO:root:current train perplexity4.547037124633789
INFO:root:current mean train loss 1924.6523251266387
INFO:root:current train perplexity4.552971839904785
INFO:root:current mean train loss 1925.9977667242829
INFO:root:current train perplexity4.5567803382873535
INFO:root:current mean train loss 1927.2698556351133
INFO:root:current train perplexity4.560272693634033
INFO:root:current mean train loss 1927.6377521143136
INFO:root:current train perplexity4.564830303192139
INFO:root:current mean train loss 1926.3267150337028
INFO:root:current train perplexity4.564489841461182
INFO:root:current mean train loss 1927.6385815302056
INFO:root:current train perplexity4.564120292663574
INFO:root:current mean train loss 1928.9892847884273
INFO:root:current train perplexity4.566101551055908
INFO:root:current mean train loss 1928.7220175819323
INFO:root:current train perplexity4.569000244140625
INFO:root:current mean train loss 1929.4958324048343
INFO:root:current train perplexity4.5697550773620605
INFO:root:current mean train loss 1930.5738531708237
INFO:root:current train perplexity4.573059558868408
INFO:root:current mean train loss 1929.228022431731
INFO:root:current train perplexity4.570847511291504
INFO:root:current mean train loss 1927.8960577269816
INFO:root:current train perplexity4.572549819946289

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.77s/it]
INFO:root:final mean train loss: 1927.8540707894545
INFO:root:final train perplexity: 4.574153900146484
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.93s/it]
INFO:root:eval mean loss: 1998.6698171196253
INFO:root:eval perplexity: 5.034965991973877
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it]
INFO:root:eval mean loss: 2426.896543245789
INFO:root:eval perplexity: 7.277466773986816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/21
 10%|â–ˆ         | 21/200 [3:42:19<31:23:13, 631.25s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1918.721688406808
INFO:root:current train perplexity4.533745288848877
INFO:root:current mean train loss 1920.13184767503
INFO:root:current train perplexity4.50787878036499
INFO:root:current mean train loss 1913.240433216095
INFO:root:current train perplexity4.503020286560059
INFO:root:current mean train loss 1913.486396018039
INFO:root:current train perplexity4.506706714630127
INFO:root:current mean train loss 1909.0059554786012
INFO:root:current train perplexity4.514162540435791
INFO:root:current mean train loss 1908.3670368880676
INFO:root:current train perplexity4.509689807891846
INFO:root:current mean train loss 1909.0481489228039
INFO:root:current train perplexity4.510417461395264
INFO:root:current mean train loss 1912.748520139664
INFO:root:current train perplexity4.513967990875244
INFO:root:current mean train loss 1908.6480605936497
INFO:root:current train perplexity4.505185604095459
INFO:root:current mean train loss 1910.9015670201768
INFO:root:current train perplexity4.509814262390137
INFO:root:current mean train loss 1910.6254792646928
INFO:root:current train perplexity4.510812282562256
INFO:root:current mean train loss 1910.9981392725117
INFO:root:current train perplexity4.5140886306762695
INFO:root:current mean train loss 1912.0046946531647
INFO:root:current train perplexity4.516048908233643
INFO:root:current mean train loss 1912.1957134595664
INFO:root:current train perplexity4.515066623687744
INFO:root:current mean train loss 1912.6167301555256
INFO:root:current train perplexity4.515224933624268
INFO:root:current mean train loss 1914.0085854812269
INFO:root:current train perplexity4.51888370513916
INFO:root:current mean train loss 1916.0047148183924
INFO:root:current train perplexity4.522986888885498
INFO:root:current mean train loss 1915.4690252838482
INFO:root:current train perplexity4.524128437042236
INFO:root:current mean train loss 1916.0719870205583
INFO:root:current train perplexity4.526939392089844
INFO:root:current mean train loss 1916.2591057837863
INFO:root:current train perplexity4.529959201812744

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:29<00:00, 569.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:29<00:00, 569.52s/it]
INFO:root:final mean train loss: 1915.4047144256454
INFO:root:final train perplexity: 4.529462814331055
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it]
INFO:root:eval mean loss: 1996.1387168938386
INFO:root:eval perplexity: 5.024670600891113
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.35s/it]
INFO:root:eval mean loss: 2422.1339622118794
INFO:root:eval perplexity: 7.249175548553467
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/22
 11%|â–ˆ         | 22/200 [3:53:04<31:24:57, 635.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1905.9559092064426
INFO:root:current train perplexity4.454453468322754
INFO:root:current mean train loss 1903.9545517408778
INFO:root:current train perplexity4.457366466522217
INFO:root:current mean train loss 1910.2033051990327
INFO:root:current train perplexity4.461817741394043
INFO:root:current mean train loss 1905.6433966178997
INFO:root:current train perplexity4.4564337730407715
INFO:root:current mean train loss 1902.0874242802754
INFO:root:current train perplexity4.4517693519592285
INFO:root:current mean train loss 1899.3674484705634
INFO:root:current train perplexity4.452206134796143
INFO:root:current mean train loss 1897.191184782167
INFO:root:current train perplexity4.446416854858398
INFO:root:current mean train loss 1898.984754318099
INFO:root:current train perplexity4.453709602355957
INFO:root:current mean train loss 1897.07657989467
INFO:root:current train perplexity4.456967830657959
INFO:root:current mean train loss 1898.8901421134299
INFO:root:current train perplexity4.464935302734375
INFO:root:current mean train loss 1900.7468678100245
INFO:root:current train perplexity4.467986106872559
INFO:root:current mean train loss 1900.6674916038935
INFO:root:current train perplexity4.468940734863281
INFO:root:current mean train loss 1901.8024289594891
INFO:root:current train perplexity4.472748279571533
INFO:root:current mean train loss 1902.0182575578683
INFO:root:current train perplexity4.471643924713135
INFO:root:current mean train loss 1902.053805328597
INFO:root:current train perplexity4.472500801086426
INFO:root:current mean train loss 1902.690175225609
INFO:root:current train perplexity4.473109245300293
INFO:root:current mean train loss 1903.2336376894752
INFO:root:current train perplexity4.476571083068848
INFO:root:current mean train loss 1903.9294463887568
INFO:root:current train perplexity4.482828617095947
INFO:root:current mean train loss 1904.4268467745803
INFO:root:current train perplexity4.487542629241943
INFO:root:current mean train loss 1904.3663951257008
INFO:root:current train perplexity4.488121509552002

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.52s/it]
INFO:root:final mean train loss: 1903.7115261830047
INFO:root:final train perplexity: 4.487884521484375
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.56s/it]
INFO:root:eval mean loss: 1995.1176134474733
INFO:root:eval perplexity: 5.0205230712890625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 2423.5559259509364
INFO:root:eval perplexity: 7.257609844207764
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/23
 12%|â–ˆâ–        | 23/200 [4:03:36<31:11:10, 634.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1864.1222588433159
INFO:root:current train perplexity4.358497619628906
INFO:root:current mean train loss 1876.4074996145148
INFO:root:current train perplexity4.39492130279541
INFO:root:current mean train loss 1877.1328621699893
INFO:root:current train perplexity4.404587268829346
INFO:root:current mean train loss 1882.747309758113
INFO:root:current train perplexity4.413055419921875
INFO:root:current mean train loss 1883.2340558733258
INFO:root:current train perplexity4.416250705718994
INFO:root:current mean train loss 1886.6437005511784
INFO:root:current train perplexity4.419419288635254
INFO:root:current mean train loss 1887.0284016927083
INFO:root:current train perplexity4.424035549163818
INFO:root:current mean train loss 1887.2684408067148
INFO:root:current train perplexity4.430692195892334
INFO:root:current mean train loss 1887.7811661966732
INFO:root:current train perplexity4.4313459396362305
INFO:root:current mean train loss 1885.774983230745
INFO:root:current train perplexity4.42827033996582
INFO:root:current mean train loss 1886.0214368907684
INFO:root:current train perplexity4.424482345581055
INFO:root:current mean train loss 1887.1223169150473
INFO:root:current train perplexity4.430193901062012
INFO:root:current mean train loss 1887.9344889322917
INFO:root:current train perplexity4.435439586639404
INFO:root:current mean train loss 1888.394496034032
INFO:root:current train perplexity4.437870979309082
INFO:root:current mean train loss 1889.5272129135644
INFO:root:current train perplexity4.441583633422852
INFO:root:current mean train loss 1889.192588950103
INFO:root:current train perplexity4.441883087158203
INFO:root:current mean train loss 1889.3239533734745
INFO:root:current train perplexity4.443240165710449
INFO:root:current mean train loss 1890.7623012777146
INFO:root:current train perplexity4.443328380584717
INFO:root:current mean train loss 1891.6487583705357
INFO:root:current train perplexity4.445609092712402

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.97s/it]
INFO:root:final mean train loss: 1892.3220466002033
INFO:root:final train perplexity: 4.447752475738525
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.15s/it]
INFO:root:eval mean loss: 1989.948849076075
INFO:root:eval perplexity: 4.999579429626465
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 2422.833265372202
INFO:root:eval perplexity: 7.253322124481201
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/24
 12%|â–ˆâ–        | 24/200 [4:14:24<31:12:30, 638.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1863.476771763393
INFO:root:current train perplexity4.3310956954956055
INFO:root:current mean train loss 1867.3579306914428
INFO:root:current train perplexity4.353583335876465
INFO:root:current mean train loss 1870.255635874283
INFO:root:current train perplexity4.354280471801758
INFO:root:current mean train loss 1868.307742836421
INFO:root:current train perplexity4.360213756561279
INFO:root:current mean train loss 1862.1464708782823
INFO:root:current train perplexity4.347572326660156
INFO:root:current mean train loss 1863.8682810766456
INFO:root:current train perplexity4.356324195861816
INFO:root:current mean train loss 1869.6848140509164
INFO:root:current train perplexity4.370724201202393
INFO:root:current mean train loss 1870.7338185182218
INFO:root:current train perplexity4.377171516418457
INFO:root:current mean train loss 1872.8780041095492
INFO:root:current train perplexity4.382803916931152
INFO:root:current mean train loss 1874.9962159548993
INFO:root:current train perplexity4.3902130126953125
INFO:root:current mean train loss 1876.584476656568
INFO:root:current train perplexity4.3953471183776855
INFO:root:current mean train loss 1877.0446019780022
INFO:root:current train perplexity4.395556926727295
INFO:root:current mean train loss 1877.6280348682167
INFO:root:current train perplexity4.3958635330200195
INFO:root:current mean train loss 1876.7594004414332
INFO:root:current train perplexity4.3950395584106445
INFO:root:current mean train loss 1877.8582454808825
INFO:root:current train perplexity4.399415493011475
INFO:root:current mean train loss 1879.349508365259
INFO:root:current train perplexity4.402339458465576
INFO:root:current mean train loss 1880.3096073058057
INFO:root:current train perplexity4.406017303466797
INFO:root:current mean train loss 1880.4753955736032
INFO:root:current train perplexity4.407210826873779
INFO:root:current mean train loss 1880.976881625709
INFO:root:current train perplexity4.409233093261719
INFO:root:current mean train loss 1881.3600165892722
INFO:root:current train perplexity4.409255504608154

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.88s/it]
INFO:root:final mean train loss: 1881.819630863807
INFO:root:final train perplexity: 4.411064624786377
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.24s/it]
INFO:root:eval mean loss: 1990.2572185976285
INFO:root:eval perplexity: 5.000825881958008
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it]
INFO:root:eval mean loss: 2424.635461685505
INFO:root:eval perplexity: 7.264021873474121
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/25
 12%|â–ˆâ–Ž        | 25/200 [4:25:03<31:02:20, 638.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1859.294657389323
INFO:root:current train perplexity4.361878871917725
INFO:root:current mean train loss 1875.7762835102696
INFO:root:current train perplexity4.3641133308410645
INFO:root:current mean train loss 1869.097110748291
INFO:root:current train perplexity4.34022855758667
INFO:root:current mean train loss 1866.4971863546489
INFO:root:current train perplexity4.337619304656982
INFO:root:current mean train loss 1872.5969831358711
INFO:root:current train perplexity4.3623881340026855
INFO:root:current mean train loss 1868.7997233849446
INFO:root:current train perplexity4.357326030731201
INFO:root:current mean train loss 1868.8196019881811
INFO:root:current train perplexity4.356930732727051
INFO:root:current mean train loss 1865.0507020054602
INFO:root:current train perplexity4.3595452308654785
INFO:root:current mean train loss 1866.633703435509
INFO:root:current train perplexity4.36059045791626
INFO:root:current mean train loss 1866.1407263289282
INFO:root:current train perplexity4.360994815826416
INFO:root:current mean train loss 1868.7636637687683
INFO:root:current train perplexity4.364217758178711
INFO:root:current mean train loss 1868.5671521387067
INFO:root:current train perplexity4.36099100112915
INFO:root:current mean train loss 1870.5960022172117
INFO:root:current train perplexity4.365663528442383
INFO:root:current mean train loss 1871.5046374732995
INFO:root:current train perplexity4.366540431976318
INFO:root:current mean train loss 1871.3909150027157
INFO:root:current train perplexity4.370493412017822
INFO:root:current mean train loss 1871.1506247532961
INFO:root:current train perplexity4.368483066558838
INFO:root:current mean train loss 1872.044293182824
INFO:root:current train perplexity4.370852947235107
INFO:root:current mean train loss 1872.6902158520338
INFO:root:current train perplexity4.372446537017822
INFO:root:current mean train loss 1871.593344772071
INFO:root:current train perplexity4.372433185577393
INFO:root:current mean train loss 1871.5940815693623
INFO:root:current train perplexity4.372454643249512

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.97s/it]
INFO:root:final mean train loss: 1870.8471800034176
INFO:root:final train perplexity: 4.373058795928955
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it]
INFO:root:eval mean loss: 1986.4320211207612
INFO:root:eval perplexity: 4.985378265380859
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it]
INFO:root:eval mean loss: 2421.3417557520224
INFO:root:eval perplexity: 7.244478702545166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/26
 13%|â–ˆâ–Ž        | 26/200 [4:35:40<30:50:36, 638.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1829.7562106993141
INFO:root:current train perplexity4.307741641998291
INFO:root:current mean train loss 1838.43703682541
INFO:root:current train perplexity4.277945518493652
INFO:root:current mean train loss 1843.0099464511475
INFO:root:current train perplexity4.289910316467285
INFO:root:current mean train loss 1843.1895197088068
INFO:root:current train perplexity4.300876140594482
INFO:root:current mean train loss 1847.3350893742913
INFO:root:current train perplexity4.310092926025391
INFO:root:current mean train loss 1848.7834438810507
INFO:root:current train perplexity4.306572914123535
INFO:root:current mean train loss 1853.42401608662
INFO:root:current train perplexity4.3222198486328125
INFO:root:current mean train loss 1854.9463070188617
INFO:root:current train perplexity4.321793079376221
INFO:root:current mean train loss 1856.8644839546484
INFO:root:current train perplexity4.323896408081055
INFO:root:current mean train loss 1857.7586506469597
INFO:root:current train perplexity4.325450897216797
INFO:root:current mean train loss 1857.9020061511242
INFO:root:current train perplexity4.327703952789307
INFO:root:current mean train loss 1857.8708689737277
INFO:root:current train perplexity4.3294997215271
INFO:root:current mean train loss 1856.4351703357927
INFO:root:current train perplexity4.3260698318481445
INFO:root:current mean train loss 1858.4263899630348
INFO:root:current train perplexity4.330102920532227
INFO:root:current mean train loss 1858.0696620795563
INFO:root:current train perplexity4.329904556274414
INFO:root:current mean train loss 1859.41651214461
INFO:root:current train perplexity4.332904815673828
INFO:root:current mean train loss 1859.595305596816
INFO:root:current train perplexity4.33193302154541
INFO:root:current mean train loss 1860.4180322742407
INFO:root:current train perplexity4.334084987640381
INFO:root:current mean train loss 1860.4001614033432
INFO:root:current train perplexity4.334788799285889
INFO:root:current mean train loss 1860.9422407430327
INFO:root:current train perplexity4.336607456207275

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.96s/it]
INFO:root:final mean train loss: 1860.4801892132934
INFO:root:final train perplexity: 4.3374505043029785
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.50s/it]
INFO:root:eval mean loss: 1985.2880681896886
INFO:root:eval perplexity: 4.980770111083984
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.12s/it]
INFO:root:eval mean loss: 2421.7613291638963
INFO:root:eval perplexity: 7.246964454650879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/27
 14%|â–ˆâ–Ž        | 27/200 [4:46:10<30:32:46, 635.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1837.2727492759968
INFO:root:current train perplexity4.220060348510742
INFO:root:current mean train loss 1836.9631177684928
INFO:root:current train perplexity4.254047393798828
INFO:root:current mean train loss 1837.8814607368884
INFO:root:current train perplexity4.269594192504883
INFO:root:current mean train loss 1835.028890769575
INFO:root:current train perplexity4.266123294830322
INFO:root:current mean train loss 1837.1366971611455
INFO:root:current train perplexity4.270723819732666
INFO:root:current mean train loss 1839.0527787840922
INFO:root:current train perplexity4.273777961730957
INFO:root:current mean train loss 1840.2252805762016
INFO:root:current train perplexity4.277633190155029
INFO:root:current mean train loss 1842.660354815561
INFO:root:current train perplexity4.278740882873535
INFO:root:current mean train loss 1843.2339103360832
INFO:root:current train perplexity4.2826828956604
INFO:root:current mean train loss 1845.6651050671157
INFO:root:current train perplexity4.28397274017334
INFO:root:current mean train loss 1844.837793245658
INFO:root:current train perplexity4.282558441162109
INFO:root:current mean train loss 1844.1353772415398
INFO:root:current train perplexity4.281397342681885
INFO:root:current mean train loss 1844.4984466601252
INFO:root:current train perplexity4.284632682800293
INFO:root:current mean train loss 1844.913728649381
INFO:root:current train perplexity4.287880897521973
INFO:root:current mean train loss 1846.196043917181
INFO:root:current train perplexity4.29345178604126
INFO:root:current mean train loss 1847.5831540148126
INFO:root:current train perplexity4.2953033447265625
INFO:root:current mean train loss 1848.0696461934087
INFO:root:current train perplexity4.298173904418945
INFO:root:current mean train loss 1849.2160411917173
INFO:root:current train perplexity4.301235675811768
INFO:root:current mean train loss 1849.7340627286355
INFO:root:current train perplexity4.303082466125488
INFO:root:current mean train loss 1851.3885644556187
INFO:root:current train perplexity4.304019927978516

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.84s/it]
INFO:root:final mean train loss: 1850.5824617894682
INFO:root:final train perplexity: 4.3037238121032715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 41.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 41.00s/it]
INFO:root:eval mean loss: 1987.961341803801
INFO:root:eval perplexity: 4.991549968719482
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 38.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 38.00s/it]
INFO:root:eval mean loss: 2426.731773430574
INFO:root:eval perplexity: 7.27648401260376
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/28
 14%|â–ˆâ–        | 28/200 [4:56:50<30:25:59, 636.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1834.0663492838542
INFO:root:current train perplexity4.252816677093506
INFO:root:current mean train loss 1832.4846595982142
INFO:root:current train perplexity4.233399391174316
INFO:root:current mean train loss 1831.5339284446022
INFO:root:current train perplexity4.2304205894470215
INFO:root:current mean train loss 1833.6121861979166
INFO:root:current train perplexity4.234677791595459
INFO:root:current mean train loss 1836.6276655016447
INFO:root:current train perplexity4.248389720916748
INFO:root:current mean train loss 1837.8497866423234
INFO:root:current train perplexity4.249582290649414
INFO:root:current mean train loss 1835.7771285445601
INFO:root:current train perplexity4.25026273727417
INFO:root:current mean train loss 1838.8065621849798
INFO:root:current train perplexity4.258273601531982
INFO:root:current mean train loss 1840.589156110491
INFO:root:current train perplexity4.259413719177246
INFO:root:current mean train loss 1841.7130005508814
INFO:root:current train perplexity4.26618766784668
INFO:root:current mean train loss 1842.2844458575582
INFO:root:current train perplexity4.2630085945129395
INFO:root:current mean train loss 1839.439145611702
INFO:root:current train perplexity4.260044097900391
INFO:root:current mean train loss 1839.6190471813725
INFO:root:current train perplexity4.2628350257873535
INFO:root:current mean train loss 1839.4257080965908
INFO:root:current train perplexity4.264031887054443
INFO:root:current mean train loss 1840.5741499768274
INFO:root:current train perplexity4.267061233520508
INFO:root:current mean train loss 1840.9834430028523
INFO:root:current train perplexity4.2670464515686035
INFO:root:current mean train loss 1841.6982668930737
INFO:root:current train perplexity4.26827335357666
INFO:root:current mean train loss 1841.7725402316241
INFO:root:current train perplexity4.269441604614258
INFO:root:current mean train loss 1841.4836296875
INFO:root:current train perplexity4.269683361053467
INFO:root:current mean train loss 1841.9480911293513
INFO:root:current train perplexity4.272515296936035

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.65s/it]
INFO:root:final mean train loss: 1841.3449094525142
INFO:root:final train perplexity: 4.2724833488464355
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.80s/it]
INFO:root:eval mean loss: 1985.1067721319537
INFO:root:eval perplexity: 4.980039596557617
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.71s/it]
INFO:root:eval mean loss: 2426.858454711048
INFO:root:eval perplexity: 7.277238368988037
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/29
 14%|â–ˆâ–        | 29/200 [5:07:17<30:07:11, 634.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1823.3397376019022
INFO:root:current train perplexity4.192957401275635
INFO:root:current mean train loss 1825.5351136525471
INFO:root:current train perplexity4.203839302062988
INFO:root:current mean train loss 1823.6249949834119
INFO:root:current train perplexity4.211150169372559
INFO:root:current mean train loss 1823.1150073615872
INFO:root:current train perplexity4.217813014984131
INFO:root:current mean train loss 1823.8196902391387
INFO:root:current train perplexity4.219363212585449
INFO:root:current mean train loss 1826.0535767013962
INFO:root:current train perplexity4.214488506317139
INFO:root:current mean train loss 1823.8735612637736
INFO:root:current train perplexity4.214386940002441
INFO:root:current mean train loss 1825.0301630810054
INFO:root:current train perplexity4.2174811363220215
INFO:root:current mean train loss 1826.51081800247
INFO:root:current train perplexity4.220234394073486
INFO:root:current mean train loss 1828.2242506704022
INFO:root:current train perplexity4.227985382080078
INFO:root:current mean train loss 1828.682857750973
INFO:root:current train perplexity4.227036952972412
INFO:root:current mean train loss 1829.7103890028575
INFO:root:current train perplexity4.228479862213135
INFO:root:current mean train loss 1830.4290391668078
INFO:root:current train perplexity4.232021331787109
INFO:root:current mean train loss 1830.9614028053722
INFO:root:current train perplexity4.233282566070557
INFO:root:current mean train loss 1830.180555001021
INFO:root:current train perplexity4.233280181884766
INFO:root:current mean train loss 1830.4455199888603
INFO:root:current train perplexity4.237068176269531
INFO:root:current mean train loss 1831.32789968937
INFO:root:current train perplexity4.238743782043457
INFO:root:current mean train loss 1832.1859867913383
INFO:root:current train perplexity4.2389984130859375
INFO:root:current mean train loss 1832.1951683641237
INFO:root:current train perplexity4.23919677734375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.39s/it]
INFO:root:final mean train loss: 1831.7564773598044
INFO:root:final train perplexity: 4.240297317504883
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it]
INFO:root:eval mean loss: 1984.6708988703735
INFO:root:eval perplexity: 4.978283882141113
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.94s/it]
INFO:root:eval mean loss: 2425.4388098750555
INFO:root:eval perplexity: 7.268794536590576
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/30
 15%|â–ˆâ–Œ        | 30/200 [5:17:58<30:02:32, 636.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1841.9296739366318
INFO:root:current train perplexity4.1635918617248535
INFO:root:current mean train loss 1801.4991208697677
INFO:root:current train perplexity4.141505718231201
INFO:root:current mean train loss 1798.8372487337394
INFO:root:current train perplexity4.138218402862549
INFO:root:current mean train loss 1808.7697611688411
INFO:root:current train perplexity4.16034460067749
INFO:root:current mean train loss 1809.4353675002865
INFO:root:current train perplexity4.16024112701416
INFO:root:current mean train loss 1810.776040547489
INFO:root:current train perplexity4.1608052253723145
INFO:root:current mean train loss 1811.3432346588286
INFO:root:current train perplexity4.171442031860352
INFO:root:current mean train loss 1812.9973067053618
INFO:root:current train perplexity4.171989440917969
INFO:root:current mean train loss 1813.2722376197466
INFO:root:current train perplexity4.178403377532959
INFO:root:current mean train loss 1816.3769588995033
INFO:root:current train perplexity4.185035705566406
INFO:root:current mean train loss 1817.0249590840638
INFO:root:current train perplexity4.187621593475342
INFO:root:current mean train loss 1816.5021450912984
INFO:root:current train perplexity4.193227291107178
INFO:root:current mean train loss 1817.676544770019
INFO:root:current train perplexity4.196992874145508
INFO:root:current mean train loss 1818.4003624621014
INFO:root:current train perplexity4.201240062713623
INFO:root:current mean train loss 1819.443338582328
INFO:root:current train perplexity4.202868938446045
INFO:root:current mean train loss 1819.4912610114054
INFO:root:current train perplexity4.203251361846924
INFO:root:current mean train loss 1820.869904986963
INFO:root:current train perplexity4.206370830535889
INFO:root:current mean train loss 1821.499975428796
INFO:root:current train perplexity4.2050299644470215
INFO:root:current mean train loss 1822.013363628904
INFO:root:current train perplexity4.206263065338135
INFO:root:current mean train loss 1822.8944997892386
INFO:root:current train perplexity4.208360195159912

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.91s/it]
INFO:root:final mean train loss: 1822.799022280202
INFO:root:final train perplexity: 4.210447788238525
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.54s/it]
INFO:root:eval mean loss: 1983.4063413362976
INFO:root:eval perplexity: 4.973196029663086
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:45<00:00, 45.29s/it]
INFO:root:eval mean loss: 2424.7220883200353
INFO:root:eval perplexity: 7.264535427093506
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/31
 16%|â–ˆâ–Œ        | 31/200 [5:28:45<30:01:03, 639.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1799.947528545673
INFO:root:current train perplexity4.129789352416992
INFO:root:current mean train loss 1822.0971098400298
INFO:root:current train perplexity4.165218830108643
INFO:root:current mean train loss 1813.3612778925262
INFO:root:current train perplexity4.153757095336914
INFO:root:current mean train loss 1809.117616243889
INFO:root:current train perplexity4.15660285949707
INFO:root:current mean train loss 1812.5613529402326
INFO:root:current train perplexity4.155699253082275
INFO:root:current mean train loss 1812.4117816881535
INFO:root:current train perplexity4.1567912101745605
INFO:root:current mean train loss 1809.630596124326
INFO:root:current train perplexity4.156536102294922
INFO:root:current mean train loss 1808.154509068849
INFO:root:current train perplexity4.155763149261475
INFO:root:current mean train loss 1810.2232116255864
INFO:root:current train perplexity4.15730619430542
INFO:root:current mean train loss 1810.16197636318
INFO:root:current train perplexity4.163839817047119
INFO:root:current mean train loss 1809.9802688687867
INFO:root:current train perplexity4.163928031921387
INFO:root:current mean train loss 1809.6887457459688
INFO:root:current train perplexity4.167799949645996
INFO:root:current mean train loss 1809.9027054803796
INFO:root:current train perplexity4.1693315505981445
INFO:root:current mean train loss 1810.886138869986
INFO:root:current train perplexity4.17139196395874
INFO:root:current mean train loss 1810.3237038461223
INFO:root:current train perplexity4.171240329742432
INFO:root:current mean train loss 1811.1514788586378
INFO:root:current train perplexity4.174314975738525
INFO:root:current mean train loss 1812.3369760736182
INFO:root:current train perplexity4.176138401031494
INFO:root:current mean train loss 1812.4716494174572
INFO:root:current train perplexity4.174248695373535
INFO:root:current mean train loss 1813.3877204485557
INFO:root:current train perplexity4.178765296936035
INFO:root:current mean train loss 1813.04454083309
INFO:root:current train perplexity4.178360939025879

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.33s/it]
INFO:root:final mean train loss: 1813.4511700898063
INFO:root:final train perplexity: 4.179521560668945
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it]
INFO:root:eval mean loss: 1981.745395958001
INFO:root:eval perplexity: 4.966519355773926
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it]
INFO:root:eval mean loss: 2427.2935933863864
INFO:root:eval perplexity: 7.279829502105713
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/32
 16%|â–ˆâ–Œ        | 32/200 [5:39:11<29:39:06, 635.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1792.802240416061
INFO:root:current train perplexity4.108371257781982
INFO:root:current mean train loss 1804.5414407369974
INFO:root:current train perplexity4.137312412261963
INFO:root:current mean train loss 1806.854692623939
INFO:root:current train perplexity4.11836051940918
INFO:root:current mean train loss 1798.9222241282116
INFO:root:current train perplexity4.109578609466553
INFO:root:current mean train loss 1796.5882932090328
INFO:root:current train perplexity4.12180233001709
INFO:root:current mean train loss 1797.566033969268
INFO:root:current train perplexity4.127559661865234
INFO:root:current mean train loss 1799.5100167898886
INFO:root:current train perplexity4.135525226593018
INFO:root:current mean train loss 1800.3838403221737
INFO:root:current train perplexity4.140771389007568
INFO:root:current mean train loss 1801.771483216563
INFO:root:current train perplexity4.145241737365723
INFO:root:current mean train loss 1802.0085051810627
INFO:root:current train perplexity4.141844749450684
INFO:root:current mean train loss 1801.560476652385
INFO:root:current train perplexity4.142834186553955
INFO:root:current mean train loss 1800.521964539589
INFO:root:current train perplexity4.140806674957275
INFO:root:current mean train loss 1801.5755763525744
INFO:root:current train perplexity4.142104625701904
INFO:root:current mean train loss 1802.2900580592948
INFO:root:current train perplexity4.142337322235107
INFO:root:current mean train loss 1803.2078079149612
INFO:root:current train perplexity4.145510196685791
INFO:root:current mean train loss 1803.0416331757838
INFO:root:current train perplexity4.146419048309326
INFO:root:current mean train loss 1803.9167164705616
INFO:root:current train perplexity4.1480021476745605
INFO:root:current mean train loss 1804.014281596251
INFO:root:current train perplexity4.147058486938477
INFO:root:current mean train loss 1805.327015173545
INFO:root:current train perplexity4.149972915649414
INFO:root:current mean train loss 1804.8939597247129
INFO:root:current train perplexity4.148521900177002

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.09s/it]
INFO:root:final mean train loss: 1804.4704180480371
INFO:root:final train perplexity: 4.150023460388184
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.74s/it]
INFO:root:eval mean loss: 1982.137576705175
INFO:root:eval perplexity: 4.968095302581787
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 2427.771477449025
INFO:root:eval perplexity: 7.282674789428711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/33
 16%|â–ˆâ–‹        | 33/200 [5:49:49<29:30:35, 636.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1779.0119689941407
INFO:root:current train perplexity4.081645965576172
INFO:root:current mean train loss 1786.5450889587403
INFO:root:current train perplexity4.114185810089111
INFO:root:current mean train loss 1789.3668269230768
INFO:root:current train perplexity4.112279891967773
INFO:root:current mean train loss 1785.6285702175564
INFO:root:current train perplexity4.105484962463379
INFO:root:current mean train loss 1787.3921707816746
INFO:root:current train perplexity4.111664772033691
INFO:root:current mean train loss 1784.3945332118444
INFO:root:current train perplexity4.100694179534912
INFO:root:current mean train loss 1783.3876046845407
INFO:root:current train perplexity4.101680278778076
INFO:root:current mean train loss 1787.0457794189454
INFO:root:current train perplexity4.101921558380127
INFO:root:current mean train loss 1786.0859917219295
INFO:root:current train perplexity4.099387168884277
INFO:root:current mean train loss 1787.8237846374511
INFO:root:current train perplexity4.102966785430908
INFO:root:current mean train loss 1789.2569515588148
INFO:root:current train perplexity4.104314804077148
INFO:root:current mean train loss 1790.136854079674
INFO:root:current train perplexity4.104721546173096
INFO:root:current mean train loss 1790.9312960185703
INFO:root:current train perplexity4.107781410217285
INFO:root:current mean train loss 1792.8907613417682
INFO:root:current train perplexity4.111148834228516
INFO:root:current mean train loss 1794.8121924831444
INFO:root:current train perplexity4.113853454589844
INFO:root:current mean train loss 1795.9540232340494
INFO:root:current train perplexity4.1159348487854
INFO:root:current mean train loss 1796.798302266684
INFO:root:current train perplexity4.119154453277588
INFO:root:current mean train loss 1796.9084539240057
INFO:root:current train perplexity4.120243549346924
INFO:root:current mean train loss 1796.6832556283603
INFO:root:current train perplexity4.1219353675842285
INFO:root:current mean train loss 1796.6077546411632
INFO:root:current train perplexity4.123055934906006

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.28s/it]
INFO:root:final mean train loss: 1796.2665336328027
INFO:root:final train perplexity: 4.123258590698242
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it]
INFO:root:eval mean loss: 1982.2618910336325
INFO:root:eval perplexity: 4.968595027923584
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it]
INFO:root:eval mean loss: 2429.0176556093475
INFO:root:eval perplexity: 7.290100574493408
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/34
 17%|â–ˆâ–‹        | 34/200 [6:00:17<29:12:44, 633.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1780.2741493126014
INFO:root:current train perplexity4.046126365661621
INFO:root:current mean train loss 1778.6086467161017
INFO:root:current train perplexity4.075059413909912
INFO:root:current mean train loss 1778.5786635195736
INFO:root:current train perplexity4.073277473449707
INFO:root:current mean train loss 1779.3514449628026
INFO:root:current train perplexity4.0753679275512695
INFO:root:current mean train loss 1780.2535346648979
INFO:root:current train perplexity4.073417663574219
INFO:root:current mean train loss 1780.3091584045305
INFO:root:current train perplexity4.0781402587890625
INFO:root:current mean train loss 1779.325134908431
INFO:root:current train perplexity4.076273441314697
INFO:root:current mean train loss 1780.3291625191039
INFO:root:current train perplexity4.074616432189941
INFO:root:current mean train loss 1783.1349837369494
INFO:root:current train perplexity4.08112096786499
INFO:root:current mean train loss 1784.6659095475227
INFO:root:current train perplexity4.083828449249268
INFO:root:current mean train loss 1783.7586616650708
INFO:root:current train perplexity4.082861423492432
INFO:root:current mean train loss 1783.7295856329984
INFO:root:current train perplexity4.087838172912598
INFO:root:current mean train loss 1784.0860402608348
INFO:root:current train perplexity4.087913990020752
INFO:root:current mean train loss 1783.896265233524
INFO:root:current train perplexity4.087409019470215
INFO:root:current mean train loss 1785.0150912626418
INFO:root:current train perplexity4.088531494140625
INFO:root:current mean train loss 1786.0409992921934
INFO:root:current train perplexity4.089195728302002
INFO:root:current mean train loss 1786.1520489469196
INFO:root:current train perplexity4.089107036590576
INFO:root:current mean train loss 1786.7872479320176
INFO:root:current train perplexity4.091019630432129
INFO:root:current mean train loss 1787.58137225241
INFO:root:current train perplexity4.092158317565918
INFO:root:current mean train loss 1787.6764502595274
INFO:root:current train perplexity4.093886375427246

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.57s/it]
INFO:root:final mean train loss: 1787.1170044253104
INFO:root:final train perplexity: 4.093613624572754
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.58s/it]
INFO:root:eval mean loss: 1982.615604048925
INFO:root:eval perplexity: 4.9700164794921875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it]
INFO:root:eval mean loss: 2434.2508488648327
INFO:root:eval perplexity: 7.32136869430542
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/35
 18%|â–ˆâ–Š        | 35/200 [6:10:46<28:58:23, 632.14s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1785.2894949405752
INFO:root:current train perplexity4.032079696655273
INFO:root:current mean train loss 1777.622525244644
INFO:root:current train perplexity4.032143592834473
INFO:root:current mean train loss 1777.0891586615114
INFO:root:current train perplexity4.048196792602539
INFO:root:current mean train loss 1773.3995686642409
INFO:root:current train perplexity4.046093940734863
INFO:root:current mean train loss 1774.5256419316959
INFO:root:current train perplexity4.052474021911621
INFO:root:current mean train loss 1773.9655753498528
INFO:root:current train perplexity4.052043914794922
INFO:root:current mean train loss 1777.4889827145623
INFO:root:current train perplexity4.061620712280273
INFO:root:current mean train loss 1780.8300335401252
INFO:root:current train perplexity4.064184188842773
INFO:root:current mean train loss 1780.0488608955536
INFO:root:current train perplexity4.058626651763916
INFO:root:current mean train loss 1777.7411965690628
INFO:root:current train perplexity4.052581310272217
INFO:root:current mean train loss 1777.003664229426
INFO:root:current train perplexity4.055864334106445
INFO:root:current mean train loss 1776.7826874443833
INFO:root:current train perplexity4.057703971862793
INFO:root:current mean train loss 1777.6041839929785
INFO:root:current train perplexity4.060415744781494
INFO:root:current mean train loss 1778.269040429267
INFO:root:current train perplexity4.061041831970215
INFO:root:current mean train loss 1779.0452975639537
INFO:root:current train perplexity4.062240123748779
INFO:root:current mean train loss 1779.8139460047935
INFO:root:current train perplexity4.063654899597168
INFO:root:current mean train loss 1780.752667747957
INFO:root:current train perplexity4.064695358276367
INFO:root:current mean train loss 1781.1231801044714
INFO:root:current train perplexity4.066105365753174
INFO:root:current mean train loss 1780.5036087438953
INFO:root:current train perplexity4.068382740020752

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.77s/it]
INFO:root:final mean train loss: 1779.2559740583042
INFO:root:final train perplexity: 4.068312644958496
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.66s/it]
INFO:root:eval mean loss: 1985.3270099179965
INFO:root:eval perplexity: 4.980926990509033
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it]
INFO:root:eval mean loss: 2435.380149029671
INFO:root:eval perplexity: 7.3281331062316895
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/36
 18%|â–ˆâ–Š        | 36/200 [6:21:21<28:50:56, 633.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1794.1027610085227
INFO:root:current train perplexity4.021519660949707
INFO:root:current mean train loss 1753.9130298511402
INFO:root:current train perplexity3.9874155521392822
INFO:root:current mean train loss 1761.0635992113448
INFO:root:current train perplexity4.012657642364502
INFO:root:current mean train loss 1763.571242746433
INFO:root:current train perplexity4.016452312469482
INFO:root:current mean train loss 1767.9354390610742
INFO:root:current train perplexity4.020081043243408
INFO:root:current mean train loss 1768.5117242443584
INFO:root:current train perplexity4.023324012756348
INFO:root:current mean train loss 1768.693892408705
INFO:root:current train perplexity4.023406028747559
INFO:root:current mean train loss 1766.3093069427962
INFO:root:current train perplexity4.021840572357178
INFO:root:current mean train loss 1766.6455314438674
INFO:root:current train perplexity4.0229363441467285
INFO:root:current mean train loss 1768.9892150677913
INFO:root:current train perplexity4.02609395980835
INFO:root:current mean train loss 1769.5496952951132
INFO:root:current train perplexity4.029273986816406
INFO:root:current mean train loss 1768.580382806347
INFO:root:current train perplexity4.030506610870361
INFO:root:current mean train loss 1768.7599168268735
INFO:root:current train perplexity4.0311598777771
INFO:root:current mean train loss 1769.093649159307
INFO:root:current train perplexity4.032070636749268
INFO:root:current mean train loss 1769.3899855799577
INFO:root:current train perplexity4.034729957580566
INFO:root:current mean train loss 1770.096252885739
INFO:root:current train perplexity4.037042617797852
INFO:root:current mean train loss 1769.5546081656628
INFO:root:current train perplexity4.036435604095459
INFO:root:current mean train loss 1770.2170615628197
INFO:root:current train perplexity4.037248611450195
INFO:root:current mean train loss 1771.5497483369859
INFO:root:current train perplexity4.040308475494385
INFO:root:current mean train loss 1771.5890287342402
INFO:root:current train perplexity4.041552543640137

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.85s/it]
INFO:root:final mean train loss: 1771.2043878706309
INFO:root:final train perplexity: 4.042561054229736
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it]
INFO:root:eval mean loss: 1986.5462897550974
INFO:root:eval perplexity: 4.985840797424316
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it]
INFO:root:eval mean loss: 2438.079519285378
INFO:root:eval perplexity: 7.344328880310059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/37
 18%|â–ˆâ–Š        | 37/200 [6:31:51<28:37:06, 632.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1723.7679486955915
INFO:root:current train perplexity3.9957375526428223
INFO:root:current mean train loss 1767.2637023925781
INFO:root:current train perplexity4.002204895019531
INFO:root:current mean train loss 1761.571977046498
INFO:root:current train perplexity4.005768775939941
INFO:root:current mean train loss 1755.6674998213605
INFO:root:current train perplexity4.002997875213623
INFO:root:current mean train loss 1753.4870479975905
INFO:root:current train perplexity4.000090599060059
INFO:root:current mean train loss 1755.2213155573065
INFO:root:current train perplexity3.9953839778900146
INFO:root:current mean train loss 1756.9100930766695
INFO:root:current train perplexity3.9981284141540527
INFO:root:current mean train loss 1756.935275402698
INFO:root:current train perplexity4.000070571899414
INFO:root:current mean train loss 1758.8413225994018
INFO:root:current train perplexity4.001987457275391
INFO:root:current mean train loss 1760.4743758892191
INFO:root:current train perplexity4.001563549041748
INFO:root:current mean train loss 1762.3203458674686
INFO:root:current train perplexity4.003211975097656
INFO:root:current mean train loss 1762.77085205511
INFO:root:current train perplexity4.008195400238037
INFO:root:current mean train loss 1762.2612413039813
INFO:root:current train perplexity4.011639595031738
INFO:root:current mean train loss 1762.353927704225
INFO:root:current train perplexity4.009517192840576
INFO:root:current mean train loss 1763.1765324782257
INFO:root:current train perplexity4.011213779449463
INFO:root:current mean train loss 1763.342401953892
INFO:root:current train perplexity4.010483264923096
INFO:root:current mean train loss 1762.8039195367687
INFO:root:current train perplexity4.0104217529296875
INFO:root:current mean train loss 1763.63325048376
INFO:root:current train perplexity4.010823726654053
INFO:root:current mean train loss 1762.991873910182
INFO:root:current train perplexity4.012982368469238
INFO:root:current mean train loss 1762.9577988747244
INFO:root:current train perplexity4.014346122741699

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.73s/it]
INFO:root:final mean train loss: 1762.7270758970783
INFO:root:final train perplexity: 4.015624046325684
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it]
INFO:root:eval mean loss: 1985.0760285938886
INFO:root:eval perplexity: 4.979914665222168
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.00s/it]
INFO:root:eval mean loss: 2442.631280993739
INFO:root:eval perplexity: 7.371720314025879
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/38
 19%|â–ˆâ–‰        | 38/200 [6:42:20<28:24:38, 631.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1745.8542371961805
INFO:root:current train perplexity3.96376633644104
INFO:root:current mean train loss 1746.9742751549031
INFO:root:current train perplexity3.9672365188598633
INFO:root:current mean train loss 1750.6981554926658
INFO:root:current train perplexity3.9703259468078613
INFO:root:current mean train loss 1754.7049595929575
INFO:root:current train perplexity3.974905014038086
INFO:root:current mean train loss 1752.0897507571103
INFO:root:current train perplexity3.9792914390563965
INFO:root:current mean train loss 1749.9217477780962
INFO:root:current train perplexity3.9788060188293457
INFO:root:current mean train loss 1750.5581595960514
INFO:root:current train perplexity3.9747183322906494
INFO:root:current mean train loss 1750.3886587667785
INFO:root:current train perplexity3.9768600463867188
INFO:root:current mean train loss 1750.6848748382026
INFO:root:current train perplexity3.977064371109009
INFO:root:current mean train loss 1749.140812303654
INFO:root:current train perplexity3.9733917713165283
INFO:root:current mean train loss 1749.0027518970544
INFO:root:current train perplexity3.974611520767212
INFO:root:current mean train loss 1749.2990676813251
INFO:root:current train perplexity3.975356101989746
INFO:root:current mean train loss 1748.807431189602
INFO:root:current train perplexity3.9766945838928223
INFO:root:current mean train loss 1750.5306499949174
INFO:root:current train perplexity3.979116439819336
INFO:root:current mean train loss 1751.2233939939717
INFO:root:current train perplexity3.9803802967071533
INFO:root:current mean train loss 1752.3835133179107
INFO:root:current train perplexity3.983762502670288
INFO:root:current mean train loss 1753.607277245797
INFO:root:current train perplexity3.9852523803710938
INFO:root:current mean train loss 1754.5231561436694
INFO:root:current train perplexity3.9873030185699463
INFO:root:current mean train loss 1755.0831759982639
INFO:root:current train perplexity3.9890310764312744
INFO:root:current mean train loss 1755.3856389455134
INFO:root:current train perplexity3.990129232406616

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.28s/it]
INFO:root:final mean train loss: 1755.271720112903
INFO:root:final train perplexity: 3.992081880569458
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.70s/it]
INFO:root:eval mean loss: 1986.2841602081949
INFO:root:eval perplexity: 4.98478364944458
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it]
INFO:root:eval mean loss: 2441.6465241993574
INFO:root:eval perplexity: 7.365784645080566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/39
 20%|â–ˆâ–‰        | 39/200 [6:52:48<28:10:54, 630.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1733.9898937594505
INFO:root:current train perplexity3.9147047996520996
INFO:root:current mean train loss 1741.8102778682003
INFO:root:current train perplexity3.919381618499756
INFO:root:current mean train loss 1735.5072869453722
INFO:root:current train perplexity3.9209578037261963
INFO:root:current mean train loss 1735.1858163064355
INFO:root:current train perplexity3.9223556518554688
INFO:root:current mean train loss 1736.6215064639136
INFO:root:current train perplexity3.922581672668457
INFO:root:current mean train loss 1736.8450882120912
INFO:root:current train perplexity3.931321620941162
INFO:root:current mean train loss 1740.2082373858218
INFO:root:current train perplexity3.9413957595825195
INFO:root:current mean train loss 1743.474378851142
INFO:root:current train perplexity3.94533371925354
INFO:root:current mean train loss 1744.4803893051678
INFO:root:current train perplexity3.946287155151367
INFO:root:current mean train loss 1746.369072737664
INFO:root:current train perplexity3.9497058391571045
INFO:root:current mean train loss 1749.280602521591
INFO:root:current train perplexity3.95884370803833
INFO:root:current mean train loss 1748.361023684582
INFO:root:current train perplexity3.956925392150879
INFO:root:current mean train loss 1747.5252892544077
INFO:root:current train perplexity3.9558825492858887
INFO:root:current mean train loss 1748.495300920349
INFO:root:current train perplexity3.958071708679199
INFO:root:current mean train loss 1749.5790141427892
INFO:root:current train perplexity3.962700366973877
INFO:root:current mean train loss 1750.4099212529259
INFO:root:current train perplexity3.965498924255371
INFO:root:current mean train loss 1749.51209575777
INFO:root:current train perplexity3.965179443359375
INFO:root:current mean train loss 1749.5493078156037
INFO:root:current train perplexity3.966099739074707
INFO:root:current mean train loss 1749.0422445885222
INFO:root:current train perplexity3.967348098754883
INFO:root:current mean train loss 1748.478046755543
INFO:root:current train perplexity3.9680681228637695

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.19s/it]
INFO:root:final mean train loss: 1747.7426725802131
INFO:root:final train perplexity: 3.9684479236602783
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.07s/it]
INFO:root:eval mean loss: 1986.735835082142
INFO:root:eval perplexity: 4.986604690551758
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.09s/it]
INFO:root:eval mean loss: 2443.656454749141
INFO:root:eval perplexity: 7.377902507781982
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/40
 20%|â–ˆâ–ˆ        | 40/200 [7:03:26<28:07:10, 632.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1730.6287579113923
INFO:root:current train perplexity3.927341938018799
INFO:root:current mean train loss 1726.621736835501
INFO:root:current train perplexity3.925109386444092
INFO:root:current mean train loss 1728.7004884562612
INFO:root:current train perplexity3.923574924468994
INFO:root:current mean train loss 1731.544810433501
INFO:root:current train perplexity3.9282820224761963
INFO:root:current mean train loss 1730.7553769551637
INFO:root:current train perplexity3.92779278755188
INFO:root:current mean train loss 1731.2779707570974
INFO:root:current train perplexity3.927457094192505
INFO:root:current mean train loss 1730.1521120141638
INFO:root:current train perplexity3.9242212772369385
INFO:root:current mean train loss 1732.8847245692596
INFO:root:current train perplexity3.926729679107666
INFO:root:current mean train loss 1736.6643934369222
INFO:root:current train perplexity3.932310104370117
INFO:root:current mean train loss 1737.444232071749
INFO:root:current train perplexity3.9371981620788574
INFO:root:current mean train loss 1738.146806916669
INFO:root:current train perplexity3.9405901432037354
INFO:root:current mean train loss 1740.5514388145077
INFO:root:current train perplexity3.9420325756073
INFO:root:current mean train loss 1739.7482268786039
INFO:root:current train perplexity3.9393868446350098
INFO:root:current mean train loss 1740.2664101803277
INFO:root:current train perplexity3.9410762786865234
INFO:root:current mean train loss 1740.2402082937163
INFO:root:current train perplexity3.9408743381500244
INFO:root:current mean train loss 1740.9576428385005
INFO:root:current train perplexity3.9431028366088867
INFO:root:current mean train loss 1740.2820019792985
INFO:root:current train perplexity3.942835807800293
INFO:root:current mean train loss 1741.1846242457577
INFO:root:current train perplexity3.945052146911621
INFO:root:current mean train loss 1741.2192270422058
INFO:root:current train perplexity3.9465134143829346
INFO:root:current mean train loss 1741.2001446708998
INFO:root:current train perplexity3.946737051010132

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.39s/it]
INFO:root:final mean train loss: 1740.8202614680843
INFO:root:final train perplexity: 3.94684100151062
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 37.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 37.00s/it]
INFO:root:eval mean loss: 1987.6186852421322
INFO:root:eval perplexity: 4.990166187286377
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.15s/it]
INFO:root:eval mean loss: 2445.1967163085938
INFO:root:eval perplexity: 7.387203216552734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/41
 20%|â–ˆâ–ˆ        | 41/200 [7:14:07<28:03:01, 635.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1724.6734364827473
INFO:root:current train perplexity3.885291337966919
INFO:root:current mean train loss 1733.4899341816804
INFO:root:current train perplexity3.9125776290893555
INFO:root:current mean train loss 1740.6449741672825
INFO:root:current train perplexity3.914853096008301
INFO:root:current mean train loss 1737.8482613611702
INFO:root:current train perplexity3.90857195854187
INFO:root:current mean train loss 1732.3752010714622
INFO:root:current train perplexity3.909529447555542
INFO:root:current mean train loss 1733.5902496952338
INFO:root:current train perplexity3.907402515411377
INFO:root:current mean train loss 1734.9047086869164
INFO:root:current train perplexity3.9097633361816406
INFO:root:current mean train loss 1733.6148810458542
INFO:root:current train perplexity3.9054722785949707
INFO:root:current mean train loss 1733.1700350897652
INFO:root:current train perplexity3.9085633754730225
INFO:root:current mean train loss 1732.8908472022856
INFO:root:current train perplexity3.910165786743164
INFO:root:current mean train loss 1733.5396177194414
INFO:root:current train perplexity3.913408041000366
INFO:root:current mean train loss 1733.7301563275698
INFO:root:current train perplexity3.913925886154175
INFO:root:current mean train loss 1734.5960081124013
INFO:root:current train perplexity3.9155681133270264
INFO:root:current mean train loss 1735.213080725902
INFO:root:current train perplexity3.9177756309509277
INFO:root:current mean train loss 1734.4909180013892
INFO:root:current train perplexity3.9190900325775146
INFO:root:current mean train loss 1734.4668556156016
INFO:root:current train perplexity3.9194228649139404
INFO:root:current mean train loss 1733.4484802102143
INFO:root:current train perplexity3.919119119644165
INFO:root:current mean train loss 1732.917420996855
INFO:root:current train perplexity3.9208288192749023
INFO:root:current mean train loss 1733.235083728903
INFO:root:current train perplexity3.9209017753601074

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.90s/it]
INFO:root:final mean train loss: 1733.0975426131886
INFO:root:final train perplexity: 3.9228756427764893
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.61s/it]
INFO:root:eval mean loss: 1989.0852141684675
INFO:root:eval perplexity: 4.996088027954102
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.09s/it]
INFO:root:eval mean loss: 2449.975947819703
INFO:root:eval perplexity: 7.416133403778076
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/42
 21%|â–ˆâ–ˆ        | 42/200 [7:24:37<27:48:18, 633.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1696.5916841947114
INFO:root:current train perplexity3.8604724407196045
INFO:root:current mean train loss 1717.636024137514
INFO:root:current train perplexity3.83589768409729
INFO:root:current mean train loss 1708.1579137094704
INFO:root:current train perplexity3.8560802936553955
INFO:root:current mean train loss 1709.440469857603
INFO:root:current train perplexity3.8588969707489014
INFO:root:current mean train loss 1713.697136461013
INFO:root:current train perplexity3.86332106590271
INFO:root:current mean train loss 1714.2637168482731
INFO:root:current train perplexity3.869014024734497
INFO:root:current mean train loss 1717.70946827526
INFO:root:current train perplexity3.877716064453125
INFO:root:current mean train loss 1719.2007149245594
INFO:root:current train perplexity3.880872964859009
INFO:root:current mean train loss 1718.0645196405578
INFO:root:current train perplexity3.8778905868530273
INFO:root:current mean train loss 1717.4366163606842
INFO:root:current train perplexity3.878464460372925
INFO:root:current mean train loss 1718.2690199525312
INFO:root:current train perplexity3.8790462017059326
INFO:root:current mean train loss 1719.7440648383101
INFO:root:current train perplexity3.881608724594116
INFO:root:current mean train loss 1721.1298220289314
INFO:root:current train perplexity3.8820395469665527
INFO:root:current mean train loss 1720.0773768661045
INFO:root:current train perplexity3.8809022903442383
INFO:root:current mean train loss 1720.3619329475462
INFO:root:current train perplexity3.883145332336426
INFO:root:current mean train loss 1720.3224244051553
INFO:root:current train perplexity3.882453680038452
INFO:root:current mean train loss 1721.8365534518125
INFO:root:current train perplexity3.8869593143463135
INFO:root:current mean train loss 1723.4783022691824
INFO:root:current train perplexity3.8911325931549072
INFO:root:current mean train loss 1724.576291858065
INFO:root:current train perplexity3.894758939743042
INFO:root:current mean train loss 1726.3080271089257
INFO:root:current train perplexity3.8992302417755127

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.90s/it]
INFO:root:final mean train loss: 1725.4495732032826
INFO:root:final train perplexity: 3.8992860317230225
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.77s/it]
INFO:root:eval mean loss: 1990.4722406914893
INFO:root:eval perplexity: 5.00169563293457
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.75s/it]
INFO:root:eval mean loss: 2453.008109884059
INFO:root:eval perplexity: 7.43454647064209
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/43
 22%|â–ˆâ–ˆâ–       | 43/200 [7:35:03<27:31:36, 631.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1714.7994099934897
INFO:root:current train perplexity3.8294811248779297
INFO:root:current mean train loss 1704.9169067382813
INFO:root:current train perplexity3.8330421447753906
INFO:root:current mean train loss 1707.7954218325408
INFO:root:current train perplexity3.8325648307800293
INFO:root:current mean train loss 1711.579804761482
INFO:root:current train perplexity3.846872091293335
INFO:root:current mean train loss 1710.9288449309593
INFO:root:current train perplexity3.843967914581299
INFO:root:current mean train loss 1712.3535877155807
INFO:root:current train perplexity3.8479058742523193
INFO:root:current mean train loss 1711.5450497581846
INFO:root:current train perplexity3.847029209136963
INFO:root:current mean train loss 1712.9880730615903
INFO:root:current train perplexity3.8557424545288086
INFO:root:current mean train loss 1713.7771746164344
INFO:root:current train perplexity3.8584322929382324
INFO:root:current mean train loss 1712.6187304424984
INFO:root:current train perplexity3.856975555419922
INFO:root:current mean train loss 1711.2573027675592
INFO:root:current train perplexity3.858478307723999
INFO:root:current mean train loss 1711.060956728775
INFO:root:current train perplexity3.8573179244995117
INFO:root:current mean train loss 1711.4831816882622
INFO:root:current train perplexity3.857419729232788
INFO:root:current mean train loss 1712.259002731438
INFO:root:current train perplexity3.8629679679870605
INFO:root:current mean train loss 1713.782449532889
INFO:root:current train perplexity3.8655738830566406
INFO:root:current mean train loss 1715.9512041877297
INFO:root:current train perplexity3.867671251296997
INFO:root:current mean train loss 1716.1857950596723
INFO:root:current train perplexity3.8695263862609863
INFO:root:current mean train loss 1718.388318858946
INFO:root:current train perplexity3.872925281524658
INFO:root:current mean train loss 1719.1829937377263
INFO:root:current train perplexity3.874793291091919
INFO:root:current mean train loss 1718.7195931706403
INFO:root:current train perplexity3.8759384155273438

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.07s/it]
INFO:root:final mean train loss: 1718.2492468329433
INFO:root:final train perplexity: 3.8772060871124268
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.54s/it]
INFO:root:eval mean loss: 1992.9265742741577
INFO:root:eval perplexity: 5.0116353034973145
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it]
INFO:root:eval mean loss: 2455.2069182700297
INFO:root:eval perplexity: 7.447926998138428
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/44
 22%|â–ˆâ–ˆâ–       | 44/200 [7:45:40<27:25:45, 632.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1680.3267562541555
INFO:root:current train perplexity3.79209041595459
INFO:root:current mean train loss 1699.8925324524341
INFO:root:current train perplexity3.8164045810699463
INFO:root:current mean train loss 1701.6580622746394
INFO:root:current train perplexity3.8261213302612305
INFO:root:current mean train loss 1700.852907735951
INFO:root:current train perplexity3.8300952911376953
INFO:root:current mean train loss 1702.023245792261
INFO:root:current train perplexity3.832519054412842
INFO:root:current mean train loss 1700.092431774523
INFO:root:current train perplexity3.8346071243286133
INFO:root:current mean train loss 1703.4338912845947
INFO:root:current train perplexity3.8371686935424805
INFO:root:current mean train loss 1704.3877247270332
INFO:root:current train perplexity3.8403995037078857
INFO:root:current mean train loss 1705.3247605000645
INFO:root:current train perplexity3.8424556255340576
INFO:root:current mean train loss 1705.7504998824413
INFO:root:current train perplexity3.845919609069824
INFO:root:current mean train loss 1706.3034412635432
INFO:root:current train perplexity3.8466458320617676
INFO:root:current mean train loss 1707.4473734342646
INFO:root:current train perplexity3.8473598957061768
INFO:root:current mean train loss 1707.1708468488434
INFO:root:current train perplexity3.846264362335205
INFO:root:current mean train loss 1708.1551273518699
INFO:root:current train perplexity3.8476099967956543
INFO:root:current mean train loss 1709.103721718831
INFO:root:current train perplexity3.8478100299835205
INFO:root:current mean train loss 1710.3000927008425
INFO:root:current train perplexity3.8511388301849365
INFO:root:current mean train loss 1710.6913931313325
INFO:root:current train perplexity3.852834939956665
INFO:root:current mean train loss 1711.6662210552913
INFO:root:current train perplexity3.853522539138794
INFO:root:current mean train loss 1711.4447897191815
INFO:root:current train perplexity3.8540310859680176
INFO:root:current mean train loss 1711.9736152574474
INFO:root:current train perplexity3.8559608459472656

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.48s/it]
INFO:root:final mean train loss: 1711.424549097012
INFO:root:final train perplexity: 3.856393337249756
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.49s/it]
INFO:root:eval mean loss: 1992.2947651748116
INFO:root:eval perplexity: 5.009073734283447
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it]
INFO:root:eval mean loss: 2457.8863109832114
INFO:root:eval perplexity: 7.464263916015625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/45
 22%|â–ˆâ–ˆâ–Ž       | 45/200 [7:56:09<27:12:20, 631.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1716.5184631347656
INFO:root:current train perplexity3.838452100753784
INFO:root:current mean train loss 1700.877193543969
INFO:root:current train perplexity3.793931722640991
INFO:root:current mean train loss 1694.8595932469223
INFO:root:current train perplexity3.7943944931030273
INFO:root:current mean train loss 1691.5510750236092
INFO:root:current train perplexity3.786973476409912
INFO:root:current mean train loss 1689.1108227433829
INFO:root:current train perplexity3.790904998779297
INFO:root:current mean train loss 1692.7462409269724
INFO:root:current train perplexity3.7994906902313232
INFO:root:current mean train loss 1695.7925484898578
INFO:root:current train perplexity3.8015389442443848
INFO:root:current mean train loss 1694.873269605387
INFO:root:current train perplexity3.807682514190674
INFO:root:current mean train loss 1698.1410076000072
INFO:root:current train perplexity3.8121917247772217
INFO:root:current mean train loss 1699.896582892327
INFO:root:current train perplexity3.814408302307129
INFO:root:current mean train loss 1700.1394445663109
INFO:root:current train perplexity3.8179879188537598
INFO:root:current mean train loss 1701.2034497867335
INFO:root:current train perplexity3.8204283714294434
INFO:root:current mean train loss 1700.635220588008
INFO:root:current train perplexity3.820669174194336
INFO:root:current mean train loss 1700.614246983682
INFO:root:current train perplexity3.8237392902374268
INFO:root:current mean train loss 1700.5761622027621
INFO:root:current train perplexity3.825457811355591
INFO:root:current mean train loss 1700.756091730064
INFO:root:current train perplexity3.8273403644561768
INFO:root:current mean train loss 1702.035802767827
INFO:root:current train perplexity3.829833984375
INFO:root:current mean train loss 1702.875824666618
INFO:root:current train perplexity3.8304436206817627
INFO:root:current mean train loss 1703.7861671938917
INFO:root:current train perplexity3.8320188522338867
INFO:root:current mean train loss 1704.5781993360965
INFO:root:current train perplexity3.834334135055542

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.41s/it]
INFO:root:final mean train loss: 1704.3284920727551
INFO:root:final train perplexity: 3.834871768951416
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it]
INFO:root:eval mean loss: 1993.4321358322252
INFO:root:eval perplexity: 5.013683795928955
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it]
INFO:root:eval mean loss: 2459.504574606605
INFO:root:eval perplexity: 7.474151134490967
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/46
 23%|â–ˆâ–ˆâ–Ž       | 46/200 [8:06:36<26:57:35, 630.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1681.120531623746
INFO:root:current train perplexity3.770521879196167
INFO:root:current mean train loss 1684.659243083132
INFO:root:current train perplexity3.7760426998138428
INFO:root:current mean train loss 1679.0313386204405
INFO:root:current train perplexity3.7725577354431152
INFO:root:current mean train loss 1683.092878526903
INFO:root:current train perplexity3.7748517990112305
INFO:root:current mean train loss 1683.3605459613761
INFO:root:current train perplexity3.788705587387085
INFO:root:current mean train loss 1685.9754079795746
INFO:root:current train perplexity3.7877771854400635
INFO:root:current mean train loss 1686.420662004692
INFO:root:current train perplexity3.7866687774658203
INFO:root:current mean train loss 1687.612197621989
INFO:root:current train perplexity3.7908196449279785
INFO:root:current mean train loss 1687.800513692936
INFO:root:current train perplexity3.795938491821289
INFO:root:current mean train loss 1689.6292121101715
INFO:root:current train perplexity3.7992799282073975
INFO:root:current mean train loss 1690.7253105170632
INFO:root:current train perplexity3.802122116088867
INFO:root:current mean train loss 1692.2820337927008
INFO:root:current train perplexity3.8050172328948975
INFO:root:current mean train loss 1693.112208536879
INFO:root:current train perplexity3.8049769401550293
INFO:root:current mean train loss 1694.4415915210898
INFO:root:current train perplexity3.8058905601501465
INFO:root:current mean train loss 1695.254107365167
INFO:root:current train perplexity3.805140256881714
INFO:root:current mean train loss 1696.596444348909
INFO:root:current train perplexity3.8073325157165527
INFO:root:current mean train loss 1697.7733949460421
INFO:root:current train perplexity3.8095977306365967
INFO:root:current mean train loss 1698.1286141996902
INFO:root:current train perplexity3.810429811477661
INFO:root:current mean train loss 1697.5116831867192
INFO:root:current train perplexity3.812546730041504
INFO:root:current mean train loss 1698.0810782881713
INFO:root:current train perplexity3.8147897720336914

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.67s/it]
INFO:root:final mean train loss: 1697.734452348133
INFO:root:final train perplexity: 3.8149802684783936
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 1995.4570247568984
INFO:root:eval perplexity: 5.021900653839111
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it]
INFO:root:eval mean loss: 2463.2188279172206
INFO:root:eval perplexity: 7.496887683868408
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/47
 24%|â–ˆâ–ˆâ–Ž       | 47/200 [8:17:12<26:52:11, 632.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1686.923328633211
INFO:root:current train perplexity3.7584609985351562
INFO:root:current mean train loss 1677.92906913372
INFO:root:current train perplexity3.7504734992980957
INFO:root:current mean train loss 1675.2072368852243
INFO:root:current train perplexity3.746438980102539
INFO:root:current mean train loss 1676.5579045741401
INFO:root:current train perplexity3.7616515159606934
INFO:root:current mean train loss 1677.27962386656
INFO:root:current train perplexity3.76642107963562
INFO:root:current mean train loss 1679.7432059093462
INFO:root:current train perplexity3.771022081375122
INFO:root:current mean train loss 1681.8779092258574
INFO:root:current train perplexity3.7745158672332764
INFO:root:current mean train loss 1682.6607439619556
INFO:root:current train perplexity3.7760229110717773
INFO:root:current mean train loss 1685.9205418780014
INFO:root:current train perplexity3.782374858856201
INFO:root:current mean train loss 1686.52251389987
INFO:root:current train perplexity3.7794740200042725
INFO:root:current mean train loss 1687.1193777615906
INFO:root:current train perplexity3.7802774906158447
INFO:root:current mean train loss 1689.678625039943
INFO:root:current train perplexity3.7838189601898193
INFO:root:current mean train loss 1690.2367822679423
INFO:root:current train perplexity3.783665418624878
INFO:root:current mean train loss 1690.1681222547277
INFO:root:current train perplexity3.7861859798431396
INFO:root:current mean train loss 1690.5328237128672
INFO:root:current train perplexity3.789093255996704
INFO:root:current mean train loss 1691.0929760986633
INFO:root:current train perplexity3.7910144329071045
INFO:root:current mean train loss 1690.9236455227658
INFO:root:current train perplexity3.792917490005493
INFO:root:current mean train loss 1691.7701986989666
INFO:root:current train perplexity3.7930245399475098
INFO:root:current mean train loss 1691.7487941536938
INFO:root:current train perplexity3.7950615882873535

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.39s/it]
INFO:root:final mean train loss: 1691.2474844158749
INFO:root:final train perplexity: 3.7955126762390137
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.25s/it]
INFO:root:eval mean loss: 1996.9141555677913
INFO:root:eval perplexity: 5.0278215408325195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.25s/it]
INFO:root:eval mean loss: 2466.3678575880986
INFO:root:eval perplexity: 7.5162200927734375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/48
 24%|â–ˆâ–ˆâ–       | 48/200 [8:27:40<26:37:49, 630.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1658.0742350260416
INFO:root:current train perplexity3.7065787315368652
INFO:root:current mean train loss 1678.238420304008
INFO:root:current train perplexity3.7395451068878174
INFO:root:current mean train loss 1668.5150992460028
INFO:root:current train perplexity3.736523151397705
INFO:root:current mean train loss 1674.8545851934523
INFO:root:current train perplexity3.7473974227905273
INFO:root:current mean train loss 1675.8924572312687
INFO:root:current train perplexity3.7472000122070312
INFO:root:current mean train loss 1675.2980328902458
INFO:root:current train perplexity3.747115135192871
INFO:root:current mean train loss 1674.8143574536332
INFO:root:current train perplexity3.7464778423309326
INFO:root:current mean train loss 1675.7244278914445
INFO:root:current train perplexity3.7482693195343018
INFO:root:current mean train loss 1673.8553857721433
INFO:root:current train perplexity3.7477731704711914
INFO:root:current mean train loss 1673.9838066726434
INFO:root:current train perplexity3.748904228210449
INFO:root:current mean train loss 1674.341362352794
INFO:root:current train perplexity3.7521631717681885
INFO:root:current mean train loss 1675.9745205866382
INFO:root:current train perplexity3.754568099975586
INFO:root:current mean train loss 1676.8880372098445
INFO:root:current train perplexity3.7551536560058594
INFO:root:current mean train loss 1677.539535650101
INFO:root:current train perplexity3.757545232772827
INFO:root:current mean train loss 1679.9546245237964
INFO:root:current train perplexity3.7621872425079346
INFO:root:current mean train loss 1680.6431601143513
INFO:root:current train perplexity3.7652525901794434
INFO:root:current mean train loss 1680.7972465019109
INFO:root:current train perplexity3.7654197216033936
INFO:root:current mean train loss 1681.3795312642355
INFO:root:current train perplexity3.7669923305511475
INFO:root:current mean train loss 1681.943274026666
INFO:root:current train perplexity3.7693488597869873
INFO:root:current mean train loss 1683.2456775635403
INFO:root:current train perplexity3.7705883979797363

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.15s/it]
INFO:root:final mean train loss: 1683.4449271443993
INFO:root:final train perplexity: 3.772228956222534
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it]
INFO:root:eval mean loss: 2000.0963719144781
INFO:root:eval perplexity: 5.040778160095215
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.71s/it]
INFO:root:eval mean loss: 2471.114205867686
INFO:root:eval perplexity: 7.54545259475708
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/49
 24%|â–ˆâ–ˆâ–       | 49/200 [8:38:11<26:28:01, 631.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1662.0192909240723
INFO:root:current train perplexity3.747520923614502
INFO:root:current mean train loss 1666.7313657818418
INFO:root:current train perplexity3.7158448696136475
INFO:root:current mean train loss 1670.5002562424231
INFO:root:current train perplexity3.7156951427459717
INFO:root:current mean train loss 1669.0761648890484
INFO:root:current train perplexity3.7154595851898193
INFO:root:current mean train loss 1672.0322556672272
INFO:root:current train perplexity3.72283673286438
INFO:root:current mean train loss 1672.796780234889
INFO:root:current train perplexity3.718916416168213
INFO:root:current mean train loss 1675.4410572293439
INFO:root:current train perplexity3.7279539108276367
INFO:root:current mean train loss 1676.1881707196678
INFO:root:current train perplexity3.7323131561279297
INFO:root:current mean train loss 1675.9946632385254
INFO:root:current train perplexity3.7336337566375732
INFO:root:current mean train loss 1676.7764562516766
INFO:root:current train perplexity3.736948013305664
INFO:root:current mean train loss 1676.5503458422284
INFO:root:current train perplexity3.7401251792907715
INFO:root:current mean train loss 1675.8543573925435
INFO:root:current train perplexity3.7403922080993652
INFO:root:current mean train loss 1676.1156896615958
INFO:root:current train perplexity3.7414474487304688
INFO:root:current mean train loss 1675.9699101261906
INFO:root:current train perplexity3.7433221340179443
INFO:root:current mean train loss 1676.198756127384
INFO:root:current train perplexity3.7450218200683594
INFO:root:current mean train loss 1676.4265943880803
INFO:root:current train perplexity3.7463371753692627
INFO:root:current mean train loss 1675.733787910611
INFO:root:current train perplexity3.7489895820617676
INFO:root:current mean train loss 1676.026801974889
INFO:root:current train perplexity3.7489891052246094
INFO:root:current mean train loss 1676.945206021638
INFO:root:current train perplexity3.7509958744049072
INFO:root:current mean train loss 1677.4304765341938
INFO:root:current train perplexity3.7524900436401367

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.93s/it]
INFO:root:final mean train loss: 1677.0259153180452
INFO:root:final train perplexity: 3.7531800270080566
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it]
INFO:root:eval mean loss: 2002.733908795296
INFO:root:eval perplexity: 5.051543235778809
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it]
INFO:root:eval mean loss: 2477.674915935976
INFO:root:eval perplexity: 7.586047172546387
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/50
 25%|â–ˆâ–ˆâ–Œ       | 50/200 [8:48:50<26:23:34, 633.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1645.6513522401149
INFO:root:current train perplexity3.687747001647949
INFO:root:current mean train loss 1659.419241886011
INFO:root:current train perplexity3.6898818016052246
INFO:root:current mean train loss 1659.4350076085593
INFO:root:current train perplexity3.6948020458221436
INFO:root:current mean train loss 1658.852693311806
INFO:root:current train perplexity3.7020227909088135
INFO:root:current mean train loss 1660.1203781841593
INFO:root:current train perplexity3.705432176589966
INFO:root:current mean train loss 1660.200560411686
INFO:root:current train perplexity3.7088382244110107
INFO:root:current mean train loss 1662.3183789363443
INFO:root:current train perplexity3.709641456604004
INFO:root:current mean train loss 1663.6227005473443
INFO:root:current train perplexity3.7110047340393066
INFO:root:current mean train loss 1663.2455029526925
INFO:root:current train perplexity3.708524227142334
INFO:root:current mean train loss 1663.4492075591495
INFO:root:current train perplexity3.7110745906829834
INFO:root:current mean train loss 1664.2391520337449
INFO:root:current train perplexity3.7163760662078857
INFO:root:current mean train loss 1664.2414821694476
INFO:root:current train perplexity3.717003107070923
INFO:root:current mean train loss 1666.5921146096564
INFO:root:current train perplexity3.7222118377685547
INFO:root:current mean train loss 1667.1102667738544
INFO:root:current train perplexity3.725717067718506
INFO:root:current mean train loss 1667.066322173967
INFO:root:current train perplexity3.7261199951171875
INFO:root:current mean train loss 1667.985508307401
INFO:root:current train perplexity3.7294604778289795
INFO:root:current mean train loss 1668.7858036149987
INFO:root:current train perplexity3.731513500213623
INFO:root:current mean train loss 1669.5611313328598
INFO:root:current train perplexity3.732903480529785
INFO:root:current mean train loss 1670.2667825223305
INFO:root:current train perplexity3.733468770980835
INFO:root:current mean train loss 1671.6452583481312
INFO:root:current train perplexity3.7365739345550537

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.01s/it]
INFO:root:final mean train loss: 1671.3602481751627
INFO:root:final train perplexity: 3.736447334289551
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.39s/it]
INFO:root:eval mean loss: 2000.6400570700355
INFO:root:eval perplexity: 5.042995452880859
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.83s/it]
INFO:root:eval mean loss: 2473.7686862810283
INFO:root:eval perplexity: 7.561850070953369
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/51
 26%|â–ˆâ–ˆâ–Œ       | 51/200 [8:59:27<26:15:18, 634.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1633.7217647668087
INFO:root:current train perplexity3.6473686695098877
INFO:root:current mean train loss 1646.6745303969785
INFO:root:current train perplexity3.653944730758667
INFO:root:current mean train loss 1649.4195818219866
INFO:root:current train perplexity3.6706206798553467
INFO:root:current mean train loss 1646.5454855330004
INFO:root:current train perplexity3.668328285217285
INFO:root:current mean train loss 1653.7849888617388
INFO:root:current train perplexity3.6759042739868164
INFO:root:current mean train loss 1654.4295130214084
INFO:root:current train perplexity3.6792378425598145
INFO:root:current mean train loss 1654.554415316195
INFO:root:current train perplexity3.683837413787842
INFO:root:current mean train loss 1656.5415343441477
INFO:root:current train perplexity3.6868598461151123
INFO:root:current mean train loss 1656.6775122239462
INFO:root:current train perplexity3.6872241497039795
INFO:root:current mean train loss 1658.5499850128995
INFO:root:current train perplexity3.69288969039917
INFO:root:current mean train loss 1661.6434405185491
INFO:root:current train perplexity3.696958541870117
INFO:root:current mean train loss 1662.488289730013
INFO:root:current train perplexity3.7011311054229736
INFO:root:current mean train loss 1663.3321191869077
INFO:root:current train perplexity3.7050492763519287
INFO:root:current mean train loss 1664.0543251316858
INFO:root:current train perplexity3.7070086002349854
INFO:root:current mean train loss 1664.9020369921343
INFO:root:current train perplexity3.709620714187622
INFO:root:current mean train loss 1665.3575867400773
INFO:root:current train perplexity3.710754871368408
INFO:root:current mean train loss 1664.0293879514697
INFO:root:current train perplexity3.710780382156372
INFO:root:current mean train loss 1665.3040977469386
INFO:root:current train perplexity3.713024377822876
INFO:root:current mean train loss 1665.1719170638858
INFO:root:current train perplexity3.7135250568389893
INFO:root:current mean train loss 1664.9949030366822
INFO:root:current train perplexity3.7164695262908936

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.38s/it]
INFO:root:final mean train loss: 1664.5203561018166
INFO:root:final train perplexity: 3.716346025466919
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.74s/it]
INFO:root:eval mean loss: 2006.0880261143893
INFO:root:eval perplexity: 5.065263271331787
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.51s/it]
INFO:root:eval mean loss: 2481.6047012653758
INFO:root:eval perplexity: 7.6104655265808105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/52
 26%|â–ˆâ–ˆâ–Œ       | 52/200 [9:09:57<26:01:26, 633.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1619.604265695595
INFO:root:current train perplexity3.634186029434204
INFO:root:current mean train loss 1634.4625077377902
INFO:root:current train perplexity3.6609046459198
INFO:root:current mean train loss 1636.948275832321
INFO:root:current train perplexity3.660183906555176
INFO:root:current mean train loss 1641.4974209060867
INFO:root:current train perplexity3.6601860523223877
INFO:root:current mean train loss 1642.4020718086826
INFO:root:current train perplexity3.662951946258545
INFO:root:current mean train loss 1645.7640087723119
INFO:root:current train perplexity3.6669514179229736
INFO:root:current mean train loss 1646.1955786240048
INFO:root:current train perplexity3.668755054473877
INFO:root:current mean train loss 1648.9520483491979
INFO:root:current train perplexity3.669717311859131
INFO:root:current mean train loss 1650.8773843110755
INFO:root:current train perplexity3.6747593879699707
INFO:root:current mean train loss 1652.7568837473375
INFO:root:current train perplexity3.680363655090332
INFO:root:current mean train loss 1653.5708809215937
INFO:root:current train perplexity3.6808629035949707
INFO:root:current mean train loss 1654.511126456176
INFO:root:current train perplexity3.6837306022644043
INFO:root:current mean train loss 1655.3368105453526
INFO:root:current train perplexity3.6842381954193115
INFO:root:current mean train loss 1655.4250322343298
INFO:root:current train perplexity3.6868722438812256
INFO:root:current mean train loss 1656.6392083094076
INFO:root:current train perplexity3.6900665760040283
INFO:root:current mean train loss 1657.4467907614596
INFO:root:current train perplexity3.6920361518859863
INFO:root:current mean train loss 1657.4414729063383
INFO:root:current train perplexity3.693211078643799
INFO:root:current mean train loss 1658.582951398626
INFO:root:current train perplexity3.695929765701294
INFO:root:current mean train loss 1658.9807936009483
INFO:root:current train perplexity3.695448160171509
INFO:root:current mean train loss 1658.1118646680377
INFO:root:current train perplexity3.6976101398468018

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.40s/it]
INFO:root:final mean train loss: 1658.1118646680377
INFO:root:final train perplexity: 3.6976101398468018
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.48s/it]
INFO:root:eval mean loss: 2005.8093421881927
INFO:root:eval perplexity: 5.064122200012207
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.93s/it]
INFO:root:eval mean loss: 2483.550972147191
INFO:root:eval perplexity: 7.6225905418396
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/53
 26%|â–ˆâ–ˆâ–‹       | 53/200 [9:20:27<25:48:42, 632.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1616.4781774902344
INFO:root:current train perplexity3.6216259002685547
INFO:root:current mean train loss 1625.2110522460937
INFO:root:current train perplexity3.6269900798797607
INFO:root:current mean train loss 1633.102078857422
INFO:root:current train perplexity3.6357905864715576
INFO:root:current mean train loss 1633.5630819702149
INFO:root:current train perplexity3.6447641849517822
INFO:root:current mean train loss 1637.355362060547
INFO:root:current train perplexity3.6496541500091553
INFO:root:current mean train loss 1639.5904541015625
INFO:root:current train perplexity3.6471290588378906
INFO:root:current mean train loss 1640.8258578055245
INFO:root:current train perplexity3.6498656272888184
INFO:root:current mean train loss 1640.8137120056153
INFO:root:current train perplexity3.650352954864502
INFO:root:current mean train loss 1642.4003578016493
INFO:root:current train perplexity3.6538844108581543
INFO:root:current mean train loss 1643.964877319336
INFO:root:current train perplexity3.656660318374634
INFO:root:current mean train loss 1644.0163161399148
INFO:root:current train perplexity3.65852427482605
INFO:root:current mean train loss 1646.1737940470377
INFO:root:current train perplexity3.6634953022003174
INFO:root:current mean train loss 1646.5234977839543
INFO:root:current train perplexity3.6644303798675537
INFO:root:current mean train loss 1648.0227825927734
INFO:root:current train perplexity3.66793155670166
INFO:root:current mean train loss 1648.7116499837239
INFO:root:current train perplexity3.6704869270324707
INFO:root:current mean train loss 1650.071075668335
INFO:root:current train perplexity3.6742842197418213
INFO:root:current mean train loss 1651.3883076746324
INFO:root:current train perplexity3.675563097000122
INFO:root:current mean train loss 1651.7654547797308
INFO:root:current train perplexity3.676089286804199
INFO:root:current mean train loss 1652.4162136358964
INFO:root:current train perplexity3.67798113822937

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.48s/it]
INFO:root:final mean train loss: 1651.92441930112
INFO:root:final train perplexity: 3.6796107292175293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it]
INFO:root:eval mean loss: 2008.4906815332724
INFO:root:eval perplexity: 5.07511568069458
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 2487.119902049396
INFO:root:eval perplexity: 7.644872665405273
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/54
 27%|â–ˆâ–ˆâ–‹       | 54/200 [9:30:58<25:37:36, 631.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1611.4336081112133
INFO:root:current train perplexity3.6215648651123047
INFO:root:current mean train loss 1633.823218190772
INFO:root:current train perplexity3.6133434772491455
INFO:root:current mean train loss 1634.8328435519873
INFO:root:current train perplexity3.6194515228271484
INFO:root:current mean train loss 1633.0208516888063
INFO:root:current train perplexity3.6210837364196777
INFO:root:current mean train loss 1631.8869886512664
INFO:root:current train perplexity3.6241424083709717
INFO:root:current mean train loss 1636.7556513596319
INFO:root:current train perplexity3.631744623184204
INFO:root:current mean train loss 1638.9685929111376
INFO:root:current train perplexity3.6337244510650635
INFO:root:current mean train loss 1639.856928315954
INFO:root:current train perplexity3.6363916397094727
INFO:root:current mean train loss 1640.791959466082
INFO:root:current train perplexity3.6375441551208496
INFO:root:current mean train loss 1642.0907027682406
INFO:root:current train perplexity3.6405704021453857
INFO:root:current mean train loss 1641.3996295160014
INFO:root:current train perplexity3.642352819442749
INFO:root:current mean train loss 1642.5957079334994
INFO:root:current train perplexity3.645812749862671
INFO:root:current mean train loss 1642.5635462739767
INFO:root:current train perplexity3.6474387645721436
INFO:root:current mean train loss 1643.1391300325965
INFO:root:current train perplexity3.649815320968628
INFO:root:current mean train loss 1643.3066998941426
INFO:root:current train perplexity3.651059865951538
INFO:root:current mean train loss 1643.5668610564642
INFO:root:current train perplexity3.652982234954834
INFO:root:current mean train loss 1643.0640651724113
INFO:root:current train perplexity3.6537938117980957
INFO:root:current mean train loss 1643.146773092262
INFO:root:current train perplexity3.654994249343872
INFO:root:current mean train loss 1643.7943406805732
INFO:root:current train perplexity3.657003879547119
INFO:root:current mean train loss 1645.537507615863
INFO:root:current train perplexity3.659984827041626

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.01s/it]
INFO:root:final mean train loss: 1645.3126405378332
INFO:root:final train perplexity: 3.660473585128784
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.77s/it]
INFO:root:eval mean loss: 2012.4981711096798
INFO:root:eval perplexity: 5.0915913581848145
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.01s/it]
INFO:root:eval mean loss: 2493.691174662705
INFO:root:eval perplexity: 7.686066627502441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/55
 28%|â–ˆâ–ˆâ–Š       | 55/200 [9:41:25<25:23:33, 630.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1613.2475980870863
INFO:root:current train perplexity3.6104466915130615
INFO:root:current mean train loss 1623.697049724522
INFO:root:current train perplexity3.6181116104125977
INFO:root:current mean train loss 1628.5421001727764
INFO:root:current train perplexity3.6132185459136963
INFO:root:current mean train loss 1629.9917262642684
INFO:root:current train perplexity3.609579563140869
INFO:root:current mean train loss 1629.4278859784527
INFO:root:current train perplexity3.61480450630188
INFO:root:current mean train loss 1630.2151258375761
INFO:root:current train perplexity3.612414598464966
INFO:root:current mean train loss 1630.7586929850775
INFO:root:current train perplexity3.618276357650757
INFO:root:current mean train loss 1631.077944389156
INFO:root:current train perplexity3.621854782104492
INFO:root:current mean train loss 1633.0724610253203
INFO:root:current train perplexity3.626941442489624
INFO:root:current mean train loss 1635.246899361784
INFO:root:current train perplexity3.6314947605133057
INFO:root:current mean train loss 1636.385658485516
INFO:root:current train perplexity3.634969711303711
INFO:root:current mean train loss 1637.1040138096616
INFO:root:current train perplexity3.6359148025512695
INFO:root:current mean train loss 1637.5234465019437
INFO:root:current train perplexity3.6379239559173584
INFO:root:current mean train loss 1638.2928882238568
INFO:root:current train perplexity3.6401398181915283
INFO:root:current mean train loss 1638.6306228956917
INFO:root:current train perplexity3.6409878730773926
INFO:root:current mean train loss 1639.6841819793024
INFO:root:current train perplexity3.64298939704895
INFO:root:current mean train loss 1639.5860207976734
INFO:root:current train perplexity3.6434202194213867
INFO:root:current mean train loss 1640.2699009104447
INFO:root:current train perplexity3.6443679332733154
INFO:root:current mean train loss 1639.4694448822588
INFO:root:current train perplexity3.6443045139312744
INFO:root:current mean train loss 1639.7136055631745
INFO:root:current train perplexity3.644880771636963

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.40s/it]
INFO:root:final mean train loss: 1639.9385545877753
INFO:root:final train perplexity: 3.644991874694824
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.05s/it]
INFO:root:eval mean loss: 2013.7559805795656
INFO:root:eval perplexity: 5.096772193908691
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.44s/it]
INFO:root:eval mean loss: 2497.7481273894614
INFO:root:eval perplexity: 7.711609840393066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/56
 28%|â–ˆâ–ˆâ–Š       | 56/200 [9:52:11<25:24:21, 635.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1608.302983302696
INFO:root:current train perplexity3.5681114196777344
INFO:root:current mean train loss 1603.4756821386072
INFO:root:current train perplexity3.564141273498535
INFO:root:current mean train loss 1616.9994193149278
INFO:root:current train perplexity3.583367347717285
INFO:root:current mean train loss 1624.4334476829595
INFO:root:current train perplexity3.5929455757141113
INFO:root:current mean train loss 1626.1114480299855
INFO:root:current train perplexity3.59733247756958
INFO:root:current mean train loss 1624.597958656491
INFO:root:current train perplexity3.594900608062744
INFO:root:current mean train loss 1626.5702146187357
INFO:root:current train perplexity3.599628448486328
INFO:root:current mean train loss 1627.515467332619
INFO:root:current train perplexity3.6010961532592773
INFO:root:current mean train loss 1627.5694660406416
INFO:root:current train perplexity3.6047744750976562
INFO:root:current mean train loss 1627.1615420240207
INFO:root:current train perplexity3.6042778491973877
INFO:root:current mean train loss 1627.9525889824051
INFO:root:current train perplexity3.6074600219726562
INFO:root:current mean train loss 1629.2671839153113
INFO:root:current train perplexity3.608072519302368
INFO:root:current mean train loss 1629.5509018566397
INFO:root:current train perplexity3.610114812850952
INFO:root:current mean train loss 1630.7736501065472
INFO:root:current train perplexity3.613525152206421
INFO:root:current mean train loss 1632.040439850211
INFO:root:current train perplexity3.6160354614257812
INFO:root:current mean train loss 1632.7034949887422
INFO:root:current train perplexity3.617065668106079
INFO:root:current mean train loss 1633.2164701465258
INFO:root:current train perplexity3.6193110942840576
INFO:root:current mean train loss 1634.2839690796109
INFO:root:current train perplexity3.6228935718536377
INFO:root:current mean train loss 1633.7417851493915
INFO:root:current train perplexity3.623512029647827
INFO:root:current mean train loss 1633.4881705045088
INFO:root:current train perplexity3.6251819133758545

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.28s/it]
INFO:root:final mean train loss: 1633.1181326369353
INFO:root:final train perplexity: 3.6254382133483887
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.23s/it]
INFO:root:eval mean loss: 2014.411326739805
INFO:root:eval perplexity: 5.099475383758545
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.25s/it]
INFO:root:eval mean loss: 2496.4042817244294
INFO:root:eval perplexity: 7.703140735626221
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/57
 28%|â–ˆâ–ˆâ–Š       | 57/200 [10:02:46<25:13:38, 635.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1609.3643367991729
INFO:root:current train perplexity3.5651988983154297
INFO:root:current mean train loss 1616.1459779285249
INFO:root:current train perplexity3.5699656009674072
INFO:root:current mean train loss 1614.7388178127915
INFO:root:current train perplexity3.5765492916107178
INFO:root:current mean train loss 1619.7301788330078
INFO:root:current train perplexity3.592034339904785
INFO:root:current mean train loss 1619.13428777711
INFO:root:current train perplexity3.5868213176727295
INFO:root:current mean train loss 1620.7567400865153
INFO:root:current train perplexity3.585538387298584
INFO:root:current mean train loss 1620.8245361693605
INFO:root:current train perplexity3.585395574569702
INFO:root:current mean train loss 1618.4376538594563
INFO:root:current train perplexity3.585427761077881
INFO:root:current mean train loss 1618.5622105752268
INFO:root:current train perplexity3.5866823196411133
INFO:root:current mean train loss 1620.891696141771
INFO:root:current train perplexity3.593418598175049
INFO:root:current mean train loss 1623.1519857685219
INFO:root:current train perplexity3.5967605113983154
INFO:root:current mean train loss 1623.5618890213639
INFO:root:current train perplexity3.6004180908203125
INFO:root:current mean train loss 1623.8230685164876
INFO:root:current train perplexity3.6008918285369873
INFO:root:current mean train loss 1623.7454202216968
INFO:root:current train perplexity3.601747512817383
INFO:root:current mean train loss 1624.7868526780962
INFO:root:current train perplexity3.6035234928131104
INFO:root:current mean train loss 1625.556579356291
INFO:root:current train perplexity3.604619026184082
INFO:root:current mean train loss 1626.0411620654647
INFO:root:current train perplexity3.6054158210754395
INFO:root:current mean train loss 1626.7436111933505
INFO:root:current train perplexity3.605574369430542
INFO:root:current mean train loss 1627.2613844942996
INFO:root:current train perplexity3.606703758239746
INFO:root:current mean train loss 1627.8423982945885
INFO:root:current train perplexity3.608520269393921

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.06s/it]
INFO:root:final mean train loss: 1627.4133183204701
INFO:root:final train perplexity: 3.609163284301758
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.74s/it]
INFO:root:eval mean loss: 2016.7747309258643
INFO:root:eval perplexity: 5.109230995178223
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it]
INFO:root:eval mean loss: 2501.1083863170434
INFO:root:eval perplexity: 7.732832431793213
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/58
 29%|â–ˆâ–ˆâ–‰       | 58/200 [10:13:15<24:58:19, 633.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1598.893289005055
INFO:root:current train perplexity3.5260329246520996
INFO:root:current mean train loss 1603.4207387563345
INFO:root:current train perplexity3.5525169372558594
INFO:root:current mean train loss 1608.9402977658992
INFO:root:current train perplexity3.565223455429077
INFO:root:current mean train loss 1611.270880998884
INFO:root:current train perplexity3.5748958587646484
INFO:root:current mean train loss 1612.7731150833602
INFO:root:current train perplexity3.5750489234924316
INFO:root:current mean train loss 1613.5274712456596
INFO:root:current train perplexity3.5744760036468506
INFO:root:current mean train loss 1613.3732311388003
INFO:root:current train perplexity3.574678421020508
INFO:root:current mean train loss 1613.904357987908
INFO:root:current train perplexity3.5784568786621094
INFO:root:current mean train loss 1615.7326486361228
INFO:root:current train perplexity3.577385902404785
INFO:root:current mean train loss 1616.0420280030537
INFO:root:current train perplexity3.5775015354156494
INFO:root:current mean train loss 1615.1309903333813
INFO:root:current train perplexity3.576753616333008
INFO:root:current mean train loss 1616.1878969087882
INFO:root:current train perplexity3.5782854557037354
INFO:root:current mean train loss 1618.063346797483
INFO:root:current train perplexity3.5802135467529297
INFO:root:current mean train loss 1618.242657272394
INFO:root:current train perplexity3.582170009613037
INFO:root:current mean train loss 1618.9310080788352
INFO:root:current train perplexity3.5846776962280273
INFO:root:current mean train loss 1620.1163259223433
INFO:root:current train perplexity3.586501121520996
INFO:root:current mean train loss 1620.9699783823257
INFO:root:current train perplexity3.5902273654937744
INFO:root:current mean train loss 1621.644822919402
INFO:root:current train perplexity3.591012716293335
INFO:root:current mean train loss 1621.8524032633247
INFO:root:current train perplexity3.5930745601654053

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.98s/it]
INFO:root:final mean train loss: 1621.9143561028015
INFO:root:final train perplexity: 3.593545436859131
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.86s/it]
INFO:root:eval mean loss: 2019.6647460071754
INFO:root:eval perplexity: 5.121187686920166
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 2507.8728841145835
INFO:root:eval perplexity: 7.775729656219482
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/59
 30%|â–ˆâ–ˆâ–‰       | 59/200 [10:23:49<24:48:25, 633.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1625.02587890625
INFO:root:current train perplexity3.502211093902588
INFO:root:current mean train loss 1587.1312459309895
INFO:root:current train perplexity3.5029304027557373
INFO:root:current mean train loss 1595.2200498675356
INFO:root:current train perplexity3.5253281593322754
INFO:root:current mean train loss 1598.081144421306
INFO:root:current train perplexity3.527175188064575
INFO:root:current mean train loss 1600.5719410151391
INFO:root:current train perplexity3.5333573818206787
INFO:root:current mean train loss 1602.395621371934
INFO:root:current train perplexity3.541313648223877
INFO:root:current mean train loss 1605.8609156814525
INFO:root:current train perplexity3.550603151321411
INFO:root:current mean train loss 1606.6613371324675
INFO:root:current train perplexity3.5519726276397705
INFO:root:current mean train loss 1608.268500653883
INFO:root:current train perplexity3.5535480976104736
INFO:root:current mean train loss 1610.0335835458964
INFO:root:current train perplexity3.5569005012512207
INFO:root:current mean train loss 1610.9882674835876
INFO:root:current train perplexity3.5621933937072754
INFO:root:current mean train loss 1613.4971221536127
INFO:root:current train perplexity3.56573224067688
INFO:root:current mean train loss 1613.9629817207324
INFO:root:current train perplexity3.5658977031707764
INFO:root:current mean train loss 1614.0572659775225
INFO:root:current train perplexity3.5697174072265625
INFO:root:current mean train loss 1614.2151694739937
INFO:root:current train perplexity3.572340250015259
INFO:root:current mean train loss 1614.8137992929999
INFO:root:current train perplexity3.5739963054656982
INFO:root:current mean train loss 1614.73696727967
INFO:root:current train perplexity3.575820207595825
INFO:root:current mean train loss 1614.6209967105565
INFO:root:current train perplexity3.5744500160217285
INFO:root:current mean train loss 1615.2095546912935
INFO:root:current train perplexity3.574794292449951
INFO:root:current mean train loss 1615.3938621095804
INFO:root:current train perplexity3.5754587650299072

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.29s/it]
INFO:root:final mean train loss: 1615.8479585325363
INFO:root:final train perplexity: 3.5763936042785645
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.45s/it]
INFO:root:eval mean loss: 2022.4634706754211
INFO:root:eval perplexity: 5.132791519165039
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 2511.201906894116
INFO:root:eval perplexity: 7.796929359436035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/60
 30%|â–ˆâ–ˆâ–ˆ       | 60/200 [10:34:27<24:41:20, 634.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1599.6161723889802
INFO:root:current train perplexity3.554116725921631
INFO:root:current mean train loss 1599.4292802570246
INFO:root:current train perplexity3.5361440181732178
INFO:root:current mean train loss 1604.0812102017337
INFO:root:current train perplexity3.532827138900757
INFO:root:current mean train loss 1600.8625553334396
INFO:root:current train perplexity3.530348777770996
INFO:root:current mean train loss 1596.8975844644988
INFO:root:current train perplexity3.5245840549468994
INFO:root:current mean train loss 1600.91895095737
INFO:root:current train perplexity3.5315120220184326
INFO:root:current mean train loss 1599.6623266956533
INFO:root:current train perplexity3.53513240814209
INFO:root:current mean train loss 1601.7864061549244
INFO:root:current train perplexity3.541043519973755
INFO:root:current mean train loss 1601.873297573737
INFO:root:current train perplexity3.5410330295562744
INFO:root:current mean train loss 1602.3868186377856
INFO:root:current train perplexity3.5430872440338135
INFO:root:current mean train loss 1603.2444604755735
INFO:root:current train perplexity3.5452473163604736
INFO:root:current mean train loss 1603.8985601157563
INFO:root:current train perplexity3.5469603538513184
INFO:root:current mean train loss 1604.5682370042684
INFO:root:current train perplexity3.547504186630249
INFO:root:current mean train loss 1605.34736444735
INFO:root:current train perplexity3.5497710704803467
INFO:root:current mean train loss 1606.2733786584963
INFO:root:current train perplexity3.5508625507354736
INFO:root:current mean train loss 1606.954130171474
INFO:root:current train perplexity3.5518105030059814
INFO:root:current mean train loss 1607.8216880718228
INFO:root:current train perplexity3.553854465484619
INFO:root:current mean train loss 1608.4179379306192
INFO:root:current train perplexity3.5552871227264404
INFO:root:current mean train loss 1608.9443955969325
INFO:root:current train perplexity3.5578701496124268
INFO:root:current mean train loss 1609.334502108337
INFO:root:current train perplexity3.557706356048584

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.78s/it]
INFO:root:final mean train loss: 1609.5512549419086
INFO:root:final train perplexity: 3.5586771965026855
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it]
INFO:root:eval mean loss: 2025.387475412788
INFO:root:eval perplexity: 5.144943714141846
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it]
INFO:root:eval mean loss: 2513.198772024601
INFO:root:eval perplexity: 7.809671878814697
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/61
 30%|â–ˆâ–ˆâ–ˆ       | 61/200 [10:44:53<24:24:45, 632.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1577.616678873698
INFO:root:current train perplexity3.4799511432647705
INFO:root:current mean train loss 1578.6410863539752
INFO:root:current train perplexity3.483910083770752
INFO:root:current mean train loss 1586.682217355502
INFO:root:current train perplexity3.5081946849823
INFO:root:current mean train loss 1592.8520249866303
INFO:root:current train perplexity3.5151755809783936
INFO:root:current mean train loss 1591.7967537696209
INFO:root:current train perplexity3.5163490772247314
INFO:root:current mean train loss 1592.3598477947178
INFO:root:current train perplexity3.5159711837768555
INFO:root:current mean train loss 1592.9128112792969
INFO:root:current train perplexity3.516559600830078
INFO:root:current mean train loss 1595.9922800478728
INFO:root:current train perplexity3.5207176208496094
INFO:root:current mean train loss 1596.9863476912942
INFO:root:current train perplexity3.525709390640259
INFO:root:current mean train loss 1597.3627567128237
INFO:root:current train perplexity3.525212526321411
INFO:root:current mean train loss 1597.2715841757285
INFO:root:current train perplexity3.5244991779327393
INFO:root:current mean train loss 1597.0683180043395
INFO:root:current train perplexity3.5245347023010254
INFO:root:current mean train loss 1597.8864281910523
INFO:root:current train perplexity3.529393434524536
INFO:root:current mean train loss 1599.8747156565776
INFO:root:current train perplexity3.533450126647949
INFO:root:current mean train loss 1599.9955196114968
INFO:root:current train perplexity3.5361058712005615
INFO:root:current mean train loss 1601.5703625679016
INFO:root:current train perplexity3.540151596069336
INFO:root:current mean train loss 1602.5119930351275
INFO:root:current train perplexity3.5414559841156006
INFO:root:current mean train loss 1603.444315334619
INFO:root:current train perplexity3.5434048175811768
INFO:root:current mean train loss 1604.3227757805053
INFO:root:current train perplexity3.5435383319854736
INFO:root:current mean train loss 1604.9361377432326
INFO:root:current train perplexity3.5440807342529297

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:10<00:00, 550.36s/it]
INFO:root:final mean train loss: 1604.2248285229134
INFO:root:final train perplexity: 3.54375958442688
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.54s/it]
INFO:root:eval mean loss: 2027.3542766165226
INFO:root:eval perplexity: 5.153133869171143
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it]
INFO:root:eval mean loss: 2518.4233017508864
INFO:root:eval perplexity: 7.843113422393799
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/62
 31%|â–ˆâ–ˆâ–ˆ       | 62/200 [10:55:21<24:10:53, 630.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1583.3038698592277
INFO:root:current train perplexity3.4686880111694336
INFO:root:current mean train loss 1586.489151699091
INFO:root:current train perplexity3.4918103218078613
INFO:root:current mean train loss 1597.120085825562
INFO:root:current train perplexity3.5144479274749756
INFO:root:current mean train loss 1596.181306920038
INFO:root:current train perplexity3.515338182449341
INFO:root:current mean train loss 1597.3561874288596
INFO:root:current train perplexity3.5190131664276123
INFO:root:current mean train loss 1596.8187322081967
INFO:root:current train perplexity3.5185744762420654
INFO:root:current mean train loss 1597.1190557552882
INFO:root:current train perplexity3.5162665843963623
INFO:root:current mean train loss 1597.1110518862051
INFO:root:current train perplexity3.5120012760162354
INFO:root:current mean train loss 1596.5551674810413
INFO:root:current train perplexity3.5119001865386963
INFO:root:current mean train loss 1595.0786880861424
INFO:root:current train perplexity3.5107274055480957
INFO:root:current mean train loss 1595.9873226560644
INFO:root:current train perplexity3.5147738456726074
INFO:root:current mean train loss 1595.5675659709048
INFO:root:current train perplexity3.5155184268951416
INFO:root:current mean train loss 1595.8117336751172
INFO:root:current train perplexity3.5164942741394043
INFO:root:current mean train loss 1596.5421393395175
INFO:root:current train perplexity3.5201363563537598
INFO:root:current mean train loss 1596.5572333339157
INFO:root:current train perplexity3.520987033843994
INFO:root:current mean train loss 1596.182757179275
INFO:root:current train perplexity3.522876024246216
INFO:root:current mean train loss 1596.8948338780342
INFO:root:current train perplexity3.5228326320648193
INFO:root:current mean train loss 1597.1098348004982
INFO:root:current train perplexity3.5237390995025635
INFO:root:current mean train loss 1597.7912054828741
INFO:root:current train perplexity3.525949716567993
INFO:root:current mean train loss 1598.3175818252369
INFO:root:current train perplexity3.5269482135772705

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.10s/it]
INFO:root:final mean train loss: 1598.440211524521
INFO:root:final train perplexity: 3.5276293754577637
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.38s/it]
INFO:root:eval mean loss: 2029.3914401007037
INFO:root:eval perplexity: 5.161631107330322
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.56s/it]
INFO:root:eval mean loss: 2522.9561165884033
INFO:root:eval perplexity: 7.872241497039795
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/63
 32%|â–ˆâ–ˆâ–ˆâ–      | 63/200 [11:06:02<24:07:32, 633.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1591.223575265067
INFO:root:current train perplexity3.483044147491455
INFO:root:current mean train loss 1589.4372817095589
INFO:root:current train perplexity3.476318120956421
INFO:root:current mean train loss 1583.1388201678242
INFO:root:current train perplexity3.4716672897338867
INFO:root:current mean train loss 1579.6840546479095
INFO:root:current train perplexity3.475980281829834
INFO:root:current mean train loss 1583.610599079538
INFO:root:current train perplexity3.4843809604644775
INFO:root:current mean train loss 1585.173777797766
INFO:root:current train perplexity3.4910991191864014
INFO:root:current mean train loss 1584.8826375932836
INFO:root:current train perplexity3.489650249481201
INFO:root:current mean train loss 1585.411281833401
INFO:root:current train perplexity3.4904520511627197
INFO:root:current mean train loss 1585.8070851293103
INFO:root:current train perplexity3.4947445392608643
INFO:root:current mean train loss 1585.5986905756686
INFO:root:current train perplexity3.4935503005981445
INFO:root:current mean train loss 1585.2792658440421
INFO:root:current train perplexity3.4957849979400635
INFO:root:current mean train loss 1586.2969486595218
INFO:root:current train perplexity3.499711036682129
INFO:root:current mean train loss 1586.5723790446605
INFO:root:current train perplexity3.5015013217926025
INFO:root:current mean train loss 1588.0501950451928
INFO:root:current train perplexity3.5032825469970703
INFO:root:current mean train loss 1588.9046574391475
INFO:root:current train perplexity3.504183053970337
INFO:root:current mean train loss 1589.2813370820063
INFO:root:current train perplexity3.505741834640503
INFO:root:current mean train loss 1590.1713889847258
INFO:root:current train perplexity3.5066404342651367
INFO:root:current mean train loss 1590.9496709618866
INFO:root:current train perplexity3.5069172382354736
INFO:root:current mean train loss 1592.0057577367772
INFO:root:current train perplexity3.508504867553711
INFO:root:current mean train loss 1593.2213281002141
INFO:root:current train perplexity3.5115034580230713

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.80s/it]
INFO:root:final mean train loss: 1592.6992113937708
INFO:root:final train perplexity: 3.5116934776306152
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.08s/it]
INFO:root:eval mean loss: 2030.7374622534353
INFO:root:eval perplexity: 5.1672539710998535
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.56s/it]
INFO:root:eval mean loss: 2524.6645321676915
INFO:root:eval perplexity: 7.883247375488281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/64
 32%|â–ˆâ–ˆâ–ˆâ–      | 64/200 [11:16:31<23:53:23, 632.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1575.6683503951149
INFO:root:current train perplexity3.4368679523468018
INFO:root:current mean train loss 1574.902877073237
INFO:root:current train perplexity3.4591634273529053
INFO:root:current mean train loss 1579.3699963931838
INFO:root:current train perplexity3.476414680480957
INFO:root:current mean train loss 1578.0012374207647
INFO:root:current train perplexity3.471694231033325
INFO:root:current mean train loss 1578.078820825847
INFO:root:current train perplexity3.4761862754821777
INFO:root:current mean train loss 1580.6732429361425
INFO:root:current train perplexity3.4746546745300293
INFO:root:current mean train loss 1578.863301328523
INFO:root:current train perplexity3.4751455783843994
INFO:root:current mean train loss 1579.5786982806544
INFO:root:current train perplexity3.478348970413208
INFO:root:current mean train loss 1580.4211966633932
INFO:root:current train perplexity3.4800689220428467
INFO:root:current mean train loss 1580.8190519725176
INFO:root:current train perplexity3.483529567718506
INFO:root:current mean train loss 1581.516671188621
INFO:root:current train perplexity3.4868574142456055
INFO:root:current mean train loss 1582.65655697547
INFO:root:current train perplexity3.4889402389526367
INFO:root:current mean train loss 1583.6598777741356
INFO:root:current train perplexity3.491459846496582
INFO:root:current mean train loss 1583.3828399592196
INFO:root:current train perplexity3.491955280303955
INFO:root:current mean train loss 1584.4703674521636
INFO:root:current train perplexity3.4926364421844482
INFO:root:current mean train loss 1585.2232249884314
INFO:root:current train perplexity3.4937798976898193
INFO:root:current mean train loss 1586.118308853665
INFO:root:current train perplexity3.4945504665374756
INFO:root:current mean train loss 1585.7530185590595
INFO:root:current train perplexity3.495216131210327
INFO:root:current mean train loss 1586.912391941574
INFO:root:current train perplexity3.496260404586792

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.59s/it]
INFO:root:final mean train loss: 1587.4301486032152
INFO:root:final train perplexity: 3.497130870819092
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 37.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 37.00s/it]
INFO:root:eval mean loss: 2034.961467337101
INFO:root:eval perplexity: 5.1849365234375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.81s/it]
INFO:root:eval mean loss: 2529.042810751191
INFO:root:eval perplexity: 7.911526679992676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/65
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 65/200 [11:27:10<23:47:45, 634.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1525.0216674804688
INFO:root:current train perplexity3.4181954860687256
INFO:root:current mean train loss 1558.404539841872
INFO:root:current train perplexity3.433117151260376
INFO:root:current mean train loss 1560.7836955949372
INFO:root:current train perplexity3.440631151199341
INFO:root:current mean train loss 1562.3377135427374
INFO:root:current train perplexity3.44905948638916
INFO:root:current mean train loss 1566.6874365476099
INFO:root:current train perplexity3.454521656036377
INFO:root:current mean train loss 1569.9928646995909
INFO:root:current train perplexity3.4593863487243652
INFO:root:current mean train loss 1572.4052936478167
INFO:root:current train perplexity3.4599313735961914
INFO:root:current mean train loss 1574.3998730399392
INFO:root:current train perplexity3.464724063873291
INFO:root:current mean train loss 1576.0670074918378
INFO:root:current train perplexity3.467984437942505
INFO:root:current mean train loss 1577.391856640841
INFO:root:current train perplexity3.4719769954681396
INFO:root:current mean train loss 1578.338170632898
INFO:root:current train perplexity3.474329948425293
INFO:root:current mean train loss 1579.7235014542289
INFO:root:current train perplexity3.475703477859497
INFO:root:current mean train loss 1579.877853647023
INFO:root:current train perplexity3.4747323989868164
INFO:root:current mean train loss 1580.2591414188314
INFO:root:current train perplexity3.475674867630005
INFO:root:current mean train loss 1580.7802411810285
INFO:root:current train perplexity3.477226972579956
INFO:root:current mean train loss 1581.9672643783244
INFO:root:current train perplexity3.479346990585327
INFO:root:current mean train loss 1581.799923713665
INFO:root:current train perplexity3.4790923595428467
INFO:root:current mean train loss 1581.7830259654443
INFO:root:current train perplexity3.479897975921631
INFO:root:current mean train loss 1581.477910957421
INFO:root:current train perplexity3.479569911956787
INFO:root:current mean train loss 1582.1159476272198
INFO:root:current train perplexity3.481508255004883

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.67s/it]
INFO:root:final mean train loss: 1581.9916242098363
INFO:root:final train perplexity: 3.482163190841675
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it]
INFO:root:eval mean loss: 2038.21461779006
INFO:root:eval perplexity: 5.19859504699707
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it]
INFO:root:eval mean loss: 2534.38086067362
INFO:root:eval perplexity: 7.946139335632324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/66
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 66/200 [11:37:41<23:34:33, 633.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1587.6538550967261
INFO:root:current train perplexity3.484562635421753
INFO:root:current mean train loss 1571.9693623692535
INFO:root:current train perplexity3.451674222946167
INFO:root:current mean train loss 1578.889520843644
INFO:root:current train perplexity3.4578518867492676
INFO:root:current mean train loss 1572.6524855949426
INFO:root:current train perplexity3.452040433883667
INFO:root:current mean train loss 1569.5716865883871
INFO:root:current train perplexity3.4474124908447266
INFO:root:current mean train loss 1570.1580166221809
INFO:root:current train perplexity3.450437545776367
INFO:root:current mean train loss 1569.7361189739331
INFO:root:current train perplexity3.450749397277832
INFO:root:current mean train loss 1569.925746034154
INFO:root:current train perplexity3.44832444190979
INFO:root:current mean train loss 1570.669479091333
INFO:root:current train perplexity3.4506008625030518
INFO:root:current mean train loss 1570.409405139836
INFO:root:current train perplexity3.453139543533325
INFO:root:current mean train loss 1570.0933492363492
INFO:root:current train perplexity3.4547407627105713
INFO:root:current mean train loss 1571.4942177220394
INFO:root:current train perplexity3.4551444053649902
INFO:root:current mean train loss 1571.0734714317477
INFO:root:current train perplexity3.456205129623413
INFO:root:current mean train loss 1571.0884772278341
INFO:root:current train perplexity3.457491636276245
INFO:root:current mean train loss 1572.1995608217694
INFO:root:current train perplexity3.458639621734619
INFO:root:current mean train loss 1574.3558843187561
INFO:root:current train perplexity3.4603445529937744
INFO:root:current mean train loss 1575.451656014444
INFO:root:current train perplexity3.4619197845458984
INFO:root:current mean train loss 1576.0735027838557
INFO:root:current train perplexity3.464946746826172
INFO:root:current mean train loss 1576.6262729232092
INFO:root:current train perplexity3.4667794704437256
INFO:root:current mean train loss 1576.8218816849542
INFO:root:current train perplexity3.4669785499572754

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.82s/it]
INFO:root:final mean train loss: 1576.8017659997677
INFO:root:final train perplexity: 3.4679393768310547
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it]
INFO:root:eval mean loss: 2038.0638155024103
INFO:root:eval perplexity: 5.197960376739502
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.04s/it]
INFO:root:eval mean loss: 2536.131821652676
INFO:root:eval perplexity: 7.957525730133057
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/67
 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 67/200 [11:48:08<23:19:44, 631.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1534.5294928299754
INFO:root:current train perplexity3.3960208892822266
INFO:root:current mean train loss 1547.1679643271625
INFO:root:current train perplexity3.3920493125915527
INFO:root:current mean train loss 1553.4324905010833
INFO:root:current train perplexity3.4041483402252197
INFO:root:current mean train loss 1557.4996514856462
INFO:root:current train perplexity3.4135520458221436
INFO:root:current mean train loss 1557.5947611212187
INFO:root:current train perplexity3.4168643951416016
INFO:root:current mean train loss 1558.9332071183783
INFO:root:current train perplexity3.41833758354187
INFO:root:current mean train loss 1561.3264284522556
INFO:root:current train perplexity3.425172805786133
INFO:root:current mean train loss 1561.8400419074992
INFO:root:current train perplexity3.4314677715301514
INFO:root:current mean train loss 1563.973026976665
INFO:root:current train perplexity3.436659574508667
INFO:root:current mean train loss 1564.8322406435318
INFO:root:current train perplexity3.4380645751953125
INFO:root:current mean train loss 1563.4887621223581
INFO:root:current train perplexity3.43530011177063
INFO:root:current mean train loss 1564.2108394575873
INFO:root:current train perplexity3.435990571975708
INFO:root:current mean train loss 1566.0192708399068
INFO:root:current train perplexity3.4386117458343506
INFO:root:current mean train loss 1567.7744611389435
INFO:root:current train perplexity3.442974328994751
INFO:root:current mean train loss 1568.8527801471228
INFO:root:current train perplexity3.444305419921875
INFO:root:current mean train loss 1569.7421967068635
INFO:root:current train perplexity3.4464123249053955
INFO:root:current mean train loss 1570.356948796646
INFO:root:current train perplexity3.448000192642212
INFO:root:current mean train loss 1570.5665311297557
INFO:root:current train perplexity3.4503977298736572
INFO:root:current mean train loss 1570.3482582997185
INFO:root:current train perplexity3.450876474380493
INFO:root:current mean train loss 1571.3122840778992
INFO:root:current train perplexity3.451770067214966

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.80s/it]
INFO:root:final mean train loss: 1571.3408228363944
INFO:root:final train perplexity: 3.453036069869995
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it]
INFO:root:eval mean loss: 2041.9656861217309
INFO:root:eval perplexity: 5.214388847351074
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it]
INFO:root:eval mean loss: 2538.578599862173
INFO:root:eval perplexity: 7.9734673500061035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/68
 34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [11:58:39<23:08:43, 631.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1557.6077969637784
INFO:root:current train perplexity3.396876811981201
INFO:root:current mean train loss 1559.359349798387
INFO:root:current train perplexity3.407609462738037
INFO:root:current mean train loss 1556.9907327090993
INFO:root:current train perplexity3.403860569000244
INFO:root:current mean train loss 1554.8158048387984
INFO:root:current train perplexity3.401930570602417
INFO:root:current mean train loss 1557.4758644187843
INFO:root:current train perplexity3.402905225753784
INFO:root:current mean train loss 1557.12436303491
INFO:root:current train perplexity3.399850606918335
INFO:root:current mean train loss 1557.1067845002385
INFO:root:current train perplexity3.4054207801818848
INFO:root:current mean train loss 1559.1967653792426
INFO:root:current train perplexity3.411705493927002
INFO:root:current mean train loss 1560.0167143526132
INFO:root:current train perplexity3.4151735305786133
INFO:root:current mean train loss 1560.4109791700753
INFO:root:current train perplexity3.4164228439331055
INFO:root:current mean train loss 1561.79001522697
INFO:root:current train perplexity3.4187443256378174
INFO:root:current mean train loss 1560.7807373046876
INFO:root:current train perplexity3.417811632156372
INFO:root:current mean train loss 1562.018330972983
INFO:root:current train perplexity3.4230968952178955
INFO:root:current mean train loss 1562.140509235903
INFO:root:current train perplexity3.4252524375915527
INFO:root:current mean train loss 1562.6423520222563
INFO:root:current train perplexity3.4256184101104736
INFO:root:current mean train loss 1563.891967930441
INFO:root:current train perplexity3.4283738136291504
INFO:root:current mean train loss 1564.1043302138407
INFO:root:current train perplexity3.430105447769165
INFO:root:current mean train loss 1565.2347540091926
INFO:root:current train perplexity3.432102680206299
INFO:root:current mean train loss 1564.7102793732101
INFO:root:current train perplexity3.4336140155792236
INFO:root:current mean train loss 1565.8781446686182
INFO:root:current train perplexity3.4373507499694824

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.76s/it]
INFO:root:final mean train loss: 1565.7628664756387
INFO:root:final train perplexity: 3.4378793239593506
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.03s/it]
INFO:root:eval mean loss: 2045.822874677942
INFO:root:eval perplexity: 5.2306809425354
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it]
INFO:root:eval mean loss: 2545.892503670767
INFO:root:eval perplexity: 8.021305084228516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/69
 34%|â–ˆâ–ˆâ–ˆâ–      | 69/200 [12:09:06<22:55:27, 629.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1570.2704213460286
INFO:root:current train perplexity3.4235787391662598
INFO:root:current mean train loss 1562.003531522529
INFO:root:current train perplexity3.4085280895233154
INFO:root:current mean train loss 1559.9750384162453
INFO:root:current train perplexity3.41166615486145
INFO:root:current mean train loss 1559.8179941485005
INFO:root:current train perplexity3.413011312484741
INFO:root:current mean train loss 1554.9352173886057
INFO:root:current train perplexity3.4068074226379395
INFO:root:current mean train loss 1552.9136203152316
INFO:root:current train perplexity3.403531551361084
INFO:root:current mean train loss 1553.8156912667412
INFO:root:current train perplexity3.405207633972168
INFO:root:current mean train loss 1554.9357407327761
INFO:root:current train perplexity3.4069385528564453
INFO:root:current mean train loss 1555.2795541745807
INFO:root:current train perplexity3.409442901611328
INFO:root:current mean train loss 1557.048938766919
INFO:root:current train perplexity3.411890983581543
INFO:root:current mean train loss 1555.996766389306
INFO:root:current train perplexity3.4139907360076904
INFO:root:current mean train loss 1556.157671827505
INFO:root:current train perplexity3.413400173187256
INFO:root:current mean train loss 1555.6448419918804
INFO:root:current train perplexity3.4144999980926514
INFO:root:current mean train loss 1557.0179497632619
INFO:root:current train perplexity3.417180061340332
INFO:root:current mean train loss 1558.0233989383864
INFO:root:current train perplexity3.419295310974121
INFO:root:current mean train loss 1558.065034356736
INFO:root:current train perplexity3.4190564155578613
INFO:root:current mean train loss 1558.5486612274317
INFO:root:current train perplexity3.418916702270508
INFO:root:current mean train loss 1560.0554246062889
INFO:root:current train perplexity3.421271562576294
INFO:root:current mean train loss 1560.9873717218384
INFO:root:current train perplexity3.4232869148254395
INFO:root:current mean train loss 1561.6796605108234
INFO:root:current train perplexity3.4257113933563232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.75s/it]
INFO:root:final mean train loss: 1561.291470572375
INFO:root:final train perplexity: 3.425776720046997
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it]
INFO:root:eval mean loss: 2049.0072995449636
INFO:root:eval perplexity: 5.244168758392334
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 2551.867277537677
INFO:root:eval perplexity: 8.060593605041504
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/70
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/200 [12:19:32<22:42:31, 628.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1525.7023336003335
INFO:root:current train perplexity3.3666083812713623
INFO:root:current mean train loss 1531.628376632771
INFO:root:current train perplexity3.3683927059173584
INFO:root:current mean train loss 1541.3282010299524
INFO:root:current train perplexity3.369015693664551
INFO:root:current mean train loss 1541.4091385789886
INFO:root:current train perplexity3.376054048538208
INFO:root:current mean train loss 1543.4827511403214
INFO:root:current train perplexity3.3816640377044678
INFO:root:current mean train loss 1545.1870757590327
INFO:root:current train perplexity3.386761426925659
INFO:root:current mean train loss 1546.7967745444598
INFO:root:current train perplexity3.3899290561676025
INFO:root:current mean train loss 1548.4880436074145
INFO:root:current train perplexity3.3904151916503906
INFO:root:current mean train loss 1550.0512177646494
INFO:root:current train perplexity3.3951315879821777
INFO:root:current mean train loss 1551.8106800538344
INFO:root:current train perplexity3.399688959121704
INFO:root:current mean train loss 1550.1373503994132
INFO:root:current train perplexity3.3968799114227295
INFO:root:current mean train loss 1550.589046750979
INFO:root:current train perplexity3.3978216648101807
INFO:root:current mean train loss 1550.0693664314028
INFO:root:current train perplexity3.3966827392578125
INFO:root:current mean train loss 1551.1029261018493
INFO:root:current train perplexity3.400268077850342
INFO:root:current mean train loss 1551.9975367047148
INFO:root:current train perplexity3.4016547203063965
INFO:root:current mean train loss 1552.9429755718022
INFO:root:current train perplexity3.404346466064453
INFO:root:current mean train loss 1553.3555049591334
INFO:root:current train perplexity3.405250310897827
INFO:root:current mean train loss 1554.377955752821
INFO:root:current train perplexity3.405941963195801
INFO:root:current mean train loss 1555.3959048479685
INFO:root:current train perplexity3.4088971614837646

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.30s/it]
INFO:root:final mean train loss: 1555.4171248150785
INFO:root:final train perplexity: 3.409942388534546
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 2050.9950288813166
INFO:root:eval perplexity: 5.252606391906738
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it]
INFO:root:eval mean loss: 2553.1948419665614
INFO:root:eval perplexity: 8.069348335266113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/71
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 71/200 [12:30:03<22:33:37, 629.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1566.958740234375
INFO:root:current train perplexity3.3394851684570312
INFO:root:current mean train loss 1528.297722582547
INFO:root:current train perplexity3.349397659301758
INFO:root:current mean train loss 1538.39894355848
INFO:root:current train perplexity3.350625991821289
INFO:root:current mean train loss 1540.0160107581444
INFO:root:current train perplexity3.356098175048828
INFO:root:current mean train loss 1542.7932856517473
INFO:root:current train perplexity3.36104416847229
INFO:root:current mean train loss 1540.583143633816
INFO:root:current train perplexity3.3640267848968506
INFO:root:current mean train loss 1541.077168581116
INFO:root:current train perplexity3.364330768585205
INFO:root:current mean train loss 1540.3934848342333
INFO:root:current train perplexity3.36578369140625
INFO:root:current mean train loss 1540.7125487978346
INFO:root:current train perplexity3.3727662563323975
INFO:root:current mean train loss 1541.5118051154197
INFO:root:current train perplexity3.3772778511047363
INFO:root:current mean train loss 1543.4765809440235
INFO:root:current train perplexity3.3793110847473145
INFO:root:current mean train loss 1545.3020370510992
INFO:root:current train perplexity3.3826115131378174
INFO:root:current mean train loss 1546.1849234661652
INFO:root:current train perplexity3.3843085765838623
INFO:root:current mean train loss 1546.8430651537674
INFO:root:current train perplexity3.3870174884796143
INFO:root:current mean train loss 1547.3815757349919
INFO:root:current train perplexity3.3879919052124023
INFO:root:current mean train loss 1548.3043255039736
INFO:root:current train perplexity3.389802932739258
INFO:root:current mean train loss 1548.6727988123152
INFO:root:current train perplexity3.3906965255737305
INFO:root:current mean train loss 1549.6061645364705
INFO:root:current train perplexity3.391308546066284
INFO:root:current mean train loss 1549.9877324067345
INFO:root:current train perplexity3.3926756381988525
INFO:root:current mean train loss 1550.6699424335363
INFO:root:current train perplexity3.39458966255188

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.47s/it]
INFO:root:final mean train loss: 1550.5932373108433
INFO:root:final train perplexity: 3.3969945907592773
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.71s/it]
INFO:root:eval mean loss: 2054.7620356133643
INFO:root:eval perplexity: 5.268632411956787
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it]
INFO:root:eval mean loss: 2558.166041597407
INFO:root:eval perplexity: 8.10222339630127
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/72
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 72/200 [12:40:40<22:27:46, 631.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1563.269536557405
INFO:root:current train perplexity3.369015693664551
INFO:root:current mean train loss 1548.4828912998603
INFO:root:current train perplexity3.369824171066284
INFO:root:current mean train loss 1540.5739510711533
INFO:root:current train perplexity3.3571338653564453
INFO:root:current mean train loss 1539.7917015618953
INFO:root:current train perplexity3.3570072650909424
INFO:root:current mean train loss 1540.980398335919
INFO:root:current train perplexity3.3581886291503906
INFO:root:current mean train loss 1540.7577499477175
INFO:root:current train perplexity3.3613991737365723
INFO:root:current mean train loss 1540.6456008837656
INFO:root:current train perplexity3.3629298210144043
INFO:root:current mean train loss 1540.807242196955
INFO:root:current train perplexity3.3676235675811768
INFO:root:current mean train loss 1540.0604593640833
INFO:root:current train perplexity3.367419958114624
INFO:root:current mean train loss 1541.4097749621226
INFO:root:current train perplexity3.3713715076446533
INFO:root:current mean train loss 1540.932804767687
INFO:root:current train perplexity3.3735690116882324
INFO:root:current mean train loss 1541.7994964137633
INFO:root:current train perplexity3.37491774559021
INFO:root:current mean train loss 1542.2523085562207
INFO:root:current train perplexity3.375885486602783
INFO:root:current mean train loss 1542.529905012135
INFO:root:current train perplexity3.3763487339019775
INFO:root:current mean train loss 1543.026125363037
INFO:root:current train perplexity3.3777613639831543
INFO:root:current mean train loss 1544.8762784120056
INFO:root:current train perplexity3.3804574012756348
INFO:root:current mean train loss 1544.8012829943343
INFO:root:current train perplexity3.3819327354431152
INFO:root:current mean train loss 1544.9585991769216
INFO:root:current train perplexity3.382126569747925
INFO:root:current mean train loss 1545.5632383144628
INFO:root:current train perplexity3.3843884468078613
INFO:root:current mean train loss 1546.5541956004413
INFO:root:current train perplexity3.386054515838623

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.22s/it]
INFO:root:final mean train loss: 1546.4516021682348
INFO:root:final train perplexity: 3.3859169483184814
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it]
INFO:root:eval mean loss: 2057.687071888159
INFO:root:eval perplexity: 5.281111717224121
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.21s/it]
INFO:root:eval mean loss: 2562.797116110511
INFO:root:eval perplexity: 8.13296890258789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/73
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 73/200 [12:51:08<22:14:40, 630.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1529.469546508789
INFO:root:current train perplexity3.338484525680542
INFO:root:current mean train loss 1524.7679827008928
INFO:root:current train perplexity3.3206002712249756
INFO:root:current mean train loss 1533.3311503092448
INFO:root:current train perplexity3.3301382064819336
INFO:root:current mean train loss 1531.2985312069163
INFO:root:current train perplexity3.3378074169158936
INFO:root:current mean train loss 1531.9413882168856
INFO:root:current train perplexity3.339465618133545
INFO:root:current mean train loss 1534.104793520327
INFO:root:current train perplexity3.3416028022766113
INFO:root:current mean train loss 1534.1951929092406
INFO:root:current train perplexity3.3451321125030518
INFO:root:current mean train loss 1533.9127880199535
INFO:root:current train perplexity3.3460254669189453
INFO:root:current mean train loss 1535.0996619814919
INFO:root:current train perplexity3.3488175868988037
INFO:root:current mean train loss 1536.001176290309
INFO:root:current train perplexity3.3512356281280518
INFO:root:current mean train loss 1535.6968190119817
INFO:root:current train perplexity3.3529274463653564
INFO:root:current mean train loss 1535.8835152609306
INFO:root:current train perplexity3.3537838459014893
INFO:root:current mean train loss 1537.3319411739226
INFO:root:current train perplexity3.3577535152435303
INFO:root:current mean train loss 1538.1044501916685
INFO:root:current train perplexity3.360407829284668
INFO:root:current mean train loss 1538.3965098063152
INFO:root:current train perplexity3.3613505363464355
INFO:root:current mean train loss 1538.6203102012732
INFO:root:current train perplexity3.362386465072632
INFO:root:current mean train loss 1538.2660015571407
INFO:root:current train perplexity3.3631598949432373
INFO:root:current mean train loss 1539.2889921341819
INFO:root:current train perplexity3.3638968467712402
INFO:root:current mean train loss 1540.3737224413
INFO:root:current train perplexity3.3667147159576416
INFO:root:current mean train loss 1540.6627736514376
INFO:root:current train perplexity3.3681960105895996

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.15s/it]
INFO:root:final mean train loss: 1540.2356487049096
INFO:root:final train perplexity: 3.369359016418457
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.28s/it]
INFO:root:eval mean loss: 2059.6924615954676
INFO:root:eval perplexity: 5.289682865142822
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.16s/it]
INFO:root:eval mean loss: 2564.4790428648603
INFO:root:eval perplexity: 8.144163131713867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/74
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [13:01:46<22:08:44, 632.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1498.4882555509869
INFO:root:current train perplexity3.309537887573242
INFO:root:current mean train loss 1521.465865408539
INFO:root:current train perplexity3.323714017868042
INFO:root:current mean train loss 1527.3361759408438
INFO:root:current train perplexity3.33010196685791
INFO:root:current mean train loss 1522.7986585259105
INFO:root:current train perplexity3.32773494720459
INFO:root:current mean train loss 1525.852990482255
INFO:root:current train perplexity3.3291776180267334
INFO:root:current mean train loss 1523.3716368204387
INFO:root:current train perplexity3.3318941593170166
INFO:root:current mean train loss 1525.5600045260774
INFO:root:current train perplexity3.3343217372894287
INFO:root:current mean train loss 1527.2685590413948
INFO:root:current train perplexity3.33833646774292
INFO:root:current mean train loss 1528.0019863133114
INFO:root:current train perplexity3.3422696590423584
INFO:root:current mean train loss 1529.6890237742457
INFO:root:current train perplexity3.3436059951782227
INFO:root:current mean train loss 1530.2331715045161
INFO:root:current train perplexity3.343865156173706
INFO:root:current mean train loss 1531.0165477544972
INFO:root:current train perplexity3.3467905521392822
INFO:root:current mean train loss 1532.0579909732062
INFO:root:current train perplexity3.348560094833374
INFO:root:current mean train loss 1532.2652354904546
INFO:root:current train perplexity3.348423480987549
INFO:root:current mean train loss 1532.9099879320468
INFO:root:current train perplexity3.3494906425476074
INFO:root:current mean train loss 1533.7242317959217
INFO:root:current train perplexity3.352505922317505
INFO:root:current mean train loss 1534.086479338955
INFO:root:current train perplexity3.3535735607147217
INFO:root:current mean train loss 1534.7048290515395
INFO:root:current train perplexity3.3542423248291016
INFO:root:current mean train loss 1536.1604104481144
INFO:root:current train perplexity3.3571054935455322
INFO:root:current mean train loss 1536.2335698474228
INFO:root:current train perplexity3.3576765060424805

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.11s/it]
INFO:root:final mean train loss: 1535.7767152079296
INFO:root:final train perplexity: 3.3575313091278076
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.34s/it]
INFO:root:eval mean loss: 2059.771808597213
INFO:root:eval perplexity: 5.290023326873779
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.22s/it]
INFO:root:eval mean loss: 2568.0536776062445
INFO:root:eval perplexity: 8.168006896972656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/75
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 75/200 [13:12:13<21:54:34, 630.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1519.7733896616344
INFO:root:current train perplexity3.3084120750427246
INFO:root:current mean train loss 1517.6260600473688
INFO:root:current train perplexity3.3120460510253906
INFO:root:current mean train loss 1516.5940810154825
INFO:root:current train perplexity3.3179097175598145
INFO:root:current mean train loss 1517.8642398609834
INFO:root:current train perplexity3.318826198577881
INFO:root:current mean train loss 1518.6232866375758
INFO:root:current train perplexity3.3173916339874268
INFO:root:current mean train loss 1522.4077820462217
INFO:root:current train perplexity3.321213722229004
INFO:root:current mean train loss 1523.450414278387
INFO:root:current train perplexity3.324086904525757
INFO:root:current mean train loss 1523.682344027576
INFO:root:current train perplexity3.3220202922821045
INFO:root:current mean train loss 1523.6095942796233
INFO:root:current train perplexity3.325180768966675
INFO:root:current mean train loss 1524.9670824994787
INFO:root:current train perplexity3.3256778717041016
INFO:root:current mean train loss 1526.3858560743279
INFO:root:current train perplexity3.327172040939331
INFO:root:current mean train loss 1526.0740149528854
INFO:root:current train perplexity3.329094171524048
INFO:root:current mean train loss 1526.4690475104555
INFO:root:current train perplexity3.3323543071746826
INFO:root:current mean train loss 1528.2873737718342
INFO:root:current train perplexity3.33494234085083
INFO:root:current mean train loss 1528.6777933397643
INFO:root:current train perplexity3.3365814685821533
INFO:root:current mean train loss 1529.4171193763898
INFO:root:current train perplexity3.3396029472351074
INFO:root:current mean train loss 1530.4179572284293
INFO:root:current train perplexity3.3410277366638184
INFO:root:current mean train loss 1530.9182698659456
INFO:root:current train perplexity3.3416218757629395
INFO:root:current mean train loss 1531.0901437798075
INFO:root:current train perplexity3.3429462909698486
INFO:root:current mean train loss 1530.897596983441
INFO:root:current train perplexity3.343660831451416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.75s/it]
INFO:root:final mean train loss: 1530.62857174164
INFO:root:final train perplexity: 3.343925952911377
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it]
INFO:root:eval mean loss: 2064.8176901526485
INFO:root:eval perplexity: 5.311654090881348
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.07s/it]
INFO:root:eval mean loss: 2574.0524820097794
INFO:root:eval perplexity: 8.20817756652832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/76
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 76/200 [13:22:48<21:46:51, 632.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1497.614005623283
INFO:root:current train perplexity3.3189268112182617
INFO:root:current mean train loss 1511.7582726603403
INFO:root:current train perplexity3.3144099712371826
INFO:root:current mean train loss 1509.4023475253705
INFO:root:current train perplexity3.317345380783081
INFO:root:current mean train loss 1510.2610322215673
INFO:root:current train perplexity3.3080990314483643
INFO:root:current mean train loss 1509.9805052965091
INFO:root:current train perplexity3.308753252029419
INFO:root:current mean train loss 1509.7318458105303
INFO:root:current train perplexity3.305494546890259
INFO:root:current mean train loss 1512.5656985601709
INFO:root:current train perplexity3.30551815032959
INFO:root:current mean train loss 1513.1869651128911
INFO:root:current train perplexity3.308722972869873
INFO:root:current mean train loss 1515.8562318607078
INFO:root:current train perplexity3.3140053749084473
INFO:root:current mean train loss 1517.264327556406
INFO:root:current train perplexity3.3150506019592285
INFO:root:current mean train loss 1517.843257578877
INFO:root:current train perplexity3.317220449447632
INFO:root:current mean train loss 1519.666427240764
INFO:root:current train perplexity3.3195483684539795
INFO:root:current mean train loss 1520.2849662893045
INFO:root:current train perplexity3.321092128753662
INFO:root:current mean train loss 1521.7450636555873
INFO:root:current train perplexity3.322009563446045
INFO:root:current mean train loss 1522.6498271038995
INFO:root:current train perplexity3.3235955238342285
INFO:root:current mean train loss 1523.7825034649247
INFO:root:current train perplexity3.3266968727111816
INFO:root:current mean train loss 1524.3943689708383
INFO:root:current train perplexity3.328869581222534
INFO:root:current mean train loss 1525.7355728021619
INFO:root:current train perplexity3.3301055431365967
INFO:root:current mean train loss 1525.6664594935714
INFO:root:current train perplexity3.3309743404388428

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.95s/it]
INFO:root:final mean train loss: 1525.9302058833089
INFO:root:final train perplexity: 3.331559181213379
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.27s/it]
INFO:root:eval mean loss: 2066.3030754792776
INFO:root:eval perplexity: 5.318039417266846
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.79s/it]
INFO:root:eval mean loss: 2577.1850971194867
INFO:root:eval perplexity: 8.229233741760254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/77
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 77/200 [13:33:27<21:40:34, 634.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1472.8243865966797
INFO:root:current train perplexity3.2625744342803955
INFO:root:current mean train loss 1510.3754803692852
INFO:root:current train perplexity3.279034376144409
INFO:root:current mean train loss 1510.1408010629507
INFO:root:current train perplexity3.293252468109131
INFO:root:current mean train loss 1509.411132416168
INFO:root:current train perplexity3.299581527709961
INFO:root:current mean train loss 1509.9839609183516
INFO:root:current train perplexity3.296271324157715
INFO:root:current mean train loss 1511.3666984978622
INFO:root:current train perplexity3.299325466156006
INFO:root:current mean train loss 1510.4087514375385
INFO:root:current train perplexity3.2992842197418213
INFO:root:current mean train loss 1510.689437262756
INFO:root:current train perplexity3.300588846206665
INFO:root:current mean train loss 1513.8505966639755
INFO:root:current train perplexity3.302509307861328
INFO:root:current mean train loss 1515.1453705506178
INFO:root:current train perplexity3.304208993911743
INFO:root:current mean train loss 1516.1216466994513
INFO:root:current train perplexity3.3068151473999023
INFO:root:current mean train loss 1517.0453963847797
INFO:root:current train perplexity3.3082263469696045
INFO:root:current mean train loss 1517.4702774957316
INFO:root:current train perplexity3.30903959274292
INFO:root:current mean train loss 1518.9606326975224
INFO:root:current train perplexity3.311553478240967
INFO:root:current mean train loss 1519.1141851598566
INFO:root:current train perplexity3.3126237392425537
INFO:root:current mean train loss 1520.0161459844371
INFO:root:current train perplexity3.3146655559539795
INFO:root:current mean train loss 1521.0696180353118
INFO:root:current train perplexity3.315528631210327
INFO:root:current mean train loss 1521.2006769470643
INFO:root:current train perplexity3.316582679748535
INFO:root:current mean train loss 1521.2737434859825
INFO:root:current train perplexity3.318113327026367
INFO:root:current mean train loss 1521.636867307267
INFO:root:current train perplexity3.3197109699249268

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.44s/it]
INFO:root:final mean train loss: 1521.54364047529
INFO:root:final train perplexity: 3.3200533390045166
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 2071.04261725676
INFO:root:eval perplexity: 5.338461875915527
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it]
INFO:root:eval mean loss: 2582.282709649269
INFO:root:eval perplexity: 8.263611793518066
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/78
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 78/200 [13:43:53<21:24:43, 631.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1500.2899755859376
INFO:root:current train perplexity3.2702810764312744
INFO:root:current mean train loss 1498.558712890625
INFO:root:current train perplexity3.295900344848633
INFO:root:current mean train loss 1499.4313118489583
INFO:root:current train perplexity3.279240846633911
INFO:root:current mean train loss 1503.6932598407452
INFO:root:current train perplexity3.285477638244629
INFO:root:current mean train loss 1505.4627665441176
INFO:root:current train perplexity3.2900407314300537
INFO:root:current mean train loss 1507.1264376395088
INFO:root:current train perplexity3.290006637573242
INFO:root:current mean train loss 1504.958194140625
INFO:root:current train perplexity3.2928659915924072
INFO:root:current mean train loss 1505.254261011584
INFO:root:current train perplexity3.2905824184417725
INFO:root:current mean train loss 1507.8786305930398
INFO:root:current train perplexity3.291114091873169
INFO:root:current mean train loss 1509.1806606313344
INFO:root:current train perplexity3.2942495346069336
INFO:root:current mean train loss 1509.1415991806402
INFO:root:current train perplexity3.2973639965057373
INFO:root:current mean train loss 1510.8139896918403
INFO:root:current train perplexity3.297898530960083
INFO:root:current mean train loss 1512.570115493463
INFO:root:current train perplexity3.299722909927368
INFO:root:current mean train loss 1512.9693937942218
INFO:root:current train perplexity3.2998199462890625
INFO:root:current mean train loss 1514.0975802665844
INFO:root:current train perplexity3.3015363216400146
INFO:root:current mean train loss 1514.3915937980278
INFO:root:current train perplexity3.30126953125
INFO:root:current mean train loss 1514.3826998197114
INFO:root:current train perplexity3.302410125732422
INFO:root:current mean train loss 1514.9220601222826
INFO:root:current train perplexity3.30181884765625
INFO:root:current mean train loss 1516.120896363977
INFO:root:current train perplexity3.303610324859619
INFO:root:current mean train loss 1516.673759385146
INFO:root:current train perplexity3.3057546615600586

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.82s/it]
INFO:root:final mean train loss: 1516.386598741894
INFO:root:final train perplexity: 3.306577444076538
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it]
INFO:root:eval mean loss: 2071.0220224366967
INFO:root:eval perplexity: 5.338373184204102
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.63s/it]
INFO:root:eval mean loss: 2584.2218472095246
INFO:root:eval perplexity: 8.276725769042969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/79
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 79/200 [13:54:20<21:11:15, 630.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1507.8656964983259
INFO:root:current train perplexity3.2710015773773193
INFO:root:current mean train loss 1515.3342629016286
INFO:root:current train perplexity3.2806172370910645
INFO:root:current mean train loss 1512.4114622005745
INFO:root:current train perplexity3.280233144760132
INFO:root:current mean train loss 1508.9029840837445
INFO:root:current train perplexity3.278237819671631
INFO:root:current mean train loss 1507.132784329928
INFO:root:current train perplexity3.281831979751587
INFO:root:current mean train loss 1504.871752073844
INFO:root:current train perplexity3.275698661804199
INFO:root:current mean train loss 1507.1551121982088
INFO:root:current train perplexity3.278599739074707
INFO:root:current mean train loss 1507.8292201779923
INFO:root:current train perplexity3.280648708343506
INFO:root:current mean train loss 1506.961599318262
INFO:root:current train perplexity3.281318426132202
INFO:root:current mean train loss 1507.5377100075887
INFO:root:current train perplexity3.284605026245117
INFO:root:current mean train loss 1509.2284395946422
INFO:root:current train perplexity3.2860310077667236
INFO:root:current mean train loss 1507.6894643486278
INFO:root:current train perplexity3.285616874694824
INFO:root:current mean train loss 1508.393352612973
INFO:root:current train perplexity3.2877731323242188
INFO:root:current mean train loss 1508.2162092638087
INFO:root:current train perplexity3.2878596782684326
INFO:root:current mean train loss 1509.1209828539463
INFO:root:current train perplexity3.2901835441589355
INFO:root:current mean train loss 1510.1441592601177
INFO:root:current train perplexity3.290982246398926
INFO:root:current mean train loss 1510.759631065155
INFO:root:current train perplexity3.291616678237915
INFO:root:current mean train loss 1510.78693937352
INFO:root:current train perplexity3.292398452758789
INFO:root:current mean train loss 1511.7826357167396
INFO:root:current train perplexity3.2934212684631348
INFO:root:current mean train loss 1511.8901858108788
INFO:root:current train perplexity3.2943532466888428

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.46s/it]
INFO:root:final mean train loss: 1511.8451605184596
INFO:root:final train perplexity: 3.294755220413208
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it]
INFO:root:eval mean loss: 2074.9289130894003
INFO:root:eval perplexity: 5.355267524719238
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 2589.8179996571644
INFO:root:eval perplexity: 8.314696311950684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/80
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [14:04:47<20:58:30, 629.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1496.7172044657045
INFO:root:current train perplexity3.2440967559814453
INFO:root:current mean train loss 1488.9558965335102
INFO:root:current train perplexity3.2320070266723633
INFO:root:current mean train loss 1490.7068149168979
INFO:root:current train perplexity3.2453298568725586
INFO:root:current mean train loss 1496.322922560498
INFO:root:current train perplexity3.252715587615967
INFO:root:current mean train loss 1495.7584547653696
INFO:root:current train perplexity3.253580331802368
INFO:root:current mean train loss 1497.7357367718582
INFO:root:current train perplexity3.2525763511657715
INFO:root:current mean train loss 1499.291476861841
INFO:root:current train perplexity3.2558436393737793
INFO:root:current mean train loss 1499.1849622563097
INFO:root:current train perplexity3.2581605911254883
INFO:root:current mean train loss 1498.520340978336
INFO:root:current train perplexity3.259942054748535
INFO:root:current mean train loss 1500.1457226766163
INFO:root:current train perplexity3.263645648956299
INFO:root:current mean train loss 1501.0649882056332
INFO:root:current train perplexity3.265589714050293
INFO:root:current mean train loss 1501.6346166971123
INFO:root:current train perplexity3.2672648429870605
INFO:root:current mean train loss 1503.3871505046477
INFO:root:current train perplexity3.270040988922119
INFO:root:current mean train loss 1504.367666080298
INFO:root:current train perplexity3.272400379180908
INFO:root:current mean train loss 1505.200420293357
INFO:root:current train perplexity3.2739505767822266
INFO:root:current mean train loss 1505.1586913279496
INFO:root:current train perplexity3.2754671573638916
INFO:root:current mean train loss 1506.3910743570816
INFO:root:current train perplexity3.2772183418273926
INFO:root:current mean train loss 1506.648905794752
INFO:root:current train perplexity3.279616594314575
INFO:root:current mean train loss 1506.470633520626
INFO:root:current train perplexity3.2801454067230225
INFO:root:current mean train loss 1507.055910072502
INFO:root:current train perplexity3.2821199893951416

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.94s/it]
INFO:root:final mean train loss: 1507.2077727825185
INFO:root:final train perplexity: 3.2827277183532715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.70s/it]
INFO:root:eval mean loss: 2076.2590163210607
INFO:root:eval perplexity: 5.361031532287598
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.21s/it]
INFO:root:eval mean loss: 2591.3799615954676
INFO:root:eval perplexity: 8.32532024383545
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/81
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 81/200 [14:15:20<20:50:20, 630.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1485.0413015265215
INFO:root:current train perplexity3.239043951034546
INFO:root:current mean train loss 1494.7833099365234
INFO:root:current train perplexity3.247807502746582
INFO:root:current mean train loss 1492.9276737821274
INFO:root:current train perplexity3.246255874633789
INFO:root:current mean train loss 1493.8041479232463
INFO:root:current train perplexity3.2498388290405273
INFO:root:current mean train loss 1494.9647388618534
INFO:root:current train perplexity3.24665904045105
INFO:root:current mean train loss 1497.4729355706108
INFO:root:current train perplexity3.2481741905212402
INFO:root:current mean train loss 1497.460526505871
INFO:root:current train perplexity3.2501747608184814
INFO:root:current mean train loss 1497.8924820103596
INFO:root:current train perplexity3.251157522201538
INFO:root:current mean train loss 1498.791559924818
INFO:root:current train perplexity3.253840208053589
INFO:root:current mean train loss 1499.651783427254
INFO:root:current train perplexity3.2551889419555664
INFO:root:current mean train loss 1499.7710595113194
INFO:root:current train perplexity3.257838249206543
INFO:root:current mean train loss 1500.316702602672
INFO:root:current train perplexity3.2598204612731934
INFO:root:current mean train loss 1501.7882928638996
INFO:root:current train perplexity3.2633185386657715
INFO:root:current mean train loss 1501.7084014360296
INFO:root:current train perplexity3.263827085494995
INFO:root:current mean train loss 1500.702868371152
INFO:root:current train perplexity3.2641541957855225
INFO:root:current mean train loss 1501.2394691118734
INFO:root:current train perplexity3.265580654144287
INFO:root:current mean train loss 1501.2712081872762
INFO:root:current train perplexity3.2666263580322266
INFO:root:current mean train loss 1501.334934337719
INFO:root:current train perplexity3.267732858657837
INFO:root:current mean train loss 1502.2243604843043
INFO:root:current train perplexity3.2693932056427
INFO:root:current mean train loss 1502.87863171535
INFO:root:current train perplexity3.2706804275512695

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.20s/it]
INFO:root:final mean train loss: 1502.576931505689
INFO:root:final train perplexity: 3.2707607746124268
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it]
INFO:root:eval mean loss: 2079.895907354693
INFO:root:eval perplexity: 5.3768229484558105
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it]
INFO:root:eval mean loss: 2595.715816416639
INFO:root:eval perplexity: 8.354896545410156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/82
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 82/200 [14:26:01<20:46:00, 633.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1482.1817745085687
INFO:root:current train perplexity3.2183966636657715
INFO:root:current mean train loss 1487.020278851603
INFO:root:current train perplexity3.234922409057617
INFO:root:current mean train loss 1488.5828594949871
INFO:root:current train perplexity3.2378101348876953
INFO:root:current mean train loss 1490.4578292108977
INFO:root:current train perplexity3.2369420528411865
INFO:root:current mean train loss 1490.5199014226514
INFO:root:current train perplexity3.2358152866363525
INFO:root:current mean train loss 1494.4918735755032
INFO:root:current train perplexity3.2438132762908936
INFO:root:current mean train loss 1493.1929877034856
INFO:root:current train perplexity3.246976852416992
INFO:root:current mean train loss 1493.9158225907354
INFO:root:current train perplexity3.2496445178985596
INFO:root:current mean train loss 1494.222366042527
INFO:root:current train perplexity3.2489871978759766
INFO:root:current mean train loss 1495.5310719961606
INFO:root:current train perplexity3.250168561935425
INFO:root:current mean train loss 1496.2544126240136
INFO:root:current train perplexity3.250878095626831
INFO:root:current mean train loss 1496.4573052686897
INFO:root:current train perplexity3.253150701522827
INFO:root:current mean train loss 1495.7977579091744
INFO:root:current train perplexity3.253087043762207
INFO:root:current mean train loss 1495.9319693297682
INFO:root:current train perplexity3.253873109817505
INFO:root:current mean train loss 1496.308541258948
INFO:root:current train perplexity3.25425386428833
INFO:root:current mean train loss 1497.4736058390222
INFO:root:current train perplexity3.254371404647827
INFO:root:current mean train loss 1497.4975591705736
INFO:root:current train perplexity3.2564854621887207
INFO:root:current mean train loss 1497.7775313828952
INFO:root:current train perplexity3.2577219009399414
INFO:root:current mean train loss 1498.1063779255605
INFO:root:current train perplexity3.2577931880950928

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.91s/it]
INFO:root:final mean train loss: 1497.9665282033516
INFO:root:final train perplexity: 3.2588894367218018
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it]
INFO:root:eval mean loss: 2082.4357451310393
INFO:root:eval perplexity: 5.387878894805908
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it]
INFO:root:eval mean loss: 2601.4414655536625
INFO:root:eval perplexity: 8.394110679626465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/83
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 83/200 [14:36:31<20:33:15, 632.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1446.6401611328124
INFO:root:current train perplexity3.15775465965271
INFO:root:current mean train loss 1474.4415660511363
INFO:root:current train perplexity3.2023513317108154
INFO:root:current mean train loss 1478.271148390997
INFO:root:current train perplexity3.2052009105682373
INFO:root:current mean train loss 1478.8839946131552
INFO:root:current train perplexity3.204280138015747
INFO:root:current mean train loss 1477.4568540991806
INFO:root:current train perplexity3.2047982215881348
INFO:root:current mean train loss 1480.0336176853555
INFO:root:current train perplexity3.2108891010284424
INFO:root:current mean train loss 1480.5185712970672
INFO:root:current train perplexity3.216945171356201
INFO:root:current mean train loss 1481.343906284386
INFO:root:current train perplexity3.2213900089263916
INFO:root:current mean train loss 1482.0722076039256
INFO:root:current train perplexity3.224125385284424
INFO:root:current mean train loss 1482.5817421714028
INFO:root:current train perplexity3.226148843765259
INFO:root:current mean train loss 1485.1274207389001
INFO:root:current train perplexity3.227882146835327
INFO:root:current mean train loss 1485.9529306772592
INFO:root:current train perplexity3.230147361755371
INFO:root:current mean train loss 1487.1972141738765
INFO:root:current train perplexity3.232234477996826
INFO:root:current mean train loss 1487.2479702782084
INFO:root:current train perplexity3.2337942123413086
INFO:root:current mean train loss 1488.0815426224513
INFO:root:current train perplexity3.236626148223877
INFO:root:current mean train loss 1489.0348848658682
INFO:root:current train perplexity3.2377614974975586
INFO:root:current mean train loss 1489.6351523831765
INFO:root:current train perplexity3.2390458583831787
INFO:root:current mean train loss 1489.519432166027
INFO:root:current train perplexity3.240063428878784
INFO:root:current mean train loss 1491.6199689496289
INFO:root:current train perplexity3.243762254714966
INFO:root:current mean train loss 1492.7124734129582
INFO:root:current train perplexity3.2447214126586914

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.63s/it]
INFO:root:final mean train loss: 1493.422142994506
INFO:root:final train perplexity: 3.247230291366577
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.44s/it]
INFO:root:eval mean loss: 2084.9805232920544
INFO:root:eval perplexity: 5.398978233337402
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.59s/it]
INFO:root:eval mean loss: 2603.1512884045324
INFO:root:eval perplexity: 8.405856132507324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/84
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 84/200 [14:47:00<20:20:41, 631.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1460.3490577980324
INFO:root:current train perplexity3.1928634643554688
INFO:root:current mean train loss 1478.485848494402
INFO:root:current train perplexity3.209868907928467
INFO:root:current mean train loss 1483.4333609022233
INFO:root:current train perplexity3.2131118774414062
INFO:root:current mean train loss 1480.0114021884556
INFO:root:current train perplexity3.215559720993042
INFO:root:current mean train loss 1480.7229389842835
INFO:root:current train perplexity3.2145001888275146
INFO:root:current mean train loss 1480.8962988373903
INFO:root:current train perplexity3.2123019695281982
INFO:root:current mean train loss 1482.212907952365
INFO:root:current train perplexity3.214787006378174
INFO:root:current mean train loss 1484.5867124030153
INFO:root:current train perplexity3.2187600135803223
INFO:root:current mean train loss 1485.1322902693282
INFO:root:current train perplexity3.2204723358154297
INFO:root:current mean train loss 1483.8190371483531
INFO:root:current train perplexity3.218247413635254
INFO:root:current mean train loss 1483.8262436670825
INFO:root:current train perplexity3.2182812690734863
INFO:root:current mean train loss 1485.9731907814926
INFO:root:current train perplexity3.220583200454712
INFO:root:current mean train loss 1486.2900598552428
INFO:root:current train perplexity3.2229316234588623
INFO:root:current mean train loss 1487.2717884009103
INFO:root:current train perplexity3.226051092147827
INFO:root:current mean train loss 1487.7495669797324
INFO:root:current train perplexity3.226684093475342
INFO:root:current mean train loss 1487.8216190600442
INFO:root:current train perplexity3.228771924972534
INFO:root:current mean train loss 1487.565264176062
INFO:root:current train perplexity3.228883981704712
INFO:root:current mean train loss 1488.0832820642734
INFO:root:current train perplexity3.2314345836639404
INFO:root:current mean train loss 1488.899016047803
INFO:root:current train perplexity3.2341160774230957
INFO:root:current mean train loss 1489.9029798205802
INFO:root:current train perplexity3.23645281791687

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.36s/it]
INFO:root:final mean train loss: 1489.4663283539974
INFO:root:final train perplexity: 3.2371158599853516
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it]
INFO:root:eval mean loss: 2086.7868388290944
INFO:root:eval perplexity: 5.406871318817139
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.87s/it]
INFO:root:eval mean loss: 2608.0412766476893
INFO:root:eval perplexity: 8.43954086303711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/85
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 85/200 [14:57:25<20:06:40, 629.57s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1467.681768243963
INFO:root:current train perplexity3.187058210372925
INFO:root:current mean train loss 1473.0736389160156
INFO:root:current train perplexity3.205625057220459
INFO:root:current mean train loss 1476.3728707735656
INFO:root:current train perplexity3.213017225265503
INFO:root:current mean train loss 1477.5295324990916
INFO:root:current train perplexity3.2088749408721924
INFO:root:current mean train loss 1479.060502060899
INFO:root:current train perplexity3.2107858657836914
INFO:root:current mean train loss 1479.0017619413488
INFO:root:current train perplexity3.2095842361450195
INFO:root:current mean train loss 1480.6837796987213
INFO:root:current train perplexity3.21115779876709
INFO:root:current mean train loss 1482.9610259353474
INFO:root:current train perplexity3.213758945465088
INFO:root:current mean train loss 1483.942001270457
INFO:root:current train perplexity3.215038776397705
INFO:root:current mean train loss 1483.1732948432534
INFO:root:current train perplexity3.2127323150634766
INFO:root:current mean train loss 1482.6893225191197
INFO:root:current train perplexity3.213681936264038
INFO:root:current mean train loss 1482.6034476540306
INFO:root:current train perplexity3.2149503231048584
INFO:root:current mean train loss 1483.6966798052526
INFO:root:current train perplexity3.2163984775543213
INFO:root:current mean train loss 1484.0905693599157
INFO:root:current train perplexity3.217420816421509
INFO:root:current mean train loss 1485.216259900883
INFO:root:current train perplexity3.2199175357818604
INFO:root:current mean train loss 1485.4628608189716
INFO:root:current train perplexity3.221107006072998
INFO:root:current mean train loss 1485.329400501112
INFO:root:current train perplexity3.222208023071289
INFO:root:current mean train loss 1485.303405481741
INFO:root:current train perplexity3.2239603996276855
INFO:root:current mean train loss 1485.138035639765
INFO:root:current train perplexity3.2249274253845215
INFO:root:current mean train loss 1485.4636683208953
INFO:root:current train perplexity3.2265264987945557

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.09s/it]
INFO:root:final mean train loss: 1485.28072164423
INFO:root:final train perplexity: 3.226447582244873
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.81s/it]
INFO:root:eval mean loss: 2091.7320045849956
INFO:root:eval perplexity: 5.428539276123047
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.78s/it]
INFO:root:eval mean loss: 2613.238015898576
INFO:root:eval perplexity: 8.475485801696777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/86
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [15:08:09<20:04:23, 633.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1461.1798335841445
INFO:root:current train perplexity3.161621570587158
INFO:root:current mean train loss 1464.4828404017858
INFO:root:current train perplexity3.1833279132843018
INFO:root:current mean train loss 1468.0310152134218
INFO:root:current train perplexity3.1915698051452637
INFO:root:current mean train loss 1470.1069924309643
INFO:root:current train perplexity3.194946050643921
INFO:root:current mean train loss 1470.527151773912
INFO:root:current train perplexity3.1957454681396484
INFO:root:current mean train loss 1470.0064856109348
INFO:root:current train perplexity3.198225498199463
INFO:root:current mean train loss 1471.1217868360557
INFO:root:current train perplexity3.1968295574188232
INFO:root:current mean train loss 1473.188471589859
INFO:root:current train perplexity3.201207399368286
INFO:root:current mean train loss 1473.7569054084095
INFO:root:current train perplexity3.2021350860595703
INFO:root:current mean train loss 1473.952185274535
INFO:root:current train perplexity3.2035090923309326
INFO:root:current mean train loss 1474.4231954533238
INFO:root:current train perplexity3.2036550045013428
INFO:root:current mean train loss 1475.896676470143
INFO:root:current train perplexity3.2053117752075195
INFO:root:current mean train loss 1476.2519618373935
INFO:root:current train perplexity3.206475019454956
INFO:root:current mean train loss 1477.4536850345564
INFO:root:current train perplexity3.206864595413208
INFO:root:current mean train loss 1478.4801921909757
INFO:root:current train perplexity3.208573579788208
INFO:root:current mean train loss 1478.3532591287635
INFO:root:current train perplexity3.2073841094970703
INFO:root:current mean train loss 1478.0328221421582
INFO:root:current train perplexity3.2076873779296875
INFO:root:current mean train loss 1478.7439021685122
INFO:root:current train perplexity3.2095437049865723
INFO:root:current mean train loss 1479.924247204649
INFO:root:current train perplexity3.213747024536133
INFO:root:current mean train loss 1481.3157179004254
INFO:root:current train perplexity3.214982748031616

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.35s/it]
INFO:root:final mean train loss: 1480.7425589434017
INFO:root:final train perplexity: 3.214920997619629
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.77s/it]
INFO:root:eval mean loss: 2093.727635593279
INFO:root:eval perplexity: 5.4373064041137695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.89s/it]
INFO:root:eval mean loss: 2615.9893326996066
INFO:root:eval perplexity: 8.494576454162598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/87
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 87/200 [15:18:52<19:59:07, 636.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1455.3487611428286
INFO:root:current train perplexity3.144463300704956
INFO:root:current mean train loss 1471.634926785244
INFO:root:current train perplexity3.175502300262451
INFO:root:current mean train loss 1466.742937046847
INFO:root:current train perplexity3.1708521842956543
INFO:root:current mean train loss 1468.183425822586
INFO:root:current train perplexity3.172386884689331
INFO:root:current mean train loss 1469.5489228699496
INFO:root:current train perplexity3.178661823272705
INFO:root:current mean train loss 1469.462342153371
INFO:root:current train perplexity3.1780552864074707
INFO:root:current mean train loss 1470.4622302210084
INFO:root:current train perplexity3.180891752243042
INFO:root:current mean train loss 1470.8018634080274
INFO:root:current train perplexity3.1826138496398926
INFO:root:current mean train loss 1470.8409503076505
INFO:root:current train perplexity3.1874377727508545
INFO:root:current mean train loss 1472.4135436387637
INFO:root:current train perplexity3.1920695304870605
INFO:root:current mean train loss 1471.7164229638943
INFO:root:current train perplexity3.193122625350952
INFO:root:current mean train loss 1473.3315729163903
INFO:root:current train perplexity3.194251298904419
INFO:root:current mean train loss 1473.6363096520747
INFO:root:current train perplexity3.1959078311920166
INFO:root:current mean train loss 1474.3368148471516
INFO:root:current train perplexity3.196974039077759
INFO:root:current mean train loss 1475.4202634736553
INFO:root:current train perplexity3.198186159133911
INFO:root:current mean train loss 1475.0132614155082
INFO:root:current train perplexity3.1980416774749756
INFO:root:current mean train loss 1475.9003149675952
INFO:root:current train perplexity3.1999924182891846
INFO:root:current mean train loss 1475.9788162008313
INFO:root:current train perplexity3.200464963912964
INFO:root:current mean train loss 1476.3450011232028
INFO:root:current train perplexity3.202352523803711
INFO:root:current mean train loss 1476.9170492112455
INFO:root:current train perplexity3.2042953968048096

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.87s/it]
INFO:root:final mean train loss: 1476.5788040507398
INFO:root:final train perplexity: 3.2043802738189697
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.25s/it]
INFO:root:eval mean loss: 2097.4703815000275
INFO:root:eval perplexity: 5.453790664672852
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.05s/it]
INFO:root:eval mean loss: 2617.528776128241
INFO:root:eval perplexity: 8.505278587341309
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/88
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 88/200 [15:29:22<19:44:29, 634.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1462.9197406969572
INFO:root:current train perplexity3.1692113876342773
INFO:root:current mean train loss 1460.1992381560497
INFO:root:current train perplexity3.1646509170532227
INFO:root:current mean train loss 1463.829518256753
INFO:root:current train perplexity3.168628454208374
INFO:root:current mean train loss 1460.040035044996
INFO:root:current train perplexity3.1684937477111816
INFO:root:current mean train loss 1463.1325284090908
INFO:root:current train perplexity3.1713943481445312
INFO:root:current mean train loss 1464.187346950499
INFO:root:current train perplexity3.1723835468292236
INFO:root:current mean train loss 1464.741022299348
INFO:root:current train perplexity3.175122022628784
INFO:root:current mean train loss 1465.8550087215015
INFO:root:current train perplexity3.176569700241089
INFO:root:current mean train loss 1468.1575680865922
INFO:root:current train perplexity3.1766178607940674
INFO:root:current mean train loss 1468.0227286334014
INFO:root:current train perplexity3.180725336074829
INFO:root:current mean train loss 1469.5882131358803
INFO:root:current train perplexity3.1822307109832764
INFO:root:current mean train loss 1469.6801980501439
INFO:root:current train perplexity3.1849236488342285
INFO:root:current mean train loss 1469.8342381304296
INFO:root:current train perplexity3.1847949028015137
INFO:root:current mean train loss 1470.6270556815637
INFO:root:current train perplexity3.1853368282318115
INFO:root:current mean train loss 1470.7027840196488
INFO:root:current train perplexity3.186713457107544
INFO:root:current mean train loss 1470.852211041585
INFO:root:current train perplexity3.1895031929016113
INFO:root:current mean train loss 1471.3975114220364
INFO:root:current train perplexity3.1899335384368896
INFO:root:current mean train loss 1471.7637499455955
INFO:root:current train perplexity3.191272020339966
INFO:root:current mean train loss 1472.095415245197
INFO:root:current train perplexity3.192488193511963

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:09<00:00, 549.98s/it]
INFO:root:final mean train loss: 1472.5337953168337
INFO:root:final train perplexity: 3.1941747665405273
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it]
INFO:root:eval mean loss: 2099.7989636143893
INFO:root:eval perplexity: 5.464069843292236
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.73s/it]
INFO:root:eval mean loss: 2622.3245286873894
INFO:root:eval perplexity: 8.538703918457031
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/89
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 89/200 [15:39:45<19:27:43, 631.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1491.8888346354167
INFO:root:current train perplexity3.1478657722473145
INFO:root:current mean train loss 1453.9598519461495
INFO:root:current train perplexity3.1350371837615967
INFO:root:current mean train loss 1455.7465584233123
INFO:root:current train perplexity3.139583110809326
INFO:root:current mean train loss 1456.2987217047275
INFO:root:current train perplexity3.1494035720825195
INFO:root:current mean train loss 1457.1968407492036
INFO:root:current train perplexity3.154093027114868
INFO:root:current mean train loss 1459.8215460777283
INFO:root:current train perplexity3.161029100418091
INFO:root:current mean train loss 1462.8987642176012
INFO:root:current train perplexity3.164712429046631
INFO:root:current mean train loss 1462.8912627830935
INFO:root:current train perplexity3.167572259902954
INFO:root:current mean train loss 1462.689853762171
INFO:root:current train perplexity3.171635150909424
INFO:root:current mean train loss 1463.597128349438
INFO:root:current train perplexity3.174098253250122
INFO:root:current mean train loss 1464.552387946208
INFO:root:current train perplexity3.1744771003723145
INFO:root:current mean train loss 1465.4161674444624
INFO:root:current train perplexity3.1747734546661377
INFO:root:current mean train loss 1466.3464156046953
INFO:root:current train perplexity3.1760966777801514
INFO:root:current mean train loss 1466.489301448915
INFO:root:current train perplexity3.176652669906616
INFO:root:current mean train loss 1466.9966342482958
INFO:root:current train perplexity3.177924394607544
INFO:root:current mean train loss 1467.3281631066054
INFO:root:current train perplexity3.1790096759796143
INFO:root:current mean train loss 1467.804425185135
INFO:root:current train perplexity3.1816344261169434
INFO:root:current mean train loss 1468.2882925015745
INFO:root:current train perplexity3.183063507080078
INFO:root:current mean train loss 1468.4472487830694
INFO:root:current train perplexity3.182767152786255
INFO:root:current mean train loss 1468.6429451020692
INFO:root:current train perplexity3.1837382316589355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.28s/it]
INFO:root:final mean train loss: 1468.3733944029623
INFO:root:final train perplexity: 3.183711290359497
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it]
INFO:root:eval mean loss: 2104.426421036957
INFO:root:eval perplexity: 5.48455810546875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 36.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.03s/it]
INFO:root:eval mean loss: 2630.4584419845687
INFO:root:eval perplexity: 8.595691680908203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/90
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 90/200 [15:50:16<19:16:48, 630.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1433.2933686355066
INFO:root:current train perplexity3.152571201324463
INFO:root:current mean train loss 1452.2235949612402
INFO:root:current train perplexity3.151271104812622
INFO:root:current mean train loss 1452.4778445048103
INFO:root:current train perplexity3.156881809234619
INFO:root:current mean train loss 1451.203012205547
INFO:root:current train perplexity3.154186487197876
INFO:root:current mean train loss 1456.3011855901261
INFO:root:current train perplexity3.1567542552948
INFO:root:current mean train loss 1456.6096152177606
INFO:root:current train perplexity3.1506261825561523
INFO:root:current mean train loss 1457.9803719088459
INFO:root:current train perplexity3.1536834239959717
INFO:root:current mean train loss 1457.947808996967
INFO:root:current train perplexity3.1551170349121094
INFO:root:current mean train loss 1457.9035188056016
INFO:root:current train perplexity3.1548912525177
INFO:root:current mean train loss 1458.6716776376647
INFO:root:current train perplexity3.1558406352996826
INFO:root:current mean train loss 1459.6085959565187
INFO:root:current train perplexity3.1591672897338867
INFO:root:current mean train loss 1460.0574863592642
INFO:root:current train perplexity3.1619200706481934
INFO:root:current mean train loss 1461.1020304196438
INFO:root:current train perplexity3.1644980907440186
INFO:root:current mean train loss 1461.0954412570836
INFO:root:current train perplexity3.1655666828155518
INFO:root:current mean train loss 1462.3306364535952
INFO:root:current train perplexity3.1683950424194336
INFO:root:current mean train loss 1463.1303049091266
INFO:root:current train perplexity3.1692934036254883
INFO:root:current mean train loss 1464.1597469510148
INFO:root:current train perplexity3.1704800128936768
INFO:root:current mean train loss 1464.0888714236012
INFO:root:current train perplexity3.1703152656555176
INFO:root:current mean train loss 1464.0361125898075
INFO:root:current train perplexity3.1714930534362793
INFO:root:current mean train loss 1464.5204351018783
INFO:root:current train perplexity3.1730082035064697

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.72s/it]
INFO:root:final mean train loss: 1464.2603449819067
INFO:root:final train perplexity: 3.173400640487671
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.76s/it]
INFO:root:eval mean loss: 2103.914451220357
INFO:root:eval perplexity: 5.482287883758545
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.93s/it]
INFO:root:eval mean loss: 2631.011063379599
INFO:root:eval perplexity: 8.599575996398926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/91
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 91/200 [16:00:58<19:12:38, 634.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1428.674149222996
INFO:root:current train perplexity3.0925586223602295
INFO:root:current mean train loss 1438.8032176396619
INFO:root:current train perplexity3.1240015029907227
INFO:root:current mean train loss 1441.837721413713
INFO:root:current train perplexity3.1237752437591553
INFO:root:current mean train loss 1442.3913990527908
INFO:root:current train perplexity3.12886643409729
INFO:root:current mean train loss 1445.936406293792
INFO:root:current train perplexity3.132200241088867
INFO:root:current mean train loss 1449.4624363266942
INFO:root:current train perplexity3.1431217193603516
INFO:root:current mean train loss 1450.7739962645728
INFO:root:current train perplexity3.143463134765625
INFO:root:current mean train loss 1453.1668036821382
INFO:root:current train perplexity3.1467912197113037
INFO:root:current mean train loss 1452.9737300647348
INFO:root:current train perplexity3.1487390995025635
INFO:root:current mean train loss 1453.502142037196
INFO:root:current train perplexity3.1506195068359375
INFO:root:current mean train loss 1455.6690664491964
INFO:root:current train perplexity3.1520237922668457
INFO:root:current mean train loss 1455.6878183840872
INFO:root:current train perplexity3.153651237487793
INFO:root:current mean train loss 1456.2809138657767
INFO:root:current train perplexity3.153815507888794
INFO:root:current mean train loss 1457.1308404205458
INFO:root:current train perplexity3.155061960220337
INFO:root:current mean train loss 1458.2958593513627
INFO:root:current train perplexity3.1565983295440674
INFO:root:current mean train loss 1458.5588967938936
INFO:root:current train perplexity3.1577584743499756
INFO:root:current mean train loss 1459.5915164692578
INFO:root:current train perplexity3.16043758392334
INFO:root:current mean train loss 1459.4389526786674
INFO:root:current train perplexity3.1608235836029053
INFO:root:current mean train loss 1459.6093072860237
INFO:root:current train perplexity3.161649465560913
INFO:root:current mean train loss 1460.4302711290788
INFO:root:current train perplexity3.163379430770874

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.69s/it]
INFO:root:final mean train loss: 1460.5101286964589
INFO:root:final train perplexity: 3.1640288829803467
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it]
INFO:root:eval mean loss: 2106.4393492353724
INFO:root:eval perplexity: 5.493493556976318
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it]
INFO:root:eval mean loss: 2633.7251032836048
INFO:root:eval perplexity: 8.618685722351074
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/92
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [16:11:27<18:58:43, 632.63s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1442.0352008153523
INFO:root:current train perplexity3.141871213912964
INFO:root:current mean train loss 1442.2584969924271
INFO:root:current train perplexity3.1416730880737305
INFO:root:current mean train loss 1446.7984920835313
INFO:root:current train perplexity3.1421422958374023
INFO:root:current mean train loss 1447.63811095687
INFO:root:current train perplexity3.1412858963012695
INFO:root:current mean train loss 1446.9789830778382
INFO:root:current train perplexity3.1368603706359863
INFO:root:current mean train loss 1446.873033215267
INFO:root:current train perplexity3.137651205062866
INFO:root:current mean train loss 1448.3201950326404
INFO:root:current train perplexity3.1401968002319336
INFO:root:current mean train loss 1449.4132856016547
INFO:root:current train perplexity3.1402435302734375
INFO:root:current mean train loss 1450.6005439272071
INFO:root:current train perplexity3.1413087844848633
INFO:root:current mean train loss 1451.1813604844074
INFO:root:current train perplexity3.141089916229248
INFO:root:current mean train loss 1452.7864440171536
INFO:root:current train perplexity3.1422922611236572
INFO:root:current mean train loss 1453.2893165070132
INFO:root:current train perplexity3.1432573795318604
INFO:root:current mean train loss 1454.5206470867045
INFO:root:current train perplexity3.1463587284088135
INFO:root:current mean train loss 1455.1393174236518
INFO:root:current train perplexity3.147136688232422
INFO:root:current mean train loss 1455.0680937072796
INFO:root:current train perplexity3.1485931873321533
INFO:root:current mean train loss 1455.3318390458803
INFO:root:current train perplexity3.1486291885375977
INFO:root:current mean train loss 1455.4032808947263
INFO:root:current train perplexity3.1506588459014893
INFO:root:current mean train loss 1455.6431114815612
INFO:root:current train perplexity3.1511754989624023
INFO:root:current mean train loss 1456.1819017362159
INFO:root:current train perplexity3.1520962715148926
INFO:root:current mean train loss 1456.4454313366618
INFO:root:current train perplexity3.152578115463257

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.25s/it]
INFO:root:final mean train loss: 1456.075665988047
INFO:root:final train perplexity: 3.152982473373413
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.38s/it]
INFO:root:eval mean loss: 2111.9931216409022
INFO:root:eval perplexity: 5.518224239349365
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.99s/it]
INFO:root:eval mean loss: 2641.0580396719856
INFO:root:eval perplexity: 8.670528411865234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/93
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 93/200 [16:22:06<18:52:05, 634.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1433.7476028442384
INFO:root:current train perplexity3.101123809814453
INFO:root:current mean train loss 1444.5927069769966
INFO:root:current train perplexity3.113586664199829
INFO:root:current mean train loss 1445.436839076451
INFO:root:current train perplexity3.118441343307495
INFO:root:current mean train loss 1446.2195922851563
INFO:root:current train perplexity3.118812322616577
INFO:root:current mean train loss 1444.4812761942546
INFO:root:current train perplexity3.1210954189300537
INFO:root:current mean train loss 1444.157542051118
INFO:root:current train perplexity3.121337652206421
INFO:root:current mean train loss 1445.8203631232766
INFO:root:current train perplexity3.12431263923645
INFO:root:current mean train loss 1446.2603060208835
INFO:root:current train perplexity3.124844551086426
INFO:root:current mean train loss 1446.4523750998758
INFO:root:current train perplexity3.1281025409698486
INFO:root:current mean train loss 1448.1426015425702
INFO:root:current train perplexity3.1309666633605957
INFO:root:current mean train loss 1448.1323954264324
INFO:root:current train perplexity3.1317050457000732
INFO:root:current mean train loss 1449.222130313162
INFO:root:current train perplexity3.133814811706543
INFO:root:current mean train loss 1449.3523189544678
INFO:root:current train perplexity3.1351048946380615
INFO:root:current mean train loss 1449.9678120046422
INFO:root:current train perplexity3.135328531265259
INFO:root:current mean train loss 1450.2347940805796
INFO:root:current train perplexity3.1374430656433105
INFO:root:current mean train loss 1451.4635015173803
INFO:root:current train perplexity3.139810800552368
INFO:root:current mean train loss 1451.8838322230747
INFO:root:current train perplexity3.140902042388916
INFO:root:current mean train loss 1452.3419389017513
INFO:root:current train perplexity3.1421196460723877
INFO:root:current mean train loss 1452.3726367057639
INFO:root:current train perplexity3.142444372177124
INFO:root:current mean train loss 1452.4887218745068
INFO:root:current train perplexity3.143129587173462

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.37s/it]
INFO:root:final mean train loss: 1452.1481340170749
INFO:root:final train perplexity: 3.1432313919067383
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.03s/it]
INFO:root:eval mean loss: 2113.2078216769173
INFO:root:eval perplexity: 5.523647785186768
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.73s/it]
INFO:root:eval mean loss: 2643.750577020307
INFO:root:eval perplexity: 8.689641952514648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/94
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 94/200 [16:32:39<18:40:12, 634.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1435.5550813969878
INFO:root:current train perplexity3.115389108657837
INFO:root:current mean train loss 1438.4973039191386
INFO:root:current train perplexity3.1164259910583496
INFO:root:current mean train loss 1435.962093674374
INFO:root:current train perplexity3.112602472305298
INFO:root:current mean train loss 1434.311279296875
INFO:root:current train perplexity3.1059558391571045
INFO:root:current mean train loss 1434.6193353971485
INFO:root:current train perplexity3.1111392974853516
INFO:root:current mean train loss 1435.9330506700167
INFO:root:current train perplexity3.1145498752593994
INFO:root:current mean train loss 1437.0094787510088
INFO:root:current train perplexity3.1157891750335693
INFO:root:current mean train loss 1440.805146220936
INFO:root:current train perplexity3.120922565460205
INFO:root:current mean train loss 1442.6968370860768
INFO:root:current train perplexity3.122954845428467
INFO:root:current mean train loss 1442.8818327541217
INFO:root:current train perplexity3.1233770847320557
INFO:root:current mean train loss 1443.622683891081
INFO:root:current train perplexity3.123483896255493
INFO:root:current mean train loss 1444.8001893568558
INFO:root:current train perplexity3.1250243186950684
INFO:root:current mean train loss 1445.3865591268311
INFO:root:current train perplexity3.1263785362243652
INFO:root:current mean train loss 1445.703813207431
INFO:root:current train perplexity3.1255884170532227
INFO:root:current mean train loss 1445.9429793017023
INFO:root:current train perplexity3.125429391860962
INFO:root:current mean train loss 1446.7728942603562
INFO:root:current train perplexity3.1268670558929443
INFO:root:current mean train loss 1446.4982229670006
INFO:root:current train perplexity3.1284751892089844
INFO:root:current mean train loss 1447.4639258790694
INFO:root:current train perplexity3.130894660949707
INFO:root:current mean train loss 1447.6536014538788
INFO:root:current train perplexity3.1309595108032227

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.92s/it]
INFO:root:final mean train loss: 1447.4825584115372
INFO:root:final train perplexity: 3.1316871643066406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it]
INFO:root:eval mean loss: 2117.9217576912956
INFO:root:eval perplexity: 5.544745922088623
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.88s/it]
INFO:root:eval mean loss: 2648.3141340972684
INFO:root:eval perplexity: 8.722132682800293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/95
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 95/200 [16:43:06<18:25:55, 631.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1458.06596156529
INFO:root:current train perplexity3.1021690368652344
INFO:root:current mean train loss 1429.9821691680372
INFO:root:current train perplexity3.1076674461364746
INFO:root:current mean train loss 1436.4473380685968
INFO:root:current train perplexity3.098001003265381
INFO:root:current mean train loss 1436.8545271758062
INFO:root:current train perplexity3.104607343673706
INFO:root:current mean train loss 1437.4575867583785
INFO:root:current train perplexity3.1008613109588623
INFO:root:current mean train loss 1437.9863665985226
INFO:root:current train perplexity3.102501392364502
INFO:root:current mean train loss 1436.7777761651948
INFO:root:current train perplexity3.1035959720611572
INFO:root:current mean train loss 1437.2170946992078
INFO:root:current train perplexity3.1042513847351074
INFO:root:current mean train loss 1438.9520373145251
INFO:root:current train perplexity3.1077351570129395
INFO:root:current mean train loss 1439.517407039584
INFO:root:current train perplexity3.1093251705169678
INFO:root:current mean train loss 1439.506585416474
INFO:root:current train perplexity3.1110904216766357
INFO:root:current mean train loss 1440.490368827669
INFO:root:current train perplexity3.1111016273498535
INFO:root:current mean train loss 1440.8441957476898
INFO:root:current train perplexity3.1133317947387695
INFO:root:current mean train loss 1441.6446412433409
INFO:root:current train perplexity3.115645408630371
INFO:root:current mean train loss 1442.6789785598257
INFO:root:current train perplexity3.1157376766204834
INFO:root:current mean train loss 1442.7967429318549
INFO:root:current train perplexity3.1175057888031006
INFO:root:current mean train loss 1443.014837215381
INFO:root:current train perplexity3.118849039077759
INFO:root:current mean train loss 1443.0726697959587
INFO:root:current train perplexity3.120168924331665
INFO:root:current mean train loss 1443.5267160367282
INFO:root:current train perplexity3.1211018562316895
INFO:root:current mean train loss 1444.146179326774
INFO:root:current train perplexity3.1225409507751465

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.47s/it]
INFO:root:final mean train loss: 1443.9177123592528
INFO:root:final train perplexity: 3.122894525527954
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.93s/it]
INFO:root:eval mean loss: 2119.9773490310563
INFO:root:eval perplexity: 5.553971767425537
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it]
INFO:root:eval mean loss: 2654.126730195174
INFO:root:eval perplexity: 8.763694763183594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/96
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 96/200 [16:53:37<18:14:58, 631.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1426.9212843371977
INFO:root:current train perplexity3.0457396507263184
INFO:root:current mean train loss 1428.7620952111165
INFO:root:current train perplexity3.0737664699554443
INFO:root:current mean train loss 1433.2696739295861
INFO:root:current train perplexity3.0857532024383545
INFO:root:current mean train loss 1432.9438487626276
INFO:root:current train perplexity3.0878117084503174
INFO:root:current mean train loss 1432.0448901537122
INFO:root:current train perplexity3.0806798934936523
INFO:root:current mean train loss 1431.2990727254003
INFO:root:current train perplexity3.085791826248169
INFO:root:current mean train loss 1433.5020823531597
INFO:root:current train perplexity3.0907580852508545
INFO:root:current mean train loss 1435.7180459665697
INFO:root:current train perplexity3.0930113792419434
INFO:root:current mean train loss 1435.7711424018503
INFO:root:current train perplexity3.0937647819519043
INFO:root:current mean train loss 1435.8261505028615
INFO:root:current train perplexity3.0974504947662354
INFO:root:current mean train loss 1436.7406256867196
INFO:root:current train perplexity3.0991601943969727
INFO:root:current mean train loss 1437.1415441430427
INFO:root:current train perplexity3.101841688156128
INFO:root:current mean train loss 1437.1729367439773
INFO:root:current train perplexity3.1040267944335938
INFO:root:current mean train loss 1437.0603057609117
INFO:root:current train perplexity3.105374336242676
INFO:root:current mean train loss 1437.7482713956585
INFO:root:current train perplexity3.1067323684692383
INFO:root:current mean train loss 1437.8413917546486
INFO:root:current train perplexity3.1073734760284424
INFO:root:current mean train loss 1438.7810876636984
INFO:root:current train perplexity3.1086668968200684
INFO:root:current mean train loss 1439.7966522269687
INFO:root:current train perplexity3.110197067260742
INFO:root:current mean train loss 1439.9811213028229
INFO:root:current train perplexity3.1116137504577637
INFO:root:current mean train loss 1440.2646998954153
INFO:root:current train perplexity3.1134140491485596

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.41s/it]
INFO:root:final mean train loss: 1440.4139287951493
INFO:root:final train perplexity: 3.1142771244049072
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.21s/it]
INFO:root:eval mean loss: 2122.229347607768
INFO:root:eval perplexity: 5.564096450805664
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.81s/it]
INFO:root:eval mean loss: 2655.739422737284
INFO:root:eval perplexity: 8.775260925292969
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/97
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 97/200 [17:04:22<18:11:07, 635.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1440.7425333658855
INFO:root:current train perplexity3.0870978832244873
INFO:root:current mean train loss 1434.8659700960727
INFO:root:current train perplexity3.077605724334717
INFO:root:current mean train loss 1435.362996747417
INFO:root:current train perplexity3.0913639068603516
INFO:root:current mean train loss 1432.5153117563532
INFO:root:current train perplexity3.0958151817321777
INFO:root:current mean train loss 1431.5711391993932
INFO:root:current train perplexity3.095736265182495
INFO:root:current mean train loss 1432.21301002224
INFO:root:current train perplexity3.0933468341827393
INFO:root:current mean train loss 1431.0767362618153
INFO:root:current train perplexity3.094731569290161
INFO:root:current mean train loss 1431.4166582892922
INFO:root:current train perplexity3.095707416534424
INFO:root:current mean train loss 1432.86760726065
INFO:root:current train perplexity3.09538197517395
INFO:root:current mean train loss 1432.7032430785619
INFO:root:current train perplexity3.093801975250244
INFO:root:current mean train loss 1433.027262214486
INFO:root:current train perplexity3.0953423976898193
INFO:root:current mean train loss 1434.1369263120644
INFO:root:current train perplexity3.0980303287506104
INFO:root:current mean train loss 1434.6887272565793
INFO:root:current train perplexity3.0981664657592773
INFO:root:current mean train loss 1435.3300047741445
INFO:root:current train perplexity3.098478317260742
INFO:root:current mean train loss 1434.9841071703158
INFO:root:current train perplexity3.1001482009887695
INFO:root:current mean train loss 1434.7190002914547
INFO:root:current train perplexity3.101160764694214
INFO:root:current mean train loss 1434.9905642166877
INFO:root:current train perplexity3.1024508476257324
INFO:root:current mean train loss 1435.7397292636897
INFO:root:current train perplexity3.1027581691741943
INFO:root:current mean train loss 1436.3445264147474
INFO:root:current train perplexity3.1035594940185547
INFO:root:current mean train loss 1437.090758901357
INFO:root:current train perplexity3.1042771339416504

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:13<00:00, 553.09s/it]
INFO:root:final mean train loss: 1436.534423520333
INFO:root:final train perplexity: 3.1047630310058594
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it]
INFO:root:eval mean loss: 2123.9862670898438
INFO:root:eval perplexity: 5.572007656097412
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.83s/it]
INFO:root:eval mean loss: 2656.8626661368294
INFO:root:eval perplexity: 8.783326148986816
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/98
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [17:14:49<17:56:26, 633.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1402.2344388521635
INFO:root:current train perplexity3.042792797088623
INFO:root:current mean train loss 1416.2354802911932
INFO:root:current train perplexity3.0487325191497803
INFO:root:current mean train loss 1418.1015164357311
INFO:root:current train perplexity3.054255247116089
INFO:root:current mean train loss 1419.620082405822
INFO:root:current train perplexity3.055413007736206
INFO:root:current mean train loss 1422.5181659001175
INFO:root:current train perplexity3.064779043197632
INFO:root:current mean train loss 1421.8730298067617
INFO:root:current train perplexity3.071026563644409
INFO:root:current mean train loss 1422.535718507695
INFO:root:current train perplexity3.0740513801574707
INFO:root:current mean train loss 1423.0118360332415
INFO:root:current train perplexity3.0751545429229736
INFO:root:current mean train loss 1424.8076760352692
INFO:root:current train perplexity3.0788567066192627
INFO:root:current mean train loss 1426.2175742035702
INFO:root:current train perplexity3.0819005966186523
INFO:root:current mean train loss 1427.1645435601893
INFO:root:current train perplexity3.0822503566741943
INFO:root:current mean train loss 1427.8370066892435
INFO:root:current train perplexity3.084200143814087
INFO:root:current mean train loss 1428.4254687885993
INFO:root:current train perplexity3.085947036743164
INFO:root:current mean train loss 1428.492591092176
INFO:root:current train perplexity3.087757110595703
INFO:root:current mean train loss 1429.6339285476215
INFO:root:current train perplexity3.0887224674224854
INFO:root:current mean train loss 1430.2089992730382
INFO:root:current train perplexity3.0911645889282227
INFO:root:current mean train loss 1431.5799235759196
INFO:root:current train perplexity3.0928597450256348
INFO:root:current mean train loss 1432.2378712597379
INFO:root:current train perplexity3.094710350036621
INFO:root:current mean train loss 1432.451529380655
INFO:root:current train perplexity3.0947673320770264
INFO:root:current mean train loss 1432.713083825342
INFO:root:current train perplexity3.0945956707000732

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.68s/it]
INFO:root:final mean train loss: 1432.4067027004933
INFO:root:final train perplexity: 3.0946719646453857
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.31s/it]
INFO:root:eval mean loss: 2128.665122607076
INFO:root:eval perplexity: 5.593132019042969
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.93s/it]
INFO:root:eval mean loss: 2662.906496737866
INFO:root:eval perplexity: 8.8268461227417
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/99
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 99/200 [17:25:29<17:49:26, 635.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1413.1703297684833
INFO:root:current train perplexity3.0650620460510254
INFO:root:current mean train loss 1415.1225002414578
INFO:root:current train perplexity3.0685086250305176
INFO:root:current mean train loss 1419.3186004855108
INFO:root:current train perplexity3.0641262531280518
INFO:root:current mean train loss 1421.7414563563482
INFO:root:current train perplexity3.063258409500122
INFO:root:current mean train loss 1422.4494226226172
INFO:root:current train perplexity3.0686752796173096
INFO:root:current mean train loss 1421.2967806157378
INFO:root:current train perplexity3.067304849624634
INFO:root:current mean train loss 1421.032870205966
INFO:root:current train perplexity3.069838523864746
INFO:root:current mean train loss 1420.6365793525715
INFO:root:current train perplexity3.069486379623413
INFO:root:current mean train loss 1422.5415992650314
INFO:root:current train perplexity3.071756601333618
INFO:root:current mean train loss 1423.7107823637984
INFO:root:current train perplexity3.071145534515381
INFO:root:current mean train loss 1424.1030341128985
INFO:root:current train perplexity3.0729784965515137
INFO:root:current mean train loss 1424.3052652168597
INFO:root:current train perplexity3.0717811584472656
INFO:root:current mean train loss 1425.2065066904433
INFO:root:current train perplexity3.0732531547546387
INFO:root:current mean train loss 1425.9468027824257
INFO:root:current train perplexity3.0751845836639404
INFO:root:current mean train loss 1426.832114689424
INFO:root:current train perplexity3.0780224800109863
INFO:root:current mean train loss 1427.1798378887731
INFO:root:current train perplexity3.0799028873443604
INFO:root:current mean train loss 1428.172572150667
INFO:root:current train perplexity3.081664562225342
INFO:root:current mean train loss 1428.4291795587164
INFO:root:current train perplexity3.082404136657715
INFO:root:current mean train loss 1428.707236732864
INFO:root:current train perplexity3.0848841667175293
INFO:root:current mean train loss 1429.2819202781084
INFO:root:current train perplexity3.0859715938568115

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.30s/it]
INFO:root:final mean train loss: 1428.8271241219309
INFO:root:final train perplexity: 3.0859484672546387
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.76s/it]
INFO:root:eval mean loss: 2132.069566659048
INFO:root:eval perplexity: 5.608552932739258
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it]
INFO:root:eval mean loss: 2666.854657978031
INFO:root:eval perplexity: 8.855395317077637
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/100
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [17:36:07<17:39:45, 635.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1410.4920074771148
INFO:root:current train perplexity3.0545074939727783
INFO:root:current mean train loss 1420.5824870200613
INFO:root:current train perplexity3.0600242614746094
INFO:root:current mean train loss 1418.906556604698
INFO:root:current train perplexity3.056777000427246
INFO:root:current mean train loss 1418.6932565789473
INFO:root:current train perplexity3.0602078437805176
INFO:root:current mean train loss 1420.1507059529215
INFO:root:current train perplexity3.0576670169830322
INFO:root:current mean train loss 1419.2459482438178
INFO:root:current train perplexity3.060495376586914
INFO:root:current mean train loss 1419.1334621445815
INFO:root:current train perplexity3.0636274814605713
INFO:root:current mean train loss 1419.2204783872908
INFO:root:current train perplexity3.0628819465637207
INFO:root:current mean train loss 1420.1266481528955
INFO:root:current train perplexity3.066835403442383
INFO:root:current mean train loss 1420.4193858164806
INFO:root:current train perplexity3.0673258304595947
INFO:root:current mean train loss 1421.5772971655695
INFO:root:current train perplexity3.070993185043335
INFO:root:current mean train loss 1423.4701018345365
INFO:root:current train perplexity3.073296546936035
INFO:root:current mean train loss 1422.760804961148
INFO:root:current train perplexity3.0727591514587402
INFO:root:current mean train loss 1422.9144914475742
INFO:root:current train perplexity3.073801040649414
INFO:root:current mean train loss 1424.1300640856925
INFO:root:current train perplexity3.075188636779785
INFO:root:current mean train loss 1424.9585764815167
INFO:root:current train perplexity3.075329065322876
INFO:root:current mean train loss 1425.3609436645868
INFO:root:current train perplexity3.0764362812042236
INFO:root:current mean train loss 1425.6096448574947
INFO:root:current train perplexity3.076611280441284
INFO:root:current mean train loss 1426.1225879060526
INFO:root:current train perplexity3.077353000640869

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.09s/it]
INFO:root:final mean train loss: 1426.0126544685
INFO:root:final train perplexity: 3.079106330871582
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.74s/it]
INFO:root:eval mean loss: 2132.8183862131536
INFO:root:eval perplexity: 5.611949920654297
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.34s/it]
INFO:root:eval mean loss: 2667.5509206352503
INFO:root:eval perplexity: 8.860441207885742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/101
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 101/200 [17:46:47<17:31:26, 637.24s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1403.3984985351562
INFO:root:current train perplexity3.065290927886963
INFO:root:current mean train loss 1415.0958020440464
INFO:root:current train perplexity3.0417144298553467
INFO:root:current mean train loss 1419.0066562228733
INFO:root:current train perplexity3.0439887046813965
INFO:root:current mean train loss 1416.2900780786442
INFO:root:current train perplexity3.0461180210113525
INFO:root:current mean train loss 1414.095605116624
INFO:root:current train perplexity3.050121307373047
INFO:root:current mean train loss 1413.8888940145803
INFO:root:current train perplexity3.051085948944092
INFO:root:current mean train loss 1413.6447333794135
INFO:root:current train perplexity3.0480504035949707
INFO:root:current mean train loss 1412.1191842702515
INFO:root:current train perplexity3.0486602783203125
INFO:root:current mean train loss 1413.1687189737956
INFO:root:current train perplexity3.0506060123443604
INFO:root:current mean train loss 1414.2022058745138
INFO:root:current train perplexity3.052736520767212
INFO:root:current mean train loss 1414.5975893275945
INFO:root:current train perplexity3.054637908935547
INFO:root:current mean train loss 1416.6650131389658
INFO:root:current train perplexity3.0578408241271973
INFO:root:current mean train loss 1416.73406450372
INFO:root:current train perplexity3.05838680267334
INFO:root:current mean train loss 1417.5011413945253
INFO:root:current train perplexity3.059311628341675
INFO:root:current mean train loss 1418.7310938431044
INFO:root:current train perplexity3.062051296234131
INFO:root:current mean train loss 1419.554120307862
INFO:root:current train perplexity3.064889669418335
INFO:root:current mean train loss 1420.0969195979656
INFO:root:current train perplexity3.066091299057007
INFO:root:current mean train loss 1420.957610372619
INFO:root:current train perplexity3.067810297012329
INFO:root:current mean train loss 1421.6910032700862
INFO:root:current train perplexity3.0690484046936035
INFO:root:current mean train loss 1421.9134146226472
INFO:root:current train perplexity3.0691564083099365

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.73s/it]
INFO:root:final mean train loss: 1422.1656274377128
INFO:root:final train perplexity: 3.0697784423828125
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.23s/it]
INFO:root:eval mean loss: 2136.253391996343
INFO:root:eval perplexity: 5.627562522888184
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 2674.1647170046544
INFO:root:eval perplexity: 8.908496856689453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/102
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 102/200 [17:57:14<17:15:42, 634.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1412.6785629734848
INFO:root:current train perplexity3.035766839981079
INFO:root:current mean train loss 1414.1195490557448
INFO:root:current train perplexity3.0620105266571045
INFO:root:current mean train loss 1410.4801952705875
INFO:root:current train perplexity3.048116683959961
INFO:root:current mean train loss 1411.8496771918403
INFO:root:current train perplexity3.0466971397399902
INFO:root:current mean train loss 1413.9768244014326
INFO:root:current train perplexity3.046809434890747
INFO:root:current mean train loss 1412.6169099217284
INFO:root:current train perplexity3.045426368713379
INFO:root:current mean train loss 1411.4216755992052
INFO:root:current train perplexity3.0461130142211914
INFO:root:current mean train loss 1413.3980727878795
INFO:root:current train perplexity3.047785997390747
INFO:root:current mean train loss 1413.2608603011518
INFO:root:current train perplexity3.0485904216766357
INFO:root:current mean train loss 1415.1438773299337
INFO:root:current train perplexity3.0492544174194336
INFO:root:current mean train loss 1415.3626901602584
INFO:root:current train perplexity3.049696207046509
INFO:root:current mean train loss 1415.5308924083256
INFO:root:current train perplexity3.0515687465667725
INFO:root:current mean train loss 1415.7221928184242
INFO:root:current train perplexity3.0518152713775635
INFO:root:current mean train loss 1416.4192316694896
INFO:root:current train perplexity3.0530824661254883
INFO:root:current mean train loss 1416.992597581287
INFO:root:current train perplexity3.0548040866851807
INFO:root:current mean train loss 1417.4790397390227
INFO:root:current train perplexity3.0568907260894775
INFO:root:current mean train loss 1417.5161001996182
INFO:root:current train perplexity3.057189702987671
INFO:root:current mean train loss 1417.3729896083155
INFO:root:current train perplexity3.0570971965789795
INFO:root:current mean train loss 1418.447429717335
INFO:root:current train perplexity3.059166193008423
INFO:root:current mean train loss 1418.509797074051
INFO:root:current train perplexity3.059858798980713

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.41s/it]
INFO:root:final mean train loss: 1418.2511672704316
INFO:root:final train perplexity: 3.0603158473968506
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.30s/it]
INFO:root:eval mean loss: 2138.8002375609485
INFO:root:eval perplexity: 5.63916540145874
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.91s/it]
INFO:root:eval mean loss: 2677.218250031167
INFO:root:eval perplexity: 8.930770874023438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/103
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 103/200 [18:07:53<17:07:27, 635.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1415.3775390625
INFO:root:current train perplexity3.0200183391571045
INFO:root:current mean train loss 1403.584004720052
INFO:root:current train perplexity3.0259127616882324
INFO:root:current mean train loss 1407.8328427734375
INFO:root:current train perplexity3.027966260910034
INFO:root:current mean train loss 1407.0716053989956
INFO:root:current train perplexity3.0270817279815674
INFO:root:current mean train loss 1406.1071546766493
INFO:root:current train perplexity3.029379367828369
INFO:root:current mean train loss 1408.6116099964488
INFO:root:current train perplexity3.0350136756896973
INFO:root:current mean train loss 1409.3542933067909
INFO:root:current train perplexity3.0390560626983643
INFO:root:current mean train loss 1410.9170408528646
INFO:root:current train perplexity3.039139747619629
INFO:root:current mean train loss 1411.5413209443934
INFO:root:current train perplexity3.0390677452087402
INFO:root:current mean train loss 1413.1183795487252
INFO:root:current train perplexity3.042452573776245
INFO:root:current mean train loss 1413.2551862444197
INFO:root:current train perplexity3.044804096221924
INFO:root:current mean train loss 1412.9900167713995
INFO:root:current train perplexity3.0444421768188477
INFO:root:current mean train loss 1413.2700778320313
INFO:root:current train perplexity3.044492721557617
INFO:root:current mean train loss 1413.465810546875
INFO:root:current train perplexity3.046247720718384
INFO:root:current mean train loss 1413.5696273908943
INFO:root:current train perplexity3.0468127727508545
INFO:root:current mean train loss 1413.989699392011
INFO:root:current train perplexity3.048999071121216
INFO:root:current mean train loss 1414.8259700520832
INFO:root:current train perplexity3.0499608516693115
INFO:root:current mean train loss 1415.3336990792411
INFO:root:current train perplexity3.0508220195770264
INFO:root:current mean train loss 1415.2455962969805
INFO:root:current train perplexity3.051551103591919
INFO:root:current mean train loss 1415.3511608573717
INFO:root:current train perplexity3.052069902420044

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.86s/it]
INFO:root:final mean train loss: 1415.0685521759171
INFO:root:final train perplexity: 3.0526442527770996
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.94s/it]
INFO:root:eval mean loss: 2142.3948165136026
INFO:root:eval perplexity: 5.655583381652832
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.54s/it]
INFO:root:eval mean loss: 2682.477895317348
INFO:root:eval perplexity: 8.969267845153809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/104
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [18:18:40<17:02:41, 639.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1415.8527959567398
INFO:root:current train perplexity2.996769666671753
INFO:root:current mean train loss 1404.6376828861808
INFO:root:current train perplexity3.0107338428497314
INFO:root:current mean train loss 1404.0032117750761
INFO:root:current train perplexity3.012028932571411
INFO:root:current mean train loss 1403.9053851966962
INFO:root:current train perplexity3.0168838500976562
INFO:root:current mean train loss 1402.87103284554
INFO:root:current train perplexity3.014791488647461
INFO:root:current mean train loss 1402.9667729776372
INFO:root:current train perplexity3.0166521072387695
INFO:root:current mean train loss 1403.6315599524457
INFO:root:current train perplexity3.018933057785034
INFO:root:current mean train loss 1405.1091033259147
INFO:root:current train perplexity3.0218443870544434
INFO:root:current mean train loss 1405.2531790375847
INFO:root:current train perplexity3.025355100631714
INFO:root:current mean train loss 1405.5766385698762
INFO:root:current train perplexity3.027522325515747
INFO:root:current mean train loss 1405.633681178428
INFO:root:current train perplexity3.031292200088501
INFO:root:current mean train loss 1407.1936862556568
INFO:root:current train perplexity3.034205913543701
INFO:root:current mean train loss 1407.2889313731687
INFO:root:current train perplexity3.0351221561431885
INFO:root:current mean train loss 1408.3108829032267
INFO:root:current train perplexity3.0366628170013428
INFO:root:current mean train loss 1407.9166701615222
INFO:root:current train perplexity3.0381429195404053
INFO:root:current mean train loss 1408.339956004831
INFO:root:current train perplexity3.0393011569976807
INFO:root:current mean train loss 1409.1502878867586
INFO:root:current train perplexity3.0404672622680664
INFO:root:current mean train loss 1410.2281885152493
INFO:root:current train perplexity3.0423543453216553
INFO:root:current mean train loss 1410.9199105637176
INFO:root:current train perplexity3.0432164669036865
INFO:root:current mean train loss 1411.6872768974208
INFO:root:current train perplexity3.043440818786621

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.03s/it]
INFO:root:final mean train loss: 1411.43311433316
INFO:root:final train perplexity: 3.0439045429229736
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.21s/it]
INFO:root:eval mean loss: 2146.142076424673
INFO:root:eval perplexity: 5.6727495193481445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it]
INFO:root:eval mean loss: 2686.173993049784
INFO:root:eval perplexity: 8.996419906616211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/105
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 105/200 [18:29:23<16:53:35, 640.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1390.554920014881
INFO:root:current train perplexity2.9878244400024414
INFO:root:current mean train loss 1393.0767994756284
INFO:root:current train perplexity2.998321771621704
INFO:root:current mean train loss 1395.1627682967924
INFO:root:current train perplexity3.0069739818573
INFO:root:current mean train loss 1395.1728658676147
INFO:root:current train perplexity3.0065581798553467
INFO:root:current mean train loss 1397.2560376884524
INFO:root:current train perplexity3.010563611984253
INFO:root:current mean train loss 1401.5274530698175
INFO:root:current train perplexity3.0162909030914307
INFO:root:current mean train loss 1402.821928146987
INFO:root:current train perplexity3.017336368560791
INFO:root:current mean train loss 1402.8148263425244
INFO:root:current train perplexity3.017948865890503
INFO:root:current mean train loss 1402.245475527388
INFO:root:current train perplexity3.0204484462738037
INFO:root:current mean train loss 1402.0608654487423
INFO:root:current train perplexity3.0215678215026855
INFO:root:current mean train loss 1402.9278544183146
INFO:root:current train perplexity3.0227768421173096
INFO:root:current mean train loss 1404.2726258973817
INFO:root:current train perplexity3.02392578125
INFO:root:current mean train loss 1404.4902918925538
INFO:root:current train perplexity3.0260725021362305
INFO:root:current mean train loss 1405.3232198726234
INFO:root:current train perplexity3.0283586978912354
INFO:root:current mean train loss 1406.0904842901102
INFO:root:current train perplexity3.0298726558685303
INFO:root:current mean train loss 1406.4008896952928
INFO:root:current train perplexity3.030447006225586
INFO:root:current mean train loss 1406.355726445939
INFO:root:current train perplexity3.0312535762786865
INFO:root:current mean train loss 1407.1693973968916
INFO:root:current train perplexity3.034097671508789
INFO:root:current mean train loss 1407.868191664386
INFO:root:current train perplexity3.0352184772491455

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.66s/it]
INFO:root:final mean train loss: 1408.0914369737989
INFO:root:final train perplexity: 3.035893201828003
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.35s/it]
INFO:root:eval mean loss: 2148.212559043938
INFO:root:eval perplexity: 5.682255744934082
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.68s/it]
INFO:root:eval mean loss: 2688.9574091485206
INFO:root:eval perplexity: 9.016924858093262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/106
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 106/200 [18:40:12<16:47:04, 642.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1349.820556640625
INFO:root:current train perplexity2.9937405586242676
INFO:root:current mean train loss 1392.6130189801206
INFO:root:current train perplexity3.005851984024048
INFO:root:current mean train loss 1397.2757197897233
INFO:root:current train perplexity3.0118870735168457
INFO:root:current mean train loss 1399.1922108596345
INFO:root:current train perplexity3.0126569271087646
INFO:root:current mean train loss 1397.3756267899587
INFO:root:current train perplexity3.0122599601745605
INFO:root:current mean train loss 1396.3802824039421
INFO:root:current train perplexity3.009561538696289
INFO:root:current mean train loss 1397.6375801479955
INFO:root:current train perplexity3.0093905925750732
INFO:root:current mean train loss 1399.1441664321617
INFO:root:current train perplexity3.014996290206909
INFO:root:current mean train loss 1400.3320518236483
INFO:root:current train perplexity3.01644229888916
INFO:root:current mean train loss 1400.1782420303396
INFO:root:current train perplexity3.017472267150879
INFO:root:current mean train loss 1399.9821349304991
INFO:root:current train perplexity3.0178658962249756
INFO:root:current mean train loss 1399.6924297114483
INFO:root:current train perplexity3.0194437503814697
INFO:root:current mean train loss 1400.1584582428054
INFO:root:current train perplexity3.0211517810821533
INFO:root:current mean train loss 1401.1063466053756
INFO:root:current train perplexity3.0221595764160156
INFO:root:current mean train loss 1400.979035796139
INFO:root:current train perplexity3.02292537689209
INFO:root:current mean train loss 1401.4722344934107
INFO:root:current train perplexity3.0237226486206055
INFO:root:current mean train loss 1402.4881770213196
INFO:root:current train perplexity3.024592399597168
INFO:root:current mean train loss 1403.0575701821767
INFO:root:current train perplexity3.0248401165008545
INFO:root:current mean train loss 1404.38195238214
INFO:root:current train perplexity3.0267865657806396
INFO:root:current mean train loss 1404.7861398117973
INFO:root:current train perplexity3.027716875076294

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.89s/it]
INFO:root:final mean train loss: 1404.9099762532305
INFO:root:final train perplexity: 3.028285026550293
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.15s/it]
INFO:root:eval mean loss: 2148.6438910301695
INFO:root:eval perplexity: 5.684237480163574
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.59s/it]
INFO:root:eval mean loss: 2691.3346739424037
INFO:root:eval perplexity: 9.03447151184082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/107
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 107/200 [18:50:47<16:32:42, 640.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1404.3881089952256
INFO:root:current train perplexity3.0042946338653564
INFO:root:current mean train loss 1394.8864725403866
INFO:root:current train perplexity3.002450704574585
INFO:root:current mean train loss 1395.6793599259963
INFO:root:current train perplexity3.002903938293457
INFO:root:current mean train loss 1394.603652282331
INFO:root:current train perplexity2.999595880508423
INFO:root:current mean train loss 1395.7164435135692
INFO:root:current train perplexity3.0000133514404297
INFO:root:current mean train loss 1394.6353064577552
INFO:root:current train perplexity3.004887819290161
INFO:root:current mean train loss 1394.6939527394316
INFO:root:current train perplexity3.005324125289917
INFO:root:current mean train loss 1395.0767839267062
INFO:root:current train perplexity3.0074799060821533
INFO:root:current mean train loss 1395.4290093979218
INFO:root:current train perplexity3.008089780807495
INFO:root:current mean train loss 1397.5128059470317
INFO:root:current train perplexity3.0097906589508057
INFO:root:current mean train loss 1398.017914118139
INFO:root:current train perplexity3.0108869075775146
INFO:root:current mean train loss 1397.8434821659423
INFO:root:current train perplexity3.0118753910064697
INFO:root:current mean train loss 1397.4627390894398
INFO:root:current train perplexity3.011265277862549
INFO:root:current mean train loss 1398.5658555443263
INFO:root:current train perplexity3.0137479305267334
INFO:root:current mean train loss 1399.7591903966304
INFO:root:current train perplexity3.016204833984375
INFO:root:current mean train loss 1400.168003328547
INFO:root:current train perplexity3.016697883605957
INFO:root:current mean train loss 1401.109134480744
INFO:root:current train perplexity3.0171315670013428
INFO:root:current mean train loss 1401.3444944299558
INFO:root:current train perplexity3.0183961391448975
INFO:root:current mean train loss 1402.0235892485732
INFO:root:current train perplexity3.0188450813293457
INFO:root:current mean train loss 1401.9679968936352
INFO:root:current train perplexity3.0194058418273926

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.39s/it]
INFO:root:final mean train loss: 1401.7104888931406
INFO:root:final train perplexity: 3.020653486251831
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.37s/it]
INFO:root:eval mean loss: 2152.1989425767397
INFO:root:eval perplexity: 5.700604438781738
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.04s/it]
INFO:root:eval mean loss: 2697.4216247991467
INFO:root:eval perplexity: 9.079556465148926
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/108
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 108/200 [19:01:29<16:22:48, 640.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1390.8298758370536
INFO:root:current train perplexity3.01593017578125
INFO:root:current mean train loss 1379.0091887297453
INFO:root:current train perplexity3.007883310317993
INFO:root:current mean train loss 1383.980600689827
INFO:root:current train perplexity2.992689371109009
INFO:root:current mean train loss 1385.3320760698462
INFO:root:current train perplexity2.9888973236083984
INFO:root:current mean train loss 1385.9052501459232
INFO:root:current train perplexity2.991748332977295
INFO:root:current mean train loss 1388.6812515971817
INFO:root:current train perplexity2.9937469959259033
INFO:root:current mean train loss 1389.7307532603347
INFO:root:current train perplexity2.993488311767578
INFO:root:current mean train loss 1391.1787762077488
INFO:root:current train perplexity2.996452808380127
INFO:root:current mean train loss 1390.713719679781
INFO:root:current train perplexity3.0009067058563232
INFO:root:current mean train loss 1392.1713952049215
INFO:root:current train perplexity3.000685691833496
INFO:root:current mean train loss 1393.2376915383454
INFO:root:current train perplexity3.003861427307129
INFO:root:current mean train loss 1394.0752758681513
INFO:root:current train perplexity3.0048744678497314
INFO:root:current mean train loss 1394.4195093069964
INFO:root:current train perplexity3.006416082382202
INFO:root:current mean train loss 1395.3645440148057
INFO:root:current train perplexity3.0069448947906494
INFO:root:current mean train loss 1395.6859809689406
INFO:root:current train perplexity3.008162498474121
INFO:root:current mean train loss 1396.0462904144188
INFO:root:current train perplexity3.0082333087921143
INFO:root:current mean train loss 1396.3191182267776
INFO:root:current train perplexity3.0089290142059326
INFO:root:current mean train loss 1396.6945929535527
INFO:root:current train perplexity3.009690523147583
INFO:root:current mean train loss 1397.3165677021245
INFO:root:current train perplexity3.010425090789795
INFO:root:current mean train loss 1398.7043533995477
INFO:root:current train perplexity3.012458324432373

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.01s/it]
INFO:root:final mean train loss: 1398.445191137609
INFO:root:final train perplexity: 3.0128846168518066
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.80s/it]
INFO:root:eval mean loss: 2155.8786967392507
INFO:root:eval perplexity: 5.717594623565674
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.14s/it]
INFO:root:eval mean loss: 2702.4458951476618
INFO:root:eval perplexity: 9.116942405700684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/109
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 109/200 [19:12:09<16:11:46, 640.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1386.0994779146636
INFO:root:current train perplexity3.0009782314300537
INFO:root:current mean train loss 1393.3122582686574
INFO:root:current train perplexity2.9968693256378174
INFO:root:current mean train loss 1395.0778038388207
INFO:root:current train perplexity2.9930429458618164
INFO:root:current mean train loss 1392.305744864724
INFO:root:current train perplexity2.9974586963653564
INFO:root:current mean train loss 1392.1710637185427
INFO:root:current train perplexity3.000617742538452
INFO:root:current mean train loss 1393.3718082593834
INFO:root:current train perplexity2.9960973262786865
INFO:root:current mean train loss 1394.0507003690568
INFO:root:current train perplexity2.9966137409210205
INFO:root:current mean train loss 1396.0754655878595
INFO:root:current train perplexity2.9969985485076904
INFO:root:current mean train loss 1395.8065999348958
INFO:root:current train perplexity2.997774600982666
INFO:root:current mean train loss 1395.395862611402
INFO:root:current train perplexity2.9991941452026367
INFO:root:current mean train loss 1394.7471120856108
INFO:root:current train perplexity2.999852418899536
INFO:root:current mean train loss 1394.4861244625515
INFO:root:current train perplexity2.99818754196167
INFO:root:current mean train loss 1394.7979492577501
INFO:root:current train perplexity2.9987170696258545
INFO:root:current mean train loss 1394.8018447605111
INFO:root:current train perplexity3.0005486011505127
INFO:root:current mean train loss 1395.5959540753324
INFO:root:current train perplexity3.001941442489624
INFO:root:current mean train loss 1395.7920684027918
INFO:root:current train perplexity3.003338575363159
INFO:root:current mean train loss 1395.5598927791125
INFO:root:current train perplexity3.004136323928833
INFO:root:current mean train loss 1395.6921117773884
INFO:root:current train perplexity3.0058486461639404
INFO:root:current mean train loss 1395.8026853359543
INFO:root:current train perplexity3.0064918994903564
INFO:root:current mean train loss 1396.3600211221665
INFO:root:current train perplexity3.0072009563446045

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.07s/it]
INFO:root:final mean train loss: 1395.8928840087028
INFO:root:final train perplexity: 3.006826400756836
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.96s/it]
INFO:root:eval mean loss: 2159.5031279435393
INFO:root:eval perplexity: 5.734377861022949
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.71s/it]
INFO:root:eval mean loss: 2703.029792082225
INFO:root:eval perplexity: 9.121297836303711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/110
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [19:22:42<15:57:39, 638.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1382.575980808424
INFO:root:current train perplexity2.970423698425293
INFO:root:current mean train loss 1377.8654814048632
INFO:root:current train perplexity2.967970132827759
INFO:root:current mean train loss 1378.385906914353
INFO:root:current train perplexity2.9707388877868652
INFO:root:current mean train loss 1382.8799450055049
INFO:root:current train perplexity2.9709503650665283
INFO:root:current mean train loss 1383.6537849084655
INFO:root:current train perplexity2.971679449081421
INFO:root:current mean train loss 1384.9043578028889
INFO:root:current train perplexity2.973688840866089
INFO:root:current mean train loss 1386.327251166328
INFO:root:current train perplexity2.975792407989502
INFO:root:current mean train loss 1387.0523783233602
INFO:root:current train perplexity2.9796907901763916
INFO:root:current mean train loss 1387.09909903962
INFO:root:current train perplexity2.9836339950561523
INFO:root:current mean train loss 1388.8011470830108
INFO:root:current train perplexity2.9854578971862793
INFO:root:current mean train loss 1388.1433210524585
INFO:root:current train perplexity2.9868924617767334
INFO:root:current mean train loss 1388.042685450806
INFO:root:current train perplexity2.98905348777771
INFO:root:current mean train loss 1388.5914701998374
INFO:root:current train perplexity2.9880003929138184
INFO:root:current mean train loss 1388.297377102213
INFO:root:current train perplexity2.98970627784729
INFO:root:current mean train loss 1389.8166653481853
INFO:root:current train perplexity2.991140365600586
INFO:root:current mean train loss 1390.1710899066136
INFO:root:current train perplexity2.991684675216675
INFO:root:current mean train loss 1390.6258660482747
INFO:root:current train perplexity2.9927515983581543
INFO:root:current mean train loss 1391.5544840724808
INFO:root:current train perplexity2.9945003986358643
INFO:root:current mean train loss 1391.422586521661
INFO:root:current train perplexity2.995252847671509
INFO:root:current mean train loss 1391.6009929418685
INFO:root:current train perplexity2.995778799057007

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.52s/it]
INFO:root:final mean train loss: 1391.4613648384313
INFO:root:final train perplexity: 2.996335983276367
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.42s/it]
INFO:root:eval mean loss: 2161.687391781638
INFO:root:eval perplexity: 5.744516372680664
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.14s/it]
INFO:root:eval mean loss: 2707.546993607325
INFO:root:eval perplexity: 9.155056953430176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/111
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 111/200 [19:33:19<15:46:04, 637.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1378.5866912132085
INFO:root:current train perplexity2.9713640213012695
INFO:root:current mean train loss 1378.4309357673892
INFO:root:current train perplexity2.967590093612671
INFO:root:current mean train loss 1380.152609658408
INFO:root:current train perplexity2.9725635051727295
INFO:root:current mean train loss 1378.9661131547523
INFO:root:current train perplexity2.96879243850708
INFO:root:current mean train loss 1380.6252639833301
INFO:root:current train perplexity2.965069532394409
INFO:root:current mean train loss 1381.2942027850363
INFO:root:current train perplexity2.9677329063415527
INFO:root:current mean train loss 1382.770053874647
INFO:root:current train perplexity2.969594717025757
INFO:root:current mean train loss 1381.406739523696
INFO:root:current train perplexity2.9717373847961426
INFO:root:current mean train loss 1381.8920315641312
INFO:root:current train perplexity2.971431255340576
INFO:root:current mean train loss 1382.9919060945028
INFO:root:current train perplexity2.9739882946014404
INFO:root:current mean train loss 1384.1131807611791
INFO:root:current train perplexity2.976323127746582
INFO:root:current mean train loss 1384.2218021695166
INFO:root:current train perplexity2.977550745010376
INFO:root:current mean train loss 1385.1004096664499
INFO:root:current train perplexity2.9797046184539795
INFO:root:current mean train loss 1385.0037142490755
INFO:root:current train perplexity2.9814610481262207
INFO:root:current mean train loss 1386.4775931151687
INFO:root:current train perplexity2.983220100402832
INFO:root:current mean train loss 1386.2874335617316
INFO:root:current train perplexity2.9847240447998047
INFO:root:current mean train loss 1387.0456529936332
INFO:root:current train perplexity2.9869582653045654
INFO:root:current mean train loss 1387.8672485351562
INFO:root:current train perplexity2.9878625869750977
INFO:root:current mean train loss 1388.144841409564
INFO:root:current train perplexity2.988614797592163

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.67s/it]
INFO:root:final mean train loss: 1388.358261316158
INFO:root:final train perplexity: 2.9890120029449463
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.00s/it]
INFO:root:eval mean loss: 2161.7327833243294
INFO:root:eval perplexity: 5.744728088378906
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.29s/it]
INFO:root:eval mean loss: 2709.085870837489
INFO:root:eval perplexity: 9.166584014892578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/112
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 112/200 [19:43:52<15:33:28, 636.46s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1363.991455078125
INFO:root:current train perplexity2.918872833251953
INFO:root:current mean train loss 1380.1729712625151
INFO:root:current train perplexity2.9652161598205566
INFO:root:current mean train loss 1376.1630119737147
INFO:root:current train perplexity2.9689693450927734
INFO:root:current mean train loss 1372.2199126895111
INFO:root:current train perplexity2.967682123184204
INFO:root:current mean train loss 1373.5312827136322
INFO:root:current train perplexity2.9704477787017822
INFO:root:current mean train loss 1374.5109093971328
INFO:root:current train perplexity2.969555139541626
INFO:root:current mean train loss 1377.2752155158453
INFO:root:current train perplexity2.9721312522888184
INFO:root:current mean train loss 1376.7881432393538
INFO:root:current train perplexity2.9726290702819824
INFO:root:current mean train loss 1377.466537228557
INFO:root:current train perplexity2.9729835987091064
INFO:root:current mean train loss 1378.3847894172204
INFO:root:current train perplexity2.9752695560455322
INFO:root:current mean train loss 1379.7083833947377
INFO:root:current train perplexity2.9774601459503174
INFO:root:current mean train loss 1380.4487579152028
INFO:root:current train perplexity2.976269245147705
INFO:root:current mean train loss 1381.277026651308
INFO:root:current train perplexity2.975822687149048
INFO:root:current mean train loss 1381.5521202760756
INFO:root:current train perplexity2.9759209156036377
INFO:root:current mean train loss 1381.7740613375913
INFO:root:current train perplexity2.974576234817505
INFO:root:current mean train loss 1381.8347859944174
INFO:root:current train perplexity2.974686861038208
INFO:root:current mean train loss 1382.7592184027508
INFO:root:current train perplexity2.975738525390625
INFO:root:current mean train loss 1383.97131892421
INFO:root:current train perplexity2.975515842437744
INFO:root:current mean train loss 1384.5609824825378
INFO:root:current train perplexity2.9774155616760254
INFO:root:current mean train loss 1385.1867326825654
INFO:root:current train perplexity2.978883743286133

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.44s/it]
INFO:root:final mean train loss: 1384.763713580818
INFO:root:final train perplexity: 2.980550527572632
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.53s/it]
INFO:root:eval mean loss: 2166.1532861154974
INFO:root:eval perplexity: 5.765302658081055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it]
INFO:root:eval mean loss: 2715.567902260638
INFO:root:eval perplexity: 9.215307235717773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/113
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 113/200 [19:54:28<15:22:53, 636.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1345.148779296875
INFO:root:current train perplexity2.9413864612579346
INFO:root:current mean train loss 1375.5229736328124
INFO:root:current train perplexity2.9625167846679688
INFO:root:current mean train loss 1370.9672735040838
INFO:root:current train perplexity2.9520061016082764
INFO:root:current mean train loss 1373.9560413360596
INFO:root:current train perplexity2.9538371562957764
INFO:root:current mean train loss 1372.8505170549665
INFO:root:current train perplexity2.9585821628570557
INFO:root:current mean train loss 1373.3031940166766
INFO:root:current train perplexity2.9592490196228027
INFO:root:current mean train loss 1374.6855492376512
INFO:root:current train perplexity2.9584169387817383
INFO:root:current mean train loss 1373.9704564412434
INFO:root:current train perplexity2.95993709564209
INFO:root:current mean train loss 1373.1461638659966
INFO:root:current train perplexity2.959413528442383
INFO:root:current mean train loss 1374.115130217179
INFO:root:current train perplexity2.9604246616363525
INFO:root:current mean train loss 1376.2018664790135
INFO:root:current train perplexity2.9612174034118652
INFO:root:current mean train loss 1377.0378165108816
INFO:root:current train perplexity2.9627597332000732
INFO:root:current mean train loss 1378.4134466452676
INFO:root:current train perplexity2.964740753173828
INFO:root:current mean train loss 1379.1543382124466
INFO:root:current train perplexity2.9670751094818115
INFO:root:current mean train loss 1380.2947515783176
INFO:root:current train perplexity2.9682860374450684
INFO:root:current mean train loss 1380.4871488069234
INFO:root:current train perplexity2.970097541809082
INFO:root:current mean train loss 1380.9513927318433
INFO:root:current train perplexity2.971672773361206
INFO:root:current mean train loss 1381.2547256824582
INFO:root:current train perplexity2.971299886703491
INFO:root:current mean train loss 1381.8250494317695
INFO:root:current train perplexity2.973430871963501
INFO:root:current mean train loss 1382.9525955835977
INFO:root:current train perplexity2.974623680114746

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.06s/it]
INFO:root:final mean train loss: 1382.5250430970377
INFO:root:final train perplexity: 2.975292682647705
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.35s/it]
INFO:root:eval mean loss: 2169.065827931073
INFO:root:eval perplexity: 5.778897285461426
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.46s/it]
INFO:root:eval mean loss: 2718.9358295413617
INFO:root:eval perplexity: 9.24072551727295
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/114
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 114/200 [20:05:16<15:16:53, 639.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1364.3616316511825
INFO:root:current train perplexity2.9180185794830322
INFO:root:current mean train loss 1362.7137139313413
INFO:root:current train perplexity2.950505256652832
INFO:root:current mean train loss 1363.0000767446268
INFO:root:current train perplexity2.9390575885772705
INFO:root:current mean train loss 1369.779722853301
INFO:root:current train perplexity2.9497814178466797
INFO:root:current mean train loss 1370.5847807650707
INFO:root:current train perplexity2.9575774669647217
INFO:root:current mean train loss 1373.2864299184562
INFO:root:current train perplexity2.9624812602996826
INFO:root:current mean train loss 1374.487590220884
INFO:root:current train perplexity2.965078592300415
INFO:root:current mean train loss 1374.7137933159133
INFO:root:current train perplexity2.9629974365234375
INFO:root:current mean train loss 1374.7534652217741
INFO:root:current train perplexity2.9611127376556396
INFO:root:current mean train loss 1374.4127964601955
INFO:root:current train perplexity2.960563898086548
INFO:root:current mean train loss 1375.4144165863067
INFO:root:current train perplexity2.960888147354126
INFO:root:current mean train loss 1374.9128854931082
INFO:root:current train perplexity2.9600555896759033
INFO:root:current mean train loss 1375.5786178206472
INFO:root:current train perplexity2.9613239765167236
INFO:root:current mean train loss 1376.011505834541
INFO:root:current train perplexity2.9616506099700928
INFO:root:current mean train loss 1377.025480669907
INFO:root:current train perplexity2.9628565311431885
INFO:root:current mean train loss 1376.9278931378853
INFO:root:current train perplexity2.963472604751587
INFO:root:current mean train loss 1377.744045623425
INFO:root:current train perplexity2.965233564376831
INFO:root:current mean train loss 1377.983921013691
INFO:root:current train perplexity2.966827154159546
INFO:root:current mean train loss 1378.919449076811
INFO:root:current train perplexity2.9671945571899414
INFO:root:current mean train loss 1379.3367107590266
INFO:root:current train perplexity2.9671695232391357

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.85s/it]
INFO:root:final mean train loss: 1379.1205613005961
INFO:root:final train perplexity: 2.9673149585723877
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.48s/it]
INFO:root:eval mean loss: 2170.5211220599235
INFO:root:eval perplexity: 5.785704612731934
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.50s/it]
INFO:root:eval mean loss: 2722.2126183476007
INFO:root:eval perplexity: 9.265524864196777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/115
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 115/200 [20:15:54<15:05:33, 639.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1377.1767600730614
INFO:root:current train perplexity2.9374468326568604
INFO:root:current mean train loss 1380.4720641297179
INFO:root:current train perplexity2.941438674926758
INFO:root:current mean train loss 1375.3128508320005
INFO:root:current train perplexity2.94488787651062
INFO:root:current mean train loss 1368.8418910139699
INFO:root:current train perplexity2.940908432006836
INFO:root:current mean train loss 1368.5091394096744
INFO:root:current train perplexity2.943716526031494
INFO:root:current mean train loss 1369.8077304440715
INFO:root:current train perplexity2.9451985359191895
INFO:root:current mean train loss 1371.0542438285431
INFO:root:current train perplexity2.9484002590179443
INFO:root:current mean train loss 1371.9273306039663
INFO:root:current train perplexity2.950164318084717
INFO:root:current mean train loss 1371.8669685167229
INFO:root:current train perplexity2.9511172771453857
INFO:root:current mean train loss 1372.1812714710675
INFO:root:current train perplexity2.9544239044189453
INFO:root:current mean train loss 1372.9211893678842
INFO:root:current train perplexity2.954566240310669
INFO:root:current mean train loss 1373.7779503992567
INFO:root:current train perplexity2.954643726348877
INFO:root:current mean train loss 1373.6882327139092
INFO:root:current train perplexity2.956264019012451
INFO:root:current mean train loss 1373.6196910232702
INFO:root:current train perplexity2.955101251602173
INFO:root:current mean train loss 1373.5967405547467
INFO:root:current train perplexity2.9552619457244873
INFO:root:current mean train loss 1374.2783692505982
INFO:root:current train perplexity2.956609010696411
INFO:root:current mean train loss 1375.0945153380535
INFO:root:current train perplexity2.9569764137268066
INFO:root:current mean train loss 1375.8368774553253
INFO:root:current train perplexity2.9580531120300293
INFO:root:current mean train loss 1375.9788495735572
INFO:root:current train perplexity2.9593944549560547
INFO:root:current mean train loss 1376.202232649773
INFO:root:current train perplexity2.9604876041412354

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.36s/it]
INFO:root:final mean train loss: 1376.1570014742006
INFO:root:final train perplexity: 2.9603872299194336
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.99s/it]
INFO:root:eval mean loss: 2173.1331055553246
INFO:root:eval perplexity: 5.797937870025635
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.26s/it]
INFO:root:eval mean loss: 2725.08476008422
INFO:root:eval perplexity: 9.287311553955078
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/116
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 116/200 [20:26:37<14:56:25, 640.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1380.2519892303037
INFO:root:current train perplexity2.9368512630462646
INFO:root:current mean train loss 1368.5021337319536
INFO:root:current train perplexity2.9355392456054688
INFO:root:current mean train loss 1372.1701624120733
INFO:root:current train perplexity2.944181203842163
INFO:root:current mean train loss 1370.966534637698
INFO:root:current train perplexity2.9447970390319824
INFO:root:current mean train loss 1370.4878207002223
INFO:root:current train perplexity2.9411416053771973
INFO:root:current mean train loss 1370.1140512977506
INFO:root:current train perplexity2.942124843597412
INFO:root:current mean train loss 1370.0436043888553
INFO:root:current train perplexity2.94508695602417
INFO:root:current mean train loss 1370.9681192242217
INFO:root:current train perplexity2.9454331398010254
INFO:root:current mean train loss 1372.4122115440675
INFO:root:current train perplexity2.9473955631256104
INFO:root:current mean train loss 1371.2909459782923
INFO:root:current train perplexity2.9465155601501465
INFO:root:current mean train loss 1371.2957743155855
INFO:root:current train perplexity2.945995330810547
INFO:root:current mean train loss 1370.6965415426853
INFO:root:current train perplexity2.9472408294677734
INFO:root:current mean train loss 1370.5537720206776
INFO:root:current train perplexity2.9477949142456055
INFO:root:current mean train loss 1371.3241896347613
INFO:root:current train perplexity2.9489059448242188
INFO:root:current mean train loss 1371.6935265059378
INFO:root:current train perplexity2.950465202331543
INFO:root:current mean train loss 1371.8559397036372
INFO:root:current train perplexity2.9521586894989014
INFO:root:current mean train loss 1371.8228515040582
INFO:root:current train perplexity2.9520490169525146
INFO:root:current mean train loss 1372.3927620920604
INFO:root:current train perplexity2.9526262283325195
INFO:root:current mean train loss 1372.7522635528712
INFO:root:current train perplexity2.9522249698638916
INFO:root:current mean train loss 1373.3612899741565
INFO:root:current train perplexity2.9531004428863525

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:29<00:00, 569.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:29<00:00, 569.01s/it]
INFO:root:final mean train loss: 1373.0433156008198
INFO:root:final train perplexity: 2.953127145767212
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.30s/it]
INFO:root:eval mean loss: 2176.9781862083055
INFO:root:eval perplexity: 5.815997123718262
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.02s/it]
INFO:root:eval mean loss: 2729.131943290115
INFO:root:eval perplexity: 9.318103790283203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/117
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 117/200 [20:37:22<14:47:58, 641.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1359.8543479225852
INFO:root:current train perplexity2.905815362930298
INFO:root:current mean train loss 1366.4400485424285
INFO:root:current train perplexity2.9158575534820557
INFO:root:current mean train loss 1365.0680016411675
INFO:root:current train perplexity2.919123411178589
INFO:root:current mean train loss 1366.9524297026014
INFO:root:current train perplexity2.9171366691589355
INFO:root:current mean train loss 1365.3485762799373
INFO:root:current train perplexity2.922377109527588
INFO:root:current mean train loss 1365.8350884054794
INFO:root:current train perplexity2.9228174686431885
INFO:root:current mean train loss 1367.1415900296943
INFO:root:current train perplexity2.9256808757781982
INFO:root:current mean train loss 1366.3779169847517
INFO:root:current train perplexity2.927931308746338
INFO:root:current mean train loss 1366.7640951345634
INFO:root:current train perplexity2.93038010597229
INFO:root:current mean train loss 1366.28188246754
INFO:root:current train perplexity2.931861639022827
INFO:root:current mean train loss 1368.1339313282685
INFO:root:current train perplexity2.9340975284576416
INFO:root:current mean train loss 1367.7770209007392
INFO:root:current train perplexity2.934666395187378
INFO:root:current mean train loss 1368.3721437631928
INFO:root:current train perplexity2.9372012615203857
INFO:root:current mean train loss 1368.8718634613654
INFO:root:current train perplexity2.9374969005584717
INFO:root:current mean train loss 1369.3242268716135
INFO:root:current train perplexity2.937955856323242
INFO:root:current mean train loss 1369.3740714815463
INFO:root:current train perplexity2.9409401416778564
INFO:root:current mean train loss 1370.5277144445627
INFO:root:current train perplexity2.943108558654785
INFO:root:current mean train loss 1370.8875489373602
INFO:root:current train perplexity2.944321632385254
INFO:root:current mean train loss 1370.7592362872624
INFO:root:current train perplexity2.9451441764831543

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.89s/it]
INFO:root:final mean train loss: 1370.3755758172986
INFO:root:final train perplexity: 2.946920156478882
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.90s/it]
INFO:root:eval mean loss: 2180.23783062874
INFO:root:eval perplexity: 5.831348896026611
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it]
INFO:root:eval mean loss: 2733.677478546792
INFO:root:eval perplexity: 9.35280704498291
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/118
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 118/200 [20:47:59<14:35:20, 640.49s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1319.549365234375
INFO:root:current train perplexity2.8507838249206543
INFO:root:current mean train loss 1358.5705926804314
INFO:root:current train perplexity2.916120767593384
INFO:root:current mean train loss 1353.7996123523246
INFO:root:current train perplexity2.912099599838257
INFO:root:current mean train loss 1359.7131931992828
INFO:root:current train perplexity2.915667772293091
INFO:root:current mean train loss 1360.5405173972802
INFO:root:current train perplexity2.9170584678649902
INFO:root:current mean train loss 1362.7289591874226
INFO:root:current train perplexity2.9186010360717773
INFO:root:current mean train loss 1362.9567840828383
INFO:root:current train perplexity2.9242498874664307
INFO:root:current mean train loss 1363.1427365566822
INFO:root:current train perplexity2.929788827896118
INFO:root:current mean train loss 1363.273002596079
INFO:root:current train perplexity2.9314024448394775
INFO:root:current mean train loss 1364.452267405473
INFO:root:current train perplexity2.933234691619873
INFO:root:current mean train loss 1364.0126227990904
INFO:root:current train perplexity2.933910846710205
INFO:root:current mean train loss 1365.350396590427
INFO:root:current train perplexity2.936030387878418
INFO:root:current mean train loss 1365.64593622358
INFO:root:current train perplexity2.936819314956665
INFO:root:current mean train loss 1366.5919203484195
INFO:root:current train perplexity2.938185691833496
INFO:root:current mean train loss 1367.025289754087
INFO:root:current train perplexity2.939044952392578
INFO:root:current mean train loss 1367.8225691380294
INFO:root:current train perplexity2.940232992172241
INFO:root:current mean train loss 1367.7600114388629
INFO:root:current train perplexity2.9406778812408447
INFO:root:current mean train loss 1367.5492302768741
INFO:root:current train perplexity2.9400057792663574
INFO:root:current mean train loss 1368.126730896165
INFO:root:current train perplexity2.939985513687134
INFO:root:current mean train loss 1368.2616965786992
INFO:root:current train perplexity2.9408791065216064

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.35s/it]
INFO:root:final mean train loss: 1367.929643024054
INFO:root:final train perplexity: 2.9412412643432617
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.74s/it]
INFO:root:eval mean loss: 2179.5013349817154
INFO:root:eval perplexity: 5.827877044677734
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it]
INFO:root:eval mean loss: 2732.623347289173
INFO:root:eval perplexity: 9.344749450683594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/119
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 119/200 [20:58:41<14:25:18, 640.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1356.4411843039773
INFO:root:current train perplexity2.898348093032837
INFO:root:current mean train loss 1349.5148865746671
INFO:root:current train perplexity2.9076831340789795
INFO:root:current mean train loss 1351.5853953318554
INFO:root:current train perplexity2.901221990585327
INFO:root:current mean train loss 1353.608682762762
INFO:root:current train perplexity2.906911611557007
INFO:root:current mean train loss 1354.9120599104895
INFO:root:current train perplexity2.9083070755004883
INFO:root:current mean train loss 1356.391309014682
INFO:root:current train perplexity2.9133784770965576
INFO:root:current mean train loss 1355.7762786767107
INFO:root:current train perplexity2.9136245250701904
INFO:root:current mean train loss 1356.108608763634
INFO:root:current train perplexity2.9144539833068848
INFO:root:current mean train loss 1358.3863856554613
INFO:root:current train perplexity2.915832281112671
INFO:root:current mean train loss 1359.6208357076582
INFO:root:current train perplexity2.9189887046813965
INFO:root:current mean train loss 1359.9225052984727
INFO:root:current train perplexity2.9196383953094482
INFO:root:current mean train loss 1360.8385695187167
INFO:root:current train perplexity2.921621561050415
INFO:root:current mean train loss 1360.8579254400124
INFO:root:current train perplexity2.9236485958099365
INFO:root:current mean train loss 1360.7710817830466
INFO:root:current train perplexity2.9253883361816406
INFO:root:current mean train loss 1361.2190646186325
INFO:root:current train perplexity2.9276793003082275
INFO:root:current mean train loss 1362.5954850506375
INFO:root:current train perplexity2.929455280303955
INFO:root:current mean train loss 1363.3302350402907
INFO:root:current train perplexity2.930739164352417
INFO:root:current mean train loss 1363.5211379420052
INFO:root:current train perplexity2.9320192337036133
INFO:root:current mean train loss 1364.3074836605335
INFO:root:current train perplexity2.932448387145996
INFO:root:current mean train loss 1364.4593201636276
INFO:root:current train perplexity2.93290638923645

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.75s/it]
INFO:root:final mean train loss: 1364.4820422135515
INFO:root:final train perplexity: 2.9332547187805176
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it]
INFO:root:eval mean loss: 2184.091530657829
INFO:root:eval perplexity: 5.849551677703857
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it]
INFO:root:eval mean loss: 2738.051430127299
INFO:root:eval perplexity: 9.386322021484375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/120
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 120/200 [21:09:16<14:11:57, 638.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1351.501474233774
INFO:root:current train perplexity2.8851444721221924
INFO:root:current mean train loss 1352.6083518927046
INFO:root:current train perplexity2.894047737121582
INFO:root:current mean train loss 1351.997876283015
INFO:root:current train perplexity2.90317440032959
INFO:root:current mean train loss 1348.0935404279592
INFO:root:current train perplexity2.908118963241577
INFO:root:current mean train loss 1348.9314273495338
INFO:root:current train perplexity2.904041051864624
INFO:root:current mean train loss 1351.723764394785
INFO:root:current train perplexity2.9071033000946045
INFO:root:current mean train loss 1352.9239377781446
INFO:root:current train perplexity2.9070940017700195
INFO:root:current mean train loss 1353.352474310724
INFO:root:current train perplexity2.91129469871521
INFO:root:current mean train loss 1354.8985275614104
INFO:root:current train perplexity2.9101381301879883
INFO:root:current mean train loss 1355.287760156666
INFO:root:current train perplexity2.9107635021209717
INFO:root:current mean train loss 1356.168553254143
INFO:root:current train perplexity2.9129724502563477
INFO:root:current mean train loss 1357.1258768913933
INFO:root:current train perplexity2.9144632816314697
INFO:root:current mean train loss 1357.3397642417335
INFO:root:current train perplexity2.9153761863708496
INFO:root:current mean train loss 1358.126708072722
INFO:root:current train perplexity2.9168126583099365
INFO:root:current mean train loss 1358.263659065676
INFO:root:current train perplexity2.9182920455932617
INFO:root:current mean train loss 1359.7671449697195
INFO:root:current train perplexity2.9205496311187744
INFO:root:current mean train loss 1360.6647191772088
INFO:root:current train perplexity2.922898292541504
INFO:root:current mean train loss 1361.225505984604
INFO:root:current train perplexity2.923907518386841
INFO:root:current mean train loss 1361.58402380391
INFO:root:current train perplexity2.925732135772705
INFO:root:current mean train loss 1362.0909428234995
INFO:root:current train perplexity2.9268410205841064

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.29s/it]
INFO:root:final mean train loss: 1361.8936715253483
INFO:root:final train perplexity: 2.9272730350494385
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.67s/it]
INFO:root:eval mean loss: 2185.6462086346132
INFO:root:eval perplexity: 5.856910228729248
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.92s/it]
INFO:root:eval mean loss: 2740.5929552443486
INFO:root:eval perplexity: 9.405852317810059
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/121
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 121/200 [21:20:01<14:03:45, 640.83s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1349.4593462262835
INFO:root:current train perplexity2.8962550163269043
INFO:root:current mean train loss 1350.3033251640124
INFO:root:current train perplexity2.89994740486145
INFO:root:current mean train loss 1350.9834671020508
INFO:root:current train perplexity2.899549961090088
INFO:root:current mean train loss 1350.1833773838
INFO:root:current train perplexity2.9016945362091064
INFO:root:current mean train loss 1353.8198871277925
INFO:root:current train perplexity2.901503562927246
INFO:root:current mean train loss 1355.7888666605777
INFO:root:current train perplexity2.9022929668426514
INFO:root:current mean train loss 1356.8323243303996
INFO:root:current train perplexity2.903221368789673
INFO:root:current mean train loss 1355.164955583199
INFO:root:current train perplexity2.9050753116607666
INFO:root:current mean train loss 1355.5547369841104
INFO:root:current train perplexity2.9087185859680176
INFO:root:current mean train loss 1355.8306579589844
INFO:root:current train perplexity2.912254810333252
INFO:root:current mean train loss 1355.5277970053933
INFO:root:current train perplexity2.9119176864624023
INFO:root:current mean train loss 1354.8423799824961
INFO:root:current train perplexity2.9123923778533936
INFO:root:current mean train loss 1354.624245516054
INFO:root:current train perplexity2.9128262996673584
INFO:root:current mean train loss 1355.8698753874562
INFO:root:current train perplexity2.914198160171509
INFO:root:current mean train loss 1355.97351703015
INFO:root:current train perplexity2.9151885509490967
INFO:root:current mean train loss 1357.0171283633665
INFO:root:current train perplexity2.9161465167999268
INFO:root:current mean train loss 1357.1752975390152
INFO:root:current train perplexity2.9163403511047363
INFO:root:current mean train loss 1357.6549500484944
INFO:root:current train perplexity2.917778730392456
INFO:root:current mean train loss 1358.514916124015
INFO:root:current train perplexity2.918501853942871
INFO:root:current mean train loss 1358.912626239176
INFO:root:current train perplexity2.9196670055389404

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.90s/it]
INFO:root:final mean train loss: 1358.7490989081016
INFO:root:final train perplexity: 2.9200220108032227
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.01s/it]
INFO:root:eval mean loss: 2186.440469944731
INFO:root:eval perplexity: 5.8606743812561035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.31s/it]
INFO:root:eval mean loss: 2743.52447553053
INFO:root:eval perplexity: 9.42842960357666
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/122
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [21:30:40<13:52:34, 640.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1347.804468442316
INFO:root:current train perplexity2.912872552871704
INFO:root:current mean train loss 1348.971301481214
INFO:root:current train perplexity2.905369997024536
INFO:root:current mean train loss 1350.6512428814674
INFO:root:current train perplexity2.9003238677978516
INFO:root:current mean train loss 1350.7106668508084
INFO:root:current train perplexity2.8984177112579346
INFO:root:current mean train loss 1349.0830341363305
INFO:root:current train perplexity2.9012680053710938
INFO:root:current mean train loss 1349.9635109893106
INFO:root:current train perplexity2.904078722000122
INFO:root:current mean train loss 1350.100530978652
INFO:root:current train perplexity2.9047906398773193
INFO:root:current mean train loss 1351.5221991101027
INFO:root:current train perplexity2.905327320098877
INFO:root:current mean train loss 1353.142531701926
INFO:root:current train perplexity2.905696153640747
INFO:root:current mean train loss 1354.401053919699
INFO:root:current train perplexity2.9060256481170654
INFO:root:current mean train loss 1355.0759738093764
INFO:root:current train perplexity2.9070398807525635
INFO:root:current mean train loss 1355.8517857232057
INFO:root:current train perplexity2.909247875213623
INFO:root:current mean train loss 1356.6604637751313
INFO:root:current train perplexity2.909498929977417
INFO:root:current mean train loss 1356.3298787938706
INFO:root:current train perplexity2.910630226135254
INFO:root:current mean train loss 1356.0721075882818
INFO:root:current train perplexity2.9100279808044434
INFO:root:current mean train loss 1356.1914400075245
INFO:root:current train perplexity2.9105334281921387
INFO:root:current mean train loss 1356.9881801935846
INFO:root:current train perplexity2.9114818572998047
INFO:root:current mean train loss 1357.3714117662287
INFO:root:current train perplexity2.9125099182128906
INFO:root:current mean train loss 1356.8204781715078
INFO:root:current train perplexity2.9133312702178955
INFO:root:current mean train loss 1356.8730990936233
INFO:root:current train perplexity2.9145514965057373

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.99s/it]
INFO:root:final mean train loss: 1356.4595227647899
INFO:root:final train perplexity: 2.914754867553711
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.81s/it]
INFO:root:eval mean loss: 2191.2313223764404
INFO:root:eval perplexity: 5.883426189422607
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it]
INFO:root:eval mean loss: 2748.2038712738254
INFO:root:eval perplexity: 9.464580535888672
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/123
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 123/200 [21:41:13<13:38:39, 637.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1343.4613715277778
INFO:root:current train perplexity2.9006199836730957
INFO:root:current mean train loss 1342.1279271175986
INFO:root:current train perplexity2.8909101486206055
INFO:root:current mean train loss 1347.9986930057921
INFO:root:current train perplexity2.8975088596343994
INFO:root:current mean train loss 1350.7686639247797
INFO:root:current train perplexity2.900912046432495
INFO:root:current mean train loss 1351.1838887117347
INFO:root:current train perplexity2.9027016162872314
INFO:root:current mean train loss 1350.7468921726033
INFO:root:current train perplexity2.9012112617492676
INFO:root:current mean train loss 1349.8103321020153
INFO:root:current train perplexity2.901496171951294
INFO:root:current mean train loss 1350.3991218663468
INFO:root:current train perplexity2.9018619060516357
INFO:root:current mean train loss 1350.9967866704706
INFO:root:current train perplexity2.9029486179351807
INFO:root:current mean train loss 1350.685752914891
INFO:root:current train perplexity2.904043197631836
INFO:root:current mean train loss 1350.8131984885679
INFO:root:current train perplexity2.903229236602783
INFO:root:current mean train loss 1350.9166900891216
INFO:root:current train perplexity2.9050662517547607
INFO:root:current mean train loss 1350.6688582546028
INFO:root:current train perplexity2.9053003787994385
INFO:root:current mean train loss 1351.0299635194187
INFO:root:current train perplexity2.9049599170684814
INFO:root:current mean train loss 1352.0161364664168
INFO:root:current train perplexity2.905181646347046
INFO:root:current mean train loss 1351.8581937585986
INFO:root:current train perplexity2.9046177864074707
INFO:root:current mean train loss 1351.9250044783191
INFO:root:current train perplexity2.9050586223602295
INFO:root:current mean train loss 1352.8162078686933
INFO:root:current train perplexity2.9057905673980713
INFO:root:current mean train loss 1353.537540819279
INFO:root:current train perplexity2.9078528881073

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:30<00:00, 570.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:30<00:00, 570.32s/it]
INFO:root:final mean train loss: 1353.9944070497668
INFO:root:final train perplexity: 2.9090936183929443
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.98s/it]
INFO:root:eval mean loss: 2191.043803330009
INFO:root:eval perplexity: 5.882534503936768
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it]
INFO:root:eval mean loss: 2748.729309514905
INFO:root:eval perplexity: 9.468649864196777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/124
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 124/200 [21:52:00<13:31:50, 640.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1354.9424525669642
INFO:root:current train perplexity2.8278648853302
INFO:root:current mean train loss 1345.7770402854849
INFO:root:current train perplexity2.871156930923462
INFO:root:current mean train loss 1350.4336869244414
INFO:root:current train perplexity2.885718822479248
INFO:root:current mean train loss 1347.2074332470227
INFO:root:current train perplexity2.8857500553131104
INFO:root:current mean train loss 1343.3121343889165
INFO:root:current train perplexity2.887511730194092
INFO:root:current mean train loss 1345.7327351165711
INFO:root:current train perplexity2.8913676738739014
INFO:root:current mean train loss 1345.9969381869723
INFO:root:current train perplexity2.890120029449463
INFO:root:current mean train loss 1346.7553410509856
INFO:root:current train perplexity2.8889880180358887
INFO:root:current mean train loss 1346.3197673433629
INFO:root:current train perplexity2.887862205505371
INFO:root:current mean train loss 1347.1789277569856
INFO:root:current train perplexity2.8905937671661377
INFO:root:current mean train loss 1346.422934963071
INFO:root:current train perplexity2.891300678253174
INFO:root:current mean train loss 1346.6313467740797
INFO:root:current train perplexity2.8926379680633545
INFO:root:current mean train loss 1347.0540959596042
INFO:root:current train perplexity2.8926830291748047
INFO:root:current mean train loss 1347.3885880041962
INFO:root:current train perplexity2.893446683883667
INFO:root:current mean train loss 1347.7096715085288
INFO:root:current train perplexity2.8946261405944824
INFO:root:current mean train loss 1348.7550964152963
INFO:root:current train perplexity2.895533800125122
INFO:root:current mean train loss 1348.565560493398
INFO:root:current train perplexity2.896365165710449
INFO:root:current mean train loss 1349.3013187312354
INFO:root:current train perplexity2.897951602935791
INFO:root:current mean train loss 1349.818465637646
INFO:root:current train perplexity2.899481773376465
INFO:root:current mean train loss 1350.3997247752934
INFO:root:current train perplexity2.900818109512329

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.21s/it]
INFO:root:final mean train loss: 1350.6154784848459
INFO:root:final train perplexity: 2.9013514518737793
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it]
INFO:root:eval mean loss: 2195.126076123393
INFO:root:eval perplexity: 5.901987075805664
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.95s/it]
INFO:root:eval mean loss: 2754.167473975648
INFO:root:eval perplexity: 9.510854721069336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/125
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 125/200 [22:02:44<13:22:05, 641.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1337.359125773112
INFO:root:current train perplexity2.883629083633423
INFO:root:current mean train loss 1339.3563212733116
INFO:root:current train perplexity2.880518674850464
INFO:root:current mean train loss 1339.0749157496862
INFO:root:current train perplexity2.8673017024993896
INFO:root:current mean train loss 1341.0695032190395
INFO:root:current train perplexity2.875612497329712
INFO:root:current mean train loss 1344.0745555949661
INFO:root:current train perplexity2.878502368927002
INFO:root:current mean train loss 1343.072212277478
INFO:root:current train perplexity2.878242254257202
INFO:root:current mean train loss 1343.2737418932793
INFO:root:current train perplexity2.881281852722168
INFO:root:current mean train loss 1343.4968059392265
INFO:root:current train perplexity2.88214111328125
INFO:root:current mean train loss 1342.6372999172766
INFO:root:current train perplexity2.8847293853759766
INFO:root:current mean train loss 1342.0781704460903
INFO:root:current train perplexity2.885591983795166
INFO:root:current mean train loss 1343.0418379306793
INFO:root:current train perplexity2.8875558376312256
INFO:root:current mean train loss 1343.282183229711
INFO:root:current train perplexity2.887787342071533
INFO:root:current mean train loss 1344.9507188983991
INFO:root:current train perplexity2.8892345428466797
INFO:root:current mean train loss 1345.2826480001122
INFO:root:current train perplexity2.889252185821533
INFO:root:current mean train loss 1345.684660665105
INFO:root:current train perplexity2.890738010406494
INFO:root:current mean train loss 1346.521941017291
INFO:root:current train perplexity2.8922226428985596
INFO:root:current mean train loss 1347.152804069331
INFO:root:current train perplexity2.892650604248047
INFO:root:current mean train loss 1347.8005545277606
INFO:root:current train perplexity2.8942294120788574
INFO:root:current mean train loss 1348.1970175358288
INFO:root:current train perplexity2.895071029663086
INFO:root:current mean train loss 1348.4987621029795
INFO:root:current train perplexity2.8953278064727783

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.01s/it]
INFO:root:final mean train loss: 1348.1953359537515
INFO:root:final train perplexity: 2.8958189487457275
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.03s/it]
INFO:root:eval mean loss: 2198.384970374141
INFO:root:eval perplexity: 5.917562484741211
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.24s/it]
INFO:root:eval mean loss: 2756.4833495228004
INFO:root:eval perplexity: 9.528887748718262
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/126
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 126/200 [22:13:19<13:09:08, 639.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1331.0420487566691
INFO:root:current train perplexity2.862514019012451
INFO:root:current mean train loss 1338.6889180934174
INFO:root:current train perplexity2.8681180477142334
INFO:root:current mean train loss 1338.3999631256484
INFO:root:current train perplexity2.8685991764068604
INFO:root:current mean train loss 1339.3154604735612
INFO:root:current train perplexity2.8698441982269287
INFO:root:current mean train loss 1341.646945529514
INFO:root:current train perplexity2.870609998703003
INFO:root:current mean train loss 1341.6699509823388
INFO:root:current train perplexity2.8686699867248535
INFO:root:current mean train loss 1341.5217521298507
INFO:root:current train perplexity2.8681156635284424
INFO:root:current mean train loss 1340.8230364306576
INFO:root:current train perplexity2.868706703186035
INFO:root:current mean train loss 1340.998885691095
INFO:root:current train perplexity2.8698737621307373
INFO:root:current mean train loss 1341.8051993910235
INFO:root:current train perplexity2.872950315475464
INFO:root:current mean train loss 1341.980720160903
INFO:root:current train perplexity2.87485408782959
INFO:root:current mean train loss 1342.5189227171888
INFO:root:current train perplexity2.876892566680908
INFO:root:current mean train loss 1342.8900679619826
INFO:root:current train perplexity2.8794960975646973
INFO:root:current mean train loss 1343.826711223696
INFO:root:current train perplexity2.8817360401153564
INFO:root:current mean train loss 1344.2671659153257
INFO:root:current train perplexity2.882533311843872
INFO:root:current mean train loss 1344.9902505348596
INFO:root:current train perplexity2.8845608234405518
INFO:root:current mean train loss 1345.3222453171418
INFO:root:current train perplexity2.887174129486084
INFO:root:current mean train loss 1345.9193017073296
INFO:root:current train perplexity2.8882410526275635
INFO:root:current mean train loss 1345.9681531086621
INFO:root:current train perplexity2.888887882232666
INFO:root:current mean train loss 1346.2692809461134
INFO:root:current train perplexity2.889906644821167

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.19s/it]
INFO:root:final mean train loss: 1345.8141810984187
INFO:root:final train perplexity: 2.890385866165161
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it]
INFO:root:eval mean loss: 2200.3718101555573
INFO:root:eval perplexity: 5.927079677581787
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it]
INFO:root:eval mean loss: 2759.5440414104055
INFO:root:eval perplexity: 9.552769660949707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/127
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 127/200 [22:23:55<12:56:44, 638.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1320.2675128805226
INFO:root:current train perplexity2.8512558937072754
INFO:root:current mean train loss 1326.1931631353837
INFO:root:current train perplexity2.8671164512634277
INFO:root:current mean train loss 1331.506027339965
INFO:root:current train perplexity2.874140501022339
INFO:root:current mean train loss 1333.4645058402803
INFO:root:current train perplexity2.8746583461761475
INFO:root:current mean train loss 1334.687148181632
INFO:root:current train perplexity2.8723342418670654
INFO:root:current mean train loss 1336.2540738232246
INFO:root:current train perplexity2.871049642562866
INFO:root:current mean train loss 1337.0970219667197
INFO:root:current train perplexity2.8723130226135254
INFO:root:current mean train loss 1338.0555147759833
INFO:root:current train perplexity2.8741605281829834
INFO:root:current mean train loss 1338.9679878430488
INFO:root:current train perplexity2.873486280441284
INFO:root:current mean train loss 1339.1063159791313
INFO:root:current train perplexity2.8739700317382812
INFO:root:current mean train loss 1340.2886131012597
INFO:root:current train perplexity2.8750226497650146
INFO:root:current mean train loss 1340.2929362822485
INFO:root:current train perplexity2.87613844871521
INFO:root:current mean train loss 1340.6448839730413
INFO:root:current train perplexity2.877375841140747
INFO:root:current mean train loss 1340.9217029509734
INFO:root:current train perplexity2.8780581951141357
INFO:root:current mean train loss 1341.1747907055094
INFO:root:current train perplexity2.8785157203674316
INFO:root:current mean train loss 1341.8797992123566
INFO:root:current train perplexity2.8786699771881104
INFO:root:current mean train loss 1342.3171321192467
INFO:root:current train perplexity2.8800370693206787
INFO:root:current mean train loss 1342.8051694624796
INFO:root:current train perplexity2.8808248043060303
INFO:root:current mean train loss 1343.118952526343
INFO:root:current train perplexity2.881650686264038
INFO:root:current mean train loss 1343.297877747143
INFO:root:current train perplexity2.883261203765869

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.50s/it]
INFO:root:final mean train loss: 1343.0476326300409
INFO:root:final train perplexity: 2.8840863704681396
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.94s/it]
INFO:root:eval mean loss: 2203.278364898465
INFO:root:eval perplexity: 5.941028118133545
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.69s/it]
INFO:root:eval mean loss: 2763.330069467531
INFO:root:eval perplexity: 9.58239459991455
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/128
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [22:34:39<12:48:15, 640.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1333.3760888671875
INFO:root:current train perplexity2.8724472522735596
INFO:root:current mean train loss 1334.9537779017858
INFO:root:current train perplexity2.8581948280334473
INFO:root:current mean train loss 1335.901991743608
INFO:root:current train perplexity2.867295503616333
INFO:root:current mean train loss 1336.3281946614584
INFO:root:current train perplexity2.868124485015869
INFO:root:current mean train loss 1334.7263402035362
INFO:root:current train perplexity2.8680357933044434
INFO:root:current mean train loss 1335.6851526409646
INFO:root:current train perplexity2.869630813598633
INFO:root:current mean train loss 1335.3473012514467
INFO:root:current train perplexity2.8678524494171143
INFO:root:current mean train loss 1336.4804522114416
INFO:root:current train perplexity2.8689944744110107
INFO:root:current mean train loss 1337.726744280134
INFO:root:current train perplexity2.8703489303588867
INFO:root:current mean train loss 1337.543428485577
INFO:root:current train perplexity2.871596097946167
INFO:root:current mean train loss 1338.2120768986192
INFO:root:current train perplexity2.8719708919525146
INFO:root:current mean train loss 1338.4076219664228
INFO:root:current train perplexity2.8718504905700684
INFO:root:current mean train loss 1338.068228113511
INFO:root:current train perplexity2.872037887573242
INFO:root:current mean train loss 1338.2920114524147
INFO:root:current train perplexity2.873662233352661
INFO:root:current mean train loss 1339.2619417041842
INFO:root:current train perplexity2.8745546340942383
INFO:root:current mean train loss 1339.1689634486606
INFO:root:current train perplexity2.8759942054748535
INFO:root:current mean train loss 1339.4199521192863
INFO:root:current train perplexity2.876664161682129
INFO:root:current mean train loss 1340.1768580133144
INFO:root:current train perplexity2.877317428588867
INFO:root:current mean train loss 1340.808242578125
INFO:root:current train perplexity2.878020763397217
INFO:root:current mean train loss 1340.593507342761
INFO:root:current train perplexity2.878114700317383

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.01s/it]
INFO:root:final mean train loss: 1340.403901670055
INFO:root:final train perplexity: 2.8780789375305176
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 2206.6254198872452
INFO:root:eval perplexity: 5.957131385803223
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.02s/it]
INFO:root:eval mean loss: 2771.2051798502603
INFO:root:eval perplexity: 9.644306182861328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/129
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 129/200 [22:45:11<12:34:50, 637.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1330.9401298191237
INFO:root:current train perplexity2.838129997253418
INFO:root:current mean train loss 1328.2973899841309
INFO:root:current train perplexity2.853271007537842
INFO:root:current mean train loss 1325.9490753591876
INFO:root:current train perplexity2.858189344406128
INFO:root:current mean train loss 1329.4154417076888
INFO:root:current train perplexity2.8632538318634033
INFO:root:current mean train loss 1329.370385394833
INFO:root:current train perplexity2.859917640686035
INFO:root:current mean train loss 1330.4894438047668
INFO:root:current train perplexity2.8607587814331055
INFO:root:current mean train loss 1331.9679281422168
INFO:root:current train perplexity2.864759922027588
INFO:root:current mean train loss 1331.7272288004558
INFO:root:current train perplexity2.8657097816467285
INFO:root:current mean train loss 1331.6187114630045
INFO:root:current train perplexity2.865926742553711
INFO:root:current mean train loss 1332.3308448791504
INFO:root:current train perplexity2.866201639175415
INFO:root:current mean train loss 1333.5008831094037
INFO:root:current train perplexity2.8688700199127197
INFO:root:current mean train loss 1333.5572201517605
INFO:root:current train perplexity2.8687148094177246
INFO:root:current mean train loss 1334.409207654073
INFO:root:current train perplexity2.8689777851104736
INFO:root:current mean train loss 1334.9114074707031
INFO:root:current train perplexity2.868229866027832
INFO:root:current mean train loss 1335.7011701568522
INFO:root:current train perplexity2.8685622215270996
INFO:root:current mean train loss 1336.7152048235562
INFO:root:current train perplexity2.8699533939361572
INFO:root:current mean train loss 1337.6019258972601
INFO:root:current train perplexity2.869744062423706
INFO:root:current mean train loss 1337.8987797328405
INFO:root:current train perplexity2.8709182739257812
INFO:root:current mean train loss 1338.2491877678838
INFO:root:current train perplexity2.872389316558838

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.75s/it]
INFO:root:final mean train loss: 1338.0950353086687
INFO:root:final train perplexity: 2.8728432655334473
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.26s/it]
INFO:root:eval mean loss: 2204.859971499612
INFO:root:eval perplexity: 5.94863224029541
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.10s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it]
INFO:root:eval mean loss: 2767.608227452488
INFO:root:eval perplexity: 9.615978240966797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/130
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [22:55:42<12:21:36, 635.67s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1313.1547444661458
INFO:root:current train perplexity2.7903566360473633
INFO:root:current mean train loss 1330.883156312715
INFO:root:current train perplexity2.8547744750976562
INFO:root:current mean train loss 1328.8908726450359
INFO:root:current train perplexity2.861271381378174
INFO:root:current mean train loss 1329.0173466259607
INFO:root:current train perplexity2.861477851867676
INFO:root:current mean train loss 1329.7188177505157
INFO:root:current train perplexity2.8579068183898926
INFO:root:current mean train loss 1331.2309471984743
INFO:root:current train perplexity2.860734224319458
INFO:root:current mean train loss 1330.9188529078792
INFO:root:current train perplexity2.8595497608184814
INFO:root:current mean train loss 1330.9784059511085
INFO:root:current train perplexity2.8612008094787598
INFO:root:current mean train loss 1331.6672987967397
INFO:root:current train perplexity2.8636584281921387
INFO:root:current mean train loss 1331.2824373990134
INFO:root:current train perplexity2.863739252090454
INFO:root:current mean train loss 1331.5027785816326
INFO:root:current train perplexity2.864299774169922
INFO:root:current mean train loss 1332.2348901389203
INFO:root:current train perplexity2.8637187480926514
INFO:root:current mean train loss 1332.3466453583799
INFO:root:current train perplexity2.8644258975982666
INFO:root:current mean train loss 1333.4998301833161
INFO:root:current train perplexity2.865313768386841
INFO:root:current mean train loss 1333.4391116919967
INFO:root:current train perplexity2.8657708168029785
INFO:root:current mean train loss 1334.3829511537544
INFO:root:current train perplexity2.865859031677246
INFO:root:current mean train loss 1333.9200540356492
INFO:root:current train perplexity2.8656139373779297
INFO:root:current mean train loss 1334.4501078133
INFO:root:current train perplexity2.86598539352417
INFO:root:current mean train loss 1334.6960258251927
INFO:root:current train perplexity2.865849018096924
INFO:root:current mean train loss 1335.3270446553538
INFO:root:current train perplexity2.8658928871154785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.04s/it]
INFO:root:final mean train loss: 1335.4960223114738
INFO:root:final train perplexity: 2.8669610023498535
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it]
INFO:root:eval mean loss: 2209.217338399684
INFO:root:eval perplexity: 5.969631195068359
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.48s/it]
INFO:root:eval mean loss: 2774.1743544991136
INFO:root:eval perplexity: 9.667753219604492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/131
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 131/200 [23:06:13<12:09:28, 634.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1296.7631366436299
INFO:root:current train perplexity2.867354154586792
INFO:root:current mean train loss 1322.4670972067213
INFO:root:current train perplexity2.8421764373779297
INFO:root:current mean train loss 1323.9025884307591
INFO:root:current train perplexity2.843073606491089
INFO:root:current mean train loss 1325.638300796228
INFO:root:current train perplexity2.846221923828125
INFO:root:current mean train loss 1326.9090725177891
INFO:root:current train perplexity2.8466713428497314
INFO:root:current mean train loss 1328.715643008852
INFO:root:current train perplexity2.848320245742798
INFO:root:current mean train loss 1328.9525610585563
INFO:root:current train perplexity2.850127935409546
INFO:root:current mean train loss 1329.0871380262138
INFO:root:current train perplexity2.851203441619873
INFO:root:current mean train loss 1329.837631558102
INFO:root:current train perplexity2.851517915725708
INFO:root:current mean train loss 1330.6251957607062
INFO:root:current train perplexity2.853450298309326
INFO:root:current mean train loss 1331.2858388205486
INFO:root:current train perplexity2.8540189266204834
INFO:root:current mean train loss 1331.7140674218404
INFO:root:current train perplexity2.855617046356201
INFO:root:current mean train loss 1331.8359783228614
INFO:root:current train perplexity2.855609893798828
INFO:root:current mean train loss 1331.9810616103412
INFO:root:current train perplexity2.8560428619384766
INFO:root:current mean train loss 1331.6050599086168
INFO:root:current train perplexity2.8563737869262695
INFO:root:current mean train loss 1331.9212024933702
INFO:root:current train perplexity2.8572845458984375
INFO:root:current mean train loss 1332.6523886442478
INFO:root:current train perplexity2.8590846061706543
INFO:root:current mean train loss 1333.1098080454944
INFO:root:current train perplexity2.8613338470458984
INFO:root:current mean train loss 1333.9067800632572
INFO:root:current train perplexity2.8619799613952637
INFO:root:current mean train loss 1334.0985334956881
INFO:root:current train perplexity2.862952470779419

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.97s/it]
INFO:root:final mean train loss: 1334.0145069455114
INFO:root:final train perplexity: 2.8636128902435303
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.03s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.03s/it]
INFO:root:eval mean loss: 2210.0950858474625
INFO:root:eval perplexity: 5.973870277404785
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 2774.110991349457
INFO:root:eval perplexity: 9.667253494262695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/132
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 132/200 [23:16:53<12:00:43, 635.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1320.2336198673693
INFO:root:current train perplexity2.8420541286468506
INFO:root:current mean train loss 1324.2367950652863
INFO:root:current train perplexity2.841700792312622
INFO:root:current mean train loss 1324.2293535397378
INFO:root:current train perplexity2.8359568119049072
INFO:root:current mean train loss 1327.4303957213465
INFO:root:current train perplexity2.8403074741363525
INFO:root:current mean train loss 1327.5253390964483
INFO:root:current train perplexity2.844085931777954
INFO:root:current mean train loss 1327.404145804558
INFO:root:current train perplexity2.8430237770080566
INFO:root:current mean train loss 1327.7980459637442
INFO:root:current train perplexity2.8439106941223145
INFO:root:current mean train loss 1327.3090266642307
INFO:root:current train perplexity2.8434996604919434
INFO:root:current mean train loss 1327.606597067764
INFO:root:current train perplexity2.843282461166382
INFO:root:current mean train loss 1326.9335298022436
INFO:root:current train perplexity2.845362663269043
INFO:root:current mean train loss 1327.2645992816695
INFO:root:current train perplexity2.8470377922058105
INFO:root:current mean train loss 1327.797055168519
INFO:root:current train perplexity2.8483266830444336
INFO:root:current mean train loss 1328.6047249362052
INFO:root:current train perplexity2.8488409519195557
INFO:root:current mean train loss 1328.5159240404528
INFO:root:current train perplexity2.849975824356079
INFO:root:current mean train loss 1329.0887004511271
INFO:root:current train perplexity2.8516905307769775
INFO:root:current mean train loss 1329.545856903531
INFO:root:current train perplexity2.8531606197357178
INFO:root:current mean train loss 1329.982379674186
INFO:root:current train perplexity2.853156805038452
INFO:root:current mean train loss 1329.9927351005585
INFO:root:current train perplexity2.854313373565674
INFO:root:current mean train loss 1330.4109745781122
INFO:root:current train perplexity2.8541855812072754
INFO:root:current mean train loss 1330.850015417424
INFO:root:current train perplexity2.8558645248413086

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.68s/it]
INFO:root:final mean train loss: 1330.7219690119925
INFO:root:final train perplexity: 2.856186866760254
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 2213.13029577377
INFO:root:eval perplexity: 5.988553524017334
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.20s/it]
INFO:root:eval mean loss: 2780.7599647467864
INFO:root:eval perplexity: 9.719963073730469
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/133
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 133/200 [23:27:22<11:47:53, 633.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1317.6000671386719
INFO:root:current train perplexity2.8494138717651367
INFO:root:current mean train loss 1326.1406158447267
INFO:root:current train perplexity2.8291828632354736
INFO:root:current mean train loss 1324.7653794508715
INFO:root:current train perplexity2.8282699584960938
INFO:root:current mean train loss 1325.6561072455513
INFO:root:current train perplexity2.8332841396331787
INFO:root:current mean train loss 1326.448504904042
INFO:root:current train perplexity2.8359172344207764
INFO:root:current mean train loss 1326.6541133335659
INFO:root:current train perplexity2.832894802093506
INFO:root:current mean train loss 1326.8759887695312
INFO:root:current train perplexity2.834988832473755
INFO:root:current mean train loss 1326.1274727269222
INFO:root:current train perplexity2.8384487628936768
INFO:root:current mean train loss 1326.8379459824673
INFO:root:current train perplexity2.839827299118042
INFO:root:current mean train loss 1326.471845626831
INFO:root:current train perplexity2.8422045707702637
INFO:root:current mean train loss 1326.5682632158387
INFO:root:current train perplexity2.8427841663360596
INFO:root:current mean train loss 1327.1568781359442
INFO:root:current train perplexity2.844693422317505
INFO:root:current mean train loss 1328.0700279599143
INFO:root:current train perplexity2.8453776836395264
INFO:root:current mean train loss 1328.0864426556755
INFO:root:current train perplexity2.845991849899292
INFO:root:current mean train loss 1328.1883721338559
INFO:root:current train perplexity2.845221996307373
INFO:root:current mean train loss 1327.9075000469502
INFO:root:current train perplexity2.846342086791992
INFO:root:current mean train loss 1328.1400106039391
INFO:root:current train perplexity2.8482577800750732
INFO:root:current mean train loss 1328.5824883200905
INFO:root:current train perplexity2.8490195274353027
INFO:root:current mean train loss 1328.534157767347
INFO:root:current train perplexity2.850003480911255
INFO:root:current mean train loss 1328.74570555395
INFO:root:current train perplexity2.8504812717437744

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.62s/it]
INFO:root:final mean train loss: 1328.4272401841433
INFO:root:final train perplexity: 2.851022243499756
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it]
INFO:root:eval mean loss: 2214.5958494362258
INFO:root:eval perplexity: 5.9956560134887695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.41s/it]
INFO:root:eval mean loss: 2781.549300822806
INFO:root:eval perplexity: 9.726241111755371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/134
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [23:37:52<11:36:10, 632.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1308.8191948432427
INFO:root:current train perplexity2.8089048862457275
INFO:root:current mean train loss 1314.574500822078
INFO:root:current train perplexity2.825364589691162
INFO:root:current mean train loss 1315.2121339653372
INFO:root:current train perplexity2.821725606918335
INFO:root:current mean train loss 1315.8546330378606
INFO:root:current train perplexity2.824002265930176
INFO:root:current mean train loss 1316.32484752727
INFO:root:current train perplexity2.8256683349609375
INFO:root:current mean train loss 1317.2596653454018
INFO:root:current train perplexity2.8286726474761963
INFO:root:current mean train loss 1318.8561966641087
INFO:root:current train perplexity2.8313779830932617
INFO:root:current mean train loss 1319.542389033844
INFO:root:current train perplexity2.833624839782715
INFO:root:current mean train loss 1321.1189783285527
INFO:root:current train perplexity2.8350741863250732
INFO:root:current mean train loss 1321.4121680986918
INFO:root:current train perplexity2.8337409496307373
INFO:root:current mean train loss 1322.2636683613698
INFO:root:current train perplexity2.8385937213897705
INFO:root:current mean train loss 1321.9319737514602
INFO:root:current train perplexity2.838862657546997
INFO:root:current mean train loss 1321.9024895269981
INFO:root:current train perplexity2.8382861614227295
INFO:root:current mean train loss 1322.3932516836305
INFO:root:current train perplexity2.8393144607543945
INFO:root:current mean train loss 1322.993163897205
INFO:root:current train perplexity2.8405420780181885
INFO:root:current mean train loss 1323.555254581236
INFO:root:current train perplexity2.8408641815185547
INFO:root:current mean train loss 1324.026060301133
INFO:root:current train perplexity2.8421709537506104
INFO:root:current mean train loss 1324.895799077624
INFO:root:current train perplexity2.8429760932922363
INFO:root:current mean train loss 1325.2775144013053
INFO:root:current train perplexity2.844745635986328
INFO:root:current mean train loss 1325.7601812321186
INFO:root:current train perplexity2.8444161415100098

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.35s/it]
INFO:root:final mean train loss: 1325.4633899867624
INFO:root:final train perplexity: 2.8443655967712402
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.42s/it]
INFO:root:eval mean loss: 2218.6648698089816
INFO:root:eval perplexity: 6.015418529510498
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 2784.912927938691
INFO:root:eval perplexity: 9.753033638000488
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/135
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 135/200 [23:48:27<11:26:04, 633.30s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1306.8967311128656
INFO:root:current train perplexity2.806772232055664
INFO:root:current mean train loss 1312.1902088283264
INFO:root:current train perplexity2.817329168319702
INFO:root:current mean train loss 1313.3478024022108
INFO:root:current train perplexity2.818469762802124
INFO:root:current mean train loss 1315.753573190137
INFO:root:current train perplexity2.8158233165740967
INFO:root:current mean train loss 1316.301774368595
INFO:root:current train perplexity2.8203558921813965
INFO:root:current mean train loss 1318.6342323380288
INFO:root:current train perplexity2.8244781494140625
INFO:root:current mean train loss 1319.2943572558313
INFO:root:current train perplexity2.8262782096862793
INFO:root:current mean train loss 1319.557864402944
INFO:root:current train perplexity2.8288803100585938
INFO:root:current mean train loss 1321.3443589861229
INFO:root:current train perplexity2.8323512077331543
INFO:root:current mean train loss 1321.9472936250315
INFO:root:current train perplexity2.8337936401367188
INFO:root:current mean train loss 1321.9095941017054
INFO:root:current train perplexity2.8338348865509033
INFO:root:current mean train loss 1322.183017443173
INFO:root:current train perplexity2.8354568481445312
INFO:root:current mean train loss 1322.3247507086494
INFO:root:current train perplexity2.835338592529297
INFO:root:current mean train loss 1322.9754280517227
INFO:root:current train perplexity2.836595058441162
INFO:root:current mean train loss 1322.929353563342
INFO:root:current train perplexity2.836366891860962
INFO:root:current mean train loss 1322.8723166739776
INFO:root:current train perplexity2.8373959064483643
INFO:root:current mean train loss 1323.8718794965687
INFO:root:current train perplexity2.8389530181884766
INFO:root:current mean train loss 1323.928173120471
INFO:root:current train perplexity2.83975887298584
INFO:root:current mean train loss 1324.204400228724
INFO:root:current train perplexity2.840569257736206

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.55s/it]
INFO:root:final mean train loss: 1324.1882277126572
INFO:root:final train perplexity: 2.8415067195892334
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.45s/it]
INFO:root:eval mean loss: 2219.6264393042165
INFO:root:eval perplexity: 6.020097255706787
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.09s/it]
INFO:root:eval mean loss: 2786.77441276388
INFO:root:eval perplexity: 9.76789379119873
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/136
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 136/200 [23:59:08<11:18:05, 635.71s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1326.098788174716
INFO:root:current train perplexity2.8497915267944336
INFO:root:current mean train loss 1315.1453560494087
INFO:root:current train perplexity2.813570261001587
INFO:root:current mean train loss 1310.7424709808206
INFO:root:current train perplexity2.8187241554260254
INFO:root:current mean train loss 1313.372784678959
INFO:root:current train perplexity2.8165714740753174
INFO:root:current mean train loss 1313.9266900946625
INFO:root:current train perplexity2.81577205657959
INFO:root:current mean train loss 1313.8106517455815
INFO:root:current train perplexity2.816964626312256
INFO:root:current mean train loss 1314.7102120706961
INFO:root:current train perplexity2.8204920291900635
INFO:root:current mean train loss 1315.8213932772394
INFO:root:current train perplexity2.823709726333618
INFO:root:current mean train loss 1316.582331684456
INFO:root:current train perplexity2.8262181282043457
INFO:root:current mean train loss 1317.4787201028232
INFO:root:current train perplexity2.827359437942505
INFO:root:current mean train loss 1317.8058041233926
INFO:root:current train perplexity2.828001022338867
INFO:root:current mean train loss 1318.840913595754
INFO:root:current train perplexity2.82912540435791
INFO:root:current mean train loss 1318.736900978498
INFO:root:current train perplexity2.828584671020508
INFO:root:current mean train loss 1319.4399595631614
INFO:root:current train perplexity2.829833745956421
INFO:root:current mean train loss 1320.4357315809655
INFO:root:current train perplexity2.832639217376709
INFO:root:current mean train loss 1320.406566930401
INFO:root:current train perplexity2.8334615230560303
INFO:root:current mean train loss 1320.653167251028
INFO:root:current train perplexity2.834315538406372
INFO:root:current mean train loss 1320.7759304169253
INFO:root:current train perplexity2.8340091705322266
INFO:root:current mean train loss 1322.047783011695
INFO:root:current train perplexity2.8357651233673096
INFO:root:current mean train loss 1322.510033464257
INFO:root:current train perplexity2.8366668224334717

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.36s/it]
INFO:root:final mean train loss: 1322.1426150600416
INFO:root:final train perplexity: 2.8369264602661133
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.29s/it]
INFO:root:eval mean loss: 2223.3238616294047
INFO:root:eval perplexity: 6.038126468658447
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.82s/it]
INFO:root:eval mean loss: 2791.182851804909
INFO:root:eval perplexity: 9.80317211151123
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/137
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 137/200 [24:09:41<11:06:33, 634.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1304.1398402622767
INFO:root:current train perplexity2.7890446186065674
INFO:root:current mean train loss 1304.6830625534058
INFO:root:current train perplexity2.795501232147217
INFO:root:current mean train loss 1310.0870559424684
INFO:root:current train perplexity2.8029863834381104
INFO:root:current mean train loss 1313.219514800281
INFO:root:current train perplexity2.8090767860412598
INFO:root:current mean train loss 1311.79123010368
INFO:root:current train perplexity2.813735246658325
INFO:root:current mean train loss 1312.4300994873047
INFO:root:current train perplexity2.814851760864258
INFO:root:current mean train loss 1312.6594162473252
INFO:root:current train perplexity2.816638946533203
INFO:root:current mean train loss 1312.5332663399834
INFO:root:current train perplexity2.8173773288726807
INFO:root:current mean train loss 1313.9319726326614
INFO:root:current train perplexity2.820124387741089
INFO:root:current mean train loss 1314.5579589317585
INFO:root:current train perplexity2.8199410438537598
INFO:root:current mean train loss 1314.9753454779836
INFO:root:current train perplexity2.8210489749908447
INFO:root:current mean train loss 1315.6356025858129
INFO:root:current train perplexity2.824725389480591
INFO:root:current mean train loss 1316.6716538221128
INFO:root:current train perplexity2.8261566162109375
INFO:root:current mean train loss 1317.092126961214
INFO:root:current train perplexity2.828123092651367
INFO:root:current mean train loss 1316.972224815219
INFO:root:current train perplexity2.829249858856201
INFO:root:current mean train loss 1317.2637766094108
INFO:root:current train perplexity2.8294780254364014
INFO:root:current mean train loss 1317.3199446394638
INFO:root:current train perplexity2.829411745071411
INFO:root:current mean train loss 1318.1342132709644
INFO:root:current train perplexity2.829706907272339
INFO:root:current mean train loss 1319.8346430071074
INFO:root:current train perplexity2.8313708305358887
INFO:root:current mean train loss 1319.9335207484075
INFO:root:current train perplexity2.831486225128174

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.26s/it]
INFO:root:final mean train loss: 1319.865357122455
INFO:root:final train perplexity: 2.831835985183716
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.32s/it]
INFO:root:eval mean loss: 2222.3602831684952
INFO:root:eval perplexity: 6.033423900604248
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it]
INFO:root:eval mean loss: 2792.042202563996
INFO:root:eval perplexity: 9.810062408447266
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/138
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 138/200 [24:20:13<10:55:13, 634.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1307.6732611762152
INFO:root:current train perplexity2.823410987854004
INFO:root:current mean train loss 1311.0022410425647
INFO:root:current train perplexity2.81174898147583
INFO:root:current mean train loss 1309.9274698062818
INFO:root:current train perplexity2.8085553646087646
INFO:root:current mean train loss 1308.9338555819747
INFO:root:current train perplexity2.8069756031036377
INFO:root:current mean train loss 1307.764798487974
INFO:root:current train perplexity2.807630777359009
INFO:root:current mean train loss 1309.8068695348338
INFO:root:current train perplexity2.81000018119812
INFO:root:current mean train loss 1310.5758473004482
INFO:root:current train perplexity2.8101770877838135
INFO:root:current mean train loss 1310.7307182977663
INFO:root:current train perplexity2.8118624687194824
INFO:root:current mean train loss 1311.744945566753
INFO:root:current train perplexity2.813962936401367
INFO:root:current mean train loss 1312.5949067615327
INFO:root:current train perplexity2.815476417541504
INFO:root:current mean train loss 1313.2628436658943
INFO:root:current train perplexity2.81683349609375
INFO:root:current mean train loss 1314.346065497919
INFO:root:current train perplexity2.817092180252075
INFO:root:current mean train loss 1314.735738657756
INFO:root:current train perplexity2.819363594055176
INFO:root:current mean train loss 1315.377930776603
INFO:root:current train perplexity2.8204030990600586
INFO:root:current mean train loss 1316.2752611206477
INFO:root:current train perplexity2.8218016624450684
INFO:root:current mean train loss 1316.7285029044044
INFO:root:current train perplexity2.822258949279785
INFO:root:current mean train loss 1317.1445654593701
INFO:root:current train perplexity2.8240771293640137
INFO:root:current mean train loss 1317.4261778211185
INFO:root:current train perplexity2.8240652084350586
INFO:root:current mean train loss 1317.8084207343538
INFO:root:current train perplexity2.825014591217041
INFO:root:current mean train loss 1317.718853493031
INFO:root:current train perplexity2.8264029026031494

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.73s/it]
INFO:root:final mean train loss: 1317.4074099449815
INFO:root:final train perplexity: 2.8263518810272217
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.77s/it]
INFO:root:eval mean loss: 2228.017825295739
INFO:root:eval perplexity: 6.061091423034668
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.50s/it]
INFO:root:eval mean loss: 2795.2351649940438
INFO:root:eval perplexity: 9.835714340209961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/139
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 139/200 [24:30:54<10:46:51, 636.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1302.648640294229
INFO:root:current train perplexity2.8057079315185547
INFO:root:current mean train loss 1307.0602605372299
INFO:root:current train perplexity2.801283121109009
INFO:root:current mean train loss 1309.9559433332836
INFO:root:current train perplexity2.802739143371582
INFO:root:current mean train loss 1311.9550966715944
INFO:root:current train perplexity2.8030130863189697
INFO:root:current mean train loss 1313.090969333401
INFO:root:current train perplexity2.807143211364746
INFO:root:current mean train loss 1312.917906194395
INFO:root:current train perplexity2.805246353149414
INFO:root:current mean train loss 1311.5081198885362
INFO:root:current train perplexity2.8063392639160156
INFO:root:current mean train loss 1311.9023323759945
INFO:root:current train perplexity2.809087038040161
INFO:root:current mean train loss 1313.519655302893
INFO:root:current train perplexity2.8107669353485107
INFO:root:current mean train loss 1314.6416533345243
INFO:root:current train perplexity2.810359001159668
INFO:root:current mean train loss 1316.2277671109935
INFO:root:current train perplexity2.813201665878296
INFO:root:current mean train loss 1316.037921741374
INFO:root:current train perplexity2.814981698989868
INFO:root:current mean train loss 1315.1937751105017
INFO:root:current train perplexity2.8138694763183594
INFO:root:current mean train loss 1314.6359629357964
INFO:root:current train perplexity2.8139865398406982
INFO:root:current mean train loss 1314.5044448789918
INFO:root:current train perplexity2.8144989013671875
INFO:root:current mean train loss 1314.517656509458
INFO:root:current train perplexity2.8156838417053223
INFO:root:current mean train loss 1315.3677471725518
INFO:root:current train perplexity2.816946506500244
INFO:root:current mean train loss 1315.7097158269632
INFO:root:current train perplexity2.8186726570129395
INFO:root:current mean train loss 1315.5699746759826
INFO:root:current train perplexity2.8205032348632812
INFO:root:current mean train loss 1315.7834325201286
INFO:root:current train perplexity2.821521520614624

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.87s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.87s/it]
INFO:root:final mean train loss: 1315.4356079409354
INFO:root:final train perplexity: 2.8219597339630127
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.70s/it]
INFO:root:eval mean loss: 2227.869761798399
INFO:root:eval perplexity: 6.060366630554199
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.53s/it]
INFO:root:eval mean loss: 2798.230646228114
INFO:root:eval perplexity: 9.859841346740723
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/140
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [24:41:22<10:33:36, 633.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1300.4227573056764
INFO:root:current train perplexity2.8134732246398926
INFO:root:current mean train loss 1308.3598919234462
INFO:root:current train perplexity2.8091721534729004
INFO:root:current mean train loss 1304.5680653561828
INFO:root:current train perplexity2.8042821884155273
INFO:root:current mean train loss 1305.4342775370012
INFO:root:current train perplexity2.80273175239563
INFO:root:current mean train loss 1307.3607618614626
INFO:root:current train perplexity2.806945562362671
INFO:root:current mean train loss 1306.884632380721
INFO:root:current train perplexity2.805903673171997
INFO:root:current mean train loss 1308.6651223004303
INFO:root:current train perplexity2.8076581954956055
INFO:root:current mean train loss 1309.5299753916279
INFO:root:current train perplexity2.807872772216797
INFO:root:current mean train loss 1309.9503362696869
INFO:root:current train perplexity2.8110334873199463
INFO:root:current mean train loss 1311.0941709493104
INFO:root:current train perplexity2.813467025756836
INFO:root:current mean train loss 1312.0996217064774
INFO:root:current train perplexity2.8138859272003174
INFO:root:current mean train loss 1311.943955852583
INFO:root:current train perplexity2.8133633136749268
INFO:root:current mean train loss 1312.1145068206667
INFO:root:current train perplexity2.813694715499878
INFO:root:current mean train loss 1312.205773899225
INFO:root:current train perplexity2.813314437866211
INFO:root:current mean train loss 1313.745814284092
INFO:root:current train perplexity2.814775228500366
INFO:root:current mean train loss 1313.9832617558582
INFO:root:current train perplexity2.816551923751831
INFO:root:current mean train loss 1314.1392049420228
INFO:root:current train perplexity2.8172953128814697
INFO:root:current mean train loss 1313.7954341037143
INFO:root:current train perplexity2.8171122074127197
INFO:root:current mean train loss 1313.8464016998112
INFO:root:current train perplexity2.8175647258758545
INFO:root:current mean train loss 1314.0105253723668
INFO:root:current train perplexity2.8179304599761963

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.60s/it]
INFO:root:final mean train loss: 1313.6866515405359
INFO:root:final train perplexity: 2.81807017326355
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it]
INFO:root:eval mean loss: 2229.48789209677
INFO:root:eval perplexity: 6.068302154541016
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it]
INFO:root:eval mean loss: 2799.9921580646055
INFO:root:eval perplexity: 9.874054908752441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/141
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 141/200 [24:52:01<10:24:41, 635.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1304.5251846313477
INFO:root:current train perplexity2.797485113143921
INFO:root:current mean train loss 1303.4690944126673
INFO:root:current train perplexity2.8029379844665527
INFO:root:current mean train loss 1303.0013687546189
INFO:root:current train perplexity2.7969045639038086
INFO:root:current mean train loss 1304.2526642770479
INFO:root:current train perplexity2.799053430557251
INFO:root:current mean train loss 1305.2843455653037
INFO:root:current train perplexity2.8000295162200928
INFO:root:current mean train loss 1307.1862756101877
INFO:root:current train perplexity2.8012728691101074
INFO:root:current mean train loss 1306.4006119651356
INFO:root:current train perplexity2.799739122390747
INFO:root:current mean train loss 1306.3528905513897
INFO:root:current train perplexity2.801431179046631
INFO:root:current mean train loss 1307.2256110055107
INFO:root:current train perplexity2.8033807277679443
INFO:root:current mean train loss 1308.0939073677523
INFO:root:current train perplexity2.8044044971466064
INFO:root:current mean train loss 1309.182786482094
INFO:root:current train perplexity2.8057851791381836
INFO:root:current mean train loss 1308.7961103254338
INFO:root:current train perplexity2.8061087131500244
INFO:root:current mean train loss 1308.6744808620876
INFO:root:current train perplexity2.8060615062713623
INFO:root:current mean train loss 1309.2283635617669
INFO:root:current train perplexity2.806018829345703
INFO:root:current mean train loss 1309.488217277323
INFO:root:current train perplexity2.8060595989227295
INFO:root:current mean train loss 1310.6262234565907
INFO:root:current train perplexity2.8080832958221436
INFO:root:current mean train loss 1310.9958629248276
INFO:root:current train perplexity2.8102822303771973
INFO:root:current mean train loss 1312.021577762867
INFO:root:current train perplexity2.8113460540771484
INFO:root:current mean train loss 1312.0424616045086
INFO:root:current train perplexity2.812753438949585

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.57s/it]
INFO:root:final mean train loss: 1311.495996210711
INFO:root:final train perplexity: 2.8132057189941406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it]
INFO:root:eval mean loss: 2231.5806360988754
INFO:root:eval perplexity: 6.078581809997559
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.38s/it]
INFO:root:eval mean loss: 2803.350779864805
INFO:root:eval perplexity: 9.901216506958008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/142
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 142/200 [25:02:35<10:13:43, 634.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1328.722891000601
INFO:root:current train perplexity2.7837274074554443
INFO:root:current mean train loss 1317.9516839221515
INFO:root:current train perplexity2.7985715866088867
INFO:root:current mean train loss 1311.5981267651482
INFO:root:current train perplexity2.7872369289398193
INFO:root:current mean train loss 1309.150885926268
INFO:root:current train perplexity2.7892918586730957
INFO:root:current mean train loss 1308.4610962209633
INFO:root:current train perplexity2.7900264263153076
INFO:root:current mean train loss 1307.2372832716558
INFO:root:current train perplexity2.790982484817505
INFO:root:current mean train loss 1307.3584500137006
INFO:root:current train perplexity2.793302059173584
INFO:root:current mean train loss 1306.2313544017904
INFO:root:current train perplexity2.7959156036376953
INFO:root:current mean train loss 1306.4079197957508
INFO:root:current train perplexity2.7967655658721924
INFO:root:current mean train loss 1306.171306497296
INFO:root:current train perplexity2.7970237731933594
INFO:root:current mean train loss 1306.3305467641364
INFO:root:current train perplexity2.7986342906951904
INFO:root:current mean train loss 1306.7030244263462
INFO:root:current train perplexity2.79954195022583
INFO:root:current mean train loss 1306.7071721390664
INFO:root:current train perplexity2.8002724647521973
INFO:root:current mean train loss 1307.374960208611
INFO:root:current train perplexity2.801118850708008
INFO:root:current mean train loss 1307.8657099567906
INFO:root:current train perplexity2.8015105724334717
INFO:root:current mean train loss 1308.5332003818469
INFO:root:current train perplexity2.801851511001587
INFO:root:current mean train loss 1308.5870174400864
INFO:root:current train perplexity2.80346417427063
INFO:root:current mean train loss 1308.747417354194
INFO:root:current train perplexity2.804340124130249
INFO:root:current mean train loss 1309.036736296345
INFO:root:current train perplexity2.8050858974456787
INFO:root:current mean train loss 1309.3399535686135
INFO:root:current train perplexity2.806598424911499

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.56s/it]
INFO:root:final mean train loss: 1309.0744320806446
INFO:root:final train perplexity: 2.807837963104248
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.93s/it]
INFO:root:eval mean loss: 2233.306862689079
INFO:root:eval perplexity: 6.0870747566223145
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it]
INFO:root:eval mean loss: 2805.445380028258
INFO:root:eval perplexity: 9.918190002441406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/143
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 143/200 [25:13:23<10:06:49, 638.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1298.9458862304687
INFO:root:current train perplexity2.7611517906188965
INFO:root:current mean train loss 1302.8133554311898
INFO:root:current train perplexity2.779156446456909
INFO:root:current mean train loss 1307.3360558551292
INFO:root:current train perplexity2.7795825004577637
INFO:root:current mean train loss 1305.8255396987452
INFO:root:current train perplexity2.7823925018310547
INFO:root:current mean train loss 1306.961184763354
INFO:root:current train perplexity2.78444766998291
INFO:root:current mean train loss 1306.0462922869988
INFO:root:current train perplexity2.789041042327881
INFO:root:current mean train loss 1306.410574389261
INFO:root:current train perplexity2.7928106784820557
INFO:root:current mean train loss 1305.9940295911815
INFO:root:current train perplexity2.7948412895202637
INFO:root:current mean train loss 1306.505876582502
INFO:root:current train perplexity2.7959535121917725
INFO:root:current mean train loss 1306.1479964717741
INFO:root:current train perplexity2.7958853244781494
INFO:root:current mean train loss 1306.7053629162242
INFO:root:current train perplexity2.798471450805664
INFO:root:current mean train loss 1307.962685482059
INFO:root:current train perplexity2.800180435180664
INFO:root:current mean train loss 1307.3588071249364
INFO:root:current train perplexity2.799710512161255
INFO:root:current mean train loss 1307.8615392240367
INFO:root:current train perplexity2.800690174102783
INFO:root:current mean train loss 1307.9027138876747
INFO:root:current train perplexity2.802053213119507
INFO:root:current mean train loss 1307.1417307336346
INFO:root:current train perplexity2.8020074367523193
INFO:root:current mean train loss 1307.5026029434673
INFO:root:current train perplexity2.8033547401428223
INFO:root:current mean train loss 1307.8388201233968
INFO:root:current train perplexity2.8044803142547607
INFO:root:current mean train loss 1307.991125354871
INFO:root:current train perplexity2.804490804672241
INFO:root:current mean train loss 1308.2442299323995
INFO:root:current train perplexity2.8044426441192627

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:21<00:00, 561.23s/it]
INFO:root:final mean train loss: 1307.713165206255
INFO:root:final train perplexity: 2.8048255443573
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.02s/it]
INFO:root:eval mean loss: 2236.4446692500555
INFO:root:eval perplexity: 6.102540016174316
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it]
INFO:root:eval mean loss: 2808.321586446559
INFO:root:eval perplexity: 9.941547393798828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/144
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 144/200 [25:24:02<9:56:15, 638.86s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1284.2180954953458
INFO:root:current train perplexity2.7764394283294678
INFO:root:current mean train loss 1294.6199760177508
INFO:root:current train perplexity2.777245044708252
INFO:root:current mean train loss 1295.937874612538
INFO:root:current train perplexity2.77754282951355
INFO:root:current mean train loss 1297.7424618943623
INFO:root:current train perplexity2.7801780700683594
INFO:root:current mean train loss 1299.7433134416071
INFO:root:current train perplexity2.7846434116363525
INFO:root:current mean train loss 1299.3559958616602
INFO:root:current train perplexity2.7821543216705322
INFO:root:current mean train loss 1300.4608254292648
INFO:root:current train perplexity2.7872421741485596
INFO:root:current mean train loss 1302.036575991466
INFO:root:current train perplexity2.7883243560791016
INFO:root:current mean train loss 1303.170067437002
INFO:root:current train perplexity2.789729356765747
INFO:root:current mean train loss 1303.867002138744
INFO:root:current train perplexity2.7915501594543457
INFO:root:current mean train loss 1303.9867049456782
INFO:root:current train perplexity2.79288649559021
INFO:root:current mean train loss 1303.7996754866635
INFO:root:current train perplexity2.793281078338623
INFO:root:current mean train loss 1304.3341329738246
INFO:root:current train perplexity2.793912410736084
INFO:root:current mean train loss 1305.1502342082522
INFO:root:current train perplexity2.794463634490967
INFO:root:current mean train loss 1305.4472042102195
INFO:root:current train perplexity2.7956948280334473
INFO:root:current mean train loss 1305.4978291684763
INFO:root:current train perplexity2.795771598815918
INFO:root:current mean train loss 1305.7379191896014
INFO:root:current train perplexity2.7965359687805176
INFO:root:current mean train loss 1305.572190859554
INFO:root:current train perplexity2.79777455329895
INFO:root:current mean train loss 1305.7977684198615
INFO:root:current train perplexity2.7986152172088623
INFO:root:current mean train loss 1305.8517475177155
INFO:root:current train perplexity2.799109935760498

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.98s/it]
INFO:root:final mean train loss: 1305.2879050481338
INFO:root:final train perplexity: 2.7994654178619385
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it]
INFO:root:eval mean loss: 2238.8995685983214
INFO:root:eval perplexity: 6.1146674156188965
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.63s/it]
INFO:root:eval mean loss: 2811.1745791604335
INFO:root:eval perplexity: 9.96476936340332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/145
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 145/200 [25:34:36<9:44:17, 637.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1297.5447025299072
INFO:root:current train perplexity2.7727630138397217
INFO:root:current mean train loss 1297.1041468178353
INFO:root:current train perplexity2.7764692306518555
INFO:root:current mean train loss 1290.4604168516216
INFO:root:current train perplexity2.7748184204101562
INFO:root:current mean train loss 1292.9064609401828
INFO:root:current train perplexity2.7762722969055176
INFO:root:current mean train loss 1294.0632697796
INFO:root:current train perplexity2.7816803455352783
INFO:root:current mean train loss 1295.9347192209664
INFO:root:current train perplexity2.7849953174591064
INFO:root:current mean train loss 1296.1715593452914
INFO:root:current train perplexity2.7857096195220947
INFO:root:current mean train loss 1297.4158440235396
INFO:root:current train perplexity2.784212350845337
INFO:root:current mean train loss 1297.0554621661151
INFO:root:current train perplexity2.7850306034088135
INFO:root:current mean train loss 1297.81778992459
INFO:root:current train perplexity2.7872092723846436
INFO:root:current mean train loss 1299.106439690841
INFO:root:current train perplexity2.7904398441314697
INFO:root:current mean train loss 1299.2113907542016
INFO:root:current train perplexity2.790797472000122
INFO:root:current mean train loss 1299.8898049849497
INFO:root:current train perplexity2.7910943031311035
INFO:root:current mean train loss 1300.088885175867
INFO:root:current train perplexity2.791334867477417
INFO:root:current mean train loss 1300.7740282569428
INFO:root:current train perplexity2.7916226387023926
INFO:root:current mean train loss 1301.5851304622563
INFO:root:current train perplexity2.7928225994110107
INFO:root:current mean train loss 1301.7901087540847
INFO:root:current train perplexity2.792961359024048
INFO:root:current mean train loss 1302.1186723427977
INFO:root:current train perplexity2.7939422130584717
INFO:root:current mean train loss 1303.1851511288098
INFO:root:current train perplexity2.7955079078674316
INFO:root:current mean train loss 1303.5291631197492
INFO:root:current train perplexity2.7951347827911377

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.51s/it]
INFO:root:final mean train loss: 1303.2963498144875
INFO:root:final train perplexity: 2.795072317123413
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.18s/it]
INFO:root:eval mean loss: 2239.8067271996897
INFO:root:eval perplexity: 6.1191558837890625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.98s/it]
INFO:root:eval mean loss: 2811.7607846090978
INFO:root:eval perplexity: 9.969551086425781
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/146
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [25:45:23<9:36:14, 640.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1308.984748746142
INFO:root:current train perplexity2.788414478302002
INFO:root:current mean train loss 1303.0182296162811
INFO:root:current train perplexity2.7809195518493652
INFO:root:current mean train loss 1301.1315392327901
INFO:root:current train perplexity2.7802045345306396
INFO:root:current mean train loss 1299.6050423048925
INFO:root:current train perplexity2.784005880355835
INFO:root:current mean train loss 1298.9277011292393
INFO:root:current train perplexity2.7815141677856445
INFO:root:current mean train loss 1299.0195680181664
INFO:root:current train perplexity2.7830896377563477
INFO:root:current mean train loss 1298.6397975747982
INFO:root:current train perplexity2.784019708633423
INFO:root:current mean train loss 1298.6904112440982
INFO:root:current train perplexity2.7847821712493896
INFO:root:current mean train loss 1300.2328714983416
INFO:root:current train perplexity2.786259889602661
INFO:root:current mean train loss 1299.7569012656488
INFO:root:current train perplexity2.787574291229248
INFO:root:current mean train loss 1299.9214159659386
INFO:root:current train perplexity2.787868022918701
INFO:root:current mean train loss 1300.0472038973196
INFO:root:current train perplexity2.7878856658935547
INFO:root:current mean train loss 1299.4634362726263
INFO:root:current train perplexity2.78861927986145
INFO:root:current mean train loss 1299.2700298731954
INFO:root:current train perplexity2.7880191802978516
INFO:root:current mean train loss 1299.76782721108
INFO:root:current train perplexity2.7879464626312256
INFO:root:current mean train loss 1299.8475866058368
INFO:root:current train perplexity2.7880401611328125
INFO:root:current mean train loss 1300.4623003885335
INFO:root:current train perplexity2.7886910438537598
INFO:root:current mean train loss 1301.0496780935264
INFO:root:current train perplexity2.7891626358032227
INFO:root:current mean train loss 1301.005606213762
INFO:root:current train perplexity2.7893240451812744
INFO:root:current mean train loss 1301.3647693863184
INFO:root:current train perplexity2.789905548095703

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.06s/it]
INFO:root:final mean train loss: 1301.0016115066444
INFO:root:final train perplexity: 2.790018320083618
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.78s/it]
INFO:root:eval mean loss: 2240.7919692452074
INFO:root:eval perplexity: 6.1240339279174805
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.11s/it]
INFO:root:eval mean loss: 2814.31718195922
INFO:root:eval perplexity: 9.990413665771484
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/147
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 147/200 [25:55:58<9:24:14, 638.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1289.3552719427614
INFO:root:current train perplexity2.7788801193237305
INFO:root:current mean train loss 1293.4168399078678
INFO:root:current train perplexity2.7732062339782715
INFO:root:current mean train loss 1292.1096879587878
INFO:root:current train perplexity2.7794930934906006
INFO:root:current mean train loss 1291.118980522731
INFO:root:current train perplexity2.775874376296997
INFO:root:current mean train loss 1295.294554683578
INFO:root:current train perplexity2.7780001163482666
INFO:root:current mean train loss 1296.4918288419078
INFO:root:current train perplexity2.7790298461914062
INFO:root:current mean train loss 1296.180878647419
INFO:root:current train perplexity2.7778444290161133
INFO:root:current mean train loss 1295.9787152512629
INFO:root:current train perplexity2.7777721881866455
INFO:root:current mean train loss 1296.0236484722996
INFO:root:current train perplexity2.778681993484497
INFO:root:current mean train loss 1296.186765498771
INFO:root:current train perplexity2.7790896892547607
INFO:root:current mean train loss 1297.3141910851762
INFO:root:current train perplexity2.7806308269500732
INFO:root:current mean train loss 1297.409142903374
INFO:root:current train perplexity2.7812983989715576
INFO:root:current mean train loss 1297.6981809642539
INFO:root:current train perplexity2.7825675010681152
INFO:root:current mean train loss 1297.519508372731
INFO:root:current train perplexity2.782674789428711
INFO:root:current mean train loss 1297.9743187042359
INFO:root:current train perplexity2.7822721004486084
INFO:root:current mean train loss 1298.5677053286825
INFO:root:current train perplexity2.7831621170043945
INFO:root:current mean train loss 1298.7803759535575
INFO:root:current train perplexity2.783681869506836
INFO:root:current mean train loss 1299.2137580846122
INFO:root:current train perplexity2.7852556705474854
INFO:root:current mean train loss 1299.6502229551872
INFO:root:current train perplexity2.7859838008880615

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.37s/it]
INFO:root:final mean train loss: 1299.7134098393474
INFO:root:final train perplexity: 2.7871851921081543
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.06s/it]
INFO:root:eval mean loss: 2242.4911382147607
INFO:root:eval perplexity: 6.132455348968506
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:39<00:00, 39.17s/it]
INFO:root:eval mean loss: 2817.8506244632367
INFO:root:eval perplexity: 10.019323348999023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/148
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 148/200 [26:06:33<9:12:35, 637.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1308.4247395833333
INFO:root:current train perplexity2.786301851272583
INFO:root:current mean train loss 1301.778664232337
INFO:root:current train perplexity2.779463291168213
INFO:root:current mean train loss 1288.8195062681687
INFO:root:current train perplexity2.7770023345947266
INFO:root:current mean train loss 1291.9499345083086
INFO:root:current train perplexity2.781458854675293
INFO:root:current mean train loss 1292.2069465361446
INFO:root:current train perplexity2.7768545150756836
INFO:root:current mean train loss 1292.7382513842535
INFO:root:current train perplexity2.776942491531372
INFO:root:current mean train loss 1293.7157659267023
INFO:root:current train perplexity2.776280403137207
INFO:root:current mean train loss 1294.8813136814358
INFO:root:current train perplexity2.7758238315582275
INFO:root:current mean train loss 1295.5446856726899
INFO:root:current train perplexity2.774339199066162
INFO:root:current mean train loss 1296.202017828936
INFO:root:current train perplexity2.7762391567230225
INFO:root:current mean train loss 1296.6361913821968
INFO:root:current train perplexity2.7772507667541504
INFO:root:current mean train loss 1296.7488306430423
INFO:root:current train perplexity2.779526472091675
INFO:root:current mean train loss 1296.9483743047517
INFO:root:current train perplexity2.7787082195281982
INFO:root:current mean train loss 1297.5699732095115
INFO:root:current train perplexity2.779115915298462
INFO:root:current mean train loss 1296.9522197817746
INFO:root:current train perplexity2.779740810394287
INFO:root:current mean train loss 1296.7230252004692
INFO:root:current train perplexity2.780059337615967
INFO:root:current mean train loss 1297.029571476514
INFO:root:current train perplexity2.7813026905059814
INFO:root:current mean train loss 1297.588146509999
INFO:root:current train perplexity2.7822203636169434
INFO:root:current mean train loss 1297.6375542086346
INFO:root:current train perplexity2.7824912071228027
INFO:root:current mean train loss 1298.0910738872797
INFO:root:current train perplexity2.783714771270752

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.57s/it]
INFO:root:final mean train loss: 1298.3708061491427
INFO:root:final train perplexity: 2.7842354774475098
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:41<00:00, 41.45s/it]
INFO:root:eval mean loss: 2244.8891008525875
INFO:root:eval perplexity: 6.144360065460205
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it]
INFO:root:eval mean loss: 2820.031735684009
INFO:root:eval perplexity: 10.037212371826172
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/149
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 149/200 [26:17:24<9:05:22, 641.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1286.9189834594727
INFO:root:current train perplexity2.7824840545654297
INFO:root:current mean train loss 1290.2728197502367
INFO:root:current train perplexity2.7620882987976074
INFO:root:current mean train loss 1290.0781739333581
INFO:root:current train perplexity2.7708699703216553
INFO:root:current mean train loss 1287.8477408167828
INFO:root:current train perplexity2.7705321311950684
INFO:root:current mean train loss 1290.3214868616176
INFO:root:current train perplexity2.7684144973754883
INFO:root:current mean train loss 1290.6109268073749
INFO:root:current train perplexity2.767268180847168
INFO:root:current mean train loss 1291.6635852282561
INFO:root:current train perplexity2.7689273357391357
INFO:root:current mean train loss 1291.7906110586364
INFO:root:current train perplexity2.7705767154693604
INFO:root:current mean train loss 1292.5448689093957
INFO:root:current train perplexity2.770909309387207
INFO:root:current mean train loss 1293.3355829459915
INFO:root:current train perplexity2.773155927658081
INFO:root:current mean train loss 1294.0684478523194
INFO:root:current train perplexity2.772397041320801
INFO:root:current mean train loss 1294.0764049085205
INFO:root:current train perplexity2.7734429836273193
INFO:root:current mean train loss 1293.6916121445693
INFO:root:current train perplexity2.7728774547576904
INFO:root:current mean train loss 1293.9457691639393
INFO:root:current train perplexity2.7732012271881104
INFO:root:current mean train loss 1294.3223044113074
INFO:root:current train perplexity2.773353338241577
INFO:root:current mean train loss 1294.7446918537348
INFO:root:current train perplexity2.775717258453369
INFO:root:current mean train loss 1295.1344410017425
INFO:root:current train perplexity2.7762084007263184
INFO:root:current mean train loss 1295.744538481186
INFO:root:current train perplexity2.7772417068481445
INFO:root:current mean train loss 1295.8224960393782
INFO:root:current train perplexity2.7766075134277344
INFO:root:current mean train loss 1295.9211766971564
INFO:root:current train perplexity2.777811050415039

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.90s/it]
INFO:root:final mean train loss: 1295.6960902288595
INFO:root:final train perplexity: 2.7783687114715576
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.50s/it]
INFO:root:eval mean loss: 2246.5483567258143
INFO:root:eval perplexity: 6.1526103019714355
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it]
INFO:root:eval mean loss: 2823.9431130700077
INFO:root:eval perplexity: 10.069371223449707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/150
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [26:28:00<8:53:13, 639.88s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1288.1604452327806
INFO:root:current train perplexity2.7472848892211914
INFO:root:current mean train loss 1284.4384446112101
INFO:root:current train perplexity2.7531018257141113
INFO:root:current mean train loss 1283.2804661026921
INFO:root:current train perplexity2.7527379989624023
INFO:root:current mean train loss 1284.5015417935172
INFO:root:current train perplexity2.754878282546997
INFO:root:current mean train loss 1286.0155964534904
INFO:root:current train perplexity2.753169536590576
INFO:root:current mean train loss 1285.875998352829
INFO:root:current train perplexity2.7557551860809326
INFO:root:current mean train loss 1288.137764153385
INFO:root:current train perplexity2.7608940601348877
INFO:root:current mean train loss 1288.8474988135222
INFO:root:current train perplexity2.76214337348938
INFO:root:current mean train loss 1290.7426237324241
INFO:root:current train perplexity2.7626633644104004
INFO:root:current mean train loss 1290.5351966399664
INFO:root:current train perplexity2.765059471130371
INFO:root:current mean train loss 1291.2096245168389
INFO:root:current train perplexity2.765810012817383
INFO:root:current mean train loss 1291.7517070720464
INFO:root:current train perplexity2.7666900157928467
INFO:root:current mean train loss 1291.8204718071331
INFO:root:current train perplexity2.7676796913146973
INFO:root:current mean train loss 1292.3013989312105
INFO:root:current train perplexity2.7689082622528076
INFO:root:current mean train loss 1292.4611426354113
INFO:root:current train perplexity2.7695586681365967
INFO:root:current mean train loss 1293.1987999755386
INFO:root:current train perplexity2.7709836959838867
INFO:root:current mean train loss 1293.152572196928
INFO:root:current train perplexity2.771141290664673
INFO:root:current mean train loss 1293.649654573819
INFO:root:current train perplexity2.77227783203125
INFO:root:current mean train loss 1293.8060511356434
INFO:root:current train perplexity2.7730627059936523
INFO:root:current mean train loss 1294.2453250640353
INFO:root:current train perplexity2.773853302001953

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.15s/it]
INFO:root:final mean train loss: 1293.8896080551879
INFO:root:final train perplexity: 2.7744128704071045
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.68s/it]
INFO:root:eval mean loss: 2246.0796712239585
INFO:root:eval perplexity: 6.150278091430664
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it]
INFO:root:eval mean loss: 2823.1678137813055
INFO:root:eval perplexity: 10.062987327575684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/151
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 151/200 [26:38:42<8:43:01, 640.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1288.7351684570312
INFO:root:current train perplexity2.768617868423462
INFO:root:current mean train loss 1286.2231967420464
INFO:root:current train perplexity2.7597320079803467
INFO:root:current mean train loss 1284.8706408048931
INFO:root:current train perplexity2.7523176670074463
INFO:root:current mean train loss 1286.4626858403774
INFO:root:current train perplexity2.7561089992523193
INFO:root:current mean train loss 1285.5472430446118
INFO:root:current train perplexity2.757906913757324
INFO:root:current mean train loss 1285.8302411729792
INFO:root:current train perplexity2.7605576515197754
INFO:root:current mean train loss 1287.0329036311703
INFO:root:current train perplexity2.762907028198242
INFO:root:current mean train loss 1286.8971764786124
INFO:root:current train perplexity2.7607815265655518
INFO:root:current mean train loss 1287.1573170580434
INFO:root:current train perplexity2.762472629547119
INFO:root:current mean train loss 1287.7599250998803
INFO:root:current train perplexity2.7630271911621094
INFO:root:current mean train loss 1288.52778279088
INFO:root:current train perplexity2.7644240856170654
INFO:root:current mean train loss 1289.0282716309432
INFO:root:current train perplexity2.7660748958587646
INFO:root:current mean train loss 1290.3150885462949
INFO:root:current train perplexity2.768968343734741
INFO:root:current mean train loss 1290.324362982419
INFO:root:current train perplexity2.7694480419158936
INFO:root:current mean train loss 1291.8524627893717
INFO:root:current train perplexity2.7708640098571777
INFO:root:current mean train loss 1292.0423923068577
INFO:root:current train perplexity2.770742416381836
INFO:root:current mean train loss 1292.0525163922991
INFO:root:current train perplexity2.7711896896362305
INFO:root:current mean train loss 1292.3553381776217
INFO:root:current train perplexity2.7715799808502197
INFO:root:current mean train loss 1292.7685917796045
INFO:root:current train perplexity2.7721331119537354
INFO:root:current mean train loss 1292.8480466142191
INFO:root:current train perplexity2.771120309829712

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.94s/it]
INFO:root:final mean train loss: 1292.496020218488
INFO:root:final train perplexity: 2.7713658809661865
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.66s/it]
INFO:root:eval mean loss: 2251.0756853252437
INFO:root:eval perplexity: 6.175179481506348
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.51s/it]
INFO:root:eval mean loss: 2828.6683704565603
INFO:root:eval perplexity: 10.108357429504395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/152
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 152/200 [26:49:14<8:30:24, 638.00s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1278.935876317771
INFO:root:current train perplexity2.7469394207000732
INFO:root:current mean train loss 1284.686719550461
INFO:root:current train perplexity2.7561686038970947
INFO:root:current mean train loss 1283.7504033065095
INFO:root:current train perplexity2.7528324127197266
INFO:root:current mean train loss 1286.7452386203697
INFO:root:current train perplexity2.756335735321045
INFO:root:current mean train loss 1287.6797534634609
INFO:root:current train perplexity2.754244089126587
INFO:root:current mean train loss 1287.7071809588738
INFO:root:current train perplexity2.755606174468994
INFO:root:current mean train loss 1287.3122385228885
INFO:root:current train perplexity2.755941152572632
INFO:root:current mean train loss 1288.7586557673312
INFO:root:current train perplexity2.760446548461914
INFO:root:current mean train loss 1288.5083939583628
INFO:root:current train perplexity2.7590231895446777
INFO:root:current mean train loss 1289.244180114684
INFO:root:current train perplexity2.761042356491089
INFO:root:current mean train loss 1288.8932752670894
INFO:root:current train perplexity2.7618894577026367
INFO:root:current mean train loss 1289.3054617126413
INFO:root:current train perplexity2.762235641479492
INFO:root:current mean train loss 1289.3267962127948
INFO:root:current train perplexity2.7631428241729736
INFO:root:current mean train loss 1289.6236725846495
INFO:root:current train perplexity2.7636425495147705
INFO:root:current mean train loss 1289.3321151270388
INFO:root:current train perplexity2.762990951538086
INFO:root:current mean train loss 1289.2861451506237
INFO:root:current train perplexity2.7631516456604004
INFO:root:current mean train loss 1289.3189960554535
INFO:root:current train perplexity2.7631757259368896
INFO:root:current mean train loss 1289.3362057397558
INFO:root:current train perplexity2.764307737350464
INFO:root:current mean train loss 1289.7724335154383
INFO:root:current train perplexity2.7649214267730713
INFO:root:current mean train loss 1289.9473338317102
INFO:root:current train perplexity2.765800714492798

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.27s/it]
INFO:root:final mean train loss: 1289.9473338317102
INFO:root:final train perplexity: 2.765800714492798
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.52s/it]
INFO:root:eval mean loss: 2250.7644726908798
INFO:root:eval perplexity: 6.1736249923706055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 2827.508193861508
INFO:root:eval perplexity: 10.098775863647461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/153
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 153/200 [26:59:43<8:17:37, 635.27s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1288.949940185547
INFO:root:current train perplexity2.772627115249634
INFO:root:current mean train loss 1286.1029382324218
INFO:root:current train perplexity2.7654874324798584
INFO:root:current mean train loss 1289.4102685546875
INFO:root:current train perplexity2.762598752975464
INFO:root:current mean train loss 1288.391389465332
INFO:root:current train perplexity2.759183645248413
INFO:root:current mean train loss 1288.1886845703125
INFO:root:current train perplexity2.758863687515259
INFO:root:current mean train loss 1287.1418223063151
INFO:root:current train perplexity2.7560641765594482
INFO:root:current mean train loss 1287.6411872209821
INFO:root:current train perplexity2.7571277618408203
INFO:root:current mean train loss 1287.0592446899414
INFO:root:current train perplexity2.7552616596221924
INFO:root:current mean train loss 1287.1300796169705
INFO:root:current train perplexity2.7570018768310547
INFO:root:current mean train loss 1287.6148406982422
INFO:root:current train perplexity2.7579360008239746
INFO:root:current mean train loss 1288.7181768243963
INFO:root:current train perplexity2.7584240436553955
INFO:root:current mean train loss 1287.5274994913736
INFO:root:current train perplexity2.7581186294555664
INFO:root:current mean train loss 1287.4679345703125
INFO:root:current train perplexity2.757681369781494
INFO:root:current mean train loss 1287.813603515625
INFO:root:current train perplexity2.759086847305298
INFO:root:current mean train loss 1288.2900336914063
INFO:root:current train perplexity2.758538246154785
INFO:root:current mean train loss 1288.8864014434814
INFO:root:current train perplexity2.759361982345581
INFO:root:current mean train loss 1288.1234663660387
INFO:root:current train perplexity2.7602744102478027
INFO:root:current mean train loss 1288.2226546223958
INFO:root:current train perplexity2.7604780197143555
INFO:root:current mean train loss 1288.2816127415708
INFO:root:current train perplexity2.7610881328582764

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.49s/it]
INFO:root:final mean train loss: 1287.9401836385646
INFO:root:final train perplexity: 2.761425495147705
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.00s/it]
INFO:root:eval mean loss: 2253.554819526402
INFO:root:eval perplexity: 6.187572002410889
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 36.00s/it]
INFO:root:eval mean loss: 2832.4475950416945
INFO:root:eval perplexity: 10.139649391174316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/154
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 154/200 [27:10:14<8:06:00, 633.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1257.9946576286766
INFO:root:current train perplexity2.6896238327026367
INFO:root:current mean train loss 1275.259537134415
INFO:root:current train perplexity2.742903709411621
INFO:root:current mean train loss 1276.9908824164747
INFO:root:current train perplexity2.746201753616333
INFO:root:current mean train loss 1280.042177025828
INFO:root:current train perplexity2.749112844467163
INFO:root:current mean train loss 1283.2486701068833
INFO:root:current train perplexity2.751711368560791
INFO:root:current mean train loss 1283.27181611347
INFO:root:current train perplexity2.748356342315674
INFO:root:current mean train loss 1283.2946882201554
INFO:root:current train perplexity2.7487521171569824
INFO:root:current mean train loss 1284.3664618881842
INFO:root:current train perplexity2.7501161098480225
INFO:root:current mean train loss 1284.2095956230396
INFO:root:current train perplexity2.75137996673584
INFO:root:current mean train loss 1284.4117161408635
INFO:root:current train perplexity2.7516109943389893
INFO:root:current mean train loss 1284.6719002062591
INFO:root:current train perplexity2.7515079975128174
INFO:root:current mean train loss 1285.4978675398318
INFO:root:current train perplexity2.7530808448791504
INFO:root:current mean train loss 1285.7383273899702
INFO:root:current train perplexity2.752819538116455
INFO:root:current mean train loss 1285.6631057727673
INFO:root:current train perplexity2.7541654109954834
INFO:root:current mean train loss 1286.8878054083782
INFO:root:current train perplexity2.7550668716430664
INFO:root:current mean train loss 1287.3508715997343
INFO:root:current train perplexity2.7562949657440186
INFO:root:current mean train loss 1287.4942866262272
INFO:root:current train perplexity2.7574124336242676
INFO:root:current mean train loss 1287.2242794225713
INFO:root:current train perplexity2.757938861846924
INFO:root:current mean train loss 1287.6547084340173
INFO:root:current train perplexity2.7593393325805664
INFO:root:current mean train loss 1287.993224556395
INFO:root:current train perplexity2.759803295135498

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.06s/it]
INFO:root:final mean train loss: 1287.3330207397646
INFO:root:final train perplexity: 2.760103940963745
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.64s/it]
INFO:root:eval mean loss: 2254.3420955576794
INFO:root:eval perplexity: 6.191513538360596
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.65s/it]
INFO:root:eval mean loss: 2832.386607934397
INFO:root:eval perplexity: 10.139144897460938
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/155
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 155/200 [27:20:48<7:55:35, 634.12s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1286.6156831629137
INFO:root:current train perplexity2.735781669616699
INFO:root:current mean train loss 1284.4408751530434
INFO:root:current train perplexity2.757293224334717
INFO:root:current mean train loss 1280.0626627604167
INFO:root:current train perplexity2.7503254413604736
INFO:root:current mean train loss 1280.5324268455277
INFO:root:current train perplexity2.746912717819214
INFO:root:current mean train loss 1281.331042311708
INFO:root:current train perplexity2.7490363121032715
INFO:root:current mean train loss 1282.1700910361071
INFO:root:current train perplexity2.7496631145477295
INFO:root:current mean train loss 1282.9572784712639
INFO:root:current train perplexity2.7496438026428223
INFO:root:current mean train loss 1283.967258214301
INFO:root:current train perplexity2.7493202686309814
INFO:root:current mean train loss 1284.705237372602
INFO:root:current train perplexity2.7488083839416504
INFO:root:current mean train loss 1284.6063372266879
INFO:root:current train perplexity2.748654365539551
INFO:root:current mean train loss 1283.478590354698
INFO:root:current train perplexity2.749469518661499
INFO:root:current mean train loss 1283.233113499125
INFO:root:current train perplexity2.749830722808838
INFO:root:current mean train loss 1283.4027893956709
INFO:root:current train perplexity2.7501492500305176
INFO:root:current mean train loss 1284.089910550096
INFO:root:current train perplexity2.7518904209136963
INFO:root:current mean train loss 1284.1729661417473
INFO:root:current train perplexity2.752927780151367
INFO:root:current mean train loss 1284.4096884994806
INFO:root:current train perplexity2.7529373168945312
INFO:root:current mean train loss 1284.9277936172018
INFO:root:current train perplexity2.753474712371826
INFO:root:current mean train loss 1285.6007167371774
INFO:root:current train perplexity2.7551958560943604
INFO:root:current mean train loss 1285.9109228835111
INFO:root:current train perplexity2.7554514408111572
INFO:root:current mean train loss 1286.0764174042222
INFO:root:current train perplexity2.75640606880188

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.13s/it]
INFO:root:final mean train loss: 1285.7557017239308
INFO:root:final train perplexity: 2.7566723823547363
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.40s/it]
INFO:root:eval mean loss: 2254.9648238378213
INFO:root:eval perplexity: 6.1946306228637695
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 2833.139753625748
INFO:root:eval perplexity: 10.145390510559082
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/156
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 156/200 [27:31:27<7:46:05, 635.58s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1279.22951372932
INFO:root:current train perplexity2.7657713890075684
INFO:root:current mean train loss 1280.6057242084023
INFO:root:current train perplexity2.753541946411133
INFO:root:current mean train loss 1279.599214470244
INFO:root:current train perplexity2.7470359802246094
INFO:root:current mean train loss 1279.9537277004317
INFO:root:current train perplexity2.7424864768981934
INFO:root:current mean train loss 1282.6792766291921
INFO:root:current train perplexity2.7454981803894043
INFO:root:current mean train loss 1282.656199931233
INFO:root:current train perplexity2.74753737449646
INFO:root:current mean train loss 1283.5719569802468
INFO:root:current train perplexity2.7479941844940186
INFO:root:current mean train loss 1282.4380518358334
INFO:root:current train perplexity2.7476744651794434
INFO:root:current mean train loss 1282.2059390721395
INFO:root:current train perplexity2.748337984085083
INFO:root:current mean train loss 1282.6406706961423
INFO:root:current train perplexity2.747251510620117
INFO:root:current mean train loss 1283.1163235999197
INFO:root:current train perplexity2.7476556301116943
INFO:root:current mean train loss 1283.4054457782975
INFO:root:current train perplexity2.7485122680664062
INFO:root:current mean train loss 1283.6465129654089
INFO:root:current train perplexity2.749006986618042
INFO:root:current mean train loss 1283.7529576977124
INFO:root:current train perplexity2.7500956058502197
INFO:root:current mean train loss 1284.5237082252004
INFO:root:current train perplexity2.750990152359009
INFO:root:current mean train loss 1284.5582528818354
INFO:root:current train perplexity2.750901460647583
INFO:root:current mean train loss 1284.6328138308695
INFO:root:current train perplexity2.751349449157715
INFO:root:current mean train loss 1284.9445436173748
INFO:root:current train perplexity2.7526769638061523
INFO:root:current mean train loss 1284.583212120349
INFO:root:current train perplexity2.753021478652954
INFO:root:current mean train loss 1284.619628155433
INFO:root:current train perplexity2.752591848373413

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.96s/it]
INFO:root:final mean train loss: 1284.078813099825
INFO:root:final train perplexity: 2.7530288696289062
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it]
INFO:root:eval mean loss: 2257.3136691911845
INFO:root:eval perplexity: 6.206411361694336
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.47s/it]
INFO:root:eval mean loss: 2836.682946171321
INFO:root:eval perplexity: 10.17483139038086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/157
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 157/200 [27:41:57<7:34:09, 633.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1275.4311325970818
INFO:root:current train perplexity2.7291698455810547
INFO:root:current mean train loss 1274.5340154738653
INFO:root:current train perplexity2.7364861965179443
INFO:root:current mean train loss 1274.4123890435517
INFO:root:current train perplexity2.7387375831604004
INFO:root:current mean train loss 1276.4538136357846
INFO:root:current train perplexity2.742952346801758
INFO:root:current mean train loss 1277.536129943326
INFO:root:current train perplexity2.7435011863708496
INFO:root:current mean train loss 1277.0924319415026
INFO:root:current train perplexity2.7424614429473877
INFO:root:current mean train loss 1277.1980099249743
INFO:root:current train perplexity2.7461233139038086
INFO:root:current mean train loss 1278.2602871259053
INFO:root:current train perplexity2.7475287914276123
INFO:root:current mean train loss 1279.2595697218371
INFO:root:current train perplexity2.748826265335083
INFO:root:current mean train loss 1279.61684714073
INFO:root:current train perplexity2.750027656555176
INFO:root:current mean train loss 1280.3980468292807
INFO:root:current train perplexity2.749591112136841
INFO:root:current mean train loss 1281.0334643011224
INFO:root:current train perplexity2.750352382659912
INFO:root:current mean train loss 1281.6950000077015
INFO:root:current train perplexity2.7489025592803955
INFO:root:current mean train loss 1281.7237460487768
INFO:root:current train perplexity2.7490766048431396
INFO:root:current mean train loss 1281.1855058799972
INFO:root:current train perplexity2.7480967044830322
INFO:root:current mean train loss 1281.6973920549665
INFO:root:current train perplexity2.7485439777374268
INFO:root:current mean train loss 1281.8913632033825
INFO:root:current train perplexity2.7496016025543213
INFO:root:current mean train loss 1281.8626277457536
INFO:root:current train perplexity2.748894691467285
INFO:root:current mean train loss 1281.9409625361768
INFO:root:current train perplexity2.748929977416992
INFO:root:current mean train loss 1282.7494922420842
INFO:root:current train perplexity2.7494513988494873

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.56s/it]
INFO:root:final mean train loss: 1282.384825859897
INFO:root:final train perplexity: 2.7493538856506348
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.83s/it]
INFO:root:eval mean loss: 2258.509735756732
INFO:root:eval perplexity: 6.2124176025390625
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it]
INFO:root:eval mean loss: 2839.323091980413
INFO:root:eval perplexity: 10.196826934814453
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/158
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [27:52:38<7:25:08, 635.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1270.4084501378677
INFO:root:current train perplexity2.73396635055542
INFO:root:current mean train loss 1271.314867504223
INFO:root:current train perplexity2.7378764152526855
INFO:root:current mean train loss 1273.5441423382676
INFO:root:current train perplexity2.7377212047576904
INFO:root:current mean train loss 1274.3360760577314
INFO:root:current train perplexity2.73797607421875
INFO:root:current mean train loss 1275.6562557889015
INFO:root:current train perplexity2.7395710945129395
INFO:root:current mean train loss 1274.2576797876602
INFO:root:current train perplexity2.7408273220062256
INFO:root:current mean train loss 1275.15180129448
INFO:root:current train perplexity2.7399003505706787
INFO:root:current mean train loss 1275.374449050806
INFO:root:current train perplexity2.7397685050964355
INFO:root:current mean train loss 1275.849738755738
INFO:root:current train perplexity2.7387936115264893
INFO:root:current mean train loss 1277.3623190632932
INFO:root:current train perplexity2.7394208908081055
INFO:root:current mean train loss 1276.9374507218463
INFO:root:current train perplexity2.7397985458374023
INFO:root:current mean train loss 1277.2371031942246
INFO:root:current train perplexity2.7407259941101074
INFO:root:current mean train loss 1277.5453360590952
INFO:root:current train perplexity2.741438865661621
INFO:root:current mean train loss 1278.3762107435978
INFO:root:current train perplexity2.7414045333862305
INFO:root:current mean train loss 1278.6729813598222
INFO:root:current train perplexity2.741232395172119
INFO:root:current mean train loss 1279.0014113176508
INFO:root:current train perplexity2.742550849914551
INFO:root:current mean train loss 1279.7576315316674
INFO:root:current train perplexity2.7428696155548096
INFO:root:current mean train loss 1280.3852100019694
INFO:root:current train perplexity2.7434051036834717
INFO:root:current mean train loss 1280.7983411389257
INFO:root:current train perplexity2.744297981262207

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.96s/it]
INFO:root:final mean train loss: 1280.4324940091362
INFO:root:final train perplexity: 2.7451233863830566
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.72s/it]
INFO:root:eval mean loss: 2259.9990723521996
INFO:root:eval perplexity: 6.219904899597168
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.95s/it]
INFO:root:eval mean loss: 2841.6761033078456
INFO:root:eval perplexity: 10.216466903686523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/159
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 159/200 [28:03:05<7:12:53, 633.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1193.9774169921875
INFO:root:current train perplexity2.709169864654541
INFO:root:current mean train loss 1267.2502309761796
INFO:root:current train perplexity2.737011432647705
INFO:root:current mean train loss 1268.8186089544013
INFO:root:current train perplexity2.7306833267211914
INFO:root:current mean train loss 1273.6921358424306
INFO:root:current train perplexity2.7312068939208984
INFO:root:current mean train loss 1272.9418839032378
INFO:root:current train perplexity2.72920298576355
INFO:root:current mean train loss 1274.2327187830708
INFO:root:current train perplexity2.730663537979126
INFO:root:current mean train loss 1275.8786320987333
INFO:root:current train perplexity2.7330095767974854
INFO:root:current mean train loss 1276.099796827702
INFO:root:current train perplexity2.733001947402954
INFO:root:current mean train loss 1277.127025423502
INFO:root:current train perplexity2.7352921962738037
INFO:root:current mean train loss 1276.5095333936738
INFO:root:current train perplexity2.7366771697998047
INFO:root:current mean train loss 1276.3866065476468
INFO:root:current train perplexity2.7380106449127197
INFO:root:current mean train loss 1277.550601578451
INFO:root:current train perplexity2.7394630908966064
INFO:root:current mean train loss 1277.6362172664699
INFO:root:current train perplexity2.739143133163452
INFO:root:current mean train loss 1278.1090439475627
INFO:root:current train perplexity2.739168643951416
INFO:root:current mean train loss 1278.9315616536924
INFO:root:current train perplexity2.7388932704925537
INFO:root:current mean train loss 1279.170018425953
INFO:root:current train perplexity2.7404630184173584
INFO:root:current mean train loss 1279.5910858649588
INFO:root:current train perplexity2.741506814956665
INFO:root:current mean train loss 1279.4592831675511
INFO:root:current train perplexity2.7421233654022217
INFO:root:current mean train loss 1279.5840474424035
INFO:root:current train perplexity2.7427406311035156
INFO:root:current mean train loss 1279.7896423018944
INFO:root:current train perplexity2.7432031631469727

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:37<00:00, 577.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:37<00:00, 577.31s/it]
INFO:root:final mean train loss: 1279.6030927187737
INFO:root:final train perplexity: 2.743328094482422
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.85s/it]
INFO:root:eval mean loss: 2261.9353252437945
INFO:root:eval perplexity: 6.229651927947998
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.78s/it]
INFO:root:eval mean loss: 2841.7340403888243
INFO:root:eval perplexity: 10.216951370239258
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/160
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 160/200 [28:13:59<7:06:17, 639.44s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1278.5207840768915
INFO:root:current train perplexity2.745875597000122
INFO:root:current mean train loss 1274.3502248555671
INFO:root:current train perplexity2.7191011905670166
INFO:root:current mean train loss 1276.4705693493152
INFO:root:current train perplexity2.723118305206299
INFO:root:current mean train loss 1272.8646818059365
INFO:root:current train perplexity2.727938175201416
INFO:root:current mean train loss 1273.83958737321
INFO:root:current train perplexity2.7298953533172607
INFO:root:current mean train loss 1273.469413977827
INFO:root:current train perplexity2.7324013710021973
INFO:root:current mean train loss 1273.8566933972386
INFO:root:current train perplexity2.7328782081604004
INFO:root:current mean train loss 1274.5216449848965
INFO:root:current train perplexity2.7324254512786865
INFO:root:current mean train loss 1274.4592426751851
INFO:root:current train perplexity2.7332303524017334
INFO:root:current mean train loss 1274.7898801984154
INFO:root:current train perplexity2.734365463256836
INFO:root:current mean train loss 1275.788251373321
INFO:root:current train perplexity2.7358198165893555
INFO:root:current mean train loss 1275.903019663902
INFO:root:current train perplexity2.7369601726531982
INFO:root:current mean train loss 1276.8670848567922
INFO:root:current train perplexity2.737478733062744
INFO:root:current mean train loss 1278.0990893499159
INFO:root:current train perplexity2.738507032394409
INFO:root:current mean train loss 1278.26023420639
INFO:root:current train perplexity2.738077163696289
INFO:root:current mean train loss 1277.8938999238808
INFO:root:current train perplexity2.739854335784912
INFO:root:current mean train loss 1277.5001217687181
INFO:root:current train perplexity2.7400870323181152
INFO:root:current mean train loss 1277.7548188303292
INFO:root:current train perplexity2.7401790618896484
INFO:root:current mean train loss 1278.040570158956
INFO:root:current train perplexity2.739342212677002
INFO:root:current mean train loss 1278.413954933091
INFO:root:current train perplexity2.7397897243499756

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:27<00:00, 567.06s/it]
INFO:root:final mean train loss: 1277.8703604970865
INFO:root:final train perplexity: 2.7395823001861572
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.84s/it]
INFO:root:eval mean loss: 2265.513491366772
INFO:root:eval perplexity: 6.24770450592041
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.50s/it]
INFO:root:eval mean loss: 2846.183777721216
INFO:root:eval perplexity: 10.25420093536377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/161
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 161/200 [28:24:47<6:57:26, 642.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1277.9338819715713
INFO:root:current train perplexity2.7242465019226074
INFO:root:current mean train loss 1273.6440456614775
INFO:root:current train perplexity2.712534189224243
INFO:root:current mean train loss 1274.330501233117
INFO:root:current train perplexity2.7280049324035645
INFO:root:current mean train loss 1273.8894791376024
INFO:root:current train perplexity2.727125644683838
INFO:root:current mean train loss 1275.0173561026197
INFO:root:current train perplexity2.7282803058624268
INFO:root:current mean train loss 1274.6443424509532
INFO:root:current train perplexity2.7308871746063232
INFO:root:current mean train loss 1275.7179302479485
INFO:root:current train perplexity2.729797840118408
INFO:root:current mean train loss 1275.6650306038234
INFO:root:current train perplexity2.7336678504943848
INFO:root:current mean train loss 1276.0535316284763
INFO:root:current train perplexity2.733396530151367
INFO:root:current mean train loss 1275.3623805901943
INFO:root:current train perplexity2.7326457500457764
INFO:root:current mean train loss 1275.7085954231645
INFO:root:current train perplexity2.7340621948242188
INFO:root:current mean train loss 1276.4911060601892
INFO:root:current train perplexity2.735203981399536
INFO:root:current mean train loss 1276.234106958877
INFO:root:current train perplexity2.734804391860962
INFO:root:current mean train loss 1276.507602440383
INFO:root:current train perplexity2.7360646724700928
INFO:root:current mean train loss 1276.6498467490533
INFO:root:current train perplexity2.7361092567443848
INFO:root:current mean train loss 1277.2729139328003
INFO:root:current train perplexity2.736104726791382
INFO:root:current mean train loss 1277.267031793198
INFO:root:current train perplexity2.7370247840881348
INFO:root:current mean train loss 1276.8638716315345
INFO:root:current train perplexity2.7373931407928467
INFO:root:current mean train loss 1277.0836393069599
INFO:root:current train perplexity2.7377030849456787
INFO:root:current mean train loss 1277.1286842409245
INFO:root:current train perplexity2.7372684478759766

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.74s/it]
INFO:root:final mean train loss: 1276.735882349827
INFO:root:final train perplexity: 2.7371320724487305
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.21s/it]
INFO:root:eval mean loss: 2262.990665516955
INFO:root:eval perplexity: 6.234971046447754
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it]
INFO:root:eval mean loss: 2845.8621142231827
INFO:root:eval perplexity: 10.251502990722656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/162
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 162/200 [28:35:19<6:44:43, 639.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1270.2505343455189
INFO:root:current train perplexity2.7147064208984375
INFO:root:current mean train loss 1272.7736090367137
INFO:root:current train perplexity2.7122766971588135
INFO:root:current mean train loss 1273.0869212998703
INFO:root:current train perplexity2.7109856605529785
INFO:root:current mean train loss 1271.931809033618
INFO:root:current train perplexity2.713294506072998
INFO:root:current mean train loss 1271.0967950210402
INFO:root:current train perplexity2.7174129486083984
INFO:root:current mean train loss 1270.8058413183064
INFO:root:current train perplexity2.7194302082061768
INFO:root:current mean train loss 1270.9852672536013
INFO:root:current train perplexity2.720424175262451
INFO:root:current mean train loss 1271.547270066868
INFO:root:current train perplexity2.7227132320404053
INFO:root:current mean train loss 1271.8442739149052
INFO:root:current train perplexity2.722869396209717
INFO:root:current mean train loss 1271.9676174231865
INFO:root:current train perplexity2.7233283519744873
INFO:root:current mean train loss 1272.3428737136826
INFO:root:current train perplexity2.7235500812530518
INFO:root:current mean train loss 1273.0854748397524
INFO:root:current train perplexity2.7238948345184326
INFO:root:current mean train loss 1273.1206993839785
INFO:root:current train perplexity2.724397897720337
INFO:root:current mean train loss 1274.1517740885417
INFO:root:current train perplexity2.7271957397460938
INFO:root:current mean train loss 1273.4732340046723
INFO:root:current train perplexity2.727753162384033
INFO:root:current mean train loss 1273.7301783908665
INFO:root:current train perplexity2.72861385345459
INFO:root:current mean train loss 1273.7204535196422
INFO:root:current train perplexity2.729039192199707
INFO:root:current mean train loss 1273.9287443623432
INFO:root:current train perplexity2.7294905185699463
INFO:root:current mean train loss 1274.3708101489772
INFO:root:current train perplexity2.7307441234588623
INFO:root:current mean train loss 1274.6572969420042
INFO:root:current train perplexity2.731900453567505

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:12<00:00, 552.21s/it]
INFO:root:final mean train loss: 1274.2988776179557
INFO:root:final train perplexity: 2.7318766117095947
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.43s/it]
INFO:root:eval mean loss: 2267.343438331117
INFO:root:eval perplexity: 6.256959438323975
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.57s/it]
INFO:root:eval mean loss: 2849.330510565575
INFO:root:eval perplexity: 10.280624389648438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/163
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 163/200 [28:45:46<6:31:44, 635.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1267.089146205357
INFO:root:current train perplexity2.7329955101013184
INFO:root:current mean train loss 1269.1884643554688
INFO:root:current train perplexity2.7274117469787598
INFO:root:current mean train loss 1269.5870578342015
INFO:root:current train perplexity2.7295446395874023
INFO:root:current mean train loss 1269.8818102037585
INFO:root:current train perplexity2.7224411964416504
INFO:root:current mean train loss 1270.656204288564
INFO:root:current train perplexity2.7209181785583496
INFO:root:current mean train loss 1272.2350733706826
INFO:root:current train perplexity2.7207441329956055
INFO:root:current mean train loss 1272.275667014051
INFO:root:current train perplexity2.722769021987915
INFO:root:current mean train loss 1272.5237621753247
INFO:root:current train perplexity2.723702907562256
INFO:root:current mean train loss 1272.7842885686064
INFO:root:current train perplexity2.7241218090057373
INFO:root:current mean train loss 1273.3640027233005
INFO:root:current train perplexity2.7245450019836426
INFO:root:current mean train loss 1273.1658294392523
INFO:root:current train perplexity2.7259252071380615
INFO:root:current mean train loss 1272.3747182992788
INFO:root:current train perplexity2.7266290187835693
INFO:root:current mean train loss 1272.271384315791
INFO:root:current train perplexity2.726581335067749
INFO:root:current mean train loss 1272.2795471636919
INFO:root:current train perplexity2.7263946533203125
INFO:root:current mean train loss 1272.4533543593218
INFO:root:current train perplexity2.727627992630005
INFO:root:current mean train loss 1272.697329770228
INFO:root:current train perplexity2.7269959449768066
INFO:root:current mean train loss 1272.9209333042897
INFO:root:current train perplexity2.727477550506592
INFO:root:current mean train loss 1273.3411954200874
INFO:root:current train perplexity2.728166341781616
INFO:root:current mean train loss 1273.423790067785
INFO:root:current train perplexity2.729485273361206
INFO:root:current mean train loss 1273.9293357268202
INFO:root:current train perplexity2.730250835418701

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.92s/it]
INFO:root:final mean train loss: 1273.4888742728722
INFO:root:final train perplexity: 2.7301316261291504
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.98s/it]
INFO:root:eval mean loss: 2267.679029532358
INFO:root:eval perplexity: 6.2586565017700195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it]
INFO:root:eval mean loss: 2850.398576452377
INFO:root:eval perplexity: 10.289607048034668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/164
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [28:56:18<6:20:35, 634.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1258.2744673805676
INFO:root:current train perplexity2.708744525909424
INFO:root:current mean train loss 1266.9469699145639
INFO:root:current train perplexity2.7156362533569336
INFO:root:current mean train loss 1265.8738324633873
INFO:root:current train perplexity2.7117793560028076
INFO:root:current mean train loss 1268.988650299782
INFO:root:current train perplexity2.714275598526001
INFO:root:current mean train loss 1268.2410725744353
INFO:root:current train perplexity2.7154314517974854
INFO:root:current mean train loss 1267.09848682722
INFO:root:current train perplexity2.7165651321411133
INFO:root:current mean train loss 1267.3315459894127
INFO:root:current train perplexity2.717816114425659
INFO:root:current mean train loss 1267.8650857811508
INFO:root:current train perplexity2.7188398838043213
INFO:root:current mean train loss 1268.418909118033
INFO:root:current train perplexity2.719542980194092
INFO:root:current mean train loss 1267.9878476344827
INFO:root:current train perplexity2.7207131385803223
INFO:root:current mean train loss 1268.6615948155043
INFO:root:current train perplexity2.7210936546325684
INFO:root:current mean train loss 1269.3227797189277
INFO:root:current train perplexity2.7216458320617676
INFO:root:current mean train loss 1270.24028805938
INFO:root:current train perplexity2.7231504917144775
INFO:root:current mean train loss 1270.0107751033593
INFO:root:current train perplexity2.724815607070923
INFO:root:current mean train loss 1270.3082570099718
INFO:root:current train perplexity2.724377155303955
INFO:root:current mean train loss 1271.0225441637622
INFO:root:current train perplexity2.7256383895874023
INFO:root:current mean train loss 1271.6715086443437
INFO:root:current train perplexity2.727108955383301
INFO:root:current mean train loss 1272.0618476376696
INFO:root:current train perplexity2.7274937629699707
INFO:root:current mean train loss 1272.1631246222096
INFO:root:current train perplexity2.7270522117614746

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.50s/it]
INFO:root:final mean train loss: 1272.2959157354112
INFO:root:final train perplexity: 2.727564573287964
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.18s/it]
INFO:root:eval mean loss: 2267.8859491010085
INFO:root:eval perplexity: 6.259704113006592
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.06s/it]
INFO:root:eval mean loss: 2851.609507892149
INFO:root:eval perplexity: 10.299802780151367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/165
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 165/200 [29:06:58<6:11:00, 636.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1250.2777404785156
INFO:root:current train perplexity2.73258638381958
INFO:root:current mean train loss 1259.9246943547175
INFO:root:current train perplexity2.7061073780059814
INFO:root:current mean train loss 1262.9340239880132
INFO:root:current train perplexity2.7121989727020264
INFO:root:current mean train loss 1263.5757004587274
INFO:root:current train perplexity2.712181329727173
INFO:root:current mean train loss 1266.3789775584003
INFO:root:current train perplexity2.712641716003418
INFO:root:current mean train loss 1266.456781780909
INFO:root:current train perplexity2.7132670879364014
INFO:root:current mean train loss 1266.3822237734762
INFO:root:current train perplexity2.7169816493988037
INFO:root:current mean train loss 1267.4076962904496
INFO:root:current train perplexity2.7179863452911377
INFO:root:current mean train loss 1267.35436131112
INFO:root:current train perplexity2.715559244155884
INFO:root:current mean train loss 1267.5502719035192
INFO:root:current train perplexity2.7168939113616943
INFO:root:current mean train loss 1268.2658450669976
INFO:root:current train perplexity2.7176480293273926
INFO:root:current mean train loss 1268.3016577458036
INFO:root:current train perplexity2.7179794311523438
INFO:root:current mean train loss 1269.3836757114955
INFO:root:current train perplexity2.719456195831299
INFO:root:current mean train loss 1270.0430099393693
INFO:root:current train perplexity2.720989227294922
INFO:root:current mean train loss 1269.5806059660736
INFO:root:current train perplexity2.7215163707733154
INFO:root:current mean train loss 1269.589357903663
INFO:root:current train perplexity2.722813367843628
INFO:root:current mean train loss 1269.6298156890489
INFO:root:current train perplexity2.723078727722168
INFO:root:current mean train loss 1269.8486406209884
INFO:root:current train perplexity2.721977710723877
INFO:root:current mean train loss 1269.9134766436998
INFO:root:current train perplexity2.722358465194702
INFO:root:current mean train loss 1270.1794696455243
INFO:root:current train perplexity2.7233197689056396

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:14<00:00, 554.80s/it]
INFO:root:final mean train loss: 1270.4954971567404
INFO:root:final train perplexity: 2.7236945629119873
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it]
INFO:root:eval mean loss: 2270.4188405571253
INFO:root:eval perplexity: 6.2725396156311035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 2853.604514264046
INFO:root:eval perplexity: 10.316622734069824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/166
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 166/200 [29:17:28<5:59:23, 634.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1262.8553641183037
INFO:root:current train perplexity2.6967055797576904
INFO:root:current mean train loss 1269.4547038432981
INFO:root:current train perplexity2.715949296951294
INFO:root:current mean train loss 1268.6938410279977
INFO:root:current train perplexity2.7079131603240967
INFO:root:current mean train loss 1267.8435876198646
INFO:root:current train perplexity2.70937442779541
INFO:root:current mean train loss 1267.6955363438985
INFO:root:current train perplexity2.7089271545410156
INFO:root:current mean train loss 1266.650313540292
INFO:root:current train perplexity2.7129709720611572
INFO:root:current mean train loss 1268.07476403671
INFO:root:current train perplexity2.7148451805114746
INFO:root:current mean train loss 1267.919186066986
INFO:root:current train perplexity2.7158427238464355
INFO:root:current mean train loss 1268.5044898382785
INFO:root:current train perplexity2.7156004905700684
INFO:root:current mean train loss 1269.247158452302
INFO:root:current train perplexity2.7160208225250244
INFO:root:current mean train loss 1268.7978386500674
INFO:root:current train perplexity2.7160048484802246
INFO:root:current mean train loss 1268.6795990779717
INFO:root:current train perplexity2.7191953659057617
INFO:root:current mean train loss 1269.572932762752
INFO:root:current train perplexity2.7190511226654053
INFO:root:current mean train loss 1269.3491723799145
INFO:root:current train perplexity2.7191059589385986
INFO:root:current mean train loss 1269.2904776909418
INFO:root:current train perplexity2.718301296234131
INFO:root:current mean train loss 1269.2382049259584
INFO:root:current train perplexity2.718587636947632
INFO:root:current mean train loss 1269.4238952222538
INFO:root:current train perplexity2.7185659408569336
INFO:root:current mean train loss 1269.3344688969667
INFO:root:current train perplexity2.718960762023926
INFO:root:current mean train loss 1269.545489324311
INFO:root:current train perplexity2.7202701568603516
INFO:root:current mean train loss 1269.8288275556351
INFO:root:current train perplexity2.721473217010498

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:23<00:00, 563.76s/it]
INFO:root:final mean train loss: 1269.6013154969094
INFO:root:final train perplexity: 2.721774101257324
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 2270.9826538951684
INFO:root:eval perplexity: 6.275401592254639
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.12s/it]
INFO:root:eval mean loss: 2854.672365878491
INFO:root:eval perplexity: 10.325631141662598
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/167
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 167/200 [29:28:07<5:49:39, 635.73s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1260.1357550370067
INFO:root:current train perplexity2.6949241161346436
INFO:root:current mean train loss 1259.6928286345108
INFO:root:current train perplexity2.6954708099365234
INFO:root:current mean train loss 1264.2087166409533
INFO:root:current train perplexity2.7002649307250977
INFO:root:current mean train loss 1264.5125349597818
INFO:root:current train perplexity2.699246644973755
INFO:root:current mean train loss 1266.45453466128
INFO:root:current train perplexity2.704963445663452
INFO:root:current mean train loss 1265.5195407796527
INFO:root:current train perplexity2.7061092853546143
INFO:root:current mean train loss 1266.1266029860158
INFO:root:current train perplexity2.7055866718292236
INFO:root:current mean train loss 1267.4757447281504
INFO:root:current train perplexity2.7085330486297607
INFO:root:current mean train loss 1267.9065184672863
INFO:root:current train perplexity2.7084691524505615
INFO:root:current mean train loss 1267.2029079282715
INFO:root:current train perplexity2.7100300788879395
INFO:root:current mean train loss 1267.01426670317
INFO:root:current train perplexity2.7118639945983887
INFO:root:current mean train loss 1267.132015717679
INFO:root:current train perplexity2.7140636444091797
INFO:root:current mean train loss 1266.6580426981839
INFO:root:current train perplexity2.7156589031219482
INFO:root:current mean train loss 1266.8854694908152
INFO:root:current train perplexity2.7158889770507812
INFO:root:current mean train loss 1267.368573481914
INFO:root:current train perplexity2.716298818588257
INFO:root:current mean train loss 1267.3261697320231
INFO:root:current train perplexity2.71681809425354
INFO:root:current mean train loss 1267.5717316605378
INFO:root:current train perplexity2.7172343730926514
INFO:root:current mean train loss 1267.9237720766057
INFO:root:current train perplexity2.717832326889038
INFO:root:current mean train loss 1268.007164624103
INFO:root:current train perplexity2.717681407928467
INFO:root:current mean train loss 1268.382022066382
INFO:root:current train perplexity2.7183165550231934

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.96s/it]
INFO:root:final mean train loss: 1267.9085539463367
INFO:root:final train perplexity: 2.7181432247161865
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.74s/it]
INFO:root:eval mean loss: 2273.6248606147497
INFO:root:eval perplexity: 6.288824558258057
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.17s/it]
INFO:root:eval mean loss: 2856.671845997479
INFO:root:eval perplexity: 10.342531204223633
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/168
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 168/200 [29:38:42<5:38:57, 635.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1260.4849010120738
INFO:root:current train perplexity2.706543207168579
INFO:root:current mean train loss 1261.6343915385585
INFO:root:current train perplexity2.6972928047180176
INFO:root:current mean train loss 1263.1926743451286
INFO:root:current train perplexity2.700774669647217
INFO:root:current mean train loss 1263.6293340118839
INFO:root:current train perplexity2.7015461921691895
INFO:root:current mean train loss 1262.9887917990213
INFO:root:current train perplexity2.703256368637085
INFO:root:current mean train loss 1263.7434966216217
INFO:root:current train perplexity2.7048890590667725
INFO:root:current mean train loss 1264.3520942047353
INFO:root:current train perplexity2.707571506500244
INFO:root:current mean train loss 1264.5836160621895
INFO:root:current train perplexity2.7074952125549316
INFO:root:current mean train loss 1264.1461727030794
INFO:root:current train perplexity2.7084665298461914
INFO:root:current mean train loss 1264.6853300883508
INFO:root:current train perplexity2.7090303897857666
INFO:root:current mean train loss 1264.75653741484
INFO:root:current train perplexity2.708618640899658
INFO:root:current mean train loss 1265.247481652462
INFO:root:current train perplexity2.7094061374664307
INFO:root:current mean train loss 1266.3929597041522
INFO:root:current train perplexity2.7095234394073486
INFO:root:current mean train loss 1266.2316294539899
INFO:root:current train perplexity2.710103988647461
INFO:root:current mean train loss 1266.1288111106637
INFO:root:current train perplexity2.7114148139953613
INFO:root:current mean train loss 1266.4232170669213
INFO:root:current train perplexity2.712780475616455
INFO:root:current mean train loss 1266.4663310900917
INFO:root:current train perplexity2.7147388458251953
INFO:root:current mean train loss 1266.3309593961449
INFO:root:current train perplexity2.715277671813965
INFO:root:current mean train loss 1266.6439064210958
INFO:root:current train perplexity2.7156336307525635
INFO:root:current mean train loss 1266.604943441796
INFO:root:current train perplexity2.71498966217041

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.67s/it]
INFO:root:final mean train loss: 1266.4049289258994
INFO:root:final train perplexity: 2.714921712875366
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.65s/it]
INFO:root:eval mean loss: 2274.5147302505816
INFO:root:eval perplexity: 6.293352127075195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.39s/it]
INFO:root:eval mean loss: 2858.6349764343695
INFO:root:eval perplexity: 10.359148979187012
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/169
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 169/200 [29:49:13<5:27:39, 634.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1262.2388899061416
INFO:root:current train perplexity2.6849353313446045
INFO:root:current mean train loss 1265.4900292684865
INFO:root:current train perplexity2.693235158920288
INFO:root:current mean train loss 1267.3754339779125
INFO:root:current train perplexity2.6997623443603516
INFO:root:current mean train loss 1266.74417836179
INFO:root:current train perplexity2.7036895751953125
INFO:root:current mean train loss 1265.8959906626555
INFO:root:current train perplexity2.701831340789795
INFO:root:current mean train loss 1264.704373873197
INFO:root:current train perplexity2.7064995765686035
INFO:root:current mean train loss 1264.4163970947266
INFO:root:current train perplexity2.7069568634033203
INFO:root:current mean train loss 1265.126840225773
INFO:root:current train perplexity2.7077064514160156
INFO:root:current mean train loss 1264.9853864197337
INFO:root:current train perplexity2.708575963973999
INFO:root:current mean train loss 1265.236110106417
INFO:root:current train perplexity2.7093663215637207
INFO:root:current mean train loss 1263.926453092205
INFO:root:current train perplexity2.708092212677002
INFO:root:current mean train loss 1264.465309012872
INFO:root:current train perplexity2.7095913887023926
INFO:root:current mean train loss 1264.9912324341587
INFO:root:current train perplexity2.709116220474243
INFO:root:current mean train loss 1265.289627030709
INFO:root:current train perplexity2.710749387741089
INFO:root:current mean train loss 1265.6020147074823
INFO:root:current train perplexity2.7114036083221436
INFO:root:current mean train loss 1265.1734864523696
INFO:root:current train perplexity2.7115249633789062
INFO:root:current mean train loss 1265.069242340526
INFO:root:current train perplexity2.7118520736694336
INFO:root:current mean train loss 1265.3801252998026
INFO:root:current train perplexity2.7123425006866455
INFO:root:current mean train loss 1265.9004414876301
INFO:root:current train perplexity2.7139785289764404
INFO:root:current mean train loss 1266.3166550332585
INFO:root:current train perplexity2.7140586376190186

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.40s/it]
INFO:root:final mean train loss: 1265.9423258709776
INFO:root:final train perplexity: 2.7139313220977783
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.11s/it]
INFO:root:eval mean loss: 2275.2792098674367
INFO:root:eval perplexity: 6.297245502471924
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it]
INFO:root:eval mean loss: 2860.4663458208665
INFO:root:eval perplexity: 10.374676704406738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/170
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [29:59:52<5:17:49, 635.64s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1258.15858030855
INFO:root:current train perplexity2.708986282348633
INFO:root:current mean train loss 1261.0490515976355
INFO:root:current train perplexity2.7138023376464844
INFO:root:current mean train loss 1263.9461627683013
INFO:root:current train perplexity2.707690954208374
INFO:root:current mean train loss 1264.2549540463328
INFO:root:current train perplexity2.705075740814209
INFO:root:current mean train loss 1264.3743983855763
INFO:root:current train perplexity2.708895683288574
INFO:root:current mean train loss 1263.1443130156383
INFO:root:current train perplexity2.708203077316284
INFO:root:current mean train loss 1263.5813220374298
INFO:root:current train perplexity2.7090201377868652
INFO:root:current mean train loss 1264.4556264357573
INFO:root:current train perplexity2.7087290287017822
INFO:root:current mean train loss 1264.5898381202105
INFO:root:current train perplexity2.709059715270996
INFO:root:current mean train loss 1264.652665773706
INFO:root:current train perplexity2.707977294921875
INFO:root:current mean train loss 1264.2447230651687
INFO:root:current train perplexity2.70746111869812
INFO:root:current mean train loss 1263.9040017091897
INFO:root:current train perplexity2.707632541656494
INFO:root:current mean train loss 1264.0845100633667
INFO:root:current train perplexity2.7085351943969727
INFO:root:current mean train loss 1264.3201911327562
INFO:root:current train perplexity2.70943546295166
INFO:root:current mean train loss 1263.8945444490062
INFO:root:current train perplexity2.7089431285858154
INFO:root:current mean train loss 1264.3085942877547
INFO:root:current train perplexity2.710456371307373
INFO:root:current mean train loss 1264.3858854340124
INFO:root:current train perplexity2.7106688022613525
INFO:root:current mean train loss 1264.4763883672792
INFO:root:current train perplexity2.711195945739746
INFO:root:current mean train loss 1264.9635849847182
INFO:root:current train perplexity2.711069107055664

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.87s/it]
INFO:root:final mean train loss: 1265.1698368628458
INFO:root:final train perplexity: 2.712278127670288
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.13s/it]
INFO:root:eval mean loss: 2275.271387844221
INFO:root:eval perplexity: 6.297204494476318
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.45s/it]
INFO:root:eval mean loss: 2859.5892282039563
INFO:root:eval perplexity: 10.367238998413086
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/171
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 171/200 [30:10:19<5:05:55, 632.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1248.627217610677
INFO:root:current train perplexity2.6998801231384277
INFO:root:current mean train loss 1266.3639814268868
INFO:root:current train perplexity2.6872639656066895
INFO:root:current mean train loss 1261.283822957752
INFO:root:current train perplexity2.687779188156128
INFO:root:current mean train loss 1260.4928652694803
INFO:root:current train perplexity2.6900582313537598
INFO:root:current mean train loss 1261.8631333224291
INFO:root:current train perplexity2.695767879486084
INFO:root:current mean train loss 1263.6061970706985
INFO:root:current train perplexity2.6991329193115234
INFO:root:current mean train loss 1262.3047618299427
INFO:root:current train perplexity2.697950839996338
INFO:root:current mean train loss 1261.4748486743094
INFO:root:current train perplexity2.6983747482299805
INFO:root:current mean train loss 1260.4602496050131
INFO:root:current train perplexity2.6997125148773193
INFO:root:current mean train loss 1260.763305798798
INFO:root:current train perplexity2.7009477615356445
INFO:root:current mean train loss 1260.9785561533145
INFO:root:current train perplexity2.702533721923828
INFO:root:current mean train loss 1261.326343501886
INFO:root:current train perplexity2.7031655311584473
INFO:root:current mean train loss 1261.9832206966469
INFO:root:current train perplexity2.703707695007324
INFO:root:current mean train loss 1262.5832360634213
INFO:root:current train perplexity2.7041752338409424
INFO:root:current mean train loss 1263.6440682336581
INFO:root:current train perplexity2.7055468559265137
INFO:root:current mean train loss 1263.316318142145
INFO:root:current train perplexity2.7062833309173584
INFO:root:current mean train loss 1263.9414083782494
INFO:root:current train perplexity2.706570863723755
INFO:root:current mean train loss 1264.276824629181
INFO:root:current train perplexity2.707794427871704
INFO:root:current mean train loss 1264.2429733867793
INFO:root:current train perplexity2.708858013153076
INFO:root:current mean train loss 1264.102226073194
INFO:root:current train perplexity2.708611488342285

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.73s/it]
INFO:root:final mean train loss: 1263.8251130704741
INFO:root:final train perplexity: 2.7094039916992188
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it]
INFO:root:eval mean loss: 2276.6603475800644
INFO:root:eval perplexity: 6.304282188415527
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.31s/it]
INFO:root:eval mean loss: 2862.563190866024
INFO:root:eval perplexity: 10.392483711242676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/172
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 172/200 [30:20:48<4:54:54, 631.94s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1244.4074547809103
INFO:root:current train perplexity2.673215389251709
INFO:root:current mean train loss 1250.7247542714686
INFO:root:current train perplexity2.6900875568389893
INFO:root:current mean train loss 1253.0931505964477
INFO:root:current train perplexity2.6998696327209473
INFO:root:current mean train loss 1253.6641259916796
INFO:root:current train perplexity2.697967290878296
INFO:root:current mean train loss 1255.1492253296765
INFO:root:current train perplexity2.697181463241577
INFO:root:current mean train loss 1255.59739390386
INFO:root:current train perplexity2.7009048461914062
INFO:root:current mean train loss 1256.8407391935443
INFO:root:current train perplexity2.700723648071289
INFO:root:current mean train loss 1256.8834716459198
INFO:root:current train perplexity2.700289487838745
INFO:root:current mean train loss 1258.0712183121489
INFO:root:current train perplexity2.7006900310516357
INFO:root:current mean train loss 1259.3073688147515
INFO:root:current train perplexity2.7009713649749756
INFO:root:current mean train loss 1259.534615346064
INFO:root:current train perplexity2.700716018676758
INFO:root:current mean train loss 1259.1773218577819
INFO:root:current train perplexity2.6999006271362305
INFO:root:current mean train loss 1259.5930086948397
INFO:root:current train perplexity2.7004175186157227
INFO:root:current mean train loss 1260.9039679402576
INFO:root:current train perplexity2.702867269515991
INFO:root:current mean train loss 1261.9548999520982
INFO:root:current train perplexity2.7024483680725098
INFO:root:current mean train loss 1262.039557914709
INFO:root:current train perplexity2.703122138977051
INFO:root:current mean train loss 1262.121429198918
INFO:root:current train perplexity2.7038302421569824
INFO:root:current mean train loss 1262.099847210194
INFO:root:current train perplexity2.7046799659729004
INFO:root:current mean train loss 1261.9512092393634
INFO:root:current train perplexity2.705423593521118
INFO:root:current mean train loss 1262.222870936322
INFO:root:current train perplexity2.7055983543395996

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:28<00:00, 568.12s/it]
INFO:root:final mean train loss: 1262.073500424999
INFO:root:final train perplexity: 2.7056632041931152
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.71s/it]
INFO:root:eval mean loss: 2277.519780152233
INFO:root:eval perplexity: 6.308665752410889
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.55s/it]
INFO:root:eval mean loss: 2862.830994950964
INFO:root:eval perplexity: 10.394758224487305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/173
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 173/200 [30:31:32<4:45:57, 635.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1252.0761657714843
INFO:root:current train perplexity2.696089506149292
INFO:root:current mean train loss 1257.5582048688616
INFO:root:current train perplexity2.7000350952148438
INFO:root:current mean train loss 1262.4857549031576
INFO:root:current train perplexity2.6980693340301514
INFO:root:current mean train loss 1261.4881896972656
INFO:root:current train perplexity2.6974761486053467
INFO:root:current mean train loss 1260.63222545277
INFO:root:current train perplexity2.7001283168792725
INFO:root:current mean train loss 1260.4573475025318
INFO:root:current train perplexity2.6995904445648193
INFO:root:current mean train loss 1260.2244934082032
INFO:root:current train perplexity2.698503255844116
INFO:root:current mean train loss 1260.7487212309966
INFO:root:current train perplexity2.697521209716797
INFO:root:current mean train loss 1259.597353835333
INFO:root:current train perplexity2.698049306869507
INFO:root:current mean train loss 1259.9442523063497
INFO:root:current train perplexity2.699617862701416
INFO:root:current mean train loss 1260.014487515963
INFO:root:current train perplexity2.7001404762268066
INFO:root:current mean train loss 1259.483444909882
INFO:root:current train perplexity2.7009024620056152
INFO:root:current mean train loss 1259.92686738045
INFO:root:current train perplexity2.70097017288208
INFO:root:current mean train loss 1259.478189952338
INFO:root:current train perplexity2.7020812034606934
INFO:root:current mean train loss 1259.9628250969781
INFO:root:current train perplexity2.702972173690796
INFO:root:current mean train loss 1260.402648846515
INFO:root:current train perplexity2.7036900520324707
INFO:root:current mean train loss 1260.6461555294875
INFO:root:current train perplexity2.7041029930114746
INFO:root:current mean train loss 1261.1825200924927
INFO:root:current train perplexity2.7046217918395996
INFO:root:current mean train loss 1261.2865586654
INFO:root:current train perplexity2.704737663269043
INFO:root:current mean train loss 1261.5801235552915
INFO:root:current train perplexity2.704512596130371

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.14s/it]
INFO:root:final mean train loss: 1261.4188949885058
INFO:root:final train perplexity: 2.7042667865753174
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it]
INFO:root:eval mean loss: 2278.700148995041
INFO:root:eval perplexity: 6.314691543579102
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.99s/it]
INFO:root:eval mean loss: 2863.514028129848
INFO:root:eval perplexity: 10.400568962097168
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/174
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 174/200 [30:42:02<4:34:41, 633.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1257.7376066509046
INFO:root:current train perplexity2.7010080814361572
INFO:root:current mean train loss 1254.3572119451633
INFO:root:current train perplexity2.697232484817505
INFO:root:current mean train loss 1255.8228047292985
INFO:root:current train perplexity2.694866418838501
INFO:root:current mean train loss 1257.0254029346113
INFO:root:current train perplexity2.6927871704101562
INFO:root:current mean train loss 1257.6844100451312
INFO:root:current train perplexity2.691737174987793
INFO:root:current mean train loss 1257.2742518865014
INFO:root:current train perplexity2.6950223445892334
INFO:root:current mean train loss 1256.8052697958285
INFO:root:current train perplexity2.695366859436035
INFO:root:current mean train loss 1256.6061808536988
INFO:root:current train perplexity2.6943469047546387
INFO:root:current mean train loss 1256.8779103157817
INFO:root:current train perplexity2.6959869861602783
INFO:root:current mean train loss 1257.873637710619
INFO:root:current train perplexity2.69661545753479
INFO:root:current mean train loss 1257.497922032987
INFO:root:current train perplexity2.6964974403381348
INFO:root:current mean train loss 1257.3513982273323
INFO:root:current train perplexity2.6967031955718994
INFO:root:current mean train loss 1258.5161366853433
INFO:root:current train perplexity2.6972978115081787
INFO:root:current mean train loss 1258.7342191961818
INFO:root:current train perplexity2.6971824169158936
INFO:root:current mean train loss 1258.5541227258225
INFO:root:current train perplexity2.697183132171631
INFO:root:current mean train loss 1258.9901701646045
INFO:root:current train perplexity2.697474479675293
INFO:root:current mean train loss 1259.1224250310001
INFO:root:current train perplexity2.697932481765747
INFO:root:current mean train loss 1259.6642870482356
INFO:root:current train perplexity2.699345588684082
INFO:root:current mean train loss 1259.814587685005
INFO:root:current train perplexity2.699037790298462
INFO:root:current mean train loss 1260.0533426681463
INFO:root:current train perplexity2.700300455093384

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:26<00:00, 566.09s/it]
INFO:root:final mean train loss: 1259.6674341152727
INFO:root:final train perplexity: 2.700533866882324
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.56s/it]
INFO:root:eval mean loss: 2278.6292062313
INFO:root:eval perplexity: 6.314328193664551
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.24s/it]
INFO:root:eval mean loss: 2864.812266248338
INFO:root:eval perplexity: 10.411617279052734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/175
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 175/200 [30:52:44<4:25:08, 636.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1259.1490214579815
INFO:root:current train perplexity2.689995288848877
INFO:root:current mean train loss 1254.8508230625898
INFO:root:current train perplexity2.682406187057495
INFO:root:current mean train loss 1251.0942142235972
INFO:root:current train perplexity2.6904149055480957
INFO:root:current mean train loss 1251.313129608644
INFO:root:current train perplexity2.6907122135162354
INFO:root:current mean train loss 1252.4755485953158
INFO:root:current train perplexity2.691412925720215
INFO:root:current mean train loss 1253.6623071544261
INFO:root:current train perplexity2.692091941833496
INFO:root:current mean train loss 1254.9476602707136
INFO:root:current train perplexity2.693834066390991
INFO:root:current mean train loss 1255.5398461787893
INFO:root:current train perplexity2.6930952072143555
INFO:root:current mean train loss 1256.3825239447763
INFO:root:current train perplexity2.6947219371795654
INFO:root:current mean train loss 1256.700136658592
INFO:root:current train perplexity2.6953160762786865
INFO:root:current mean train loss 1256.6000879951916
INFO:root:current train perplexity2.6957130432128906
INFO:root:current mean train loss 1257.1496395910415
INFO:root:current train perplexity2.6955461502075195
INFO:root:current mean train loss 1257.661098126901
INFO:root:current train perplexity2.6959099769592285
INFO:root:current mean train loss 1257.5443271598094
INFO:root:current train perplexity2.6955082416534424
INFO:root:current mean train loss 1258.0976223783869
INFO:root:current train perplexity2.6966910362243652
INFO:root:current mean train loss 1258.1758077735367
INFO:root:current train perplexity2.6974875926971436
INFO:root:current mean train loss 1258.7226213936026
INFO:root:current train perplexity2.6987297534942627
INFO:root:current mean train loss 1259.0731446826337
INFO:root:current train perplexity2.699291944503784
INFO:root:current mean train loss 1259.3862694218167
INFO:root:current train perplexity2.699681043624878
INFO:root:current mean train loss 1259.6370870016267
INFO:root:current train perplexity2.6994473934173584

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.86s/it]
INFO:root:final mean train loss: 1259.2612240051178
INFO:root:final train perplexity: 2.6996688842773438
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it]
INFO:root:eval mean loss: 2281.4634066101507
INFO:root:eval perplexity: 6.3288187980651855
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.92s/it]
INFO:root:eval mean loss: 2868.117480122451
INFO:root:eval perplexity: 10.439799308776855
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/176
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [31:03:14<4:13:45, 634.40s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1251.852540403932
INFO:root:current train perplexity2.6959068775177
INFO:root:current mean train loss 1252.6827577920485
INFO:root:current train perplexity2.6921632289886475
INFO:root:current mean train loss 1253.2987677190722
INFO:root:current train perplexity2.6919569969177246
INFO:root:current mean train loss 1254.797976442615
INFO:root:current train perplexity2.6898906230926514
INFO:root:current mean train loss 1255.2511045995896
INFO:root:current train perplexity2.6921114921569824
INFO:root:current mean train loss 1256.359518344834
INFO:root:current train perplexity2.6933741569519043
INFO:root:current mean train loss 1256.8836498564128
INFO:root:current train perplexity2.6935012340545654
INFO:root:current mean train loss 1257.0973121073996
INFO:root:current train perplexity2.6961050033569336
INFO:root:current mean train loss 1257.0157222726396
INFO:root:current train perplexity2.695401191711426
INFO:root:current mean train loss 1257.3317144338105
INFO:root:current train perplexity2.6940197944641113
INFO:root:current mean train loss 1256.665342280233
INFO:root:current train perplexity2.6947903633117676
INFO:root:current mean train loss 1257.3285643916286
INFO:root:current train perplexity2.694828510284424
INFO:root:current mean train loss 1257.4254865225298
INFO:root:current train perplexity2.695648193359375
INFO:root:current mean train loss 1257.5177148507705
INFO:root:current train perplexity2.6958181858062744
INFO:root:current mean train loss 1257.5947951707642
INFO:root:current train perplexity2.696167230606079
INFO:root:current mean train loss 1257.8133013213976
INFO:root:current train perplexity2.6963844299316406
INFO:root:current mean train loss 1258.027643114628
INFO:root:current train perplexity2.696744203567505
INFO:root:current mean train loss 1258.129463097824
INFO:root:current train perplexity2.6970932483673096
INFO:root:current mean train loss 1257.9971793430436
INFO:root:current train perplexity2.6971235275268555

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.52s/it]
INFO:root:final mean train loss: 1258.1884903208029
INFO:root:final train perplexity: 2.697385787963867
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.19s/it]
INFO:root:eval mean loss: 2281.6741103584886
INFO:root:eval perplexity: 6.329897880554199
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.92s/it]
INFO:root:eval mean loss: 2868.428519174562
INFO:root:eval perplexity: 10.442453384399414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/177
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 177/200 [31:13:53<4:03:41, 635.74s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1238.3438110351562
INFO:root:current train perplexity2.697599172592163
INFO:root:current mean train loss 1260.4386008933739
INFO:root:current train perplexity2.6961190700531006
INFO:root:current mean train loss 1259.574334364671
INFO:root:current train perplexity2.6998825073242188
INFO:root:current mean train loss 1254.2573250114144
INFO:root:current train perplexity2.695542335510254
INFO:root:current mean train loss 1255.2330148734297
INFO:root:current train perplexity2.693633794784546
INFO:root:current mean train loss 1255.1749068132535
INFO:root:current train perplexity2.695079803466797
INFO:root:current mean train loss 1255.6173282422517
INFO:root:current train perplexity2.697056770324707
INFO:root:current mean train loss 1257.2397700595318
INFO:root:current train perplexity2.6968765258789062
INFO:root:current mean train loss 1256.4579280437808
INFO:root:current train perplexity2.694453716278076
INFO:root:current mean train loss 1256.6649063715327
INFO:root:current train perplexity2.6955318450927734
INFO:root:current mean train loss 1256.921763465518
INFO:root:current train perplexity2.694669723510742
INFO:root:current mean train loss 1256.9064660468257
INFO:root:current train perplexity2.695800542831421
INFO:root:current mean train loss 1256.6462874254644
INFO:root:current train perplexity2.6952996253967285
INFO:root:current mean train loss 1256.5732785846114
INFO:root:current train perplexity2.695598840713501
INFO:root:current mean train loss 1256.7900930751455
INFO:root:current train perplexity2.694880247116089
INFO:root:current mean train loss 1256.407651137294
INFO:root:current train perplexity2.694836139678955
INFO:root:current mean train loss 1256.5721865981373
INFO:root:current train perplexity2.69577693939209
INFO:root:current mean train loss 1256.9668271066992
INFO:root:current train perplexity2.6962873935699463
INFO:root:current mean train loss 1257.4449096949754
INFO:root:current train perplexity2.6962790489196777
INFO:root:current mean train loss 1257.8825711744137
INFO:root:current train perplexity2.695866584777832

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.46s/it]
INFO:root:final mean train loss: 1257.319494635062
INFO:root:final train perplexity: 2.695537805557251
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.16s/it]
INFO:root:eval mean loss: 2282.3502474304632
INFO:root:eval perplexity: 6.33336067199707
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.88s/it]
INFO:root:eval mean loss: 2869.5346558482934
INFO:root:eval perplexity: 10.451903343200684
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/178
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 178/200 [31:24:25<3:52:39, 634.54s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1252.635634765625
INFO:root:current train perplexity2.7428176403045654
INFO:root:current mean train loss 1251.50675390625
INFO:root:current train perplexity2.6965365409851074
INFO:root:current mean train loss 1257.1713704427084
INFO:root:current train perplexity2.692305326461792
INFO:root:current mean train loss 1254.040674203726
INFO:root:current train perplexity2.6915650367736816
INFO:root:current mean train loss 1253.2534693818934
INFO:root:current train perplexity2.690293312072754
INFO:root:current mean train loss 1253.9915050688244
INFO:root:current train perplexity2.690115213394165
INFO:root:current mean train loss 1253.795078515625
INFO:root:current train perplexity2.6911513805389404
INFO:root:current mean train loss 1253.4216318696122
INFO:root:current train perplexity2.69107723236084
INFO:root:current mean train loss 1253.5165987511837
INFO:root:current train perplexity2.6926181316375732
INFO:root:current mean train loss 1254.184306772593
INFO:root:current train perplexity2.6924285888671875
INFO:root:current mean train loss 1255.1071527248475
INFO:root:current train perplexity2.6922266483306885
INFO:root:current mean train loss 1254.6122333984374
INFO:root:current train perplexity2.691340446472168
INFO:root:current mean train loss 1254.874088408801
INFO:root:current train perplexity2.693105459213257
INFO:root:current mean train loss 1255.9398103994693
INFO:root:current train perplexity2.6933586597442627
INFO:root:current mean train loss 1256.0410367838542
INFO:root:current train perplexity2.692335605621338
INFO:root:current mean train loss 1255.8241508709016
INFO:root:current train perplexity2.693012237548828
INFO:root:current mean train loss 1256.4023231670674
INFO:root:current train perplexity2.692826747894287
INFO:root:current mean train loss 1256.2616920714447
INFO:root:current train perplexity2.692964553833008
INFO:root:current mean train loss 1256.1854268782106
INFO:root:current train perplexity2.693814516067505
INFO:root:current mean train loss 1256.5619287109375
INFO:root:current train perplexity2.693647623062134

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.02s/it]
INFO:root:final mean train loss: 1256.5450866976232
INFO:root:final train perplexity: 2.693892240524292
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.96s/it]
INFO:root:eval mean loss: 2283.595281506261
INFO:root:eval perplexity: 6.339739799499512
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.85s/it]
INFO:root:eval mean loss: 2871.7903983474625
INFO:root:eval perplexity: 10.471203804016113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/179
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 179/200 [31:35:05<3:42:40, 636.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1249.04146030971
INFO:root:current train perplexity2.6704938411712646
INFO:root:current mean train loss 1247.401261450539
INFO:root:current train perplexity2.671445846557617
INFO:root:current mean train loss 1250.343574460873
INFO:root:current train perplexity2.672717809677124
INFO:root:current mean train loss 1251.258520293654
INFO:root:current train perplexity2.6801774501800537
INFO:root:current mean train loss 1251.3812297285951
INFO:root:current train perplexity2.684116840362549
INFO:root:current mean train loss 1252.6141147965434
INFO:root:current train perplexity2.684629440307617
INFO:root:current mean train loss 1251.931648801049
INFO:root:current train perplexity2.684915781021118
INFO:root:current mean train loss 1252.13842444407
INFO:root:current train perplexity2.68664288520813
INFO:root:current mean train loss 1252.7412935741725
INFO:root:current train perplexity2.6886868476867676
INFO:root:current mean train loss 1252.0910627685028
INFO:root:current train perplexity2.687769889831543
INFO:root:current mean train loss 1252.6877208277726
INFO:root:current train perplexity2.688713312149048
INFO:root:current mean train loss 1253.6613089700088
INFO:root:current train perplexity2.6888253688812256
INFO:root:current mean train loss 1254.0706526653394
INFO:root:current train perplexity2.6902828216552734
INFO:root:current mean train loss 1254.6374595403315
INFO:root:current train perplexity2.690044403076172
INFO:root:current mean train loss 1255.4814390481429
INFO:root:current train perplexity2.690915584564209
INFO:root:current mean train loss 1256.0165550934512
INFO:root:current train perplexity2.691049337387085
INFO:root:current mean train loss 1255.8863466660084
INFO:root:current train perplexity2.6920487880706787
INFO:root:current mean train loss 1255.4270010421526
INFO:root:current train perplexity2.691309690475464
INFO:root:current mean train loss 1255.5553973898955
INFO:root:current train perplexity2.691190004348755
INFO:root:current mean train loss 1256.0346736259735
INFO:root:current train perplexity2.692303419113159

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:24<00:00, 564.05s/it]
INFO:root:final mean train loss: 1255.5393007310183
INFO:root:final train perplexity: 2.691756248474121
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.53s/it]
INFO:root:eval mean loss: 2284.7219485019114
INFO:root:eval perplexity: 6.345520496368408
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 2872.4917481334496
INFO:root:eval perplexity: 10.477211952209473
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/180
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 180/200 [31:45:45<3:32:25, 637.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1250.8032454151219
INFO:root:current train perplexity2.657048463821411
INFO:root:current mean train loss 1257.9020474032036
INFO:root:current train perplexity2.6759591102600098
INFO:root:current mean train loss 1255.2050998054417
INFO:root:current train perplexity2.681326150894165
INFO:root:current mean train loss 1253.557593385489
INFO:root:current train perplexity2.680612564086914
INFO:root:current mean train loss 1252.6326585158804
INFO:root:current train perplexity2.679051637649536
INFO:root:current mean train loss 1252.1013581031978
INFO:root:current train perplexity2.682887315750122
INFO:root:current mean train loss 1253.8044509540377
INFO:root:current train perplexity2.68324875831604
INFO:root:current mean train loss 1253.802708320467
INFO:root:current train perplexity2.6818814277648926
INFO:root:current mean train loss 1253.0447071506203
INFO:root:current train perplexity2.681718111038208
INFO:root:current mean train loss 1252.2011665288549
INFO:root:current train perplexity2.6834073066711426
INFO:root:current mean train loss 1251.3975397817812
INFO:root:current train perplexity2.683701515197754
INFO:root:current mean train loss 1251.7006935995132
INFO:root:current train perplexity2.6856210231781006
INFO:root:current mean train loss 1252.5292548921204
INFO:root:current train perplexity2.6865317821502686
INFO:root:current mean train loss 1252.422460470417
INFO:root:current train perplexity2.6860570907592773
INFO:root:current mean train loss 1252.6434411512328
INFO:root:current train perplexity2.6854708194732666
INFO:root:current mean train loss 1253.323984945027
INFO:root:current train perplexity2.6876559257507324
INFO:root:current mean train loss 1253.8674332593994
INFO:root:current train perplexity2.68758225440979
INFO:root:current mean train loss 1254.3896739064055
INFO:root:current train perplexity2.688122510910034
INFO:root:current mean train loss 1254.7054376381582
INFO:root:current train perplexity2.6888933181762695
INFO:root:current mean train loss 1254.5365065632577
INFO:root:current train perplexity2.688760280609131

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.75s/it]
INFO:root:final mean train loss: 1254.2205969675347
INFO:root:final train perplexity: 2.688958168029785
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.22s/it]
INFO:root:eval mean loss: 2285.896386978474
INFO:root:eval perplexity: 6.35154914855957
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.22s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.22s/it]
INFO:root:eval mean loss: 2874.3868486120346
INFO:root:eval perplexity: 10.493464469909668
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/181
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 181/200 [31:56:11<3:20:46, 634.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1244.0693230879933
INFO:root:current train perplexity2.6702356338500977
INFO:root:current mean train loss 1249.5849595503373
INFO:root:current train perplexity2.675901174545288
INFO:root:current mean train loss 1251.2766215006511
INFO:root:current train perplexity2.6779210567474365
INFO:root:current mean train loss 1249.3725235310008
INFO:root:current train perplexity2.6799263954162598
INFO:root:current mean train loss 1250.200168128775
INFO:root:current train perplexity2.683394432067871
INFO:root:current mean train loss 1251.533537970649
INFO:root:current train perplexity2.682021379470825
INFO:root:current mean train loss 1251.12923291449
INFO:root:current train perplexity2.6826202869415283
INFO:root:current mean train loss 1252.3162497294318
INFO:root:current train perplexity2.68475079536438
INFO:root:current mean train loss 1252.4750860902273
INFO:root:current train perplexity2.6871466636657715
INFO:root:current mean train loss 1251.4906278516426
INFO:root:current train perplexity2.6865644454956055
INFO:root:current mean train loss 1251.3885452667578
INFO:root:current train perplexity2.686013698577881
INFO:root:current mean train loss 1251.8496141498592
INFO:root:current train perplexity2.685857057571411
INFO:root:current mean train loss 1252.3639572287054
INFO:root:current train perplexity2.686047077178955
INFO:root:current mean train loss 1252.2927514009698
INFO:root:current train perplexity2.68569278717041
INFO:root:current mean train loss 1252.8630717621263
INFO:root:current train perplexity2.6865625381469727
INFO:root:current mean train loss 1253.812041229403
INFO:root:current train perplexity2.6876609325408936
INFO:root:current mean train loss 1254.337547648209
INFO:root:current train perplexity2.6889259815216064
INFO:root:current mean train loss 1254.432397722124
INFO:root:current train perplexity2.6874759197235107
INFO:root:current mean train loss 1254.1274305396496
INFO:root:current train perplexity2.686943292617798
INFO:root:current mean train loss 1254.1639658815948
INFO:root:current train perplexity2.688222885131836

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.33s/it]
INFO:root:final mean train loss: 1253.8629343684008
INFO:root:final train perplexity: 2.688199520111084
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.55s/it]
INFO:root:eval mean loss: 2286.1117887023493
INFO:root:eval perplexity: 6.352654457092285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.44s/it]
INFO:root:eval mean loss: 2873.619399050449
INFO:root:eval perplexity: 10.486881256103516
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/182
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [32:06:53<3:10:53, 636.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1257.80322265625
INFO:root:current train perplexity2.683539628982544
INFO:root:current mean train loss 1253.9186619575778
INFO:root:current train perplexity2.6773681640625
INFO:root:current mean train loss 1251.850038912516
INFO:root:current train perplexity2.674854040145874
INFO:root:current mean train loss 1251.8125655390227
INFO:root:current train perplexity2.6797051429748535
INFO:root:current mean train loss 1253.0097252650387
INFO:root:current train perplexity2.679892063140869
INFO:root:current mean train loss 1252.0616963532884
INFO:root:current train perplexity2.681751012802124
INFO:root:current mean train loss 1252.260598451028
INFO:root:current train perplexity2.6854217052459717
INFO:root:current mean train loss 1253.542130113099
INFO:root:current train perplexity2.6865761280059814
INFO:root:current mean train loss 1253.1318979978828
INFO:root:current train perplexity2.685682773590088
INFO:root:current mean train loss 1252.448761324388
INFO:root:current train perplexity2.686070680618286
INFO:root:current mean train loss 1252.6867501554636
INFO:root:current train perplexity2.6873817443847656
INFO:root:current mean train loss 1252.5864020425136
INFO:root:current train perplexity2.6864547729492188
INFO:root:current mean train loss 1252.337748634474
INFO:root:current train perplexity2.6863691806793213
INFO:root:current mean train loss 1252.8301935353386
INFO:root:current train perplexity2.686180830001831
INFO:root:current mean train loss 1252.4313389240938
INFO:root:current train perplexity2.6853108406066895
INFO:root:current mean train loss 1252.9826572032673
INFO:root:current train perplexity2.6862456798553467
INFO:root:current mean train loss 1253.1240984245792
INFO:root:current train perplexity2.6862809658050537
INFO:root:current mean train loss 1253.0453157270679
INFO:root:current train perplexity2.6860885620117188
INFO:root:current mean train loss 1253.3246773036144
INFO:root:current train perplexity2.6856637001037598

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.96s/it]
INFO:root:final mean train loss: 1252.8572293510956
INFO:root:final train perplexity: 2.686068296432495
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.90s/it]
INFO:root:eval mean loss: 2286.416099602449
INFO:root:eval perplexity: 6.354220390319824
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 2873.9607007182235
INFO:root:eval perplexity: 10.4898099899292
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/183
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 183/200 [32:17:27<3:00:07, 635.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1263.7372924804688
INFO:root:current train perplexity2.649057388305664
INFO:root:current mean train loss 1249.8838312322443
INFO:root:current train perplexity2.663862466812134
INFO:root:current mean train loss 1251.2743849981398
INFO:root:current train perplexity2.675078868865967
INFO:root:current mean train loss 1249.7574584960937
INFO:root:current train perplexity2.679246187210083
INFO:root:current mean train loss 1250.3610726705413
INFO:root:current train perplexity2.6842763423919678
INFO:root:current mean train loss 1251.0920031977635
INFO:root:current train perplexity2.6877641677856445
INFO:root:current mean train loss 1251.8158115074282
INFO:root:current train perplexity2.6873085498809814
INFO:root:current mean train loss 1251.7926078688931
INFO:root:current train perplexity2.686272144317627
INFO:root:current mean train loss 1251.4133701654127
INFO:root:current train perplexity2.6854264736175537
INFO:root:current mean train loss 1251.5294180063102
INFO:root:current train perplexity2.684983968734741
INFO:root:current mean train loss 1251.7923428072788
INFO:root:current train perplexity2.686077833175659
INFO:root:current mean train loss 1252.0161945514851
INFO:root:current train perplexity2.6866679191589355
INFO:root:current mean train loss 1252.929766089069
INFO:root:current train perplexity2.684943914413452
INFO:root:current mean train loss 1253.1043213822459
INFO:root:current train perplexity2.684983730316162
INFO:root:current mean train loss 1253.26809151291
INFO:root:current train perplexity2.6846354007720947
INFO:root:current mean train loss 1252.86715686116
INFO:root:current train perplexity2.6834564208984375
INFO:root:current mean train loss 1252.2345477939393
INFO:root:current train perplexity2.682738780975342
INFO:root:current mean train loss 1252.429256827371
INFO:root:current train perplexity2.68324875831604
INFO:root:current mean train loss 1251.8999132693802
INFO:root:current train perplexity2.6830286979675293
INFO:root:current mean train loss 1251.997721631115
INFO:root:current train perplexity2.6840195655822754

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.06s/it]
INFO:root:final mean train loss: 1251.8588744378487
INFO:root:final train perplexity: 2.6839542388916016
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.62s/it]
INFO:root:eval mean loss: 2287.91261020958
INFO:root:eval perplexity: 6.36191463470459
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.67s/it]
INFO:root:eval mean loss: 2875.3553497098014
INFO:root:eval perplexity: 10.501778602600098
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/184
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 184/200 [32:28:05<2:49:40, 636.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1242.4956552010995
INFO:root:current train perplexity2.668663501739502
INFO:root:current mean train loss 1244.1747796967275
INFO:root:current train perplexity2.6739635467529297
INFO:root:current mean train loss 1247.8676026466135
INFO:root:current train perplexity2.676149845123291
INFO:root:current mean train loss 1246.5868673995365
INFO:root:current train perplexity2.6681106090545654
INFO:root:current mean train loss 1246.6483851841517
INFO:root:current train perplexity2.6696224212646484
INFO:root:current mean train loss 1246.287088296445
INFO:root:current train perplexity2.672736406326294
INFO:root:current mean train loss 1247.9790975518965
INFO:root:current train perplexity2.6724157333374023
INFO:root:current mean train loss 1248.6222323453082
INFO:root:current train perplexity2.6729509830474854
INFO:root:current mean train loss 1249.5112437533064
INFO:root:current train perplexity2.6759984493255615
INFO:root:current mean train loss 1250.2795628750337
INFO:root:current train perplexity2.6782491207122803
INFO:root:current mean train loss 1250.4046722382393
INFO:root:current train perplexity2.6817891597747803
INFO:root:current mean train loss 1250.7319054320099
INFO:root:current train perplexity2.6811940670013428
INFO:root:current mean train loss 1251.0530547225194
INFO:root:current train perplexity2.681272029876709
INFO:root:current mean train loss 1251.1746323908192
INFO:root:current train perplexity2.6822774410247803
INFO:root:current mean train loss 1250.9675378512065
INFO:root:current train perplexity2.6821236610412598
INFO:root:current mean train loss 1251.511778626008
INFO:root:current train perplexity2.6820895671844482
INFO:root:current mean train loss 1251.8400368716868
INFO:root:current train perplexity2.682589054107666
INFO:root:current mean train loss 1251.3227570163217
INFO:root:current train perplexity2.682464361190796
INFO:root:current mean train loss 1251.3061966418436
INFO:root:current train perplexity2.68229341506958
INFO:root:current mean train loss 1251.4860808170083
INFO:root:current train perplexity2.6816887855529785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.39s/it]
INFO:root:final mean train loss: 1250.9908363546197
INFO:root:final train perplexity: 2.6821179389953613
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it]
INFO:root:eval mean loss: 2288.217426272994
INFO:root:eval perplexity: 6.363483905792236
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.66s/it]
INFO:root:eval mean loss: 2875.8296175476507
INFO:root:eval perplexity: 10.505852699279785
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/185
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 185/200 [32:38:37<2:38:45, 635.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1246.5854325727983
INFO:root:current train perplexity2.693150520324707
INFO:root:current mean train loss 1248.8814171685112
INFO:root:current train perplexity2.6788899898529053
INFO:root:current mean train loss 1248.545527223681
INFO:root:current train perplexity2.677405834197998
INFO:root:current mean train loss 1249.2769019548284
INFO:root:current train perplexity2.6781609058380127
INFO:root:current mean train loss 1249.147836221231
INFO:root:current train perplexity2.6784427165985107
INFO:root:current mean train loss 1247.9561047273523
INFO:root:current train perplexity2.6801857948303223
INFO:root:current mean train loss 1247.2598486479765
INFO:root:current train perplexity2.6784634590148926
INFO:root:current mean train loss 1247.8734311339676
INFO:root:current train perplexity2.6778404712677
INFO:root:current mean train loss 1250.5579343678262
INFO:root:current train perplexity2.678853750228882
INFO:root:current mean train loss 1249.872533636578
INFO:root:current train perplexity2.6792452335357666
INFO:root:current mean train loss 1250.2753418670304
INFO:root:current train perplexity2.678668260574341
INFO:root:current mean train loss 1250.7654616349228
INFO:root:current train perplexity2.6776678562164307
INFO:root:current mean train loss 1250.9873586574934
INFO:root:current train perplexity2.6785430908203125
INFO:root:current mean train loss 1250.5876910800025
INFO:root:current train perplexity2.6777942180633545
INFO:root:current mean train loss 1251.2027647065984
INFO:root:current train perplexity2.679455041885376
INFO:root:current mean train loss 1250.899955551859
INFO:root:current train perplexity2.6795482635498047
INFO:root:current mean train loss 1250.555022228083
INFO:root:current train perplexity2.6798031330108643
INFO:root:current mean train loss 1250.5858091301875
INFO:root:current train perplexity2.6804580688476562
INFO:root:current mean train loss 1250.9632069883532
INFO:root:current train perplexity2.6814377307891846
INFO:root:current mean train loss 1250.83893462758
INFO:root:current train perplexity2.681572198867798

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:15<00:00, 555.92s/it]
INFO:root:final mean train loss: 1250.7320327951159
INFO:root:final train perplexity: 2.681570053100586
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 2287.024650411403
INFO:root:eval perplexity: 6.357346534729004
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.89s/it]
INFO:root:eval mean loss: 2875.3015080445202
INFO:root:eval perplexity: 10.501315116882324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/186
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 186/200 [32:49:08<2:27:52, 633.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1254.018946913422
INFO:root:current train perplexity2.6672801971435547
INFO:root:current mean train loss 1256.844180657997
INFO:root:current train perplexity2.675137996673584
INFO:root:current mean train loss 1255.425703143708
INFO:root:current train perplexity2.6767497062683105
INFO:root:current mean train loss 1253.8522895115564
INFO:root:current train perplexity2.679913282394409
INFO:root:current mean train loss 1251.5543551827718
INFO:root:current train perplexity2.6770684719085693
INFO:root:current mean train loss 1252.0894257516572
INFO:root:current train perplexity2.677375316619873
INFO:root:current mean train loss 1251.3540762989314
INFO:root:current train perplexity2.678598165512085
INFO:root:current mean train loss 1249.7655648470866
INFO:root:current train perplexity2.6793839931488037
INFO:root:current mean train loss 1250.3011002490746
INFO:root:current train perplexity2.6802353858947754
INFO:root:current mean train loss 1249.405161021031
INFO:root:current train perplexity2.679399013519287
INFO:root:current mean train loss 1249.336819489647
INFO:root:current train perplexity2.6790637969970703
INFO:root:current mean train loss 1248.967617931908
INFO:root:current train perplexity2.6788127422332764
INFO:root:current mean train loss 1248.9065726489703
INFO:root:current train perplexity2.6794004440307617
INFO:root:current mean train loss 1250.2142192271594
INFO:root:current train perplexity2.680172920227051
INFO:root:current mean train loss 1250.6559125311485
INFO:root:current train perplexity2.6784117221832275
INFO:root:current mean train loss 1250.8720373902697
INFO:root:current train perplexity2.6796438694000244
INFO:root:current mean train loss 1250.6674656233538
INFO:root:current train perplexity2.680464029312134
INFO:root:current mean train loss 1250.4248486355852
INFO:root:current train perplexity2.6801204681396484
INFO:root:current mean train loss 1250.054328832365
INFO:root:current train perplexity2.679197311401367
INFO:root:current mean train loss 1250.003444549078
INFO:root:current train perplexity2.679555892944336

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.04s/it]
INFO:root:final mean train loss: 1249.630647767991
INFO:root:final train perplexity: 2.679241895675659
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.62s/it]
INFO:root:eval mean loss: 2289.2897286922375
INFO:root:eval perplexity: 6.36900520324707
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it]
INFO:root:eval mean loss: 2878.0571631032526
INFO:root:eval perplexity: 10.525007247924805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/187
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 187/200 [32:59:38<2:17:06, 632.85s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1239.4925677959736
INFO:root:current train perplexity2.6868796348571777
INFO:root:current mean train loss 1246.2142910046523
INFO:root:current train perplexity2.6808884143829346
INFO:root:current mean train loss 1246.6655255873427
INFO:root:current train perplexity2.6715502738952637
INFO:root:current mean train loss 1246.851124274037
INFO:root:current train perplexity2.6709647178649902
INFO:root:current mean train loss 1245.427954510166
INFO:root:current train perplexity2.670459747314453
INFO:root:current mean train loss 1245.4233694109537
INFO:root:current train perplexity2.672382354736328
INFO:root:current mean train loss 1245.5744781944252
INFO:root:current train perplexity2.673279285430908
INFO:root:current mean train loss 1246.1373755447662
INFO:root:current train perplexity2.672283887863159
INFO:root:current mean train loss 1245.9758494036073
INFO:root:current train perplexity2.6735854148864746
INFO:root:current mean train loss 1246.754000860733
INFO:root:current train perplexity2.6739211082458496
INFO:root:current mean train loss 1247.243476145785
INFO:root:current train perplexity2.6755220890045166
INFO:root:current mean train loss 1247.3990336549302
INFO:root:current train perplexity2.675781726837158
INFO:root:current mean train loss 1248.2616749078454
INFO:root:current train perplexity2.675593376159668
INFO:root:current mean train loss 1248.807157076322
INFO:root:current train perplexity2.6748640537261963
INFO:root:current mean train loss 1248.9128347765932
INFO:root:current train perplexity2.67523455619812
INFO:root:current mean train loss 1248.9149785688471
INFO:root:current train perplexity2.674475908279419
INFO:root:current mean train loss 1248.475454701002
INFO:root:current train perplexity2.6739799976348877
INFO:root:current mean train loss 1248.68138089947
INFO:root:current train perplexity2.6747114658355713
INFO:root:current mean train loss 1249.0257130258253
INFO:root:current train perplexity2.6761133670806885
INFO:root:current mean train loss 1248.8562385705652
INFO:root:current train perplexity2.676776885986328

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.06s/it]
INFO:root:final mean train loss: 1248.5764705255906
INFO:root:final train perplexity: 2.6770153045654297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.20s/it]
INFO:root:eval mean loss: 2289.4045241335607
INFO:root:eval perplexity: 6.369596481323242
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.54s/it]
INFO:root:eval mean loss: 2877.7420247395835
INFO:root:eval perplexity: 10.522296905517578
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/188
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [33:10:09<2:06:27, 632.32s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1248.255746299342
INFO:root:current train perplexity2.6784069538116455
INFO:root:current mean train loss 1245.5405661558493
INFO:root:current train perplexity2.661943197250366
INFO:root:current mean train loss 1246.8548749503443
INFO:root:current train perplexity2.66060209274292
INFO:root:current mean train loss 1246.3359384271164
INFO:root:current train perplexity2.660792589187622
INFO:root:current mean train loss 1247.731604620423
INFO:root:current train perplexity2.6661102771759033
INFO:root:current mean train loss 1247.2846281676734
INFO:root:current train perplexity2.6678037643432617
INFO:root:current mean train loss 1246.7088396470324
INFO:root:current train perplexity2.6676857471466064
INFO:root:current mean train loss 1246.1866132628243
INFO:root:current train perplexity2.667924404144287
INFO:root:current mean train loss 1246.189662076641
INFO:root:current train perplexity2.6678833961486816
INFO:root:current mean train loss 1247.2178585800095
INFO:root:current train perplexity2.6692054271698
INFO:root:current mean train loss 1247.2082347852454
INFO:root:current train perplexity2.6711621284484863
INFO:root:current mean train loss 1247.7473758458093
INFO:root:current train perplexity2.6723289489746094
INFO:root:current mean train loss 1247.273622066542
INFO:root:current train perplexity2.6728708744049072
INFO:root:current mean train loss 1247.2735247430835
INFO:root:current train perplexity2.6741108894348145
INFO:root:current mean train loss 1247.9073369565217
INFO:root:current train perplexity2.674839496612549
INFO:root:current mean train loss 1247.8705432473305
INFO:root:current train perplexity2.6756625175476074
INFO:root:current mean train loss 1248.384489220363
INFO:root:current train perplexity2.675794839859009
INFO:root:current mean train loss 1248.5145656065024
INFO:root:current train perplexity2.6767122745513916
INFO:root:current mean train loss 1248.6479369150932
INFO:root:current train perplexity2.677560567855835

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.62s/it]
INFO:root:final mean train loss: 1248.5521046325407
INFO:root:final train perplexity: 2.676964282989502
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.08s/it]
INFO:root:eval mean loss: 2290.5678416583555
INFO:root:eval perplexity: 6.3755903244018555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.61s/it]
INFO:root:eval mean loss: 2880.126218105884
INFO:root:eval perplexity: 10.54283332824707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/189
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 189/200 [33:20:51<1:56:25, 635.09s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1249.1516520182292
INFO:root:current train perplexity2.679215431213379
INFO:root:current mean train loss 1242.8116934640068
INFO:root:current train perplexity2.6554512977600098
INFO:root:current mean train loss 1243.6266629201061
INFO:root:current train perplexity2.669717311859131
INFO:root:current mean train loss 1244.7107117481721
INFO:root:current train perplexity2.6690428256988525
INFO:root:current mean train loss 1243.656786279771
INFO:root:current train perplexity2.6672298908233643
INFO:root:current mean train loss 1244.0616657733917
INFO:root:current train perplexity2.6711535453796387
INFO:root:current mean train loss 1246.1385428235421
INFO:root:current train perplexity2.670228958129883
INFO:root:current mean train loss 1247.2399379430192
INFO:root:current train perplexity2.6722536087036133
INFO:root:current mean train loss 1247.48159579573
INFO:root:current train perplexity2.6743810176849365
INFO:root:current mean train loss 1246.1812811065138
INFO:root:current train perplexity2.6747097969055176
INFO:root:current mean train loss 1246.506907587466
INFO:root:current train perplexity2.6739323139190674
INFO:root:current mean train loss 1247.0510004715954
INFO:root:current train perplexity2.6737654209136963
INFO:root:current mean train loss 1247.4693166399159
INFO:root:current train perplexity2.673460006713867
INFO:root:current mean train loss 1247.0938999827315
INFO:root:current train perplexity2.6737289428710938
INFO:root:current mean train loss 1247.4862169476473
INFO:root:current train perplexity2.674567937850952
INFO:root:current mean train loss 1247.8132408182457
INFO:root:current train perplexity2.674398183822632
INFO:root:current mean train loss 1247.661835776961
INFO:root:current train perplexity2.675151824951172
INFO:root:current mean train loss 1247.5614893547843
INFO:root:current train perplexity2.67466139793396
INFO:root:current mean train loss 1247.7549581296134
INFO:root:current train perplexity2.674793004989624
INFO:root:current mean train loss 1247.8868279876071
INFO:root:current train perplexity2.6752326488494873

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.84s/it]
INFO:root:final mean train loss: 1247.5488791261366
INFO:root:final train perplexity: 2.674846887588501
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.70s/it]
INFO:root:eval mean loss: 2290.2527006974456
INFO:root:eval perplexity: 6.373967170715332
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.63s/it]
INFO:root:eval mean loss: 2880.0769856770835
INFO:root:eval perplexity: 10.542410850524902
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/190
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 190/200 [33:31:24<1:45:46, 634.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1251.1019329202586
INFO:root:current train perplexity2.6635680198669434
INFO:root:current mean train loss 1240.4137691527374
INFO:root:current train perplexity2.666905641555786
INFO:root:current mean train loss 1241.6715295783297
INFO:root:current train perplexity2.664822816848755
INFO:root:current mean train loss 1244.4403903578552
INFO:root:current train perplexity2.6701338291168213
INFO:root:current mean train loss 1247.2355154611014
INFO:root:current train perplexity2.672222375869751
INFO:root:current mean train loss 1246.965064353438
INFO:root:current train perplexity2.672212839126587
INFO:root:current mean train loss 1245.3429779877533
INFO:root:current train perplexity2.6712934970855713
INFO:root:current mean train loss 1246.8678140941145
INFO:root:current train perplexity2.67159366607666
INFO:root:current mean train loss 1246.5979859429187
INFO:root:current train perplexity2.6719014644622803
INFO:root:current mean train loss 1247.107736445859
INFO:root:current train perplexity2.6736488342285156
INFO:root:current mean train loss 1246.5584772552995
INFO:root:current train perplexity2.6738333702087402
INFO:root:current mean train loss 1245.856629985745
INFO:root:current train perplexity2.673740863800049
INFO:root:current mean train loss 1246.4121652949234
INFO:root:current train perplexity2.672797679901123
INFO:root:current mean train loss 1246.96751790732
INFO:root:current train perplexity2.6733109951019287
INFO:root:current mean train loss 1247.235119124907
INFO:root:current train perplexity2.674325704574585
INFO:root:current mean train loss 1247.490715790294
INFO:root:current train perplexity2.673910140991211
INFO:root:current mean train loss 1247.612328442128
INFO:root:current train perplexity2.675171136856079
INFO:root:current mean train loss 1247.3102949681897
INFO:root:current train perplexity2.67512583732605
INFO:root:current mean train loss 1247.3163393749574
INFO:root:current train perplexity2.6747920513153076
INFO:root:current mean train loss 1247.4697764284442
INFO:root:current train perplexity2.674539566040039

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:18<00:00, 558.01s/it]
INFO:root:final mean train loss: 1247.5018999385402
INFO:root:final train perplexity: 2.6747474670410156
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.49s/it]
INFO:root:eval mean loss: 2290.39638394836
INFO:root:eval perplexity: 6.374706745147705
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.76s/it]
INFO:root:eval mean loss: 2880.6130678433897
INFO:root:eval perplexity: 10.547032356262207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/191
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 191/200 [33:41:58<1:35:08, 634.29s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1239.7754357379415
INFO:root:current train perplexity2.6481220722198486
INFO:root:current mean train loss 1236.1125530086151
INFO:root:current train perplexity2.652493953704834
INFO:root:current mean train loss 1240.9260045493522
INFO:root:current train perplexity2.6648736000061035
INFO:root:current mean train loss 1242.6796441050624
INFO:root:current train perplexity2.669463634490967
INFO:root:current mean train loss 1242.227750632795
INFO:root:current train perplexity2.666557550430298
INFO:root:current mean train loss 1242.7002319783082
INFO:root:current train perplexity2.6672005653381348
INFO:root:current mean train loss 1243.0959861920715
INFO:root:current train perplexity2.668264627456665
INFO:root:current mean train loss 1243.3603738166053
INFO:root:current train perplexity2.6676135063171387
INFO:root:current mean train loss 1244.3061767289544
INFO:root:current train perplexity2.666635274887085
INFO:root:current mean train loss 1244.1717094437518
INFO:root:current train perplexity2.666200637817383
INFO:root:current mean train loss 1244.830650431704
INFO:root:current train perplexity2.6663572788238525
INFO:root:current mean train loss 1245.5582113482358
INFO:root:current train perplexity2.6668875217437744
INFO:root:current mean train loss 1245.835614297784
INFO:root:current train perplexity2.6691606044769287
INFO:root:current mean train loss 1245.987114961576
INFO:root:current train perplexity2.669816255569458
INFO:root:current mean train loss 1245.8902503471322
INFO:root:current train perplexity2.6704509258270264
INFO:root:current mean train loss 1245.6555215260653
INFO:root:current train perplexity2.6708672046661377
INFO:root:current mean train loss 1245.8953907110276
INFO:root:current train perplexity2.671675205230713
INFO:root:current mean train loss 1246.3428153161467
INFO:root:current train perplexity2.671769142150879
INFO:root:current mean train loss 1246.6263663807515
INFO:root:current train perplexity2.6719045639038086
INFO:root:current mean train loss 1246.4026793492662
INFO:root:current train perplexity2.671536922454834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:16<00:00, 556.73s/it]
INFO:root:final mean train loss: 1246.0973728351141
INFO:root:final train perplexity: 2.6717867851257324
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.21s/it]
INFO:root:eval mean loss: 2291.498539917858
INFO:root:eval perplexity: 6.380392551422119
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.23s/it]
INFO:root:eval mean loss: 2881.051089455895
INFO:root:eval perplexity: 10.550811767578125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/192
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 192/200 [33:52:29<1:24:27, 633.43s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1262.5401863219247
INFO:root:current train perplexity2.6530869007110596
INFO:root:current mean train loss 1246.5351015804736
INFO:root:current train perplexity2.672106981277466
INFO:root:current mean train loss 1244.4440560576581
INFO:root:current train perplexity2.670813798904419
INFO:root:current mean train loss 1247.6257085458635
INFO:root:current train perplexity2.6696062088012695
INFO:root:current mean train loss 1248.6041900437028
INFO:root:current train perplexity2.669391632080078
INFO:root:current mean train loss 1248.326189437514
INFO:root:current train perplexity2.6721127033233643
INFO:root:current mean train loss 1248.5886994558941
INFO:root:current train perplexity2.6733591556549072
INFO:root:current mean train loss 1248.423800127222
INFO:root:current train perplexity2.6717803478240967
INFO:root:current mean train loss 1247.2182013201134
INFO:root:current train perplexity2.6710946559906006
INFO:root:current mean train loss 1246.9982133114697
INFO:root:current train perplexity2.671208620071411
INFO:root:current mean train loss 1247.1039220284204
INFO:root:current train perplexity2.672743558883667
INFO:root:current mean train loss 1247.004190485947
INFO:root:current train perplexity2.6726908683776855
INFO:root:current mean train loss 1247.3698659913462
INFO:root:current train perplexity2.6731841564178467
INFO:root:current mean train loss 1246.7838887069825
INFO:root:current train perplexity2.6723649501800537
INFO:root:current mean train loss 1246.4855662493858
INFO:root:current train perplexity2.6731908321380615
INFO:root:current mean train loss 1246.7847597362595
INFO:root:current train perplexity2.673283576965332
INFO:root:current mean train loss 1246.7723746881811
INFO:root:current train perplexity2.672823667526245
INFO:root:current mean train loss 1247.3221597568731
INFO:root:current train perplexity2.672240734100342
INFO:root:current mean train loss 1247.2071492578543
INFO:root:current train perplexity2.672804117202759
INFO:root:current mean train loss 1246.5891812869133
INFO:root:current train perplexity2.672635793685913

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:22<00:00, 562.72s/it]
INFO:root:final mean train loss: 1246.4353806980919
INFO:root:final train perplexity: 2.672498941421509
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.94s/it]
INFO:root:eval mean loss: 2291.8166170593695
INFO:root:eval perplexity: 6.382033348083496
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.40s/it]
INFO:root:eval mean loss: 2881.532420489805
INFO:root:eval perplexity: 10.55496597290039
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/193
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 193/200 [34:03:07<1:14:02, 634.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1242.7173904418946
INFO:root:current train perplexity2.664644718170166
INFO:root:current mean train loss 1244.2476406521268
INFO:root:current train perplexity2.671111822128296
INFO:root:current mean train loss 1243.573441859654
INFO:root:current train perplexity2.672916889190674
INFO:root:current mean train loss 1243.9507645456415
INFO:root:current train perplexity2.672877788543701
INFO:root:current mean train loss 1245.0538663228353
INFO:root:current train perplexity2.670076370239258
INFO:root:current mean train loss 1244.6643811456088
INFO:root:current train perplexity2.668731212615967
INFO:root:current mean train loss 1243.9543904024013
INFO:root:current train perplexity2.666579484939575
INFO:root:current mean train loss 1244.6846571702224
INFO:root:current train perplexity2.668353796005249
INFO:root:current mean train loss 1244.696269087358
INFO:root:current train perplexity2.667527675628662
INFO:root:current mean train loss 1244.6486269581076
INFO:root:current train perplexity2.667001724243164
INFO:root:current mean train loss 1244.262991333008
INFO:root:current train perplexity2.666917562484741
INFO:root:current mean train loss 1245.085642048464
INFO:root:current train perplexity2.668052911758423
INFO:root:current mean train loss 1245.2272909164428
INFO:root:current train perplexity2.668226480484009
INFO:root:current mean train loss 1245.4713282488394
INFO:root:current train perplexity2.6681461334228516
INFO:root:current mean train loss 1245.078828223976
INFO:root:current train perplexity2.668501377105713
INFO:root:current mean train loss 1244.6299181974387
INFO:root:current train perplexity2.6689651012420654
INFO:root:current mean train loss 1244.4111812046597
INFO:root:current train perplexity2.6687190532684326
INFO:root:current mean train loss 1244.9549476194918
INFO:root:current train perplexity2.6690824031829834
INFO:root:current mean train loss 1245.278016305477
INFO:root:current train perplexity2.670067071914673
INFO:root:current mean train loss 1245.4440558539497
INFO:root:current train perplexity2.6697680950164795

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:31<00:00, 571.65s/it]
INFO:root:final mean train loss: 1245.0688900392101
INFO:root:final train perplexity: 2.6696200370788574
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.01s/it]
INFO:root:eval mean loss: 2292.163827016844
INFO:root:eval perplexity: 6.38382625579834
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.39s/it]
INFO:root:eval mean loss: 2881.878233997534
INFO:root:eval perplexity: 10.557950973510742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/194
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [34:13:55<1:03:52, 638.72s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1234.631694990335
INFO:root:current train perplexity2.666903018951416
INFO:root:current mean train loss 1237.7965515446542
INFO:root:current train perplexity2.6637048721313477
INFO:root:current mean train loss 1241.8335507582333
INFO:root:current train perplexity2.6712512969970703
INFO:root:current mean train loss 1243.8749400410304
INFO:root:current train perplexity2.6667356491088867
INFO:root:current mean train loss 1244.1873248769964
INFO:root:current train perplexity2.665001630783081
INFO:root:current mean train loss 1243.5049147102702
INFO:root:current train perplexity2.666837453842163
INFO:root:current mean train loss 1243.5993822226394
INFO:root:current train perplexity2.67035174369812
INFO:root:current mean train loss 1243.8261055557462
INFO:root:current train perplexity2.6692981719970703
INFO:root:current mean train loss 1244.869212479097
INFO:root:current train perplexity2.6689789295196533
INFO:root:current mean train loss 1244.4523748246693
INFO:root:current train perplexity2.669903516769409
INFO:root:current mean train loss 1244.71829154085
INFO:root:current train perplexity2.670438528060913
INFO:root:current mean train loss 1244.6211893054576
INFO:root:current train perplexity2.6701343059539795
INFO:root:current mean train loss 1244.737271558163
INFO:root:current train perplexity2.6685707569122314
INFO:root:current mean train loss 1244.9394376586827
INFO:root:current train perplexity2.6688427925109863
INFO:root:current mean train loss 1244.6540717339626
INFO:root:current train perplexity2.669187307357788
INFO:root:current mean train loss 1245.4347792155459
INFO:root:current train perplexity2.6692326068878174
INFO:root:current mean train loss 1245.6078615295373
INFO:root:current train perplexity2.6699016094207764
INFO:root:current mean train loss 1245.7535877259625
INFO:root:current train perplexity2.669867515563965
INFO:root:current mean train loss 1245.6224375530237
INFO:root:current train perplexity2.6694977283477783

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.17s/it]
INFO:root:final mean train loss: 1245.1053615152625
INFO:root:final train perplexity: 2.6696970462799072
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:40<00:00, 40.97s/it]
INFO:root:eval mean loss: 2291.888719923953
INFO:root:eval perplexity: 6.38240385055542
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.72s/it]
INFO:root:eval mean loss: 2881.6637010506706
INFO:root:eval perplexity: 10.556098937988281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/195
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 195/200 [34:24:33<53:12, 638.56s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1225.1379656110491
INFO:root:current train perplexity2.682539701461792
INFO:root:current mean train loss 1244.1398111979167
INFO:root:current train perplexity2.671675205230713
INFO:root:current mean train loss 1246.4915720146394
INFO:root:current train perplexity2.6711976528167725
INFO:root:current mean train loss 1245.5181663173018
INFO:root:current train perplexity2.6678929328918457
INFO:root:current mean train loss 1245.618920662553
INFO:root:current train perplexity2.668900966644287
INFO:root:current mean train loss 1245.5340298307544
INFO:root:current train perplexity2.6708261966705322
INFO:root:current mean train loss 1244.2224834827337
INFO:root:current train perplexity2.6695032119750977
INFO:root:current mean train loss 1244.5796366886598
INFO:root:current train perplexity2.6691343784332275
INFO:root:current mean train loss 1245.1936614015472
INFO:root:current train perplexity2.6683504581451416
INFO:root:current mean train loss 1245.701381825253
INFO:root:current train perplexity2.6696889400482178
INFO:root:current mean train loss 1244.9453164727024
INFO:root:current train perplexity2.6694555282592773
INFO:root:current mean train loss 1244.6245438252147
INFO:root:current train perplexity2.6693661212921143
INFO:root:current mean train loss 1244.8489798179764
INFO:root:current train perplexity2.6691598892211914
INFO:root:current mean train loss 1244.5660715320882
INFO:root:current train perplexity2.668564558029175
INFO:root:current mean train loss 1244.4979703004828
INFO:root:current train perplexity2.668239116668701
INFO:root:current mean train loss 1245.113816134051
INFO:root:current train perplexity2.667353391647339
INFO:root:current mean train loss 1245.5321515353935
INFO:root:current train perplexity2.6680967807769775
INFO:root:current mean train loss 1245.3351187600276
INFO:root:current train perplexity2.668309211730957
INFO:root:current mean train loss 1245.4595279041698
INFO:root:current train perplexity2.6688015460968018
INFO:root:current mean train loss 1245.4016274000783
INFO:root:current train perplexity2.6687896251678467

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.82s/it]
INFO:root:final mean train loss: 1244.9398847109612
INFO:root:final train perplexity: 2.66934871673584
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.37s/it]
INFO:root:eval mean loss: 2292.0255590127713
INFO:root:eval perplexity: 6.38311243057251
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.27s/it]
INFO:root:eval mean loss: 2881.227619144088
INFO:root:eval perplexity: 10.55233383178711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/196
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 196/200 [34:35:06<42:27, 636.82s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1233.995125063004
INFO:root:current train perplexity2.681582450866699
INFO:root:current mean train loss 1244.9421880591008
INFO:root:current train perplexity2.6709721088409424
INFO:root:current mean train loss 1247.1646723231195
INFO:root:current train perplexity2.6657943725585938
INFO:root:current mean train loss 1245.4397064854372
INFO:root:current train perplexity2.6648759841918945
INFO:root:current mean train loss 1246.0753918711935
INFO:root:current train perplexity2.6681466102600098
INFO:root:current mean train loss 1247.7558340873647
INFO:root:current train perplexity2.6704397201538086
INFO:root:current mean train loss 1247.9707930817278
INFO:root:current train perplexity2.669633150100708
INFO:root:current mean train loss 1247.6522185068613
INFO:root:current train perplexity2.6704013347625732
INFO:root:current mean train loss 1247.681052748477
INFO:root:current train perplexity2.6707961559295654
INFO:root:current mean train loss 1247.2149578221502
INFO:root:current train perplexity2.6710243225097656
INFO:root:current mean train loss 1246.4847524589295
INFO:root:current train perplexity2.6707968711853027
INFO:root:current mean train loss 1245.3024567756686
INFO:root:current train perplexity2.6702396869659424
INFO:root:current mean train loss 1245.6887261571194
INFO:root:current train perplexity2.669687509536743
INFO:root:current mean train loss 1245.8218638293283
INFO:root:current train perplexity2.6702539920806885
INFO:root:current mean train loss 1245.772978478091
INFO:root:current train perplexity2.6710145473480225
INFO:root:current mean train loss 1245.3578791403443
INFO:root:current train perplexity2.670536994934082
INFO:root:current mean train loss 1244.8640207820404
INFO:root:current train perplexity2.6695950031280518
INFO:root:current mean train loss 1244.7955925212575
INFO:root:current train perplexity2.669004201889038
INFO:root:current mean train loss 1244.8861678668802
INFO:root:current train perplexity2.6694986820220947
INFO:root:current mean train loss 1245.218243196429
INFO:root:current train perplexity2.669515609741211

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:17<00:00, 557.62s/it]
INFO:root:final mean train loss: 1244.703578823934
INFO:root:final train perplexity: 2.668851375579834
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.86s/it]
INFO:root:eval mean loss: 2292.436834240636
INFO:root:eval perplexity: 6.385234832763672
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.84s/it]
INFO:root:eval mean loss: 2881.818068916916
INFO:root:eval perplexity: 10.557430267333984
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/197
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 197/200 [34:45:39<31:46, 635.56s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1241.6097717285156
INFO:root:current train perplexity2.6727187633514404
INFO:root:current mean train loss 1240.766361545872
INFO:root:current train perplexity2.6684231758117676
INFO:root:current mean train loss 1239.524165491904
INFO:root:current train perplexity2.662024736404419
INFO:root:current mean train loss 1242.000511783293
INFO:root:current train perplexity2.6629769802093506
INFO:root:current mean train loss 1241.0590242658343
INFO:root:current train perplexity2.663031578063965
INFO:root:current mean train loss 1242.4261178343836
INFO:root:current train perplexity2.6600301265716553
INFO:root:current mean train loss 1242.1163433687186
INFO:root:current train perplexity2.661269426345825
INFO:root:current mean train loss 1241.9438122428037
INFO:root:current train perplexity2.662240743637085
INFO:root:current mean train loss 1242.7892484844856
INFO:root:current train perplexity2.662569522857666
INFO:root:current mean train loss 1243.4336786068945
INFO:root:current train perplexity2.6666293144226074
INFO:root:current mean train loss 1244.233187493477
INFO:root:current train perplexity2.6678690910339355
INFO:root:current mean train loss 1244.131051625109
INFO:root:current train perplexity2.668546438217163
INFO:root:current mean train loss 1244.6304339873484
INFO:root:current train perplexity2.669405460357666
INFO:root:current mean train loss 1245.230083069391
INFO:root:current train perplexity2.6696865558624268
INFO:root:current mean train loss 1245.2381826158387
INFO:root:current train perplexity2.6681981086730957
INFO:root:current mean train loss 1245.0587147163174
INFO:root:current train perplexity2.6678731441497803
INFO:root:current mean train loss 1244.5919335374554
INFO:root:current train perplexity2.6671934127807617
INFO:root:current mean train loss 1244.253697166181
INFO:root:current train perplexity2.6669745445251465
INFO:root:current mean train loss 1244.4447555872268
INFO:root:current train perplexity2.6669869422912598
INFO:root:current mean train loss 1244.3539204998917
INFO:root:current train perplexity2.6672232151031494

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:25<00:00, 565.90s/it]
INFO:root:final mean train loss: 1243.8577570912817
INFO:root:final train perplexity: 2.667071580886841
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.59s/it]
INFO:root:eval mean loss: 2292.3898904137577
INFO:root:eval perplexity: 6.384991645812988
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.75s/it]
INFO:root:eval mean loss: 2881.967312427277
INFO:root:eval perplexity: 10.55871868133545
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/198
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 198/200 [34:56:26<21:18, 639.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1228.6528339092547
INFO:root:current train perplexity2.6716396808624268
INFO:root:current mean train loss 1237.6946821732954
INFO:root:current train perplexity2.664836883544922
INFO:root:current mean train loss 1241.6880320423054
INFO:root:current train perplexity2.669569253921509
INFO:root:current mean train loss 1241.1954941004924
INFO:root:current train perplexity2.6730668544769287
INFO:root:current mean train loss 1242.278863984795
INFO:root:current train perplexity2.67122745513916
INFO:root:current mean train loss 1242.3470346636477
INFO:root:current train perplexity2.6711132526397705
INFO:root:current mean train loss 1242.1818970644385
INFO:root:current train perplexity2.6711394786834717
INFO:root:current mean train loss 1242.2098958333333
INFO:root:current train perplexity2.67106556892395
INFO:root:current mean train loss 1242.5831489342486
INFO:root:current train perplexity2.671036958694458
INFO:root:current mean train loss 1242.6286002519835
INFO:root:current train perplexity2.672088146209717
INFO:root:current mean train loss 1243.6352304091477
INFO:root:current train perplexity2.6717052459716797
INFO:root:current mean train loss 1243.5520654506438
INFO:root:current train perplexity2.670006513595581
INFO:root:current mean train loss 1243.7053819015564
INFO:root:current train perplexity2.6703152656555176
INFO:root:current mean train loss 1243.9478392213255
INFO:root:current train perplexity2.669382333755493
INFO:root:current mean train loss 1243.502362081378
INFO:root:current train perplexity2.669226884841919
INFO:root:current mean train loss 1243.9492503400809
INFO:root:current train perplexity2.6684465408325195
INFO:root:current mean train loss 1243.7204023848067
INFO:root:current train perplexity2.668165922164917
INFO:root:current mean train loss 1243.720726432476
INFO:root:current train perplexity2.666754961013794
INFO:root:current mean train loss 1243.6871032878478
INFO:root:current train perplexity2.666454792022705
INFO:root:current mean train loss 1243.813061026459
INFO:root:current train perplexity2.6663010120391846

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:11<00:00, 551.30s/it]
INFO:root:final mean train loss: 1243.4209052704828
INFO:root:final train perplexity: 2.6661527156829834
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.63s/it]
INFO:root:eval mean loss: 2292.486302152593
INFO:root:eval perplexity: 6.385490894317627
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.75s/it]
INFO:root:eval mean loss: 2882.1464982269504
INFO:root:eval perplexity: 10.560264587402344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/199
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 199/200 [35:06:53<10:35, 635.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1229.631356588224
INFO:root:current train perplexity2.6772003173828125
INFO:root:current mean train loss 1237.2890088427198
INFO:root:current train perplexity2.6654253005981445
INFO:root:current mean train loss 1239.7587007563166
INFO:root:current train perplexity2.665708065032959
INFO:root:current mean train loss 1238.112275288367
INFO:root:current train perplexity2.6620419025421143
INFO:root:current mean train loss 1240.8772914775675
INFO:root:current train perplexity2.6633405685424805
INFO:root:current mean train loss 1242.5820048224066
INFO:root:current train perplexity2.6654956340789795
INFO:root:current mean train loss 1242.6907096258706
INFO:root:current train perplexity2.6651368141174316
INFO:root:current mean train loss 1243.8683053331301
INFO:root:current train perplexity2.6649959087371826
INFO:root:current mean train loss 1243.0499476564714
INFO:root:current train perplexity2.665198564529419
INFO:root:current mean train loss 1242.6492849066399
INFO:root:current train perplexity2.666428327560425
INFO:root:current mean train loss 1243.6501276435781
INFO:root:current train perplexity2.666734218597412
INFO:root:current mean train loss 1243.4357399980831
INFO:root:current train perplexity2.6666157245635986
INFO:root:current mean train loss 1243.4370998912223
INFO:root:current train perplexity2.66619610786438
INFO:root:current mean train loss 1243.7877638026016
INFO:root:current train perplexity2.6668615341186523
INFO:root:current mean train loss 1243.5904408402128
INFO:root:current train perplexity2.6667256355285645
INFO:root:current mean train loss 1243.5243164525473
INFO:root:current train perplexity2.66660475730896
INFO:root:current mean train loss 1243.8223753576472
INFO:root:current train perplexity2.666043281555176
INFO:root:current mean train loss 1243.9406933511548
INFO:root:current train perplexity2.666468381881714
INFO:root:current mean train loss 1243.6680528111717
INFO:root:current train perplexity2.6663970947265625
INFO:root:current mean train loss 1243.6628342213712
INFO:root:current train perplexity2.6659865379333496

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.81s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:19<00:00, 559.81s/it]
INFO:root:final mean train loss: 1243.3441818321946
INFO:root:final train perplexity: 2.6659915447235107
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.71s/it]
INFO:root:eval mean loss: 2292.4371311918217
INFO:root:eval perplexity: 6.385237216949463
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.60s/it]
INFO:root:eval mean loss: 2882.101703616744
INFO:root:eval perplexity: 10.559882164001465
INFO:root:evalaution complete
INFO:root:checkpoint. save model: allminil16_minilml12_real/200
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [35:17:28<00:00, 635.47s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [35:17:29<00:00, 635.25s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.83s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:51<00:00, 51.83s/it]
INFO:root:eval mean loss: 2292.4371311918217
INFO:root:eval perplexity: 6.385237216949463
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.70s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:43<00:00, 43.70s/it]
INFO:root:eval mean loss: 2882.101703616744
INFO:root:eval perplexity: 10.559882164001465
INFO:root:evalaution complete
INFO:root:save model final: allminil16_minilml12_real/final
Fatal error condition occurred in /opt/vcpkg/buildtrees/aws-c-io/src/9e6648842a-364b708815.clean/source/event_loop.c:72: aws_thread_launch(&cleanup_thread, s_event_loop_destroy_async_thread_fn, el_group, &thread_options) == AWS_OP_SUCCESS
Exiting Application
################################################################################
Stack trace:
################################################################################
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200af06) [0x1477406bbf06]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x20028e5) [0x1477406b38e5]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f27e09) [0x1477405d8e09]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x1477406bca3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1f25948) [0x1477405d6948]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x200ba3d) [0x1477406bca3d]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x1ee0b46) [0x147740591b46]
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/pyarrow/libarrow.so.900(+0x194546a) [0x14773fff646a]
/lib/x86_64-linux-gnu/libc.so.6(+0x49a27) [0x14783c812a27]
/lib/x86_64-linux-gnu/libc.so.6(on_exit+0) [0x14783c812be0]
python(+0x24a989) [0x555b5d638989]
python(+0x24a9bd) [0x555b5d6389bd]
python(+0x24aa14) [0x555b5d638a14]
python(+0x108f75) [0x555b5d4f6f75]
python(Py_RunMain+0x313) [0x555b5d63b983]
python(Py_BytesMain+0x39) [0x555b5d63bbc9]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x14783c7f00b3]
python(+0x1d6e13) [0x555b5d5c4e13]
/opt/slurm/data/slurmd/job29414821/slurm_script: line 224: 1389215 Aborted                 singularity exec --nv --overlay /scratch/zw2374/overlay-50G-10M.ext3:ro /scratch/work/public/singularity/cuda11.3.0-cudnn8-devel-ubuntu20.04.sif /bin/bash -c "
source /ext3/env.sh
conda activate rblm
python train_script.py --model_path microsoft/MiniLM-L12-H384-uncased --data_config data_config.json --data_folder fast_processed_data_opt_allmini --output allminil16_minilml12_real --epochs 200 --save_head  --save_epochs 1 --external_embedding --test_eval
"
