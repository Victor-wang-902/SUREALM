INFO:root:Output: std_33
INFO:root:Steps per epochs:1983
INFO:root:Total steps:198300
/scratch/zw2374/public/faiss_db/models.py:432: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['cls.predictions.transform.dense.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.1.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.5.crossattention.self.value.weight', 'cls.predictions.bias', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'cls.predictions.decoder.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:446: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training

  0%|          | 0/100 [00:00<?, ?it/s]

  0%|          | 0/1 [00:00<?, ?it/s][A/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.
  warnings.warn('Was asked to gather along dimension 0, but all '
INFO:root:current mean train loss 12223.13828716856
INFO:root:current train perplexity16502.34765625
INFO:root:current mean train loss 10531.928379691426
INFO:root:current train perplexity4072.711181640625
INFO:root:current mean train loss 9163.025973623015
INFO:root:current train perplexity1372.591552734375
INFO:root:current mean train loss 8216.68623830083
INFO:root:current train perplexity650.0946655273438
INFO:root:current mean train loss 7526.280498986253
INFO:root:current train perplexity377.9118347167969
INFO:root:current mean train loss 7002.610682517738
INFO:root:current train perplexity250.00682067871094
INFO:root:current mean train loss 6594.006308537867
INFO:root:current train perplexity180.5634307861328
INFO:root:current mean train loss 6269.740898657502
INFO:root:current train perplexity139.3689422607422
INFO:root:current mean train loss 5993.736502200796
INFO:root:current train perplexity112.67105102539062
INFO:root:current mean train loss 5770.215240386871
INFO:root:current train perplexity93.97298431396484
INFO:root:current mean train loss 5571.141015980436
INFO:root:current train perplexity80.50727844238281
INFO:root:current mean train loss 5401.926761884904
INFO:root:current train perplexity70.49268341064453
INFO:root:current mean train loss 5255.875907210775
INFO:root:current train perplexity62.65224075317383
INFO:root:current mean train loss 5120.468867620287
INFO:root:current train perplexity56.4520149230957
INFO:root:current mean train loss 5002.110235925513
INFO:root:current train perplexity51.494911193847656
INFO:root:current mean train loss 4895.686390450331
INFO:root:current train perplexity47.37592697143555
INFO:root:current mean train loss 4800.43129172951
INFO:root:current train perplexity43.91670227050781
INFO:root:current mean train loss 4712.172991478556
INFO:root:current train perplexity41.011173248291016
INFO:root:current mean train loss 4629.746072922838
INFO:root:current train perplexity38.489559173583984


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:37<00:00, 277.98s/it]
INFO:root:final mean train loss: 4565.774914532314
INFO:root:final train perplexity: 36.629150390625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.64s/it]
INFO:root:eval mean loss: 3469.6031703089807
INFO:root:eval perplexity: 17.237075805664062
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/1

  1%|          | 1/100 [05:08<8:28:12, 308.00s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 3088.8234252929688
INFO:root:current train perplexity11.345233917236328
INFO:root:current mean train loss 3091.556928963497
INFO:root:current train perplexity11.474310874938965
INFO:root:current mean train loss 3074.194818567347
INFO:root:current train perplexity11.415987014770508
INFO:root:current mean train loss 3072.4566117298755
INFO:root:current train perplexity11.391907691955566
INFO:root:current mean train loss 3065.1592671320986
INFO:root:current train perplexity11.294675827026367
INFO:root:current mean train loss 3055.5842606891956
INFO:root:current train perplexity11.159637451171875
INFO:root:current mean train loss 3037.7405680866987
INFO:root:current train perplexity11.030399322509766
INFO:root:current mean train loss 3027.0995029897
INFO:root:current train perplexity10.932398796081543
INFO:root:current mean train loss 3018.305568321078
INFO:root:current train perplexity10.85580825805664
INFO:root:current mean train loss 3012.3906948306153
INFO:root:current train perplexity10.780304908752441
INFO:root:current mean train loss 2999.5840970737727
INFO:root:current train perplexity10.691985130310059
INFO:root:current mean train loss 2991.238492138497
INFO:root:current train perplexity10.600676536560059
INFO:root:current mean train loss 2984.1571878132067
INFO:root:current train perplexity10.526179313659668
INFO:root:current mean train loss 2975.2776936354244
INFO:root:current train perplexity10.444991111755371
INFO:root:current mean train loss 2966.4305171643273
INFO:root:current train perplexity10.374889373779297
INFO:root:current mean train loss 2958.5564799044564
INFO:root:current train perplexity10.303881645202637
INFO:root:current mean train loss 2949.503845668075
INFO:root:current train perplexity10.233036994934082
INFO:root:current mean train loss 2942.164474238327
INFO:root:current train perplexity10.171882629394531
INFO:root:current mean train loss 2932.179041118874
INFO:root:current train perplexity10.103042602539062
INFO:root:current mean train loss 2924.4037674364317
INFO:root:current train perplexity10.034446716308594


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.96s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:39<00:00, 279.96s/it]
INFO:root:final mean train loss: 2918.744346722532
INFO:root:final train perplexity: 9.993124008178711
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.04s/it]
INFO:root:eval mean loss: 3217.3495697846283
INFO:root:eval perplexity: 14.01418399810791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/2

  2%|â–         | 2/100 [10:18<8:25:24, 309.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2798.718232125947
INFO:root:current train perplexity9.065755844116211
INFO:root:current mean train loss 2747.8588995682567
INFO:root:current train perplexity8.806517601013184
INFO:root:current mean train loss 2745.527615133785
INFO:root:current train perplexity8.770180702209473
INFO:root:current mean train loss 2732.922167528857
INFO:root:current train perplexity8.697375297546387
INFO:root:current mean train loss 2735.89512440459
INFO:root:current train perplexity8.666413307189941
INFO:root:current mean train loss 2731.5775341155604
INFO:root:current train perplexity8.621867179870605
INFO:root:current mean train loss 2727.296019543592
INFO:root:current train perplexity8.582965850830078
INFO:root:current mean train loss 2721.5315347752176
INFO:root:current train perplexity8.547979354858398
INFO:root:current mean train loss 2717.1730514471415
INFO:root:current train perplexity8.517996788024902
INFO:root:current mean train loss 2711.031676526494
INFO:root:current train perplexity8.48608684539795
INFO:root:current mean train loss 2706.3327634355337
INFO:root:current train perplexity8.455463409423828
INFO:root:current mean train loss 2701.4778484940425
INFO:root:current train perplexity8.432428359985352
INFO:root:current mean train loss 2696.3371457287867
INFO:root:current train perplexity8.40241813659668
INFO:root:current mean train loss 2689.962116810941
INFO:root:current train perplexity8.364178657531738
INFO:root:current mean train loss 2688.9932218180284
INFO:root:current train perplexity8.34699821472168
INFO:root:current mean train loss 2687.6935573311625
INFO:root:current train perplexity8.322810173034668
INFO:root:current mean train loss 2683.597867948178
INFO:root:current train perplexity8.296037673950195
INFO:root:current mean train loss 2680.1352812364757
INFO:root:current train perplexity8.268054962158203
INFO:root:current mean train loss 2676.1702199583165
INFO:root:current train perplexity8.237942695617676
INFO:root:current mean train loss 2671.6820153612825
INFO:root:current train perplexity8.213723182678223


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.44s/it]
INFO:root:final mean train loss: 2667.768922683631
INFO:root:final train perplexity: 8.19859790802002
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.94s/it]
INFO:root:eval mean loss: 3100.382028024118
INFO:root:eval perplexity: 12.731634140014648
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/3

  3%|â–Ž         | 3/100 [15:30<8:22:00, 310.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2600.789736328125
INFO:root:current train perplexity7.73164176940918
INFO:root:current mean train loss 2585.595478515625
INFO:root:current train perplexity7.677125453948975
INFO:root:current mean train loss 2576.809619140625
INFO:root:current train perplexity7.6425909996032715
INFO:root:current mean train loss 2570.8125265066965
INFO:root:current train perplexity7.59469747543335
INFO:root:current mean train loss 2574.687182074653
INFO:root:current train perplexity7.585444927215576
INFO:root:current mean train loss 2567.410791015625
INFO:root:current train perplexity7.5503997802734375
INFO:root:current mean train loss 2564.1779856520434
INFO:root:current train perplexity7.5378594398498535
INFO:root:current mean train loss 2561.4033548177085
INFO:root:current train perplexity7.524388790130615
INFO:root:current mean train loss 2559.274227653952
INFO:root:current train perplexity7.5212016105651855
INFO:root:current mean train loss 2556.2323501747533
INFO:root:current train perplexity7.500910758972168
INFO:root:current mean train loss 2552.51628952753
INFO:root:current train perplexity7.480536937713623
INFO:root:current mean train loss 2551.9790926460596
INFO:root:current train perplexity7.473076343536377
INFO:root:current mean train loss 2548.814567578125
INFO:root:current train perplexity7.459227561950684
INFO:root:current mean train loss 2546.7289339192707
INFO:root:current train perplexity7.445736408233643
INFO:root:current mean train loss 2546.2887941136855
INFO:root:current train perplexity7.441193103790283
INFO:root:current mean train loss 2543.4891711819555
INFO:root:current train perplexity7.427709579467773
INFO:root:current mean train loss 2542.082283528646
INFO:root:current train perplexity7.417420864105225
INFO:root:current mean train loss 2539.48182421875
INFO:root:current train perplexity7.401364803314209
INFO:root:current mean train loss 2538.29809979413
INFO:root:current train perplexity7.394376754760742
INFO:root:current mean train loss 2536.143214142628
INFO:root:current train perplexity7.3844499588012695


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.73s/it]
INFO:root:final mean train loss: 2534.5560683780886
INFO:root:final train perplexity: 7.380958557128906
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.90s/it]
INFO:root:eval mean loss: 3039.8230134431305
INFO:root:eval perplexity: 12.114422798156738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/4

  4%|â–         | 4/100 [20:44<8:19:08, 311.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2514.0850411030783
INFO:root:current train perplexity7.113711357116699
INFO:root:current mean train loss 2478.540774408215
INFO:root:current train perplexity7.030028820037842
INFO:root:current mean train loss 2475.6221942115812
INFO:root:current train perplexity7.035276889801025
INFO:root:current mean train loss 2475.7767314027374
INFO:root:current train perplexity7.04345178604126
INFO:root:current mean train loss 2476.4783318660498
INFO:root:current train perplexity7.052731037139893
INFO:root:current mean train loss 2471.39239275897
INFO:root:current train perplexity7.018648147583008
INFO:root:current mean train loss 2472.25962378918
INFO:root:current train perplexity7.015852451324463
INFO:root:current mean train loss 2469.614677180523
INFO:root:current train perplexity7.0034074783325195
INFO:root:current mean train loss 2469.9012473699268
INFO:root:current train perplexity6.992854595184326
INFO:root:current mean train loss 2466.1920530837965
INFO:root:current train perplexity6.976459980010986
INFO:root:current mean train loss 2465.3937969976423
INFO:root:current train perplexity6.970544338226318
INFO:root:current mean train loss 2464.8089941657295
INFO:root:current train perplexity6.963589191436768
INFO:root:current mean train loss 2462.081619852814
INFO:root:current train perplexity6.953798294067383
INFO:root:current mean train loss 2461.4806675272607
INFO:root:current train perplexity6.9479475021362305
INFO:root:current mean train loss 2458.9990751946466
INFO:root:current train perplexity6.943246364593506
INFO:root:current mean train loss 2456.7353149491964
INFO:root:current train perplexity6.938405990600586
INFO:root:current mean train loss 2453.3723149657176
INFO:root:current train perplexity6.923849105834961
INFO:root:current mean train loss 2452.0164712021833
INFO:root:current train perplexity6.912784099578857
INFO:root:current mean train loss 2450.194238908928
INFO:root:current train perplexity6.903613567352295
INFO:root:current mean train loss 2448.3424057371435
INFO:root:current train perplexity6.891633033752441


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.61s/it]
INFO:root:final mean train loss: 2447.392537127104
INFO:root:final train perplexity: 6.890621185302734
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.66s/it]
INFO:root:eval mean loss: 3006.0093579908034
INFO:root:eval perplexity: 11.78290843963623
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/5

  5%|â–Œ         | 5/100 [25:58<8:14:58, 312.61s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2404.3144647507443
INFO:root:current train perplexity6.601322174072266
INFO:root:current mean train loss 2401.475061831267
INFO:root:current train perplexity6.628875255584717
INFO:root:current mean train loss 2399.65424658547
INFO:root:current train perplexity6.652251720428467
INFO:root:current mean train loss 2401.4653717676797
INFO:root:current train perplexity6.658392429351807
INFO:root:current mean train loss 2407.3622368426363
INFO:root:current train perplexity6.670886516571045
INFO:root:current mean train loss 2401.1072607171045
INFO:root:current train perplexity6.638588905334473
INFO:root:current mean train loss 2399.469448870386
INFO:root:current train perplexity6.619330883026123
INFO:root:current mean train loss 2399.633245662767
INFO:root:current train perplexity6.626419544219971
INFO:root:current mean train loss 2397.5280184508447
INFO:root:current train perplexity6.612319469451904
INFO:root:current mean train loss 2393.359915136322
INFO:root:current train perplexity6.594632148742676
INFO:root:current mean train loss 2392.613957704213
INFO:root:current train perplexity6.593948841094971
INFO:root:current mean train loss 2390.9611235953666
INFO:root:current train perplexity6.586500644683838
INFO:root:current mean train loss 2389.5232103769654
INFO:root:current train perplexity6.579919815063477
INFO:root:current mean train loss 2389.5348506332134
INFO:root:current train perplexity6.57683801651001
INFO:root:current mean train loss 2389.9183118465453
INFO:root:current train perplexity6.578789234161377
INFO:root:current mean train loss 2389.267014243386
INFO:root:current train perplexity6.571200847625732
INFO:root:current mean train loss 2388.5711208896228
INFO:root:current train perplexity6.566301345825195
INFO:root:current mean train loss 2385.6376428989015
INFO:root:current train perplexity6.560657978057861
INFO:root:current mean train loss 2385.2158354740995
INFO:root:current train perplexity6.554912090301514


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.40s/it]
INFO:root:final mean train loss: 2382.6460617765656
INFO:root:final train perplexity: 6.547595977783203
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.14s/it]
INFO:root:eval mean loss: 2970.452860331034
INFO:root:eval perplexity: 11.444087982177734
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/6

  6%|â–Œ         | 6/100 [31:20<8:14:47, 315.83s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2487.16455078125
INFO:root:current train perplexity6.193091869354248
INFO:root:current mean train loss 2326.194826635984
INFO:root:current train perplexity6.280328273773193
INFO:root:current mean train loss 2337.709175071906
INFO:root:current train perplexity6.336099624633789
INFO:root:current mean train loss 2346.470839795084
INFO:root:current train perplexity6.348228454589844
INFO:root:current mean train loss 2343.737213058662
INFO:root:current train perplexity6.3459062576293945
INFO:root:current mean train loss 2341.0765473447636
INFO:root:current train perplexity6.34679651260376
INFO:root:current mean train loss 2338.498522563306
INFO:root:current train perplexity6.3381524085998535
INFO:root:current mean train loss 2340.174555148616
INFO:root:current train perplexity6.33845853805542
INFO:root:current mean train loss 2340.555322387543
INFO:root:current train perplexity6.3382792472839355
INFO:root:current mean train loss 2339.7460499889444
INFO:root:current train perplexity6.331204891204834
INFO:root:current mean train loss 2337.0853919030187
INFO:root:current train perplexity6.322227478027344
INFO:root:current mean train loss 2336.3077994614273
INFO:root:current train perplexity6.315654754638672
INFO:root:current mean train loss 2336.0517072971415
INFO:root:current train perplexity6.31296968460083
INFO:root:current mean train loss 2335.847709825825
INFO:root:current train perplexity6.31311559677124
INFO:root:current mean train loss 2335.674201219274
INFO:root:current train perplexity6.3129401206970215
INFO:root:current mean train loss 2336.158701084043
INFO:root:current train perplexity6.309623718261719
INFO:root:current mean train loss 2334.8294070813895
INFO:root:current train perplexity6.303140640258789
INFO:root:current mean train loss 2334.6970703555585
INFO:root:current train perplexity6.3033623695373535
INFO:root:current mean train loss 2334.504571570482
INFO:root:current train perplexity6.299359321594238
INFO:root:current mean train loss 2334.1311072400217
INFO:root:current train perplexity6.2973432540893555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.56s/it]
INFO:root:final mean train loss: 2332.8976141563644
INFO:root:final train perplexity: 6.29567813873291
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.11s/it]
INFO:root:eval mean loss: 2947.1402246973535
INFO:root:eval perplexity: 11.227246284484863
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/7

  7%|â–‹         | 7/100 [36:36<8:09:41, 315.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2290.118943956163
INFO:root:current train perplexity6.070257186889648
INFO:root:current mean train loss 2281.457577462924
INFO:root:current train perplexity6.116917610168457
INFO:root:current mean train loss 2298.70343409547
INFO:root:current train perplexity6.166119575500488
INFO:root:current mean train loss 2302.5103310639
INFO:root:current train perplexity6.167247295379639
INFO:root:current mean train loss 2301.215839294726
INFO:root:current train perplexity6.140298366546631
INFO:root:current mean train loss 2301.993604505384
INFO:root:current train perplexity6.1409687995910645
INFO:root:current mean train loss 2301.639659301363
INFO:root:current train perplexity6.1339006423950195
INFO:root:current mean train loss 2303.0758765600517
INFO:root:current train perplexity6.139461994171143
INFO:root:current mean train loss 2301.9585863780276
INFO:root:current train perplexity6.129567623138428
INFO:root:current mean train loss 2300.460300021701
INFO:root:current train perplexity6.1258721351623535
INFO:root:current mean train loss 2298.0917242083897
INFO:root:current train perplexity6.118904113769531
INFO:root:current mean train loss 2298.3661239159983
INFO:root:current train perplexity6.113251209259033
INFO:root:current mean train loss 2298.0020963421402
INFO:root:current train perplexity6.10876989364624
INFO:root:current mean train loss 2298.7206265300465
INFO:root:current train perplexity6.115850925445557
INFO:root:current mean train loss 2299.0417477886162
INFO:root:current train perplexity6.114070415496826
INFO:root:current mean train loss 2299.1607668428082
INFO:root:current train perplexity6.110542297363281
INFO:root:current mean train loss 2297.5264129072834
INFO:root:current train perplexity6.105771064758301
INFO:root:current mean train loss 2295.7005156227265
INFO:root:current train perplexity6.099045753479004
INFO:root:current mean train loss 2294.9923041986817
INFO:root:current train perplexity6.099954605102539
INFO:root:current mean train loss 2292.801538493263
INFO:root:current train perplexity6.09658145904541


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.37s/it]
INFO:root:final mean train loss: 2292.3264995503773
INFO:root:final train perplexity: 6.097424507141113
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.69s/it]
INFO:root:eval mean loss: 2930.2976132871154
INFO:root:eval perplexity: 11.073148727416992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/8

  8%|â–Š         | 8/100 [41:50<8:03:18, 315.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2257.2374441964284
INFO:root:current train perplexity5.901907444000244
INFO:root:current mean train loss 2266.919103551794
INFO:root:current train perplexity5.928952217102051
INFO:root:current mean train loss 2259.505458361037
INFO:root:current train perplexity5.935894966125488
INFO:root:current mean train loss 2261.913374897971
INFO:root:current train perplexity5.952640056610107
INFO:root:current mean train loss 2259.384533270474
INFO:root:current train perplexity5.958523273468018
INFO:root:current mean train loss 2257.983606755622
INFO:root:current train perplexity5.944649696350098
INFO:root:current mean train loss 2261.311281988189
INFO:root:current train perplexity5.9436516761779785
INFO:root:current mean train loss 2263.2603322969812
INFO:root:current train perplexity5.945900917053223
INFO:root:current mean train loss 2263.7268149735687
INFO:root:current train perplexity5.950095176696777
INFO:root:current mean train loss 2265.8304558249083
INFO:root:current train perplexity5.954784870147705
INFO:root:current mean train loss 2264.311370230412
INFO:root:current train perplexity5.952895641326904
INFO:root:current mean train loss 2261.7192201051416
INFO:root:current train perplexity5.946502208709717
INFO:root:current mean train loss 2259.8552528782893
INFO:root:current train perplexity5.942894458770752
INFO:root:current mean train loss 2260.6756979495844
INFO:root:current train perplexity5.945072650909424
INFO:root:current mean train loss 2259.8674901663217
INFO:root:current train perplexity5.941726207733154
INFO:root:current mean train loss 2260.552006247455
INFO:root:current train perplexity5.940253257751465
INFO:root:current mean train loss 2259.9116362498808
INFO:root:current train perplexity5.9400634765625
INFO:root:current mean train loss 2258.7099965384095
INFO:root:current train perplexity5.935648441314697
INFO:root:current mean train loss 2257.4163212997064
INFO:root:current train perplexity5.930795192718506
INFO:root:current mean train loss 2257.4641664017076
INFO:root:current train perplexity5.930561542510986


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.53s/it]
INFO:root:final mean train loss: 2257.734302699656
INFO:root:final train perplexity: 5.933328151702881
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.61s/it]
INFO:root:eval mean loss: 2916.9740287162163
INFO:root:eval perplexity: 10.952743530273438
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/9

  9%|â–‰         | 9/100 [47:04<7:57:47, 315.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2211.154705341046
INFO:root:current train perplexity5.759801387786865
INFO:root:current mean train loss 2219.924750077097
INFO:root:current train perplexity5.722792625427246
INFO:root:current mean train loss 2230.8248673696366
INFO:root:current train perplexity5.777736663818359
INFO:root:current mean train loss 2226.3989389592953
INFO:root:current train perplexity5.785888671875
INFO:root:current mean train loss 2233.4001740312156
INFO:root:current train perplexity5.805326461791992
INFO:root:current mean train loss 2235.5593429786572
INFO:root:current train perplexity5.81298828125
INFO:root:current mean train loss 2238.3632599064176
INFO:root:current train perplexity5.8206892013549805
INFO:root:current mean train loss 2234.972154333236
INFO:root:current train perplexity5.811758518218994
INFO:root:current mean train loss 2234.7820087844775
INFO:root:current train perplexity5.815130710601807
INFO:root:current mean train loss 2231.662763579553
INFO:root:current train perplexity5.8084282875061035
INFO:root:current mean train loss 2232.791225999027
INFO:root:current train perplexity5.8118109703063965
INFO:root:current mean train loss 2232.3266972435845
INFO:root:current train perplexity5.805105686187744
INFO:root:current mean train loss 2231.9173221283445
INFO:root:current train perplexity5.804714679718018
INFO:root:current mean train loss 2232.670769144092
INFO:root:current train perplexity5.811436176300049
INFO:root:current mean train loss 2231.2395400370447
INFO:root:current train perplexity5.806424140930176
INFO:root:current mean train loss 2228.6156081366785
INFO:root:current train perplexity5.798406600952148
INFO:root:current mean train loss 2228.6901126889284
INFO:root:current train perplexity5.795557975769043
INFO:root:current mean train loss 2230.248433640014
INFO:root:current train perplexity5.79954719543457
INFO:root:current mean train loss 2228.469841382416
INFO:root:current train perplexity5.794553756713867
INFO:root:current mean train loss 2228.650761838819
INFO:root:current train perplexity5.795053005218506


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.73s/it]
INFO:root:final mean train loss: 2227.80733161807
INFO:root:final train perplexity: 5.794925689697266
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.41s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.41s/it]
INFO:root:eval mean loss: 2901.351138736393
INFO:root:eval perplexity: 10.813230514526367
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/10

 10%|â–ˆ         | 10/100 [52:17<7:51:27, 314.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2220.8606646993885
INFO:root:current train perplexity5.706659317016602
INFO:root:current mean train loss 2221.9214661727997
INFO:root:current train perplexity5.689698219299316
INFO:root:current mean train loss 2203.900582579432
INFO:root:current train perplexity5.652767658233643
INFO:root:current mean train loss 2202.957096751143
INFO:root:current train perplexity5.658058166503906
INFO:root:current mean train loss 2204.5997348289247
INFO:root:current train perplexity5.662215232849121
INFO:root:current mean train loss 2208.1610227561373
INFO:root:current train perplexity5.674093723297119
INFO:root:current mean train loss 2204.1447706464874
INFO:root:current train perplexity5.6667633056640625
INFO:root:current mean train loss 2205.7372003959586
INFO:root:current train perplexity5.678995132446289
INFO:root:current mean train loss 2206.9302686333517
INFO:root:current train perplexity5.674228668212891
INFO:root:current mean train loss 2206.155477139972
INFO:root:current train perplexity5.6761627197265625
INFO:root:current mean train loss 2204.5201939010976
INFO:root:current train perplexity5.677155017852783
INFO:root:current mean train loss 2204.2421472972023
INFO:root:current train perplexity5.676419734954834
INFO:root:current mean train loss 2203.783963635552
INFO:root:current train perplexity5.673981189727783
INFO:root:current mean train loss 2204.2384114345555
INFO:root:current train perplexity5.676001071929932
INFO:root:current mean train loss 2204.840683035334
INFO:root:current train perplexity5.676680564880371
INFO:root:current mean train loss 2203.204764741177
INFO:root:current train perplexity5.674304962158203
INFO:root:current mean train loss 2202.531176933348
INFO:root:current train perplexity5.6741042137146
INFO:root:current mean train loss 2201.4867128983537
INFO:root:current train perplexity5.673213481903076
INFO:root:current mean train loss 2200.6058510932903
INFO:root:current train perplexity5.672332763671875
INFO:root:current mean train loss 2202.035985261792
INFO:root:current train perplexity5.676185131072998


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.13s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.13s/it]
INFO:root:final mean train loss: 2201.614469727301
INFO:root:final train perplexity: 5.676447868347168
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:29<00:00, 29.74s/it]
INFO:root:eval mean loss: 2890.7781641504785
INFO:root:eval perplexity: 10.719820022583008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/11

 11%|â–ˆ         | 11/100 [57:31<7:46:15, 314.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2208.6767365211663
INFO:root:current train perplexity5.627311706542969
INFO:root:current mean train loss 2175.5093416603663
INFO:root:current train perplexity5.5581889152526855
INFO:root:current mean train loss 2176.32463660607
INFO:root:current train perplexity5.555790901184082
INFO:root:current mean train loss 2185.4987113043435
INFO:root:current train perplexity5.584500789642334
INFO:root:current mean train loss 2180.7124704117637
INFO:root:current train perplexity5.565023899078369
INFO:root:current mean train loss 2180.70323165529
INFO:root:current train perplexity5.561995506286621
INFO:root:current mean train loss 2182.086419909063
INFO:root:current train perplexity5.567183494567871
INFO:root:current mean train loss 2182.205448063275
INFO:root:current train perplexity5.575443744659424
INFO:root:current mean train loss 2179.702935694572
INFO:root:current train perplexity5.571348667144775
INFO:root:current mean train loss 2179.6503262471474
INFO:root:current train perplexity5.574540138244629
INFO:root:current mean train loss 2176.310253501597
INFO:root:current train perplexity5.565905570983887
INFO:root:current mean train loss 2179.472048574515
INFO:root:current train perplexity5.571458339691162
INFO:root:current mean train loss 2178.3112424669516
INFO:root:current train perplexity5.56994104385376
INFO:root:current mean train loss 2178.4402378627233
INFO:root:current train perplexity5.571399211883545
INFO:root:current mean train loss 2178.126315089928
INFO:root:current train perplexity5.57009220123291
INFO:root:current mean train loss 2177.9090958699903
INFO:root:current train perplexity5.568159103393555
INFO:root:current mean train loss 2178.049606160337
INFO:root:current train perplexity5.568565845489502
INFO:root:current mean train loss 2178.282925220246
INFO:root:current train perplexity5.570544719696045
INFO:root:current mean train loss 2178.3415499512234
INFO:root:current train perplexity5.570607662200928


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.50s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.50s/it]
INFO:root:final mean train loss: 2178.2091547686587
INFO:root:final train perplexity: 5.572628974914551
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.79s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.79s/it]
INFO:root:eval mean loss: 2882.8784516938813
INFO:root:eval perplexity: 10.650555610656738
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/12

 12%|â–ˆâ–        | 12/100 [1:02:45<7:40:49, 314.20s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2036.1468505859375
INFO:root:current train perplexity5.063190937042236
INFO:root:current mean train loss 2156.9116293897905
INFO:root:current train perplexity5.469357013702393
INFO:root:current mean train loss 2162.341467946621
INFO:root:current train perplexity5.493593692779541
INFO:root:current mean train loss 2156.492815980817
INFO:root:current train perplexity5.481175422668457
INFO:root:current mean train loss 2152.1180804609958
INFO:root:current train perplexity5.477426052093506
INFO:root:current mean train loss 2156.0459253754816
INFO:root:current train perplexity5.490440845489502
INFO:root:current mean train loss 2153.9811485379096
INFO:root:current train perplexity5.487782001495361
INFO:root:current mean train loss 2152.5051604660275
INFO:root:current train perplexity5.483564853668213
INFO:root:current mean train loss 2152.652941636101
INFO:root:current train perplexity5.480123043060303
INFO:root:current mean train loss 2156.158529862481
INFO:root:current train perplexity5.485589504241943
INFO:root:current mean train loss 2155.992131880725
INFO:root:current train perplexity5.483691692352295
INFO:root:current mean train loss 2154.9060967204146
INFO:root:current train perplexity5.480503559112549
INFO:root:current mean train loss 2153.696200071923
INFO:root:current train perplexity5.481988430023193
INFO:root:current mean train loss 2152.8866776227037
INFO:root:current train perplexity5.480063438415527
INFO:root:current mean train loss 2152.813219718906
INFO:root:current train perplexity5.477673530578613
INFO:root:current mean train loss 2153.453127436533
INFO:root:current train perplexity5.474000453948975
INFO:root:current mean train loss 2155.497191164394
INFO:root:current train perplexity5.4754958152771
INFO:root:current mean train loss 2154.6351724065757
INFO:root:current train perplexity5.474867343902588
INFO:root:current mean train loss 2155.7789512460786
INFO:root:current train perplexity5.477880001068115
INFO:root:current mean train loss 2156.8162080380894
INFO:root:current train perplexity5.479949951171875


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.55s/it]
INFO:root:final mean train loss: 2157.156168250441
INFO:root:final train perplexity: 5.480865955352783
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.28s/it]
INFO:root:eval mean loss: 2878.173933699324
INFO:root:eval perplexity: 10.609518051147461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/13

 13%|â–ˆâ–Ž        | 13/100 [1:07:59<7:35:13, 313.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2204.6532348632813
INFO:root:current train perplexity5.46610164642334
INFO:root:current mean train loss 2143.128389485677
INFO:root:current train perplexity5.377574920654297
INFO:root:current mean train loss 2147.4411382501776
INFO:root:current train perplexity5.397806167602539
INFO:root:current mean train loss 2138.4716190338136
INFO:root:current train perplexity5.382987976074219
INFO:root:current mean train loss 2141.114714122954
INFO:root:current train perplexity5.381600379943848
INFO:root:current mean train loss 2141.6989807128907
INFO:root:current train perplexity5.396299839019775
INFO:root:current mean train loss 2141.800525689894
INFO:root:current train perplexity5.396373271942139
INFO:root:current mean train loss 2142.972710164388
INFO:root:current train perplexity5.399284362792969
INFO:root:current mean train loss 2143.3836824742757
INFO:root:current train perplexity5.40120267868042
INFO:root:current mean train loss 2144.146521261464
INFO:root:current train perplexity5.402960777282715
INFO:root:current mean train loss 2141.921597230201
INFO:root:current train perplexity5.40234899520874
INFO:root:current mean train loss 2142.680727495466
INFO:root:current train perplexity5.405872821807861
INFO:root:current mean train loss 2140.031350958152
INFO:root:current train perplexity5.405019283294678
INFO:root:current mean train loss 2139.095104887991
INFO:root:current train perplexity5.40505313873291
INFO:root:current mean train loss 2138.64042899978
INFO:root:current train perplexity5.399430274963379
INFO:root:current mean train loss 2137.7376484921106
INFO:root:current train perplexity5.398194313049316
INFO:root:current mean train loss 2137.6990826642073
INFO:root:current train perplexity5.3961591720581055
INFO:root:current mean train loss 2137.5268854895303
INFO:root:current train perplexity5.3950371742248535
INFO:root:current mean train loss 2138.1490167974116
INFO:root:current train perplexity5.3982367515563965
INFO:root:current mean train loss 2139.2634041468305
INFO:root:current train perplexity5.399979591369629


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:40<00:00, 280.73s/it]
INFO:root:final mean train loss: 2138.1624008540366
INFO:root:final train perplexity: 5.399376392364502
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.15s/it]
INFO:root:eval mean loss: 2871.3782581409537
INFO:root:eval perplexity: 10.550522804260254
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/14

 14%|â–ˆâ–        | 14/100 [1:13:10<7:28:52, 313.17s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2099.0705335462417
INFO:root:current train perplexity5.266133785247803
INFO:root:current mean train loss 2098.6737220931227
INFO:root:current train perplexity5.293211460113525
INFO:root:current mean train loss 2114.243864035305
INFO:root:current train perplexity5.317387580871582
INFO:root:current mean train loss 2110.8978155571913
INFO:root:current train perplexity5.312409400939941
INFO:root:current mean train loss 2110.1406428775745
INFO:root:current train perplexity5.322141170501709
INFO:root:current mean train loss 2113.923646269786
INFO:root:current train perplexity5.326379299163818
INFO:root:current mean train loss 2113.240773439033
INFO:root:current train perplexity5.316877841949463
INFO:root:current mean train loss 2110.9110851106684
INFO:root:current train perplexity5.3160719871521
INFO:root:current mean train loss 2112.4053139817615
INFO:root:current train perplexity5.3183465003967285
INFO:root:current mean train loss 2113.6904025897147
INFO:root:current train perplexity5.322685241699219
INFO:root:current mean train loss 2114.454242349476
INFO:root:current train perplexity5.325287342071533
INFO:root:current mean train loss 2116.891537467534
INFO:root:current train perplexity5.326953411102295
INFO:root:current mean train loss 2119.0323407382084
INFO:root:current train perplexity5.332267761230469
INFO:root:current mean train loss 2118.980497601323
INFO:root:current train perplexity5.3314313888549805
INFO:root:current mean train loss 2119.369718781261
INFO:root:current train perplexity5.3273162841796875
INFO:root:current mean train loss 2120.692331585856
INFO:root:current train perplexity5.333981990814209
INFO:root:current mean train loss 2120.5500870077217
INFO:root:current train perplexity5.332038402557373
INFO:root:current mean train loss 2121.206603195726
INFO:root:current train perplexity5.328463077545166
INFO:root:current mean train loss 2121.115235770469
INFO:root:current train perplexity5.326042652130127
INFO:root:current mean train loss 2121.9404203604963
INFO:root:current train perplexity5.326733589172363


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.21s/it]
INFO:root:final mean train loss: 2120.7001065452832
INFO:root:final train perplexity: 5.325527191162109
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.76s/it]
INFO:root:eval mean loss: 2867.7284305790167
INFO:root:eval perplexity: 10.51896858215332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/15

 15%|â–ˆâ–Œ        | 15/100 [1:18:22<7:23:23, 312.98s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2110.060262044271
INFO:root:current train perplexity5.222398281097412
INFO:root:current mean train loss 2102.8438712776483
INFO:root:current train perplexity5.194992542266846
INFO:root:current mean train loss 2100.419281726747
INFO:root:current train perplexity5.229681491851807
INFO:root:current mean train loss 2096.46657376909
INFO:root:current train perplexity5.236684799194336
INFO:root:current mean train loss 2097.1729983695277
INFO:root:current train perplexity5.2358222007751465
INFO:root:current mean train loss 2096.6334669202674
INFO:root:current train perplexity5.238587379455566
INFO:root:current mean train loss 2098.4857347587563
INFO:root:current train perplexity5.238994598388672
INFO:root:current mean train loss 2099.8689265972107
INFO:root:current train perplexity5.245937824249268
INFO:root:current mean train loss 2100.823468889509
INFO:root:current train perplexity5.244582653045654
INFO:root:current mean train loss 2099.5837159226776
INFO:root:current train perplexity5.2437357902526855
INFO:root:current mean train loss 2099.9995080126305
INFO:root:current train perplexity5.243206024169922
INFO:root:current mean train loss 2099.378408236975
INFO:root:current train perplexity5.245028495788574
INFO:root:current mean train loss 2101.210654129442
INFO:root:current train perplexity5.249206066131592
INFO:root:current mean train loss 2103.499829786743
INFO:root:current train perplexity5.2555694580078125
INFO:root:current mean train loss 2102.8042629404604
INFO:root:current train perplexity5.251010894775391
INFO:root:current mean train loss 2103.2542224231065
INFO:root:current train perplexity5.2536773681640625
INFO:root:current mean train loss 2102.7141512555972
INFO:root:current train perplexity5.2526397705078125
INFO:root:current mean train loss 2102.7363577030405
INFO:root:current train perplexity5.251826286315918
INFO:root:current mean train loss 2102.636963351516
INFO:root:current train perplexity5.2522053718566895
INFO:root:current mean train loss 2104.1858974679344
INFO:root:current train perplexity5.2543487548828125


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.09s/it]
INFO:root:final mean train loss: 2103.887349538952
INFO:root:final train perplexity: 5.255378723144531
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.77s/it]
INFO:root:eval mean loss: 2858.8088320253846
INFO:root:eval perplexity: 10.442264556884766
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/16

 16%|â–ˆâ–Œ        | 16/100 [1:23:37<7:18:45, 313.40s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2101.6263943524427
INFO:root:current train perplexity5.2564802169799805
INFO:root:current mean train loss 2081.412793968156
INFO:root:current train perplexity5.195460796356201
INFO:root:current mean train loss 2079.407068006227
INFO:root:current train perplexity5.199139595031738
INFO:root:current mean train loss 2081.058490763456
INFO:root:current train perplexity5.192917823791504
INFO:root:current mean train loss 2082.6848012353203
INFO:root:current train perplexity5.18882417678833
INFO:root:current mean train loss 2083.9925402425843
INFO:root:current train perplexity5.1842145919799805
INFO:root:current mean train loss 2083.081560069509
INFO:root:current train perplexity5.183294296264648
INFO:root:current mean train loss 2085.003107172351
INFO:root:current train perplexity5.1804633140563965
INFO:root:current mean train loss 2084.0218802976556
INFO:root:current train perplexity5.182182788848877
INFO:root:current mean train loss 2085.171351392532
INFO:root:current train perplexity5.1821770668029785
INFO:root:current mean train loss 2084.877873382426
INFO:root:current train perplexity5.178798675537109
INFO:root:current mean train loss 2085.8730501065797
INFO:root:current train perplexity5.178360939025879
INFO:root:current mean train loss 2084.9113735916294
INFO:root:current train perplexity5.178800582885742
INFO:root:current mean train loss 2085.3558481384766
INFO:root:current train perplexity5.183074951171875
INFO:root:current mean train loss 2085.434075973376
INFO:root:current train perplexity5.1849164962768555
INFO:root:current mean train loss 2086.408704382534
INFO:root:current train perplexity5.188288688659668
INFO:root:current mean train loss 2086.13848953658
INFO:root:current train perplexity5.183556079864502
INFO:root:current mean train loss 2087.300771806955
INFO:root:current train perplexity5.188101768493652
INFO:root:current mean train loss 2087.4871818995107
INFO:root:current train perplexity5.190184116363525
INFO:root:current mean train loss 2089.1722666654778
INFO:root:current train perplexity5.193291187286377


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.26s/it]
INFO:root:final mean train loss: 2089.0179877653904
INFO:root:final train perplexity: 5.194109916687012
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.98s/it]
INFO:root:eval mean loss: 2854.2982804581925
INFO:root:eval perplexity: 10.4036865234375
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/17

 17%|â–ˆâ–‹        | 17/100 [1:28:52<7:14:07, 313.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2056.4364748868074
INFO:root:current train perplexity5.080787181854248
INFO:root:current mean train loss 2063.932839251579
INFO:root:current train perplexity5.097929954528809
INFO:root:current mean train loss 2071.2488238016763
INFO:root:current train perplexity5.108675479888916
INFO:root:current mean train loss 2063.422263548546
INFO:root:current train perplexity5.099752902984619
INFO:root:current mean train loss 2067.8078480704885
INFO:root:current train perplexity5.119418621063232
INFO:root:current mean train loss 2069.68882118277
INFO:root:current train perplexity5.120164394378662
INFO:root:current mean train loss 2070.7547928566155
INFO:root:current train perplexity5.125943183898926
INFO:root:current mean train loss 2068.8415713237628
INFO:root:current train perplexity5.124106407165527
INFO:root:current mean train loss 2069.864149626311
INFO:root:current train perplexity5.1251068115234375
INFO:root:current mean train loss 2073.74247500771
INFO:root:current train perplexity5.129498481750488
INFO:root:current mean train loss 2075.153356103336
INFO:root:current train perplexity5.1288580894470215
INFO:root:current mean train loss 2074.976635762738
INFO:root:current train perplexity5.124637603759766
INFO:root:current mean train loss 2072.8583068847656
INFO:root:current train perplexity5.122661113739014
INFO:root:current mean train loss 2072.04139115831
INFO:root:current train perplexity5.120152950286865
INFO:root:current mean train loss 2072.456282420825
INFO:root:current train perplexity5.120813846588135
INFO:root:current mean train loss 2072.831336494657
INFO:root:current train perplexity5.125405311584473
INFO:root:current mean train loss 2073.965005160508
INFO:root:current train perplexity5.129737377166748
INFO:root:current mean train loss 2074.070051905826
INFO:root:current train perplexity5.132622718811035
INFO:root:current mean train loss 2074.4078333579887
INFO:root:current train perplexity5.134518623352051


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.40s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.40s/it]
INFO:root:final mean train loss: 2074.5977401541027
INFO:root:final train perplexity: 5.135373592376709
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.88s/it]
INFO:root:eval mean loss: 2855.1021607545044
INFO:root:eval perplexity: 10.410550117492676
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/18

 18%|â–ˆâ–Š        | 18/100 [1:34:05<7:08:53, 313.82s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2084.5049072265624
INFO:root:current train perplexity5.166101455688477
INFO:root:current mean train loss 2057.2461565290178
INFO:root:current train perplexity5.075859546661377
INFO:root:current mean train loss 2060.033495498285
INFO:root:current train perplexity5.07157564163208
INFO:root:current mean train loss 2063.696069736168
INFO:root:current train perplexity5.084089756011963
INFO:root:current mean train loss 2060.164352454668
INFO:root:current train perplexity5.080787658691406
INFO:root:current mean train loss 2059.083376682395
INFO:root:current train perplexity5.077861309051514
INFO:root:current mean train loss 2062.6826264688793
INFO:root:current train perplexity5.084312438964844
INFO:root:current mean train loss 2061.787216727615
INFO:root:current train perplexity5.085880756378174
INFO:root:current mean train loss 2062.0481320967588
INFO:root:current train perplexity5.080948829650879
INFO:root:current mean train loss 2063.716280672695
INFO:root:current train perplexity5.086858749389648
INFO:root:current mean train loss 2065.913767830768
INFO:root:current train perplexity5.091231822967529
INFO:root:current mean train loss 2064.0729429219105
INFO:root:current train perplexity5.08474588394165
INFO:root:current mean train loss 2063.400370263064
INFO:root:current train perplexity5.081839084625244
INFO:root:current mean train loss 2062.4642260087403
INFO:root:current train perplexity5.081068992614746
INFO:root:current mean train loss 2062.2569374165923
INFO:root:current train perplexity5.079646110534668
INFO:root:current mean train loss 2060.730857833913
INFO:root:current train perplexity5.078249454498291
INFO:root:current mean train loss 2059.8188051407956
INFO:root:current train perplexity5.076903343200684
INFO:root:current mean train loss 2060.575731992302
INFO:root:current train perplexity5.0785088539123535
INFO:root:current mean train loss 2059.6735884478876
INFO:root:current train perplexity5.076127052307129
INFO:root:current mean train loss 2060.1730204744913
INFO:root:current train perplexity5.07819938659668


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.09s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.09s/it]
INFO:root:final mean train loss: 2061.0471850696745
INFO:root:final train perplexity: 5.080785274505615
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.69s/it]
INFO:root:eval mean loss: 2854.3924153645835
INFO:root:eval perplexity: 10.404487609863281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/19

 19%|â–ˆâ–‰        | 19/100 [1:39:20<7:03:50, 313.95s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2015.0503040660512
INFO:root:current train perplexity4.963624477386475
INFO:root:current mean train loss 2034.9362903032147
INFO:root:current train perplexity4.9568095207214355
INFO:root:current mean train loss 2032.3471366263725
INFO:root:current train perplexity4.968123912811279
INFO:root:current mean train loss 2033.1232341505727
INFO:root:current train perplexity4.969753265380859
INFO:root:current mean train loss 2042.1395466158176
INFO:root:current train perplexity4.977686882019043
INFO:root:current mean train loss 2043.96076211162
INFO:root:current train perplexity4.9904398918151855
INFO:root:current mean train loss 2044.3983941277506
INFO:root:current train perplexity5.000063896179199
INFO:root:current mean train loss 2042.9171049588274
INFO:root:current train perplexity5.003572463989258
INFO:root:current mean train loss 2045.0314974077137
INFO:root:current train perplexity5.003808498382568
INFO:root:current mean train loss 2046.3026847260116
INFO:root:current train perplexity5.006600379943848
INFO:root:current mean train loss 2045.4550852915545
INFO:root:current train perplexity5.010256767272949
INFO:root:current mean train loss 2045.325022542753
INFO:root:current train perplexity5.012548923492432
INFO:root:current mean train loss 2046.4389291816374
INFO:root:current train perplexity5.0159220695495605
INFO:root:current mean train loss 2048.3527173664133
INFO:root:current train perplexity5.022321701049805
INFO:root:current mean train loss 2048.174684505758
INFO:root:current train perplexity5.0201849937438965
INFO:root:current mean train loss 2048.690824611428
INFO:root:current train perplexity5.022421836853027
INFO:root:current mean train loss 2048.50891482051
INFO:root:current train perplexity5.022183895111084
INFO:root:current mean train loss 2048.7692506017033
INFO:root:current train perplexity5.026587963104248
INFO:root:current mean train loss 2049.4898770077953
INFO:root:current train perplexity5.0297393798828125
INFO:root:current mean train loss 2050.0955472027226
INFO:root:current train perplexity5.031852722167969


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.92s/it]
INFO:root:final mean train loss: 2048.25694886639
INFO:root:final train perplexity: 5.029792308807373
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.36s/it]
INFO:root:eval mean loss: 2850.0887755431213
INFO:root:eval perplexity: 10.367809295654297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/20

 20%|â–ˆâ–ˆ        | 20/100 [1:44:34<6:58:55, 314.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2019.104742588141
INFO:root:current train perplexity4.952819347381592
INFO:root:current mean train loss 2046.5972145135454
INFO:root:current train perplexity4.965329647064209
INFO:root:current mean train loss 2043.316081920927
INFO:root:current train perplexity4.96543550491333
INFO:root:current mean train loss 2042.372015938998
INFO:root:current train perplexity4.966839790344238
INFO:root:current mean train loss 2039.6648680528367
INFO:root:current train perplexity4.966241836547852
INFO:root:current mean train loss 2038.8476972420715
INFO:root:current train perplexity4.970569133758545
INFO:root:current mean train loss 2037.0092668369157
INFO:root:current train perplexity4.976029872894287
INFO:root:current mean train loss 2038.2873302248076
INFO:root:current train perplexity4.977145671844482
INFO:root:current mean train loss 2036.7779912027897
INFO:root:current train perplexity4.977411270141602
INFO:root:current mean train loss 2036.9035498930878
INFO:root:current train perplexity4.975064754486084
INFO:root:current mean train loss 2036.2075204711562
INFO:root:current train perplexity4.973475933074951
INFO:root:current mean train loss 2037.348931718647
INFO:root:current train perplexity4.977105617523193
INFO:root:current mean train loss 2035.9995195020872
INFO:root:current train perplexity4.97401762008667
INFO:root:current mean train loss 2037.480453251902
INFO:root:current train perplexity4.977651596069336
INFO:root:current mean train loss 2038.2682599033888
INFO:root:current train perplexity4.98309326171875
INFO:root:current mean train loss 2039.3686172852197
INFO:root:current train perplexity4.987103462219238
INFO:root:current mean train loss 2038.077982671527
INFO:root:current train perplexity4.984804630279541
INFO:root:current mean train loss 2038.5128741009335
INFO:root:current train perplexity4.987457275390625
INFO:root:current mean train loss 2038.4954837967093
INFO:root:current train perplexity4.98655366897583
INFO:root:current mean train loss 2037.6779203449346
INFO:root:current train perplexity4.986128330230713


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.83s/it]
INFO:root:final mean train loss: 2036.6736681962698
INFO:root:final train perplexity: 4.984052658081055
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.55s/it]
INFO:root:eval mean loss: 2852.921581004833
INFO:root:eval perplexity: 10.391938209533691
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/21

 21%|â–ˆâ–ˆ        | 21/100 [1:49:48<6:53:33, 314.09s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2001.1139657156807
INFO:root:current train perplexity4.930740833282471
INFO:root:current mean train loss 2008.8344476161858
INFO:root:current train perplexity4.920993804931641
INFO:root:current mean train loss 2015.248553276062
INFO:root:current train perplexity4.935109615325928
INFO:root:current mean train loss 2020.418287984441
INFO:root:current train perplexity4.94416618347168
INFO:root:current mean train loss 2021.5794222647683
INFO:root:current train perplexity4.943413257598877
INFO:root:current mean train loss 2021.005065259316
INFO:root:current train perplexity4.929107666015625
INFO:root:current mean train loss 2019.2366865204601
INFO:root:current train perplexity4.926875591278076
INFO:root:current mean train loss 2020.1500423370846
INFO:root:current train perplexity4.924220561981201
INFO:root:current mean train loss 2020.279934464214
INFO:root:current train perplexity4.926069259643555
INFO:root:current mean train loss 2022.0643050062108
INFO:root:current train perplexity4.926947593688965
INFO:root:current mean train loss 2021.924386804754
INFO:root:current train perplexity4.927433490753174
INFO:root:current mean train loss 2022.3427045881542
INFO:root:current train perplexity4.927278518676758
INFO:root:current mean train loss 2021.8447039172906
INFO:root:current train perplexity4.923932075500488
INFO:root:current mean train loss 2023.140161114808
INFO:root:current train perplexity4.928595542907715
INFO:root:current mean train loss 2023.6212203476455
INFO:root:current train perplexity4.927920818328857
INFO:root:current mean train loss 2024.0973042387582
INFO:root:current train perplexity4.929479598999023
INFO:root:current mean train loss 2024.8347538012813
INFO:root:current train perplexity4.929498672485352
INFO:root:current mean train loss 2025.10812892349
INFO:root:current train perplexity4.931530952453613
INFO:root:current mean train loss 2025.5537094247752
INFO:root:current train perplexity4.93361759185791
INFO:root:current mean train loss 2025.0835598748642
INFO:root:current train perplexity4.935765743255615


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.55s/it]
INFO:root:final mean train loss: 2024.728793684305
INFO:root:final train perplexity: 4.937320709228516
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.58s/it]
INFO:root:eval mean loss: 2849.288544159394
INFO:root:eval perplexity: 10.361003875732422
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/22

 22%|â–ˆâ–ˆâ–       | 22/100 [1:55:03<6:48:32, 314.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2007.6086057898117
INFO:root:current train perplexity4.8956618309021
INFO:root:current mean train loss 2014.163728041456
INFO:root:current train perplexity4.887131690979004
INFO:root:current mean train loss 2012.3840515360291
INFO:root:current train perplexity4.884194374084473
INFO:root:current mean train loss 2010.6011962890625
INFO:root:current train perplexity4.888681411743164
INFO:root:current mean train loss 2008.0151973667912
INFO:root:current train perplexity4.870075225830078
INFO:root:current mean train loss 2009.8281757028524
INFO:root:current train perplexity4.876711368560791
INFO:root:current mean train loss 2010.1300663714246
INFO:root:current train perplexity4.880177021026611
INFO:root:current mean train loss 2008.5781892724672
INFO:root:current train perplexity4.879859447479248
INFO:root:current mean train loss 2009.5705563609679
INFO:root:current train perplexity4.883800506591797
INFO:root:current mean train loss 2011.997493732135
INFO:root:current train perplexity4.887668609619141
INFO:root:current mean train loss 2014.072735134953
INFO:root:current train perplexity4.893182754516602
INFO:root:current mean train loss 2014.115575818048
INFO:root:current train perplexity4.89347505569458
INFO:root:current mean train loss 2013.893868349709
INFO:root:current train perplexity4.8950605392456055
INFO:root:current mean train loss 2013.16494508703
INFO:root:current train perplexity4.894413948059082
INFO:root:current mean train loss 2014.1303176413728
INFO:root:current train perplexity4.893813133239746
INFO:root:current mean train loss 2015.6363503661644
INFO:root:current train perplexity4.900530815124512
INFO:root:current mean train loss 2016.0784808499188
INFO:root:current train perplexity4.899905204772949
INFO:root:current mean train loss 2015.0146310874047
INFO:root:current train perplexity4.896589756011963
INFO:root:current mean train loss 2015.2046270579242
INFO:root:current train perplexity4.897169589996338
INFO:root:current mean train loss 2015.7974165516703
INFO:root:current train perplexity4.899894714355469


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.39s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.39s/it]
INFO:root:final mean train loss: 2014.9092116978693
INFO:root:final train perplexity: 4.899232387542725
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.46s/it]
INFO:root:eval mean loss: 2847.5034011061844
INFO:root:eval perplexity: 10.345840454101562
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/23

 23%|â–ˆâ–ˆâ–Ž       | 23/100 [2:00:15<6:42:33, 313.68s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2018.7098185221355
INFO:root:current train perplexity4.846487522125244
INFO:root:current mean train loss 2001.5706587942022
INFO:root:current train perplexity4.814303874969482
INFO:root:current mean train loss 2002.0209279027479
INFO:root:current train perplexity4.826228141784668
INFO:root:current mean train loss 2007.0107885116186
INFO:root:current train perplexity4.84056282043457
INFO:root:current mean train loss 1998.623825882892
INFO:root:current train perplexity4.827099323272705
INFO:root:current mean train loss 2001.3753777972722
INFO:root:current train perplexity4.8352885246276855
INFO:root:current mean train loss 2003.8054257600204
INFO:root:current train perplexity4.844101905822754
INFO:root:current mean train loss 2005.3849615555775
INFO:root:current train perplexity4.844390392303467
INFO:root:current mean train loss 2004.851493784015
INFO:root:current train perplexity4.846151828765869
INFO:root:current mean train loss 2006.7369746044428
INFO:root:current train perplexity4.854101181030273
INFO:root:current mean train loss 2004.7623061433844
INFO:root:current train perplexity4.853819847106934
INFO:root:current mean train loss 2003.3303370371586
INFO:root:current train perplexity4.846201419830322
INFO:root:current mean train loss 2002.5007734904918
INFO:root:current train perplexity4.842508316040039
INFO:root:current mean train loss 2002.3629903011185
INFO:root:current train perplexity4.845373153686523
INFO:root:current mean train loss 2002.637931342413
INFO:root:current train perplexity4.848056316375732
INFO:root:current mean train loss 2004.296445757788
INFO:root:current train perplexity4.853399753570557
INFO:root:current mean train loss 2003.744652525772
INFO:root:current train perplexity4.855188846588135
INFO:root:current mean train loss 2004.2288580356364
INFO:root:current train perplexity4.857270240783691
INFO:root:current mean train loss 2004.9102542291873
INFO:root:current train perplexity4.859401702880859


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.06s/it]
INFO:root:final mean train loss: 2004.609135784047
INFO:root:final train perplexity: 4.859596252441406
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.47s/it]
INFO:root:eval mean loss: 2847.546927787162
INFO:root:eval perplexity: 10.346208572387695
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/24

 24%|â–ˆâ–ˆâ–       | 24/100 [2:05:28<6:37:06, 313.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1916.9231654575892
INFO:root:current train perplexity4.6772332191467285
INFO:root:current mean train loss 1961.5308518454294
INFO:root:current train perplexity4.733424186706543
INFO:root:current mean train loss 1973.7831258727733
INFO:root:current train perplexity4.76298713684082
INFO:root:current mean train loss 1980.6969021974246
INFO:root:current train perplexity4.786080837249756
INFO:root:current mean train loss 1981.4149031955428
INFO:root:current train perplexity4.78388786315918
INFO:root:current mean train loss 1981.6648348896697
INFO:root:current train perplexity4.7819695472717285
INFO:root:current mean train loss 1983.5312304928825
INFO:root:current train perplexity4.791139602661133
INFO:root:current mean train loss 1987.1197476960308
INFO:root:current train perplexity4.80171012878418
INFO:root:current mean train loss 1986.6530739029101
INFO:root:current train perplexity4.8007001876831055
INFO:root:current mean train loss 1988.119690816221
INFO:root:current train perplexity4.804137706756592
INFO:root:current mean train loss 1988.5283039475623
INFO:root:current train perplexity4.808362007141113
INFO:root:current mean train loss 1989.9847114376905
INFO:root:current train perplexity4.8095831871032715
INFO:root:current mean train loss 1993.0855842343815
INFO:root:current train perplexity4.819253921508789
INFO:root:current mean train loss 1992.5315829614874
INFO:root:current train perplexity4.816707134246826
INFO:root:current mean train loss 1992.517247485369
INFO:root:current train perplexity4.816704273223877
INFO:root:current mean train loss 1993.7225864261052
INFO:root:current train perplexity4.817912578582764
INFO:root:current mean train loss 1995.59903351001
INFO:root:current train perplexity4.820703983306885
INFO:root:current mean train loss 1995.0114149686951
INFO:root:current train perplexity4.821368217468262
INFO:root:current mean train loss 1994.9886483391413
INFO:root:current train perplexity4.821625232696533
INFO:root:current mean train loss 1994.7770824542392
INFO:root:current train perplexity4.821476936340332


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.11s/it]
INFO:root:final mean train loss: 1994.1790038016006
INFO:root:final train perplexity: 4.8197855949401855
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.08s/it]
INFO:root:eval mean loss: 2849.1675171265015
INFO:root:eval perplexity: 10.359973907470703
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/25

 25%|â–ˆâ–ˆâ–Œ       | 25/100 [2:10:47<6:33:49, 315.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1961.6972045898438
INFO:root:current train perplexity4.7215118408203125
INFO:root:current mean train loss 1956.9801281344505
INFO:root:current train perplexity4.761295795440674
INFO:root:current mean train loss 1970.1514086042132
INFO:root:current train perplexity4.778133392333984
INFO:root:current mean train loss 1976.742656943239
INFO:root:current train perplexity4.76688814163208
INFO:root:current mean train loss 1976.1376380200657
INFO:root:current train perplexity4.7644548416137695
INFO:root:current mean train loss 1978.3443249418535
INFO:root:current train perplexity4.765711784362793
INFO:root:current mean train loss 1982.3277349227515
INFO:root:current train perplexity4.7767438888549805
INFO:root:current mean train loss 1984.660133319665
INFO:root:current train perplexity4.78420877456665
INFO:root:current mean train loss 1985.212311679877
INFO:root:current train perplexity4.78231143951416
INFO:root:current mean train loss 1984.2309513504888
INFO:root:current train perplexity4.777043342590332
INFO:root:current mean train loss 1985.0752170085907
INFO:root:current train perplexity4.784069061279297
INFO:root:current mean train loss 1985.537375453528
INFO:root:current train perplexity4.780285835266113
INFO:root:current mean train loss 1984.1445760290608
INFO:root:current train perplexity4.774864196777344
INFO:root:current mean train loss 1984.1423772252938
INFO:root:current train perplexity4.777353763580322
INFO:root:current mean train loss 1985.0686779236526
INFO:root:current train perplexity4.7791314125061035
INFO:root:current mean train loss 1985.3787144137805
INFO:root:current train perplexity4.779949188232422
INFO:root:current mean train loss 1986.3186170455858
INFO:root:current train perplexity4.7815141677856445
INFO:root:current mean train loss 1987.3507659982915
INFO:root:current train perplexity4.784584999084473
INFO:root:current mean train loss 1986.4521958200555
INFO:root:current train perplexity4.786187648773193
INFO:root:current mean train loss 1986.611758479953
INFO:root:current train perplexity4.785853862762451


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.15s/it]
INFO:root:final mean train loss: 1985.178873451683
INFO:root:final train perplexity: 4.785696029663086
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.84s/it]
INFO:root:eval mean loss: 2850.195123346002
INFO:root:eval perplexity: 10.368714332580566
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/26

 26%|â–ˆâ–ˆâ–Œ       | 26/100 [2:16:04<6:29:07, 315.51s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1980.3627572408536
INFO:root:current train perplexity4.7237443923950195
INFO:root:current mean train loss 1966.5348489098515
INFO:root:current train perplexity4.730591773986816
INFO:root:current mean train loss 1970.0575275341998
INFO:root:current train perplexity4.747573375701904
INFO:root:current mean train loss 1979.3691048272544
INFO:root:current train perplexity4.757291316986084
INFO:root:current mean train loss 1972.8690880323484
INFO:root:current train perplexity4.752307891845703
INFO:root:current mean train loss 1975.4703236014036
INFO:root:current train perplexity4.755486488342285
INFO:root:current mean train loss 1975.3171222942667
INFO:root:current train perplexity4.75612211227417
INFO:root:current mean train loss 1975.233929220964
INFO:root:current train perplexity4.758378982543945
INFO:root:current mean train loss 1979.1883571048695
INFO:root:current train perplexity4.76522970199585
INFO:root:current mean train loss 1977.5294054540134
INFO:root:current train perplexity4.759038925170898
INFO:root:current mean train loss 1975.4464004619206
INFO:root:current train perplexity4.754267692565918
INFO:root:current mean train loss 1976.6760480715245
INFO:root:current train perplexity4.752187728881836
INFO:root:current mean train loss 1976.4543072426156
INFO:root:current train perplexity4.749346733093262
INFO:root:current mean train loss 1976.8652710598142
INFO:root:current train perplexity4.751664161682129
INFO:root:current mean train loss 1977.1882711353605
INFO:root:current train perplexity4.753881931304932
INFO:root:current mean train loss 1976.8872298451695
INFO:root:current train perplexity4.7538161277771
INFO:root:current mean train loss 1976.3817091807587
INFO:root:current train perplexity4.7527546882629395
INFO:root:current mean train loss 1976.5434209921111
INFO:root:current train perplexity4.753057956695557
INFO:root:current mean train loss 1976.546760952777
INFO:root:current train perplexity4.751855373382568
INFO:root:current mean train loss 1976.5414117717792
INFO:root:current train perplexity4.751693248748779


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.06s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.06s/it]
INFO:root:final mean train loss: 1976.295863287652
INFO:root:final train perplexity: 4.752286434173584
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.74s/it]
INFO:root:eval mean loss: 2847.9785713447823
INFO:root:eval perplexity: 10.349874496459961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/27

 27%|â–ˆâ–ˆâ–‹       | 27/100 [2:21:18<6:23:25, 315.15s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1978.146638015221
INFO:root:current train perplexity4.675478935241699
INFO:root:current mean train loss 1959.510488775712
INFO:root:current train perplexity4.672203063964844
INFO:root:current mean train loss 1950.1294252853986
INFO:root:current train perplexity4.684764385223389
INFO:root:current mean train loss 1950.1775338796265
INFO:root:current train perplexity4.68056058883667
INFO:root:current mean train loss 1954.7344488285514
INFO:root:current train perplexity4.694590091705322
INFO:root:current mean train loss 1960.0835654419384
INFO:root:current train perplexity4.702630996704102
INFO:root:current mean train loss 1961.8306804993233
INFO:root:current train perplexity4.705348014831543
INFO:root:current mean train loss 1963.5014640385368
INFO:root:current train perplexity4.708906173706055
INFO:root:current mean train loss 1964.4366358332422
INFO:root:current train perplexity4.712697982788086
INFO:root:current mean train loss 1964.0522297837292
INFO:root:current train perplexity4.709935665130615
INFO:root:current mean train loss 1963.251913896355
INFO:root:current train perplexity4.708093643188477
INFO:root:current mean train loss 1964.7164233904427
INFO:root:current train perplexity4.70963716506958
INFO:root:current mean train loss 1966.432198480506
INFO:root:current train perplexity4.713011741638184
INFO:root:current mean train loss 1966.16625778805
INFO:root:current train perplexity4.710814476013184
INFO:root:current mean train loss 1966.619945719736
INFO:root:current train perplexity4.71275520324707
INFO:root:current mean train loss 1967.6477123647355
INFO:root:current train perplexity4.715615272521973
INFO:root:current mean train loss 1967.670021121551
INFO:root:current train perplexity4.715971946716309
INFO:root:current mean train loss 1967.048494341159
INFO:root:current train perplexity4.714191436767578
INFO:root:current mean train loss 1967.796007170744
INFO:root:current train perplexity4.71878719329834
INFO:root:current mean train loss 1968.0570615743104
INFO:root:current train perplexity4.719374179840088


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.51s/it]
INFO:root:final mean train loss: 1967.8813017336815
INFO:root:final train perplexity: 4.720853328704834
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.03s/it]
INFO:root:eval mean loss: 2846.99560253613
INFO:root:eval perplexity: 10.341526985168457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/28

 28%|â–ˆâ–ˆâ–Š       | 28/100 [2:26:31<6:17:26, 314.53s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1979.1068798828126
INFO:root:current train perplexity4.725875377655029
INFO:root:current mean train loss 1965.8863685825893
INFO:root:current train perplexity4.6766252517700195
INFO:root:current mean train loss 1960.913787286932
INFO:root:current train perplexity4.676218032836914
INFO:root:current mean train loss 1961.3073782552083
INFO:root:current train perplexity4.683449745178223
INFO:root:current mean train loss 1961.6624866365132
INFO:root:current train perplexity4.68821382522583
INFO:root:current mean train loss 1957.1762094514265
INFO:root:current train perplexity4.676835060119629
INFO:root:current mean train loss 1956.8027750651042
INFO:root:current train perplexity4.677399635314941
INFO:root:current mean train loss 1960.4386605342743
INFO:root:current train perplexity4.685267448425293
INFO:root:current mean train loss 1960.8851083984375
INFO:root:current train perplexity4.684841156005859
INFO:root:current mean train loss 1961.9316533954327
INFO:root:current train perplexity4.684337615966797
INFO:root:current mean train loss 1962.7552931958576
INFO:root:current train perplexity4.6859002113342285
INFO:root:current mean train loss 1961.212122776762
INFO:root:current train perplexity4.6868438720703125
INFO:root:current mean train loss 1959.5869968788297
INFO:root:current train perplexity4.68466854095459
INFO:root:current mean train loss 1958.7107040127842
INFO:root:current train perplexity4.686605453491211
INFO:root:current mean train loss 1958.6217185017215
INFO:root:current train perplexity4.6846723556518555
INFO:root:current mean train loss 1960.063431454613
INFO:root:current train perplexity4.6862969398498535
INFO:root:current mean train loss 1960.424971431903
INFO:root:current train perplexity4.687845230102539
INFO:root:current mean train loss 1959.701612153389
INFO:root:current train perplexity4.68723201751709
INFO:root:current mean train loss 1959.8553057291667
INFO:root:current train perplexity4.688544750213623
INFO:root:current mean train loss 1959.3268765451937
INFO:root:current train perplexity4.687744140625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.45s/it]
INFO:root:final mean train loss: 1958.9591753599443
INFO:root:final train perplexity: 4.687751770019531
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.36s/it]
INFO:root:eval mean loss: 2848.9619917769332
INFO:root:eval perplexity: 10.358227729797363
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/29

 29%|â–ˆâ–ˆâ–‰       | 29/100 [2:31:47<6:12:49, 315.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1945.8871605914571
INFO:root:current train perplexity4.632941246032715
INFO:root:current mean train loss 1943.5520871480305
INFO:root:current train perplexity4.637731552124023
INFO:root:current mean train loss 1949.7953374157214
INFO:root:current train perplexity4.635316848754883
INFO:root:current mean train loss 1951.6155968490912
INFO:root:current train perplexity4.640539646148682
INFO:root:current mean train loss 1958.8656043075935
INFO:root:current train perplexity4.650821685791016
INFO:root:current mean train loss 1958.5477255743904
INFO:root:current train perplexity4.656546592712402
INFO:root:current mean train loss 1958.1116754609036
INFO:root:current train perplexity4.651144981384277
INFO:root:current mean train loss 1956.1559297195588
INFO:root:current train perplexity4.650912284851074
INFO:root:current mean train loss 1957.4575638706908
INFO:root:current train perplexity4.65218448638916
INFO:root:current mean train loss 1956.9711942365093
INFO:root:current train perplexity4.653959274291992
INFO:root:current mean train loss 1955.493387299143
INFO:root:current train perplexity4.649733066558838
INFO:root:current mean train loss 1955.1447118976773
INFO:root:current train perplexity4.651945114135742
INFO:root:current mean train loss 1954.5544080232319
INFO:root:current train perplexity4.6515302658081055
INFO:root:current mean train loss 1954.0144501609363
INFO:root:current train perplexity4.653634548187256
INFO:root:current mean train loss 1955.1250978526098
INFO:root:current train perplexity4.656411647796631
INFO:root:current mean train loss 1954.2397811352907
INFO:root:current train perplexity4.655267715454102
INFO:root:current mean train loss 1953.320472663176
INFO:root:current train perplexity4.655075550079346
INFO:root:current mean train loss 1951.3774156570435
INFO:root:current train perplexity4.6555705070495605
INFO:root:current mean train loss 1951.355040471599
INFO:root:current train perplexity4.657699108123779


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.07s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.07s/it]
INFO:root:final mean train loss: 1950.7859177889995
INFO:root:final train perplexity: 4.657631874084473
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.63s/it]
INFO:root:eval mean loss: 2846.8946918109514
INFO:root:eval perplexity: 10.340669631958008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/30
#################best################
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [2:37:01<6:06:54, 314.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1898.9605170355903
INFO:root:current train perplexity4.677460670471191
INFO:root:current mean train loss 1928.4687936765338
INFO:root:current train perplexity4.62052583694458
INFO:root:current mean train loss 1938.2111839768988
INFO:root:current train perplexity4.6223225593566895
INFO:root:current mean train loss 1939.130751131422
INFO:root:current train perplexity4.631161689758301
INFO:root:current mean train loss 1942.573436783695
INFO:root:current train perplexity4.623207092285156
INFO:root:current mean train loss 1937.6272049399865
INFO:root:current train perplexity4.606649398803711
INFO:root:current mean train loss 1938.7099136327483
INFO:root:current train perplexity4.608618259429932
INFO:root:current mean train loss 1938.1580123578544
INFO:root:current train perplexity4.610434055328369
INFO:root:current mean train loss 1939.7990457089193
INFO:root:current train perplexity4.611640453338623
INFO:root:current mean train loss 1940.6033728739085
INFO:root:current train perplexity4.615560054779053
INFO:root:current mean train loss 1941.989946076135
INFO:root:current train perplexity4.618850231170654
INFO:root:current mean train loss 1941.7434850336733
INFO:root:current train perplexity4.6194610595703125
INFO:root:current mean train loss 1942.4301279224178
INFO:root:current train perplexity4.624238014221191
INFO:root:current mean train loss 1943.0711953415955
INFO:root:current train perplexity4.625293254852295
INFO:root:current mean train loss 1943.6456857631188
INFO:root:current train perplexity4.624849319458008
INFO:root:current mean train loss 1943.5633023150162
INFO:root:current train perplexity4.6263017654418945
INFO:root:current mean train loss 1943.7176118403802
INFO:root:current train perplexity4.626762390136719
INFO:root:current mean train loss 1943.9258076069018
INFO:root:current train perplexity4.629629611968994
INFO:root:current mean train loss 1943.8386069867674
INFO:root:current train perplexity4.630546569824219
INFO:root:current mean train loss 1943.7583475887245
INFO:root:current train perplexity4.630763530731201


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.26s/it]
INFO:root:final mean train loss: 1943.3669796788326
INFO:root:final train perplexity: 4.630459785461426
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.84s/it]
INFO:root:eval mean loss: 2851.0469123909065
INFO:root:eval perplexity: 10.375965118408203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/31

 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [2:42:15<6:01:43, 314.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1922.0526357797476
INFO:root:current train perplexity4.571214199066162
INFO:root:current mean train loss 1929.06492203001
INFO:root:current train perplexity4.574631690979004
INFO:root:current mean train loss 1931.633090128941
INFO:root:current train perplexity4.575502395629883
INFO:root:current mean train loss 1923.7653130841402
INFO:root:current train perplexity4.555871486663818
INFO:root:current mean train loss 1923.0574653159845
INFO:root:current train perplexity4.555074691772461
INFO:root:current mean train loss 1925.6731326027061
INFO:root:current train perplexity4.562148571014404
INFO:root:current mean train loss 1927.358036711574
INFO:root:current train perplexity4.568395614624023
INFO:root:current mean train loss 1930.5798561789773
INFO:root:current train perplexity4.572842597961426
INFO:root:current mean train loss 1934.3001595190017
INFO:root:current train perplexity4.580277919769287
INFO:root:current mean train loss 1932.737442445034
INFO:root:current train perplexity4.580180644989014
INFO:root:current mean train loss 1932.8299333300972
INFO:root:current train perplexity4.5852556228637695
INFO:root:current mean train loss 1935.0563037933296
INFO:root:current train perplexity4.593890190124512
INFO:root:current mean train loss 1935.0571471271858
INFO:root:current train perplexity4.596004009246826
INFO:root:current mean train loss 1936.058578284078
INFO:root:current train perplexity4.596658229827881
INFO:root:current mean train loss 1935.275614820055
INFO:root:current train perplexity4.598641395568848
INFO:root:current mean train loss 1933.9933518875941
INFO:root:current train perplexity4.598649501800537
INFO:root:current mean train loss 1935.0960137061088
INFO:root:current train perplexity4.600896835327148
INFO:root:current mean train loss 1935.907969805208
INFO:root:current train perplexity4.603110313415527
INFO:root:current mean train loss 1935.7052491972506
INFO:root:current train perplexity4.6020426750183105
INFO:root:current mean train loss 1935.9532199435764
INFO:root:current train perplexity4.604170799255371


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.76s/it]
INFO:root:final mean train loss: 1936.171482872975
INFO:root:final train perplexity: 4.604256629943848
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it]
INFO:root:eval mean loss: 2849.0396094336525
INFO:root:eval perplexity: 10.358887672424316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/32

 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [2:47:28<5:55:59, 314.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1905.3694415425146
INFO:root:current train perplexity4.464241027832031
INFO:root:current mean train loss 1923.5185896866806
INFO:root:current train perplexity4.5186448097229
INFO:root:current mean train loss 1929.9670184100116
INFO:root:current train perplexity4.5466413497924805
INFO:root:current mean train loss 1930.2612375865524
INFO:root:current train perplexity4.5575642585754395
INFO:root:current mean train loss 1925.4510845244604
INFO:root:current train perplexity4.55316686630249
INFO:root:current mean train loss 1922.1976062079161
INFO:root:current train perplexity4.550803184509277
INFO:root:current mean train loss 1919.585835173564
INFO:root:current train perplexity4.552785396575928
INFO:root:current mean train loss 1921.3273176601406
INFO:root:current train perplexity4.5577898025512695
INFO:root:current mean train loss 1921.7365696591414
INFO:root:current train perplexity4.560368061065674
INFO:root:current mean train loss 1925.3732787179795
INFO:root:current train perplexity4.566783428192139
INFO:root:current mean train loss 1926.0841292676623
INFO:root:current train perplexity4.569731712341309
INFO:root:current mean train loss 1926.2842339409722
INFO:root:current train perplexity4.570431709289551
INFO:root:current mean train loss 1927.9882670101003
INFO:root:current train perplexity4.572576999664307
INFO:root:current mean train loss 1928.4094033770302
INFO:root:current train perplexity4.572136402130127
INFO:root:current mean train loss 1928.3483043308484
INFO:root:current train perplexity4.572240829467773
INFO:root:current mean train loss 1929.5248648445095
INFO:root:current train perplexity4.573175430297852
INFO:root:current mean train loss 1930.3045730080028
INFO:root:current train perplexity4.574307918548584
INFO:root:current mean train loss 1929.7119062186246
INFO:root:current train perplexity4.575235843658447
INFO:root:current mean train loss 1929.252119307536
INFO:root:current train perplexity4.5772705078125
INFO:root:current mean train loss 1929.4889059258194
INFO:root:current train perplexity4.577872276306152


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.99s/it]
INFO:root:final mean train loss: 1928.5236900125678
INFO:root:final train perplexity: 4.5765700340271
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.68s/it]
INFO:root:eval mean loss: 2853.0756205424173
INFO:root:eval perplexity: 10.393254280090332
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/33

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [2:52:50<5:53:28, 316.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1893.1609537760417
INFO:root:current train perplexity4.483770370483398
INFO:root:current mean train loss 1902.6399948120118
INFO:root:current train perplexity4.525586128234863
INFO:root:current mean train loss 1905.9097421499398
INFO:root:current train perplexity4.534554481506348
INFO:root:current mean train loss 1907.509413655599
INFO:root:current train perplexity4.5352935791015625
INFO:root:current mean train loss 1906.560053020975
INFO:root:current train perplexity4.536799430847168
INFO:root:current mean train loss 1909.156547328404
INFO:root:current train perplexity4.535346984863281
INFO:root:current mean train loss 1911.5007564660275
INFO:root:current train perplexity4.540321350097656
INFO:root:current mean train loss 1914.5729805394224
INFO:root:current train perplexity4.540806293487549
INFO:root:current mean train loss 1917.9675271677415
INFO:root:current train perplexity4.544301509857178
INFO:root:current mean train loss 1918.8101009368897
INFO:root:current train perplexity4.540726184844971
INFO:root:current mean train loss 1918.7810981030734
INFO:root:current train perplexity4.540986061096191
INFO:root:current mean train loss 1917.835332936254
INFO:root:current train perplexity4.539876937866211
INFO:root:current mean train loss 1918.3104983375185
INFO:root:current train perplexity4.5416154861450195
INFO:root:current mean train loss 1917.7646036484662
INFO:root:current train perplexity4.541268825531006
INFO:root:current mean train loss 1917.7103499739137
INFO:root:current train perplexity4.5405192375183105
INFO:root:current mean train loss 1917.594051576272
INFO:root:current train perplexity4.542297840118408
INFO:root:current mean train loss 1917.8679048469269
INFO:root:current train perplexity4.542565822601318
INFO:root:current mean train loss 1919.7802452087403
INFO:root:current train perplexity4.545280456542969
INFO:root:current mean train loss 1921.077539784421
INFO:root:current train perplexity4.548882007598877
INFO:root:current mean train loss 1922.5753288424744
INFO:root:current train perplexity4.553452014923096


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:47<00:00, 287.21s/it]
INFO:root:final mean train loss: 1921.762397523727
INFO:root:final train perplexity: 4.5522308349609375
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.60s/it]
INFO:root:eval mean loss: 2851.7288301485078
INFO:root:eval perplexity: 10.381772994995117
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/34

 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [2:58:09<5:48:46, 317.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1931.4857954545455
INFO:root:current train perplexity4.49731969833374
INFO:root:current mean train loss 1923.206353311485
INFO:root:current train perplexity4.507315158843994
INFO:root:current mean train loss 1913.3370339293772
INFO:root:current train perplexity4.499361515045166
INFO:root:current mean train loss 1911.4466277509532
INFO:root:current train perplexity4.502331256866455
INFO:root:current mean train loss 1910.0706185714753
INFO:root:current train perplexity4.511844635009766
INFO:root:current mean train loss 1911.6865845784364
INFO:root:current train perplexity4.515378475189209
INFO:root:current mean train loss 1910.731118950217
INFO:root:current train perplexity4.511950969696045
INFO:root:current mean train loss 1911.6961462543738
INFO:root:current train perplexity4.5089240074157715
INFO:root:current mean train loss 1910.5864814575614
INFO:root:current train perplexity4.506957530975342
INFO:root:current mean train loss 1911.5431705346004
INFO:root:current train perplexity4.5110297203063965
INFO:root:current mean train loss 1912.1066891130963
INFO:root:current train perplexity4.514278888702393
INFO:root:current mean train loss 1913.463231322516
INFO:root:current train perplexity4.517752647399902
INFO:root:current mean train loss 1914.8552285286255
INFO:root:current train perplexity4.523168087005615
INFO:root:current mean train loss 1915.197587067958
INFO:root:current train perplexity4.524380683898926
INFO:root:current mean train loss 1914.6521785377083
INFO:root:current train perplexity4.524602890014648
INFO:root:current mean train loss 1914.5841673643588
INFO:root:current train perplexity4.523897647857666
INFO:root:current mean train loss 1915.663134780183
INFO:root:current train perplexity4.52679443359375
INFO:root:current mean train loss 1915.843132435504
INFO:root:current train perplexity4.5277099609375
INFO:root:current mean train loss 1916.1578011449246
INFO:root:current train perplexity4.529447078704834
INFO:root:current mean train loss 1915.7499940724583
INFO:root:current train perplexity4.529114246368408


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.92s/it]
INFO:root:final mean train loss: 1915.2157104923097
INFO:root:final train perplexity: 4.528788089752197
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.69s/it]
INFO:root:eval mean loss: 2850.781207477008
INFO:root:eval perplexity: 10.373703956604004
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/35

 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [3:03:30<5:44:47, 318.28s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1929.6013988738364
INFO:root:current train perplexity4.541919708251953
INFO:root:current mean train loss 1914.779074128141
INFO:root:current train perplexity4.506627559661865
INFO:root:current mean train loss 1912.136095527078
INFO:root:current train perplexity4.491663932800293
INFO:root:current mean train loss 1909.206030521296
INFO:root:current train perplexity4.486490726470947
INFO:root:current mean train loss 1906.9978652521665
INFO:root:current train perplexity4.492088794708252
INFO:root:current mean train loss 1908.6996700402462
INFO:root:current train perplexity4.494442462921143
INFO:root:current mean train loss 1908.225581012473
INFO:root:current train perplexity4.498532295227051
INFO:root:current mean train loss 1908.6291287131514
INFO:root:current train perplexity4.49498987197876
INFO:root:current mean train loss 1908.7677064763352
INFO:root:current train perplexity4.498716354370117
INFO:root:current mean train loss 1907.2736043949242
INFO:root:current train perplexity4.496852874755859
INFO:root:current mean train loss 1909.4133469269525
INFO:root:current train perplexity4.500855922698975
INFO:root:current mean train loss 1910.3597066550199
INFO:root:current train perplexity4.500272274017334
INFO:root:current mean train loss 1909.9469320541925
INFO:root:current train perplexity4.503834247589111
INFO:root:current mean train loss 1910.1162944777282
INFO:root:current train perplexity4.50358772277832
INFO:root:current mean train loss 1910.1727964102504
INFO:root:current train perplexity4.50312614440918
INFO:root:current mean train loss 1908.7997343860277
INFO:root:current train perplexity4.501091003417969
INFO:root:current mean train loss 1908.1848981873063
INFO:root:current train perplexity4.50026798248291
INFO:root:current mean train loss 1908.94962673974
INFO:root:current train perplexity4.502466678619385
INFO:root:current mean train loss 1908.965997359569
INFO:root:current train perplexity4.503981113433838


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.46s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.46s/it]
INFO:root:final mean train loss: 1908.4017651933525
INFO:root:final train perplexity: 4.5045166015625
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.66s/it]
INFO:root:eval mean loss: 2855.6086257155594
INFO:root:eval perplexity: 10.414876937866211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/36

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [3:08:45<5:38:38, 317.48s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1931.2518532492898
INFO:root:current train perplexity4.584278583526611
INFO:root:current mean train loss 1888.0913382865288
INFO:root:current train perplexity4.475241661071777
INFO:root:current mean train loss 1881.620742580902
INFO:root:current train perplexity4.441957473754883
INFO:root:current mean train loss 1887.2307552816017
INFO:root:current train perplexity4.45280122756958
INFO:root:current mean train loss 1889.9396847912865
INFO:root:current train perplexity4.44417142868042
INFO:root:current mean train loss 1892.73195724338
INFO:root:current train perplexity4.454737663269043
INFO:root:current mean train loss 1896.635286072077
INFO:root:current train perplexity4.464837074279785
INFO:root:current mean train loss 1897.2365568136868
INFO:root:current train perplexity4.465076923370361
INFO:root:current mean train loss 1895.1878842731292
INFO:root:current train perplexity4.464745044708252
INFO:root:current mean train loss 1894.3876934365567
INFO:root:current train perplexity4.466579437255859
INFO:root:current mean train loss 1894.8695750552515
INFO:root:current train perplexity4.4677863121032715
INFO:root:current mean train loss 1894.9046668216627
INFO:root:current train perplexity4.469069480895996
INFO:root:current mean train loss 1896.450422417714
INFO:root:current train perplexity4.470008850097656
INFO:root:current mean train loss 1895.7489335840662
INFO:root:current train perplexity4.469488620758057
INFO:root:current mean train loss 1898.9872000928808
INFO:root:current train perplexity4.471965789794922
INFO:root:current mean train loss 1899.36723556872
INFO:root:current train perplexity4.475091457366943
INFO:root:current mean train loss 1900.4437995403912
INFO:root:current train perplexity4.477394104003906
INFO:root:current mean train loss 1901.4918594583303
INFO:root:current train perplexity4.477665424346924
INFO:root:current mean train loss 1901.6915147045183
INFO:root:current train perplexity4.479100704193115
INFO:root:current mean train loss 1901.5685839051666
INFO:root:current train perplexity4.479219436645508


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.15s/it]
INFO:root:final mean train loss: 1902.00001772882
INFO:root:final train perplexity: 4.48183012008667
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.52s/it]
INFO:root:eval mean loss: 2852.663893874343
INFO:root:eval perplexity: 10.38974380493164
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/37

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [3:14:01<5:32:37, 316.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1879.3276192801338
INFO:root:current train perplexity4.392735481262207
INFO:root:current mean train loss 1887.4810256958008
INFO:root:current train perplexity4.430746555328369
INFO:root:current mean train loss 1886.2621754428797
INFO:root:current train perplexity4.419248104095459
INFO:root:current mean train loss 1879.7679380091224
INFO:root:current train perplexity4.413331985473633
INFO:root:current mean train loss 1880.7733687641464
INFO:root:current train perplexity4.422989368438721
INFO:root:current mean train loss 1883.843344486121
INFO:root:current train perplexity4.433042526245117
INFO:root:current mean train loss 1884.6988049160902
INFO:root:current train perplexity4.4336628913879395
INFO:root:current mean train loss 1883.7636279431017
INFO:root:current train perplexity4.434319496154785
INFO:root:current mean train loss 1884.772124507001
INFO:root:current train perplexity4.4404616355896
INFO:root:current mean train loss 1885.2417214492273
INFO:root:current train perplexity4.44254207611084
INFO:root:current mean train loss 1887.4642160616033
INFO:root:current train perplexity4.4440107345581055
INFO:root:current mean train loss 1888.7384522350121
INFO:root:current train perplexity4.4439496994018555
INFO:root:current mean train loss 1888.8270400851868
INFO:root:current train perplexity4.447412490844727
INFO:root:current mean train loss 1889.8213128698878
INFO:root:current train perplexity4.448029518127441
INFO:root:current mean train loss 1889.3223526471136
INFO:root:current train perplexity4.4477667808532715
INFO:root:current mean train loss 1891.432084567884
INFO:root:current train perplexity4.451694965362549
INFO:root:current mean train loss 1894.0910471323375
INFO:root:current train perplexity4.455941677093506
INFO:root:current mean train loss 1895.604496496695
INFO:root:current train perplexity4.457314491271973
INFO:root:current mean train loss 1896.3139209037797
INFO:root:current train perplexity4.459263801574707
INFO:root:current mean train loss 1896.1493977906794
INFO:root:current train perplexity4.458892345428467


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:41<00:00, 281.60s/it]
INFO:root:final mean train loss: 1895.566335026928
INFO:root:final train perplexity: 4.459147930145264
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.83s/it]
INFO:root:eval mean loss: 2859.5477503871057
INFO:root:eval perplexity: 10.44859504699707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/38

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [3:19:14<5:26:08, 315.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1866.070822482639
INFO:root:current train perplexity4.403360843658447
INFO:root:current mean train loss 1887.2332713160022
INFO:root:current train perplexity4.409186363220215
INFO:root:current mean train loss 1890.9135752152424
INFO:root:current train perplexity4.420118808746338
INFO:root:current mean train loss 1884.812987573596
INFO:root:current train perplexity4.416356086730957
INFO:root:current mean train loss 1885.800644640976
INFO:root:current train perplexity4.416534900665283
INFO:root:current mean train loss 1884.074534564937
INFO:root:current train perplexity4.41421365737915
INFO:root:current mean train loss 1884.7966785519623
INFO:root:current train perplexity4.413219928741455
INFO:root:current mean train loss 1882.7657490365457
INFO:root:current train perplexity4.4082207679748535
INFO:root:current mean train loss 1884.480073213295
INFO:root:current train perplexity4.410444259643555
INFO:root:current mean train loss 1884.700197379299
INFO:root:current train perplexity4.411080837249756
INFO:root:current mean train loss 1885.1160360673969
INFO:root:current train perplexity4.414432525634766
INFO:root:current mean train loss 1886.9619677947599
INFO:root:current train perplexity4.420133590698242
INFO:root:current mean train loss 1887.5097398382593
INFO:root:current train perplexity4.422811031341553
INFO:root:current mean train loss 1886.1601260273874
INFO:root:current train perplexity4.425140857696533
INFO:root:current mean train loss 1887.587269967155
INFO:root:current train perplexity4.426014423370361
INFO:root:current mean train loss 1887.9541349836923
INFO:root:current train perplexity4.427155017852783
INFO:root:current mean train loss 1888.452480587481
INFO:root:current train perplexity4.428648948669434
INFO:root:current mean train loss 1889.2317786449007
INFO:root:current train perplexity4.430904388427734
INFO:root:current mean train loss 1889.5050015085112
INFO:root:current train perplexity4.432892799377441
INFO:root:current mean train loss 1889.3747714241244
INFO:root:current train perplexity4.433925628662109


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.64s/it]
INFO:root:final mean train loss: 1888.891350250321
INFO:root:final train perplexity: 4.435734748840332
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.78s/it]
INFO:root:eval mean loss: 2854.4077749624626
INFO:root:eval perplexity: 10.404619216918945
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/39

 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [3:24:29<5:20:40, 315.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1867.19580078125
INFO:root:current train perplexity4.374120235443115
INFO:root:current mean train loss 1872.5323456187307
INFO:root:current train perplexity4.382392883300781
INFO:root:current mean train loss 1879.5610719637107
INFO:root:current train perplexity4.38682222366333
INFO:root:current mean train loss 1879.9336706340641
INFO:root:current train perplexity4.390453338623047
INFO:root:current mean train loss 1876.4410440023844
INFO:root:current train perplexity4.393843650817871
INFO:root:current mean train loss 1879.066633231275
INFO:root:current train perplexity4.4066853523254395
INFO:root:current mean train loss 1878.838482352542
INFO:root:current train perplexity4.407736301422119
INFO:root:current mean train loss 1878.7876458756255
INFO:root:current train perplexity4.407077789306641
INFO:root:current mean train loss 1880.88907150658
INFO:root:current train perplexity4.412356376647949
INFO:root:current mean train loss 1880.1426363685275
INFO:root:current train perplexity4.412055015563965
INFO:root:current mean train loss 1881.7124282061043
INFO:root:current train perplexity4.411224842071533
INFO:root:current mean train loss 1881.676040833255
INFO:root:current train perplexity4.408230781555176
INFO:root:current mean train loss 1880.7466922040599
INFO:root:current train perplexity4.407175540924072
INFO:root:current mean train loss 1881.887531028445
INFO:root:current train perplexity4.410843849182129
INFO:root:current mean train loss 1881.5848569021994
INFO:root:current train perplexity4.413360595703125
INFO:root:current mean train loss 1882.5290598460258
INFO:root:current train perplexity4.414607048034668
INFO:root:current mean train loss 1883.4795365499963
INFO:root:current train perplexity4.415503978729248
INFO:root:current mean train loss 1883.6309663424022
INFO:root:current train perplexity4.416409969329834
INFO:root:current mean train loss 1884.0740368901468
INFO:root:current train perplexity4.416475296020508
INFO:root:current mean train loss 1884.163266429843
INFO:root:current train perplexity4.416146755218506


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.90s/it]
INFO:root:final mean train loss: 1883.5103853949981
INFO:root:final train perplexity: 4.416950702667236
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.67s/it]
INFO:root:eval mean loss: 2860.006908519848
INFO:root:eval perplexity: 10.452533721923828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/40

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [3:29:43<5:15:01, 315.02s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1875.9925923407832
INFO:root:current train perplexity4.403000354766846
INFO:root:current mean train loss 1878.876515308572
INFO:root:current train perplexity4.387417793273926
INFO:root:current mean train loss 1875.5826993552587
INFO:root:current train perplexity4.386332035064697
INFO:root:current mean train loss 1875.6519301925298
INFO:root:current train perplexity4.391997814178467
INFO:root:current mean train loss 1874.4812192658044
INFO:root:current train perplexity4.392584323883057
INFO:root:current mean train loss 1877.2398017527526
INFO:root:current train perplexity4.388309001922607
INFO:root:current mean train loss 1877.3843474577734
INFO:root:current train perplexity4.387598037719727
INFO:root:current mean train loss 1879.3398127231426
INFO:root:current train perplexity4.393268585205078
INFO:root:current mean train loss 1878.2351628326312
INFO:root:current train perplexity4.392481803894043
INFO:root:current mean train loss 1878.9635918746808
INFO:root:current train perplexity4.393898010253906
INFO:root:current mean train loss 1879.2756782086278
INFO:root:current train perplexity4.393584251403809
INFO:root:current mean train loss 1879.1326518103265
INFO:root:current train perplexity4.39677095413208
INFO:root:current mean train loss 1879.916525380699
INFO:root:current train perplexity4.395314693450928
INFO:root:current mean train loss 1881.2278003761785
INFO:root:current train perplexity4.400939464569092
INFO:root:current mean train loss 1881.5919182850268
INFO:root:current train perplexity4.401667594909668
INFO:root:current mean train loss 1880.3741553260074
INFO:root:current train perplexity4.401244640350342
INFO:root:current mean train loss 1879.5527642564166
INFO:root:current train perplexity4.397939205169678
INFO:root:current mean train loss 1878.5851687109155
INFO:root:current train perplexity4.397613048553467
INFO:root:current mean train loss 1878.3179634747955
INFO:root:current train perplexity4.398319721221924
INFO:root:current mean train loss 1878.5020769841144
INFO:root:current train perplexity4.397737979888916


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.59s/it]
INFO:root:final mean train loss: 1877.934401088451
INFO:root:final train perplexity: 4.39756965637207
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.11s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.11s/it]
INFO:root:eval mean loss: 2858.0993601022897
INFO:root:eval perplexity: 10.43618392944336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/41

 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [3:34:57<5:09:32, 314.78s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1855.8808937072754
INFO:root:current train perplexity4.333549976348877
INFO:root:current mean train loss 1855.446192527304
INFO:root:current train perplexity4.332098484039307
INFO:root:current mean train loss 1861.8301441089527
INFO:root:current train perplexity4.350277423858643
INFO:root:current mean train loss 1864.0161915788747
INFO:root:current train perplexity4.353711128234863
INFO:root:current mean train loss 1863.867172241211
INFO:root:current train perplexity4.361501693725586
INFO:root:current mean train loss 1866.7421379345376
INFO:root:current train perplexity4.356649398803711
INFO:root:current mean train loss 1863.4454747342515
INFO:root:current train perplexity4.352414131164551
INFO:root:current mean train loss 1864.4925146054982
INFO:root:current train perplexity4.355580806732178
INFO:root:current mean train loss 1865.8903097425189
INFO:root:current train perplexity4.3580851554870605
INFO:root:current mean train loss 1866.0022144241027
INFO:root:current train perplexity4.36035680770874
INFO:root:current mean train loss 1866.4152813096987
INFO:root:current train perplexity4.356898784637451
INFO:root:current mean train loss 1867.4390538448474
INFO:root:current train perplexity4.358687400817871
INFO:root:current mean train loss 1869.121227028929
INFO:root:current train perplexity4.361665725708008
INFO:root:current mean train loss 1869.0767044023662
INFO:root:current train perplexity4.364197731018066
INFO:root:current mean train loss 1870.1604868842956
INFO:root:current train perplexity4.368337154388428
INFO:root:current mean train loss 1872.5075969648242
INFO:root:current train perplexity4.372043609619141
INFO:root:current mean train loss 1872.6905591712807
INFO:root:current train perplexity4.373671531677246
INFO:root:current mean train loss 1872.39614229266
INFO:root:current train perplexity4.374106407165527
INFO:root:current mean train loss 1872.9165397032405
INFO:root:current train perplexity4.376128673553467


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.62s/it]
INFO:root:final mean train loss: 1872.1001062744265
INFO:root:final train perplexity: 4.377381801605225
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.84s/it]
INFO:root:eval mean loss: 2857.6006130642363
INFO:root:eval perplexity: 10.431915283203125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/42

 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [3:40:12<5:04:20, 314.84s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1875.6800724909856
INFO:root:current train perplexity4.437900543212891
INFO:root:current mean train loss 1851.5218430240598
INFO:root:current train perplexity4.365608215332031
INFO:root:current mean train loss 1849.7325422260124
INFO:root:current train perplexity4.348006248474121
INFO:root:current mean train loss 1854.8181784145368
INFO:root:current train perplexity4.336353778839111
INFO:root:current mean train loss 1854.1825571868378
INFO:root:current train perplexity4.33618688583374
INFO:root:current mean train loss 1857.4310890480324
INFO:root:current train perplexity4.334190845489502
INFO:root:current mean train loss 1858.9902644445224
INFO:root:current train perplexity4.342621326446533
INFO:root:current mean train loss 1862.1863234681803
INFO:root:current train perplexity4.343015193939209
INFO:root:current mean train loss 1862.5596034952048
INFO:root:current train perplexity4.34917688369751
INFO:root:current mean train loss 1864.3349118687106
INFO:root:current train perplexity4.348240375518799
INFO:root:current mean train loss 1865.5242675299235
INFO:root:current train perplexity4.34971284866333
INFO:root:current mean train loss 1865.7990063498498
INFO:root:current train perplexity4.352778911590576
INFO:root:current mean train loss 1866.1610532101774
INFO:root:current train perplexity4.35578727722168
INFO:root:current mean train loss 1866.0648102248251
INFO:root:current train perplexity4.354928016662598
INFO:root:current mean train loss 1867.6796161411337
INFO:root:current train perplexity4.35793924331665
INFO:root:current mean train loss 1867.748263826137
INFO:root:current train perplexity4.3594970703125
INFO:root:current mean train loss 1866.3274771873062
INFO:root:current train perplexity4.35509729385376
INFO:root:current mean train loss 1866.582098520505
INFO:root:current train perplexity4.3564019203186035
INFO:root:current mean train loss 1865.8712124537842
INFO:root:current train perplexity4.354866981506348
INFO:root:current mean train loss 1866.9024779443896
INFO:root:current train perplexity4.357511520385742


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.60s/it]
INFO:root:final mean train loss: 1866.9131286898107
INFO:root:final train perplexity: 4.359511375427246
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.88s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.88s/it]
INFO:root:eval mean loss: 2860.535519894895
INFO:root:eval perplexity: 10.45706558227539
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/43

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [3:45:26<4:58:52, 314.60s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1871.4735473632813
INFO:root:current train perplexity4.366446018218994
INFO:root:current mean train loss 1865.6326002854566
INFO:root:current train perplexity4.340341091156006
INFO:root:current mean train loss 1871.0829223632813
INFO:root:current train perplexity4.348154067993164
INFO:root:current mean train loss 1866.9230886748344
INFO:root:current train perplexity4.329739093780518
INFO:root:current mean train loss 1862.6246230014535
INFO:root:current train perplexity4.328783988952637
INFO:root:current mean train loss 1862.6628341962705
INFO:root:current train perplexity4.323505401611328
INFO:root:current mean train loss 1860.5010354662697
INFO:root:current train perplexity4.323964595794678
INFO:root:current mean train loss 1861.5814954783818
INFO:root:current train perplexity4.32797384262085
INFO:root:current mean train loss 1862.8143675287085
INFO:root:current train perplexity4.3270263671875
INFO:root:current mean train loss 1862.8332863428259
INFO:root:current train perplexity4.3286824226379395
INFO:root:current mean train loss 1861.8829414441748
INFO:root:current train perplexity4.329957962036133
INFO:root:current mean train loss 1862.0025999896295
INFO:root:current train perplexity4.33089017868042
INFO:root:current mean train loss 1862.561238706015
INFO:root:current train perplexity4.334341526031494
INFO:root:current mean train loss 1862.146202511895
INFO:root:current train perplexity4.333440780639648
INFO:root:current mean train loss 1862.6629963054525
INFO:root:current train perplexity4.336977005004883
INFO:root:current mean train loss 1861.3746368208742
INFO:root:current train perplexity4.3362040519714355
INFO:root:current mean train loss 1861.5460118206001
INFO:root:current train perplexity4.3399176597595215
INFO:root:current mean train loss 1862.6385471233743
INFO:root:current train perplexity4.341086387634277
INFO:root:current mean train loss 1862.5712490394467
INFO:root:current train perplexity4.3426408767700195
INFO:root:current mean train loss 1861.6814568870425
INFO:root:current train perplexity4.339950084686279


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.80s/it]
INFO:root:final mean train loss: 1861.590865434809
INFO:root:final train perplexity: 4.341251373291016
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.08s/it]
INFO:root:eval mean loss: 2861.9290452561936
INFO:root:eval perplexity: 10.469032287597656
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/44

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [3:50:43<4:54:24, 315.44s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1847.298246343085
INFO:root:current train perplexity4.310598373413086
INFO:root:current mean train loss 1831.2317857807186
INFO:root:current train perplexity4.275108337402344
INFO:root:current mean train loss 1842.4127642056237
INFO:root:current train perplexity4.274643421173096
INFO:root:current mean train loss 1849.902070059213
INFO:root:current train perplexity4.3011393547058105
INFO:root:current mean train loss 1850.6550290237872
INFO:root:current train perplexity4.302231788635254
INFO:root:current mean train loss 1851.491630707624
INFO:root:current train perplexity4.305890083312988
INFO:root:current mean train loss 1851.6562579241934
INFO:root:current train perplexity4.308572292327881
INFO:root:current mean train loss 1851.70665490739
INFO:root:current train perplexity4.30007791519165
INFO:root:current mean train loss 1854.5275638224523
INFO:root:current train perplexity4.307620048522949
INFO:root:current mean train loss 1854.769837263645
INFO:root:current train perplexity4.305799961090088
INFO:root:current mean train loss 1854.575882847011
INFO:root:current train perplexity4.311126708984375
INFO:root:current mean train loss 1856.186064423326
INFO:root:current train perplexity4.313715934753418
INFO:root:current mean train loss 1854.5306187976144
INFO:root:current train perplexity4.312636852264404
INFO:root:current mean train loss 1853.5424393255266
INFO:root:current train perplexity4.3122429847717285
INFO:root:current mean train loss 1854.306351688704
INFO:root:current train perplexity4.313134670257568
INFO:root:current mean train loss 1855.6004416941055
INFO:root:current train perplexity4.319377422332764
INFO:root:current mean train loss 1854.9648098045216
INFO:root:current train perplexity4.31878137588501
INFO:root:current mean train loss 1854.8355145511725
INFO:root:current train perplexity4.317482948303223
INFO:root:current mean train loss 1855.4437597550505
INFO:root:current train perplexity4.319555759429932
INFO:root:current mean train loss 1856.7385650148867
INFO:root:current train perplexity4.32268762588501


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.16s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.16s/it]
INFO:root:final mean train loss: 1856.2408043442504
INFO:root:final train perplexity: 4.322971820831299
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.99s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.99s/it]
INFO:root:eval mean loss: 2864.955125046922
INFO:root:eval perplexity: 10.495059967041016
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/45

 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [3:55:58<4:48:57, 315.23s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1840.8629264831543
INFO:root:current train perplexity4.268973350524902
INFO:root:current mean train loss 1850.347451558927
INFO:root:current train perplexity4.285574913024902
INFO:root:current mean train loss 1850.9182623660927
INFO:root:current train perplexity4.297014236450195
INFO:root:current mean train loss 1852.4598398732614
INFO:root:current train perplexity4.315789699554443
INFO:root:current mean train loss 1851.535593756314
INFO:root:current train perplexity4.307308197021484
INFO:root:current mean train loss 1850.5386265964373
INFO:root:current train perplexity4.304821968078613
INFO:root:current mean train loss 1848.1159500673593
INFO:root:current train perplexity4.299888610839844
INFO:root:current mean train loss 1847.7917595508834
INFO:root:current train perplexity4.301671504974365
INFO:root:current mean train loss 1850.0764427185059
INFO:root:current train perplexity4.305194854736328
INFO:root:current mean train loss 1851.1784318472835
INFO:root:current train perplexity4.307131767272949
INFO:root:current mean train loss 1849.8265912048798
INFO:root:current train perplexity4.306550979614258
INFO:root:current mean train loss 1850.9317517886866
INFO:root:current train perplexity4.305428981781006
INFO:root:current mean train loss 1851.9683989512769
INFO:root:current train perplexity4.306049823760986
INFO:root:current mean train loss 1853.1810159543393
INFO:root:current train perplexity4.3064351081848145
INFO:root:current mean train loss 1854.0953154850527
INFO:root:current train perplexity4.306537628173828
INFO:root:current mean train loss 1853.6571653712435
INFO:root:current train perplexity4.305783748626709
INFO:root:current mean train loss 1852.4729127150315
INFO:root:current train perplexity4.3069562911987305
INFO:root:current mean train loss 1852.3742284796406
INFO:root:current train perplexity4.306285858154297
INFO:root:current mean train loss 1852.0666471162067
INFO:root:current train perplexity4.307160377502441
INFO:root:current mean train loss 1852.3022116604745
INFO:root:current train perplexity4.307347774505615


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.38s/it]
INFO:root:final mean train loss: 1851.666087032747
INFO:root:final train perplexity: 4.307403564453125
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 31.00s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 31.00s/it]
INFO:root:eval mean loss: 2865.6186112870682
INFO:root:eval perplexity: 10.500777244567871
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/46

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [4:01:23<4:46:19, 318.13s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1851.1234161000193
INFO:root:current train perplexity4.284558296203613
INFO:root:current mean train loss 1849.9705405893906
INFO:root:current train perplexity4.270877361297607
INFO:root:current mean train loss 1849.9270041251946
INFO:root:current train perplexity4.271498203277588
INFO:root:current mean train loss 1849.2119089361877
INFO:root:current train perplexity4.268623352050781
INFO:root:current mean train loss 1844.80342872921
INFO:root:current train perplexity4.267897605895996
INFO:root:current mean train loss 1846.1009128590254
INFO:root:current train perplexity4.272998332977295
INFO:root:current mean train loss 1846.803386492176
INFO:root:current train perplexity4.280465126037598
INFO:root:current mean train loss 1848.292501256652
INFO:root:current train perplexity4.281730651855469
INFO:root:current mean train loss 1851.0154188244892
INFO:root:current train perplexity4.284348011016846
INFO:root:current mean train loss 1848.151820502636
INFO:root:current train perplexity4.282236099243164
INFO:root:current mean train loss 1848.056927450711
INFO:root:current train perplexity4.282658100128174
INFO:root:current mean train loss 1848.3802593596197
INFO:root:current train perplexity4.283795356750488
INFO:root:current mean train loss 1848.886736569788
INFO:root:current train perplexity4.287978649139404
INFO:root:current mean train loss 1848.6166781812885
INFO:root:current train perplexity4.288861274719238
INFO:root:current mean train loss 1847.9639275220502
INFO:root:current train perplexity4.289212226867676
INFO:root:current mean train loss 1846.9229731695475
INFO:root:current train perplexity4.287718772888184
INFO:root:current mean train loss 1847.3901909641536
INFO:root:current train perplexity4.287315845489502
INFO:root:current mean train loss 1847.277154852874
INFO:root:current train perplexity4.28826379776001
INFO:root:current mean train loss 1846.1426112871104
INFO:root:current train perplexity4.28737211227417
INFO:root:current mean train loss 1846.6504815153135
INFO:root:current train perplexity4.288484573364258


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.56s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.56s/it]
INFO:root:final mean train loss: 1846.0510896575975
INFO:root:final train perplexity: 4.288370609283447
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.78s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.78s/it]
INFO:root:eval mean loss: 2867.894339163382
INFO:root:eval perplexity: 10.520405769348145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/47

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [4:06:47<4:42:43, 320.07s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1840.9952417490433
INFO:root:current train perplexity4.235942840576172
INFO:root:current mean train loss 1838.6677141285907
INFO:root:current train perplexity4.238400936126709
INFO:root:current mean train loss 1837.4690088873742
INFO:root:current train perplexity4.257517337799072
INFO:root:current mean train loss 1834.571650059379
INFO:root:current train perplexity4.254545211791992
INFO:root:current mean train loss 1835.6995626549165
INFO:root:current train perplexity4.253110885620117
INFO:root:current mean train loss 1835.6579987899117
INFO:root:current train perplexity4.252877712249756
INFO:root:current mean train loss 1838.7946327887155
INFO:root:current train perplexity4.2603068351745605
INFO:root:current mean train loss 1839.0791817189458
INFO:root:current train perplexity4.264005184173584
INFO:root:current mean train loss 1840.3396274762058
INFO:root:current train perplexity4.26838493347168
INFO:root:current mean train loss 1839.0973368856855
INFO:root:current train perplexity4.266303539276123
INFO:root:current mean train loss 1840.9947109535092
INFO:root:current train perplexity4.265804767608643
INFO:root:current mean train loss 1841.5159327231584
INFO:root:current train perplexity4.268147945404053
INFO:root:current mean train loss 1839.6995808229608
INFO:root:current train perplexity4.265752792358398
INFO:root:current mean train loss 1840.5934958178257
INFO:root:current train perplexity4.269549369812012
INFO:root:current mean train loss 1840.5091364495108
INFO:root:current train perplexity4.270820617675781
INFO:root:current mean train loss 1841.1163467579104
INFO:root:current train perplexity4.273889064788818
INFO:root:current mean train loss 1841.5273338290913
INFO:root:current train perplexity4.2747039794921875
INFO:root:current mean train loss 1841.656110074019
INFO:root:current train perplexity4.274199485778809
INFO:root:current mean train loss 1841.8298620258167
INFO:root:current train perplexity4.273853302001953


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.27s/it]
INFO:root:final mean train loss: 1841.9483237523834
INFO:root:final train perplexity: 4.27451753616333
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.25s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.25s/it]
INFO:root:eval mean loss: 2869.645950638138
INFO:root:eval perplexity: 10.535536766052246
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/48

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [4:12:12<4:38:40, 321.54s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1779.1767496744792
INFO:root:current train perplexity4.047951698303223
INFO:root:current mean train loss 1833.2888947860054
INFO:root:current train perplexity4.240251541137695
INFO:root:current mean train loss 1838.093685274346
INFO:root:current train perplexity4.233778953552246
INFO:root:current mean train loss 1835.8646275111607
INFO:root:current train perplexity4.228680610656738
INFO:root:current mean train loss 1839.317288685994
INFO:root:current train perplexity4.239264011383057
INFO:root:current mean train loss 1835.0351972561439
INFO:root:current train perplexity4.2304277420043945
INFO:root:current mean train loss 1831.5718069185086
INFO:root:current train perplexity4.229121208190918
INFO:root:current mean train loss 1832.921274379917
INFO:root:current train perplexity4.236178398132324
INFO:root:current mean train loss 1832.6775468510352
INFO:root:current train perplexity4.240704536437988
INFO:root:current mean train loss 1831.309058017418
INFO:root:current train perplexity4.2407941818237305
INFO:root:current mean train loss 1833.4211416159944
INFO:root:current train perplexity4.244985103607178
INFO:root:current mean train loss 1834.4667548346413
INFO:root:current train perplexity4.242566108703613
INFO:root:current mean train loss 1835.6231273509839
INFO:root:current train perplexity4.243083477020264
INFO:root:current mean train loss 1835.7097190247741
INFO:root:current train perplexity4.2442803382873535
INFO:root:current mean train loss 1835.054793869396
INFO:root:current train perplexity4.246010780334473
INFO:root:current mean train loss 1834.4571101324
INFO:root:current train perplexity4.248037815093994
INFO:root:current mean train loss 1835.3346115065065
INFO:root:current train perplexity4.249381065368652
INFO:root:current mean train loss 1835.202869897959
INFO:root:current train perplexity4.250975608825684
INFO:root:current mean train loss 1836.226733331181
INFO:root:current train perplexity4.252857685089111
INFO:root:current mean train loss 1836.4465045819395
INFO:root:current train perplexity4.255768775939941


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.51s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.51s/it]
INFO:root:final mean train loss: 1836.961529722613
INFO:root:final train perplexity: 4.257739067077637
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.15s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.15s/it]
INFO:root:eval mean loss: 2872.226851363082
INFO:root:eval perplexity: 10.557872772216797
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/49

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [4:17:37<4:34:11, 322.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1856.034351348877
INFO:root:current train perplexity4.2919816970825195
INFO:root:current mean train loss 1829.5695421623461
INFO:root:current train perplexity4.193813323974609
INFO:root:current mean train loss 1826.0651239855536
INFO:root:current train perplexity4.193582057952881
INFO:root:current mean train loss 1827.7269327554359
INFO:root:current train perplexity4.20543909072876
INFO:root:current mean train loss 1829.3648684466327
INFO:root:current train perplexity4.21359395980835
INFO:root:current mean train loss 1826.9721633796405
INFO:root:current train perplexity4.21893835067749
INFO:root:current mean train loss 1827.3396260708193
INFO:root:current train perplexity4.223169326782227
INFO:root:current mean train loss 1828.4153187235847
INFO:root:current train perplexity4.226108551025391
INFO:root:current mean train loss 1828.4417526538555
INFO:root:current train perplexity4.227983474731445
INFO:root:current mean train loss 1828.74561267247
INFO:root:current train perplexity4.229879856109619
INFO:root:current mean train loss 1827.9317919117536
INFO:root:current train perplexity4.228399753570557
INFO:root:current mean train loss 1830.0110114539048
INFO:root:current train perplexity4.231442928314209
INFO:root:current mean train loss 1830.684373632654
INFO:root:current train perplexity4.232614994049072
INFO:root:current mean train loss 1829.816589447113
INFO:root:current train perplexity4.231429576873779
INFO:root:current mean train loss 1829.5160825079379
INFO:root:current train perplexity4.232043743133545
INFO:root:current mean train loss 1829.825279056559
INFO:root:current train perplexity4.232489109039307
INFO:root:current mean train loss 1830.9253767424939
INFO:root:current train perplexity4.234565258026123
INFO:root:current mean train loss 1830.4420189978619
INFO:root:current train perplexity4.235482692718506
INFO:root:current mean train loss 1831.7625911662672
INFO:root:current train perplexity4.237982749938965
INFO:root:current mean train loss 1831.8023851603948
INFO:root:current train perplexity4.2400312423706055


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.45s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.45s/it]
INFO:root:final mean train loss: 1832.3148967148497
INFO:root:final train perplexity: 4.2421650886535645
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.80s/it]
INFO:root:eval mean loss: 2871.8252583638327
INFO:root:eval perplexity: 10.55439281463623
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/50

 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [4:23:11<4:31:40, 326.01s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1807.402513153699
INFO:root:current train perplexity4.188857078552246
INFO:root:current mean train loss 1816.851546114723
INFO:root:current train perplexity4.164937496185303
INFO:root:current mean train loss 1817.7811338125941
INFO:root:current train perplexity4.185882568359375
INFO:root:current mean train loss 1819.80857696096
INFO:root:current train perplexity4.196442604064941
INFO:root:current mean train loss 1824.8948515146506
INFO:root:current train perplexity4.199718952178955
INFO:root:current mean train loss 1825.2619797892476
INFO:root:current train perplexity4.202838897705078
INFO:root:current mean train loss 1823.6089311079545
INFO:root:current train perplexity4.205420970916748
INFO:root:current mean train loss 1825.9113050799504
INFO:root:current train perplexity4.211278915405273
INFO:root:current mean train loss 1825.536826125865
INFO:root:current train perplexity4.210634231567383
INFO:root:current mean train loss 1827.560785227254
INFO:root:current train perplexity4.216740131378174
INFO:root:current mean train loss 1828.3877118367939
INFO:root:current train perplexity4.222301483154297
INFO:root:current mean train loss 1827.6416979226162
INFO:root:current train perplexity4.223760604858398
INFO:root:current mean train loss 1827.595820406325
INFO:root:current train perplexity4.226138591766357
INFO:root:current mean train loss 1826.2426667323018
INFO:root:current train perplexity4.224441051483154
INFO:root:current mean train loss 1826.201990479021
INFO:root:current train perplexity4.225175857543945
INFO:root:current mean train loss 1826.0314559985777
INFO:root:current train perplexity4.224898815155029
INFO:root:current mean train loss 1826.334949315281
INFO:root:current train perplexity4.225584506988525
INFO:root:current mean train loss 1826.7225322952402
INFO:root:current train perplexity4.226871967315674
INFO:root:current mean train loss 1827.4208087168106
INFO:root:current train perplexity4.227269172668457
INFO:root:current mean train loss 1829.0207247707158
INFO:root:current train perplexity4.229593276977539


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.27s/it]
INFO:root:final mean train loss: 1828.250825682855
INFO:root:final train perplexity: 4.228590488433838
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.73s/it]
INFO:root:eval mean loss: 2871.552543021537
INFO:root:eval perplexity: 10.552029609680176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/51

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [4:28:48<4:28:56, 329.31s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1824.7618186257102
INFO:root:current train perplexity4.184510707855225
INFO:root:current mean train loss 1818.025217814618
INFO:root:current train perplexity4.197816371917725
INFO:root:current mean train loss 1821.5017163269501
INFO:root:current train perplexity4.1874823570251465
INFO:root:current mean train loss 1820.6388339683658
INFO:root:current train perplexity4.200891971588135
INFO:root:current mean train loss 1820.5270443371949
INFO:root:current train perplexity4.198182582855225
INFO:root:current mean train loss 1826.2399164745748
INFO:root:current train perplexity4.201501369476318
INFO:root:current mean train loss 1826.4814522774727
INFO:root:current train perplexity4.201565742492676
INFO:root:current mean train loss 1823.5886426482436
INFO:root:current train perplexity4.199508190155029
INFO:root:current mean train loss 1825.3224461932105
INFO:root:current train perplexity4.20403528213501
INFO:root:current mean train loss 1823.9190212589367
INFO:root:current train perplexity4.202271938323975
INFO:root:current mean train loss 1823.790346299506
INFO:root:current train perplexity4.207928657531738
INFO:root:current mean train loss 1822.7631771028757
INFO:root:current train perplexity4.205997467041016
INFO:root:current mean train loss 1823.5815367977389
INFO:root:current train perplexity4.2075114250183105
INFO:root:current mean train loss 1822.8028687774524
INFO:root:current train perplexity4.209379196166992
INFO:root:current mean train loss 1822.2653126632044
INFO:root:current train perplexity4.209710121154785
INFO:root:current mean train loss 1823.6104869623293
INFO:root:current train perplexity4.212701320648193
INFO:root:current mean train loss 1823.4613720732434
INFO:root:current train perplexity4.212491035461426
INFO:root:current mean train loss 1824.4328964423485
INFO:root:current train perplexity4.213469505310059
INFO:root:current mean train loss 1824.3173874571903
INFO:root:current train perplexity4.214132785797119
INFO:root:current mean train loss 1824.5942657874293
INFO:root:current train perplexity4.214803695678711


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.60s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.60s/it]
INFO:root:final mean train loss: 1824.3878586885007
INFO:root:final train perplexity: 4.215726375579834
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.63s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.63s/it]
INFO:root:eval mean loss: 2874.5468486064187
INFO:root:eval perplexity: 10.57799243927002
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/52

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [4:34:11<4:21:55, 327.42s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1814.7019998941078
INFO:root:current train perplexity4.194018840789795
INFO:root:current mean train loss 1813.6482460563952
INFO:root:current train perplexity4.190433502197266
INFO:root:current mean train loss 1808.4501237094191
INFO:root:current train perplexity4.173215866088867
INFO:root:current mean train loss 1810.3089249015788
INFO:root:current train perplexity4.18109130859375
INFO:root:current mean train loss 1810.1964217476223
INFO:root:current train perplexity4.179100036621094
INFO:root:current mean train loss 1810.7555511631647
INFO:root:current train perplexity4.186398983001709
INFO:root:current mean train loss 1813.9113269096588
INFO:root:current train perplexity4.190163612365723
INFO:root:current mean train loss 1814.077884445093
INFO:root:current train perplexity4.186886310577393
INFO:root:current mean train loss 1815.7214778498371
INFO:root:current train perplexity4.18777322769165
INFO:root:current mean train loss 1816.496505287147
INFO:root:current train perplexity4.1914825439453125
INFO:root:current mean train loss 1816.2267008012682
INFO:root:current train perplexity4.190612316131592
INFO:root:current mean train loss 1817.0804751888736
INFO:root:current train perplexity4.196025848388672
INFO:root:current mean train loss 1815.8390214166322
INFO:root:current train perplexity4.196338176727295
INFO:root:current mean train loss 1816.9772024202932
INFO:root:current train perplexity4.198397636413574
INFO:root:current mean train loss 1818.5574591463671
INFO:root:current train perplexity4.199501991271973
INFO:root:current mean train loss 1819.728344125079
INFO:root:current train perplexity4.200259685516357
INFO:root:current mean train loss 1819.8433428813642
INFO:root:current train perplexity4.199221134185791
INFO:root:current mean train loss 1820.7572178265652
INFO:root:current train perplexity4.2014031410217285
INFO:root:current mean train loss 1820.7993199717664
INFO:root:current train perplexity4.202065467834473
INFO:root:current mean train loss 1820.424141980516
INFO:root:current train perplexity4.202569007873535


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.92s/it]
INFO:root:final mean train loss: 1820.424141980516
INFO:root:final train perplexity: 4.202569007873535
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.10s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.10s/it]
INFO:root:eval mean loss: 2877.5343417147615
INFO:root:eval perplexity: 10.603952407836914
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/53

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [4:39:34<4:15:20, 325.96s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1809.8734606933594
INFO:root:current train perplexity4.240323543548584
INFO:root:current mean train loss 1824.5253247070314
INFO:root:current train perplexity4.2173967361450195
INFO:root:current mean train loss 1812.585576985677
INFO:root:current train perplexity4.195606708526611
INFO:root:current mean train loss 1812.1533795166015
INFO:root:current train perplexity4.188239097595215
INFO:root:current mean train loss 1811.0736704101562
INFO:root:current train perplexity4.183277606964111
INFO:root:current mean train loss 1816.3521107991537
INFO:root:current train perplexity4.1913275718688965
INFO:root:current mean train loss 1814.333495919364
INFO:root:current train perplexity4.183733940124512
INFO:root:current mean train loss 1814.0132843017577
INFO:root:current train perplexity4.185765743255615
INFO:root:current mean train loss 1814.8299140082465
INFO:root:current train perplexity4.186330795288086
INFO:root:current mean train loss 1814.6370013427734
INFO:root:current train perplexity4.186972618103027
INFO:root:current mean train loss 1817.0770872913708
INFO:root:current train perplexity4.189990043640137
INFO:root:current mean train loss 1817.5071105957031
INFO:root:current train perplexity4.190515518188477
INFO:root:current mean train loss 1817.9809376878004
INFO:root:current train perplexity4.189546585083008
INFO:root:current mean train loss 1815.7247002301897
INFO:root:current train perplexity4.186821460723877
INFO:root:current mean train loss 1815.805065185547
INFO:root:current train perplexity4.187286853790283
INFO:root:current mean train loss 1816.2434031677246
INFO:root:current train perplexity4.188061714172363
INFO:root:current mean train loss 1816.9423535874312
INFO:root:current train perplexity4.187976360321045
INFO:root:current mean train loss 1818.414552883572
INFO:root:current train perplexity4.1907877922058105
INFO:root:current mean train loss 1817.0395172440378
INFO:root:current train perplexity4.189249038696289


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.20s/it]
INFO:root:final mean train loss: 1816.001926377874
INFO:root:final train perplexity: 4.1879377365112305
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.04s/it]
INFO:root:eval mean loss: 2876.5935762422578
INFO:root:eval perplexity: 10.595768928527832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/54

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [4:45:00<4:09:49, 325.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1806.0891041475184
INFO:root:current train perplexity4.211848735809326
INFO:root:current mean train loss 1802.0806467431223
INFO:root:current train perplexity4.164007663726807
INFO:root:current mean train loss 1806.5902594641057
INFO:root:current train perplexity4.155186176300049
INFO:root:current mean train loss 1804.461487394026
INFO:root:current train perplexity4.15731954574585
INFO:root:current mean train loss 1810.6255863473284
INFO:root:current train perplexity4.171286106109619
INFO:root:current mean train loss 1809.6847141051892
INFO:root:current train perplexity4.1668901443481445
INFO:root:current mean train loss 1807.947930779604
INFO:root:current train perplexity4.162964344024658
INFO:root:current mean train loss 1807.9454846242481
INFO:root:current train perplexity4.168270587921143
INFO:root:current mean train loss 1808.2348662695074
INFO:root:current train perplexity4.168884754180908
INFO:root:current mean train loss 1809.1299846486932
INFO:root:current train perplexity4.171228408813477
INFO:root:current mean train loss 1809.5470626065865
INFO:root:current train perplexity4.172786712646484
INFO:root:current mean train loss 1810.0282223939682
INFO:root:current train perplexity4.175498962402344
INFO:root:current mean train loss 1810.363126380187
INFO:root:current train perplexity4.177290439605713
INFO:root:current mean train loss 1809.379007650852
INFO:root:current train perplexity4.176725387573242
INFO:root:current mean train loss 1810.0874820297338
INFO:root:current train perplexity4.17636251449585
INFO:root:current mean train loss 1809.9891758153685
INFO:root:current train perplexity4.173750877380371
INFO:root:current mean train loss 1810.6313250841886
INFO:root:current train perplexity4.175524711608887
INFO:root:current mean train loss 1810.691589817587
INFO:root:current train perplexity4.175103664398193
INFO:root:current mean train loss 1811.1822189977684
INFO:root:current train perplexity4.174664497375488
INFO:root:current mean train loss 1811.4756508251621
INFO:root:current train perplexity4.17275333404541


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.21s/it]
INFO:root:final mean train loss: 1811.6753959559576
INFO:root:final train perplexity: 4.173671245574951
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.59s/it]
INFO:root:eval mean loss: 2877.8641031167886
INFO:root:eval perplexity: 10.60682201385498
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/55

 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [4:50:27<4:04:43, 326.30s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1782.6095473345588
INFO:root:current train perplexity4.112143039703369
INFO:root:current mean train loss 1799.188448322353
INFO:root:current train perplexity4.13316535949707
INFO:root:current mean train loss 1806.9625004173345
INFO:root:current train perplexity4.138128280639648
INFO:root:current mean train loss 1810.3344174687734
INFO:root:current train perplexity4.149068832397461
INFO:root:current mean train loss 1810.6271398869528
INFO:root:current train perplexity4.15414571762085
INFO:root:current mean train loss 1809.5302140025165
INFO:root:current train perplexity4.15128755569458
INFO:root:current mean train loss 1807.2926564502416
INFO:root:current train perplexity4.146274089813232
INFO:root:current mean train loss 1806.8181927340556
INFO:root:current train perplexity4.145910263061523
INFO:root:current mean train loss 1805.868246320912
INFO:root:current train perplexity4.1460981369018555
INFO:root:current mean train loss 1803.6457102610161
INFO:root:current train perplexity4.145866394042969
INFO:root:current mean train loss 1802.8960885319073
INFO:root:current train perplexity4.1489434242248535
INFO:root:current mean train loss 1803.1065997841918
INFO:root:current train perplexity4.148489952087402
INFO:root:current mean train loss 1804.1456718259344
INFO:root:current train perplexity4.1525559425354
INFO:root:current mean train loss 1804.3807670444562
INFO:root:current train perplexity4.154026508331299
INFO:root:current mean train loss 1804.794560771607
INFO:root:current train perplexity4.156912326812744
INFO:root:current mean train loss 1805.9305442999053
INFO:root:current train perplexity4.157752513885498
INFO:root:current mean train loss 1806.7241001012421
INFO:root:current train perplexity4.159633159637451
INFO:root:current mean train loss 1807.8001690680867
INFO:root:current train perplexity4.16259765625
INFO:root:current mean train loss 1807.4958243167257
INFO:root:current train perplexity4.160947322845459
INFO:root:current mean train loss 1808.3709001038167
INFO:root:current train perplexity4.161215305328369


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.87s/it]
INFO:root:final mean train loss: 1807.9117477501634
INFO:root:final train perplexity: 4.161301612854004
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.14s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.14s/it]
INFO:root:eval mean loss: 2882.1685046863267
INFO:root:eval perplexity: 10.644353866577148
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/56

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [4:55:56<3:59:54, 327.16s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1810.397310144761
INFO:root:current train perplexity4.163552284240723
INFO:root:current mean train loss 1803.4990008019454
INFO:root:current train perplexity4.137963771820068
INFO:root:current mean train loss 1800.1429117514317
INFO:root:current train perplexity4.139286994934082
INFO:root:current mean train loss 1799.3053378461093
INFO:root:current train perplexity4.130645751953125
INFO:root:current mean train loss 1798.9976665894367
INFO:root:current train perplexity4.1298747062683105
INFO:root:current mean train loss 1801.271153389434
INFO:root:current train perplexity4.133316993713379
INFO:root:current mean train loss 1802.3827819355438
INFO:root:current train perplexity4.136691570281982
INFO:root:current mean train loss 1800.4522054903357
INFO:root:current train perplexity4.136609077453613
INFO:root:current mean train loss 1800.154743844558
INFO:root:current train perplexity4.137632846832275
INFO:root:current mean train loss 1799.9322509765625
INFO:root:current train perplexity4.139009952545166
INFO:root:current mean train loss 1800.9324581824974
INFO:root:current train perplexity4.141668796539307
INFO:root:current mean train loss 1802.176701708942
INFO:root:current train perplexity4.141939163208008
INFO:root:current mean train loss 1803.8640879288757
INFO:root:current train perplexity4.1436638832092285
INFO:root:current mean train loss 1804.6116388576459
INFO:root:current train perplexity4.145162105560303
INFO:root:current mean train loss 1804.4370115504933
INFO:root:current train perplexity4.145625591278076
INFO:root:current mean train loss 1804.6194724421744
INFO:root:current train perplexity4.147253036499023
INFO:root:current mean train loss 1804.3020159272553
INFO:root:current train perplexity4.1467742919921875
INFO:root:current mean train loss 1804.4709153363256
INFO:root:current train perplexity4.147892951965332
INFO:root:current mean train loss 1805.2681103937693
INFO:root:current train perplexity4.149240970611572
INFO:root:current mean train loss 1804.6666966784862
INFO:root:current train perplexity4.148944854736328


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.72s/it]
INFO:root:final mean train loss: 1804.0534349096224
INFO:root:final train perplexity: 4.148658275604248
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.31s/it]
INFO:root:eval mean loss: 2883.86718896631
INFO:root:eval perplexity: 10.659199714660645
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/57

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [5:01:18<3:53:13, 325.43s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1784.260618322036
INFO:root:current train perplexity4.071399211883545
INFO:root:current mean train loss 1780.4309300013952
INFO:root:current train perplexity4.089229106903076
INFO:root:current mean train loss 1790.340204950589
INFO:root:current train perplexity4.098666667938232
INFO:root:current mean train loss 1787.7668765524159
INFO:root:current train perplexity4.098810195922852
INFO:root:current mean train loss 1790.9762734959268
INFO:root:current train perplexity4.104045867919922
INFO:root:current mean train loss 1792.738578903843
INFO:root:current train perplexity4.109985828399658
INFO:root:current mean train loss 1791.7082099229276
INFO:root:current train perplexity4.107415676116943
INFO:root:current mean train loss 1792.301871617635
INFO:root:current train perplexity4.109279632568359
INFO:root:current mean train loss 1794.3379714895502
INFO:root:current train perplexity4.112370491027832
INFO:root:current mean train loss 1797.0745713415224
INFO:root:current train perplexity4.11905574798584
INFO:root:current mean train loss 1795.951486880413
INFO:root:current train perplexity4.120026111602783
INFO:root:current mean train loss 1796.1807482993765
INFO:root:current train perplexity4.12318754196167
INFO:root:current mean train loss 1797.9885372318304
INFO:root:current train perplexity4.126104831695557
INFO:root:current mean train loss 1796.4585748862105
INFO:root:current train perplexity4.126436710357666
INFO:root:current mean train loss 1797.4003723310839
INFO:root:current train perplexity4.131012439727783
INFO:root:current mean train loss 1798.084004226996
INFO:root:current train perplexity4.131539821624756
INFO:root:current mean train loss 1798.3349030492402
INFO:root:current train perplexity4.131187915802002
INFO:root:current mean train loss 1799.1113036833199
INFO:root:current train perplexity4.132300853729248
INFO:root:current mean train loss 1799.6712620998603
INFO:root:current train perplexity4.1336493492126465
INFO:root:current mean train loss 1800.499169512493
INFO:root:current train perplexity4.136164665222168


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.72s/it]
INFO:root:final mean train loss: 1800.1613601784602
INFO:root:final train perplexity: 4.13594388961792
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.31s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.31s/it]
INFO:root:eval mean loss: 2883.938035203172
INFO:root:eval perplexity: 10.659820556640625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/58

 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [5:06:46<3:48:24, 326.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1791.153706629136
INFO:root:current train perplexity4.115177154541016
INFO:root:current mean train loss 1791.296349107897
INFO:root:current train perplexity4.105226516723633
INFO:root:current mean train loss 1786.9384195963542
INFO:root:current train perplexity4.091080188751221
INFO:root:current mean train loss 1786.0966654195413
INFO:root:current train perplexity4.088972091674805
INFO:root:current mean train loss 1788.0066179727771
INFO:root:current train perplexity4.092471599578857
INFO:root:current mean train loss 1788.1714847923345
INFO:root:current train perplexity4.094546794891357
INFO:root:current mean train loss 1785.520299312842
INFO:root:current train perplexity4.094928741455078
INFO:root:current mean train loss 1787.7093180856887
INFO:root:current train perplexity4.096640586853027
INFO:root:current mean train loss 1789.170817609022
INFO:root:current train perplexity4.1018757820129395
INFO:root:current mean train loss 1789.6625417641576
INFO:root:current train perplexity4.105735778808594
INFO:root:current mean train loss 1790.565391547559
INFO:root:current train perplexity4.105562210083008
INFO:root:current mean train loss 1791.937543677479
INFO:root:current train perplexity4.108940601348877
INFO:root:current mean train loss 1791.5591101501702
INFO:root:current train perplexity4.111298084259033
INFO:root:current mean train loss 1792.8467881846514
INFO:root:current train perplexity4.112120151519775
INFO:root:current mean train loss 1792.700688279277
INFO:root:current train perplexity4.113157272338867
INFO:root:current mean train loss 1793.4145708824183
INFO:root:current train perplexity4.118215084075928
INFO:root:current mean train loss 1793.6262148350565
INFO:root:current train perplexity4.119811058044434
INFO:root:current mean train loss 1795.3970823485645
INFO:root:current train perplexity4.1222405433654785
INFO:root:current mean train loss 1796.0397468060967
INFO:root:current train perplexity4.123434543609619


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.43s/it]
INFO:root:final mean train loss: 1796.9225462328227
INFO:root:final train perplexity: 4.125392913818359
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.04s/it]
INFO:root:eval mean loss: 2886.2241885440126
INFO:root:eval perplexity: 10.679835319519043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/59

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [5:12:16<3:43:47, 327.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1832.0003051757812
INFO:root:current train perplexity4.205106735229492
INFO:root:current mean train loss 1791.9642393822764
INFO:root:current train perplexity4.07943868637085
INFO:root:current mean train loss 1782.9948663994817
INFO:root:current train perplexity4.074882507324219
INFO:root:current mean train loss 1781.8136143968595
INFO:root:current train perplexity4.071223735809326
INFO:root:current mean train loss 1784.0513560736358
INFO:root:current train perplexity4.077048301696777
INFO:root:current mean train loss 1788.8011588898314
INFO:root:current train perplexity4.087109565734863
INFO:root:current mean train loss 1787.5107154212521
INFO:root:current train perplexity4.087902545928955
INFO:root:current mean train loss 1791.144851901932
INFO:root:current train perplexity4.095058441162109
INFO:root:current mean train loss 1790.9846287296893
INFO:root:current train perplexity4.103033542633057
INFO:root:current mean train loss 1789.7660910866477
INFO:root:current train perplexity4.103404998779297
INFO:root:current mean train loss 1789.482442951012
INFO:root:current train perplexity4.104732513427734
INFO:root:current mean train loss 1790.5607965542054
INFO:root:current train perplexity4.105574131011963
INFO:root:current mean train loss 1790.1108955979942
INFO:root:current train perplexity4.10597562789917
INFO:root:current mean train loss 1790.5992995114186
INFO:root:current train perplexity4.107893943786621
INFO:root:current mean train loss 1790.8536084402306
INFO:root:current train perplexity4.108997344970703
INFO:root:current mean train loss 1792.5063395290654
INFO:root:current train perplexity4.10888147354126
INFO:root:current mean train loss 1793.1904939992003
INFO:root:current train perplexity4.109421253204346
INFO:root:current mean train loss 1793.1507267845504
INFO:root:current train perplexity4.110785961151123
INFO:root:current mean train loss 1793.2264367716425
INFO:root:current train perplexity4.111018180847168
INFO:root:current mean train loss 1792.9214301685931
INFO:root:current train perplexity4.111586093902588


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.83s/it]
INFO:root:final mean train loss: 1792.7913215087028
INFO:root:final train perplexity: 4.111973285675049
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.02s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.02s/it]
INFO:root:eval mean loss: 2887.8816042605104
INFO:root:eval perplexity: 10.694372177124023
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/60

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [5:17:53<3:40:14, 330.36s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1751.9982845908717
INFO:root:current train perplexity4.075648307800293
INFO:root:current mean train loss 1774.7746920545562
INFO:root:current train perplexity4.082971096038818
INFO:root:current mean train loss 1787.125711240725
INFO:root:current train perplexity4.08872652053833
INFO:root:current mean train loss 1787.4668018496523
INFO:root:current train perplexity4.092681884765625
INFO:root:current mean train loss 1788.0321959720875
INFO:root:current train perplexity4.094578266143799
INFO:root:current mean train loss 1786.5707299851729
INFO:root:current train perplexity4.0982584953308105
INFO:root:current mean train loss 1786.0881349628307
INFO:root:current train perplexity4.096282005310059
INFO:root:current mean train loss 1782.9167507633215
INFO:root:current train perplexity4.091831684112549
INFO:root:current mean train loss 1782.7378895518543
INFO:root:current train perplexity4.091416835784912
INFO:root:current mean train loss 1782.5251819498521
INFO:root:current train perplexity4.088306903839111
INFO:root:current mean train loss 1784.943812676337
INFO:root:current train perplexity4.090020179748535
INFO:root:current mean train loss 1785.0914940446269
INFO:root:current train perplexity4.092493534088135
INFO:root:current mean train loss 1785.4195865070947
INFO:root:current train perplexity4.091724872589111
INFO:root:current mean train loss 1784.4588161234244
INFO:root:current train perplexity4.089934825897217
INFO:root:current mean train loss 1785.7137923452365
INFO:root:current train perplexity4.093222618103027
INFO:root:current mean train loss 1785.9504317383455
INFO:root:current train perplexity4.0938920974731445
INFO:root:current mean train loss 1786.3150169556343
INFO:root:current train perplexity4.093811511993408
INFO:root:current mean train loss 1787.5205883405595
INFO:root:current train perplexity4.094757080078125
INFO:root:current mean train loss 1788.20304413429
INFO:root:current train perplexity4.096691131591797
INFO:root:current mean train loss 1789.4620361328125
INFO:root:current train perplexity4.099045276641846


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.73s/it]
INFO:root:final mean train loss: 1789.127260701559
INFO:root:final train perplexity: 4.100108623504639
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.44s/it]
INFO:root:eval mean loss: 2889.0939237577422
INFO:root:eval perplexity: 10.7050142288208
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/61

 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [5:23:30<3:35:58, 332.27s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1787.8396708170574
INFO:root:current train perplexity4.038125038146973
INFO:root:current mean train loss 1774.4841963824103
INFO:root:current train perplexity4.038241863250732
INFO:root:current mean train loss 1779.6045552916446
INFO:root:current train perplexity4.05839204788208
INFO:root:current mean train loss 1782.5240405854724
INFO:root:current train perplexity4.080118656158447
INFO:root:current mean train loss 1784.3665757485485
INFO:root:current train perplexity4.083042621612549
INFO:root:current mean train loss 1786.8419496906338
INFO:root:current train perplexity4.08799409866333
INFO:root:current mean train loss 1785.4333801269531
INFO:root:current train perplexity4.086319446563721
INFO:root:current mean train loss 1786.6411242277725
INFO:root:current train perplexity4.088585376739502
INFO:root:current mean train loss 1788.5380202297958
INFO:root:current train perplexity4.094906330108643
INFO:root:current mean train loss 1788.909424741044
INFO:root:current train perplexity4.095344543457031
INFO:root:current mean train loss 1787.5165683348666
INFO:root:current train perplexity4.09126091003418
INFO:root:current mean train loss 1787.2790425260303
INFO:root:current train perplexity4.088974475860596
INFO:root:current mean train loss 1787.0262631907046
INFO:root:current train perplexity4.0880608558654785
INFO:root:current mean train loss 1787.3365768158508
INFO:root:current train perplexity4.088487148284912
INFO:root:current mean train loss 1787.0487538287234
INFO:root:current train perplexity4.090577125549316
INFO:root:current mean train loss 1787.0233727296193
INFO:root:current train perplexity4.092057704925537
INFO:root:current mean train loss 1786.5449602271642
INFO:root:current train perplexity4.091759204864502
INFO:root:current mean train loss 1786.8005387969831
INFO:root:current train perplexity4.09197998046875
INFO:root:current mean train loss 1786.8546500278715
INFO:root:current train perplexity4.091552734375
INFO:root:current mean train loss 1787.2296409922199
INFO:root:current train perplexity4.092393398284912


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.73s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.73s/it]
INFO:root:final mean train loss: 1786.79160603164
INFO:root:final train perplexity: 4.092562198638916
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.75s/it]
INFO:root:eval mean loss: 2889.451213664837
INFO:root:eval perplexity: 10.70815658569336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/62

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [5:29:09<3:31:39, 334.19s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1783.719949974204
INFO:root:current train perplexity4.045604228973389
INFO:root:current mean train loss 1770.6936290466708
INFO:root:current train perplexity4.053484916687012
INFO:root:current mean train loss 1772.5268096320715
INFO:root:current train perplexity4.0522942543029785
INFO:root:current mean train loss 1776.355976396512
INFO:root:current train perplexity4.062396049499512
INFO:root:current mean train loss 1777.0073667951503
INFO:root:current train perplexity4.065469264984131
INFO:root:current mean train loss 1778.788990538116
INFO:root:current train perplexity4.068770408630371
INFO:root:current mean train loss 1778.6577808327552
INFO:root:current train perplexity4.065922260284424
INFO:root:current mean train loss 1780.260975142399
INFO:root:current train perplexity4.070298671722412
INFO:root:current mean train loss 1781.9331131965307
INFO:root:current train perplexity4.0711588859558105
INFO:root:current mean train loss 1781.919596909226
INFO:root:current train perplexity4.06978702545166
INFO:root:current mean train loss 1782.9342109412096
INFO:root:current train perplexity4.071981906890869
INFO:root:current mean train loss 1782.9450461262738
INFO:root:current train perplexity4.0743889808654785
INFO:root:current mean train loss 1782.23823166198
INFO:root:current train perplexity4.075226783752441
INFO:root:current mean train loss 1782.3652737117748
INFO:root:current train perplexity4.075075626373291
INFO:root:current mean train loss 1783.0746725020701
INFO:root:current train perplexity4.077080726623535
INFO:root:current mean train loss 1783.8810295502908
INFO:root:current train perplexity4.080015182495117
INFO:root:current mean train loss 1783.7904557114432
INFO:root:current train perplexity4.081131458282471
INFO:root:current mean train loss 1783.6250890632798
INFO:root:current train perplexity4.080692291259766
INFO:root:current mean train loss 1783.6420405017834
INFO:root:current train perplexity4.081502437591553
INFO:root:current mean train loss 1783.8092717933948
INFO:root:current train perplexity4.081081390380859


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.27s/it]
INFO:root:final mean train loss: 1783.097543290331
INFO:root:final train perplexity: 4.080657005310059
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.52s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.52s/it]
INFO:root:eval mean loss: 2894.317675341357
INFO:root:eval perplexity: 10.75100040435791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/63

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [5:34:43<3:26:07, 334.26s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1776.9589111328125
INFO:root:current train perplexity4.060636520385742
INFO:root:current mean train loss 1777.627390423943
INFO:root:current train perplexity4.064794540405273
INFO:root:current mean train loss 1777.489804868345
INFO:root:current train perplexity4.056817054748535
INFO:root:current mean train loss 1773.3604023701437
INFO:root:current train perplexity4.04528284072876
INFO:root:current mean train loss 1775.8127451795212
INFO:root:current train perplexity4.058189868927002
INFO:root:current mean train loss 1774.9880135519463
INFO:root:current train perplexity4.062945365905762
INFO:root:current mean train loss 1776.1940508031134
INFO:root:current train perplexity4.057450771331787
INFO:root:current mean train loss 1777.8959041446835
INFO:root:current train perplexity4.061206817626953
INFO:root:current mean train loss 1779.7636497059088
INFO:root:current train perplexity4.063675403594971
INFO:root:current mean train loss 1780.9830444335937
INFO:root:current train perplexity4.064403057098389
INFO:root:current mean train loss 1780.8324388735762
INFO:root:current train perplexity4.063579082489014
INFO:root:current mean train loss 1780.5679902427216
INFO:root:current train perplexity4.06091833114624
INFO:root:current mean train loss 1780.7177298958845
INFO:root:current train perplexity4.060079574584961
INFO:root:current mean train loss 1780.3773492743499
INFO:root:current train perplexity4.061391353607178
INFO:root:current mean train loss 1780.0745219327966
INFO:root:current train perplexity4.062497138977051
INFO:root:current mean train loss 1779.476994877712
INFO:root:current train perplexity4.062131881713867
INFO:root:current mean train loss 1779.7189012356148
INFO:root:current train perplexity4.0641326904296875
INFO:root:current mean train loss 1779.9712016132592
INFO:root:current train perplexity4.06436014175415
INFO:root:current mean train loss 1779.6538631663602
INFO:root:current train perplexity4.065392971038818
INFO:root:current mean train loss 1779.7618939239967
INFO:root:current train perplexity4.0679802894592285


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.68s/it]
INFO:root:final mean train loss: 1779.3060322740855
INFO:root:final train perplexity: 4.068472385406494
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.08s/it]
INFO:root:eval mean loss: 2892.742855404232
INFO:root:eval perplexity: 10.737113952636719
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/64

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [5:40:19<3:20:46, 334.63s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1779.5969729368715
INFO:root:current train perplexity4.048244953155518
INFO:root:current mean train loss 1779.8567762731868
INFO:root:current train perplexity4.05780553817749
INFO:root:current mean train loss 1778.8956247788274
INFO:root:current train perplexity4.049257755279541
INFO:root:current mean train loss 1771.2103861333171
INFO:root:current train perplexity4.0470123291015625
INFO:root:current mean train loss 1769.6487397932174
INFO:root:current train perplexity4.046919345855713
INFO:root:current mean train loss 1767.9599744546556
INFO:root:current train perplexity4.044187545776367
INFO:root:current mean train loss 1768.6798845538233
INFO:root:current train perplexity4.044626235961914
INFO:root:current mean train loss 1768.1625002481735
INFO:root:current train perplexity4.042073726654053
INFO:root:current mean train loss 1771.6116010285284
INFO:root:current train perplexity4.045639991760254
INFO:root:current mean train loss 1773.7655415172635
INFO:root:current train perplexity4.050121307373047
INFO:root:current mean train loss 1773.3151640975377
INFO:root:current train perplexity4.049036502838135
INFO:root:current mean train loss 1774.8042106339183
INFO:root:current train perplexity4.054417133331299
INFO:root:current mean train loss 1774.5492139696241
INFO:root:current train perplexity4.0537896156311035
INFO:root:current mean train loss 1775.538651755841
INFO:root:current train perplexity4.05634069442749
INFO:root:current mean train loss 1776.625824036178
INFO:root:current train perplexity4.057519435882568
INFO:root:current mean train loss 1777.6358244138164
INFO:root:current train perplexity4.060720443725586
INFO:root:current mean train loss 1777.1874643268145
INFO:root:current train perplexity4.061906337738037
INFO:root:current mean train loss 1776.883105072551
INFO:root:current train perplexity4.060329914093018
INFO:root:current mean train loss 1777.0633420069887
INFO:root:current train perplexity4.060834884643555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.43s/it]
INFO:root:final mean train loss: 1777.356238014579
INFO:root:final train perplexity: 4.062222003936768
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.19s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.19s/it]
INFO:root:eval mean loss: 2894.464916332348
INFO:root:eval perplexity: 10.752297401428223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/65

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [5:45:47<3:14:10, 332.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1767.5097961425781
INFO:root:current train perplexity4.089302062988281
INFO:root:current mean train loss 1761.2296835092397
INFO:root:current train perplexity4.022850513458252
INFO:root:current mean train loss 1776.011636771408
INFO:root:current train perplexity4.052400588989258
INFO:root:current mean train loss 1771.887396561472
INFO:root:current train perplexity4.03775691986084
INFO:root:current mean train loss 1771.2159586991413
INFO:root:current train perplexity4.038438320159912
INFO:root:current mean train loss 1772.3656737312438
INFO:root:current train perplexity4.039785861968994
INFO:root:current mean train loss 1772.1025924177359
INFO:root:current train perplexity4.037367343902588
INFO:root:current mean train loss 1772.3755564256148
INFO:root:current train perplexity4.041223526000977
INFO:root:current mean train loss 1774.721179411779
INFO:root:current train perplexity4.0472588539123535
INFO:root:current mean train loss 1774.8709768109618
INFO:root:current train perplexity4.045531272888184
INFO:root:current mean train loss 1774.207487554664
INFO:root:current train perplexity4.04255485534668
INFO:root:current mean train loss 1773.248724453691
INFO:root:current train perplexity4.043222904205322
INFO:root:current mean train loss 1773.634126682218
INFO:root:current train perplexity4.04486083984375
INFO:root:current mean train loss 1773.766776523707
INFO:root:current train perplexity4.045773983001709
INFO:root:current mean train loss 1773.7244605257301
INFO:root:current train perplexity4.047549724578857
INFO:root:current mean train loss 1773.3514039059903
INFO:root:current train perplexity4.04713773727417
INFO:root:current mean train loss 1773.3544775755922
INFO:root:current train perplexity4.045758247375488
INFO:root:current mean train loss 1772.6748853513332
INFO:root:current train perplexity4.047239780426025
INFO:root:current mean train loss 1772.959722277859
INFO:root:current train perplexity4.0487589836120605
INFO:root:current mean train loss 1773.714404899533
INFO:root:current train perplexity4.050013065338135


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:48<00:00, 288.94s/it]
INFO:root:final mean train loss: 1774.0968394623342
INFO:root:final train perplexity: 4.051792621612549
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.24s/it]
INFO:root:eval mean loss: 2894.0958864137574
INFO:root:eval perplexity: 10.749042510986328
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/66

 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [5:51:18<3:08:12, 332.14s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1744.3608340308779
INFO:root:current train perplexity3.9715211391448975
INFO:root:current mean train loss 1770.733250137203
INFO:root:current train perplexity4.00204610824585
INFO:root:current mean train loss 1760.784053750707
INFO:root:current train perplexity4.008304595947266
INFO:root:current mean train loss 1767.5831454743477
INFO:root:current train perplexity4.028430461883545
INFO:root:current mean train loss 1770.919308333952
INFO:root:current train perplexity4.037309646606445
INFO:root:current mean train loss 1771.0910290738213
INFO:root:current train perplexity4.040670871734619
INFO:root:current mean train loss 1771.1299333311317
INFO:root:current train perplexity4.039617538452148
INFO:root:current mean train loss 1769.7492205107924
INFO:root:current train perplexity4.030369281768799
INFO:root:current mean train loss 1770.9668046066154
INFO:root:current train perplexity4.033058166503906
INFO:root:current mean train loss 1771.537375252358
INFO:root:current train perplexity4.03386116027832
INFO:root:current mean train loss 1770.0602167710501
INFO:root:current train perplexity4.0333781242370605
INFO:root:current mean train loss 1769.8808105904327
INFO:root:current train perplexity4.033658027648926
INFO:root:current mean train loss 1769.9841812471207
INFO:root:current train perplexity4.033605098724365
INFO:root:current mean train loss 1768.4152812625675
INFO:root:current train perplexity4.035400867462158
INFO:root:current mean train loss 1769.307817087301
INFO:root:current train perplexity4.037575721740723
INFO:root:current mean train loss 1768.9317763389372
INFO:root:current train perplexity4.0381622314453125
INFO:root:current mean train loss 1769.8264194043752
INFO:root:current train perplexity4.038640975952148
INFO:root:current mean train loss 1770.0268024841344
INFO:root:current train perplexity4.040545463562012
INFO:root:current mean train loss 1770.87998390093
INFO:root:current train perplexity4.0401611328125
INFO:root:current mean train loss 1770.3632673971483
INFO:root:current train perplexity4.0394721031188965


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.27s/it]
INFO:root:final mean train loss: 1770.939894190955
INFO:root:final train perplexity: 4.041718006134033
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.66s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.66s/it]
INFO:root:eval mean loss: 2898.5261149821695
INFO:root:eval perplexity: 10.788190841674805
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/67

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [5:56:43<3:01:31, 330.03s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1753.2278056897615
INFO:root:current train perplexity4.001857280731201
INFO:root:current mean train loss 1753.2532720151155
INFO:root:current train perplexity3.99918270111084
INFO:root:current mean train loss 1755.2361342486213
INFO:root:current train perplexity3.9997458457946777
INFO:root:current mean train loss 1756.4798110871625
INFO:root:current train perplexity4.009387493133545
INFO:root:current mean train loss 1758.6469294578517
INFO:root:current train perplexity4.012138843536377
INFO:root:current mean train loss 1763.3583982106036
INFO:root:current train perplexity4.017268180847168
INFO:root:current mean train loss 1766.165970661797
INFO:root:current train perplexity4.018333435058594
INFO:root:current mean train loss 1763.5884009053714
INFO:root:current train perplexity4.017875671386719
INFO:root:current mean train loss 1764.7432010623322
INFO:root:current train perplexity4.018822193145752
INFO:root:current mean train loss 1767.0551194310951
INFO:root:current train perplexity4.0218963623046875
INFO:root:current mean train loss 1767.248996977172
INFO:root:current train perplexity4.0247979164123535
INFO:root:current mean train loss 1768.373427352503
INFO:root:current train perplexity4.02412748336792
INFO:root:current mean train loss 1768.5047836180458
INFO:root:current train perplexity4.025229454040527
INFO:root:current mean train loss 1767.686628812097
INFO:root:current train perplexity4.025920391082764
INFO:root:current mean train loss 1768.1503024253793
INFO:root:current train perplexity4.027995586395264
INFO:root:current mean train loss 1769.2103064329945
INFO:root:current train perplexity4.030025005340576
INFO:root:current mean train loss 1769.1584969731332
INFO:root:current train perplexity4.031059265136719
INFO:root:current mean train loss 1769.5236437833762
INFO:root:current train perplexity4.032904624938965
INFO:root:current mean train loss 1770.052598291175
INFO:root:current train perplexity4.034142971038818
INFO:root:current mean train loss 1768.9562025198134
INFO:root:current train perplexity4.033977508544922


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.35s/it]
INFO:root:final mean train loss: 1768.702744507513
INFO:root:final train perplexity: 4.034593105316162
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.77s/it]
INFO:root:eval mean loss: 2900.1373954520927
INFO:root:eval perplexity: 10.802464485168457
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/68

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [6:02:16<2:56:28, 330.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1748.3281938032671
INFO:root:current train perplexity3.9946820735931396
INFO:root:current mean train loss 1770.0652438256047
INFO:root:current train perplexity4.00949764251709
INFO:root:current mean train loss 1766.4405086741729
INFO:root:current train perplexity4.013786792755127
INFO:root:current mean train loss 1770.1860434088908
INFO:root:current train perplexity4.025895595550537
INFO:root:current mean train loss 1768.700288407881
INFO:root:current train perplexity4.027973175048828
INFO:root:current mean train loss 1765.771996850366
INFO:root:current train perplexity4.020031452178955
INFO:root:current mean train loss 1765.048717050334
INFO:root:current train perplexity4.018521785736084
INFO:root:current mean train loss 1764.325154083454
INFO:root:current train perplexity4.011356830596924
INFO:root:current mean train loss 1763.3016193233736
INFO:root:current train perplexity4.011194229125977
INFO:root:current mean train loss 1763.9708282630481
INFO:root:current train perplexity4.012902736663818
INFO:root:current mean train loss 1763.8853785221045
INFO:root:current train perplexity4.014309883117676
INFO:root:current mean train loss 1765.735570866308
INFO:root:current train perplexity4.018086910247803
INFO:root:current mean train loss 1766.0507041171252
INFO:root:current train perplexity4.01881217956543
INFO:root:current mean train loss 1765.7321393565499
INFO:root:current train perplexity4.019406318664551
INFO:root:current mean train loss 1766.585522041452
INFO:root:current train perplexity4.021562099456787
INFO:root:current mean train loss 1767.0533312242515
INFO:root:current train perplexity4.022159576416016
INFO:root:current mean train loss 1768.3023867512038
INFO:root:current train perplexity4.025710582733154
INFO:root:current mean train loss 1767.2863471137152
INFO:root:current train perplexity4.024761199951172
INFO:root:current mean train loss 1766.6599623852342
INFO:root:current train perplexity4.024195194244385
INFO:root:current mean train loss 1765.9405485109296
INFO:root:current train perplexity4.023561477661133


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.93s/it]
INFO:root:final mean train loss: 1765.4695757136342
INFO:root:final train perplexity: 4.024318218231201
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.37s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.37s/it]
INFO:root:eval mean loss: 2900.100925388279
INFO:root:eval perplexity: 10.802143096923828
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/69

 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [6:07:36<2:49:20, 327.74s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1747.1845109727647
INFO:root:current train perplexity3.999056816101074
INFO:root:current mean train loss 1751.7826999398164
INFO:root:current train perplexity4.002394199371338
INFO:root:current mean train loss 1752.1960148530848
INFO:root:current train perplexity4.004236221313477
INFO:root:current mean train loss 1752.2452011928763
INFO:root:current train perplexity4.001070499420166
INFO:root:current mean train loss 1755.6554459394035
INFO:root:current train perplexity3.998762369155884
INFO:root:current mean train loss 1758.1829498931245
INFO:root:current train perplexity4.007087707519531
INFO:root:current mean train loss 1759.2256912958055
INFO:root:current train perplexity4.010612964630127
INFO:root:current mean train loss 1758.0939214044283
INFO:root:current train perplexity4.007731914520264
INFO:root:current mean train loss 1756.558070751505
INFO:root:current train perplexity4.007920742034912
INFO:root:current mean train loss 1757.1684399514531
INFO:root:current train perplexity4.008896827697754
INFO:root:current mean train loss 1757.1986974459976
INFO:root:current train perplexity4.009173393249512
INFO:root:current mean train loss 1758.4885917377146
INFO:root:current train perplexity4.0103349685668945
INFO:root:current mean train loss 1758.6522526771018
INFO:root:current train perplexity4.009493350982666
INFO:root:current mean train loss 1758.095977605258
INFO:root:current train perplexity4.010181903839111
INFO:root:current mean train loss 1759.0763206481934
INFO:root:current train perplexity4.011831283569336
INFO:root:current mean train loss 1759.04326577223
INFO:root:current train perplexity4.011630058288574
INFO:root:current mean train loss 1760.7768940172698
INFO:root:current train perplexity4.012986183166504
INFO:root:current mean train loss 1761.4994935322022
INFO:root:current train perplexity4.01340913772583
INFO:root:current mean train loss 1762.6240353706555
INFO:root:current train perplexity4.01430082321167
INFO:root:current mean train loss 1762.9726352652963
INFO:root:current train perplexity4.0152387619018555


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.38s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.38s/it]
INFO:root:final mean train loss: 1762.801585510531
INFO:root:final train perplexity: 4.015859603881836
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.90s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.90s/it]
INFO:root:eval mean loss: 2902.9359948327233
INFO:root:eval perplexity: 10.827301025390625
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/70

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [6:12:56<2:42:44, 325.49s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1751.1140123002986
INFO:root:current train perplexity4.02827787399292
INFO:root:current mean train loss 1744.940445188492
INFO:root:current train perplexity4.0020270347595215
INFO:root:current mean train loss 1751.0783138077152
INFO:root:current train perplexity4.002071380615234
INFO:root:current mean train loss 1749.9112743387493
INFO:root:current train perplexity3.998198986053467
INFO:root:current mean train loss 1754.7904527036203
INFO:root:current train perplexity4.004565238952637
INFO:root:current mean train loss 1754.6387193352743
INFO:root:current train perplexity4.0053558349609375
INFO:root:current mean train loss 1755.1244055937614
INFO:root:current train perplexity4.002465724945068
INFO:root:current mean train loss 1753.9000664966036
INFO:root:current train perplexity3.9962894916534424
INFO:root:current mean train loss 1755.983607288957
INFO:root:current train perplexity3.9997458457946777
INFO:root:current mean train loss 1758.1267672424008
INFO:root:current train perplexity3.999469757080078
INFO:root:current mean train loss 1756.3085781689408
INFO:root:current train perplexity3.9985125064849854
INFO:root:current mean train loss 1755.8360890355602
INFO:root:current train perplexity4.000126838684082
INFO:root:current mean train loss 1756.1877234956846
INFO:root:current train perplexity4.000821590423584
INFO:root:current mean train loss 1756.2231593835775
INFO:root:current train perplexity4.001755714416504
INFO:root:current mean train loss 1757.0246362321084
INFO:root:current train perplexity4.004096508026123
INFO:root:current mean train loss 1756.9317897366907
INFO:root:current train perplexity4.0046586990356445
INFO:root:current mean train loss 1758.1786576717686
INFO:root:current train perplexity4.004960536956787
INFO:root:current mean train loss 1759.1106950515739
INFO:root:current train perplexity4.004708766937256
INFO:root:current mean train loss 1760.274111116166
INFO:root:current train perplexity4.005876064300537


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.35s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.35s/it]
INFO:root:final mean train loss: 1760.4362702477897
INFO:root:final train perplexity: 4.008375644683838
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.62s/it]
INFO:root:eval mean loss: 2902.9215304171357
INFO:root:eval perplexity: 10.827171325683594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/71

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [6:18:17<2:36:41, 324.18s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1800.1166381835938
INFO:root:current train perplexity4.012185573577881
INFO:root:current mean train loss 1748.750202682783
INFO:root:current train perplexity3.9505550861358643
INFO:root:current mean train loss 1743.2719051027761
INFO:root:current train perplexity3.9534499645233154
INFO:root:current mean train loss 1744.3401652816074
INFO:root:current train perplexity3.95430588722229
INFO:root:current mean train loss 1747.8725447631234
INFO:root:current train perplexity3.969196319580078
INFO:root:current mean train loss 1747.906807760005
INFO:root:current train perplexity3.9717395305633545
INFO:root:current mean train loss 1750.370910443095
INFO:root:current train perplexity3.978410005569458
INFO:root:current mean train loss 1752.5360703941108
INFO:root:current train perplexity3.983017921447754
INFO:root:current mean train loss 1753.7699812138937
INFO:root:current train perplexity3.9836294651031494
INFO:root:current mean train loss 1753.372146438026
INFO:root:current train perplexity3.9824001789093018
INFO:root:current mean train loss 1754.8323950340923
INFO:root:current train perplexity3.9886488914489746
INFO:root:current mean train loss 1750.431640625
INFO:root:current train perplexity3.9835078716278076
INFO:root:current mean train loss 1752.3720047224813
INFO:root:current train perplexity3.9851090908050537
INFO:root:current mean train loss 1754.3620348429424
INFO:root:current train perplexity3.987729787826538
INFO:root:current mean train loss 1755.258427105791
INFO:root:current train perplexity3.992063283920288
INFO:root:current mean train loss 1755.8204854734706
INFO:root:current train perplexity3.9918930530548096
INFO:root:current mean train loss 1755.7895513133124
INFO:root:current train perplexity3.994530200958252
INFO:root:current mean train loss 1754.8664709630075
INFO:root:current train perplexity3.9936411380767822
INFO:root:current mean train loss 1755.757348957252
INFO:root:current train perplexity3.995997905731201
INFO:root:current mean train loss 1757.7959050341642
INFO:root:current train perplexity3.997966766357422


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:49<00:00, 289.64s/it]
INFO:root:final mean train loss: 1757.7271700814345
INFO:root:final train perplexity: 3.9998207092285156
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.04s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.04s/it]
INFO:root:eval mean loss: 2904.7941535285286
INFO:root:eval perplexity: 10.84382152557373
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/72

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [6:24:00<2:33:48, 329.58s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1780.863037109375
INFO:root:current train perplexity4.000241279602051
INFO:root:current mean train loss 1764.2847463716337
INFO:root:current train perplexity3.991995334625244
INFO:root:current mean train loss 1755.0802226387332
INFO:root:current train perplexity3.978421449661255
INFO:root:current mean train loss 1753.739133096701
INFO:root:current train perplexity3.9757120609283447
INFO:root:current mean train loss 1754.1499141756242
INFO:root:current train perplexity3.980001449584961
INFO:root:current mean train loss 1755.662103539899
INFO:root:current train perplexity3.9826483726501465
INFO:root:current mean train loss 1754.8615720696855
INFO:root:current train perplexity3.9810688495635986
INFO:root:current mean train loss 1753.6052058682897
INFO:root:current train perplexity3.9857418537139893
INFO:root:current mean train loss 1753.5534703566411
INFO:root:current train perplexity3.9860787391662598
INFO:root:current mean train loss 1754.8172333656385
INFO:root:current train perplexity3.989577054977417
INFO:root:current mean train loss 1755.9329279119318
INFO:root:current train perplexity3.989823341369629
INFO:root:current mean train loss 1755.6800756683758
INFO:root:current train perplexity3.9897758960723877
INFO:root:current mean train loss 1755.6242380337158
INFO:root:current train perplexity3.991276264190674
INFO:root:current mean train loss 1755.1441505530163
INFO:root:current train perplexity3.9909112453460693
INFO:root:current mean train loss 1754.994510867775
INFO:root:current train perplexity3.991377592086792
INFO:root:current mean train loss 1755.9021210097515
INFO:root:current train perplexity3.993558406829834
INFO:root:current mean train loss 1756.5403014798262
INFO:root:current train perplexity3.9938406944274902
INFO:root:current mean train loss 1756.4210454461468
INFO:root:current train perplexity3.993337869644165
INFO:root:current mean train loss 1756.4300078424985
INFO:root:current train perplexity3.991591215133667
INFO:root:current mean train loss 1756.097545098093
INFO:root:current train perplexity3.9924073219299316


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.98s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.98s/it]
INFO:root:final mean train loss: 1755.7766145291619
INFO:root:final train perplexity: 3.9936716556549072
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.12s/it]
INFO:root:eval mean loss: 2907.140156513936
INFO:root:eval perplexity: 10.864715576171875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/73

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [6:29:27<2:27:59, 328.88s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1738.5642974853515
INFO:root:current train perplexity4.001920223236084
INFO:root:current mean train loss 1743.471111188616
INFO:root:current train perplexity3.9659290313720703
INFO:root:current mean train loss 1740.7800135294597
INFO:root:current train perplexity3.963317394256592
INFO:root:current mean train loss 1745.0434555951288
INFO:root:current train perplexity3.971323251724243
INFO:root:current mean train loss 1749.915751509233
INFO:root:current train perplexity3.976240873336792
INFO:root:current mean train loss 1750.382329191985
INFO:root:current train perplexity3.981813907623291
INFO:root:current mean train loss 1750.8296438217162
INFO:root:current train perplexity3.976591110229492
INFO:root:current mean train loss 1750.460631829339
INFO:root:current train perplexity3.9766249656677246
INFO:root:current mean train loss 1750.9266713460286
INFO:root:current train perplexity3.977386236190796
INFO:root:current mean train loss 1751.0872713129572
INFO:root:current train perplexity3.9807465076446533
INFO:root:current mean train loss 1751.6297798743615
INFO:root:current train perplexity3.9824438095092773
INFO:root:current mean train loss 1751.9838922868696
INFO:root:current train perplexity3.9863429069519043
INFO:root:current mean train loss 1752.6726393176664
INFO:root:current train perplexity3.9868128299713135
INFO:root:current mean train loss 1753.0580186530726
INFO:root:current train perplexity3.9866113662719727
INFO:root:current mean train loss 1752.0471481323243
INFO:root:current train perplexity3.983242988586426
INFO:root:current mean train loss 1751.74865350104
INFO:root:current train perplexity3.9832258224487305
INFO:root:current mean train loss 1752.2906417474514
INFO:root:current train perplexity3.9831314086914062
INFO:root:current mean train loss 1752.507150233477
INFO:root:current train perplexity3.983042001724243
INFO:root:current mean train loss 1752.970532292905
INFO:root:current train perplexity3.984339475631714
INFO:root:current mean train loss 1753.196417299251
INFO:root:current train perplexity3.983905792236328


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.08s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.08s/it]
INFO:root:final mean train loss: 1752.5359396730116
INFO:root:final train perplexity: 3.98347806930542
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.97s/it]
INFO:root:eval mean loss: 2909.1985193201012
INFO:root:eval perplexity: 10.883084297180176
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/74

 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [6:34:59<2:22:53, 329.73s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1735.5605447334156
INFO:root:current train perplexity3.930464506149292
INFO:root:current mean train loss 1756.413058724373
INFO:root:current train perplexity3.9810569286346436
INFO:root:current mean train loss 1753.0900821908438
INFO:root:current train perplexity3.964639663696289
INFO:root:current mean train loss 1749.7821910014006
INFO:root:current train perplexity3.965405225753784
INFO:root:current mean train loss 1744.9610066820808
INFO:root:current train perplexity3.9582831859588623
INFO:root:current mean train loss 1748.0744493029063
INFO:root:current train perplexity3.9687047004699707
INFO:root:current mean train loss 1748.722233370196
INFO:root:current train perplexity3.9652507305145264
INFO:root:current mean train loss 1747.0241007433228
INFO:root:current train perplexity3.9638314247131348
INFO:root:current mean train loss 1747.4072882386322
INFO:root:current train perplexity3.9673731327056885
INFO:root:current mean train loss 1747.0240532088803
INFO:root:current train perplexity3.9666244983673096
INFO:root:current mean train loss 1746.0341689471602
INFO:root:current train perplexity3.962960720062256
INFO:root:current mean train loss 1748.2364039837335
INFO:root:current train perplexity3.964611291885376
INFO:root:current mean train loss 1746.8172161675866
INFO:root:current train perplexity3.96366286277771
INFO:root:current mean train loss 1747.9867725976706
INFO:root:current train perplexity3.9683878421783447
INFO:root:current mean train loss 1748.5843182461017
INFO:root:current train perplexity3.970668077468872
INFO:root:current mean train loss 1748.6972724458844
INFO:root:current train perplexity3.971911907196045
INFO:root:current mean train loss 1749.3720152814055
INFO:root:current train perplexity3.9736485481262207
INFO:root:current mean train loss 1749.3874748633814
INFO:root:current train perplexity3.9734978675842285
INFO:root:current mean train loss 1751.166254506807
INFO:root:current train perplexity3.9790680408477783
INFO:root:current mean train loss 1750.793846259022
INFO:root:current train perplexity3.9776225090026855


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.85s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.85s/it]
INFO:root:final mean train loss: 1750.626448038306
INFO:root:final train perplexity: 3.9774839878082275
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.76s/it]
INFO:root:eval mean loss: 2907.5700624941346
INFO:root:eval perplexity: 10.868553161621094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/75

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [6:40:20<2:16:23, 327.34s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1752.522640743771
INFO:root:current train perplexity3.986668348312378
INFO:root:current mean train loss 1739.4578653971355
INFO:root:current train perplexity3.9558796882629395
INFO:root:current mean train loss 1745.461938565665
INFO:root:current train perplexity3.956108570098877
INFO:root:current mean train loss 1745.35447064568
INFO:root:current train perplexity3.9522206783294678
INFO:root:current mean train loss 1747.6443365555776
INFO:root:current train perplexity3.9601187705993652
INFO:root:current mean train loss 1745.5747259585285
INFO:root:current train perplexity3.96185302734375
INFO:root:current mean train loss 1744.7176928421156
INFO:root:current train perplexity3.9593677520751953
INFO:root:current mean train loss 1746.6608255864421
INFO:root:current train perplexity3.9641075134277344
INFO:root:current mean train loss 1746.8463997917263
INFO:root:current train perplexity3.9632229804992676
INFO:root:current mean train loss 1748.2852127733172
INFO:root:current train perplexity3.965569257736206
INFO:root:current mean train loss 1748.2912491952907
INFO:root:current train perplexity3.9640114307403564
INFO:root:current mean train loss 1748.984551346891
INFO:root:current train perplexity3.9645724296569824
INFO:root:current mean train loss 1747.7233214086416
INFO:root:current train perplexity3.9642038345336914
INFO:root:current mean train loss 1749.9648371756164
INFO:root:current train perplexity3.970384120941162
INFO:root:current mean train loss 1749.3581478372519
INFO:root:current train perplexity3.9707159996032715
INFO:root:current mean train loss 1748.9590810075345
INFO:root:current train perplexity3.9710869789123535
INFO:root:current mean train loss 1749.2605137249618
INFO:root:current train perplexity3.9721457958221436
INFO:root:current mean train loss 1748.7982891302097
INFO:root:current train perplexity3.971151113510132
INFO:root:current mean train loss 1749.388059048159
INFO:root:current train perplexity3.9722721576690674
INFO:root:current mean train loss 1749.5858097404937
INFO:root:current train perplexity3.9731013774871826


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.26s/it]
INFO:root:final mean train loss: 1749.3216155067093
INFO:root:final train perplexity: 3.9733922481536865
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.27s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.27s/it]
INFO:root:eval mean loss: 2909.602761941629
INFO:root:eval perplexity: 10.886691093444824
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/76

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [6:45:45<2:10:36, 326.50s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1744.4046188186812
INFO:root:current train perplexity3.9765987396240234
INFO:root:current mean train loss 1748.810723269797
INFO:root:current train perplexity3.9819087982177734
INFO:root:current mean train loss 1745.3802095917902
INFO:root:current train perplexity3.9696426391601562
INFO:root:current mean train loss 1744.3634595163644
INFO:root:current train perplexity3.9622137546539307
INFO:root:current mean train loss 1745.4629393536786
INFO:root:current train perplexity3.964895248413086
INFO:root:current mean train loss 1743.4221672664842
INFO:root:current train perplexity3.954688787460327
INFO:root:current mean train loss 1743.439661580816
INFO:root:current train perplexity3.955019235610962
INFO:root:current mean train loss 1745.3533025035063
INFO:root:current train perplexity3.955976963043213
INFO:root:current mean train loss 1745.4196336191778
INFO:root:current train perplexity3.9583351612091064
INFO:root:current mean train loss 1745.6737420229329
INFO:root:current train perplexity3.96073055267334
INFO:root:current mean train loss 1746.6899608748424
INFO:root:current train perplexity3.9613561630249023
INFO:root:current mean train loss 1747.5238275920315
INFO:root:current train perplexity3.963059425354004
INFO:root:current mean train loss 1746.6748895032013
INFO:root:current train perplexity3.962571859359741
INFO:root:current mean train loss 1746.8814064535968
INFO:root:current train perplexity3.9637463092803955
INFO:root:current mean train loss 1747.0118882238744
INFO:root:current train perplexity3.9628841876983643
INFO:root:current mean train loss 1747.2926626918752
INFO:root:current train perplexity3.96354079246521
INFO:root:current mean train loss 1746.678496321865
INFO:root:current train perplexity3.9616825580596924
INFO:root:current mean train loss 1747.0958898087442
INFO:root:current train perplexity3.9634926319122314
INFO:root:current mean train loss 1746.719273075485
INFO:root:current train perplexity3.963646650314331


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.76s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.76s/it]
INFO:root:final mean train loss: 1746.7137672782126
INFO:root:final train perplexity: 3.9652295112609863
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.03s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.03s/it]
INFO:root:eval mean loss: 2911.644191799221
INFO:root:eval perplexity: 10.904945373535156
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/77

 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [6:51:10<2:04:59, 326.06s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1695.2114715576172
INFO:root:current train perplexity3.835139751434326
INFO:root:current mean train loss 1733.4401279025608
INFO:root:current train perplexity3.937749147415161
INFO:root:current mean train loss 1740.5354021512544
INFO:root:current train perplexity3.9371769428253174
INFO:root:current mean train loss 1741.713620668882
INFO:root:current train perplexity3.943007230758667
INFO:root:current mean train loss 1743.4427343630323
INFO:root:current train perplexity3.9431164264678955
INFO:root:current mean train loss 1741.4315752645177
INFO:root:current train perplexity3.941305637359619
INFO:root:current mean train loss 1741.7763324536775
INFO:root:current train perplexity3.9445464611053467
INFO:root:current mean train loss 1740.6175238830222
INFO:root:current train perplexity3.945908546447754
INFO:root:current mean train loss 1744.214089875174
INFO:root:current train perplexity3.9516561031341553
INFO:root:current mean train loss 1744.9983141390762
INFO:root:current train perplexity3.9548192024230957
INFO:root:current mean train loss 1745.2581360832094
INFO:root:current train perplexity3.953181266784668
INFO:root:current mean train loss 1743.6234646463222
INFO:root:current train perplexity3.952394485473633
INFO:root:current mean train loss 1742.7167624164101
INFO:root:current train perplexity3.950352430343628
INFO:root:current mean train loss 1742.9882443862589
INFO:root:current train perplexity3.9512081146240234
INFO:root:current mean train loss 1743.8017269481313
INFO:root:current train perplexity3.9545953273773193
INFO:root:current mean train loss 1743.8578802053112
INFO:root:current train perplexity3.9545464515686035
INFO:root:current mean train loss 1743.2865930813462
INFO:root:current train perplexity3.9545586109161377
INFO:root:current mean train loss 1744.7413267184756
INFO:root:current train perplexity3.9561004638671875
INFO:root:current mean train loss 1744.5841703836898
INFO:root:current train perplexity3.956465005874634
INFO:root:current mean train loss 1743.9725941911934
INFO:root:current train perplexity3.9559640884399414


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.80s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.80s/it]
INFO:root:final mean train loss: 1744.4398949604351
INFO:root:final train perplexity: 3.9581241607666016
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.12s/it]
INFO:root:eval mean loss: 2912.782417182808
INFO:root:eval perplexity: 10.91513729095459
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/78

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [6:56:45<2:00:35, 328.89s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1741.65705078125
INFO:root:current train perplexity3.9672279357910156
INFO:root:current mean train loss 1727.654396484375
INFO:root:current train perplexity3.919548511505127
INFO:root:current mean train loss 1739.1031987847223
INFO:root:current train perplexity3.954838752746582
INFO:root:current mean train loss 1735.5186114032451
INFO:root:current train perplexity3.951970338821411
INFO:root:current mean train loss 1738.849276194853
INFO:root:current train perplexity3.9504239559173584
INFO:root:current mean train loss 1738.0044931175596
INFO:root:current train perplexity3.9468672275543213
INFO:root:current mean train loss 1739.3907732421876
INFO:root:current train perplexity3.9455864429473877
INFO:root:current mean train loss 1739.582178912985
INFO:root:current train perplexity3.9432756900787354
INFO:root:current mean train loss 1739.4942101680872
INFO:root:current train perplexity3.946359634399414
INFO:root:current mean train loss 1737.8988737858954
INFO:root:current train perplexity3.9446122646331787
INFO:root:current mean train loss 1737.5045934165396
INFO:root:current train perplexity3.944992780685425
INFO:root:current mean train loss 1739.3045868055556
INFO:root:current train perplexity3.9466283321380615
INFO:root:current mean train loss 1739.9631767179528
INFO:root:current train perplexity3.948134660720825
INFO:root:current mean train loss 1741.158176407724
INFO:root:current train perplexity3.9490928649902344
INFO:root:current mean train loss 1740.3427652994792
INFO:root:current train perplexity3.9467313289642334
INFO:root:current mean train loss 1740.6304999679815
INFO:root:current train perplexity3.947321891784668
INFO:root:current mean train loss 1740.848016376202
INFO:root:current train perplexity3.9462270736694336
INFO:root:current mean train loss 1741.9705970476675
INFO:root:current train perplexity3.947444200515747
INFO:root:current mean train loss 1741.9225816031678
INFO:root:current train perplexity3.9510321617126465
INFO:root:current mean train loss 1742.5320620053774
INFO:root:current train perplexity3.9515600204467773


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.42s/it]
INFO:root:final mean train loss: 1742.3743221188697
INFO:root:final train perplexity: 3.951681613922119
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.97s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.97s/it]
INFO:root:eval mean loss: 2912.9514438755164
INFO:root:eval perplexity: 10.916648864746094
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/79

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [7:02:23<1:56:02, 331.52s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1741.2302943638392
INFO:root:current train perplexity3.9261646270751953
INFO:root:current mean train loss 1735.56601596886
INFO:root:current train perplexity3.9312143325805664
INFO:root:current mean train loss 1736.9947111271629
INFO:root:current train perplexity3.936507225036621
INFO:root:current mean train loss 1743.6589159156845
INFO:root:current train perplexity3.9470276832580566
INFO:root:current mean train loss 1741.5321779553167
INFO:root:current train perplexity3.9370839595794678
INFO:root:current mean train loss 1742.91648228494
INFO:root:current train perplexity3.9396440982818604
INFO:root:current mean train loss 1742.6707014517622
INFO:root:current train perplexity3.937467575073242
INFO:root:current mean train loss 1742.0111085629528
INFO:root:current train perplexity3.9409749507904053
INFO:root:current mean train loss 1742.9454038352694
INFO:root:current train perplexity3.947094202041626
INFO:root:current mean train loss 1743.8772511735338
INFO:root:current train perplexity3.950043201446533
INFO:root:current mean train loss 1742.2388940617127
INFO:root:current train perplexity3.9482178688049316
INFO:root:current mean train loss 1740.778677972102
INFO:root:current train perplexity3.9451725482940674
INFO:root:current mean train loss 1741.644377630114
INFO:root:current train perplexity3.945986270904541
INFO:root:current mean train loss 1741.3028783670304
INFO:root:current train perplexity3.94663405418396
INFO:root:current mean train loss 1741.3236608835928
INFO:root:current train perplexity3.945589065551758
INFO:root:current mean train loss 1741.2389921393685
INFO:root:current train perplexity3.9453046321868896
INFO:root:current mean train loss 1742.295897322363
INFO:root:current train perplexity3.94775390625
INFO:root:current mean train loss 1741.8368104218616
INFO:root:current train perplexity3.9478907585144043
INFO:root:current mean train loss 1740.514621200313
INFO:root:current train perplexity3.9469425678253174
INFO:root:current mean train loss 1740.5823765920684
INFO:root:current train perplexity3.9463586807250977


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.18s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.18s/it]
INFO:root:final mean train loss: 1740.2525480254035
INFO:root:final train perplexity: 3.9450745582580566
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.69s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.69s/it]
INFO:root:eval mean loss: 2914.1317655546172
INFO:root:eval perplexity: 10.927228927612305
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/80

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [7:07:54<1:50:24, 331.21s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1716.5326713949946
INFO:root:current train perplexity3.9314658641815186
INFO:root:current mean train loss 1738.9266058004127
INFO:root:current train perplexity3.9463422298431396
INFO:root:current mean train loss 1731.5408303986185
INFO:root:current train perplexity3.9263949394226074
INFO:root:current mean train loss 1730.8415194115598
INFO:root:current train perplexity3.9290425777435303
INFO:root:current mean train loss 1731.9969259025224
INFO:root:current train perplexity3.92722487449646
INFO:root:current mean train loss 1732.341607327538
INFO:root:current train perplexity3.9226784706115723
INFO:root:current mean train loss 1733.5677466153736
INFO:root:current train perplexity3.9220359325408936
INFO:root:current mean train loss 1735.0515654592803
INFO:root:current train perplexity3.9271316528320312
INFO:root:current mean train loss 1735.8598985239014
INFO:root:current train perplexity3.931417226791382
INFO:root:current mean train loss 1735.1070986878015
INFO:root:current train perplexity3.931980609893799
INFO:root:current mean train loss 1734.8606472285544
INFO:root:current train perplexity3.9321961402893066
INFO:root:current mean train loss 1736.5322603714476
INFO:root:current train perplexity3.933539390563965
INFO:root:current mean train loss 1738.0683282514335
INFO:root:current train perplexity3.937427520751953
INFO:root:current mean train loss 1738.4182129804487
INFO:root:current train perplexity3.940267562866211
INFO:root:current mean train loss 1738.7432815311215
INFO:root:current train perplexity3.9415767192840576
INFO:root:current mean train loss 1738.9925472120049
INFO:root:current train perplexity3.9410834312438965
INFO:root:current mean train loss 1739.2026349528142
INFO:root:current train perplexity3.9423506259918213
INFO:root:current mean train loss 1739.1348605608655
INFO:root:current train perplexity3.9420039653778076
INFO:root:current mean train loss 1739.2255464074688
INFO:root:current train perplexity3.9414987564086914
INFO:root:current mean train loss 1739.4823449812964
INFO:root:current train perplexity3.942255735397339


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.62s/it]
INFO:root:final mean train loss: 1739.4510767057095
INFO:root:final train perplexity: 3.9425814151763916
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.93s/it]
INFO:root:eval mean loss: 2914.3293838271866
INFO:root:eval perplexity: 10.929000854492188
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/81

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [7:13:18<1:44:12, 329.05s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1739.8723449707031
INFO:root:current train perplexity3.971473455429077
INFO:root:current mean train loss 1744.875717163086
INFO:root:current train perplexity3.9585652351379395
INFO:root:current mean train loss 1744.0504747473676
INFO:root:current train perplexity3.946455240249634
INFO:root:current mean train loss 1737.7231419340094
INFO:root:current train perplexity3.932669162750244
INFO:root:current mean train loss 1735.6957466702502
INFO:root:current train perplexity3.9297218322753906
INFO:root:current mean train loss 1736.092258029514
INFO:root:current train perplexity3.9292619228363037
INFO:root:current mean train loss 1736.003662109375
INFO:root:current train perplexity3.9288458824157715
INFO:root:current mean train loss 1735.1783779183613
INFO:root:current train perplexity3.9304795265197754
INFO:root:current mean train loss 1737.0827415152771
INFO:root:current train perplexity3.9275825023651123
INFO:root:current mean train loss 1737.5031929641473
INFO:root:current train perplexity3.9290671348571777
INFO:root:current mean train loss 1735.3210492329083
INFO:root:current train perplexity3.9273784160614014
INFO:root:current mean train loss 1735.2409379401174
INFO:root:current train perplexity3.9299261569976807
INFO:root:current mean train loss 1736.8894737506735
INFO:root:current train perplexity3.9322781562805176
INFO:root:current mean train loss 1737.6845848615778
INFO:root:current train perplexity3.932748317718506
INFO:root:current mean train loss 1737.68501418199
INFO:root:current train perplexity3.9304986000061035
INFO:root:current mean train loss 1737.8212277949765
INFO:root:current train perplexity3.9310460090637207
INFO:root:current mean train loss 1738.757319411685
INFO:root:current train perplexity3.9327147006988525
INFO:root:current mean train loss 1737.795541986689
INFO:root:current train perplexity3.9326653480529785
INFO:root:current mean train loss 1737.260994331669
INFO:root:current train perplexity3.933781862258911
INFO:root:current mean train loss 1737.3065894740796
INFO:root:current train perplexity3.9342267513275146


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.61s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.61s/it]
INFO:root:final mean train loss: 1736.6212150816116
INFO:root:final train perplexity: 3.9337925910949707
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.75s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.75s/it]
INFO:root:eval mean loss: 2915.674091327656
INFO:root:eval perplexity: 10.94106674194336
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/82

 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [7:18:49<1:38:55, 329.76s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1736.3724443989415
INFO:root:current train perplexity3.928027868270874
INFO:root:current mean train loss 1746.5271559008663
INFO:root:current train perplexity3.937314987182617
INFO:root:current mean train loss 1733.7423503992907
INFO:root:current train perplexity3.9276204109191895
INFO:root:current mean train loss 1733.9157366958889
INFO:root:current train perplexity3.9282703399658203
INFO:root:current mean train loss 1732.9997746775164
INFO:root:current train perplexity3.9238498210906982
INFO:root:current mean train loss 1731.3101627549272
INFO:root:current train perplexity3.9242727756500244
INFO:root:current mean train loss 1731.7778581011003
INFO:root:current train perplexity3.9268152713775635
INFO:root:current mean train loss 1731.4840000147778
INFO:root:current train perplexity3.9278509616851807
INFO:root:current mean train loss 1732.4969157083303
INFO:root:current train perplexity3.932657480239868
INFO:root:current mean train loss 1734.3973329665077
INFO:root:current train perplexity3.934920072555542
INFO:root:current mean train loss 1734.1595769465134
INFO:root:current train perplexity3.9336490631103516
INFO:root:current mean train loss 1733.215020460335
INFO:root:current train perplexity3.930922746658325
INFO:root:current mean train loss 1733.6530309501584
INFO:root:current train perplexity3.931602716445923
INFO:root:current mean train loss 1734.6746439718122
INFO:root:current train perplexity3.931360960006714
INFO:root:current mean train loss 1734.8668683838382
INFO:root:current train perplexity3.931124210357666
INFO:root:current mean train loss 1735.7406136895304
INFO:root:current train perplexity3.9320223331451416
INFO:root:current mean train loss 1736.096242671455
INFO:root:current train perplexity3.9317123889923096
INFO:root:current mean train loss 1736.0402603277066
INFO:root:current train perplexity3.9329264163970947
INFO:root:current mean train loss 1736.4648327230464
INFO:root:current train perplexity3.9315876960754395


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.74s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.74s/it]
INFO:root:final mean train loss: 1735.4406246429612
INFO:root:final train perplexity: 3.930131435394287
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.72s/it]
INFO:root:eval mean loss: 2915.425810576201
INFO:root:eval perplexity: 10.938838958740234
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/83

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [7:24:13<1:32:54, 327.93s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1765.6931640625
INFO:root:current train perplexity3.957791566848755
INFO:root:current mean train loss 1735.5151311700995
INFO:root:current train perplexity3.91058611869812
INFO:root:current mean train loss 1737.2219052269345
INFO:root:current train perplexity3.910928726196289
INFO:root:current mean train loss 1735.5275422127015
INFO:root:current train perplexity3.915656328201294
INFO:root:current mean train loss 1730.932269138243
INFO:root:current train perplexity3.9146206378936768
INFO:root:current mean train loss 1729.939446183747
INFO:root:current train perplexity3.920983076095581
INFO:root:current mean train loss 1731.195637687308
INFO:root:current train perplexity3.9260635375976562
INFO:root:current mean train loss 1730.32002004704
INFO:root:current train perplexity3.9250259399414062
INFO:root:current mean train loss 1731.3664073049285
INFO:root:current train perplexity3.9251270294189453
INFO:root:current mean train loss 1732.0293953361092
INFO:root:current train perplexity3.9238498210906982
INFO:root:current mean train loss 1731.2958707601717
INFO:root:current train perplexity3.92014479637146
INFO:root:current mean train loss 1732.0471587309967
INFO:root:current train perplexity3.923604726791382
INFO:root:current mean train loss 1732.7755682827028
INFO:root:current train perplexity3.924962043762207
INFO:root:current mean train loss 1733.884259732079
INFO:root:current train perplexity3.9258341789245605
INFO:root:current mean train loss 1733.475031513187
INFO:root:current train perplexity3.926516532897949
INFO:root:current mean train loss 1734.3518049429583
INFO:root:current train perplexity3.926933765411377
INFO:root:current mean train loss 1734.375450295395
INFO:root:current train perplexity3.9259212017059326
INFO:root:current mean train loss 1734.1769647609422
INFO:root:current train perplexity3.9252192974090576
INFO:root:current mean train loss 1733.1518428570657
INFO:root:current train perplexity3.9254274368286133
INFO:root:current mean train loss 1733.8486990883712
INFO:root:current train perplexity3.9247658252716064


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.28s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.28s/it]
INFO:root:final mean train loss: 1733.5839860370768
INFO:root:final train perplexity: 3.9243807792663574
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.93s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.93s/it]
INFO:root:eval mean loss: 2917.9745961782096
INFO:root:eval perplexity: 10.961740493774414
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/84

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [7:29:32<1:26:47, 325.46s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1710.1607078269676
INFO:root:current train perplexity3.891942024230957
INFO:root:current mean train loss 1717.2703876645546
INFO:root:current train perplexity3.9044010639190674
INFO:root:current mean train loss 1722.1855560168297
INFO:root:current train perplexity3.9076271057128906
INFO:root:current mean train loss 1725.6597747336104
INFO:root:current train perplexity3.90547513961792
INFO:root:current mean train loss 1726.2513910869804
INFO:root:current train perplexity3.902052402496338
INFO:root:current mean train loss 1725.1950095247273
INFO:root:current train perplexity3.9057819843292236
INFO:root:current mean train loss 1725.8831717021158
INFO:root:current train perplexity3.910710096359253
INFO:root:current mean train loss 1725.9435576762917
INFO:root:current train perplexity3.9102425575256348
INFO:root:current mean train loss 1726.5542628370144
INFO:root:current train perplexity3.911454677581787
INFO:root:current mean train loss 1728.27080963036
INFO:root:current train perplexity3.912773609161377
INFO:root:current mean train loss 1728.8625695099502
INFO:root:current train perplexity3.9132442474365234
INFO:root:current mean train loss 1730.3478974661366
INFO:root:current train perplexity3.915353298187256
INFO:root:current mean train loss 1730.9596127336747
INFO:root:current train perplexity3.9154326915740967
INFO:root:current mean train loss 1731.3630515517557
INFO:root:current train perplexity3.9167234897613525
INFO:root:current mean train loss 1732.588853928286
INFO:root:current train perplexity3.918192148208618
INFO:root:current mean train loss 1733.1943675143
INFO:root:current train perplexity3.918534755706787
INFO:root:current mean train loss 1733.4965045274805
INFO:root:current train perplexity3.9193129539489746
INFO:root:current mean train loss 1733.423017527233
INFO:root:current train perplexity3.920426845550537
INFO:root:current mean train loss 1732.5966412022783
INFO:root:current train perplexity3.919534921646118
INFO:root:current mean train loss 1732.3824768858249
INFO:root:current train perplexity3.919595241546631


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.81s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.81s/it]
INFO:root:final mean train loss: 1732.1661474523194
INFO:root:final train perplexity: 3.919995069503784
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.20s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.20s/it]
INFO:root:eval mean loss: 2917.1618058488175
INFO:root:eval perplexity: 10.95443344116211
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/85

 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [7:34:55<1:21:08, 324.57s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1700.1214682839134
INFO:root:current train perplexity3.8929147720336914
INFO:root:current mean train loss 1703.8353093465169
INFO:root:current train perplexity3.9037630558013916
INFO:root:current mean train loss 1720.1524418064805
INFO:root:current train perplexity3.9176037311553955
INFO:root:current mean train loss 1722.2652832740962
INFO:root:current train perplexity3.90826678276062
INFO:root:current mean train loss 1725.6446439725858
INFO:root:current train perplexity3.9128551483154297
INFO:root:current mean train loss 1729.3669819551355
INFO:root:current train perplexity3.9147541522979736
INFO:root:current mean train loss 1732.706743512835
INFO:root:current train perplexity3.9141814708709717
INFO:root:current mean train loss 1730.7310351299984
INFO:root:current train perplexity3.910984754562378
INFO:root:current mean train loss 1732.6697734814684
INFO:root:current train perplexity3.9142062664031982
INFO:root:current mean train loss 1731.1740478257002
INFO:root:current train perplexity3.912386894226074
INFO:root:current mean train loss 1730.1686921686048
INFO:root:current train perplexity3.9157791137695312
INFO:root:current mean train loss 1730.2398381800085
INFO:root:current train perplexity3.91432523727417
INFO:root:current mean train loss 1730.1591741923735
INFO:root:current train perplexity3.9143564701080322
INFO:root:current mean train loss 1729.207221076602
INFO:root:current train perplexity3.914116144180298
INFO:root:current mean train loss 1730.2177337054732
INFO:root:current train perplexity3.9154858589172363
INFO:root:current mean train loss 1730.4383475348122
INFO:root:current train perplexity3.9151859283447266
INFO:root:current mean train loss 1731.000234784871
INFO:root:current train perplexity3.9154953956604004
INFO:root:current mean train loss 1730.9548733912477
INFO:root:current train perplexity3.9140472412109375
INFO:root:current mean train loss 1731.2515744025175
INFO:root:current train perplexity3.9154789447784424
INFO:root:current mean train loss 1731.4503560635287
INFO:root:current train perplexity3.914719581604004


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.64s/it]
INFO:root:final mean train loss: 1730.4736881842832
INFO:root:final train perplexity: 3.914766311645508
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.22s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.22s/it]
INFO:root:eval mean loss: 2918.342552757836
INFO:root:eval perplexity: 10.965049743652344
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/86

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [7:40:32<1:16:37, 328.37s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1722.6188864786118
INFO:root:current train perplexity3.8895225524902344
INFO:root:current mean train loss 1711.5943459457492
INFO:root:current train perplexity3.890465259552002
INFO:root:current mean train loss 1715.6732318045079
INFO:root:current train perplexity3.8882131576538086
INFO:root:current mean train loss 1719.3413214432567
INFO:root:current train perplexity3.893744945526123
INFO:root:current mean train loss 1720.1576647975699
INFO:root:current train perplexity3.901289463043213
INFO:root:current mean train loss 1721.6167777702344
INFO:root:current train perplexity3.9081459045410156
INFO:root:current mean train loss 1722.201546580997
INFO:root:current train perplexity3.9064738750457764
INFO:root:current mean train loss 1723.3525052164607
INFO:root:current train perplexity3.9076647758483887
INFO:root:current mean train loss 1725.6026296582372
INFO:root:current train perplexity3.910580635070801
INFO:root:current mean train loss 1725.8330000640203
INFO:root:current train perplexity3.90807843208313
INFO:root:current mean train loss 1727.0989385060159
INFO:root:current train perplexity3.912047863006592
INFO:root:current mean train loss 1728.0334351742504
INFO:root:current train perplexity3.9112634658813477
INFO:root:current mean train loss 1727.3513086789378
INFO:root:current train perplexity3.907733678817749
INFO:root:current mean train loss 1727.795989564199
INFO:root:current train perplexity3.9089460372924805
INFO:root:current mean train loss 1728.8026905934505
INFO:root:current train perplexity3.913078784942627
INFO:root:current mean train loss 1729.1102758648303
INFO:root:current train perplexity3.912302017211914
INFO:root:current mean train loss 1728.8425186405261
INFO:root:current train perplexity3.910486936569214
INFO:root:current mean train loss 1728.8477558610386
INFO:root:current train perplexity3.910217523574829
INFO:root:current mean train loss 1729.4330969415385
INFO:root:current train perplexity3.910522699356079
INFO:root:current mean train loss 1729.8291346789745
INFO:root:current train perplexity3.9113876819610596


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.82s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:50<00:00, 290.82s/it]
INFO:root:final mean train loss: 1729.375735961483
INFO:root:final train perplexity: 3.9113779067993164
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.12s/it]
INFO:root:eval mean loss: 2918.8624124612893
INFO:root:eval perplexity: 10.969727516174316
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/87

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [7:46:18<1:12:17, 333.69s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1730.1795873397436
INFO:root:current train perplexity3.9086244106292725
INFO:root:current mean train loss 1727.4293459774403
INFO:root:current train perplexity3.8840999603271484
INFO:root:current mean train loss 1731.6006706841558
INFO:root:current train perplexity3.8935537338256836
INFO:root:current mean train loss 1733.0940206214864
INFO:root:current train perplexity3.903394937515259
INFO:root:current mean train loss 1733.8252341298378
INFO:root:current train perplexity3.9061944484710693
INFO:root:current mean train loss 1732.309478442974
INFO:root:current train perplexity3.907153367996216
INFO:root:current mean train loss 1730.55732047382
INFO:root:current train perplexity3.904616117477417
INFO:root:current mean train loss 1728.045966219473
INFO:root:current train perplexity3.9033544063568115
INFO:root:current mean train loss 1726.7520480840244
INFO:root:current train perplexity3.9003758430480957
INFO:root:current mean train loss 1725.87595347149
INFO:root:current train perplexity3.8998475074768066
INFO:root:current mean train loss 1726.7479757616825
INFO:root:current train perplexity3.9004645347595215
INFO:root:current mean train loss 1727.1334991196015
INFO:root:current train perplexity3.8982152938842773
INFO:root:current mean train loss 1727.4058838845792
INFO:root:current train perplexity3.8983569145202637
INFO:root:current mean train loss 1726.199504968563
INFO:root:current train perplexity3.8983500003814697
INFO:root:current mean train loss 1726.977649652587
INFO:root:current train perplexity3.9023184776306152
INFO:root:current mean train loss 1727.4551621353671
INFO:root:current train perplexity3.9031269550323486
INFO:root:current mean train loss 1728.6481504383473
INFO:root:current train perplexity3.9060416221618652
INFO:root:current mean train loss 1727.9606292347003
INFO:root:current train perplexity3.906045913696289
INFO:root:current mean train loss 1728.145412522256
INFO:root:current train perplexity3.906649351119995
INFO:root:current mean train loss 1728.2301955420762
INFO:root:current train perplexity3.906608819961548


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.26s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:45<00:00, 285.26s/it]
INFO:root:final mean train loss: 1727.7901995760349
INFO:root:final train perplexity: 3.9064900875091553
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.55s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.56s/it]
INFO:root:eval mean loss: 2920.211448509056
INFO:root:eval perplexity: 10.981880187988281
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/88

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [7:52:00<1:07:13, 336.11s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1746.5462543688323
INFO:root:current train perplexity3.936814785003662
INFO:root:current mean train loss 1735.2664682241586
INFO:root:current train perplexity3.9053261280059814
INFO:root:current mean train loss 1731.3301654363083
INFO:root:current train perplexity3.904240131378174
INFO:root:current mean train loss 1726.9217544748813
INFO:root:current train perplexity3.8970723152160645
INFO:root:current mean train loss 1725.2840618095013
INFO:root:current train perplexity3.890277862548828
INFO:root:current mean train loss 1723.8485831637342
INFO:root:current train perplexity3.887901782989502
INFO:root:current mean train loss 1725.2699434788108
INFO:root:current train perplexity3.8964078426361084
INFO:root:current mean train loss 1727.6632546862716
INFO:root:current train perplexity3.900399923324585
INFO:root:current mean train loss 1727.7830727348114
INFO:root:current train perplexity3.9045138359069824
INFO:root:current mean train loss 1726.8739241863616
INFO:root:current train perplexity3.9013500213623047
INFO:root:current mean train loss 1727.5206557461115
INFO:root:current train perplexity3.902117967605591
INFO:root:current mean train loss 1726.6669363109636
INFO:root:current train perplexity3.8997161388397217
INFO:root:current mean train loss 1726.706314475748
INFO:root:current train perplexity3.899648666381836
INFO:root:current mean train loss 1725.306023623012
INFO:root:current train perplexity3.900223731994629
INFO:root:current mean train loss 1725.9037984688546
INFO:root:current train perplexity3.8979523181915283
INFO:root:current mean train loss 1725.8004905007103
INFO:root:current train perplexity3.8983588218688965
INFO:root:current mean train loss 1725.927227585154
INFO:root:current train perplexity3.899242401123047
INFO:root:current mean train loss 1726.706106439872
INFO:root:current train perplexity3.902841329574585
INFO:root:current mean train loss 1727.0339410223244
INFO:root:current train perplexity3.9033052921295166


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.89s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.89s/it]
INFO:root:final mean train loss: 1726.6627668187405
INFO:root:final train perplexity: 3.9030184745788574
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.83s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.83s/it]
INFO:root:eval mean loss: 2920.904692045561
INFO:root:eval perplexity: 10.988126754760742
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/89

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [7:57:38<1:01:44, 336.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1707.3787027994792
INFO:root:current train perplexity3.8586955070495605
INFO:root:current mean train loss 1729.3846054077148
INFO:root:current train perplexity3.899392604827881
INFO:root:current mean train loss 1721.9880365335716
INFO:root:current train perplexity3.892418146133423
INFO:root:current mean train loss 1720.734670394506
INFO:root:current train perplexity3.8923959732055664
INFO:root:current mean train loss 1723.1314759485929
INFO:root:current train perplexity3.898310899734497
INFO:root:current mean train loss 1721.9941251277924
INFO:root:current train perplexity3.894617795944214
INFO:root:current mean train loss 1720.05796684315
INFO:root:current train perplexity3.891941785812378
INFO:root:current mean train loss 1719.7290452249933
INFO:root:current train perplexity3.8906450271606445
INFO:root:current mean train loss 1719.1952819824219
INFO:root:current train perplexity3.8862040042877197
INFO:root:current mean train loss 1719.3574111670778
INFO:root:current train perplexity3.8861966133117676
INFO:root:current mean train loss 1720.9060214197211
INFO:root:current train perplexity3.887537956237793
INFO:root:current mean train loss 1720.9635186504117
INFO:root:current train perplexity3.89034366607666
INFO:root:current mean train loss 1720.9587078031534
INFO:root:current train perplexity3.8912601470947266
INFO:root:current mean train loss 1722.5261083463342
INFO:root:current train perplexity3.8914337158203125
INFO:root:current mean train loss 1723.8915611893867
INFO:root:current train perplexity3.8926126956939697
INFO:root:current mean train loss 1724.026486189908
INFO:root:current train perplexity3.8932924270629883
INFO:root:current mean train loss 1723.4751587671321
INFO:root:current train perplexity3.893775224685669
INFO:root:current mean train loss 1724.19933090923
INFO:root:current train perplexity3.8961539268493652
INFO:root:current mean train loss 1724.3770126780664
INFO:root:current train perplexity3.8962109088897705
INFO:root:current mean train loss 1725.392460970699
INFO:root:current train perplexity3.8980460166931152


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.47s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.47s/it]
INFO:root:final mean train loss: 1725.108705860163
INFO:root:final train perplexity: 3.898237466812134
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.72s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.72s/it]
INFO:root:eval mean loss: 2920.350223758915
INFO:root:eval perplexity: 10.983129501342773
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/90

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [8:03:16<56:10, 337.05s/it]  

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1703.8784642712824
INFO:root:current train perplexity3.9180307388305664
INFO:root:current mean train loss 1714.705010939014
INFO:root:current train perplexity3.8720688819885254
INFO:root:current mean train loss 1724.4936150296808
INFO:root:current train perplexity3.88338565826416
INFO:root:current mean train loss 1726.798253021704
INFO:root:current train perplexity3.8877530097961426
INFO:root:current mean train loss 1730.6163722751858
INFO:root:current train perplexity3.8894200325012207
INFO:root:current mean train loss 1728.7765559465088
INFO:root:current train perplexity3.892031669616699
INFO:root:current mean train loss 1728.7667901989767
INFO:root:current train perplexity3.894217014312744
INFO:root:current mean train loss 1728.6593990456747
INFO:root:current train perplexity3.8901453018188477
INFO:root:current mean train loss 1728.8040128001546
INFO:root:current train perplexity3.8924455642700195
INFO:root:current mean train loss 1727.2408665389112
INFO:root:current train perplexity3.8919589519500732
INFO:root:current mean train loss 1727.2648797660806
INFO:root:current train perplexity3.8923592567443848
INFO:root:current mean train loss 1725.076909378633
INFO:root:current train perplexity3.890514373779297
INFO:root:current mean train loss 1725.1943123974968
INFO:root:current train perplexity3.891247272491455
INFO:root:current mean train loss 1724.380701298997
INFO:root:current train perplexity3.892380714416504
INFO:root:current mean train loss 1723.8683466127154
INFO:root:current train perplexity3.8941562175750732
INFO:root:current mean train loss 1724.1949171486674
INFO:root:current train perplexity3.8956124782562256
INFO:root:current mean train loss 1723.8364409932042
INFO:root:current train perplexity3.8942830562591553
INFO:root:current mean train loss 1724.2996071439868
INFO:root:current train perplexity3.8955841064453125
INFO:root:current mean train loss 1725.0636439503314
INFO:root:current train perplexity3.8960354328155518
INFO:root:current mean train loss 1724.852857116098
INFO:root:current train perplexity3.8954954147338867


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.36s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.36s/it]
INFO:root:final mean train loss: 1724.1743437381808
INFO:root:final train perplexity: 3.8953661918640137
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.64s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.64s/it]
INFO:root:eval mean loss: 2920.165036863035
INFO:root:eval perplexity: 10.98145866394043
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/91

 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [8:08:57<50:43, 338.22s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1728.6333432404892
INFO:root:current train perplexity3.924306869506836
INFO:root:current mean train loss 1722.3454129989832
INFO:root:current train perplexity3.897536277770996
INFO:root:current mean train loss 1723.853502227039
INFO:root:current train perplexity3.897547960281372
INFO:root:current mean train loss 1721.554137477985
INFO:root:current train perplexity3.8906450271606445
INFO:root:current mean train loss 1723.068405904043
INFO:root:current train perplexity3.8983147144317627
INFO:root:current mean train loss 1723.5936017717634
INFO:root:current train perplexity3.8987460136413574
INFO:root:current mean train loss 1723.757667943051
INFO:root:current train perplexity3.8983235359191895
INFO:root:current mean train loss 1721.9845553237055
INFO:root:current train perplexity3.8949830532073975
INFO:root:current mean train loss 1720.7444641257573
INFO:root:current train perplexity3.895258903503418
INFO:root:current mean train loss 1721.6410577947443
INFO:root:current train perplexity3.8953983783721924
INFO:root:current mean train loss 1723.6153688157265
INFO:root:current train perplexity3.899085760116577
INFO:root:current mean train loss 1723.8611224375886
INFO:root:current train perplexity3.8988122940063477
INFO:root:current mean train loss 1723.8441774420332
INFO:root:current train perplexity3.8953258991241455
INFO:root:current mean train loss 1723.8895745241978
INFO:root:current train perplexity3.8970749378204346
INFO:root:current mean train loss 1724.4196565451298
INFO:root:current train perplexity3.8959708213806152
INFO:root:current mean train loss 1724.573449849157
INFO:root:current train perplexity3.8963263034820557
INFO:root:current mean train loss 1724.031042495301
INFO:root:current train perplexity3.895740509033203
INFO:root:current mean train loss 1724.1959118051082
INFO:root:current train perplexity3.896152973175049
INFO:root:current mean train loss 1724.1986791542524
INFO:root:current train perplexity3.895381212234497
INFO:root:current mean train loss 1724.1622389727727
INFO:root:current train perplexity3.8947556018829346


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.84s/it]
INFO:root:final mean train loss: 1723.9363057669882
INFO:root:final train perplexity: 3.894634485244751
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.92s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.92s/it]
INFO:root:eval mean loss: 2921.3503579262856
INFO:root:eval perplexity: 10.992146492004395
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/92

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [8:14:38<45:12, 339.04s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1720.9312511625744
INFO:root:current train perplexity3.8839190006256104
INFO:root:current mean train loss 1719.9409861184336
INFO:root:current train perplexity3.8638064861297607
INFO:root:current mean train loss 1720.283143250208
INFO:root:current train perplexity3.883697986602783
INFO:root:current mean train loss 1717.972206977445
INFO:root:current train perplexity3.8853800296783447
INFO:root:current mean train loss 1723.8157038843142
INFO:root:current train perplexity3.8927648067474365
INFO:root:current mean train loss 1724.4363350199128
INFO:root:current train perplexity3.8943233489990234
INFO:root:current mean train loss 1724.230753028375
INFO:root:current train perplexity3.892638683319092
INFO:root:current mean train loss 1725.80616658262
INFO:root:current train perplexity3.890850067138672
INFO:root:current mean train loss 1725.9898661837794
INFO:root:current train perplexity3.895202398300171
INFO:root:current mean train loss 1725.8678933021806
INFO:root:current train perplexity3.8951303958892822
INFO:root:current mean train loss 1725.9944366713457
INFO:root:current train perplexity3.8958775997161865
INFO:root:current mean train loss 1724.4015822537685
INFO:root:current train perplexity3.892589807510376
INFO:root:current mean train loss 1723.6656285374295
INFO:root:current train perplexity3.890634059906006
INFO:root:current mean train loss 1723.1735097391152
INFO:root:current train perplexity3.8878896236419678
INFO:root:current mean train loss 1722.3659561167656
INFO:root:current train perplexity3.888467788696289
INFO:root:current mean train loss 1722.7551825603307
INFO:root:current train perplexity3.889878511428833
INFO:root:current mean train loss 1722.4548394896506
INFO:root:current train perplexity3.8884780406951904
INFO:root:current mean train loss 1722.0147045219885
INFO:root:current train perplexity3.8876101970672607
INFO:root:current mean train loss 1721.8479087121116
INFO:root:current train perplexity3.8867290019989014
INFO:root:current mean train loss 1722.8211664947028
INFO:root:current train perplexity3.889237642288208


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.24s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.24s/it]
INFO:root:final mean train loss: 1722.250944121222
INFO:root:final train perplexity: 3.8894612789154053
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.17s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.18s/it]
INFO:root:eval mean loss: 2920.9749627557244
INFO:root:eval perplexity: 10.988760948181152
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/93

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [8:20:20<39:39, 339.87s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1708.0651153564454
INFO:root:current train perplexity3.8722965717315674
INFO:root:current mean train loss 1718.60691663954
INFO:root:current train perplexity3.8714780807495117
INFO:root:current mean train loss 1723.6211595807756
INFO:root:current train perplexity3.877685070037842
INFO:root:current mean train loss 1723.0092718827098
INFO:root:current train perplexity3.8914244174957275
INFO:root:current mean train loss 1721.9408813476562
INFO:root:current train perplexity3.88887619972229
INFO:root:current mean train loss 1721.873227033944
INFO:root:current train perplexity3.889714479446411
INFO:root:current mean train loss 1721.5317452823415
INFO:root:current train perplexity3.8884854316711426
INFO:root:current mean train loss 1721.1807315141727
INFO:root:current train perplexity3.8896782398223877
INFO:root:current mean train loss 1720.4643295288085
INFO:root:current train perplexity3.8865630626678467
INFO:root:current mean train loss 1720.5962094676738
INFO:root:current train perplexity3.8875768184661865
INFO:root:current mean train loss 1720.4388276276766
INFO:root:current train perplexity3.886916160583496
INFO:root:current mean train loss 1719.6080789856992
INFO:root:current train perplexity3.886258602142334
INFO:root:current mean train loss 1720.8064769744874
INFO:root:current train perplexity3.8888213634490967
INFO:root:current mean train loss 1721.037539628623
INFO:root:current train perplexity3.8866422176361084
INFO:root:current mean train loss 1722.8091829866976
INFO:root:current train perplexity3.888734817504883
INFO:root:current mean train loss 1722.8381952599634
INFO:root:current train perplexity3.8879940509796143
INFO:root:current mean train loss 1722.3174421037947
INFO:root:current train perplexity3.8882527351379395
INFO:root:current mean train loss 1722.5605819873595
INFO:root:current train perplexity3.887871265411377
INFO:root:current mean train loss 1721.822994280876
INFO:root:current train perplexity3.8866779804229736
INFO:root:current mean train loss 1721.8857564290365
INFO:root:current train perplexity3.8870232105255127


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.59s/it]
INFO:root:final mean train loss: 1721.4235680407487
INFO:root:final train perplexity: 3.8869245052337646
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.84s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.84s/it]
INFO:root:eval mean loss: 2922.3357520117775
INFO:root:eval perplexity: 11.001036643981934
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/94

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [8:25:45<33:32, 335.45s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1722.674301304768
INFO:root:current train perplexity3.9041144847869873
INFO:root:current mean train loss 1725.158509849897
INFO:root:current train perplexity3.9050021171569824
INFO:root:current mean train loss 1724.9028899838227
INFO:root:current train perplexity3.8899786472320557
INFO:root:current mean train loss 1723.8014149701864
INFO:root:current train perplexity3.8939409255981445
INFO:root:current mean train loss 1724.3086052938727
INFO:root:current train perplexity3.893465518951416
INFO:root:current mean train loss 1725.1710495429622
INFO:root:current train perplexity3.8862006664276123
INFO:root:current mean train loss 1724.0073384048264
INFO:root:current train perplexity3.882558822631836
INFO:root:current mean train loss 1721.859207746824
INFO:root:current train perplexity3.8822455406188965
INFO:root:current mean train loss 1722.2464577835406
INFO:root:current train perplexity3.8818483352661133
INFO:root:current mean train loss 1722.8577002981601
INFO:root:current train perplexity3.885150671005249
INFO:root:current mean train loss 1723.5814334726813
INFO:root:current train perplexity3.889045000076294
INFO:root:current mean train loss 1722.8310452033404
INFO:root:current train perplexity3.8879425525665283
INFO:root:current mean train loss 1722.9607158534418
INFO:root:current train perplexity3.889355421066284
INFO:root:current mean train loss 1722.4645156368838
INFO:root:current train perplexity3.8863582611083984
INFO:root:current mean train loss 1722.2667935154163
INFO:root:current train perplexity3.8866682052612305
INFO:root:current mean train loss 1722.6035290779587
INFO:root:current train perplexity3.887514352798462
INFO:root:current mean train loss 1722.2114656321357
INFO:root:current train perplexity3.887565851211548
INFO:root:current mean train loss 1722.1113333556143
INFO:root:current train perplexity3.8882758617401123
INFO:root:current mean train loss 1722.4746306102152
INFO:root:current train perplexity3.8897857666015625


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.57s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:43<00:00, 283.57s/it]
INFO:root:final mean train loss: 1721.3683431358934
INFO:root:final train perplexity: 3.8867547512054443
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.94s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.94s/it]
INFO:root:eval mean loss: 2922.099897504927
INFO:root:eval perplexity: 10.998912811279297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/95

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [8:31:00<27:26, 329.33s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1685.3978009905134
INFO:root:current train perplexity3.801311731338501
INFO:root:current mean train loss 1708.3529898660224
INFO:root:current train perplexity3.8433361053466797
INFO:root:current mean train loss 1713.7441320686696
INFO:root:current train perplexity3.8454749584198
INFO:root:current mean train loss 1714.7408723284484
INFO:root:current train perplexity3.855051279067993
INFO:root:current mean train loss 1713.92569928008
INFO:root:current train perplexity3.855513572692871
INFO:root:current mean train loss 1715.2636984739786
INFO:root:current train perplexity3.8607120513916016
INFO:root:current mean train loss 1716.2445875534406
INFO:root:current train perplexity3.8690600395202637
INFO:root:current mean train loss 1718.0777451117165
INFO:root:current train perplexity3.868394136428833
INFO:root:current mean train loss 1717.9266687341637
INFO:root:current train perplexity3.870405673980713
INFO:root:current mean train loss 1718.4338443013198
INFO:root:current train perplexity3.870962619781494
INFO:root:current mean train loss 1718.8436310596956
INFO:root:current train perplexity3.8702590465545654
INFO:root:current mean train loss 1719.8383404442395
INFO:root:current train perplexity3.872443675994873
INFO:root:current mean train loss 1719.8160975548935
INFO:root:current train perplexity3.873905658721924
INFO:root:current mean train loss 1719.324130030709
INFO:root:current train perplexity3.8746204376220703
INFO:root:current mean train loss 1719.3089672126393
INFO:root:current train perplexity3.8768608570098877
INFO:root:current mean train loss 1720.2450526047257
INFO:root:current train perplexity3.87697696685791
INFO:root:current mean train loss 1720.2997203576372
INFO:root:current train perplexity3.8791792392730713
INFO:root:current mean train loss 1720.883744835158
INFO:root:current train perplexity3.8799991607666016
INFO:root:current mean train loss 1720.8912506944685
INFO:root:current train perplexity3.879196882247925
INFO:root:current mean train loss 1720.8577602151295
INFO:root:current train perplexity3.880152940750122


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.87s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:42<00:00, 282.87s/it]
INFO:root:final mean train loss: 1719.2365549677138
INFO:root:final train perplexity: 3.880225896835327
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.77s/it]
INFO:root:eval mean loss: 2922.1228863140486
INFO:root:eval perplexity: 10.999116897583008
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/96

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [8:36:14<21:39, 324.77s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1743.8110784715223
INFO:root:current train perplexity3.952728509902954
INFO:root:current mean train loss 1728.8295786617366
INFO:root:current train perplexity3.9305131435394287
INFO:root:current mean train loss 1726.2645369360457
INFO:root:current train perplexity3.9125254154205322
INFO:root:current mean train loss 1725.4591879484517
INFO:root:current train perplexity3.900228261947632
INFO:root:current mean train loss 1728.3447715953996
INFO:root:current train perplexity3.9011034965515137
INFO:root:current mean train loss 1727.2264602000207
INFO:root:current train perplexity3.897728681564331
INFO:root:current mean train loss 1725.6546096922668
INFO:root:current train perplexity3.89165997505188
INFO:root:current mean train loss 1724.8808184622415
INFO:root:current train perplexity3.889033794403076
INFO:root:current mean train loss 1723.8995596361217
INFO:root:current train perplexity3.8880064487457275
INFO:root:current mean train loss 1722.1927505968465
INFO:root:current train perplexity3.885096549987793
INFO:root:current mean train loss 1721.1775828231087
INFO:root:current train perplexity3.884300947189331
INFO:root:current mean train loss 1720.8392461343321
INFO:root:current train perplexity3.883185625076294
INFO:root:current mean train loss 1721.293286370805
INFO:root:current train perplexity3.883556842803955
INFO:root:current mean train loss 1721.1495007315048
INFO:root:current train perplexity3.8825106620788574
INFO:root:current mean train loss 1719.5465820653717
INFO:root:current train perplexity3.881911277770996
INFO:root:current mean train loss 1719.1064392528372
INFO:root:current train perplexity3.882189989089966
INFO:root:current mean train loss 1720.6901455054176
INFO:root:current train perplexity3.8849663734436035
INFO:root:current mean train loss 1720.5548212061308
INFO:root:current train perplexity3.8829123973846436
INFO:root:current mean train loss 1720.1008660792002
INFO:root:current train perplexity3.882817506790161
INFO:root:current mean train loss 1719.9711920384111
INFO:root:current train perplexity3.8816754817962646


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.77s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:46<00:00, 286.77s/it]
INFO:root:final mean train loss: 1719.465889873495
INFO:root:final train perplexity: 3.8809280395507812
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.32s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.32s/it]
INFO:root:eval mean loss: 2922.6950053080423
INFO:root:eval perplexity: 11.004281997680664
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/97

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [8:41:32<16:07, 322.62s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1720.7442779541016
INFO:root:current train perplexity3.89393949508667
INFO:root:current mean train loss 1716.3612695642419
INFO:root:current train perplexity3.8981659412384033
INFO:root:current mean train loss 1721.4524585354714
INFO:root:current train perplexity3.905860185623169
INFO:root:current mean train loss 1720.06962392522
INFO:root:current train perplexity3.8921473026275635
INFO:root:current mean train loss 1722.8924677712578
INFO:root:current train perplexity3.891756057739258
INFO:root:current mean train loss 1723.545235738267
INFO:root:current train perplexity3.882718086242676
INFO:root:current mean train loss 1724.7289259168838
INFO:root:current train perplexity3.883270740509033
INFO:root:current mean train loss 1724.1829230160636
INFO:root:current train perplexity3.880622386932373
INFO:root:current mean train loss 1721.6492499585422
INFO:root:current train perplexity3.8803155422210693
INFO:root:current mean train loss 1721.4171706573873
INFO:root:current train perplexity3.87992525100708
INFO:root:current mean train loss 1721.2995259525212
INFO:root:current train perplexity3.8812408447265625
INFO:root:current mean train loss 1719.3668949778487
INFO:root:current train perplexity3.8810346126556396
INFO:root:current mean train loss 1720.0627577365974
INFO:root:current train perplexity3.880373001098633
INFO:root:current mean train loss 1721.1212685242606
INFO:root:current train perplexity3.881418466567993
INFO:root:current mean train loss 1720.7538124210926
INFO:root:current train perplexity3.8812673091888428
INFO:root:current mean train loss 1719.9720167214248
INFO:root:current train perplexity3.879549264907837
INFO:root:current mean train loss 1719.9126849128204
INFO:root:current train perplexity3.878333568572998
INFO:root:current mean train loss 1719.5163401728091
INFO:root:current train perplexity3.8775222301483154
INFO:root:current mean train loss 1718.8028578985304
INFO:root:current train perplexity3.878021001815796
INFO:root:current mean train loss 1718.427191763688
INFO:root:current train perplexity3.877702474594116


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.42s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.42s/it]
INFO:root:final mean train loss: 1718.4016858753507
INFO:root:final train perplexity: 3.877671957015991
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.21s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.21s/it]
INFO:root:eval mean loss: 2922.4825318482544
INFO:root:eval perplexity: 11.002364158630371
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/98

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [8:46:48<10:41, 320.67s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1722.8040884164664
INFO:root:current train perplexity3.8584189414978027
INFO:root:current mean train loss 1714.580459132339
INFO:root:current train perplexity3.869896411895752
INFO:root:current mean train loss 1714.6539389556308
INFO:root:current train perplexity3.875371217727661
INFO:root:current mean train loss 1714.6331573068278
INFO:root:current train perplexity3.877721071243286
INFO:root:current mean train loss 1718.0887375042003
INFO:root:current train perplexity3.8795995712280273
INFO:root:current mean train loss 1721.7757771449806
INFO:root:current train perplexity3.8791773319244385
INFO:root:current mean train loss 1721.2546704285128
INFO:root:current train perplexity3.875558376312256
INFO:root:current mean train loss 1721.7152554381128
INFO:root:current train perplexity3.875516176223755
INFO:root:current mean train loss 1721.6465801966672
INFO:root:current train perplexity3.876873254776001
INFO:root:current mean train loss 1721.835005970693
INFO:root:current train perplexity3.8784005641937256
INFO:root:current mean train loss 1720.5859804825045
INFO:root:current train perplexity3.8738174438476562
INFO:root:current mean train loss 1720.2530980711842
INFO:root:current train perplexity3.8766746520996094
INFO:root:current mean train loss 1720.388794813797
INFO:root:current train perplexity3.8776488304138184
INFO:root:current mean train loss 1720.5948101784284
INFO:root:current train perplexity3.878899097442627
INFO:root:current mean train loss 1719.5558999540049
INFO:root:current train perplexity3.8776767253875732
INFO:root:current mean train loss 1718.9654398275259
INFO:root:current train perplexity3.8767752647399902
INFO:root:current mean train loss 1718.628859474709
INFO:root:current train perplexity3.87554669380188
INFO:root:current mean train loss 1718.8692207141908
INFO:root:current train perplexity3.8755807876586914
INFO:root:current mean train loss 1718.5659486008713
INFO:root:current train perplexity3.8754723072052
INFO:root:current mean train loss 1718.9326575048703
INFO:root:current train perplexity3.877290725708008


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.12s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.12s/it]
INFO:root:final mean train loss: 1718.440881895526
INFO:root:final train perplexity: 3.8777921199798584
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.43s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.43s/it]
INFO:root:eval mean loss: 2922.722681177271
INFO:root:eval perplexity: 11.004533767700195
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/99

 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [8:52:04<05:19, 319.29s/it]

  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1714.7935508169778
INFO:root:current train perplexity3.838287353515625
INFO:root:current mean train loss 1708.6097519423936
INFO:root:current train perplexity3.848294258117676
INFO:root:current mean train loss 1712.80562640251
INFO:root:current train perplexity3.8565971851348877
INFO:root:current mean train loss 1715.0313081591542
INFO:root:current train perplexity3.857053518295288
INFO:root:current mean train loss 1716.2035464211617
INFO:root:current train perplexity3.859647274017334
INFO:root:current mean train loss 1716.3821213974577
INFO:root:current train perplexity3.8666038513183594
INFO:root:current mean train loss 1717.1956998316075
INFO:root:current train perplexity3.8687386512756348
INFO:root:current mean train loss 1717.5689310137268
INFO:root:current train perplexity3.869852066040039
INFO:root:current mean train loss 1717.2897813585068
INFO:root:current train perplexity3.8703627586364746
INFO:root:current mean train loss 1717.628321878779
INFO:root:current train perplexity3.8710079193115234
INFO:root:current mean train loss 1717.4689567974888
INFO:root:current train perplexity3.8706257343292236
INFO:root:current mean train loss 1717.3943742729484
INFO:root:current train perplexity3.8696329593658447
INFO:root:current mean train loss 1717.5075314145379
INFO:root:current train perplexity3.8701109886169434
INFO:root:current mean train loss 1717.5273145131885
INFO:root:current train perplexity3.8704047203063965
INFO:root:current mean train loss 1719.332420853629
INFO:root:current train perplexity3.873706102371216
INFO:root:current mean train loss 1717.5526474905678
INFO:root:current train perplexity3.8714840412139893
INFO:root:current mean train loss 1716.5026251648892
INFO:root:current train perplexity3.8711283206939697
INFO:root:current mean train loss 1716.2475750341962
INFO:root:current train perplexity3.8707425594329834
INFO:root:current mean train loss 1717.1709791258468
INFO:root:current train perplexity3.8732235431671143
INFO:root:current mean train loss 1717.8778767821527
INFO:root:current train perplexity3.874635696411133


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.23s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [04:44<00:00, 284.23s/it]
INFO:root:final mean train loss: 1717.371166665928
INFO:root:final train perplexity: 3.8745217323303223
INFO:root:epoch finished
INFO:root:start evaluating


  0%|          | 0/1 [00:00<?, ?it/s][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.59s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.59s/it]
INFO:root:eval mean loss: 2922.853377058699
INFO:root:eval perplexity: 11.005714416503906
INFO:root:evalaution complete
INFO:root:checkpoint. save model: std_33/100

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [8:57:19<00:00, 318.09s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [8:57:19<00:00, 322.40s/it]
INFO:root:evaluating final model
INFO:root:start evaluating

  0%|          | 0/1 [00:00<?, ?it/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.10s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.10s/it]
INFO:root:eval mean loss: 2922.853377058699
INFO:root:eval perplexity: 11.005714416503906
INFO:root:evalaution complete
INFO:root:save model final: std_33/final
