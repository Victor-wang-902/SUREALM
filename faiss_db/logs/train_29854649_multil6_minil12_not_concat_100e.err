INFO:root:Output: multil6_minil12_not_concat_100e
INFO:root:Steps per epochs:1983
INFO:root:Total steps:198300
/scratch/zw2374/public/faiss_db/models.py:436: UserWarning: Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.
  warnings.warn("Retrieval mode is activated but not all embedding layers are loaded. Either pass external embeddings or define embedding layers.")
Some weights of RetrievalGenerationModel were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['cls.predictions.bias', 'encoder.layer.1.crossattention.output.LayerNorm.weight', 'encoder.layer.1.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.key.weight', 'encoder.layer.9.crossattention.self.value.weight', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.1.crossattention.self.value.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.9.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.query.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'encoder.layer.3.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.7.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.output.dense.bias', 'encoder.layer.3.crossattention.self.key.bias', 'encoder.layer.7.crossattention.self.value.weight', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.9.crossattention.self.query.weight', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.5.crossattention.self.key.weight', 'cls.predictions.decoder.weight', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.11.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.11.crossattention.self.key.weight', 'encoder.layer.7.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.5.crossattention.self.value.bias', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.3.crossattention.self.query.bias', 'encoder.layer.7.crossattention.self.key.bias', 'encoder.layer.11.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.output.dense.weight', 'encoder.layer.11.crossattention.self.query.bias', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.11.crossattention.self.query.weight', 'encoder.layer.3.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.1.crossattention.self.query.weight', 'encoder.layer.3.crossattention.self.value.weight', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.5.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.11.crossattention.output.dense.bias', 'encoder.layer.11.crossattention.output.dense.weight', 'encoder.layer.5.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.output.dense.bias', 'cls.predictions.transform.dense.weight', 'encoder.layer.3.crossattention.output.LayerNorm.weight', 'encoder.layer.9.crossattention.self.value.bias', 'encoder.layer.9.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.1.crossattention.self.key.bias', 'cls.predictions.transform.LayerNorm.bias', 'encoder.layer.1.crossattention.self.query.bias', 'encoder.layer.1.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.9.crossattention.output.LayerNorm.weight', 'encoder.layer.7.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.1.crossattention.output.LayerNorm.bias', 'encoder.layer.11.crossattention.self.value.weight', 'encoder.layer.5.crossattention.self.value.weight', 'encoder.layer.3.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.7.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.7.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.1.crossattention.self.value.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.10.crossattention.output.dense.bias', 'cls.predictions.transform.dense.bias', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.7.crossattention.self.key.weight', 'encoder.layer.5.crossattention.self.key.bias', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.3.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.11.crossattention.self.value.bias', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.5.crossattention.self.query.bias', 'encoder.layer.5.crossattention.output.LayerNorm.bias', 'encoder.layer.9.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.9.crossattention.self.query.bias', 'encoder.layer.7.crossattention.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/scratch/zw2374/public/faiss_db/models.py:450: UserWarning: Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.
  warnings.warn("Retrieval mode is activated but not both key embedding layers are initialized. Either pass external embeddings or redefine embedding layers.")
/ext3/miniconda3/envs/rblm/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
INFO:root:started training
  0%|          | 0/100 [00:00<?, ?it/s]
  0%|          | 0/1 [00:00<?, ?it/s][AAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
INFO:root:current mean train loss 11487.532127919823
INFO:root:current train perplexity9002.5634765625
INFO:root:current mean train loss 9518.574959759737
INFO:root:current train perplexity1879.4410400390625
INFO:root:current mean train loss 8352.90652925115
INFO:root:current train perplexity746.5302124023438
INFO:root:current mean train loss 7563.685513833411
INFO:root:current train perplexity393.68988037109375
INFO:root:current mean train loss 6975.835847965463
INFO:root:current train perplexity247.42062377929688
INFO:root:current mean train loss 6521.417278716481
INFO:root:current train perplexity172.8624725341797
INFO:root:current mean train loss 6163.4092317289205
INFO:root:current train perplexity129.9839630126953
INFO:root:current mean train loss 5878.940932024406
INFO:root:current train perplexity103.28450775146484
INFO:root:current mean train loss 5637.990236004414
INFO:root:current train perplexity85.4648666381836
INFO:root:current mean train loss 5431.722000076248
INFO:root:current train perplexity72.71409606933594
INFO:root:current mean train loss 5256.368894707191
INFO:root:current train perplexity63.200653076171875
INFO:root:current mean train loss 5103.8158479234
INFO:root:current train perplexity56.03690719604492
INFO:root:current mean train loss 4968.975903376696
INFO:root:current train perplexity50.36220169067383
INFO:root:current mean train loss 4849.270009933155
INFO:root:current train perplexity45.832847595214844
INFO:root:current mean train loss 4741.079629583785
INFO:root:current train perplexity42.11215591430664
INFO:root:current mean train loss 4644.509377198639
INFO:root:current train perplexity38.98625564575195
INFO:root:current mean train loss 4556.027300784699
INFO:root:current train perplexity36.35190963745117
INFO:root:current mean train loss 4476.669331540526
INFO:root:current train perplexity34.135414123535156
INFO:root:current mean train loss 4403.608181166485
INFO:root:current train perplexity32.214054107666016

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.97s/it]
INFO:root:final mean train loss: 4344.556025656558
INFO:root:final train perplexity: 30.765010833740234
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.88s/it]
INFO:root:eval mean loss: 2826.4659787441824
INFO:root:eval perplexity: 9.834330558776855
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.71s/it]
INFO:root:eval mean loss: 3121.525707921238
INFO:root:eval perplexity: 12.843907356262207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/1
  1%|          | 1/100 [08:40<14:19:01, 520.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2979.5679626464844
INFO:root:current train perplexity10.48486614227295
INFO:root:current mean train loss 3022.844808644262
INFO:root:current train perplexity10.705379486083984
INFO:root:current mean train loss 2999.5985389992043
INFO:root:current train perplexity10.546378135681152
INFO:root:current mean train loss 2982.5838445349586
INFO:root:current train perplexity10.410157203674316
INFO:root:current mean train loss 2961.778940640963
INFO:root:current train perplexity10.249405860900879
INFO:root:current mean train loss 2945.964340328246
INFO:root:current train perplexity10.153312683105469
INFO:root:current mean train loss 2933.2970965496907
INFO:root:current train perplexity10.065878868103027
INFO:root:current mean train loss 2917.748489806106
INFO:root:current train perplexity9.956021308898926
INFO:root:current mean train loss 2902.960112627815
INFO:root:current train perplexity9.853105545043945
INFO:root:current mean train loss 2894.7796926706637
INFO:root:current train perplexity9.776286125183105
INFO:root:current mean train loss 2880.785133662186
INFO:root:current train perplexity9.673107147216797
INFO:root:current mean train loss 2869.1128378153703
INFO:root:current train perplexity9.590371131896973
INFO:root:current mean train loss 2858.336896996749
INFO:root:current train perplexity9.517816543579102
INFO:root:current mean train loss 2849.0274289023914
INFO:root:current train perplexity9.443852424621582
INFO:root:current mean train loss 2842.0494974427306
INFO:root:current train perplexity9.38156509399414
INFO:root:current mean train loss 2831.685734650705
INFO:root:current train perplexity9.315893173217773
INFO:root:current mean train loss 2821.9852393122
INFO:root:current train perplexity9.250777244567871
INFO:root:current mean train loss 2813.620135683002
INFO:root:current train perplexity9.182668685913086
INFO:root:current mean train loss 2803.692752922159
INFO:root:current train perplexity9.114027976989746
INFO:root:current mean train loss 2796.3143008556644
INFO:root:current train perplexity9.065390586853027

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.59s/it]
INFO:root:final mean train loss: 2790.302027315187
INFO:root:final train perplexity: 9.030431747436523
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.68s/it]
INFO:root:eval mean loss: 2479.7549602968475
INFO:root:eval perplexity: 7.429661273956299
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.62s/it]
INFO:root:eval mean loss: 2816.0107820118574
INFO:root:eval perplexity: 10.00425910949707
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/2
  2%|â–         | 2/100 [17:27<14:16:21, 524.31s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2592.9178947679925
INFO:root:current train perplexity7.77846622467041
INFO:root:current mean train loss 2609.244729866659
INFO:root:current train perplexity7.829975128173828
INFO:root:current mean train loss 2599.6385576632915
INFO:root:current train perplexity7.803966999053955
INFO:root:current mean train loss 2601.146622941301
INFO:root:current train perplexity7.767665386199951
INFO:root:current mean train loss 2599.2131787447674
INFO:root:current train perplexity7.763886451721191
INFO:root:current mean train loss 2595.19990261858
INFO:root:current train perplexity7.730556011199951
INFO:root:current mean train loss 2589.3574527300552
INFO:root:current train perplexity7.705131530761719
INFO:root:current mean train loss 2587.5993242667123
INFO:root:current train perplexity7.68396520614624
INFO:root:current mean train loss 2583.879179992309
INFO:root:current train perplexity7.661056995391846
INFO:root:current mean train loss 2577.5565035085074
INFO:root:current train perplexity7.628009796142578
INFO:root:current mean train loss 2570.8682675800155
INFO:root:current train perplexity7.595264434814453
INFO:root:current mean train loss 2564.6551249706945
INFO:root:current train perplexity7.5600905418396
INFO:root:current mean train loss 2560.678820236466
INFO:root:current train perplexity7.538921356201172
INFO:root:current mean train loss 2556.0908150011137
INFO:root:current train perplexity7.508246421813965
INFO:root:current mean train loss 2552.520164942292
INFO:root:current train perplexity7.484254360198975
INFO:root:current mean train loss 2547.3380400874767
INFO:root:current train perplexity7.454875469207764
INFO:root:current mean train loss 2543.72535876562
INFO:root:current train perplexity7.428878307342529
INFO:root:current mean train loss 2540.414659609082
INFO:root:current train perplexity7.408834457397461
INFO:root:current mean train loss 2537.610936607615
INFO:root:current train perplexity7.393299579620361
INFO:root:current mean train loss 2534.3105466855477
INFO:root:current train perplexity7.3729472160339355

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.77s/it]
INFO:root:final mean train loss: 2532.085316621951
INFO:root:final train perplexity: 7.3665900230407715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.33s/it]
INFO:root:eval mean loss: 2356.7148679909133
INFO:root:eval perplexity: 6.72594690322876
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.80s/it]
INFO:root:eval mean loss: 2717.21098771332
INFO:root:eval perplexity: 9.227701187133789
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/3
  3%|â–Ž         | 3/100 [26:04<14:02:20, 521.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2413.4375659179686
INFO:root:current train perplexity6.789628505706787
INFO:root:current mean train loss 2425.586203613281
INFO:root:current train perplexity6.843836307525635
INFO:root:current mean train loss 2435.9452387695314
INFO:root:current train perplexity6.832554817199707
INFO:root:current mean train loss 2439.629110979353
INFO:root:current train perplexity6.813048839569092
INFO:root:current mean train loss 2437.814124620226
INFO:root:current train perplexity6.805903434753418
INFO:root:current mean train loss 2430.6163321200283
INFO:root:current train perplexity6.78312873840332
INFO:root:current mean train loss 2425.7903125
INFO:root:current train perplexity6.771446228027344
INFO:root:current mean train loss 2420.6802041015626
INFO:root:current train perplexity6.76002836227417
INFO:root:current mean train loss 2419.4304301183365
INFO:root:current train perplexity6.740652561187744
INFO:root:current mean train loss 2415.1664017526728
INFO:root:current train perplexity6.717609405517578
INFO:root:current mean train loss 2409.573055361793
INFO:root:current train perplexity6.704466819763184
INFO:root:current mean train loss 2409.6201077403193
INFO:root:current train perplexity6.701918601989746
INFO:root:current mean train loss 2409.5003331054686
INFO:root:current train perplexity6.695634365081787
INFO:root:current mean train loss 2407.084633879485
INFO:root:current train perplexity6.68035888671875
INFO:root:current mean train loss 2405.6953592234645
INFO:root:current train perplexity6.664951801300049
INFO:root:current mean train loss 2403.798555081275
INFO:root:current train perplexity6.659195899963379
INFO:root:current mean train loss 2401.883641690341
INFO:root:current train perplexity6.64517879486084
INFO:root:current mean train loss 2399.775613420759
INFO:root:current train perplexity6.632108688354492
INFO:root:current mean train loss 2396.548332651499
INFO:root:current train perplexity6.619842052459717
INFO:root:current mean train loss 2394.1854613005808
INFO:root:current train perplexity6.604677200317383

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.98s/it]
INFO:root:final mean train loss: 2392.6438618639295
INFO:root:final train perplexity: 6.599427700042725
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.76s/it]
INFO:root:eval mean loss: 2232.826833738503
INFO:root:eval perplexity: 6.08471155166626
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.32s/it]
INFO:root:eval mean loss: 2605.569657129599
INFO:root:eval perplexity: 8.422496795654297
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/4
  4%|â–         | 4/100 [34:37<13:48:47, 517.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2340.9596366312967
INFO:root:current train perplexity6.2716965675354
INFO:root:current mean train loss 2321.824167582803
INFO:root:current train perplexity6.200121879577637
INFO:root:current mean train loss 2321.0445762377108
INFO:root:current train perplexity6.224073886871338
INFO:root:current mean train loss 2314.9731012910847
INFO:root:current train perplexity6.201714992523193
INFO:root:current mean train loss 2318.0519054992806
INFO:root:current train perplexity6.226309299468994
INFO:root:current mean train loss 2319.013784472484
INFO:root:current train perplexity6.217579364776611
INFO:root:current mean train loss 2315.804763999836
INFO:root:current train perplexity6.211543083190918
INFO:root:current mean train loss 2318.144746424788
INFO:root:current train perplexity6.211789608001709
INFO:root:current mean train loss 2315.4133195184095
INFO:root:current train perplexity6.206099987030029
INFO:root:current mean train loss 2313.672327808905
INFO:root:current train perplexity6.194333076477051
INFO:root:current mean train loss 2312.5463519395794
INFO:root:current train perplexity6.187575817108154
INFO:root:current mean train loss 2309.475972859596
INFO:root:current train perplexity6.171359062194824
INFO:root:current mean train loss 2309.4668927392154
INFO:root:current train perplexity6.165878772735596
INFO:root:current mean train loss 2306.7703703829384
INFO:root:current train perplexity6.159692764282227
INFO:root:current mean train loss 2303.9431167321704
INFO:root:current train perplexity6.1445817947387695
INFO:root:current mean train loss 2303.2284312586003
INFO:root:current train perplexity6.138595104217529
INFO:root:current mean train loss 2299.992567404488
INFO:root:current train perplexity6.130521297454834
INFO:root:current mean train loss 2300.2782863234825
INFO:root:current train perplexity6.125971794128418
INFO:root:current mean train loss 2298.7308660833096
INFO:root:current train perplexity6.122741222381592
INFO:root:current mean train loss 2297.344242935685
INFO:root:current train perplexity6.117613315582275

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.65s/it]
INFO:root:final mean train loss: 2296.2193507484517
INFO:root:final train perplexity: 6.11617374420166
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.50s/it]
INFO:root:eval mean loss: 2163.9137638173206
INFO:root:eval perplexity: 5.75486946105957
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.19s/it]
INFO:root:eval mean loss: 2546.130307461353
INFO:root:eval perplexity: 8.022863388061523
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/5
  5%|â–Œ         | 5/100 [43:18<13:41:35, 518.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2247.158222016834
INFO:root:current train perplexity5.935701847076416
INFO:root:current mean train loss 2261.3949173637056
INFO:root:current train perplexity5.919857025146484
INFO:root:current mean train loss 2249.5671137420222
INFO:root:current train perplexity5.884894371032715
INFO:root:current mean train loss 2247.745585759481
INFO:root:current train perplexity5.886956214904785
INFO:root:current mean train loss 2243.4977944113994
INFO:root:current train perplexity5.881669044494629
INFO:root:current mean train loss 2246.2596648751874
INFO:root:current train perplexity5.875916004180908
INFO:root:current mean train loss 2240.971438402321
INFO:root:current train perplexity5.8633575439453125
INFO:root:current mean train loss 2238.196544257962
INFO:root:current train perplexity5.851197242736816
INFO:root:current mean train loss 2238.561736093927
INFO:root:current train perplexity5.847872734069824
INFO:root:current mean train loss 2235.1479101413634
INFO:root:current train perplexity5.837824821472168
INFO:root:current mean train loss 2234.3783597488687
INFO:root:current train perplexity5.831093788146973
INFO:root:current mean train loss 2234.082749856485
INFO:root:current train perplexity5.82541036605835
INFO:root:current mean train loss 2233.209030674254
INFO:root:current train perplexity5.81622314453125
INFO:root:current mean train loss 2232.173956281188
INFO:root:current train perplexity5.811792850494385
INFO:root:current mean train loss 2229.592502151859
INFO:root:current train perplexity5.808244228363037
INFO:root:current mean train loss 2227.721302995778
INFO:root:current train perplexity5.801199913024902
INFO:root:current mean train loss 2227.5854037685804
INFO:root:current train perplexity5.797414779663086
INFO:root:current mean train loss 2227.2768135926112
INFO:root:current train perplexity5.792500972747803
INFO:root:current mean train loss 2226.399373437189
INFO:root:current train perplexity5.789498805999756

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.43s/it]
INFO:root:final mean train loss: 2226.3418104486277
INFO:root:final train perplexity: 5.788233757019043
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.32s/it]
INFO:root:eval mean loss: 2112.545947785073
INFO:root:eval perplexity: 5.520691394805908
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.73s/it]
INFO:root:eval mean loss: 2504.313027672734
INFO:root:eval perplexity: 7.753126621246338
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/6
  6%|â–Œ         | 6/100 [51:52<13:30:10, 517.13s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2226.485107421875
INFO:root:current train perplexity5.756797790527344
INFO:root:current mean train loss 2166.562794902537
INFO:root:current train perplexity5.552011013031006
INFO:root:current mean train loss 2172.9601291637514
INFO:root:current train perplexity5.580564498901367
INFO:root:current mean train loss 2172.242047179973
INFO:root:current train perplexity5.55661678314209
INFO:root:current mean train loss 2173.7790292944396
INFO:root:current train perplexity5.562952995300293
INFO:root:current mean train loss 2179.160630643011
INFO:root:current train perplexity5.5656046867370605
INFO:root:current mean train loss 2181.7718688660175
INFO:root:current train perplexity5.573623180389404
INFO:root:current mean train loss 2182.835866626081
INFO:root:current train perplexity5.577169895172119
INFO:root:current mean train loss 2181.4792052232074
INFO:root:current train perplexity5.571267127990723
INFO:root:current mean train loss 2181.6360093602593
INFO:root:current train perplexity5.572070121765137
INFO:root:current mean train loss 2179.6495357669673
INFO:root:current train perplexity5.572730541229248
INFO:root:current mean train loss 2180.1263499801316
INFO:root:current train perplexity5.571561336517334
INFO:root:current mean train loss 2178.743443777321
INFO:root:current train perplexity5.5687689781188965
INFO:root:current mean train loss 2177.2091191121012
INFO:root:current train perplexity5.563002109527588
INFO:root:current mean train loss 2177.352681695692
INFO:root:current train perplexity5.562496662139893
INFO:root:current mean train loss 2177.00237122192
INFO:root:current train perplexity5.56407356262207
INFO:root:current mean train loss 2176.0676066716114
INFO:root:current train perplexity5.56096887588501
INFO:root:current mean train loss 2173.5263879272534
INFO:root:current train perplexity5.554366588592529
INFO:root:current mean train loss 2172.8129985836863
INFO:root:current train perplexity5.550320148468018
INFO:root:current mean train loss 2173.5775105387584
INFO:root:current train perplexity5.548399925231934

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.59s/it]
INFO:root:final mean train loss: 2172.218642519029
INFO:root:final train perplexity: 5.546363830566406
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.50s/it]
INFO:root:eval mean loss: 2080.28980184785
INFO:root:eval perplexity: 5.378536701202393
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.94s/it]
INFO:root:eval mean loss: 2478.08437352823
INFO:root:eval perplexity: 7.588587284088135
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/7
  7%|â–‹         | 7/100 [1:00:30<13:22:08, 517.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2239.6637912326387
INFO:root:current train perplexity5.4972429275512695
INFO:root:current mean train loss 2154.656005859375
INFO:root:current train perplexity5.4444708824157715
INFO:root:current mean train loss 2145.1285982744407
INFO:root:current train perplexity5.3868255615234375
INFO:root:current mean train loss 2133.345884694993
INFO:root:current train perplexity5.365598678588867
INFO:root:current mean train loss 2143.6930211993495
INFO:root:current train perplexity5.399423599243164
INFO:root:current mean train loss 2140.883472575184
INFO:root:current train perplexity5.384731769561768
INFO:root:current mean train loss 2141.384327317519
INFO:root:current train perplexity5.385115623474121
INFO:root:current mean train loss 2143.0740881789693
INFO:root:current train perplexity5.392393589019775
INFO:root:current mean train loss 2137.17092679124
INFO:root:current train perplexity5.38437032699585
INFO:root:current mean train loss 2139.3570893065344
INFO:root:current train perplexity5.388385772705078
INFO:root:current mean train loss 2138.4025177421645
INFO:root:current train perplexity5.387905120849609
INFO:root:current mean train loss 2136.987768183454
INFO:root:current train perplexity5.3876848220825195
INFO:root:current mean train loss 2134.720799237832
INFO:root:current train perplexity5.383054256439209
INFO:root:current mean train loss 2135.666066472194
INFO:root:current train perplexity5.383017063140869
INFO:root:current mean train loss 2136.0426170015535
INFO:root:current train perplexity5.3853678703308105
INFO:root:current mean train loss 2135.366051554523
INFO:root:current train perplexity5.384017467498779
INFO:root:current mean train loss 2134.2287442993616
INFO:root:current train perplexity5.379318714141846
INFO:root:current mean train loss 2134.9169552395592
INFO:root:current train perplexity5.380439281463623
INFO:root:current mean train loss 2133.7515622045603
INFO:root:current train perplexity5.378002643585205
INFO:root:current mean train loss 2132.512585589237
INFO:root:current train perplexity5.374612331390381

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.40s/it]
INFO:root:final mean train loss: 2131.7670199749627
INFO:root:final train perplexity: 5.372211933135986
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.27s/it]
INFO:root:eval mean loss: 2052.5901588818706
INFO:root:eval perplexity: 5.2593865394592285
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.58s/it]
INFO:root:eval mean loss: 2455.82177734375
INFO:root:eval perplexity: 7.4516730308532715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/8
  8%|â–Š         | 8/100 [1:09:24<13:21:20, 522.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2051.501565987723
INFO:root:current train perplexity5.071368217468262
INFO:root:current mean train loss 2084.4117621527776
INFO:root:current train perplexity5.192906379699707
INFO:root:current mean train loss 2080.6745247049535
INFO:root:current train perplexity5.200971603393555
INFO:root:current mean train loss 2094.033215149837
INFO:root:current train perplexity5.218957424163818
INFO:root:current mean train loss 2100.5824437634697
INFO:root:current train perplexity5.24156379699707
INFO:root:current mean train loss 2098.472800452687
INFO:root:current train perplexity5.229344844818115
INFO:root:current mean train loss 2099.6210979792077
INFO:root:current train perplexity5.22849178314209
INFO:root:current mean train loss 2099.168614809205
INFO:root:current train perplexity5.232254981994629
INFO:root:current mean train loss 2098.8999543880986
INFO:root:current train perplexity5.2369890213012695
INFO:root:current mean train loss 2101.9434955454126
INFO:root:current train perplexity5.238262176513672
INFO:root:current mean train loss 2102.1411577455087
INFO:root:current train perplexity5.23765754699707
INFO:root:current mean train loss 2102.7349990105313
INFO:root:current train perplexity5.242395401000977
INFO:root:current mean train loss 2100.3438813614944
INFO:root:current train perplexity5.24062967300415
INFO:root:current mean train loss 2098.2356767175797
INFO:root:current train perplexity5.235565185546875
INFO:root:current mean train loss 2098.515390812146
INFO:root:current train perplexity5.233843803405762
INFO:root:current mean train loss 2099.2525917078074
INFO:root:current train perplexity5.235940933227539
INFO:root:current mean train loss 2100.357158621225
INFO:root:current train perplexity5.238429546356201
INFO:root:current mean train loss 2100.265871110636
INFO:root:current train perplexity5.239012241363525
INFO:root:current mean train loss 2099.4070498100095
INFO:root:current train perplexity5.236438751220703
INFO:root:current mean train loss 2099.8293014171513
INFO:root:current train perplexity5.2357354164123535

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.82s/it]
INFO:root:final mean train loss: 2098.7678694193614
INFO:root:final train perplexity: 5.234202861785889
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.70s/it]
INFO:root:eval mean loss: 2023.6327086103724
INFO:root:eval perplexity: 5.137648105621338
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.70s/it]
INFO:root:eval mean loss: 2435.2095388858875
INFO:root:eval perplexity: 7.32711124420166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/9
  9%|â–‰         | 9/100 [1:18:14<13:16:22, 525.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2031.8205988957332
INFO:root:current train perplexity5.081881999969482
INFO:root:current mean train loss 2067.794706645765
INFO:root:current train perplexity5.143784046173096
INFO:root:current mean train loss 2078.128387451172
INFO:root:current train perplexity5.138264179229736
INFO:root:current mean train loss 2072.9784334356136
INFO:root:current train perplexity5.133023738861084
INFO:root:current mean train loss 2072.0481699715674
INFO:root:current train perplexity5.133899688720703
INFO:root:current mean train loss 2068.6481703606205
INFO:root:current train perplexity5.1212944984436035
INFO:root:current mean train loss 2068.9527994167584
INFO:root:current train perplexity5.1219916343688965
INFO:root:current mean train loss 2068.5307498688394
INFO:root:current train perplexity5.118505954742432
INFO:root:current mean train loss 2072.3971116330144
INFO:root:current train perplexity5.124268531799316
INFO:root:current mean train loss 2070.776598377388
INFO:root:current train perplexity5.121311187744141
INFO:root:current mean train loss 2071.1757523569318
INFO:root:current train perplexity5.12043571472168
INFO:root:current mean train loss 2072.4229193793403
INFO:root:current train perplexity5.122946262359619
INFO:root:current mean train loss 2070.495431528305
INFO:root:current train perplexity5.121633529663086
INFO:root:current mean train loss 2071.2675585323536
INFO:root:current train perplexity5.118244171142578
INFO:root:current mean train loss 2071.6434811258446
INFO:root:current train perplexity5.118264198303223
INFO:root:current mean train loss 2071.5224467798607
INFO:root:current train perplexity5.119289875030518
INFO:root:current mean train loss 2073.0046306914915
INFO:root:current train perplexity5.1229400634765625
INFO:root:current mean train loss 2073.282356436394
INFO:root:current train perplexity5.123593330383301
INFO:root:current mean train loss 2072.0747322758125
INFO:root:current train perplexity5.120663642883301
INFO:root:current mean train loss 2072.2699730669865
INFO:root:current train perplexity5.12058162689209

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:55<00:00, 475.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:55<00:00, 475.60s/it]
INFO:root:final mean train loss: 2070.429996892532
INFO:root:final train perplexity: 5.118521690368652
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.62s/it]
INFO:root:eval mean loss: 2000.0651279747062
INFO:root:eval perplexity: 5.040650844573975
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.62s/it]
INFO:root:eval mean loss: 2411.397807236259
INFO:root:eval perplexity: 7.1858038902282715
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/10
 10%|â–ˆ         | 10/100 [1:27:18<13:16:25, 530.95s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2054.2059273097825
INFO:root:current train perplexity5.0382585525512695
INFO:root:current mean train loss 2065.797317775749
INFO:root:current train perplexity5.056588172912598
INFO:root:current mean train loss 2063.0824764209165
INFO:root:current train perplexity5.047423839569092
INFO:root:current mean train loss 2056.477682635713
INFO:root:current train perplexity5.030327796936035
INFO:root:current mean train loss 2054.088078285331
INFO:root:current train perplexity5.027728080749512
INFO:root:current mean train loss 2050.3974124526308
INFO:root:current train perplexity5.028101444244385
INFO:root:current mean train loss 2047.6649529381539
INFO:root:current train perplexity5.018418312072754
INFO:root:current mean train loss 2049.091019371241
INFO:root:current train perplexity5.025335311889648
INFO:root:current mean train loss 2048.697916853963
INFO:root:current train perplexity5.028104782104492
INFO:root:current mean train loss 2048.5605204201333
INFO:root:current train perplexity5.028445243835449
INFO:root:current mean train loss 2047.7014336010582
INFO:root:current train perplexity5.026400566101074
INFO:root:current mean train loss 2049.5752340533777
INFO:root:current train perplexity5.027502536773682
INFO:root:current mean train loss 2049.1967537761957
INFO:root:current train perplexity5.029571056365967
INFO:root:current mean train loss 2048.986253224297
INFO:root:current train perplexity5.025728225708008
INFO:root:current mean train loss 2049.5079031594355
INFO:root:current train perplexity5.029274940490723
INFO:root:current mean train loss 2048.686088138967
INFO:root:current train perplexity5.027102470397949
INFO:root:current mean train loss 2048.1645861809093
INFO:root:current train perplexity5.026351451873779
INFO:root:current mean train loss 2048.161111144847
INFO:root:current train perplexity5.024580955505371
INFO:root:current mean train loss 2047.5017589489491
INFO:root:current train perplexity5.021888256072998
INFO:root:current mean train loss 2048.0185595851917
INFO:root:current train perplexity5.027078151702881

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.99s/it]
INFO:root:final mean train loss: 2047.3609738563925
INFO:root:final train perplexity: 5.026239395141602
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.51s/it]
INFO:root:eval mean loss: 1986.3780556536735
INFO:root:eval perplexity: 4.985162258148193
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.65s/it]
INFO:root:eval mean loss: 2400.4607249591368
INFO:root:eval perplexity: 7.121814727783203
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/11
 11%|â–ˆ         | 11/100 [1:36:13<13:09:09, 532.02s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2041.2307455373366
INFO:root:current train perplexity4.9427385330200195
INFO:root:current mean train loss 2020.8685519310736
INFO:root:current train perplexity4.920119285583496
INFO:root:current mean train loss 2020.9312274639424
INFO:root:current train perplexity4.922218322753906
INFO:root:current mean train loss 2022.5087365659408
INFO:root:current train perplexity4.928695201873779
INFO:root:current mean train loss 2017.7552374694574
INFO:root:current train perplexity4.9340314865112305
INFO:root:current mean train loss 2020.8847183383773
INFO:root:current train perplexity4.932920455932617
INFO:root:current mean train loss 2022.0503545377414
INFO:root:current train perplexity4.924001693725586
INFO:root:current mean train loss 2022.0483358058007
INFO:root:current train perplexity4.920644283294678
INFO:root:current mean train loss 2021.814669159142
INFO:root:current train perplexity4.919858932495117
INFO:root:current mean train loss 2024.5899148132448
INFO:root:current train perplexity4.927252292633057
INFO:root:current mean train loss 2026.352651353699
INFO:root:current train perplexity4.935349464416504
INFO:root:current mean train loss 2026.5642193799076
INFO:root:current train perplexity4.935161113739014
INFO:root:current mean train loss 2026.7408925674936
INFO:root:current train perplexity4.935867786407471
INFO:root:current mean train loss 2026.6613435731479
INFO:root:current train perplexity4.938475131988525
INFO:root:current mean train loss 2025.3882762554676
INFO:root:current train perplexity4.939925670623779
INFO:root:current mean train loss 2027.0283587192378
INFO:root:current train perplexity4.942455768585205
INFO:root:current mean train loss 2026.005600971118
INFO:root:current train perplexity4.942342758178711
INFO:root:current mean train loss 2026.3465349255057
INFO:root:current train perplexity4.943199634552002
INFO:root:current mean train loss 2025.9153520052153
INFO:root:current train perplexity4.94342565536499

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.42s/it]
INFO:root:final mean train loss: 2026.5276416311106
INFO:root:final train perplexity: 4.944329738616943
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.07s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.07s/it]
INFO:root:eval mean loss: 1977.8544722753213
INFO:root:eval perplexity: 4.950915813446045
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.46s/it]
INFO:root:eval mean loss: 2394.7773337939107
INFO:root:eval perplexity: 7.088790416717529
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/12
 12%|â–ˆâ–        | 12/100 [1:45:13<13:03:58, 534.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2074.807820638021
INFO:root:current train perplexity4.779417514801025
INFO:root:current mean train loss 2008.4767130138805
INFO:root:current train perplexity4.876763343811035
INFO:root:current mean train loss 1999.7059097665872
INFO:root:current train perplexity4.84219217300415
INFO:root:current mean train loss 2004.3852116046567
INFO:root:current train perplexity4.847968578338623
INFO:root:current mean train loss 2002.2720341457623
INFO:root:current train perplexity4.843288898468018
INFO:root:current mean train loss 2004.5298630579803
INFO:root:current train perplexity4.854475021362305
INFO:root:current mean train loss 2008.323054729607
INFO:root:current train perplexity4.871135234832764
INFO:root:current mean train loss 2006.2781864345327
INFO:root:current train perplexity4.862226963043213
INFO:root:current mean train loss 2006.7813298093574
INFO:root:current train perplexity4.864325046539307
INFO:root:current mean train loss 2007.09595848582
INFO:root:current train perplexity4.867405891418457
INFO:root:current mean train loss 2005.5513216210743
INFO:root:current train perplexity4.86090612411499
INFO:root:current mean train loss 2005.56029664746
INFO:root:current train perplexity4.8661088943481445
INFO:root:current mean train loss 2004.895455656107
INFO:root:current train perplexity4.867111682891846
INFO:root:current mean train loss 2005.2865388391572
INFO:root:current train perplexity4.867950439453125
INFO:root:current mean train loss 2005.7371703492515
INFO:root:current train perplexity4.864147663116455
INFO:root:current mean train loss 2005.470966920326
INFO:root:current train perplexity4.862452030181885
INFO:root:current mean train loss 2006.5101006901123
INFO:root:current train perplexity4.866979122161865
INFO:root:current mean train loss 2006.9895308399928
INFO:root:current train perplexity4.868061542510986
INFO:root:current mean train loss 2006.9986822770427
INFO:root:current train perplexity4.867012977600098
INFO:root:current mean train loss 2008.204053965983
INFO:root:current train perplexity4.869897365570068

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.42s/it]
INFO:root:final mean train loss: 2007.174825802032
INFO:root:final train perplexity: 4.869439601898193
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.12s/it]
INFO:root:eval mean loss: 1962.183957363697
INFO:root:eval perplexity: 4.888566970825195
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.21s/it]
INFO:root:eval mean loss: 2383.0949949440383
INFO:root:eval perplexity: 7.0213847160339355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/13
 13%|â–ˆâ–Ž        | 13/100 [1:54:00<12:51:47, 532.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1959.52802734375
INFO:root:current train perplexity4.755029201507568
INFO:root:current mean train loss 1979.5142059326172
INFO:root:current train perplexity4.753286361694336
INFO:root:current mean train loss 1981.1839433149858
INFO:root:current train perplexity4.789191246032715
INFO:root:current mean train loss 1981.0187377929688
INFO:root:current train perplexity4.772711753845215
INFO:root:current mean train loss 1982.6497962588355
INFO:root:current train perplexity4.776507377624512
INFO:root:current mean train loss 1987.3368044339693
INFO:root:current train perplexity4.783095836639404
INFO:root:current mean train loss 1983.7231831212198
INFO:root:current train perplexity4.7736358642578125
INFO:root:current mean train loss 1981.796999443902
INFO:root:current train perplexity4.772301197052002
INFO:root:current mean train loss 1981.0762908191216
INFO:root:current train perplexity4.777533054351807
INFO:root:current mean train loss 1980.1106877865998
INFO:root:current train perplexity4.777927398681641
INFO:root:current mean train loss 1981.6074726179534
INFO:root:current train perplexity4.780126094818115
INFO:root:current mean train loss 1982.6497424534389
INFO:root:current train perplexity4.7844696044921875
INFO:root:current mean train loss 1982.7152631915983
INFO:root:current train perplexity4.780603885650635
INFO:root:current mean train loss 1984.6185809511128
INFO:root:current train perplexity4.781460762023926
INFO:root:current mean train loss 1985.694766364299
INFO:root:current train perplexity4.789072513580322
INFO:root:current mean train loss 1985.073647107576
INFO:root:current train perplexity4.791388511657715
INFO:root:current mean train loss 1985.8327091923466
INFO:root:current train perplexity4.793233394622803
INFO:root:current mean train loss 1987.6495603339617
INFO:root:current train perplexity4.794406414031982
INFO:root:current mean train loss 1986.9224760956818
INFO:root:current train perplexity4.793920040130615
INFO:root:current mean train loss 1987.7089359283448
INFO:root:current train perplexity4.797531604766846

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.13s/it]
INFO:root:final mean train loss: 1988.641538896046
INFO:root:final train perplexity: 4.798782825469971
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.73s/it]
INFO:root:eval mean loss: 1956.9514934999722
INFO:root:eval perplexity: 4.867923736572266
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.41s/it]
INFO:root:eval mean loss: 2378.1230815048757
INFO:root:eval perplexity: 6.992894649505615
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/14
 14%|â–ˆâ–        | 14/100 [2:02:45<12:39:59, 530.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2000.7669116870777
INFO:root:current train perplexity4.666290760040283
INFO:root:current mean train loss 1979.6929771256273
INFO:root:current train perplexity4.704483509063721
INFO:root:current mean train loss 1971.8999899047337
INFO:root:current train perplexity4.708490371704102
INFO:root:current mean train loss 1968.8672530629867
INFO:root:current train perplexity4.697525978088379
INFO:root:current mean train loss 1969.0777808566934
INFO:root:current train perplexity4.700343132019043
INFO:root:current mean train loss 1972.9699372872294
INFO:root:current train perplexity4.715926170349121
INFO:root:current mean train loss 1970.6304715095173
INFO:root:current train perplexity4.716105937957764
INFO:root:current mean train loss 1969.4941639790218
INFO:root:current train perplexity4.716668128967285
INFO:root:current mean train loss 1969.6327986449467
INFO:root:current train perplexity4.714787483215332
INFO:root:current mean train loss 1966.9347528317185
INFO:root:current train perplexity4.710633277893066
INFO:root:current mean train loss 1966.5095065345874
INFO:root:current train perplexity4.7135772705078125
INFO:root:current mean train loss 1967.3089599609375
INFO:root:current train perplexity4.7174577713012695
INFO:root:current mean train loss 1967.715573310081
INFO:root:current train perplexity4.718886375427246
INFO:root:current mean train loss 1969.1709439970257
INFO:root:current train perplexity4.723304748535156
INFO:root:current mean train loss 1968.1926548160773
INFO:root:current train perplexity4.720309734344482
INFO:root:current mean train loss 1970.275263630576
INFO:root:current train perplexity4.725569725036621
INFO:root:current mean train loss 1971.215811215018
INFO:root:current train perplexity4.729297637939453
INFO:root:current mean train loss 1971.9297730967994
INFO:root:current train perplexity4.732604503631592
INFO:root:current mean train loss 1972.239734132587
INFO:root:current train perplexity4.734847545623779
INFO:root:current mean train loss 1972.5533115778871
INFO:root:current train perplexity4.737218856811523

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 470.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:49<00:00, 470.00s/it]
INFO:root:final mean train loss: 1973.1930738363492
INFO:root:final train perplexity: 4.740671157836914
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.36s/it]
INFO:root:eval mean loss: 1943.0837618780474
INFO:root:eval perplexity: 4.813632488250732
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.97s/it]
INFO:root:eval mean loss: 2367.6915330819206
INFO:root:eval perplexity: 6.9334893226623535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/15
 15%|â–ˆâ–Œ        | 15/100 [2:11:42<12:33:53, 532.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1930.373026529948
INFO:root:current train perplexity4.637227535247803
INFO:root:current mean train loss 1947.416780546114
INFO:root:current train perplexity4.679534912109375
INFO:root:current mean train loss 1957.0198518047182
INFO:root:current train perplexity4.693914890289307
INFO:root:current mean train loss 1953.254667637712
INFO:root:current train perplexity4.682135105133057
INFO:root:current mean train loss 1955.275753340532
INFO:root:current train perplexity4.67702054977417
INFO:root:current mean train loss 1958.333985256374
INFO:root:current train perplexity4.685494899749756
INFO:root:current mean train loss 1961.7991633517297
INFO:root:current train perplexity4.691336154937744
INFO:root:current mean train loss 1958.7348802804315
INFO:root:current train perplexity4.680275917053223
INFO:root:current mean train loss 1958.50598759171
INFO:root:current train perplexity4.682164192199707
INFO:root:current mean train loss 1957.816935605223
INFO:root:current train perplexity4.682056903839111
INFO:root:current mean train loss 1961.131394793458
INFO:root:current train perplexity4.686288833618164
INFO:root:current mean train loss 1958.0108520930933
INFO:root:current train perplexity4.680459022521973
INFO:root:current mean train loss 1958.8214410176497
INFO:root:current train perplexity4.68280029296875
INFO:root:current mean train loss 1960.1655069686462
INFO:root:current train perplexity4.681824207305908
INFO:root:current mean train loss 1960.7253841101058
INFO:root:current train perplexity4.684004783630371
INFO:root:current mean train loss 1960.0176330330748
INFO:root:current train perplexity4.684665203094482
INFO:root:current mean train loss 1959.1374330901176
INFO:root:current train perplexity4.683900356292725
INFO:root:current mean train loss 1959.440142258543
INFO:root:current train perplexity4.686258316040039
INFO:root:current mean train loss 1959.7807220162697
INFO:root:current train perplexity4.686825275421143
INFO:root:current mean train loss 1958.4485239987487
INFO:root:current train perplexity4.684134483337402

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.31s/it]
INFO:root:final mean train loss: 1957.946222856438
INFO:root:final train perplexity: 4.68400764465332
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.48s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.48s/it]
INFO:root:eval mean loss: 1938.7273369105994
INFO:root:eval perplexity: 4.7967023849487305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.84s/it]
INFO:root:eval mean loss: 2366.039291057181
INFO:root:eval perplexity: 6.924126148223877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/16
 16%|â–ˆâ–Œ        | 16/100 [2:20:32<12:24:04, 531.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1972.3571124009684
INFO:root:current train perplexity4.657993316650391
INFO:root:current mean train loss 1952.4023401806926
INFO:root:current train perplexity4.640470504760742
INFO:root:current mean train loss 1950.7810954977226
INFO:root:current train perplexity4.649014472961426
INFO:root:current mean train loss 1950.4860714812164
INFO:root:current train perplexity4.645235061645508
INFO:root:current mean train loss 1948.6760015467423
INFO:root:current train perplexity4.649832725524902
INFO:root:current mean train loss 1946.2331418974386
INFO:root:current train perplexity4.640442848205566
INFO:root:current mean train loss 1945.6848963184611
INFO:root:current train perplexity4.6328511238098145
INFO:root:current mean train loss 1945.6151298790126
INFO:root:current train perplexity4.6337714195251465
INFO:root:current mean train loss 1944.9566035133826
INFO:root:current train perplexity4.632959365844727
INFO:root:current mean train loss 1944.6512773005036
INFO:root:current train perplexity4.6347479820251465
INFO:root:current mean train loss 1943.8401138775823
INFO:root:current train perplexity4.634967803955078
INFO:root:current mean train loss 1942.9559786932575
INFO:root:current train perplexity4.6311516761779785
INFO:root:current mean train loss 1942.212372666546
INFO:root:current train perplexity4.626218795776367
INFO:root:current mean train loss 1943.7923016815964
INFO:root:current train perplexity4.630507946014404
INFO:root:current mean train loss 1944.3086136662985
INFO:root:current train perplexity4.632073879241943
INFO:root:current mean train loss 1944.257929519663
INFO:root:current train perplexity4.634727478027344
INFO:root:current mean train loss 1944.1282135685499
INFO:root:current train perplexity4.634831428527832
INFO:root:current mean train loss 1943.5522485062068
INFO:root:current train perplexity4.632296562194824
INFO:root:current mean train loss 1943.2398194925215
INFO:root:current train perplexity4.631296634674072
INFO:root:current mean train loss 1944.328544287679
INFO:root:current train perplexity4.631807327270508

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.85s/it]
INFO:root:final mean train loss: 1944.100762486999
INFO:root:final train perplexity: 4.6331400871276855
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.32s/it]
INFO:root:eval mean loss: 1929.2429761954234
INFO:root:eval perplexity: 4.76005220413208
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.75s/it]
INFO:root:eval mean loss: 2358.677414048648
INFO:root:eval perplexity: 6.882562637329102
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/17
 17%|â–ˆâ–‹        | 17/100 [2:29:23<12:15:06, 531.41s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1944.942045731978
INFO:root:current train perplexity4.608972549438477
INFO:root:current mean train loss 1918.8199605738862
INFO:root:current train perplexity4.559462070465088
INFO:root:current mean train loss 1922.9271244472927
INFO:root:current train perplexity4.572551727294922
INFO:root:current mean train loss 1930.5902209724347
INFO:root:current train perplexity4.578334808349609
INFO:root:current mean train loss 1925.9505217505282
INFO:root:current train perplexity4.566092491149902
INFO:root:current mean train loss 1930.0094388585512
INFO:root:current train perplexity4.5757737159729
INFO:root:current mean train loss 1926.6895915186683
INFO:root:current train perplexity4.571545124053955
INFO:root:current mean train loss 1926.2645801215003
INFO:root:current train perplexity4.573103427886963
INFO:root:current mean train loss 1928.4566537668038
INFO:root:current train perplexity4.580915927886963
INFO:root:current mean train loss 1927.537303970893
INFO:root:current train perplexity4.577897548675537
INFO:root:current mean train loss 1927.3634392233455
INFO:root:current train perplexity4.576938629150391
INFO:root:current mean train loss 1928.2454840149542
INFO:root:current train perplexity4.578876972198486
INFO:root:current mean train loss 1929.3206807959893
INFO:root:current train perplexity4.581772327423096
INFO:root:current mean train loss 1928.6396681376082
INFO:root:current train perplexity4.581498622894287
INFO:root:current mean train loss 1928.1610133673555
INFO:root:current train perplexity4.580450057983398
INFO:root:current mean train loss 1927.5877529499812
INFO:root:current train perplexity4.578751087188721
INFO:root:current mean train loss 1927.7037749087076
INFO:root:current train perplexity4.57957124710083
INFO:root:current mean train loss 1928.6203945083107
INFO:root:current train perplexity4.578928470611572
INFO:root:current mean train loss 1930.7666131359035
INFO:root:current train perplexity4.582080364227295

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.09s/it]
INFO:root:final mean train loss: 1929.4408478845085
INFO:root:final train perplexity: 4.579881191253662
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.67s/it]
INFO:root:eval mean loss: 1919.339323436115
INFO:root:eval perplexity: 4.722078800201416
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.86s/it]
INFO:root:eval mean loss: 2353.5612771325077
INFO:root:eval perplexity: 6.853825569152832
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/18
 18%|â–ˆâ–Š        | 18/100 [2:38:21<12:08:53, 533.34s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1832.290673828125
INFO:root:current train perplexity4.299926280975342
INFO:root:current mean train loss 1883.1497628348213
INFO:root:current train perplexity4.4855427742004395
INFO:root:current mean train loss 1892.6094619378812
INFO:root:current train perplexity4.477317810058594
INFO:root:current mean train loss 1904.1139912589651
INFO:root:current train perplexity4.496151924133301
INFO:root:current mean train loss 1899.5360414858217
INFO:root:current train perplexity4.493215560913086
INFO:root:current mean train loss 1902.6516171294863
INFO:root:current train perplexity4.494487285614014
INFO:root:current mean train loss 1901.536027892562
INFO:root:current train perplexity4.491917133331299
INFO:root:current mean train loss 1903.6458361037235
INFO:root:current train perplexity4.496007442474365
INFO:root:current mean train loss 1906.1462030825408
INFO:root:current train perplexity4.504470348358154
INFO:root:current mean train loss 1910.504631927659
INFO:root:current train perplexity4.512762069702148
INFO:root:current mean train loss 1910.3580373280083
INFO:root:current train perplexity4.512255668640137
INFO:root:current mean train loss 1911.2293101315045
INFO:root:current train perplexity4.514627933502197
INFO:root:current mean train loss 1910.91062467583
INFO:root:current train perplexity4.5149006843566895
INFO:root:current mean train loss 1910.4379978223778
INFO:root:current train perplexity4.513556003570557
INFO:root:current mean train loss 1911.5959622963467
INFO:root:current train perplexity4.514286041259766
INFO:root:current mean train loss 1912.7437275325738
INFO:root:current train perplexity4.5159759521484375
INFO:root:current mean train loss 1913.5838710511584
INFO:root:current train perplexity4.517995834350586
INFO:root:current mean train loss 1914.7429157693366
INFO:root:current train perplexity4.522502422332764
INFO:root:current mean train loss 1914.6712265733206
INFO:root:current train perplexity4.523980617523193
INFO:root:current mean train loss 1915.5635284023335
INFO:root:current train perplexity4.527338027954102

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.15s/it]
INFO:root:final mean train loss: 1914.8431441114217
INFO:root:final train perplexity: 4.5274577140808105
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.70s/it]
INFO:root:eval mean loss: 1913.663287656527
INFO:root:eval perplexity: 4.700451850891113
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.26s/it]
INFO:root:eval mean loss: 2346.095630835134
INFO:root:eval perplexity: 6.812106609344482
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/19
 19%|â–ˆâ–‰        | 19/100 [2:47:20<12:02:27, 535.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1881.578535600142
INFO:root:current train perplexity4.5147318840026855
INFO:root:current mean train loss 1893.413124959977
INFO:root:current train perplexity4.489676475524902
INFO:root:current mean train loss 1911.582148371516
INFO:root:current train perplexity4.522759914398193
INFO:root:current mean train loss 1899.601471515916
INFO:root:current train perplexity4.489654064178467
INFO:root:current mean train loss 1894.857468446849
INFO:root:current train perplexity4.4731526374816895
INFO:root:current mean train loss 1899.6436461233088
INFO:root:current train perplexity4.481374263763428
INFO:root:current mean train loss 1898.6756250314006
INFO:root:current train perplexity4.477071285247803
INFO:root:current mean train loss 1902.665242287591
INFO:root:current train perplexity4.490983963012695
INFO:root:current mean train loss 1900.9768982676114
INFO:root:current train perplexity4.4905781745910645
INFO:root:current mean train loss 1901.614434033309
INFO:root:current train perplexity4.487581729888916
INFO:root:current mean train loss 1901.8910100828646
INFO:root:current train perplexity4.484148025512695
INFO:root:current mean train loss 1903.6024511544674
INFO:root:current train perplexity4.485823154449463
INFO:root:current mean train loss 1904.2989665779075
INFO:root:current train perplexity4.486018657684326
INFO:root:current mean train loss 1903.1990396150482
INFO:root:current train perplexity4.482694149017334
INFO:root:current mean train loss 1901.9228581724958
INFO:root:current train perplexity4.478261470794678
INFO:root:current mean train loss 1901.8119652004968
INFO:root:current train perplexity4.478341579437256
INFO:root:current mean train loss 1902.8665737617766
INFO:root:current train perplexity4.480618000030518
INFO:root:current mean train loss 1902.2928678754038
INFO:root:current train perplexity4.47977876663208
INFO:root:current mean train loss 1902.743717331787
INFO:root:current train perplexity4.480788707733154
INFO:root:current mean train loss 1902.7609426952922
INFO:root:current train perplexity4.4825029373168945

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.98s/it]
INFO:root:final mean train loss: 1902.3685058963101
INFO:root:final train perplexity: 4.483133792877197
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.08s/it]
INFO:root:eval mean loss: 1920.5002341845357
INFO:root:eval perplexity: 4.726513385772705
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.09s/it]
INFO:root:eval mean loss: 2358.0620095543827
INFO:root:eval perplexity: 6.879100322723389
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/20
 20%|â–ˆâ–ˆ        | 20/100 [2:56:20<11:55:15, 536.45s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1855.8123121995193
INFO:root:current train perplexity4.370763778686523
INFO:root:current mean train loss 1877.947082958633
INFO:root:current train perplexity4.404955863952637
INFO:root:current mean train loss 1888.4075437410106
INFO:root:current train perplexity4.413747310638428
INFO:root:current mean train loss 1887.0291841670123
INFO:root:current train perplexity4.4055280685424805
INFO:root:current mean train loss 1888.7658001806308
INFO:root:current train perplexity4.425072193145752
INFO:root:current mean train loss 1883.574453152177
INFO:root:current train perplexity4.4181108474731445
INFO:root:current mean train loss 1887.666346303734
INFO:root:current train perplexity4.426254749298096
INFO:root:current mean train loss 1887.0759701864322
INFO:root:current train perplexity4.420638084411621
INFO:root:current mean train loss 1888.646255947836
INFO:root:current train perplexity4.425676345825195
INFO:root:current mean train loss 1889.715501941685
INFO:root:current train perplexity4.428433895111084
INFO:root:current mean train loss 1890.698412780468
INFO:root:current train perplexity4.4308390617370605
INFO:root:current mean train loss 1890.3582104556492
INFO:root:current train perplexity4.432734966278076
INFO:root:current mean train loss 1888.9936833785753
INFO:root:current train perplexity4.43213415145874
INFO:root:current mean train loss 1890.1887596307004
INFO:root:current train perplexity4.431463718414307
INFO:root:current mean train loss 1891.824543818407
INFO:root:current train perplexity4.434436798095703
INFO:root:current mean train loss 1891.2525931414727
INFO:root:current train perplexity4.43611478805542
INFO:root:current mean train loss 1891.8792633745568
INFO:root:current train perplexity4.436371803283691
INFO:root:current mean train loss 1892.7101422529786
INFO:root:current train perplexity4.43872594833374
INFO:root:current mean train loss 1891.3470170237306
INFO:root:current train perplexity4.436469554901123
INFO:root:current mean train loss 1889.725180253594
INFO:root:current train perplexity4.436983585357666

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.65s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.66s/it]
INFO:root:final mean train loss: 1889.7382022705694
INFO:root:final train perplexity: 4.438699245452881
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.21s/it]
INFO:root:eval mean loss: 1912.7105907683676
INFO:root:eval perplexity: 4.696830749511719
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.58s/it]
INFO:root:eval mean loss: 2351.5081042567044
INFO:root:eval perplexity: 6.842327117919922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/21
 21%|â–ˆâ–ˆ        | 21/100 [3:05:12<11:44:27, 535.03s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1888.7622637067523
INFO:root:current train perplexity4.427993297576904
INFO:root:current mean train loss 1888.237997984275
INFO:root:current train perplexity4.3965253829956055
INFO:root:current mean train loss 1881.090624332428
INFO:root:current train perplexity4.3905863761901855
INFO:root:current mean train loss 1880.0834511746182
INFO:root:current train perplexity4.389804363250732
INFO:root:current mean train loss 1875.3860021223102
INFO:root:current train perplexity4.395914554595947
INFO:root:current mean train loss 1875.5114669250927
INFO:root:current train perplexity4.394247531890869
INFO:root:current mean train loss 1874.9050938676044
INFO:root:current train perplexity4.390522480010986
INFO:root:current mean train loss 1878.5053534936653
INFO:root:current train perplexity4.393798351287842
INFO:root:current mean train loss 1873.237453139831
INFO:root:current train perplexity4.381114482879639
INFO:root:current mean train loss 1875.5453887045633
INFO:root:current train perplexity4.385864734649658
INFO:root:current mean train loss 1875.0566073330965
INFO:root:current train perplexity4.386063575744629
INFO:root:current mean train loss 1874.4370933453517
INFO:root:current train perplexity4.385780334472656
INFO:root:current mean train loss 1875.6243468849523
INFO:root:current train perplexity4.388339996337891
INFO:root:current mean train loss 1875.1583269057373
INFO:root:current train perplexity4.385145664215088
INFO:root:current mean train loss 1875.2120414985404
INFO:root:current train perplexity4.384054660797119
INFO:root:current mean train loss 1876.181866957167
INFO:root:current train perplexity4.386172294616699
INFO:root:current mean train loss 1877.9216741294676
INFO:root:current train perplexity4.3893256187438965
INFO:root:current mean train loss 1877.421834958713
INFO:root:current train perplexity4.390500545501709
INFO:root:current mean train loss 1878.0072231292725
INFO:root:current train perplexity4.393154621124268
INFO:root:current mean train loss 1878.0161917906842
INFO:root:current train perplexity4.395421981811523

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:59<00:00, 479.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:59<00:00, 479.36s/it]
INFO:root:final mean train loss: 1877.1318400003545
INFO:root:final train perplexity: 4.394787311553955
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.25s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.26s/it]
INFO:root:eval mean loss: 1896.6831059016235
INFO:root:eval perplexity: 4.636343002319336
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.99s/it]
INFO:root:eval mean loss: 2335.085131922512
INFO:root:eval perplexity: 6.751041889190674
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/22
 22%|â–ˆâ–ˆâ–       | 22/100 [3:14:21<11:40:57, 539.20s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1885.0787386959546
INFO:root:current train perplexity4.38215446472168
INFO:root:current mean train loss 1882.1688634618858
INFO:root:current train perplexity4.3817877769470215
INFO:root:current mean train loss 1886.5004618997539
INFO:root:current train perplexity4.379780292510986
INFO:root:current mean train loss 1879.7141777631743
INFO:root:current train perplexity4.366736888885498
INFO:root:current mean train loss 1874.197910300773
INFO:root:current train perplexity4.355354309082031
INFO:root:current mean train loss 1868.8481089540385
INFO:root:current train perplexity4.34664249420166
INFO:root:current mean train loss 1865.3726520056534
INFO:root:current train perplexity4.336528778076172
INFO:root:current mean train loss 1866.8418971526823
INFO:root:current train perplexity4.3425164222717285
INFO:root:current mean train loss 1864.043409070062
INFO:root:current train perplexity4.34248161315918
INFO:root:current mean train loss 1865.444199690471
INFO:root:current train perplexity4.34880256652832
INFO:root:current mean train loss 1866.826256744015
INFO:root:current train perplexity4.3502068519592285
INFO:root:current mean train loss 1866.3680291919757
INFO:root:current train perplexity4.349816799163818
INFO:root:current mean train loss 1867.480972565728
INFO:root:current train perplexity4.353451251983643
INFO:root:current mean train loss 1867.5014185228229
INFO:root:current train perplexity4.351739883422852
INFO:root:current mean train loss 1867.0514322916667
INFO:root:current train perplexity4.350895881652832
INFO:root:current mean train loss 1867.107576305974
INFO:root:current train perplexity4.34952974319458
INFO:root:current mean train loss 1916.3154770417336
INFO:root:current train perplexity4.5229291915893555
INFO:root:current mean train loss 2198.510989013259
INFO:root:current train perplexity5.654084205627441
INFO:root:current mean train loss 2512.676438526616
INFO:root:current train perplexity7.248560428619385
INFO:root:current mean train loss 2729.64529182291
INFO:root:current train perplexity8.602886199951172

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.43s/it]
INFO:root:final mean train loss: 2747.6271864929045
INFO:root:final train perplexity: 8.731561660766602
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.40s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.40s/it]
INFO:root:eval mean loss: 6478.357087696698
INFO:root:eval perplexity: 188.5408172607422
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.15s/it]
INFO:root:eval mean loss: 6582.213316572474
INFO:root:eval perplexity: 217.69952392578125
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/23
 23%|â–ˆâ–ˆâ–Ž       | 23/100 [3:23:15<11:30:06, 537.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 5634.24683702257
INFO:root:current train perplexity85.58035278320312
INFO:root:current mean train loss 4002.1651290090463
INFO:root:current train perplexity23.514842987060547
INFO:root:current mean train loss 3434.969587654903
INFO:root:current train perplexity15.075912475585938
INFO:root:current mean train loss 3126.385974747095
INFO:root:current train perplexity11.765719413757324
INFO:root:current mean train loss 2915.6036309689894
INFO:root:current train perplexity9.969322204589844
INFO:root:current mean train loss 2772.30312851728
INFO:root:current train perplexity8.878165245056152
INFO:root:current mean train loss 2663.6116755831067
INFO:root:current train perplexity8.158256530761719
INFO:root:current mean train loss 2580.008082136323
INFO:root:current train perplexity7.651825904846191
INFO:root:current mean train loss 2515.36223336552
INFO:root:current train perplexity7.2689619064331055
INFO:root:current mean train loss 2459.690799967448
INFO:root:current train perplexity6.96480131149292
INFO:root:current mean train loss 2415.8630465166284
INFO:root:current train perplexity6.7190070152282715
INFO:root:current mean train loss 2414.9108536920626
INFO:root:current train perplexity6.717592716217041
INFO:root:current mean train loss 2412.546541435774
INFO:root:current train perplexity6.709729194641113
INFO:root:current mean train loss 2399.5497435645234
INFO:root:current train perplexity6.6428351402282715
INFO:root:current mean train loss 2397.150696620045
INFO:root:current train perplexity6.629787921905518
INFO:root:current mean train loss 2424.862921180965
INFO:root:current train perplexity6.779244422912598
INFO:root:current mean train loss 2414.3711383164987
INFO:root:current train perplexity6.725071430206299
INFO:root:current mean train loss 2403.246186496159
INFO:root:current train perplexity6.656825542449951
INFO:root:current mean train loss 2392.2289674789185
INFO:root:current train perplexity6.59767484664917

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:53<00:00, 473.61s/it]
INFO:root:final mean train loss: 2382.713530001349
INFO:root:final train perplexity: 6.54794454574585
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.08s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.08s/it]
INFO:root:eval mean loss: 2046.6590714691379
INFO:root:eval perplexity: 5.234219551086426
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.82s/it]
INFO:root:eval mean loss: 2475.092278663148
INFO:root:eval perplexity: 7.570041179656982
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/24
 24%|â–ˆâ–ˆâ–       | 24/100 [3:32:15<11:21:56, 538.37s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2172.6791643415177
INFO:root:current train perplexity5.523661136627197
INFO:root:current mean train loss 2167.788250219042
INFO:root:current train perplexity5.516046524047852
INFO:root:current mean train loss 2171.99722009926
INFO:root:current train perplexity5.520739555358887
INFO:root:current mean train loss 2168.249275132965
INFO:root:current train perplexity5.523005962371826
INFO:root:current mean train loss 2164.1258364965643
INFO:root:current train perplexity5.517592430114746
INFO:root:current mean train loss 2167.8804611416726
INFO:root:current train perplexity5.5381646156311035
INFO:root:current mean train loss 2177.0078213485895
INFO:root:current train perplexity5.569833278656006
INFO:root:current mean train loss 2178.8723781645044
INFO:root:current train perplexity5.582233905792236
INFO:root:current mean train loss 2182.757884653084
INFO:root:current train perplexity5.596726894378662
INFO:root:current mean train loss 2185.5573909469317
INFO:root:current train perplexity5.609219074249268
INFO:root:current mean train loss 2186.792347003592
INFO:root:current train perplexity5.614134311676025
INFO:root:current mean train loss 2188.704390583538
INFO:root:current train perplexity5.620544910430908
INFO:root:current mean train loss 2191.439839057322
INFO:root:current train perplexity5.6301188468933105
INFO:root:current mean train loss 2192.101936182724
INFO:root:current train perplexity5.636333465576172
INFO:root:current mean train loss 2195.8132197550194
INFO:root:current train perplexity5.65370512008667
INFO:root:current mean train loss 2199.030540825756
INFO:root:current train perplexity5.664679527282715
INFO:root:current mean train loss 2202.401303303783
INFO:root:current train perplexity5.680276393890381
INFO:root:current mean train loss 2205.7838523073647
INFO:root:current train perplexity5.696385860443115
INFO:root:current mean train loss 2208.634382998409
INFO:root:current train perplexity5.709630966186523
INFO:root:current mean train loss 2211.35428927041
INFO:root:current train perplexity5.7198967933654785

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.38s/it]
INFO:root:final mean train loss: 2214.634975354478
INFO:root:final train perplexity: 5.735038757324219
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.94s/it]
INFO:root:eval mean loss: 2098.7056586082945
INFO:root:eval perplexity: 5.459242343902588
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.72s/it]
INFO:root:eval mean loss: 2512.4521151062445
INFO:root:eval perplexity: 7.804904937744141
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/25
 25%|â–ˆâ–ˆâ–Œ       | 25/100 [3:41:05<11:09:58, 535.97s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2252.4129333496094
INFO:root:current train perplexity5.955559253692627
INFO:root:current mean train loss 2277.4257241525956
INFO:root:current train perplexity5.982923984527588
INFO:root:current mean train loss 2283.1308997017995
INFO:root:current train perplexity6.008022308349609
INFO:root:current mean train loss 2281.9028934431662
INFO:root:current train perplexity6.012810230255127
INFO:root:current mean train loss 2295.294660748176
INFO:root:current train perplexity6.0831427574157715
INFO:root:current mean train loss 2289.6821370598013
INFO:root:current train perplexity6.06990909576416
INFO:root:current mean train loss 2290.998536721254
INFO:root:current train perplexity6.075414657592773
INFO:root:current mean train loss 2290.3869225939334
INFO:root:current train perplexity6.099155902862549
INFO:root:current mean train loss 2294.0817571843713
INFO:root:current train perplexity6.109383583068848
INFO:root:current mean train loss 2293.292613372142
INFO:root:current train perplexity6.109195709228516
INFO:root:current mean train loss 2294.817735671997
INFO:root:current train perplexity6.106563091278076
INFO:root:current mean train loss 2295.4245535962523
INFO:root:current train perplexity6.105098247528076
INFO:root:current mean train loss 2294.0132417367176
INFO:root:current train perplexity6.094363689422607
INFO:root:current mean train loss 2291.678935900916
INFO:root:current train perplexity6.0793304443359375
INFO:root:current mean train loss 2289.0554936441144
INFO:root:current train perplexity6.074167728424072
INFO:root:current mean train loss 2285.5987748273715
INFO:root:current train perplexity6.055637836456299
INFO:root:current mean train loss 2283.4487951870624
INFO:root:current train perplexity6.04419469833374
INFO:root:current mean train loss 2281.5693093850828
INFO:root:current train perplexity6.034189224243164
INFO:root:current mean train loss 2278.1891218486585
INFO:root:current train perplexity6.02445125579834
INFO:root:current mean train loss 2276.736093818522
INFO:root:current train perplexity6.017588138580322

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.19s/it]
INFO:root:final mean train loss: 2276.2936274249087
INFO:root:final train perplexity: 6.020812034606934
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.57s/it]
INFO:root:eval mean loss: 2089.2110959316824
INFO:root:eval perplexity: 5.417483329772949
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.36s/it]
INFO:root:eval mean loss: 2512.7002624078846
INFO:root:eval perplexity: 7.806488513946533
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/26
 26%|â–ˆâ–ˆâ–Œ       | 26/100 [3:50:04<11:02:17, 536.99s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2270.319568168826
INFO:root:current train perplexity6.122975826263428
INFO:root:current mean train loss 2297.6202548412566
INFO:root:current train perplexity6.150320053100586
INFO:root:current mean train loss 2316.8942638096473
INFO:root:current train perplexity6.2383036613464355
INFO:root:current mean train loss 2373.90932323646
INFO:root:current train perplexity6.5460662841796875
INFO:root:current mean train loss 2362.466128671521
INFO:root:current train perplexity6.477595329284668
INFO:root:current mean train loss 2343.536090166864
INFO:root:current train perplexity6.365489482879639
INFO:root:current mean train loss 2333.9373967829806
INFO:root:current train perplexity6.317109107971191
INFO:root:current mean train loss 2318.3343169795357
INFO:root:current train perplexity6.229604244232178
INFO:root:current mean train loss 2304.2274943566067
INFO:root:current train perplexity6.152801513671875
INFO:root:current mean train loss 2290.147464699497
INFO:root:current train perplexity6.082277297973633
INFO:root:current mean train loss 2277.7983233097307
INFO:root:current train perplexity6.026362895965576
INFO:root:current mean train loss 2268.585489445251
INFO:root:current train perplexity5.985954761505127
INFO:root:current mean train loss 2258.9307447213687
INFO:root:current train perplexity5.942997932434082
INFO:root:current mean train loss 2254.155778377115
INFO:root:current train perplexity5.916061878204346
INFO:root:current mean train loss 2246.0473468470786
INFO:root:current train perplexity5.880027770996094
INFO:root:current mean train loss 2241.194577067955
INFO:root:current train perplexity5.854954242706299
INFO:root:current mean train loss 2235.6191212841827
INFO:root:current train perplexity5.826711177825928
INFO:root:current mean train loss 2231.3804067121982
INFO:root:current train perplexity5.80621337890625
INFO:root:current mean train loss 2227.5670650053257
INFO:root:current train perplexity5.790011405944824
INFO:root:current mean train loss 2223.086971795909
INFO:root:current train perplexity5.7695441246032715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.49s/it]
INFO:root:final mean train loss: 2220.5658087025854
INFO:root:final train perplexity: 5.76192569732666
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.20s/it]
INFO:root:eval mean loss: 2050.304292719415
INFO:root:eval perplexity: 5.2496724128723145
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.58s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.58s/it]
INFO:root:eval mean loss: 2487.696994213348
INFO:root:eval perplexity: 7.648478984832764
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/27
 27%|â–ˆâ–ˆâ–‹       | 27/100 [3:58:52<10:49:52, 534.15s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2128.083841258082
INFO:root:current train perplexity5.3002543449401855
INFO:root:current mean train loss 2126.328903005093
INFO:root:current train perplexity5.343843460083008
INFO:root:current mean train loss 2131.8041277744974
INFO:root:current train perplexity5.385189533233643
INFO:root:current mean train loss 2130.44508336243
INFO:root:current train perplexity5.388410568237305
INFO:root:current mean train loss 2132.5024555322907
INFO:root:current train perplexity5.393497467041016
INFO:root:current mean train loss 2132.4305085212955
INFO:root:current train perplexity5.388195037841797
INFO:root:current mean train loss 2128.775675022856
INFO:root:current train perplexity5.372511863708496
INFO:root:current mean train loss 2129.9526888965615
INFO:root:current train perplexity5.3671722412109375
INFO:root:current mean train loss 2128.654702495584
INFO:root:current train perplexity5.36458158493042
INFO:root:current mean train loss 2130.7639076057703
INFO:root:current train perplexity5.363492012023926
INFO:root:current mean train loss 2130.974886283081
INFO:root:current train perplexity5.366381645202637
INFO:root:current mean train loss 2131.3425990814576
INFO:root:current train perplexity5.369688034057617
INFO:root:current mean train loss 2130.961678072834
INFO:root:current train perplexity5.3709869384765625
INFO:root:current mean train loss 2133.591194793297
INFO:root:current train perplexity5.3848185539245605
INFO:root:current mean train loss 2268.2062631614904
INFO:root:current train perplexity5.990398406982422
INFO:root:current mean train loss 2332.3260472974666
INFO:root:current train perplexity6.296072483062744
INFO:root:current mean train loss 2335.122945272448
INFO:root:current train perplexity6.3122477531433105
INFO:root:current mean train loss 2335.475918888096
INFO:root:current train perplexity6.312472343444824
INFO:root:current mean train loss 2333.3616094517374
INFO:root:current train perplexity6.302114963531494
INFO:root:current mean train loss 2332.105388512772
INFO:root:current train perplexity6.287253379821777

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:47<00:00, 467.18s/it]
INFO:root:final mean train loss: 2330.1823601196106
INFO:root:final train perplexity: 6.282212257385254
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.99s/it]
INFO:root:eval mean loss: 2141.576169277759
INFO:root:eval perplexity: 5.6518402099609375
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.55s/it]
INFO:root:eval mean loss: 2574.258573924396
INFO:root:eval perplexity: 8.209559440612793
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/28
 28%|â–ˆâ–ˆâ–Š       | 28/100 [4:07:46<10:40:55, 534.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2244.7246061197916
INFO:root:current train perplexity5.880863666534424
INFO:root:current mean train loss 2229.443415876116
INFO:root:current train perplexity5.7868828773498535
INFO:root:current mean train loss 2212.815849165483
INFO:root:current train perplexity5.7119140625
INFO:root:current mean train loss 2204.813158528646
INFO:root:current train perplexity5.671727657318115
INFO:root:current mean train loss 2195.051285464638
INFO:root:current train perplexity5.634095668792725
INFO:root:current mean train loss 2185.0158544921874
INFO:root:current train perplexity5.585211277008057
INFO:root:current mean train loss 2172.4206255425347
INFO:root:current train perplexity5.541843891143799
INFO:root:current mean train loss 2166.8736123361896
INFO:root:current train perplexity5.514385223388672
INFO:root:current mean train loss 2161.2044674944195
INFO:root:current train perplexity5.48248291015625
INFO:root:current mean train loss 2155.0132664763623
INFO:root:current train perplexity5.460323333740234
INFO:root:current mean train loss 2148.058225835756
INFO:root:current train perplexity5.422924041748047
INFO:root:current mean train loss 2138.6488571102063
INFO:root:current train perplexity5.392582416534424
INFO:root:current mean train loss 2133.2856367761947
INFO:root:current train perplexity5.373042106628418
INFO:root:current mean train loss 2128.4565402166195
INFO:root:current train perplexity5.355312824249268
INFO:root:current mean train loss 2125.524380131091
INFO:root:current train perplexity5.341742515563965
INFO:root:current mean train loss 2122.3415658327135
INFO:root:current train perplexity5.326353549957275
INFO:root:current mean train loss 2119.72126158757
INFO:root:current train perplexity5.3136773109436035
INFO:root:current mean train loss 2116.633072389415
INFO:root:current train perplexity5.302073001861572
INFO:root:current mean train loss 2113.306597591146
INFO:root:current train perplexity5.2899169921875
INFO:root:current mean train loss 2111.092615642306
INFO:root:current train perplexity5.2824907302856445

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.78s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.78s/it]
INFO:root:final mean train loss: 2110.220271292805
INFO:root:final train perplexity: 5.281692981719971
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.70s/it]
INFO:root:eval mean loss: 2005.734824755513
INFO:root:eval perplexity: 5.063817501068115
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.63s/it]
INFO:root:eval mean loss: 2447.952359679743
INFO:root:eval perplexity: 7.403869152069092
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/29
 29%|â–ˆâ–ˆâ–‰       | 29/100 [4:16:48<10:34:59, 536.61s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2054.335771643597
INFO:root:current train perplexity5.027899742126465
INFO:root:current mean train loss 2053.072650273641
INFO:root:current train perplexity5.027803421020508
INFO:root:current mean train loss 2049.263948205399
INFO:root:current train perplexity5.031047821044922
INFO:root:current mean train loss 2064.8948049739915
INFO:root:current train perplexity5.104883670806885
INFO:root:current mean train loss 2885.336529243283
INFO:root:current train perplexity9.75346851348877
INFO:root:current mean train loss 3245.880249642037
INFO:root:current train perplexity12.897571563720703
INFO:root:current mean train loss 3225.7840630856554
INFO:root:current train perplexity12.733073234558105
INFO:root:current mean train loss 3272.80466299346
INFO:root:current train perplexity13.209920883178711
INFO:root:current mean train loss 3253.430515306413
INFO:root:current train perplexity12.997693061828613
INFO:root:current mean train loss 3213.85510118546
INFO:root:current train perplexity12.60917854309082
INFO:root:current mean train loss 3129.3412252013936
INFO:root:current train perplexity11.784379959106445
INFO:root:current mean train loss 3078.718952665393
INFO:root:current train perplexity11.314469337463379
INFO:root:current mean train loss 3022.0861085118154
INFO:root:current train perplexity10.825472831726074
INFO:root:current mean train loss 2972.2409819679697
INFO:root:current train perplexity10.406371116638184
INFO:root:current mean train loss 2924.072153618125
INFO:root:current train perplexity10.02857780456543
INFO:root:current mean train loss 2882.032163227024
INFO:root:current train perplexity9.712100982666016
INFO:root:current mean train loss 2845.7714445506426
INFO:root:current train perplexity9.433833122253418
INFO:root:current mean train loss 2813.699264390128
INFO:root:current train perplexity9.18950366973877
INFO:root:current mean train loss 2783.9607012952356
INFO:root:current train perplexity8.977116584777832

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.68s/it]
INFO:root:final mean train loss: 2759.2580277697343
INFO:root:final train perplexity: 8.812020301818848
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.05s/it]
INFO:root:eval mean loss: 2164.3302278992132
INFO:root:eval perplexity: 5.756808757781982
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.18s/it]
INFO:root:eval mean loss: 2602.5728811710437
INFO:root:eval perplexity: 8.40187931060791
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/30
 30%|â–ˆâ–ˆâ–ˆ       | 30/100 [4:25:35<10:22:23, 533.48s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2306.2746310763887
INFO:root:current train perplexity5.965327262878418
INFO:root:current mean train loss 2244.469554096187
INFO:root:current train perplexity5.873692512512207
INFO:root:current mean train loss 2260.344570032147
INFO:root:current train perplexity5.957474231719971
INFO:root:current mean train loss 2265.0539084622774
INFO:root:current train perplexity5.960904121398926
INFO:root:current mean train loss 2260.3879221424204
INFO:root:current train perplexity5.934946537017822
INFO:root:current mean train loss 2260.755069395414
INFO:root:current train perplexity5.929846286773682
INFO:root:current mean train loss 2263.833736225498
INFO:root:current train perplexity5.9599080085754395
INFO:root:current mean train loss 2296.9809863005776
INFO:root:current train perplexity6.108648300170898
INFO:root:current mean train loss 2293.3320098235668
INFO:root:current train perplexity6.101287364959717
INFO:root:current mean train loss 2292.071795741586
INFO:root:current train perplexity6.088597297668457
INFO:root:current mean train loss 2289.9790732286374
INFO:root:current train perplexity6.079386234283447
INFO:root:current mean train loss 2286.7255353041874
INFO:root:current train perplexity6.0771870613098145
INFO:root:current mean train loss 2300.342061108257
INFO:root:current train perplexity6.142611980438232
INFO:root:current mean train loss 2301.58720622926
INFO:root:current train perplexity6.152079105377197
INFO:root:current mean train loss 2300.0861077400027
INFO:root:current train perplexity6.141409873962402
INFO:root:current mean train loss 2297.8961044928346
INFO:root:current train perplexity6.131217002868652
INFO:root:current mean train loss 2297.8358054910855
INFO:root:current train perplexity6.1282477378845215
INFO:root:current mean train loss 2297.40998296587
INFO:root:current train perplexity6.119889736175537
INFO:root:current mean train loss 2296.345758255705
INFO:root:current train perplexity6.113894939422607
INFO:root:current mean train loss 2295.989538465513
INFO:root:current train perplexity6.110667705535889

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.15s/it]
INFO:root:final mean train loss: 2295.0300865461895
INFO:root:final train perplexity: 6.110439777374268
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.15s/it]
INFO:root:eval mean loss: 2169.9383402073636
INFO:root:eval perplexity: 5.782978057861328
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.44s/it]
INFO:root:eval mean loss: 2608.0584184362533
INFO:root:eval perplexity: 8.439657211303711
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/31
 31%|â–ˆâ–ˆâ–ˆ       | 31/100 [4:34:20<10:10:36, 530.96s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2306.0713313176084
INFO:root:current train perplexity6.15346097946167
INFO:root:current mean train loss 2326.779806470114
INFO:root:current train perplexity6.18393087387085
INFO:root:current mean train loss 2326.010763792865
INFO:root:current train perplexity6.212675094604492
INFO:root:current mean train loss 2323.2953056850315
INFO:root:current train perplexity6.231507301330566
INFO:root:current mean train loss 2336.4601308616675
INFO:root:current train perplexity6.272716522216797
INFO:root:current mean train loss 2340.3401911630376
INFO:root:current train perplexity6.294963836669922
INFO:root:current mean train loss 2338.531480100589
INFO:root:current train perplexity6.303304195404053
INFO:root:current mean train loss 2337.359287903
INFO:root:current train perplexity6.305441856384277
INFO:root:current mean train loss 2338.255329418413
INFO:root:current train perplexity6.29964542388916
INFO:root:current mean train loss 2335.5990363300234
INFO:root:current train perplexity6.299631118774414
INFO:root:current mean train loss 2335.7676683095
INFO:root:current train perplexity6.301804065704346
INFO:root:current mean train loss 2336.6373124063334
INFO:root:current train perplexity6.3155694007873535
INFO:root:current mean train loss 2336.5808931882775
INFO:root:current train perplexity6.3169074058532715
INFO:root:current mean train loss 2335.9656784494896
INFO:root:current train perplexity6.311549663543701
INFO:root:current mean train loss 2334.3444302038592
INFO:root:current train perplexity6.3067946434021
INFO:root:current mean train loss 2335.576815503922
INFO:root:current train perplexity6.313612937927246
INFO:root:current mean train loss 2339.18957872379
INFO:root:current train perplexity6.327558994293213
INFO:root:current mean train loss 2341.4942736575945
INFO:root:current train perplexity6.334497451782227
INFO:root:current mean train loss 2343.863374173184
INFO:root:current train perplexity6.349288463592529
INFO:root:current mean train loss 2344.142265026691
INFO:root:current train perplexity6.35211181640625

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.13s/it]
INFO:root:final mean train loss: 2345.5797652851975
INFO:root:final train perplexity: 6.358963966369629
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.89s/it]
INFO:root:eval mean loss: 2183.510337450826
INFO:root:eval perplexity: 5.846803188323975
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.72s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.72s/it]
INFO:root:eval mean loss: 2615.2100946953956
INFO:root:eval perplexity: 8.489164352416992
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/32
 32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [4:43:02<9:58:43, 528.29s/it] 
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2388.522205441497
INFO:root:current train perplexity6.570258617401123
INFO:root:current mean train loss 2398.2752156290976
INFO:root:current train perplexity6.601340293884277
INFO:root:current mean train loss 2392.904888137378
INFO:root:current train perplexity6.517920970916748
INFO:root:current mean train loss 2367.5482494476587
INFO:root:current train perplexity6.42412805557251
INFO:root:current mean train loss 2358.1974554815356
INFO:root:current train perplexity6.417440891265869
INFO:root:current mean train loss 2356.726387375187
INFO:root:current train perplexity6.415257930755615
INFO:root:current mean train loss 2362.572194053448
INFO:root:current train perplexity6.448245048522949
INFO:root:current mean train loss 2364.9668993943474
INFO:root:current train perplexity6.46535062789917
INFO:root:current mean train loss 2371.700611770648
INFO:root:current train perplexity6.499660968780518
INFO:root:current mean train loss 2374.5522463526477
INFO:root:current train perplexity6.505667686462402
INFO:root:current mean train loss 2378.783237300006
INFO:root:current train perplexity6.532517910003662
INFO:root:current mean train loss 2377.3862132742443
INFO:root:current train perplexity6.528163909912109
INFO:root:current mean train loss 2377.113173910618
INFO:root:current train perplexity6.522298812866211
INFO:root:current mean train loss 2376.175333416471
INFO:root:current train perplexity6.513114929199219
INFO:root:current mean train loss 2377.2211231382375
INFO:root:current train perplexity6.518850326538086
INFO:root:current mean train loss 2376.237597323978
INFO:root:current train perplexity6.516801357269287
INFO:root:current mean train loss 2375.1839821758026
INFO:root:current train perplexity6.508744239807129
INFO:root:current mean train loss 2370.4895972001846
INFO:root:current train perplexity6.482097148895264
INFO:root:current mean train loss 2367.5722960266676
INFO:root:current train perplexity6.464386940002441
INFO:root:current mean train loss 2384.4009471349477
INFO:root:current train perplexity6.550640106201172

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.68s/it]
INFO:root:final mean train loss: 2383.7770652905656
INFO:root:final train perplexity: 6.553439140319824
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.39s/it]
INFO:root:eval mean loss: 2203.528838462018
INFO:root:eval perplexity: 5.942231178283691
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.93s/it]
INFO:root:eval mean loss: 2638.2569549776986
INFO:root:eval perplexity: 8.650689125061035
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/33
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 33/100 [4:52:03<9:54:17, 532.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2322.9595540364585
INFO:root:current train perplexity6.274847984313965
INFO:root:current mean train loss 2314.3822929382322
INFO:root:current train perplexity6.248488903045654
INFO:root:current mean train loss 2308.011400428185
INFO:root:current train perplexity6.195456504821777
INFO:root:current mean train loss 2299.8318657769096
INFO:root:current train perplexity6.165859699249268
INFO:root:current mean train loss 2295.5261939007305
INFO:root:current train perplexity6.145759105682373
INFO:root:current mean train loss 2282.516183253697
INFO:root:current train perplexity6.08050012588501
INFO:root:current mean train loss 2274.364141105883
INFO:root:current train perplexity6.0494184494018555
INFO:root:current mean train loss 2270.43974609375
INFO:root:current train perplexity6.008965492248535
INFO:root:current mean train loss 2261.4109961221384
INFO:root:current train perplexity5.967327117919922
INFO:root:current mean train loss 2257.8781686147054
INFO:root:current train perplexity5.946940898895264
INFO:root:current mean train loss 2255.3465846799454
INFO:root:current train perplexity5.929059028625488
INFO:root:current mean train loss 2252.8369415283205
INFO:root:current train perplexity5.912896633148193
INFO:root:current mean train loss 2249.269580659412
INFO:root:current train perplexity5.897159576416016
INFO:root:current mean train loss 2247.8588493795955
INFO:root:current train perplexity5.8852362632751465
INFO:root:current mean train loss 2246.5591259263965
INFO:root:current train perplexity5.872900485992432
INFO:root:current mean train loss 2244.475572243715
INFO:root:current train perplexity5.860383033752441
INFO:root:current mean train loss 2242.3500469161804
INFO:root:current train perplexity5.851428508758545
INFO:root:current mean train loss 2240.0406295082785
INFO:root:current train perplexity5.842083930969238
INFO:root:current mean train loss 2236.87085085633
INFO:root:current train perplexity5.831778526306152
INFO:root:current mean train loss 2233.4952539560745
INFO:root:current train perplexity5.818678379058838

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.90s/it]
INFO:root:final mean train loss: 2232.6749133073017
INFO:root:final train perplexity: 5.817215919494629
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.73s/it]
INFO:root:eval mean loss: 2134.2163215799533
INFO:root:eval perplexity: 5.61829948425293
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.09s/it]
INFO:root:eval mean loss: 2576.3207830334386
INFO:root:eval perplexity: 8.223417282104492
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/34
 34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [5:01:00<9:47:01, 533.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2208.88370186942
INFO:root:current train perplexity5.664832592010498
INFO:root:current mean train loss 2201.39029534119
INFO:root:current train perplexity5.690690040588379
INFO:root:current mean train loss 2196.255452620854
INFO:root:current train perplexity5.664762020111084
INFO:root:current mean train loss 2193.9040650385446
INFO:root:current train perplexity5.653575897216797
INFO:root:current mean train loss 2197.284518771701
INFO:root:current train perplexity5.660359859466553
INFO:root:current mean train loss 2195.2160128324035
INFO:root:current train perplexity5.658905506134033
INFO:root:current mean train loss 2196.9389531235574
INFO:root:current train perplexity5.668839931488037
INFO:root:current mean train loss 2199.557791102347
INFO:root:current train perplexity5.672163963317871
INFO:root:current mean train loss 2206.808692297071
INFO:root:current train perplexity5.700342655181885
INFO:root:current mean train loss 2208.975121145727
INFO:root:current train perplexity5.706244945526123
INFO:root:current mean train loss 2208.4890303332827
INFO:root:current train perplexity5.707440376281738
INFO:root:current mean train loss 2209.829372046251
INFO:root:current train perplexity5.722268581390381
INFO:root:current mean train loss 2211.270268451449
INFO:root:current train perplexity5.726914405822754
INFO:root:current mean train loss 2210.4722192967897
INFO:root:current train perplexity5.723495006561279
INFO:root:current mean train loss 2211.982018803291
INFO:root:current train perplexity5.725998401641846
INFO:root:current mean train loss 2213.212336702897
INFO:root:current train perplexity5.72696590423584
INFO:root:current mean train loss 2213.3071442651267
INFO:root:current train perplexity5.726619720458984
INFO:root:current mean train loss 2214.1891930472266
INFO:root:current train perplexity5.730368614196777
INFO:root:current mean train loss 2215.246635294748
INFO:root:current train perplexity5.732674598693848
INFO:root:current mean train loss 2214.1760574363975
INFO:root:current train perplexity5.73030424118042

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.33s/it]
INFO:root:final mean train loss: 2213.5146812481285
INFO:root:final train perplexity: 5.729973316192627
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.96s/it]
INFO:root:eval mean loss: 2133.4226355586493
INFO:root:eval perplexity: 5.6146931648254395
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.20s/it]
INFO:root:eval mean loss: 2569.011157313137
INFO:root:eval perplexity: 8.174405097961426
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/35
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 35/100 [5:09:47<9:35:54, 531.60s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2246.876953125
INFO:root:current train perplexity5.782145023345947
INFO:root:current mean train loss 2231.237405993275
INFO:root:current train perplexity5.755156517028809
INFO:root:current mean train loss 2223.2329815715348
INFO:root:current train perplexity5.750645637512207
INFO:root:current mean train loss 2211.0342001358263
INFO:root:current train perplexity5.712663173675537
INFO:root:current mean train loss 2207.645481866381
INFO:root:current train perplexity5.702303409576416
INFO:root:current mean train loss 2203.7665029198233
INFO:root:current train perplexity5.687259197235107
INFO:root:current mean train loss 2206.0289850152535
INFO:root:current train perplexity5.694459915161133
INFO:root:current mean train loss 2206.4702191484967
INFO:root:current train perplexity5.682316780090332
INFO:root:current mean train loss 2203.202248797321
INFO:root:current train perplexity5.662431716918945
INFO:root:current mean train loss 2199.7123812209193
INFO:root:current train perplexity5.649176120758057
INFO:root:current mean train loss 2196.7552009317515
INFO:root:current train perplexity5.645737648010254
INFO:root:current mean train loss 2195.3589535813835
INFO:root:current train perplexity5.643904209136963
INFO:root:current mean train loss 2194.3259226402506
INFO:root:current train perplexity5.639454364776611
INFO:root:current mean train loss 2193.7283651825346
INFO:root:current train perplexity5.6342267990112305
INFO:root:current mean train loss 2194.2614640691672
INFO:root:current train perplexity5.634393215179443
INFO:root:current mean train loss 2194.150684696518
INFO:root:current train perplexity5.632112503051758
INFO:root:current mean train loss 2194.1226372837036
INFO:root:current train perplexity5.628633975982666
INFO:root:current mean train loss 2193.1113633035684
INFO:root:current train perplexity5.624535083770752
INFO:root:current mean train loss 2191.978191049449
INFO:root:current train perplexity5.62677001953125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:55<00:00, 475.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:55<00:00, 475.65s/it]
INFO:root:final mean train loss: 2189.2831416589347
INFO:root:final train perplexity: 5.6215105056762695
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.80s/it]
INFO:root:eval mean loss: 2099.6369585618904
INFO:root:eval perplexity: 5.463355541229248
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.79s/it]
INFO:root:eval mean loss: 2537.5905913224456
INFO:root:eval perplexity: 7.967027187347412
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/36
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [5:18:50<9:30:51, 535.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2213.033369584517
INFO:root:current train perplexity5.565676689147949
INFO:root:current mean train loss 2171.580614794482
INFO:root:current train perplexity5.542900085449219
INFO:root:current mean train loss 2171.5201936694684
INFO:root:current train perplexity5.54722785949707
INFO:root:current mean train loss 2174.4751855782756
INFO:root:current train perplexity5.55309534072876
INFO:root:current mean train loss 2182.496517877509
INFO:root:current train perplexity5.5708465576171875
INFO:root:current mean train loss 2190.928401820114
INFO:root:current train perplexity5.610387325286865
INFO:root:current mean train loss 2190.267212913001
INFO:root:current train perplexity5.606612205505371
INFO:root:current mean train loss 2207.8122040095377
INFO:root:current train perplexity5.695155143737793
INFO:root:current mean train loss 2208.2109966536777
INFO:root:current train perplexity5.697000026702881
INFO:root:current mean train loss 2209.8533944926594
INFO:root:current train perplexity5.696811676025391
INFO:root:current mean train loss 2211.1457629406605
INFO:root:current train perplexity5.705093860626221
INFO:root:current mean train loss 2206.696555617476
INFO:root:current train perplexity5.692727565765381
INFO:root:current mean train loss 2206.318301313481
INFO:root:current train perplexity5.691178321838379
INFO:root:current mean train loss 2206.8757179894583
INFO:root:current train perplexity5.69341516494751
INFO:root:current mean train loss 2208.1362883461697
INFO:root:current train perplexity5.702102184295654
INFO:root:current mean train loss 2207.6230131865022
INFO:root:current train perplexity5.699912071228027
INFO:root:current mean train loss 2204.2622168817406
INFO:root:current train perplexity5.686788558959961
INFO:root:current mean train loss 2200.9126398208055
INFO:root:current train perplexity5.669524669647217
INFO:root:current mean train loss 2198.2786617858314
INFO:root:current train perplexity5.655707836151123
INFO:root:current mean train loss 2193.8700271199223
INFO:root:current train perplexity5.638021945953369

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:50<00:00, 470.86s/it]
INFO:root:final mean train loss: 2198.158374195801
INFO:root:final train perplexity: 5.660996437072754
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.61s/it]
INFO:root:eval mean loss: 2120.9670366868904
INFO:root:eval perplexity: 5.558418273925781
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.59s/it]
INFO:root:eval mean loss: 2560.1462172920824
INFO:root:eval perplexity: 8.115354537963867
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/37
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [5:27:47<9:22:18, 535.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2137.059797014509
INFO:root:current train perplexity5.569756984710693
INFO:root:current mean train loss 2176.4603424072266
INFO:root:current train perplexity5.517689228057861
INFO:root:current mean train loss 2151.2758371453538
INFO:root:current train perplexity5.445215225219727
INFO:root:current mean train loss 2127.9781646728516
INFO:root:current train perplexity5.371908187866211
INFO:root:current mean train loss 2115.328616418571
INFO:root:current train perplexity5.32488489151001
INFO:root:current mean train loss 2112.8422712846236
INFO:root:current train perplexity5.298150539398193
INFO:root:current mean train loss 2111.830811713152
INFO:root:current train perplexity5.2898125648498535
INFO:root:current mean train loss 2108.2657596462377
INFO:root:current train perplexity5.277907848358154
INFO:root:current mean train loss 2107.382312277089
INFO:root:current train perplexity5.267756938934326
INFO:root:current mean train loss 2109.0201965858196
INFO:root:current train perplexity5.265765190124512
INFO:root:current mean train loss 2116.2267153253815
INFO:root:current train perplexity5.289118766784668
INFO:root:current mean train loss 2117.9028094136124
INFO:root:current train perplexity5.301762580871582
INFO:root:current mean train loss 2115.832479868339
INFO:root:current train perplexity5.301140785217285
INFO:root:current mean train loss 2117.412138973374
INFO:root:current train perplexity5.3039069175720215
INFO:root:current mean train loss 2120.13005318094
INFO:root:current train perplexity5.313840866088867
INFO:root:current mean train loss 2119.3053133500184
INFO:root:current train perplexity5.308391571044922
INFO:root:current mean train loss 2117.331718950951
INFO:root:current train perplexity5.3027496337890625
INFO:root:current mean train loss 2118.2374250623916
INFO:root:current train perplexity5.303009510040283
INFO:root:current mean train loss 2116.8558816388086
INFO:root:current train perplexity5.303882598876953
INFO:root:current mean train loss 2115.4944126873097
INFO:root:current train perplexity5.3005266189575195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.93s/it]
INFO:root:final mean train loss: 2115.8852465192417
INFO:root:final train perplexity: 5.305342674255371
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.59s/it]
INFO:root:eval mean loss: 2065.5110534235096
INFO:root:eval perplexity: 5.314632892608643
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.02s/it]
INFO:root:eval mean loss: 2506.2712610123003
INFO:root:eval perplexity: 7.765552520751953
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/38
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 38/100 [5:36:31<9:09:44, 532.01s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2100.5532687717014
INFO:root:current train perplexity5.243526935577393
INFO:root:current mean train loss 2133.0793482287177
INFO:root:current train perplexity5.379749774932861
INFO:root:current mean train loss 2130.23916663345
INFO:root:current train perplexity5.3536272048950195
INFO:root:current mean train loss 2130.7005084493885
INFO:root:current train perplexity5.342560768127441
INFO:root:current mean train loss 2126.062123365081
INFO:root:current train perplexity5.343555450439453
INFO:root:current mean train loss 2118.4066726544584
INFO:root:current train perplexity5.321621894836426
INFO:root:current mean train loss 2114.7707515746124
INFO:root:current train perplexity5.296574115753174
INFO:root:current mean train loss 2111.915368242712
INFO:root:current train perplexity5.288955211639404
INFO:root:current mean train loss 2109.083193446052
INFO:root:current train perplexity5.275996208190918
INFO:root:current mean train loss 2104.2658342633927
INFO:root:current train perplexity5.257849216461182
INFO:root:current mean train loss 2101.472003027811
INFO:root:current train perplexity5.248896598815918
INFO:root:current mean train loss 2101.8815819886054
INFO:root:current train perplexity5.250300407409668
INFO:root:current mean train loss 2099.7710154092933
INFO:root:current train perplexity5.246127128601074
INFO:root:current mean train loss 2103.101247930704
INFO:root:current train perplexity5.255189418792725
INFO:root:current mean train loss 2103.137808850562
INFO:root:current train perplexity5.253896713256836
INFO:root:current mean train loss 2104.4242634696097
INFO:root:current train perplexity5.258815288543701
INFO:root:current mean train loss 2104.8938793425864
INFO:root:current train perplexity5.2570295333862305
INFO:root:current mean train loss 2106.242007717362
INFO:root:current train perplexity5.261309623718262
INFO:root:current mean train loss 2107.697817157859
INFO:root:current train perplexity5.267299652099609
INFO:root:current mean train loss 2108.15313309618
INFO:root:current train perplexity5.269423007965088

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.49s/it]
INFO:root:final mean train loss: 2108.239207149935
INFO:root:final train perplexity: 5.273447513580322
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.99s/it]
INFO:root:eval mean loss: 2058.348673502604
INFO:root:eval perplexity: 5.283937454223633
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.26s/it]
INFO:root:eval mean loss: 2496.6602233453846
INFO:root:eval perplexity: 7.704753398895264
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/39
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [5:45:24<9:01:13, 532.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2100.6722608996974
INFO:root:current train perplexity5.22438907623291
INFO:root:current mean train loss 2098.779214741271
INFO:root:current train perplexity5.185520648956299
INFO:root:current mean train loss 2094.328615610836
INFO:root:current train perplexity5.200891017913818
INFO:root:current mean train loss 2093.862915713484
INFO:root:current train perplexity5.202808856964111
INFO:root:current mean train loss 2100.613621567235
INFO:root:current train perplexity5.223762512207031
INFO:root:current mean train loss 2100.704617211827
INFO:root:current train perplexity5.237102508544922
INFO:root:current mean train loss 2117.7589155583223
INFO:root:current train perplexity5.307383060455322
INFO:root:current mean train loss 2137.9061585273644
INFO:root:current train perplexity5.381925582885742
INFO:root:current mean train loss 2148.591622266305
INFO:root:current train perplexity5.42371129989624
INFO:root:current mean train loss 2167.6083980568233
INFO:root:current train perplexity5.501248836517334
INFO:root:current mean train loss 2173.0612046983506
INFO:root:current train perplexity5.525036811828613
INFO:root:current mean train loss 2170.4215632059486
INFO:root:current train perplexity5.515211582183838
INFO:root:current mean train loss 2167.259248035268
INFO:root:current train perplexity5.504194259643555
INFO:root:current mean train loss 2168.8417688221307
INFO:root:current train perplexity5.509618759155273
INFO:root:current mean train loss 2168.872595081251
INFO:root:current train perplexity5.511911392211914
INFO:root:current mean train loss 2168.244034106539
INFO:root:current train perplexity5.509541034698486
INFO:root:current mean train loss 2164.6755777260314
INFO:root:current train perplexity5.498344898223877
INFO:root:current mean train loss 2163.023313351305
INFO:root:current train perplexity5.492574691772461
INFO:root:current mean train loss 2160.961099298889
INFO:root:current train perplexity5.488501071929932
INFO:root:current mean train loss 2161.1369357638887
INFO:root:current train perplexity5.493511199951172

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.76s/it]
INFO:root:final mean train loss: 2161.3035189984002
INFO:root:final train perplexity: 5.4988226890563965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.90s/it]
INFO:root:eval mean loss: 2113.2007463604
INFO:root:eval perplexity: 5.523616313934326
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.82s/it]
INFO:root:eval mean loss: 2547.9288187229886
INFO:root:eval perplexity: 8.034672737121582
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/40
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [5:54:18<8:52:48, 532.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2193.992970913271
INFO:root:current train perplexity5.6645402908325195
INFO:root:current mean train loss 2173.4052011500526
INFO:root:current train perplexity5.59136438369751
INFO:root:current mean train loss 2183.2078914300514
INFO:root:current train perplexity5.6204609870910645
INFO:root:current mean train loss 2183.3800139011996
INFO:root:current train perplexity5.6137871742248535
INFO:root:current mean train loss 2177.7646469084357
INFO:root:current train perplexity5.5924458503723145
INFO:root:current mean train loss 2178.2373807969693
INFO:root:current train perplexity5.591026782989502
INFO:root:current mean train loss 2181.5081458112804
INFO:root:current train perplexity5.605958938598633
INFO:root:current mean train loss 2184.7885864414516
INFO:root:current train perplexity5.609744548797607
INFO:root:current mean train loss 2187.021488263474
INFO:root:current train perplexity5.608589172363281
INFO:root:current mean train loss 2184.7624382042422
INFO:root:current train perplexity5.603025913238525
INFO:root:current mean train loss 2184.8687843697508
INFO:root:current train perplexity5.605659484863281
INFO:root:current mean train loss 2193.9503462696803
INFO:root:current train perplexity5.635082244873047
INFO:root:current mean train loss 2194.4509782231908
INFO:root:current train perplexity5.637032985687256
INFO:root:current mean train loss 2193.619238971713
INFO:root:current train perplexity5.63348388671875
INFO:root:current mean train loss 2191.5581794207446
INFO:root:current train perplexity5.6241254806518555
INFO:root:current mean train loss 2195.5834762254344
INFO:root:current train perplexity5.641992092132568
INFO:root:current mean train loss 2195.1568532265533
INFO:root:current train perplexity5.643404960632324
INFO:root:current mean train loss 2196.0529556660385
INFO:root:current train perplexity5.646326065063477
INFO:root:current mean train loss 2196.121632444535
INFO:root:current train perplexity5.649076461791992
INFO:root:current mean train loss 2195.5460609100633
INFO:root:current train perplexity5.6470232009887695

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.29s/it]
INFO:root:final mean train loss: 2195.1051404590385
INFO:root:final train perplexity: 5.64738130569458
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.37s/it]
INFO:root:eval mean loss: 2092.4477335611978
INFO:root:eval perplexity: 5.4316816329956055
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.86s/it]
INFO:root:eval mean loss: 2529.9847585258753
INFO:root:eval perplexity: 7.917623519897461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/41
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 41/100 [6:03:02<8:41:32, 530.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2179.966781616211
INFO:root:current train perplexity5.559354305267334
INFO:root:current mean train loss 2182.8923308703365
INFO:root:current train perplexity5.572592258453369
INFO:root:current mean train loss 2195.3270016232054
INFO:root:current train perplexity5.591669082641602
INFO:root:current mean train loss 2184.9815276174836
INFO:root:current train perplexity5.550591945648193
INFO:root:current mean train loss 2181.6745322442825
INFO:root:current train perplexity5.567941188812256
INFO:root:current mean train loss 2181.5159873194343
INFO:root:current train perplexity5.556744575500488
INFO:root:current mean train loss 2178.35891811327
INFO:root:current train perplexity5.539982318878174
INFO:root:current mean train loss 2177.169181171973
INFO:root:current train perplexity5.534217834472656
INFO:root:current mean train loss 2173.5002655301773
INFO:root:current train perplexity5.526185035705566
INFO:root:current mean train loss 2170.462942590675
INFO:root:current train perplexity5.517347812652588
INFO:root:current mean train loss 2169.9214126698294
INFO:root:current train perplexity5.517194747924805
INFO:root:current mean train loss 2166.8342296383453
INFO:root:current train perplexity5.503682613372803
INFO:root:current mean train loss 2164.771984430007
INFO:root:current train perplexity5.492961406707764
INFO:root:current mean train loss 2162.514307060351
INFO:root:current train perplexity5.483744144439697
INFO:root:current mean train loss 2157.7535610912955
INFO:root:current train perplexity5.469385147094727
INFO:root:current mean train loss 2155.768944838292
INFO:root:current train perplexity5.461548328399658
INFO:root:current mean train loss 2151.685889190098
INFO:root:current train perplexity5.448912620544434
INFO:root:current mean train loss 2146.8271845284444
INFO:root:current train perplexity5.433842182159424
INFO:root:current mean train loss 2144.638654942251
INFO:root:current train perplexity5.422917366027832

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.42s/it]
INFO:root:final mean train loss: 2142.4630672976155
INFO:root:final train perplexity: 5.417721271514893
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:38<00:00, 38.26s/it]
INFO:root:eval mean loss: 2098.9746937853224
INFO:root:eval perplexity: 5.460430145263672
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.35s/it]
INFO:root:eval mean loss: 2538.160159280114
INFO:root:eval perplexity: 7.970739841461182
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/42
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [6:12:01<8:35:00, 532.77s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2106.4405987079326
INFO:root:current train perplexity5.350032329559326
INFO:root:current mean train loss 2110.971743423327
INFO:root:current train perplexity5.21881103515625
INFO:root:current mean train loss 2095.3677399684566
INFO:root:current train perplexity5.236187934875488
INFO:root:current mean train loss 2091.710439078724
INFO:root:current train perplexity5.2192702293396
INFO:root:current mean train loss 2094.795538137958
INFO:root:current train perplexity5.217846393585205
INFO:root:current mean train loss 2095.135008337902
INFO:root:current train perplexity5.225790500640869
INFO:root:current mean train loss 2099.84050826653
INFO:root:current train perplexity5.242201805114746
INFO:root:current mean train loss 2103.5356048113167
INFO:root:current train perplexity5.255174160003662
INFO:root:current mean train loss 2102.14459686467
INFO:root:current train perplexity5.2502312660217285
INFO:root:current mean train loss 2100.4156032867263
INFO:root:current train perplexity5.247201919555664
INFO:root:current mean train loss 2100.1467216469105
INFO:root:current train perplexity5.242837905883789
INFO:root:current mean train loss 2100.6128218137565
INFO:root:current train perplexity5.241542816162109
INFO:root:current mean train loss 2103.3946809949507
INFO:root:current train perplexity5.2467546463012695
INFO:root:current mean train loss 2101.141270866307
INFO:root:current train perplexity5.240879535675049
INFO:root:current mean train loss 2099.2658050385926
INFO:root:current train perplexity5.235394477844238
INFO:root:current mean train loss 2097.54542839015
INFO:root:current train perplexity5.227357864379883
INFO:root:current mean train loss 2097.834960710463
INFO:root:current train perplexity5.228334426879883
INFO:root:current mean train loss 2097.5168822600835
INFO:root:current train perplexity5.225615978240967
INFO:root:current mean train loss 2097.748852148545
INFO:root:current train perplexity5.226991176605225
INFO:root:current mean train loss 2098.2872116001126
INFO:root:current train perplexity5.227826118469238

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.39s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.39s/it]
INFO:root:final mean train loss: 2095.9047918045576
INFO:root:final train perplexity: 5.222397804260254
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.73s/it]
INFO:root:eval mean loss: 2029.2528188718973
INFO:root:eval perplexity: 5.161052703857422
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.93s/it]
INFO:root:eval mean loss: 2467.1599181696033
INFO:root:eval perplexity: 7.521090507507324
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/43
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [6:20:45<8:23:43, 530.23s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2102.1567423502606
INFO:root:current train perplexity5.186397075653076
INFO:root:current mean train loss 2069.1561983548677
INFO:root:current train perplexity5.107544422149658
INFO:root:current mean train loss 2065.1190052861753
INFO:root:current train perplexity5.076606273651123
INFO:root:current mean train loss 2076.814183460582
INFO:root:current train perplexity5.128188133239746
INFO:root:current mean train loss 2079.8612670898438
INFO:root:current train perplexity5.138987064361572
INFO:root:current mean train loss 2083.858713286778
INFO:root:current train perplexity5.154569149017334
INFO:root:current mean train loss 2082.5156257750496
INFO:root:current train perplexity5.151682376861572
INFO:root:current mean train loss 2084.3047627488227
INFO:root:current train perplexity5.166018962860107
INFO:root:current mean train loss 2085.461175904791
INFO:root:current train perplexity5.171204566955566
INFO:root:current mean train loss 2081.6993204752603
INFO:root:current train perplexity5.15925407409668
INFO:root:current mean train loss 2077.2412736318643
INFO:root:current train perplexity5.150294303894043
INFO:root:current mean train loss 2074.221867006015
INFO:root:current train perplexity5.137129306793213
INFO:root:current mean train loss 2072.9088706411967
INFO:root:current train perplexity5.129904747009277
INFO:root:current mean train loss 2127.8180945833824
INFO:root:current train perplexity5.362468719482422
INFO:root:current mean train loss 2146.627308409364
INFO:root:current train perplexity5.4390716552734375
INFO:root:current mean train loss 2153.3622300889756
INFO:root:current train perplexity5.4600372314453125
INFO:root:current mean train loss 2154.5139943503164
INFO:root:current train perplexity5.4670186042785645
INFO:root:current mean train loss 2156.346794348921
INFO:root:current train perplexity5.469028949737549
INFO:root:current mean train loss 2156.1407831577653
INFO:root:current train perplexity5.467153549194336
INFO:root:current mean train loss 2153.740714117653
INFO:root:current train perplexity5.461343765258789

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 466.16s/it]
INFO:root:final mean train loss: 2152.43254781118
INFO:root:final train perplexity: 5.46048641204834
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.98s/it]
INFO:root:eval mean loss: 2077.8119831491026
INFO:root:eval perplexity: 5.367767810821533
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.66s/it]
INFO:root:eval mean loss: 2518.6610155037956
INFO:root:eval perplexity: 7.844637393951416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/44
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 44/100 [6:29:37<8:15:22, 530.76s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2099.2875067528257
INFO:root:current train perplexity5.2870354652404785
INFO:root:current mean train loss 2131.1035546542835
INFO:root:current train perplexity5.360464096069336
INFO:root:current mean train loss 2133.5631647148593
INFO:root:current train perplexity5.378625869750977
INFO:root:current mean train loss 2138.0162058014002
INFO:root:current train perplexity5.408906936645508
INFO:root:current mean train loss 2127.792091318425
INFO:root:current train perplexity5.363465785980225
INFO:root:current mean train loss 2113.505565245801
INFO:root:current train perplexity5.316977500915527
INFO:root:current mean train loss 2110.423150040451
INFO:root:current train perplexity5.291081428527832
INFO:root:current mean train loss 2104.240197933662
INFO:root:current train perplexity5.265894889831543
INFO:root:current mean train loss 2105.8150525233823
INFO:root:current train perplexity5.271113872528076
INFO:root:current mean train loss 2102.9938249436955
INFO:root:current train perplexity5.263053894042969
INFO:root:current mean train loss 2099.9580549150846
INFO:root:current train perplexity5.248850345611572
INFO:root:current mean train loss 2097.649093082498
INFO:root:current train perplexity5.234674453735352
INFO:root:current mean train loss 2092.884910797633
INFO:root:current train perplexity5.214605331420898
INFO:root:current mean train loss 2089.972586107148
INFO:root:current train perplexity5.199918270111084
INFO:root:current mean train loss 2087.888515132332
INFO:root:current train perplexity5.1869635581970215
INFO:root:current mean train loss 2094.373185831574
INFO:root:current train perplexity5.213049411773682
INFO:root:current mean train loss 2099.944643225609
INFO:root:current train perplexity5.23684549331665
INFO:root:current mean train loss 2103.5136234521456
INFO:root:current train perplexity5.247796058654785
INFO:root:current mean train loss 2106.0164762537224
INFO:root:current train perplexity5.260140419006348
INFO:root:current mean train loss 2106.571599975022
INFO:root:current train perplexity5.2629852294921875

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:40<00:00, 460.68s/it]
INFO:root:final mean train loss: 2105.489678071715
INFO:root:final train perplexity: 5.262024402618408
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.06s/it]
INFO:root:eval mean loss: 2021.1654624127327
INFO:root:eval perplexity: 5.127407073974609
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.52s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.52s/it]
INFO:root:eval mean loss: 2461.2448124445923
INFO:root:eval perplexity: 7.484795093536377
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/45
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 45/100 [6:38:22<8:05:04, 529.18s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2101.160327911377
INFO:root:current train perplexity5.188661098480225
INFO:root:current mean train loss 2079.641884408346
INFO:root:current train perplexity5.105587005615234
INFO:root:current mean train loss 2062.015124696674
INFO:root:current train perplexity5.0652570724487305
INFO:root:current mean train loss 2061.920859535972
INFO:root:current train perplexity5.068868160247803
INFO:root:current mean train loss 2054.43141647865
INFO:root:current train perplexity5.0572357177734375
INFO:root:current mean train loss 2062.2423483124862
INFO:root:current train perplexity5.084743499755859
INFO:root:current mean train loss 2092.840199665851
INFO:root:current train perplexity5.19696044921875
INFO:root:current mean train loss 2095.2289858513477
INFO:root:current train perplexity5.22182035446167
INFO:root:current mean train loss 2101.437662053991
INFO:root:current train perplexity5.238413333892822
INFO:root:current mean train loss 2104.401661726449
INFO:root:current train perplexity5.245450496673584
INFO:root:current mean train loss 2102.2287651578285
INFO:root:current train perplexity5.24131965637207
INFO:root:current mean train loss 2099.8253445445057
INFO:root:current train perplexity5.230114936828613
INFO:root:current mean train loss 2094.429815364789
INFO:root:current train perplexity5.211205005645752
INFO:root:current mean train loss 2094.312129045861
INFO:root:current train perplexity5.215984344482422
INFO:root:current mean train loss 2091.2333445731406
INFO:root:current train perplexity5.20640230178833
INFO:root:current mean train loss 2088.3273740022078
INFO:root:current train perplexity5.196712493896484
INFO:root:current mean train loss 2087.1367968779346
INFO:root:current train perplexity5.189549922943115
INFO:root:current mean train loss 2083.9401241657147
INFO:root:current train perplexity5.1732892990112305
INFO:root:current mean train loss 2081.613166972803
INFO:root:current train perplexity5.161869049072266
INFO:root:current mean train loss 2078.660088129296
INFO:root:current train perplexity5.149735450744629

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.43s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.43s/it]
INFO:root:final mean train loss: 2077.776577347887
INFO:root:final train perplexity: 5.1482648849487305
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.16s/it]
INFO:root:eval mean loss: 2000.34148434037
INFO:root:eval perplexity: 5.04177713394165
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.60s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.60s/it]
INFO:root:eval mean loss: 2442.0763476216202
INFO:root:eval perplexity: 7.368375778198242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/46
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [6:47:20<7:58:29, 531.66s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2016.3796251085068
INFO:root:current train perplexity4.913046360015869
INFO:root:current mean train loss 2010.3575250615072
INFO:root:current train perplexity4.88198709487915
INFO:root:current mean train loss 2002.694074854732
INFO:root:current train perplexity4.872957229614258
INFO:root:current mean train loss 2008.9486423602568
INFO:root:current train perplexity4.881921768188477
INFO:root:current mean train loss 2004.3354558171452
INFO:root:current train perplexity4.884214401245117
INFO:root:current mean train loss 2004.4004744564195
INFO:root:current train perplexity4.871044635772705
INFO:root:current mean train loss 2034.3759222492772
INFO:root:current train perplexity4.983882427215576
INFO:root:current mean train loss 2044.1870545449544
INFO:root:current train perplexity5.023580551147461
INFO:root:current mean train loss 2047.9920152713978
INFO:root:current train perplexity5.046042442321777
INFO:root:current mean train loss 2051.387880471139
INFO:root:current train perplexity5.056132793426514
INFO:root:current mean train loss 2056.454215163549
INFO:root:current train perplexity5.075679779052734
INFO:root:current mean train loss 2059.0700784888336
INFO:root:current train perplexity5.083280086517334
INFO:root:current mean train loss 2057.6069321643554
INFO:root:current train perplexity5.073303699493408
INFO:root:current mean train loss 2055.8113006879075
INFO:root:current train perplexity5.061146259307861
INFO:root:current mean train loss 2054.021961776249
INFO:root:current train perplexity5.048877716064453
INFO:root:current mean train loss 2052.5606895606024
INFO:root:current train perplexity5.040125370025635
INFO:root:current mean train loss 2055.7188107083766
INFO:root:current train perplexity5.050648212432861
INFO:root:current mean train loss 2054.6029880016054
INFO:root:current train perplexity5.045835494995117
INFO:root:current mean train loss 2050.989778671792
INFO:root:current train perplexity5.037827491760254
INFO:root:current mean train loss 2049.408321744562
INFO:root:current train perplexity5.032395839691162

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.84s/it]
INFO:root:final mean train loss: 2049.000813124941
INFO:root:final train perplexity: 5.032743453979492
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.92s/it]
INFO:root:eval mean loss: 2023.2581865026596
INFO:root:eval perplexity: 5.136091709136963
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.62s/it]
INFO:root:eval mean loss: 2464.966264007785
INFO:root:eval perplexity: 7.50761079788208
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/47
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 47/100 [6:56:04<7:47:30, 529.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2026.4724781269929
INFO:root:current train perplexity4.906251907348633
INFO:root:current mean train loss 2008.4423877446338
INFO:root:current train perplexity4.865952491760254
INFO:root:current mean train loss 1998.6747452908714
INFO:root:current train perplexity4.834808826446533
INFO:root:current mean train loss 1994.7065303936677
INFO:root:current train perplexity4.836866855621338
INFO:root:current mean train loss 1992.5053615340266
INFO:root:current train perplexity4.832459449768066
INFO:root:current mean train loss 1994.4611665349341
INFO:root:current train perplexity4.835762023925781
INFO:root:current mean train loss 1994.514219442548
INFO:root:current train perplexity4.831603527069092
INFO:root:current mean train loss 1994.3130496223469
INFO:root:current train perplexity4.8295817375183105
INFO:root:current mean train loss 2000.5084848382692
INFO:root:current train perplexity4.848124027252197
INFO:root:current mean train loss 2001.400862026788
INFO:root:current train perplexity4.844393730163574
INFO:root:current mean train loss 2001.4067610721554
INFO:root:current train perplexity4.842933177947998
INFO:root:current mean train loss 2003.5878742198913
INFO:root:current train perplexity4.845051288604736
INFO:root:current mean train loss 2003.2660308978957
INFO:root:current train perplexity4.841070175170898
INFO:root:current mean train loss 2002.549183857799
INFO:root:current train perplexity4.842466831207275
INFO:root:current mean train loss 2002.878519992803
INFO:root:current train perplexity4.846480369567871
INFO:root:current mean train loss 2003.7841334718935
INFO:root:current train perplexity4.850316524505615
INFO:root:current mean train loss 2002.699288268252
INFO:root:current train perplexity4.849819183349609
INFO:root:current mean train loss 2003.3618600609836
INFO:root:current train perplexity4.8486833572387695
INFO:root:current mean train loss 2002.103639496139
INFO:root:current train perplexity4.847053050994873

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.80s/it]
INFO:root:final mean train loss: 2000.754744613886
INFO:root:final train perplexity: 4.844846248626709
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.34s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.34s/it]
INFO:root:eval mean loss: 1985.8994763962767
INFO:root:eval perplexity: 4.9832329750061035
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.42s/it]
INFO:root:eval mean loss: 2428.500911198609
INFO:root:eval perplexity: 7.287020206451416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/48
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 48/100 [7:04:50<7:38:03, 528.52s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1973.1464436848958
INFO:root:current train perplexity4.754350662231445
INFO:root:current mean train loss 2033.9260996942935
INFO:root:current train perplexity4.94564151763916
INFO:root:current mean train loss 2111.0505615234374
INFO:root:current train perplexity5.300313949584961
INFO:root:current mean train loss 2117.641951109871
INFO:root:current train perplexity5.313844680786133
INFO:root:current mean train loss 2109.561033391378
INFO:root:current train perplexity5.274294376373291
INFO:root:current mean train loss 2099.236504712151
INFO:root:current train perplexity5.234469890594482
INFO:root:current mean train loss 2091.3815755208334
INFO:root:current train perplexity5.203520774841309
INFO:root:current mean train loss 2085.268115234375
INFO:root:current train perplexity5.176948070526123
INFO:root:current mean train loss 2072.001451213813
INFO:root:current train perplexity5.131590843200684
INFO:root:current mean train loss 2063.601502999061
INFO:root:current train perplexity5.098938941955566
INFO:root:current mean train loss 2057.2374850869764
INFO:root:current train perplexity5.077046871185303
INFO:root:current mean train loss 2052.2799312027046
INFO:root:current train perplexity5.053188323974609
INFO:root:current mean train loss 2047.1013102213542
INFO:root:current train perplexity5.0291032791137695
INFO:root:current mean train loss 2041.0040952501188
INFO:root:current train perplexity5.005713939666748
INFO:root:current mean train loss 2038.0004282381847
INFO:root:current train perplexity4.9897990226745605
INFO:root:current mean train loss 2034.1108527356641
INFO:root:current train perplexity4.9761481285095215
INFO:root:current mean train loss 2030.2476742393092
INFO:root:current train perplexity4.960544586181641
INFO:root:current mean train loss 2026.7128037878097
INFO:root:current train perplexity4.946481704711914
INFO:root:current mean train loss 2023.314132043087
INFO:root:current train perplexity4.934311389923096
INFO:root:current mean train loss 2022.257899574698
INFO:root:current train perplexity4.926065444946289

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.18s/it]
INFO:root:final mean train loss: 2020.5409076515616
INFO:root:final train perplexity: 4.921041488647461
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.05s/it]
INFO:root:eval mean loss: 1958.3858781097629
INFO:root:eval perplexity: 4.8735737800598145
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.33s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.33s/it]
INFO:root:eval mean loss: 2398.4911187354555
INFO:root:eval perplexity: 7.110352993011475
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/49
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [7:13:35<7:28:18, 527.42s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1951.1646537780762
INFO:root:current train perplexity4.715846061706543
INFO:root:current mean train loss 1955.4675246729996
INFO:root:current train perplexity4.6645684242248535
INFO:root:current mean train loss 1966.1571723674906
INFO:root:current train perplexity4.687376499176025
INFO:root:current mean train loss 1967.4730268731175
INFO:root:current train perplexity4.698066711425781
INFO:root:current mean train loss 1975.3381175288448
INFO:root:current train perplexity4.7253098487854
INFO:root:current mean train loss 1975.094017315628
INFO:root:current train perplexity4.715181827545166
INFO:root:current mean train loss 1977.456344411343
INFO:root:current train perplexity4.725893974304199
INFO:root:current mean train loss 1977.7134237654222
INFO:root:current train perplexity4.730093955993652
INFO:root:current mean train loss 1975.0411729079026
INFO:root:current train perplexity4.722986221313477
INFO:root:current mean train loss 1973.994192491785
INFO:root:current train perplexity4.72061824798584
INFO:root:current mean train loss 1971.0076690200688
INFO:root:current train perplexity4.71523904800415
INFO:root:current mean train loss 1969.3901993714458
INFO:root:current train perplexity4.712669849395752
INFO:root:current mean train loss 1968.2064482453582
INFO:root:current train perplexity4.7087016105651855
INFO:root:current mean train loss 1980.036324715829
INFO:root:current train perplexity4.756215572357178
INFO:root:current mean train loss 1991.4741917615497
INFO:root:current train perplexity4.800816535949707
INFO:root:current mean train loss 1998.4040742480724
INFO:root:current train perplexity4.828083038330078
INFO:root:current mean train loss 1999.8362200867896
INFO:root:current train perplexity4.840771675109863
INFO:root:current mean train loss 2000.5344439147527
INFO:root:current train perplexity4.842101097106934
INFO:root:current mean train loss 2000.7368329976844
INFO:root:current train perplexity4.841782569885254
INFO:root:current mean train loss 2000.2775348797595
INFO:root:current train perplexity4.840119361877441

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.06s/it]
INFO:root:final mean train loss: 1999.4088831914535
INFO:root:final train perplexity: 4.839707374572754
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.92s/it]
INFO:root:eval mean loss: 1971.142454756067
INFO:root:eval perplexity: 4.924113750457764
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.38s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.38s/it]
INFO:root:eval mean loss: 2412.9141962578956
INFO:root:eval perplexity: 7.19472074508667
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/50
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 50/100 [7:22:26<7:20:17, 528.35s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1957.7444121691644
INFO:root:current train perplexity4.723301887512207
INFO:root:current mean train loss 1966.0361623059982
INFO:root:current train perplexity4.696576118469238
INFO:root:current mean train loss 1967.02229523563
INFO:root:current train perplexity4.707582473754883
INFO:root:current mean train loss 1963.2082313165965
INFO:root:current train perplexity4.706875324249268
INFO:root:current mean train loss 1963.6041303265067
INFO:root:current train perplexity4.707901477813721
INFO:root:current mean train loss 1960.3912787098702
INFO:root:current train perplexity4.700727939605713
INFO:root:current mean train loss 1961.2101266446577
INFO:root:current train perplexity4.695698261260986
INFO:root:current mean train loss 1961.2593141767147
INFO:root:current train perplexity4.692221164703369
INFO:root:current mean train loss 1960.162335399183
INFO:root:current train perplexity4.686115264892578
INFO:root:current mean train loss 1959.3203600932725
INFO:root:current train perplexity4.685913562774658
INFO:root:current mean train loss 1958.1979147271954
INFO:root:current train perplexity4.686205863952637
INFO:root:current mean train loss 1961.0563445327798
INFO:root:current train perplexity4.697707176208496
INFO:root:current mean train loss 1963.8634958748248
INFO:root:current train perplexity4.705603122711182
INFO:root:current mean train loss 1962.2380982802654
INFO:root:current train perplexity4.702523708343506
INFO:root:current mean train loss 1960.967075555879
INFO:root:current train perplexity4.698599338531494
INFO:root:current mean train loss 1960.0080373331837
INFO:root:current train perplexity4.695987701416016
INFO:root:current mean train loss 1959.358335218551
INFO:root:current train perplexity4.693132400512695
INFO:root:current mean train loss 1959.3052205892207
INFO:root:current train perplexity4.691617488861084
INFO:root:current mean train loss 1958.779031872169
INFO:root:current train perplexity4.687442302703857
INFO:root:current mean train loss 1959.7706280664763
INFO:root:current train perplexity4.689702033996582

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 467.00s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:46<00:00, 467.00s/it]
INFO:root:final mean train loss: 1959.264876234369
INFO:root:final train perplexity: 4.6888813972473145
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:34<00:00, 34.05s/it]
INFO:root:eval mean loss: 1970.643162937029
INFO:root:eval perplexity: 4.922125339508057
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.90s/it]
INFO:root:eval mean loss: 2417.103532939938
INFO:root:eval perplexity: 7.219414710998535
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/51
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [7:31:20<7:12:54, 530.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1932.742655436198
INFO:root:current train perplexity4.622097015380859
INFO:root:current mean train loss 1935.6219666262707
INFO:root:current train perplexity4.586820125579834
INFO:root:current mean train loss 1933.4755483068022
INFO:root:current train perplexity4.591943264007568
INFO:root:current mean train loss 1927.6061634834998
INFO:root:current train perplexity4.579535007476807
INFO:root:current mean train loss 1935.5519458950846
INFO:root:current train perplexity4.588695526123047
INFO:root:current mean train loss 1940.5816365703677
INFO:root:current train perplexity4.6090569496154785
INFO:root:current mean train loss 1941.816782725108
INFO:root:current train perplexity4.619776725769043
INFO:root:current mean train loss 1942.4211588329185
INFO:root:current train perplexity4.61793851852417
INFO:root:current mean train loss 1941.9984377537257
INFO:root:current train perplexity4.616355895996094
INFO:root:current mean train loss 1942.8605241795258
INFO:root:current train perplexity4.619818210601807
INFO:root:current mean train loss 1944.7162827139277
INFO:root:current train perplexity4.619350910186768
INFO:root:current mean train loss 1944.8009844562407
INFO:root:current train perplexity4.622162818908691
INFO:root:current mean train loss 1944.836314606629
INFO:root:current train perplexity4.624420166015625
INFO:root:current mean train loss 1943.8375079712093
INFO:root:current train perplexity4.620569705963135
INFO:root:current mean train loss 1944.2753101884912
INFO:root:current train perplexity4.62236213684082
INFO:root:current mean train loss 1943.4081919001437
INFO:root:current train perplexity4.618921279907227
INFO:root:current mean train loss 1940.594782981552
INFO:root:current train perplexity4.614362716674805
INFO:root:current mean train loss 1941.538682464565
INFO:root:current train perplexity4.615642547607422
INFO:root:current mean train loss 1940.5116899005852
INFO:root:current train perplexity4.613195419311523
INFO:root:current mean train loss 1939.1106753654906
INFO:root:current train perplexity4.613109588623047

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:44<00:00, 464.55s/it]
INFO:root:final mean train loss: 1938.3914799538754
INFO:root:final train perplexity: 4.612325668334961
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.69s/it]
INFO:root:eval mean loss: 1936.420889780031
INFO:root:eval perplexity: 4.787764072418213
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.89s/it]
INFO:root:eval mean loss: 2381.0311210037125
INFO:root:eval perplexity: 7.0095438957214355
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/52
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [7:40:09<7:03:54, 529.89s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1887.5202313158886
INFO:root:current train perplexity4.498937606811523
INFO:root:current mean train loss 1907.2835693359375
INFO:root:current train perplexity4.546334266662598
INFO:root:current mean train loss 1913.9063198777053
INFO:root:current train perplexity4.558719635009766
INFO:root:current mean train loss 1917.841377756303
INFO:root:current train perplexity4.553739547729492
INFO:root:current mean train loss 1916.6720152671294
INFO:root:current train perplexity4.549746513366699
INFO:root:current mean train loss 1919.4835927449615
INFO:root:current train perplexity4.551547050476074
INFO:root:current mean train loss 1918.7369256082427
INFO:root:current train perplexity4.549665451049805
INFO:root:current mean train loss 1921.2766523300306
INFO:root:current train perplexity4.548641204833984
INFO:root:current mean train loss 1922.945166236817
INFO:root:current train perplexity4.553860664367676
INFO:root:current mean train loss 1924.4745844145393
INFO:root:current train perplexity4.559578895568848
INFO:root:current mean train loss 1926.2368342152154
INFO:root:current train perplexity4.563226222991943
INFO:root:current mean train loss 1929.244172716181
INFO:root:current train perplexity4.57425594329834
INFO:root:current mean train loss 1932.6072754477116
INFO:root:current train perplexity4.583651065826416
INFO:root:current mean train loss 1933.997467592671
INFO:root:current train perplexity4.592132091522217
INFO:root:current mean train loss 1935.2843035687006
INFO:root:current train perplexity4.596304893493652
INFO:root:current mean train loss 1935.6315206984366
INFO:root:current train perplexity4.597009658813477
INFO:root:current mean train loss 1935.1025932434409
INFO:root:current train perplexity4.596823692321777
INFO:root:current mean train loss 1935.7209337783274
INFO:root:current train perplexity4.5981855392456055
INFO:root:current mean train loss 1935.6208078604204
INFO:root:current train perplexity4.595441818237305
INFO:root:current mean train loss 1933.7288022409227
INFO:root:current train perplexity4.595395565032959

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.20s/it]
INFO:root:final mean train loss: 1933.7288022409227
INFO:root:final train perplexity: 4.595395565032959
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.90s/it]
INFO:root:eval mean loss: 1932.3148093798482
INFO:root:eval perplexity: 4.771891117095947
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.05s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.05s/it]
INFO:root:eval mean loss: 2376.9852662864305
INFO:root:eval perplexity: 6.986391067504883
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/53
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [7:48:53<6:53:32, 527.93s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1895.2571215820312
INFO:root:current train perplexity4.521603584289551
INFO:root:current mean train loss 1900.8528228759765
INFO:root:current train perplexity4.512814521789551
INFO:root:current mean train loss 1909.0304125976563
INFO:root:current train perplexity4.521862030029297
INFO:root:current mean train loss 1906.5004888916017
INFO:root:current train perplexity4.523906707763672
INFO:root:current mean train loss 1909.0570375976563
INFO:root:current train perplexity4.524300575256348
INFO:root:current mean train loss 1910.2554994710285
INFO:root:current train perplexity4.515631198883057
INFO:root:current mean train loss 1910.092606201172
INFO:root:current train perplexity4.513869762420654
INFO:root:current mean train loss 1909.2593167114258
INFO:root:current train perplexity4.511653423309326
INFO:root:current mean train loss 1910.3907927788628
INFO:root:current train perplexity4.514186382293701
INFO:root:current mean train loss 1911.3955859375
INFO:root:current train perplexity4.515273094177246
INFO:root:current mean train loss 1910.6661472389915
INFO:root:current train perplexity4.51513671875
INFO:root:current mean train loss 1912.2373875935873
INFO:root:current train perplexity4.518928050994873
INFO:root:current mean train loss 1911.2469642052283
INFO:root:current train perplexity4.515292167663574
INFO:root:current mean train loss 1912.372046334403
INFO:root:current train perplexity4.518106937408447
INFO:root:current mean train loss 1911.7946571451823
INFO:root:current train perplexity4.5168538093566895
INFO:root:current mean train loss 1912.2746320343017
INFO:root:current train perplexity4.5183634757995605
INFO:root:current mean train loss 1913.298223805147
INFO:root:current train perplexity4.5183939933776855
INFO:root:current mean train loss 1912.4964620632595
INFO:root:current train perplexity4.514732837677002
INFO:root:current mean train loss 1912.9334560032894
INFO:root:current train perplexity4.516298294067383

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.63s/it]
INFO:root:final mean train loss: 1910.9973146685795
INFO:root:final train perplexity: 4.5137457847595215
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.15s/it]
INFO:root:eval mean loss: 1949.02353792664
INFO:root:eval perplexity: 4.8368120193481445
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.01s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.01s/it]
INFO:root:eval mean loss: 2392.8899925718915
INFO:root:eval perplexity: 7.077857971191406
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/54
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [7:57:41<6:44:47, 527.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1900.0540340647979
INFO:root:current train perplexity4.560358047485352
INFO:root:current mean train loss 1909.0152848724626
INFO:root:current train perplexity4.486217975616455
INFO:root:current mean train loss 1906.858175673243
INFO:root:current train perplexity4.483294486999512
INFO:root:current mean train loss 1902.8249446255174
INFO:root:current train perplexity4.478871822357178
INFO:root:current mean train loss 1898.32533582509
INFO:root:current train perplexity4.472050666809082
INFO:root:current mean train loss 1903.7889269712584
INFO:root:current train perplexity4.4822587966918945
INFO:root:current mean train loss 1905.9330445325163
INFO:root:current train perplexity4.483583450317383
INFO:root:current mean train loss 1906.8177512367067
INFO:root:current train perplexity4.4868879318237305
INFO:root:current mean train loss 1908.3301919776047
INFO:root:current train perplexity4.4900431632995605
INFO:root:current mean train loss 1911.371552478786
INFO:root:current train perplexity4.499805450439453
INFO:root:current mean train loss 1909.519569539508
INFO:root:current train perplexity4.498656272888184
INFO:root:current mean train loss 1909.6131033355248
INFO:root:current train perplexity4.499027729034424
INFO:root:current mean train loss 1908.4159328739665
INFO:root:current train perplexity4.497249126434326
INFO:root:current mean train loss 1908.4293430707812
INFO:root:current train perplexity4.498330593109131
INFO:root:current mean train loss 1908.2715715557736
INFO:root:current train perplexity4.4988627433776855
INFO:root:current mean train loss 1907.6213637209285
INFO:root:current train perplexity4.498235702514648
INFO:root:current mean train loss 1905.6410344677645
INFO:root:current train perplexity4.494441032409668
INFO:root:current mean train loss 1904.752063109143
INFO:root:current train perplexity4.492663860321045
INFO:root:current mean train loss 1905.507797921432
INFO:root:current train perplexity4.495543956756592
INFO:root:current mean train loss 1906.5933969703638
INFO:root:current train perplexity4.496476650238037

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.26s/it]
INFO:root:final mean train loss: 1906.3503966454118
INFO:root:final train perplexity: 4.49723482131958
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.83s/it]
INFO:root:eval mean loss: 1947.9074507909463
INFO:root:eval perplexity: 4.832448482513428
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.70s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.70s/it]
INFO:root:eval mean loss: 2394.50091509447
INFO:root:eval perplexity: 7.087188243865967
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/55
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [8:06:31<6:36:27, 528.62s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1865.1334623448988
INFO:root:current train perplexity4.411803722381592
INFO:root:current mean train loss 1888.2962582716302
INFO:root:current train perplexity4.461620807647705
INFO:root:current mean train loss 1896.1906999115251
INFO:root:current train perplexity4.462552070617676
INFO:root:current mean train loss 1897.076107550524
INFO:root:current train perplexity4.454503059387207
INFO:root:current mean train loss 1891.9935569938975
INFO:root:current train perplexity4.446460723876953
INFO:root:current mean train loss 1891.5503974371636
INFO:root:current train perplexity4.43829870223999
INFO:root:current mean train loss 1890.9738059058927
INFO:root:current train perplexity4.442424774169922
INFO:root:current mean train loss 1890.5369342523309
INFO:root:current train perplexity4.44468879699707
INFO:root:current mean train loss 1891.9854870986023
INFO:root:current train perplexity4.448894023895264
INFO:root:current mean train loss 1894.7434540775143
INFO:root:current train perplexity4.456204414367676
INFO:root:current mean train loss 1895.5489713274071
INFO:root:current train perplexity4.459338188171387
INFO:root:current mean train loss 1895.1117647362764
INFO:root:current train perplexity4.456218719482422
INFO:root:current mean train loss 1894.6303274689462
INFO:root:current train perplexity4.45566987991333
INFO:root:current mean train loss 1894.945485448194
INFO:root:current train perplexity4.456789016723633
INFO:root:current mean train loss 1895.5870467735301
INFO:root:current train perplexity4.458870887756348
INFO:root:current mean train loss 1896.3803071938407
INFO:root:current train perplexity4.460210800170898
INFO:root:current mean train loss 1894.9443560335305
INFO:root:current train perplexity4.456171035766602
INFO:root:current mean train loss 1895.009896143085
INFO:root:current train perplexity4.454965114593506
INFO:root:current mean train loss 1893.095602287201
INFO:root:current train perplexity4.4513983726501465
INFO:root:current mean train loss 1893.0911077521087
INFO:root:current train perplexity4.451205730438232

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 476.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:56<00:00, 476.19s/it]
INFO:root:final mean train loss: 1893.373542204687
INFO:root:final train perplexity: 4.451441764831543
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.28s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.28s/it]
INFO:root:eval mean loss: 1916.5490527863199
INFO:root:eval perplexity: 4.7114338874816895
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.79s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.79s/it]
INFO:root:eval mean loss: 2364.84189730164
INFO:root:eval perplexity: 6.9173502922058105
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/56
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 56/100 [8:15:36<6:31:22, 533.69s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1872.6304668351715
INFO:root:current train perplexity4.39777135848999
INFO:root:current mean train loss 1859.9344846207575
INFO:root:current train perplexity4.367512226104736
INFO:root:current mean train loss 1872.3937686752988
INFO:root:current train perplexity4.383670330047607
INFO:root:current mean train loss 1881.759571912282
INFO:root:current train perplexity4.399866580963135
INFO:root:current mean train loss 1884.5553341207906
INFO:root:current train perplexity4.409045696258545
INFO:root:current mean train loss 1879.8567809504736
INFO:root:current train perplexity4.395386695861816
INFO:root:current mean train loss 1882.100355297739
INFO:root:current train perplexity4.401941776275635
INFO:root:current mean train loss 1881.7435913898655
INFO:root:current train perplexity4.398993015289307
INFO:root:current mean train loss 1881.165405129994
INFO:root:current train perplexity4.401966094970703
INFO:root:current mean train loss 1880.0233375075989
INFO:root:current train perplexity4.398939609527588
INFO:root:current mean train loss 1880.4112817127289
INFO:root:current train perplexity4.401603698730469
INFO:root:current mean train loss 1881.7457301904594
INFO:root:current train perplexity4.401829242706299
INFO:root:current mean train loss 1880.3178783145358
INFO:root:current train perplexity4.398619174957275
INFO:root:current mean train loss 1881.8302730218645
INFO:root:current train perplexity4.40376615524292
INFO:root:current mean train loss 1882.5012229745919
INFO:root:current train perplexity4.404550552368164
INFO:root:current mean train loss 1883.0368831002427
INFO:root:current train perplexity4.4052042961120605
INFO:root:current mean train loss 1882.658241794154
INFO:root:current train perplexity4.404991149902344
INFO:root:current mean train loss 1883.4227299801898
INFO:root:current train perplexity4.4083991050720215
INFO:root:current mean train loss 1882.1182138534703
INFO:root:current train perplexity4.406905651092529
INFO:root:current mean train loss 1881.525913568963
INFO:root:current train perplexity4.408203125

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:45<00:00, 465.63s/it]
INFO:root:final mean train loss: 1880.8775588904616
INFO:root:final train perplexity: 4.4077887535095215
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.57s/it]
INFO:root:eval mean loss: 1902.9780797214373
INFO:root:eval perplexity: 4.660007476806641
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.69s/it]
INFO:root:eval mean loss: 2350.4642230094746
INFO:root:eval perplexity: 6.836489200592041
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/57
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 57/100 [8:24:28<6:21:55, 532.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1876.6604757869945
INFO:root:current train perplexity4.403299808502197
INFO:root:current mean train loss 1881.8599359421503
INFO:root:current train perplexity4.4007697105407715
INFO:root:current mean train loss 1883.050343983209
INFO:root:current train perplexity4.420079231262207
INFO:root:current mean train loss 1885.6815099301546
INFO:root:current train perplexity4.431232452392578
INFO:root:current mean train loss 1886.31495183961
INFO:root:current train perplexity4.428379535675049
INFO:root:current mean train loss 1892.1842950095593
INFO:root:current train perplexity4.440433979034424
INFO:root:current mean train loss 1898.0695568701465
INFO:root:current train perplexity4.4605841636657715
INFO:root:current mean train loss 1902.1291001637776
INFO:root:current train perplexity4.4848198890686035
INFO:root:current mean train loss 1906.6321152366252
INFO:root:current train perplexity4.5021138191223145
INFO:root:current mean train loss 1912.2634408493673
INFO:root:current train perplexity4.522369384765625
INFO:root:current mean train loss 1920.4321002174406
INFO:root:current train perplexity4.547017574310303
INFO:root:current mean train loss 1921.2334431687445
INFO:root:current train perplexity4.553625583648682
INFO:root:current mean train loss 1922.7418909885155
INFO:root:current train perplexity4.558647155761719
INFO:root:current mean train loss 1922.4735085113705
INFO:root:current train perplexity4.559295177459717
INFO:root:current mean train loss 1923.8846120392593
INFO:root:current train perplexity4.562596797943115
INFO:root:current mean train loss 1924.993421126385
INFO:root:current train perplexity4.564951419830322
INFO:root:current mean train loss 1924.240871950877
INFO:root:current train perplexity4.561371803283691
INFO:root:current mean train loss 1925.2431377566238
INFO:root:current train perplexity4.562222480773926
INFO:root:current mean train loss 1925.6189356932548
INFO:root:current train perplexity4.563061714172363
INFO:root:current mean train loss 1926.0027903114876
INFO:root:current train perplexity4.564688682556152

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:39<00:00, 459.06s/it]
INFO:root:final mean train loss: 1925.4392371781234
INFO:root:final train perplexity: 4.565450191497803
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.24s/it]
INFO:root:eval mean loss: 1950.7651566309287
INFO:root:eval perplexity: 4.843630313873291
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.45s/it]
INFO:root:eval mean loss: 2392.852819564495
INFO:root:eval perplexity: 7.07764196395874
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/58
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [8:33:13<6:11:23, 530.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1954.0755485983457
INFO:root:current train perplexity4.665111064910889
INFO:root:current mean train loss 1937.2978423247466
INFO:root:current train perplexity4.625654697418213
INFO:root:current mean train loss 1934.0009632846766
INFO:root:current train perplexity4.609215259552002
INFO:root:current mean train loss 1932.2533304586038
INFO:root:current train perplexity4.607649326324463
INFO:root:current mean train loss 1928.4387617288176
INFO:root:current train perplexity4.587488651275635
INFO:root:current mean train loss 1927.450608890892
INFO:root:current train perplexity4.579771041870117
INFO:root:current mean train loss 1927.2413993000114
INFO:root:current train perplexity4.579990386962891
INFO:root:current mean train loss 1927.4517696307723
INFO:root:current train perplexity4.584238529205322
INFO:root:current mean train loss 1930.5056548210187
INFO:root:current train perplexity4.585747241973877
INFO:root:current mean train loss 1929.9540881781409
INFO:root:current train perplexity4.58259391784668
INFO:root:current mean train loss 1928.742184124784
INFO:root:current train perplexity4.581000804901123
INFO:root:current mean train loss 1931.9447072990836
INFO:root:current train perplexity4.590364933013916
INFO:root:current mean train loss 1935.838798410141
INFO:root:current train perplexity4.599308013916016
INFO:root:current mean train loss 1936.894940383856
INFO:root:current train perplexity4.60537052154541
INFO:root:current mean train loss 1937.335933883102
INFO:root:current train perplexity4.607837677001953
INFO:root:current mean train loss 1940.4385002834188
INFO:root:current train perplexity4.616766929626465
INFO:root:current mean train loss 1942.4502019050212
INFO:root:current train perplexity4.626120567321777
INFO:root:current mean train loss 1943.7447210231749
INFO:root:current train perplexity4.629106044769287
INFO:root:current mean train loss 1944.776236115716
INFO:root:current train perplexity4.635152339935303

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.37s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.37s/it]
INFO:root:final mean train loss: 1946.2638150598445
INFO:root:final train perplexity: 4.641050338745117
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.66s/it]
INFO:root:eval mean loss: 1950.5348060553802
INFO:root:eval perplexity: 4.8427276611328125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.68s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.68s/it]
INFO:root:eval mean loss: 2392.7739240497563
INFO:root:eval perplexity: 7.0771870613098145
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/59
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [8:42:11<6:04:14, 533.04s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2042.6957397460938
INFO:root:current train perplexity4.833381175994873
INFO:root:current mean train loss 2025.2522726619945
INFO:root:current train perplexity4.9513044357299805
INFO:root:current mean train loss 2050.172938582921
INFO:root:current train perplexity5.049630165100098
INFO:root:current mean train loss 2053.9407081856634
INFO:root:current train perplexity5.0533928871154785
INFO:root:current mean train loss 2051.825399673993
INFO:root:current train perplexity5.043587684631348
INFO:root:current mean train loss 2048.74554248825
INFO:root:current train perplexity5.036571979522705
INFO:root:current mean train loss 2049.952601233194
INFO:root:current train perplexity5.0406317710876465
INFO:root:current mean train loss 2050.579939187422
INFO:root:current train perplexity5.041545391082764
INFO:root:current mean train loss 2049.1099031595813
INFO:root:current train perplexity5.0304155349731445
INFO:root:current mean train loss 2050.0533562298624
INFO:root:current train perplexity5.031282901763916
INFO:root:current mean train loss 2052.8319971385354
INFO:root:current train perplexity5.047035217285156
INFO:root:current mean train loss 2059.505737193916
INFO:root:current train perplexity5.067288875579834
INFO:root:current mean train loss 2057.6976833248295
INFO:root:current train perplexity5.0580058097839355
INFO:root:current mean train loss 2056.5507041825676
INFO:root:current train perplexity5.0598578453063965
INFO:root:current mean train loss 2052.6048316683477
INFO:root:current train perplexity5.048055171966553
INFO:root:current mean train loss 2050.0785137232388
INFO:root:current train perplexity5.03795051574707
INFO:root:current mean train loss 2045.3021911544895
INFO:root:current train perplexity5.022637367248535
INFO:root:current mean train loss 2041.6328056864397
INFO:root:current train perplexity5.00626802444458
INFO:root:current mean train loss 2038.891075278228
INFO:root:current train perplexity4.993130683898926
INFO:root:current mean train loss 2036.6886012000116
INFO:root:current train perplexity4.984720230102539

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.66s/it]
INFO:root:final mean train loss: 2034.8249709321224
INFO:root:final train perplexity: 4.976791858673096
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.42s/it]
INFO:root:eval mean loss: 2009.5725625761856
INFO:root:eval perplexity: 5.079558372497559
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.90s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.90s/it]
INFO:root:eval mean loss: 2456.3604056716813
INFO:root:eval perplexity: 7.454955101013184
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/60
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [8:50:45<5:51:22, 527.07s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2036.4819400185033
INFO:root:current train perplexity5.025046348571777
INFO:root:current mean train loss 2014.6688078551733
INFO:root:current train perplexity4.908376216888428
INFO:root:current mean train loss 2032.8687030670305
INFO:root:current train perplexity4.950410842895508
INFO:root:current mean train loss 2020.3613671568867
INFO:root:current train perplexity4.913270473480225
INFO:root:current mean train loss 2007.0710752209502
INFO:root:current train perplexity4.871201038360596
INFO:root:current mean train loss 2001.3785089922778
INFO:root:current train perplexity4.842052936553955
INFO:root:current mean train loss 1990.7268705352635
INFO:root:current train perplexity4.813630104064941
INFO:root:current mean train loss 1983.3481063312217
INFO:root:current train perplexity4.785638809204102
INFO:root:current mean train loss 1976.0256054031688
INFO:root:current train perplexity4.757637023925781
INFO:root:current mean train loss 1970.1650143562126
INFO:root:current train perplexity4.736694812774658
INFO:root:current mean train loss 1965.7518255441532
INFO:root:current train perplexity4.719829559326172
INFO:root:current mean train loss 1961.1624194052306
INFO:root:current train perplexity4.702569961547852
INFO:root:current mean train loss 1958.0076088158198
INFO:root:current train perplexity4.68872594833374
INFO:root:current mean train loss 1954.5972350657755
INFO:root:current train perplexity4.676260471343994
INFO:root:current mean train loss 1951.461259751861
INFO:root:current train perplexity4.6623029708862305
INFO:root:current mean train loss 1948.636825230029
INFO:root:current train perplexity4.650403022766113
INFO:root:current mean train loss 1946.357330793507
INFO:root:current train perplexity4.6414361000061035
INFO:root:current mean train loss 1943.4095540648632
INFO:root:current train perplexity4.630282878875732
INFO:root:current mean train loss 1940.3697501712609
INFO:root:current train perplexity4.620929718017578
INFO:root:current mean train loss 1938.486913031995
INFO:root:current train perplexity4.612106800079346

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.67s/it]
INFO:root:final mean train loss: 1936.9369520378787
INFO:root:final train perplexity: 4.607037544250488
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.80s/it]
INFO:root:eval mean loss: 1915.939549655779
INFO:root:eval perplexity: 4.709112644195557
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.16s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.16s/it]
INFO:root:eval mean loss: 2362.352037362173
INFO:root:eval perplexity: 6.90327787399292
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/61
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [8:59:26<5:41:34, 525.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1870.9760843912761
INFO:root:current train perplexity4.388127326965332
INFO:root:current mean train loss 1878.2096153708064
INFO:root:current train perplexity4.415008068084717
INFO:root:current mean train loss 1889.7800215381687
INFO:root:current train perplexity4.458705425262451
INFO:root:current mean train loss 1894.524571373349
INFO:root:current train perplexity4.460101127624512
INFO:root:current mean train loss 1889.2975687849412
INFO:root:current train perplexity4.44789457321167
INFO:root:current mean train loss 1887.2987062824307
INFO:root:current train perplexity4.437971115112305
INFO:root:current mean train loss 1886.0345332307636
INFO:root:current train perplexity4.432130336761475
INFO:root:current mean train loss 1889.3062764043393
INFO:root:current train perplexity4.4370269775390625
INFO:root:current mean train loss 1890.2919984662362
INFO:root:current train perplexity4.443803787231445
INFO:root:current mean train loss 1889.631319877429
INFO:root:current train perplexity4.439188003540039
INFO:root:current mean train loss 1886.7259992798322
INFO:root:current train perplexity4.428343772888184
INFO:root:current mean train loss 1885.469633075553
INFO:root:current train perplexity4.424848556518555
INFO:root:current mean train loss 1885.7100715513754
INFO:root:current train perplexity4.429513931274414
INFO:root:current mean train loss 1886.9007085012104
INFO:root:current train perplexity4.431479454040527
INFO:root:current mean train loss 1886.0383466545254
INFO:root:current train perplexity4.431890964508057
INFO:root:current mean train loss 1887.1727566719055
INFO:root:current train perplexity4.4353413581848145
INFO:root:current mean train loss 1887.3469609118324
INFO:root:current train perplexity4.433992385864258
INFO:root:current mean train loss 1888.938238187869
INFO:root:current train perplexity4.438592910766602
INFO:root:current mean train loss 1889.8961801965252
INFO:root:current train perplexity4.438520908355713
INFO:root:current mean train loss 1890.5552589479557
INFO:root:current train perplexity4.439098834991455

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.73s/it]
INFO:root:final mean train loss: 1889.4717233631866
INFO:root:final train perplexity: 4.437765598297119
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.02s/it]
INFO:root:eval mean loss: 1918.4644675829732
INFO:root:eval perplexity: 4.718738079071045
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.45s/it]
INFO:root:eval mean loss: 2365.1261207093585
INFO:root:eval perplexity: 6.918957710266113
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/62
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/100 [9:07:58<5:30:08, 521.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1899.0751354289505
INFO:root:current train perplexity4.445235729217529
INFO:root:current mean train loss 1907.9123136233661
INFO:root:current train perplexity4.49855375289917
INFO:root:current mean train loss 1918.1883969514267
INFO:root:current train perplexity4.524708271026611
INFO:root:current mean train loss 1916.0355961180949
INFO:root:current train perplexity4.522430896759033
INFO:root:current mean train loss 1917.2605317307361
INFO:root:current train perplexity4.527446269989014
INFO:root:current mean train loss 1913.9644550233809
INFO:root:current train perplexity4.517322540283203
INFO:root:current mean train loss 1913.0933013495405
INFO:root:current train perplexity4.509398460388184
INFO:root:current mean train loss 1913.4549627012782
INFO:root:current train perplexity4.504161834716797
INFO:root:current mean train loss 1910.63755420895
INFO:root:current train perplexity4.496389865875244
INFO:root:current mean train loss 1906.1556646260985
INFO:root:current train perplexity4.4849958419799805
INFO:root:current mean train loss 1905.9798967700171
INFO:root:current train perplexity4.4867143630981445
INFO:root:current mean train loss 1905.5084546131357
INFO:root:current train perplexity4.487954616546631
INFO:root:current mean train loss 1907.0874104298123
INFO:root:current train perplexity4.493999481201172
INFO:root:current mean train loss 1906.7814049111062
INFO:root:current train perplexity4.495382308959961
INFO:root:current mean train loss 1906.5158456170961
INFO:root:current train perplexity4.495675086975098
INFO:root:current mean train loss 1905.76606918502
INFO:root:current train perplexity4.497481346130371
INFO:root:current mean train loss 1906.5651573370387
INFO:root:current train perplexity4.4972333908081055
INFO:root:current mean train loss 1906.0028828230845
INFO:root:current train perplexity4.495710849761963
INFO:root:current mean train loss 1905.9884890923292
INFO:root:current train perplexity4.4961419105529785
INFO:root:current mean train loss 1906.8285222754257
INFO:root:current train perplexity4.4984130859375

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.88s/it]
INFO:root:final mean train loss: 1906.9105657057153
INFO:root:final train perplexity: 4.499221324920654
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.98s/it]
INFO:root:eval mean loss: 1922.6661995962156
INFO:root:eval perplexity: 4.734799385070801
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.97s/it]
INFO:root:eval mean loss: 2369.0996491993574
INFO:root:eval perplexity: 6.941479206085205
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/63
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [9:16:38<5:21:14, 520.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1934.679185267857
INFO:root:current train perplexity4.559711456298828
INFO:root:current mean train loss 1924.391463694853
INFO:root:current train perplexity4.5201592445373535
INFO:root:current mean train loss 1917.3256777162906
INFO:root:current train perplexity4.514825820922852
INFO:root:current mean train loss 1915.9690310916385
INFO:root:current train perplexity4.53171443939209
INFO:root:current mean train loss 1925.2551617561503
INFO:root:current train perplexity4.56123685836792
INFO:root:current mean train loss 1931.947648540296
INFO:root:current train perplexity4.589243412017822
INFO:root:current mean train loss 1931.2305793420592
INFO:root:current train perplexity4.585611343383789
INFO:root:current mean train loss 1933.3435212370637
INFO:root:current train perplexity4.592209815979004
INFO:root:current mean train loss 1935.7265556247755
INFO:root:current train perplexity4.60599946975708
INFO:root:current mean train loss 1936.715081472495
INFO:root:current train perplexity4.608595371246338
INFO:root:current mean train loss 1936.6462416033878
INFO:root:current train perplexity4.613365173339844
INFO:root:current mean train loss 1937.015669654781
INFO:root:current train perplexity4.616509914398193
INFO:root:current mean train loss 1938.453014944482
INFO:root:current train perplexity4.6234130859375
INFO:root:current mean train loss 1945.7270193280965
INFO:root:current train perplexity4.646299839019775
INFO:root:current mean train loss 1948.5148500611183
INFO:root:current train perplexity4.654154300689697
INFO:root:current mean train loss 1949.8761224248606
INFO:root:current train perplexity4.660001277923584
INFO:root:current mean train loss 1952.5664828546032
INFO:root:current train perplexity4.667348384857178
INFO:root:current mean train loss 1954.9409203825696
INFO:root:current train perplexity4.673027515411377
INFO:root:current mean train loss 1956.9378848805147
INFO:root:current train perplexity4.6782050132751465
INFO:root:current mean train loss 1958.2042205965458
INFO:root:current train perplexity4.682279109954834

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.50s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.50s/it]
INFO:root:final mean train loss: 1957.3706990683013
INFO:root:final train perplexity: 4.681882381439209
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.98s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.98s/it]
INFO:root:eval mean loss: 1962.5794353079289
INFO:root:eval perplexity: 4.890130519866943
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.15s/it]
INFO:root:eval mean loss: 2411.4858415752437
INFO:root:eval perplexity: 7.186321258544922
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/64
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [9:25:19<5:12:32, 520.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1954.7526771282328
INFO:root:current train perplexity4.625475883483887
INFO:root:current mean train loss 1943.29622482871
INFO:root:current train perplexity4.624283790588379
INFO:root:current mean train loss 1946.9347425720002
INFO:root:current train perplexity4.645884990692139
INFO:root:current mean train loss 1944.8478738947433
INFO:root:current train perplexity4.636648654937744
INFO:root:current mean train loss 1941.3819690367525
INFO:root:current train perplexity4.6310038566589355
INFO:root:current mean train loss 1943.3700496017223
INFO:root:current train perplexity4.624105453491211
INFO:root:current mean train loss 1949.6548356190865
INFO:root:current train perplexity4.656064510345459
INFO:root:current mean train loss 1956.4540713163615
INFO:root:current train perplexity4.683177947998047
INFO:root:current mean train loss 1958.0428150267317
INFO:root:current train perplexity4.6880621910095215
INFO:root:current mean train loss 1956.9128974520327
INFO:root:current train perplexity4.687828540802002
INFO:root:current mean train loss 1956.2839103916313
INFO:root:current train perplexity4.6878437995910645
INFO:root:current mean train loss 1956.5158166925548
INFO:root:current train perplexity4.686947345733643
INFO:root:current mean train loss 1956.517999158502
INFO:root:current train perplexity4.68654727935791
INFO:root:current mean train loss 1954.7999991022948
INFO:root:current train perplexity4.682278633117676
INFO:root:current mean train loss 1954.615105244804
INFO:root:current train perplexity4.67776346206665
INFO:root:current mean train loss 1952.9772777689577
INFO:root:current train perplexity4.67018461227417
INFO:root:current mean train loss 1952.3469785318334
INFO:root:current train perplexity4.665072441101074
INFO:root:current mean train loss 1952.516545958004
INFO:root:current train perplexity4.668447017669678
INFO:root:current mean train loss 1953.2953237949002
INFO:root:current train perplexity4.667773723602295

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.93s/it]
INFO:root:final mean train loss: 1953.2291634656297
INFO:root:final train perplexity: 4.666615009307861
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.62s/it]
INFO:root:eval mean loss: 1953.7001888193984
INFO:root:eval perplexity: 4.8551411628723145
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.88s/it]
INFO:root:eval mean loss: 2400.588194502161
INFO:root:eval perplexity: 7.122558116912842
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/65
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [9:33:54<5:02:56, 519.33s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1896.9799194335938
INFO:root:current train perplexity4.6130900382995605
INFO:root:current mean train loss 1950.1893627460186
INFO:root:current train perplexity4.681244850158691
INFO:root:current mean train loss 1948.9721039416743
INFO:root:current train perplexity4.678508281707764
INFO:root:current mean train loss 1945.8236180355675
INFO:root:current train perplexity4.67393684387207
INFO:root:current mean train loss 1951.5229229313313
INFO:root:current train perplexity4.684201240539551
INFO:root:current mean train loss 1955.1812531001983
INFO:root:current train perplexity4.690718650817871
INFO:root:current mean train loss 1956.731040904064
INFO:root:current train perplexity4.686254501342773
INFO:root:current mean train loss 1958.1669545607133
INFO:root:current train perplexity4.690458297729492
INFO:root:current mean train loss 1960.375622042376
INFO:root:current train perplexity4.696450233459473
INFO:root:current mean train loss 1960.6661351296755
INFO:root:current train perplexity4.698141098022461
INFO:root:current mean train loss 1960.412842040043
INFO:root:current train perplexity4.696798324584961
INFO:root:current mean train loss 1960.3154812135558
INFO:root:current train perplexity4.692372798919678
INFO:root:current mean train loss 1961.3425512979197
INFO:root:current train perplexity4.693836212158203
INFO:root:current mean train loss 1962.7375492025737
INFO:root:current train perplexity4.6988301277160645
INFO:root:current mean train loss 1964.4509746844951
INFO:root:current train perplexity4.705390453338623
INFO:root:current mean train loss 1965.8735517948232
INFO:root:current train perplexity4.708759784698486
INFO:root:current mean train loss 1965.7938856472101
INFO:root:current train perplexity4.708805561065674
INFO:root:current mean train loss 1965.3627844438865
INFO:root:current train perplexity4.708640098571777
INFO:root:current mean train loss 1964.4433965238923
INFO:root:current train perplexity4.706084728240967
INFO:root:current mean train loss 1964.9771645810424
INFO:root:current train perplexity4.70837926864624

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.82s/it]
INFO:root:final mean train loss: 1964.7115015288646
INFO:root:final train perplexity: 4.709066390991211
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.86s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.86s/it]
INFO:root:eval mean loss: 1954.823797131261
INFO:root:eval perplexity: 4.859554290771484
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.45s/it]
INFO:root:eval mean loss: 2404.7809811855886
INFO:root:eval perplexity: 7.147023677825928
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/66
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 66/100 [9:42:32<4:53:57, 518.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2013.143798828125
INFO:root:current train perplexity4.869042873382568
INFO:root:current mean train loss 1999.615540055204
INFO:root:current train perplexity4.835018634796143
INFO:root:current mean train loss 2002.033111434177
INFO:root:current train perplexity4.821774005889893
INFO:root:current mean train loss 1989.9186718902113
INFO:root:current train perplexity4.7955851554870605
INFO:root:current mean train loss 1980.5919737464742
INFO:root:current train perplexity4.767002582550049
INFO:root:current mean train loss 1976.154600996431
INFO:root:current train perplexity4.752834320068359
INFO:root:current mean train loss 1972.9397188883856
INFO:root:current train perplexity4.743317604064941
INFO:root:current mean train loss 1971.7480853076781
INFO:root:current train perplexity4.733788013458252
INFO:root:current mean train loss 1969.1092768679582
INFO:root:current train perplexity4.724384784698486
INFO:root:current mean train loss 1970.3886250880073
INFO:root:current train perplexity4.734736919403076
INFO:root:current mean train loss 1970.8210140755082
INFO:root:current train perplexity4.740593433380127
INFO:root:current mean train loss 1970.9091219736144
INFO:root:current train perplexity4.735044479370117
INFO:root:current mean train loss 1967.5094975901861
INFO:root:current train perplexity4.726141929626465
INFO:root:current mean train loss 1967.215979345814
INFO:root:current train perplexity4.72717809677124
INFO:root:current mean train loss 1968.8502996177592
INFO:root:current train perplexity4.730052947998047
INFO:root:current mean train loss 1971.8146530442298
INFO:root:current train perplexity4.733956813812256
INFO:root:current mean train loss 1972.2654777776306
INFO:root:current train perplexity4.733217239379883
INFO:root:current mean train loss 1972.7965685120162
INFO:root:current train perplexity4.737473011016846
INFO:root:current mean train loss 1973.1377839324632
INFO:root:current train perplexity4.739299774169922
INFO:root:current mean train loss 1972.3064159927487
INFO:root:current train perplexity4.735620975494385

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.91s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:33<00:00, 453.91s/it]
INFO:root:final mean train loss: 1972.0645743334949
INFO:root:final train perplexity: 4.736454010009766
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.14s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.14s/it]
INFO:root:eval mean loss: 1976.4160519863697
INFO:root:eval perplexity: 4.945159435272217
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.18s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.18s/it]
INFO:root:eval mean loss: 2423.1464692244294
INFO:root:eval perplexity: 7.255180835723877
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/67
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [9:51:08<4:44:56, 518.06s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1934.2368678042762
INFO:root:current train perplexity4.669551372528076
INFO:root:current mean train loss 1974.3665974934895
INFO:root:current train perplexity4.752604007720947
INFO:root:current mean train loss 1966.8197908802192
INFO:root:current train perplexity4.716094017028809
INFO:root:current mean train loss 1969.0134483201969
INFO:root:current train perplexity4.721580505371094
INFO:root:current mean train loss 1965.513057900346
INFO:root:current train perplexity4.7138895988464355
INFO:root:current mean train loss 1968.1355679309945
INFO:root:current train perplexity4.719926834106445
INFO:root:current mean train loss 1969.2259071852345
INFO:root:current train perplexity4.724646091461182
INFO:root:current mean train loss 1968.4976254181488
INFO:root:current train perplexity4.730458736419678
INFO:root:current mean train loss 1970.3780379192926
INFO:root:current train perplexity4.736459732055664
INFO:root:current mean train loss 1971.1096197913196
INFO:root:current train perplexity4.737587928771973
INFO:root:current mean train loss 1967.3763161955083
INFO:root:current train perplexity4.725171089172363
INFO:root:current mean train loss 1967.1420558399811
INFO:root:current train perplexity4.722105979919434
INFO:root:current mean train loss 1969.4518792517542
INFO:root:current train perplexity4.726768970489502
INFO:root:current mean train loss 1972.2921444560736
INFO:root:current train perplexity4.736676216125488
INFO:root:current mean train loss 1974.8576632991785
INFO:root:current train perplexity4.743497848510742
INFO:root:current mean train loss 1978.4280709017394
INFO:root:current train perplexity4.756330490112305
INFO:root:current mean train loss 1978.7186873998398
INFO:root:current train perplexity4.757277488708496
INFO:root:current mean train loss 1977.1357114240957
INFO:root:current train perplexity4.754515647888184
INFO:root:current mean train loss 1975.7865903437203
INFO:root:current train perplexity4.751317501068115
INFO:root:current mean train loss 1977.1357423134755
INFO:root:current train perplexity4.753376007080078

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.57s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.57s/it]
INFO:root:final mean train loss: 1976.7200970517465
INFO:root:final train perplexity: 4.753876686096191
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.23s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.23s/it]
INFO:root:eval mean loss: 1947.10042274421
INFO:root:eval perplexity: 4.829294681549072
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.31s/it]
INFO:root:eval mean loss: 2393.066793238863
INFO:root:eval perplexity: 7.078880310058594
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/68
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [9:59:57<4:37:57, 521.16s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1995.2684259588068
INFO:root:current train perplexity4.789651393890381
INFO:root:current mean train loss 1995.1810223979335
INFO:root:current train perplexity4.800239562988281
INFO:root:current mean train loss 1989.231098728554
INFO:root:current train perplexity4.7824883460998535
INFO:root:current mean train loss 1990.2814380914392
INFO:root:current train perplexity4.793455123901367
INFO:root:current mean train loss 1997.1681227463941
INFO:root:current train perplexity4.808358669281006
INFO:root:current mean train loss 1997.0279519020974
INFO:root:current train perplexity4.8039960861206055
INFO:root:current mean train loss 1995.5416494587905
INFO:root:current train perplexity4.80855131149292
INFO:root:current mean train loss 1997.8204597927877
INFO:root:current train perplexity4.818410396575928
INFO:root:current mean train loss 1999.0030440481084
INFO:root:current train perplexity4.82519006729126
INFO:root:current mean train loss 1999.1046758681691
INFO:root:current train perplexity4.8259172439575195
INFO:root:current mean train loss 2000.8521979598638
INFO:root:current train perplexity4.830045223236084
INFO:root:current mean train loss 1997.9053491105249
INFO:root:current train perplexity4.822073936462402
INFO:root:current mean train loss 1999.4556777771725
INFO:root:current train perplexity4.8314924240112305
INFO:root:current mean train loss 2000.544160444534
INFO:root:current train perplexity4.838940143585205
INFO:root:current mean train loss 2001.938360364986
INFO:root:current train perplexity4.842468738555908
INFO:root:current mean train loss 2002.8460266309535
INFO:root:current train perplexity4.844813346862793
INFO:root:current mean train loss 2003.648569896502
INFO:root:current train perplexity4.849975109100342
INFO:root:current mean train loss 2005.0940160506811
INFO:root:current train perplexity4.853582859039307
INFO:root:current mean train loss 2005.3993849103983
INFO:root:current train perplexity4.8600616455078125
INFO:root:current mean train loss 2006.6872005999242
INFO:root:current train perplexity4.8660407066345215

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:51<00:00, 471.66s/it]
INFO:root:final mean train loss: 2006.8750656520365
INFO:root:final train perplexity: 4.868288516998291
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:36<00:00, 36.36s/it]
INFO:root:eval mean loss: 2001.7058200700908
INFO:root:eval perplexity: 5.047343730926514
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.12s/it]
INFO:root:eval mean loss: 2448.0941607969025
INFO:root:eval perplexity: 7.404726982116699
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/69
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 69/100 [10:08:58<4:32:23, 527.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2029.938468085395
INFO:root:current train perplexity4.9083967208862305
INFO:root:current mean train loss 2019.270543298056
INFO:root:current train perplexity4.880593299865723
INFO:root:current mean train loss 2011.241698769962
INFO:root:current train perplexity4.865662574768066
INFO:root:current mean train loss 2006.2828123031125
INFO:root:current train perplexity4.849949359893799
INFO:root:current mean train loss 2006.8411660921777
INFO:root:current train perplexity4.864767551422119
INFO:root:current mean train loss 2015.879078044758
INFO:root:current train perplexity4.903570175170898
INFO:root:current mean train loss 2025.6764097667876
INFO:root:current train perplexity4.940197467803955
INFO:root:current mean train loss 2026.152158430821
INFO:root:current train perplexity4.939636707305908
INFO:root:current mean train loss 2022.4789763284386
INFO:root:current train perplexity4.9283246994018555
INFO:root:current mean train loss 2021.877823817877
INFO:root:current train perplexity4.921654224395752
INFO:root:current mean train loss 2016.6922567566828
INFO:root:current train perplexity4.910766124725342
INFO:root:current mean train loss 2016.0085539834085
INFO:root:current train perplexity4.906209945678711
INFO:root:current mean train loss 2012.1732880214474
INFO:root:current train perplexity4.895987510681152
INFO:root:current mean train loss 2010.8093884526468
INFO:root:current train perplexity4.888830184936523
INFO:root:current mean train loss 2009.3479986605437
INFO:root:current train perplexity4.88209342956543
INFO:root:current mean train loss 2006.9305343045532
INFO:root:current train perplexity4.872146129608154
INFO:root:current mean train loss 2005.997380014812
INFO:root:current train perplexity4.865911483764648
INFO:root:current mean train loss 2006.8260928599614
INFO:root:current train perplexity4.865963459014893
INFO:root:current mean train loss 2006.4117633786975
INFO:root:current train perplexity4.863462448120117
INFO:root:current mean train loss 2005.8225372500158
INFO:root:current train perplexity4.862216949462891

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:29<00:00, 449.74s/it]
INFO:root:final mean train loss: 2005.3638851994885
INFO:root:final train perplexity: 4.862490177154541
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.32s/it]
INFO:root:eval mean loss: 1946.2875595633866
INFO:root:eval perplexity: 4.8261213302612305
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.69s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.69s/it]
INFO:root:eval mean loss: 2389.7094328318926
INFO:root:eval perplexity: 7.059470176696777
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/70
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [10:17:34<4:21:55, 523.86s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1994.8520795843574
INFO:root:current train perplexity4.889935493469238
INFO:root:current mean train loss 2015.600914041832
INFO:root:current train perplexity4.944025993347168
INFO:root:current mean train loss 2028.8322209024925
INFO:root:current train perplexity4.947046279907227
INFO:root:current mean train loss 2019.8048955530005
INFO:root:current train perplexity4.92501974105835
INFO:root:current mean train loss 2015.843899030627
INFO:root:current train perplexity4.909795761108398
INFO:root:current mean train loss 2014.6454068816984
INFO:root:current train perplexity4.9061808586120605
INFO:root:current mean train loss 2015.080957066684
INFO:root:current train perplexity4.9057207107543945
INFO:root:current mean train loss 2015.1271312022238
INFO:root:current train perplexity4.898299694061279
INFO:root:current mean train loss 2014.0463477221597
INFO:root:current train perplexity4.895129203796387
INFO:root:current mean train loss 2017.763034862985
INFO:root:current train perplexity4.909204483032227
INFO:root:current mean train loss 2016.8440714854512
INFO:root:current train perplexity4.90879487991333
INFO:root:current mean train loss 2021.7810372752838
INFO:root:current train perplexity4.9274420738220215
INFO:root:current mean train loss 2022.827884742139
INFO:root:current train perplexity4.931993007659912
INFO:root:current mean train loss 2023.4726029925419
INFO:root:current train perplexity4.936045169830322
INFO:root:current mean train loss 2024.0890103270337
INFO:root:current train perplexity4.936525821685791
INFO:root:current mean train loss 2024.2309584908699
INFO:root:current train perplexity4.937368392944336
INFO:root:current mean train loss 2022.4779418439396
INFO:root:current train perplexity4.930160999298096
INFO:root:current mean train loss 2023.0743467566554
INFO:root:current train perplexity4.928609371185303
INFO:root:current mean train loss 2023.4597677833633
INFO:root:current train perplexity4.930522441864014

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.84s/it]
INFO:root:final mean train loss: 2023.677183119504
INFO:root:final train perplexity: 4.933228492736816
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.75s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.75s/it]
INFO:root:eval mean loss: 1956.1822587682846
INFO:root:eval perplexity: 4.864895820617676
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.31s/it]
INFO:root:eval mean loss: 2398.6831881475787
INFO:root:eval perplexity: 7.111471176147461
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/71
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 71/100 [10:26:19<4:13:22, 524.22s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2102.1777954101562
INFO:root:current train perplexity5.041391372680664
INFO:root:current mean train loss 2006.374975816259
INFO:root:current train perplexity4.888607501983643
INFO:root:current mean train loss 2010.2548016298165
INFO:root:current train perplexity4.855029582977295
INFO:root:current mean train loss 2011.9000611149409
INFO:root:current train perplexity4.863605499267578
INFO:root:current mean train loss 2024.2383098132505
INFO:root:current train perplexity4.906435489654541
INFO:root:current mean train loss 2020.4057612362587
INFO:root:current train perplexity4.908542633056641
INFO:root:current mean train loss 2021.8479048222205
INFO:root:current train perplexity4.91219425201416
INFO:root:current mean train loss 2017.9374315299663
INFO:root:current train perplexity4.903323173522949
INFO:root:current mean train loss 2015.130114988417
INFO:root:current train perplexity4.904155254364014
INFO:root:current mean train loss 2017.0026107687033
INFO:root:current train perplexity4.915946006774902
INFO:root:current mean train loss 2020.1303061756414
INFO:root:current train perplexity4.921981334686279
INFO:root:current mean train loss 2023.775868752119
INFO:root:current train perplexity4.933159828186035
INFO:root:current mean train loss 2023.4846916135468
INFO:root:current train perplexity4.9307684898376465
INFO:root:current mean train loss 2022.592514154922
INFO:root:current train perplexity4.929114818572998
INFO:root:current mean train loss 2023.0453306282227
INFO:root:current train perplexity4.929990768432617
INFO:root:current mean train loss 2023.1396858853648
INFO:root:current train perplexity4.92911434173584
INFO:root:current mean train loss 2022.0744950423948
INFO:root:current train perplexity4.924801826477051
INFO:root:current mean train loss 2021.0476281008434
INFO:root:current train perplexity4.9172539710998535
INFO:root:current mean train loss 2020.4482037279165
INFO:root:current train perplexity4.915587902069092
INFO:root:current mean train loss 2020.6211766886436
INFO:root:current train perplexity4.916426181793213

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.53s/it]
INFO:root:final mean train loss: 2020.535212822172
INFO:root:final train perplexity: 4.921018600463867
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.17s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.17s/it]
INFO:root:eval mean loss: 1959.0262295337434
INFO:root:eval perplexity: 4.876098155975342
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.64s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.64s/it]
INFO:root:eval mean loss: 2402.7592228016956
INFO:root:eval perplexity: 7.135214805603027
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/72
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [10:34:49<4:02:34, 519.81s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2069.6068645974865
INFO:root:current train perplexity4.992974758148193
INFO:root:current mean train loss 2039.670829959032
INFO:root:current train perplexity4.954128742218018
INFO:root:current mean train loss 2022.3596580060607
INFO:root:current train perplexity4.902927398681641
INFO:root:current mean train loss 2015.9912101816467
INFO:root:current train perplexity4.882131099700928
INFO:root:current mean train loss 2015.6373109208776
INFO:root:current train perplexity4.877052307128906
INFO:root:current mean train loss 2011.199398004302
INFO:root:current train perplexity4.867245197296143
INFO:root:current mean train loss 2010.5366277556932
INFO:root:current train perplexity4.868157386779785
INFO:root:current mean train loss 2006.9112845984073
INFO:root:current train perplexity4.862305641174316
INFO:root:current mean train loss 2006.6867253059027
INFO:root:current train perplexity4.8647918701171875
INFO:root:current mean train loss 2011.1020456233496
INFO:root:current train perplexity4.882449626922607
INFO:root:current mean train loss 2013.3510890151515
INFO:root:current train perplexity4.897687911987305
INFO:root:current mean train loss 2013.6929352268617
INFO:root:current train perplexity4.897190570831299
INFO:root:current mean train loss 2013.7553651050184
INFO:root:current train perplexity4.896980285644531
INFO:root:current mean train loss 2017.4097841339226
INFO:root:current train perplexity4.910593509674072
INFO:root:current mean train loss 2018.5675618432394
INFO:root:current train perplexity4.915253162384033
INFO:root:current mean train loss 2020.3502153182453
INFO:root:current train perplexity4.917913436889648
INFO:root:current mean train loss 2018.0343697501492
INFO:root:current train perplexity4.912118911743164
INFO:root:current mean train loss 2017.8040947186275
INFO:root:current train perplexity4.910799503326416
INFO:root:current mean train loss 2018.0775579053886
INFO:root:current train perplexity4.913087368011475
INFO:root:current mean train loss 2019.5180834821283
INFO:root:current train perplexity4.916815280914307

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.24s/it]
INFO:root:final mean train loss: 2018.6728262312174
INFO:root:final train perplexity: 4.9137959480285645
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.95s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.95s/it]
INFO:root:eval mean loss: 1948.6609518713985
INFO:root:eval perplexity: 4.83539342880249
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.97s/it]
INFO:root:eval mean loss: 2388.494157074191
INFO:root:eval perplexity: 7.052457809448242
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/73
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [10:43:22<3:53:02, 517.87s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1996.171157836914
INFO:root:current train perplexity4.822863578796387
INFO:root:current mean train loss 1989.9716587611608
INFO:root:current train perplexity4.788933753967285
INFO:root:current mean train loss 2030.2083674112955
INFO:root:current train perplexity4.917750358581543
INFO:root:current mean train loss 2019.7452913172106
INFO:root:current train perplexity4.902670860290527
INFO:root:current mean train loss 2017.2058965509589
INFO:root:current train perplexity4.892819404602051
INFO:root:current mean train loss 2016.977197265625
INFO:root:current train perplexity4.885107517242432
INFO:root:current mean train loss 2013.665567779541
INFO:root:current train perplexity4.878701210021973
INFO:root:current mean train loss 2012.4960327148438
INFO:root:current train perplexity4.877342224121094
INFO:root:current mean train loss 2011.271825299944
INFO:root:current train perplexity4.8720011711120605
INFO:root:current mean train loss 2008.6962610123005
INFO:root:current train perplexity4.862209796905518
INFO:root:current mean train loss 2006.0200509878305
INFO:root:current train perplexity4.85669469833374
INFO:root:current mean train loss 2004.38759626422
INFO:root:current train perplexity4.851138114929199
INFO:root:current mean train loss 2004.2864151493195
INFO:root:current train perplexity4.851015090942383
INFO:root:current mean train loss 2004.663897613981
INFO:root:current train perplexity4.853607654571533
INFO:root:current mean train loss 2004.2089252048067
INFO:root:current train perplexity4.852184772491455
INFO:root:current mean train loss 2003.152619121601
INFO:root:current train perplexity4.848979949951172
INFO:root:current mean train loss 2001.930386352539
INFO:root:current train perplexity4.8475236892700195
INFO:root:current mean train loss 2003.4742849766524
INFO:root:current train perplexity4.8497185707092285
INFO:root:current mean train loss 2004.509713612432
INFO:root:current train perplexity4.853565692901611
INFO:root:current mean train loss 2005.608247988986
INFO:root:current train perplexity4.859109878540039

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.29s/it]
INFO:root:final mean train loss: 2005.5272109685254
INFO:root:final train perplexity: 4.863116264343262
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.36s/it]
INFO:root:eval mean loss: 1979.8869009897219
INFO:root:eval perplexity: 4.9590606689453125
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.71s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.71s/it]
INFO:root:eval mean loss: 2423.362957893534
INFO:root:eval perplexity: 7.25646448135376
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/74
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [10:52:08<3:45:24, 520.19s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1986.8337145353619
INFO:root:current train perplexity4.888271808624268
INFO:root:current mean train loss 2032.2579446780453
INFO:root:current train perplexity4.9744486808776855
INFO:root:current mean train loss 2044.0291325313108
INFO:root:current train perplexity5.002686023712158
INFO:root:current mean train loss 2043.343888141194
INFO:root:current train perplexity5.01923131942749
INFO:root:current mean train loss 2055.157414609546
INFO:root:current train perplexity5.052784442901611
INFO:root:current mean train loss 2049.7793315017675
INFO:root:current train perplexity5.050208568572998
INFO:root:current mean train loss 2056.5783013237847
INFO:root:current train perplexity5.070565700531006
INFO:root:current mean train loss 2062.231164244396
INFO:root:current train perplexity5.09224271774292
INFO:root:current mean train loss 2065.7141633183983
INFO:root:current train perplexity5.1103949546813965
INFO:root:current mean train loss 2069.193117275258
INFO:root:current train perplexity5.11799430847168
INFO:root:current mean train loss 2069.9050737595717
INFO:root:current train perplexity5.118432998657227
INFO:root:current mean train loss 2071.229265982876
INFO:root:current train perplexity5.125563144683838
INFO:root:current mean train loss 2072.804599321922
INFO:root:current train perplexity5.129902362823486
INFO:root:current mean train loss 2073.376228349386
INFO:root:current train perplexity5.130797863006592
INFO:root:current mean train loss 2075.6184074490875
INFO:root:current train perplexity5.138557434082031
INFO:root:current mean train loss 2077.903323291737
INFO:root:current train perplexity5.149621963500977
INFO:root:current mean train loss 2078.7949167918064
INFO:root:current train perplexity5.153472423553467
INFO:root:current mean train loss 2080.6250571792075
INFO:root:current train perplexity5.158900260925293
INFO:root:current mean train loss 2082.6301090074085
INFO:root:current train perplexity5.1650004386901855
INFO:root:current mean train loss 2083.401073707265
INFO:root:current train perplexity5.168929576873779

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.19s/it]
INFO:root:final mean train loss: 2083.111496179439
INFO:root:final train perplexity: 5.169970989227295
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.82s/it]
INFO:root:eval mean loss: 1982.7074364195478
INFO:root:eval perplexity: 4.970385551452637
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.32s/it]
INFO:root:eval mean loss: 2422.5873495331894
INFO:root:eval perplexity: 7.251863956451416
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/75
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [11:00:44<3:36:17, 519.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2111.1815993850296
INFO:root:current train perplexity5.270181655883789
INFO:root:current mean train loss 2099.5411068269577
INFO:root:current train perplexity5.242288589477539
INFO:root:current mean train loss 2093.507910067148
INFO:root:current train perplexity5.23602819442749
INFO:root:current mean train loss 2096.6213666130516
INFO:root:current train perplexity5.243658065795898
INFO:root:current mean train loss 2100.0283097536753
INFO:root:current train perplexity5.250295639038086
INFO:root:current mean train loss 2105.4167529381943
INFO:root:current train perplexity5.25930643081665
INFO:root:current mean train loss 2106.884925366863
INFO:root:current train perplexity5.2657084465026855
INFO:root:current mean train loss 2108.704430710746
INFO:root:current train perplexity5.267397880554199
INFO:root:current mean train loss 2109.2432408802024
INFO:root:current train perplexity5.276995658874512
INFO:root:current mean train loss 2113.9688748275476
INFO:root:current train perplexity5.289940357208252
INFO:root:current mean train loss 2116.991341873254
INFO:root:current train perplexity5.297636985778809
INFO:root:current mean train loss 2115.402487655718
INFO:root:current train perplexity5.29705286026001
INFO:root:current mean train loss 2114.8418656712984
INFO:root:current train perplexity5.2996110916137695
INFO:root:current mean train loss 2118.7199211287184
INFO:root:current train perplexity5.310999393463135
INFO:root:current mean train loss 2121.4968369379135
INFO:root:current train perplexity5.323992729187012
INFO:root:current mean train loss 2120.3652032757655
INFO:root:current train perplexity5.321622848510742
INFO:root:current mean train loss 2122.1623193884407
INFO:root:current train perplexity5.326490879058838
INFO:root:current mean train loss 2124.121850118024
INFO:root:current train perplexity5.3331217765808105
INFO:root:current mean train loss 2122.5314836532607
INFO:root:current train perplexity5.328366756439209
INFO:root:current mean train loss 2120.5546423574833
INFO:root:current train perplexity5.322765827178955

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:43<00:00, 463.63s/it]
INFO:root:final mean train loss: 2119.9860027272834
INFO:root:final train perplexity: 5.32252836227417
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.32s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:35<00:00, 35.32s/it]
INFO:root:eval mean loss: 1978.0069800843585
INFO:root:eval perplexity: 4.951527118682861
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.61s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.61s/it]
INFO:root:eval mean loss: 2413.766289460744
INFO:root:eval perplexity: 7.199736595153809
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/76
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [11:09:36<3:29:10, 522.92s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2075.9378554794816
INFO:root:current train perplexity5.274580955505371
INFO:root:current mean train loss 2115.226582951571
INFO:root:current train perplexity5.347410678863525
INFO:root:current mean train loss 2114.9444408089025
INFO:root:current train perplexity5.366875171661377
INFO:root:current mean train loss 2110.1082307859456
INFO:root:current train perplexity5.32041072845459
INFO:root:current mean train loss 2108.0886081299327
INFO:root:current train perplexity5.3150224685668945
INFO:root:current mean train loss 2105.989432965842
INFO:root:current train perplexity5.300355434417725
INFO:root:current mean train loss 2107.741119782245
INFO:root:current train perplexity5.291194915771484
INFO:root:current mean train loss 2108.567157036435
INFO:root:current train perplexity5.298178195953369
INFO:root:current mean train loss 2109.767077239408
INFO:root:current train perplexity5.299404144287109
INFO:root:current mean train loss 2109.9493730931904
INFO:root:current train perplexity5.29429292678833
INFO:root:current mean train loss 2115.560477951707
INFO:root:current train perplexity5.319269180297852
INFO:root:current mean train loss 2119.2026252394257
INFO:root:current train perplexity5.329104900360107
INFO:root:current mean train loss 2117.862349695609
INFO:root:current train perplexity5.323294639587402
INFO:root:current mean train loss 2117.180883718857
INFO:root:current train perplexity5.313944339752197
INFO:root:current mean train loss 2115.0111014393656
INFO:root:current train perplexity5.30311393737793
INFO:root:current mean train loss 2114.5099053421836
INFO:root:current train perplexity5.301306247711182
INFO:root:current mean train loss 2113.0993829204936
INFO:root:current train perplexity5.2966628074646
INFO:root:current mean train loss 2112.5675413471436
INFO:root:current train perplexity5.289407253265381
INFO:root:current mean train loss 2110.3379215460363
INFO:root:current train perplexity5.282418727874756

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:31<00:00, 451.55s/it]
INFO:root:final mean train loss: 2108.5761585168266
INFO:root:final train perplexity: 5.274848937988281
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.74s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.74s/it]
INFO:root:eval mean loss: 1967.850114105441
INFO:root:eval perplexity: 4.911020278930664
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.92s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.92s/it]
INFO:root:eval mean loss: 2404.4552408854165
INFO:root:eval perplexity: 7.145119667053223
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/77
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [11:18:14<3:19:55, 521.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1979.6561126708984
INFO:root:current train perplexity4.901037216186523
INFO:root:current mean train loss 2089.9614721227576
INFO:root:current train perplexity5.171975612640381
INFO:root:current mean train loss 2091.3440240713267
INFO:root:current train perplexity5.210048198699951
INFO:root:current mean train loss 2081.787920270647
INFO:root:current train perplexity5.188731670379639
INFO:root:current mean train loss 2081.7004586014095
INFO:root:current train perplexity5.1779632568359375
INFO:root:current mean train loss 2081.685279425674
INFO:root:current train perplexity5.17671537399292
INFO:root:current mean train loss 2083.6414726658872
INFO:root:current train perplexity5.190046787261963
INFO:root:current mean train loss 2083.393593308616
INFO:root:current train perplexity5.190271854400635
INFO:root:current mean train loss 2088.741408395295
INFO:root:current train perplexity5.198489189147949
INFO:root:current mean train loss 2090.2182415529496
INFO:root:current train perplexity5.200911521911621
INFO:root:current mean train loss 2090.285970415388
INFO:root:current train perplexity5.201319217681885
INFO:root:current mean train loss 2090.927465666072
INFO:root:current train perplexity5.201787948608398
INFO:root:current mean train loss 2093.0354155483624
INFO:root:current train perplexity5.209799766540527
INFO:root:current mean train loss 2096.505087569584
INFO:root:current train perplexity5.221076011657715
INFO:root:current mean train loss 2096.848267208446
INFO:root:current train perplexity5.223945617675781
INFO:root:current mean train loss 2097.6429821388792
INFO:root:current train perplexity5.226535320281982
INFO:root:current mean train loss 2098.4943746690133
INFO:root:current train perplexity5.225931167602539
INFO:root:current mean train loss 2097.325486909031
INFO:root:current train perplexity5.222665309906006
INFO:root:current mean train loss 2095.818080935858
INFO:root:current train perplexity5.219367027282715
INFO:root:current mean train loss 2095.356096119751
INFO:root:current train perplexity5.218869686126709

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.02s/it]
INFO:root:final mean train loss: 2094.454213167884
INFO:root:final train perplexity: 5.216426372528076
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.51s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.51s/it]
INFO:root:eval mean loss: 1973.6704755201408
INFO:root:eval perplexity: 4.934191703796387
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.96s/it]
INFO:root:eval mean loss: 2410.253143959857
INFO:root:eval perplexity: 7.179080009460449
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/78
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [11:26:49<3:10:29, 519.51s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2077.1264599609376
INFO:root:current train perplexity5.157443523406982
INFO:root:current mean train loss 2105.3091748046877
INFO:root:current train perplexity5.341906547546387
INFO:root:current mean train loss 2119.8732340494794
INFO:root:current train perplexity5.360341548919678
INFO:root:current mean train loss 2133.018452899639
INFO:root:current train perplexity5.405117511749268
INFO:root:current mean train loss 2124.5099764476104
INFO:root:current train perplexity5.368768215179443
INFO:root:current mean train loss 2117.747728562128
INFO:root:current train perplexity5.330183029174805
INFO:root:current mean train loss 2108.277848046875
INFO:root:current train perplexity5.30961799621582
INFO:root:current mean train loss 2102.619660391972
INFO:root:current train perplexity5.279032230377197
INFO:root:current mean train loss 2101.7783090672347
INFO:root:current train perplexity5.261455535888672
INFO:root:current mean train loss 2098.1703844225085
INFO:root:current train perplexity5.2459235191345215
INFO:root:current mean train loss 2107.3261298351754
INFO:root:current train perplexity5.291207790374756
INFO:root:current mean train loss 2113.1812940538193
INFO:root:current train perplexity5.3071393966674805
INFO:root:current mean train loss 2114.477738958865
INFO:root:current train perplexity5.306386947631836
INFO:root:current mean train loss 2114.228641380454
INFO:root:current train perplexity5.303225040435791
INFO:root:current mean train loss 2113.5148354406524
INFO:root:current train perplexity5.2975006103515625
INFO:root:current mean train loss 2111.732856605405
INFO:root:current train perplexity5.287752628326416
INFO:root:current mean train loss 2110.660982496995
INFO:root:current train perplexity5.285879611968994
INFO:root:current mean train loss 2108.986630859375
INFO:root:current train perplexity5.274462699890137
INFO:root:current mean train loss 2110.0722593375426
INFO:root:current train perplexity5.276020526885986
INFO:root:current mean train loss 2108.531091213474
INFO:root:current train perplexity5.271176815032959

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.84s/it]
INFO:root:final mean train loss: 2107.187275434947
INFO:root:final train perplexity: 5.269074440002441
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.85s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:33<00:00, 33.85s/it]
INFO:root:eval mean loss: 1970.702362709857
INFO:root:eval perplexity: 4.922361850738525
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.02s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.02s/it]
INFO:root:eval mean loss: 2409.405610213043
INFO:root:eval perplexity: 7.174105167388916
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/79
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [11:35:32<3:02:11, 520.55s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2072.114531017485
INFO:root:current train perplexity5.096549034118652
INFO:root:current mean train loss 2095.670351700044
INFO:root:current train perplexity5.170754909515381
INFO:root:current mean train loss 2086.680381585744
INFO:root:current train perplexity5.14986515045166
INFO:root:current mean train loss 2082.237907186586
INFO:root:current train perplexity5.147157669067383
INFO:root:current mean train loss 2078.3327879754665
INFO:root:current train perplexity5.149004936218262
INFO:root:current mean train loss 2079.856231802064
INFO:root:current train perplexity5.154568672180176
INFO:root:current mean train loss 2082.463683131328
INFO:root:current train perplexity5.158649444580078
INFO:root:current mean train loss 2083.8654293255663
INFO:root:current train perplexity5.165019512176514
INFO:root:current mean train loss 2082.763844977082
INFO:root:current train perplexity5.166872024536133
INFO:root:current mean train loss 2082.446158957836
INFO:root:current train perplexity5.169482231140137
INFO:root:current mean train loss 2086.223664677303
INFO:root:current train perplexity5.178465843200684
INFO:root:current mean train loss 2083.0126120438717
INFO:root:current train perplexity5.1731390953063965
INFO:root:current mean train loss 2083.250809870672
INFO:root:current train perplexity5.174830436706543
INFO:root:current mean train loss 2081.8179650569637
INFO:root:current train perplexity5.170167446136475
INFO:root:current mean train loss 2082.5976062197956
INFO:root:current train perplexity5.1732964515686035
INFO:root:current mean train loss 2084.6206502753626
INFO:root:current train perplexity5.177524089813232
INFO:root:current mean train loss 2084.008842068671
INFO:root:current train perplexity5.172936916351318
INFO:root:current mean train loss 2085.800204674494
INFO:root:current train perplexity5.181796073913574
INFO:root:current mean train loss 2092.8942790243705
INFO:root:current train perplexity5.207447528839111
INFO:root:current mean train loss 2092.5777089426374
INFO:root:current train perplexity5.207574844360352

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.63s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:36<00:00, 456.63s/it]
INFO:root:final mean train loss: 2092.3514002320508
INFO:root:final train perplexity: 5.20778226852417
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.27s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.27s/it]
INFO:root:eval mean loss: 1976.3292937583112
INFO:root:eval perplexity: 4.944813251495361
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.09s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.09s/it]
INFO:root:eval mean loss: 2418.0549602102724
INFO:root:eval perplexity: 7.225033283233643
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/80
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [11:44:13<2:53:34, 520.75s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2085.902927204714
INFO:root:current train perplexity5.155691146850586
INFO:root:current mean train loss 2071.441078425953
INFO:root:current train perplexity5.114224910736084
INFO:root:current mean train loss 2066.795294684333
INFO:root:current train perplexity5.11489200592041
INFO:root:current mean train loss 2072.39224727705
INFO:root:current train perplexity5.122189044952393
INFO:root:current mean train loss 2071.7092383557156
INFO:root:current train perplexity5.124475479125977
INFO:root:current mean train loss 2074.6916744116165
INFO:root:current train perplexity5.1232686042785645
INFO:root:current mean train loss 2076.9090535420028
INFO:root:current train perplexity5.130650520324707
INFO:root:current mean train loss 2074.799306756423
INFO:root:current train perplexity5.127776145935059
INFO:root:current mean train loss 2077.5072592756383
INFO:root:current train perplexity5.146358489990234
INFO:root:current mean train loss 2086.8812817204607
INFO:root:current train perplexity5.183486461639404
INFO:root:current mean train loss 2089.112254891112
INFO:root:current train perplexity5.191678047180176
INFO:root:current mean train loss 2087.5720530815224
INFO:root:current train perplexity5.185837745666504
INFO:root:current mean train loss 2088.357512336955
INFO:root:current train perplexity5.185213088989258
INFO:root:current mean train loss 2090.258984878012
INFO:root:current train perplexity5.1926188468933105
INFO:root:current mean train loss 2091.7684756220815
INFO:root:current train perplexity5.197478771209717
INFO:root:current mean train loss 2091.1425949595846
INFO:root:current train perplexity5.198497772216797
INFO:root:current mean train loss 2092.1694268243295
INFO:root:current train perplexity5.199552059173584
INFO:root:current mean train loss 2091.727425666883
INFO:root:current train perplexity5.201554775238037
INFO:root:current mean train loss 2089.717542364111
INFO:root:current train perplexity5.195494651794434
INFO:root:current mean train loss 2089.6625744136636
INFO:root:current train perplexity5.1962809562683105

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.45s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:24<00:00, 444.45s/it]
INFO:root:final mean train loss: 2089.649001744319
INFO:root:final train perplexity: 5.196695327758789
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.31s/it]
INFO:root:eval mean loss: 1971.1856728411735
INFO:root:eval perplexity: 4.924285888671875
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.24s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.24s/it]
INFO:root:eval mean loss: 2411.2329841776095
INFO:root:eval perplexity: 7.184835433959961
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/81
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [11:52:42<2:43:48, 517.28s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2078.478346975226
INFO:root:current train perplexity5.180652141571045
INFO:root:current mean train loss 2081.0649025656962
INFO:root:current train perplexity5.15519905090332
INFO:root:current mean train loss 2076.220740719118
INFO:root:current train perplexity5.14259147644043
INFO:root:current mean train loss 2079.6529044293343
INFO:root:current train perplexity5.15949010848999
INFO:root:current mean train loss 2079.001589735015
INFO:root:current train perplexity5.143270492553711
INFO:root:current mean train loss 2085.571996476915
INFO:root:current train perplexity5.159103870391846
INFO:root:current mean train loss 2084.9146390835913
INFO:root:current train perplexity5.160928249359131
INFO:root:current mean train loss 2088.058223449078
INFO:root:current train perplexity5.173442840576172
INFO:root:current mean train loss 2086.372786709163
INFO:root:current train perplexity5.167427062988281
INFO:root:current mean train loss 2085.1917848430694
INFO:root:current train perplexity5.160738468170166
INFO:root:current mean train loss 2082.875847004603
INFO:root:current train perplexity5.156492710113525
INFO:root:current mean train loss 2082.8515919795655
INFO:root:current train perplexity5.157672882080078
INFO:root:current mean train loss 2083.250941644268
INFO:root:current train perplexity5.158677101135254
INFO:root:current mean train loss 2081.7280716119812
INFO:root:current train perplexity5.154055595397949
INFO:root:current mean train loss 2079.7998588582686
INFO:root:current train perplexity5.1526007652282715
INFO:root:current mean train loss 2079.9644881505046
INFO:root:current train perplexity5.153368949890137
INFO:root:current mean train loss 2078.227540446352
INFO:root:current train perplexity5.1484198570251465
INFO:root:current mean train loss 2077.8718759347726
INFO:root:current train perplexity5.149032115936279
INFO:root:current mean train loss 2078.568036825672
INFO:root:current train perplexity5.1504807472229
INFO:root:current mean train loss 2079.1991276914773
INFO:root:current train perplexity5.152172565460205

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.35s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:37<00:00, 457.35s/it]
INFO:root:final mean train loss: 2078.833107167762
INFO:root:final train perplexity: 5.1525559425354
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.53s/it]
INFO:root:eval mean loss: 1963.2998869334551
INFO:root:eval perplexity: 4.892981052398682
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.89s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.89s/it]
INFO:root:eval mean loss: 2403.670753424895
INFO:root:eval perplexity: 7.140538215637207
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/82
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [12:01:23<2:35:30, 518.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2088.02197265625
INFO:root:current train perplexity5.189633369445801
INFO:root:current mean train loss 2096.023880242066
INFO:root:current train perplexity5.232110023498535
INFO:root:current mean train loss 2096.746205404757
INFO:root:current train perplexity5.232576370239258
INFO:root:current mean train loss 2092.956234531548
INFO:root:current train perplexity5.20415735244751
INFO:root:current mean train loss 2091.032125291186
INFO:root:current train perplexity5.193378925323486
INFO:root:current mean train loss 2091.3581997901956
INFO:root:current train perplexity5.189913272857666
INFO:root:current mean train loss 2088.1559521343456
INFO:root:current train perplexity5.191323757171631
INFO:root:current mean train loss 2097.1612421062223
INFO:root:current train perplexity5.230172157287598
INFO:root:current mean train loss 2101.7018824253746
INFO:root:current train perplexity5.24566125869751
INFO:root:current mean train loss 2102.4048033500126
INFO:root:current train perplexity5.243641376495361
INFO:root:current mean train loss 2100.1781821150576
INFO:root:current train perplexity5.2318620681762695
INFO:root:current mean train loss 2097.746389256339
INFO:root:current train perplexity5.225794315338135
INFO:root:current mean train loss 2094.1153356754216
INFO:root:current train perplexity5.214509010314941
INFO:root:current mean train loss 2092.6894400679457
INFO:root:current train perplexity5.209637641906738
INFO:root:current mean train loss 2090.262800212842
INFO:root:current train perplexity5.198370456695557
INFO:root:current mean train loss 2090.1302447322023
INFO:root:current train perplexity5.191425800323486
INFO:root:current mean train loss 2088.844209223757
INFO:root:current train perplexity5.190732955932617
INFO:root:current mean train loss 2087.6437907264144
INFO:root:current train perplexity5.186970233917236
INFO:root:current mean train loss 2088.2238649588944
INFO:root:current train perplexity5.187628269195557

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.20s/it]
INFO:root:final mean train loss: 2087.029102011876
INFO:root:final train perplexity: 5.185969352722168
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.67s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.67s/it]
INFO:root:eval mean loss: 1975.2562255859375
INFO:root:eval perplexity: 4.940523147583008
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.30s/it]
INFO:root:eval mean loss: 2415.282982359541
INFO:root:eval perplexity: 7.208671569824219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/83
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [12:09:52<2:26:01, 515.38s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2057.236193847656
INFO:root:current train perplexity5.130447864532471
INFO:root:current mean train loss 2068.3606567382812
INFO:root:current train perplexity5.117722034454346
INFO:root:current mean train loss 2077.4648513067336
INFO:root:current train perplexity5.139202117919922
INFO:root:current mean train loss 2074.3435546875
INFO:root:current train perplexity5.121042251586914
INFO:root:current mean train loss 2077.364985768388
INFO:root:current train perplexity5.142526626586914
INFO:root:current mean train loss 2085.1594020469515
INFO:root:current train perplexity5.173254489898682
INFO:root:current mean train loss 2086.4838448946593
INFO:root:current train perplexity5.189631462097168
INFO:root:current mean train loss 2083.77793192259
INFO:root:current train perplexity5.1838765144348145
INFO:root:current mean train loss 2081.5336329330635
INFO:root:current train perplexity5.176687717437744
INFO:root:current mean train loss 2083.0193429129463
INFO:root:current train perplexity5.184402942657471
INFO:root:current mean train loss 2093.058418258818
INFO:root:current train perplexity5.214841365814209
INFO:root:current mean train loss 2104.735659707559
INFO:root:current train perplexity5.263485908508301
INFO:root:current mean train loss 2110.554344088972
INFO:root:current train perplexity5.285185813903809
INFO:root:current mean train loss 2111.649291899004
INFO:root:current train perplexity5.2930779457092285
INFO:root:current mean train loss 2110.0502777316046
INFO:root:current train perplexity5.288035869598389
INFO:root:current mean train loss 2109.2632665368897
INFO:root:current train perplexity5.281744480133057
INFO:root:current mean train loss 2109.0094463466858
INFO:root:current train perplexity5.280111312866211
INFO:root:current mean train loss 2106.2049958167718
INFO:root:current train perplexity5.27146053314209
INFO:root:current mean train loss 2107.0044975154306
INFO:root:current train perplexity5.270938396453857
INFO:root:current mean train loss 2108.4926473407845
INFO:root:current train perplexity5.27291202545166

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.31s/it]
INFO:root:final mean train loss: 2108.386110429865
INFO:root:final train perplexity: 5.274059295654297
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.88s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.96s/it]
INFO:root:eval mean loss: 1978.7111937610816
INFO:root:eval perplexity: 4.954348087310791
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.99s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.99s/it]
INFO:root:eval mean loss: 2418.2366073283742
INFO:root:eval perplexity: 7.226105690002441
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/84
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/100 [12:18:31<2:17:45, 516.59s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2073.9442997685187
INFO:root:current train perplexity5.200222492218018
INFO:root:current mean train loss 2089.6902278389516
INFO:root:current train perplexity5.198386192321777
INFO:root:current mean train loss 2092.6653713948926
INFO:root:current train perplexity5.189380645751953
INFO:root:current mean train loss 2076.8593873190225
INFO:root:current train perplexity5.150143146514893
INFO:root:current mean train loss 2076.546191749305
INFO:root:current train perplexity5.142440319061279
INFO:root:current mean train loss 2077.8692237810574
INFO:root:current train perplexity5.141881942749023
INFO:root:current mean train loss 2078.3439530611417
INFO:root:current train perplexity5.141900539398193
INFO:root:current mean train loss 2081.494066744756
INFO:root:current train perplexity5.15009069442749
INFO:root:current mean train loss 2092.324366503788
INFO:root:current train perplexity5.1949462890625
INFO:root:current mean train loss 2089.5986944402307
INFO:root:current train perplexity5.186313152313232
INFO:root:current mean train loss 2086.943875469739
INFO:root:current train perplexity5.17551326751709
INFO:root:current mean train loss 2094.821501900268
INFO:root:current train perplexity5.20056676864624
INFO:root:current mean train loss 2093.264556113743
INFO:root:current train perplexity5.197707653045654
INFO:root:current mean train loss 2092.6347447433413
INFO:root:current train perplexity5.1965508460998535
INFO:root:current mean train loss 2092.1667162247613
INFO:root:current train perplexity5.193321704864502
INFO:root:current mean train loss 2089.3144105163055
INFO:root:current train perplexity5.1859660148620605
INFO:root:current mean train loss 2087.416927588521
INFO:root:current train perplexity5.179940223693848
INFO:root:current mean train loss 2087.325128516643
INFO:root:current train perplexity5.182337284088135
INFO:root:current mean train loss 2088.3697376136383
INFO:root:current train perplexity5.187963485717773
INFO:root:current mean train loss 2088.6906728145677
INFO:root:current train perplexity5.188772201538086

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.29s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.29s/it]
INFO:root:final mean train loss: 2089.137483582374
INFO:root:final train perplexity: 5.194599151611328
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.95s/it]
INFO:root:eval mean loss: 2006.7264473556627
INFO:root:eval perplexity: 5.067879676818848
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.54s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.54s/it]
INFO:root:eval mean loss: 2447.1706599242298
INFO:root:eval perplexity: 7.3991379737854
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/85
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [12:27:05<2:08:57, 515.80s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2107.190995649858
INFO:root:current train perplexity5.281177997589111
INFO:root:current mean train loss 2103.2509841918945
INFO:root:current train perplexity5.276440620422363
INFO:root:current mean train loss 2102.5434945528623
INFO:root:current train perplexity5.271193027496338
INFO:root:current mean train loss 2102.6428864944814
INFO:root:current train perplexity5.2550950050354
INFO:root:current mean train loss 2104.0923508652695
INFO:root:current train perplexity5.256524562835693
INFO:root:current mean train loss 2104.6601062101477
INFO:root:current train perplexity5.2564263343811035
INFO:root:current mean train loss 2104.33829209227
INFO:root:current train perplexity5.248852252960205
INFO:root:current mean train loss 2107.6810279764154
INFO:root:current train perplexity5.255334854125977
INFO:root:current mean train loss 2116.358364737994
INFO:root:current train perplexity5.288535118103027
INFO:root:current mean train loss 2119.3133531990698
INFO:root:current train perplexity5.299996376037598
INFO:root:current mean train loss 2116.365864954689
INFO:root:current train perplexity5.292823791503906
INFO:root:current mean train loss 2113.0142204444724
INFO:root:current train perplexity5.282351970672607
INFO:root:current mean train loss 2112.065423309228
INFO:root:current train perplexity5.275320529937744
INFO:root:current mean train loss 2115.531453450521
INFO:root:current train perplexity5.289796352386475
INFO:root:current mean train loss 2122.115513429087
INFO:root:current train perplexity5.316450119018555
INFO:root:current mean train loss 2124.7100563642275
INFO:root:current train perplexity5.328655242919922
INFO:root:current mean train loss 2126.1890526096317
INFO:root:current train perplexity5.3382792472839355
INFO:root:current mean train loss 2126.2480670334003
INFO:root:current train perplexity5.342841625213623
INFO:root:current mean train loss 2125.648101144654
INFO:root:current train perplexity5.3436055183410645
INFO:root:current mean train loss 2124.891373120218
INFO:root:current train perplexity5.342244625091553

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.66s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.66s/it]
INFO:root:final mean train loss: 2124.381824733871
INFO:root:final train perplexity: 5.341012477874756
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.77s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.77s/it]
INFO:root:eval mean loss: 1992.9019623884917
INFO:root:eval perplexity: 5.011534214019775
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.19s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.19s/it]
INFO:root:eval mean loss: 2432.6641443130816
INFO:root:eval perplexity: 7.311875343322754
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/86
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [12:35:44<2:00:33, 516.70s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2124.873248991419
INFO:root:current train perplexity5.333074569702148
INFO:root:current mean train loss 2114.4058807562596
INFO:root:current train perplexity5.3217573165893555
INFO:root:current mean train loss 2118.5801127349737
INFO:root:current train perplexity5.337660312652588
INFO:root:current mean train loss 2117.871135679969
INFO:root:current train perplexity5.330183029174805
INFO:root:current mean train loss 2114.1314511909404
INFO:root:current train perplexity5.313833713531494
INFO:root:current mean train loss 2110.65902410769
INFO:root:current train perplexity5.308314323425293
INFO:root:current mean train loss 2113.257801050137
INFO:root:current train perplexity5.309170722961426
INFO:root:current mean train loss 2117.50334963504
INFO:root:current train perplexity5.324983596801758
INFO:root:current mean train loss 2117.5145440893584
INFO:root:current train perplexity5.323812007904053
INFO:root:current mean train loss 2116.3681809567265
INFO:root:current train perplexity5.321094512939453
INFO:root:current mean train loss 2115.1993494492226
INFO:root:current train perplexity5.313694477081299
INFO:root:current mean train loss 2115.7715481964296
INFO:root:current train perplexity5.311171054840088
INFO:root:current mean train loss 2114.6663357570565
INFO:root:current train perplexity5.307167053222656
INFO:root:current mean train loss 2115.547266683361
INFO:root:current train perplexity5.304574012756348
INFO:root:current mean train loss 2115.8564921854945
INFO:root:current train perplexity5.303765296936035
INFO:root:current mean train loss 2116.5604603075203
INFO:root:current train perplexity5.304654121398926
INFO:root:current mean train loss 2115.660411561418
INFO:root:current train perplexity5.303527355194092
INFO:root:current mean train loss 2114.9711593809893
INFO:root:current train perplexity5.300779342651367
INFO:root:current mean train loss 2114.9636938227304
INFO:root:current train perplexity5.303611755371094
INFO:root:current mean train loss 2117.2550098004845
INFO:root:current train perplexity5.3077921867370605

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.59s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.59s/it]
INFO:root:final mean train loss: 2116.386950148036
INFO:root:final train perplexity: 5.307443618774414
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.56s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.56s/it]
INFO:root:eval mean loss: 1984.6395826407359
INFO:root:eval perplexity: 4.978157997131348
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.76s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.76s/it]
INFO:root:eval mean loss: 2426.1462069031195
INFO:root:eval perplexity: 7.273000240325928
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/87
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [12:44:15<1:51:36, 515.11s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2112.942615998097
INFO:root:current train perplexity5.276684284210205
INFO:root:current mean train loss 2118.2195091676176
INFO:root:current train perplexity5.275834560394287
INFO:root:current mean train loss 2100.4380822490443
INFO:root:current train perplexity5.220418453216553
INFO:root:current mean train loss 2098.5559692382812
INFO:root:current train perplexity5.207857608795166
INFO:root:current mean train loss 2103.062830968881
INFO:root:current train perplexity5.233098030090332
INFO:root:current mean train loss 2104.3484642794388
INFO:root:current train perplexity5.237473964691162
INFO:root:current mean train loss 2101.968672580775
INFO:root:current train perplexity5.228464126586914
INFO:root:current mean train loss 2099.669327998223
INFO:root:current train perplexity5.221053600311279
INFO:root:current mean train loss 2098.4642538361777
INFO:root:current train perplexity5.2271575927734375
INFO:root:current mean train loss 2097.4830580635303
INFO:root:current train perplexity5.224698543548584
INFO:root:current mean train loss 2092.6485164267233
INFO:root:current train perplexity5.211339473724365
INFO:root:current mean train loss 2093.4480599110316
INFO:root:current train perplexity5.207808017730713
INFO:root:current mean train loss 2091.379902584452
INFO:root:current train perplexity5.201379299163818
INFO:root:current mean train loss 2090.4372435460414
INFO:root:current train perplexity5.1959028244018555
INFO:root:current mean train loss 2089.9718992984344
INFO:root:current train perplexity5.190503120422363
INFO:root:current mean train loss 2086.208179701115
INFO:root:current train perplexity5.177150249481201
INFO:root:current mean train loss 2085.900333081724
INFO:root:current train perplexity5.175241470336914
INFO:root:current mean train loss 2084.637523603922
INFO:root:current train perplexity5.170720100402832
INFO:root:current mean train loss 2082.5868459423255
INFO:root:current train perplexity5.1645612716674805
INFO:root:current mean train loss 2080.503513193468
INFO:root:current train perplexity5.1572160720825195

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:35<00:00, 455.93s/it]
INFO:root:final mean train loss: 2079.9597940526705
INFO:root:final train perplexity: 5.1571364402771
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.73s/it]
INFO:root:eval mean loss: 1967.4692594920489
INFO:root:eval perplexity: 4.909506797790527
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.47s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.47s/it]
INFO:root:eval mean loss: 2410.719426148327
INFO:root:eval perplexity: 7.18181848526001
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/88
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [12:52:57<1:43:23, 516.98s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2056.6538394325657
INFO:root:current train perplexity5.06133508682251
INFO:root:current mean train loss 2046.1845465244392
INFO:root:current train perplexity5.024686336517334
INFO:root:current mean train loss 2048.492257845604
INFO:root:current train perplexity5.022529602050781
INFO:root:current mean train loss 2040.537063019185
INFO:root:current train perplexity5.011720180511475
INFO:root:current mean train loss 2049.2879976523045
INFO:root:current train perplexity5.035695552825928
INFO:root:current mean train loss 2049.9710812352287
INFO:root:current train perplexity5.0347418785095215
INFO:root:current mean train loss 2048.8927253119377
INFO:root:current train perplexity5.033463478088379
INFO:root:current mean train loss 2047.9018393462559
INFO:root:current train perplexity5.026561737060547
INFO:root:current mean train loss 2049.939626887657
INFO:root:current train perplexity5.022003650665283
INFO:root:current mean train loss 2047.3065967042241
INFO:root:current train perplexity5.021386623382568
INFO:root:current mean train loss 2046.2898744069278
INFO:root:current train perplexity5.012050628662109
INFO:root:current mean train loss 2044.9594733713063
INFO:root:current train perplexity5.012194633483887
INFO:root:current mean train loss 2043.5453298443533
INFO:root:current train perplexity5.0054850578308105
INFO:root:current mean train loss 2042.1559059279793
INFO:root:current train perplexity4.99685001373291
INFO:root:current mean train loss 2040.4099583246239
INFO:root:current train perplexity4.9925618171691895
INFO:root:current mean train loss 2037.9812241318084
INFO:root:current train perplexity4.988245487213135
INFO:root:current mean train loss 2036.2411108326419
INFO:root:current train perplexity4.979371547698975
INFO:root:current mean train loss 2033.9186539078821
INFO:root:current train perplexity4.971161842346191
INFO:root:current mean train loss 2032.6771656368528
INFO:root:current train perplexity4.967116832733154

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.46s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.46s/it]
INFO:root:final mean train loss: 2031.5774049821432
INFO:root:final train perplexity: 4.9640607833862305
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.62s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.62s/it]
INFO:root:eval mean loss: 1954.4014360143783
INFO:root:eval perplexity: 4.857893943786621
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.41s/it]
INFO:root:eval mean loss: 2397.667835857851
INFO:root:eval perplexity: 7.105567455291748
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/89
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [13:01:27<1:34:25, 515.08s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2083.1757202148438
INFO:root:current train perplexity4.9590349197387695
INFO:root:current mean train loss 2009.6343547276088
INFO:root:current train perplexity4.851731777191162
INFO:root:current mean train loss 2011.0546149487766
INFO:root:current train perplexity4.857450008392334
INFO:root:current mean train loss 2007.2617363562952
INFO:root:current train perplexity4.860975742340088
INFO:root:current mean train loss 2007.6270520849134
INFO:root:current train perplexity4.867606163024902
INFO:root:current mean train loss 2013.2830147743225
INFO:root:current train perplexity4.890218734741211
INFO:root:current mean train loss 2017.2234812219158
INFO:root:current train perplexity4.896907329559326
INFO:root:current mean train loss 2014.791355604536
INFO:root:current train perplexity4.893661022186279
INFO:root:current mean train loss 2013.9781749706551
INFO:root:current train perplexity4.900235176086426
INFO:root:current mean train loss 2014.32401931495
INFO:root:current train perplexity4.901979923248291
INFO:root:current mean train loss 2014.4679082938333
INFO:root:current train perplexity4.898261070251465
INFO:root:current mean train loss 2013.3379645038851
INFO:root:current train perplexity4.889946460723877
INFO:root:current mean train loss 2012.589433928134
INFO:root:current train perplexity4.884938716888428
INFO:root:current mean train loss 2011.9445773799246
INFO:root:current train perplexity4.882872581481934
INFO:root:current mean train loss 2010.4120082260868
INFO:root:current train perplexity4.876983165740967
INFO:root:current mean train loss 2009.4119011611535
INFO:root:current train perplexity4.873673439025879
INFO:root:current mean train loss 2008.3491897772324
INFO:root:current train perplexity4.872591495513916
INFO:root:current mean train loss 2007.7043832796755
INFO:root:current train perplexity4.870565414428711
INFO:root:current mean train loss 2006.645998047414
INFO:root:current train perplexity4.865048408508301
INFO:root:current mean train loss 2005.6499262215204
INFO:root:current train perplexity4.862231731414795

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.30s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:41<00:00, 461.30s/it]
INFO:root:final mean train loss: 2004.6413106990474
INFO:root:final train perplexity: 4.859719753265381
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.13s/it]
INFO:root:eval mean loss: 1941.6573880242963
INFO:root:eval perplexity: 4.8080830574035645
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.06s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.06s/it]
INFO:root:eval mean loss: 2385.8836747839096
INFO:root:eval perplexity: 7.037417411804199
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/90
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 90/100 [13:10:13<1:26:22, 518.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1929.0111925848598
INFO:root:current train perplexity4.689567565917969
INFO:root:current mean train loss 1983.7646484375
INFO:root:current train perplexity4.796682357788086
INFO:root:current mean train loss 1984.768859063694
INFO:root:current train perplexity4.810852527618408
INFO:root:current mean train loss 1984.8480428678286
INFO:root:current train perplexity4.8121724128723145
INFO:root:current mean train loss 1991.823131783581
INFO:root:current train perplexity4.817539691925049
INFO:root:current mean train loss 1993.2732279728853
INFO:root:current train perplexity4.8086466789245605
INFO:root:current mean train loss 1992.661015788019
INFO:root:current train perplexity4.805605888366699
INFO:root:current mean train loss 1992.5012433087384
INFO:root:current train perplexity4.808154582977295
INFO:root:current mean train loss 1991.0606976590773
INFO:root:current train perplexity4.802457809448242
INFO:root:current mean train loss 1991.01959077406
INFO:root:current train perplexity4.800307750701904
INFO:root:current mean train loss 1990.8941468886662
INFO:root:current train perplexity4.801899433135986
INFO:root:current mean train loss 1989.3465962169232
INFO:root:current train perplexity4.799426078796387
INFO:root:current mean train loss 1989.9365837277194
INFO:root:current train perplexity4.801602840423584
INFO:root:current mean train loss 1988.5794734682152
INFO:root:current train perplexity4.798706531524658
INFO:root:current mean train loss 1989.8072369670936
INFO:root:current train perplexity4.802825927734375
INFO:root:current mean train loss 1989.711833746781
INFO:root:current train perplexity4.800197601318359
INFO:root:current mean train loss 1989.7372047232293
INFO:root:current train perplexity4.797441005706787
INFO:root:current mean train loss 1988.1231957739526
INFO:root:current train perplexity4.791369915008545
INFO:root:current mean train loss 1986.204694094066
INFO:root:current train perplexity4.7868123054504395
INFO:root:current mean train loss 1985.4413322104635
INFO:root:current train perplexity4.784552574157715

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.73s/it]
INFO:root:final mean train loss: 1984.5713050676848
INFO:root:final train perplexity: 4.7834038734436035
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.20s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.20s/it]
INFO:root:eval mean loss: 1936.8038165586215
INFO:root:eval perplexity: 4.789247035980225
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.44s/it]
INFO:root:eval mean loss: 2380.8080933482934
INFO:root:eval perplexity: 7.008265495300293
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/91
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [13:18:45<1:17:26, 516.26s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1947.4856514308763
INFO:root:current train perplexity4.659859657287598
INFO:root:current mean train loss 1949.83766989512
INFO:root:current train perplexity4.6819071769714355
INFO:root:current mean train loss 1957.0202998959921
INFO:root:current train perplexity4.692817687988281
INFO:root:current mean train loss 1959.0854922608833
INFO:root:current train perplexity4.7080912590026855
INFO:root:current mean train loss 1963.726002782984
INFO:root:current train perplexity4.714254379272461
INFO:root:current mean train loss 1966.5967805184723
INFO:root:current train perplexity4.729422092437744
INFO:root:current mean train loss 1968.5519488544287
INFO:root:current train perplexity4.73077392578125
INFO:root:current mean train loss 1970.5096501000125
INFO:root:current train perplexity4.732757091522217
INFO:root:current mean train loss 1968.0775095982472
INFO:root:current train perplexity4.728621482849121
INFO:root:current mean train loss 1967.7963878800954
INFO:root:current train perplexity4.728723526000977
INFO:root:current mean train loss 1970.82696988341
INFO:root:current train perplexity4.731939315795898
INFO:root:current mean train loss 1968.6090688655513
INFO:root:current train perplexity4.726874351501465
INFO:root:current mean train loss 1970.0997448671687
INFO:root:current train perplexity4.7297749519348145
INFO:root:current mean train loss 1970.7003414159722
INFO:root:current train perplexity4.730254173278809
INFO:root:current mean train loss 1971.8267222888571
INFO:root:current train perplexity4.731695175170898
INFO:root:current mean train loss 1970.7175918322484
INFO:root:current train perplexity4.728582382202148
INFO:root:current mean train loss 1971.0967290050928
INFO:root:current train perplexity4.7302117347717285
INFO:root:current mean train loss 1969.8182882022747
INFO:root:current train perplexity4.726993083953857
INFO:root:current mean train loss 1968.9231586559622
INFO:root:current train perplexity4.724466323852539
INFO:root:current mean train loss 1969.215181231131
INFO:root:current train perplexity4.724914073944092

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.04s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:26<00:00, 446.04s/it]
INFO:root:final mean train loss: 1968.947410872051
INFO:root:final train perplexity: 4.724823951721191
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.94s/it]
INFO:root:eval mean loss: 1931.1486019919105
INFO:root:eval perplexity: 4.767392635345459
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.26s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.26s/it]
INFO:root:eval mean loss: 2374.5489320146276
INFO:root:eval perplexity: 6.972483158111572
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/92
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [13:27:14<1:08:33, 514.21s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1940.7023208860367
INFO:root:current train perplexity4.667882919311523
INFO:root:current mean train loss 1951.4938732685487
INFO:root:current train perplexity4.706515789031982
INFO:root:current mean train loss 1960.444939791023
INFO:root:current train perplexity4.717940330505371
INFO:root:current mean train loss 1960.4623895650395
INFO:root:current train perplexity4.7120208740234375
INFO:root:current mean train loss 1961.4609828479347
INFO:root:current train perplexity4.710066795349121
INFO:root:current mean train loss 1958.8215982494728
INFO:root:current train perplexity4.702391147613525
INFO:root:current mean train loss 1962.6872127757354
INFO:root:current train perplexity4.714653491973877
INFO:root:current mean train loss 1964.8123937684306
INFO:root:current train perplexity4.717146396636963
INFO:root:current mean train loss 1966.4759800138506
INFO:root:current train perplexity4.719516754150391
INFO:root:current mean train loss 1966.5915674385872
INFO:root:current train perplexity4.716570854187012
INFO:root:current mean train loss 1970.1260300759202
INFO:root:current train perplexity4.724076271057129
INFO:root:current mean train loss 1971.4961743604902
INFO:root:current train perplexity4.728607654571533
INFO:root:current mean train loss 1972.9958370447348
INFO:root:current train perplexity4.734301567077637
INFO:root:current mean train loss 1973.4845232218395
INFO:root:current train perplexity4.734580993652344
INFO:root:current mean train loss 1972.7392384548018
INFO:root:current train perplexity4.7351298332214355
INFO:root:current mean train loss 1973.429667428298
INFO:root:current train perplexity4.736446857452393
INFO:root:current mean train loss 1973.4596800950371
INFO:root:current train perplexity4.7403364181518555
INFO:root:current mean train loss 1973.9303823937357
INFO:root:current train perplexity4.741936683654785
INFO:root:current mean train loss 1975.8114023500402
INFO:root:current train perplexity4.748118877410889
INFO:root:current mean train loss 1976.0901513199265
INFO:root:current train perplexity4.74880838394165

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.21s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.21s/it]
INFO:root:final mean train loss: 1975.6319917418173
INFO:root:final train perplexity: 4.749798774719238
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.13s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.13s/it]
INFO:root:eval mean loss: 1946.8120558718417
INFO:root:eval perplexity: 4.828168869018555
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.82s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.82s/it]
INFO:root:eval mean loss: 2389.6966968292886
INFO:root:eval perplexity: 7.059396266937256
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/93
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [13:35:42<59:47, 512.45s/it]  
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1974.0332962036132
INFO:root:current train perplexity4.75051212310791
INFO:root:current mean train loss 1999.7203470865886
INFO:root:current train perplexity4.817383289337158
INFO:root:current mean train loss 1996.1761971609933
INFO:root:current train perplexity4.809914588928223
INFO:root:current mean train loss 1994.5742290296052
INFO:root:current train perplexity4.800564289093018
INFO:root:current mean train loss 1989.816988627116
INFO:root:current train perplexity4.79648494720459
INFO:root:current mean train loss 1990.7529534701644
INFO:root:current train perplexity4.802224159240723
INFO:root:current mean train loss 1992.6711231904872
INFO:root:current train perplexity4.8071184158325195
INFO:root:current mean train loss 1991.7778888408955
INFO:root:current train perplexity4.802569389343262
INFO:root:current mean train loss 1989.8486276799981
INFO:root:current train perplexity4.801156044006348
INFO:root:current mean train loss 1992.0664003956074
INFO:root:current train perplexity4.806796073913574
INFO:root:current mean train loss 1990.6328773781106
INFO:root:current train perplexity4.802978515625
INFO:root:current mean train loss 1990.8718982761188
INFO:root:current train perplexity4.802658557891846
INFO:root:current mean train loss 1989.3921604156494
INFO:root:current train perplexity4.799095630645752
INFO:root:current mean train loss 1989.2446113918138
INFO:root:current train perplexity4.795813083648682
INFO:root:current mean train loss 1988.4240790289803
INFO:root:current train perplexity4.7957611083984375
INFO:root:current mean train loss 1990.072720839102
INFO:root:current train perplexity4.800588130950928
INFO:root:current mean train loss 1989.9571708315896
INFO:root:current train perplexity4.800256729125977
INFO:root:current mean train loss 1989.7784975201896
INFO:root:current train perplexity4.799756050109863
INFO:root:current mean train loss 1988.8408932949635
INFO:root:current train perplexity4.796727657318115
INFO:root:current mean train loss 1988.0313277427597
INFO:root:current train perplexity4.794497966766357

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.94s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:38<00:00, 458.94s/it]
INFO:root:final mean train loss: 1987.52647008237
INFO:root:final train perplexity: 4.794564247131348
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.97s/it]
INFO:root:eval mean loss: 1941.9747353411735
INFO:root:eval perplexity: 4.809317111968994
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.73s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.73s/it]
INFO:root:eval mean loss: 2384.7213628241357
INFO:root:eval perplexity: 7.030731201171875
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/94
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [13:44:26<51:35, 515.90s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1969.9971307184278
INFO:root:current train perplexity4.75600004196167
INFO:root:current mean train loss 1977.841651877776
INFO:root:current train perplexity4.772506237030029
INFO:root:current mean train loss 1974.4499741884995
INFO:root:current train perplexity4.7648115158081055
INFO:root:current mean train loss 1972.3453673547701
INFO:root:current train perplexity4.751448631286621
INFO:root:current mean train loss 1972.7952347876321
INFO:root:current train perplexity4.762454986572266
INFO:root:current mean train loss 1975.121941903528
INFO:root:current train perplexity4.771598815917969
INFO:root:current mean train loss 1975.4111685403964
INFO:root:current train perplexity4.769713401794434
INFO:root:current mean train loss 1980.1073852692225
INFO:root:current train perplexity4.778549671173096
INFO:root:current mean train loss 1982.8815705672555
INFO:root:current train perplexity4.783486366271973
INFO:root:current mean train loss 1981.5317594629591
INFO:root:current train perplexity4.778321743011475
INFO:root:current mean train loss 1982.0965296867878
INFO:root:current train perplexity4.776839256286621
INFO:root:current mean train loss 1983.7268223455774
INFO:root:current train perplexity4.780125141143799
INFO:root:current mean train loss 1983.5793729030636
INFO:root:current train perplexity4.7793779373168945
INFO:root:current mean train loss 1983.5820942512134
INFO:root:current train perplexity4.7760910987854
INFO:root:current mean train loss 1983.0108997291459
INFO:root:current train perplexity4.772373676300049
INFO:root:current mean train loss 1983.3789515772983
INFO:root:current train perplexity4.772488594055176
INFO:root:current mean train loss 1981.2475242097728
INFO:root:current train perplexity4.7692484855651855
INFO:root:current mean train loss 1982.0160304065805
INFO:root:current train perplexity4.772214889526367
INFO:root:current mean train loss 1982.3582515284206
INFO:root:current train perplexity4.77266263961792

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.12s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.12s/it]
INFO:root:final mean train loss: 1981.245552559303
INFO:root:final train perplexity: 4.770873069763184
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.36s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.36s/it]
INFO:root:eval mean loss: 1940.9104458423371
INFO:root:eval perplexity: 4.805179595947266
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.97s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.97s/it]
INFO:root:eval mean loss: 2384.1626898582945
INFO:root:eval perplexity: 7.027519226074219
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/95
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [13:52:59<42:54, 514.91s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 2054.0527866908483
INFO:root:current train perplexity4.927589416503906
INFO:root:current mean train loss 1981.3281464158442
INFO:root:current train perplexity4.811697483062744
INFO:root:current mean train loss 1989.4250625182535
INFO:root:current train perplexity4.7877278327941895
INFO:root:current mean train loss 1987.3471664137141
INFO:root:current train perplexity4.7918806076049805
INFO:root:current mean train loss 1987.3870743461277
INFO:root:current train perplexity4.7808942794799805
INFO:root:current mean train loss 1984.4015244064628
INFO:root:current train perplexity4.770410537719727
INFO:root:current mean train loss 1983.0855339124848
INFO:root:current train perplexity4.774057865142822
INFO:root:current mean train loss 1981.4990095891872
INFO:root:current train perplexity4.767203330993652
INFO:root:current mean train loss 1982.7614449165962
INFO:root:current train perplexity4.770331859588623
INFO:root:current mean train loss 1982.384329697757
INFO:root:current train perplexity4.769348621368408
INFO:root:current mean train loss 1981.1208801871455
INFO:root:current train perplexity4.768381595611572
INFO:root:current mean train loss 1981.4539903404468
INFO:root:current train perplexity4.764571189880371
INFO:root:current mean train loss 1979.5099666287517
INFO:root:current train perplexity4.760140895843506
INFO:root:current mean train loss 1979.7603544238132
INFO:root:current train perplexity4.761812210083008
INFO:root:current mean train loss 1981.750976994149
INFO:root:current train perplexity4.764143943786621
INFO:root:current mean train loss 1981.02252914852
INFO:root:current train perplexity4.764515399932861
INFO:root:current mean train loss 1980.5478748572066
INFO:root:current train perplexity4.7644267082214355
INFO:root:current mean train loss 1979.1726117662677
INFO:root:current train perplexity4.761729717254639
INFO:root:current mean train loss 1979.0311644027356
INFO:root:current train perplexity4.760812759399414
INFO:root:current mean train loss 1980.0136129445043
INFO:root:current train perplexity4.764324188232422

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.15s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:30<00:00, 450.15s/it]
INFO:root:final mean train loss: 1979.5609707353817
INFO:root:final train perplexity: 4.7645392417907715
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.41s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.41s/it]
INFO:root:eval mean loss: 1940.425900723072
INFO:root:eval perplexity: 4.80329704284668
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.80s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.80s/it]
INFO:root:eval mean loss: 2383.105624151568
INFO:root:eval perplexity: 7.02144718170166
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/96
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [14:01:32<34:17, 514.50s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1983.6808570123487
INFO:root:current train perplexity4.703500270843506
INFO:root:current mean train loss 1977.7316009288527
INFO:root:current train perplexity4.732029438018799
INFO:root:current mean train loss 1982.1895519438244
INFO:root:current train perplexity4.7509331703186035
INFO:root:current mean train loss 1981.3536801064483
INFO:root:current train perplexity4.753875732421875
INFO:root:current mean train loss 1980.2115753244634
INFO:root:current train perplexity4.739076137542725
INFO:root:current mean train loss 1977.311809417667
INFO:root:current train perplexity4.7429704666137695
INFO:root:current mean train loss 1981.021623856292
INFO:root:current train perplexity4.756014347076416
INFO:root:current mean train loss 1982.907361491108
INFO:root:current train perplexity4.756402015686035
INFO:root:current mean train loss 1981.9517225869151
INFO:root:current train perplexity4.754153251647949
INFO:root:current mean train loss 1980.7554130513224
INFO:root:current train perplexity4.757205486297607
INFO:root:current mean train loss 1982.0925297704746
INFO:root:current train perplexity4.761111736297607
INFO:root:current mean train loss 1981.5444584179515
INFO:root:current train perplexity4.762663841247559
INFO:root:current mean train loss 1979.952417567336
INFO:root:current train perplexity4.761148452758789
INFO:root:current mean train loss 1978.6021488226957
INFO:root:current train perplexity4.759509563446045
INFO:root:current mean train loss 1977.6899998396282
INFO:root:current train perplexity4.75540018081665
INFO:root:current mean train loss 1977.0386272407995
INFO:root:current train perplexity4.7538275718688965
INFO:root:current mean train loss 1978.0390025500794
INFO:root:current train perplexity4.755454063415527
INFO:root:current mean train loss 1979.4332394569612
INFO:root:current train perplexity4.758664608001709
INFO:root:current mean train loss 1978.6629331329361
INFO:root:current train perplexity4.7578020095825195
INFO:root:current mean train loss 1978.2342326373155
INFO:root:current train perplexity4.758514881134033

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.53s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:28<00:00, 448.53s/it]
INFO:root:final mean train loss: 1977.6297603112787
INFO:root:final train perplexity: 4.757288455963135
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.93s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.93s/it]
INFO:root:eval mean loss: 1933.6532726964206
INFO:root:eval perplexity: 4.777060508728027
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.55s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.55s/it]
INFO:root:eval mean loss: 2375.58418392966
INFO:root:eval perplexity: 6.978388786315918
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/97
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [14:10:06<25:42, 514.10s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1995.129280090332
INFO:root:current train perplexity4.763493061065674
INFO:root:current mean train loss 1990.3786241686023
INFO:root:current train perplexity4.755827903747559
INFO:root:current mean train loss 1989.17479484312
INFO:root:current train perplexity4.77822732925415
INFO:root:current mean train loss 1984.0608369673805
INFO:root:current train perplexity4.783355236053467
INFO:root:current mean train loss 1979.378139768328
INFO:root:current train perplexity4.770461559295654
INFO:root:current mean train loss 1980.3691929726706
INFO:root:current train perplexity4.765759468078613
INFO:root:current mean train loss 1976.0923441192251
INFO:root:current train perplexity4.758534908294678
INFO:root:current mean train loss 1977.1864653398645
INFO:root:current train perplexity4.762956142425537
INFO:root:current mean train loss 1979.9918889459575
INFO:root:current train perplexity4.765275478363037
INFO:root:current mean train loss 1978.1937676924692
INFO:root:current train perplexity4.756020545959473
INFO:root:current mean train loss 1976.4837599892653
INFO:root:current train perplexity4.751201629638672
INFO:root:current mean train loss 1977.8328781925427
INFO:root:current train perplexity4.7562127113342285
INFO:root:current mean train loss 1978.601496672019
INFO:root:current train perplexity4.756530284881592
INFO:root:current mean train loss 1978.4385333414955
INFO:root:current train perplexity4.753265380859375
INFO:root:current mean train loss 1976.635330284498
INFO:root:current train perplexity4.75182580947876
INFO:root:current mean train loss 1975.1132237633994
INFO:root:current train perplexity4.749626636505127
INFO:root:current mean train loss 1975.0190238582277
INFO:root:current train perplexity4.75059175491333
INFO:root:current mean train loss 1975.7419948970698
INFO:root:current train perplexity4.75008487701416
INFO:root:current mean train loss 1976.1163657052177
INFO:root:current train perplexity4.750058174133301
INFO:root:current mean train loss 1976.1137311179534
INFO:root:current train perplexity4.747715473175049

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.83s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:25<00:00, 445.83s/it]
INFO:root:final mean train loss: 1974.9732561981925
INFO:root:final train perplexity: 4.747332572937012
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.96s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.96s/it]
INFO:root:eval mean loss: 1931.8368062770112
INFO:root:eval perplexity: 4.770046710968018
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.42s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.42s/it]
INFO:root:eval mean loss: 2373.8344410564882
INFO:root:eval perplexity: 6.968410015106201
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/98
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [14:18:34<17:04, 512.39s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1941.38271484375
INFO:root:current train perplexity4.667527198791504
INFO:root:current mean train loss 1966.098651308002
INFO:root:current train perplexity4.699827194213867
INFO:root:current mean train loss 1968.1881780660378
INFO:root:current train perplexity4.709792613983154
INFO:root:current mean train loss 1969.4747334519477
INFO:root:current train perplexity4.709227085113525
INFO:root:current mean train loss 1971.666384986139
INFO:root:current train perplexity4.722461223602295
INFO:root:current mean train loss 1970.4369272417728
INFO:root:current train perplexity4.734557628631592
INFO:root:current mean train loss 1971.1568151947251
INFO:root:current train perplexity4.7402777671813965
INFO:root:current mean train loss 1971.4211052389705
INFO:root:current train perplexity4.741154193878174
INFO:root:current mean train loss 1973.520003161127
INFO:root:current train perplexity4.7476067543029785
INFO:root:current mean train loss 1973.2380592464783
INFO:root:current train perplexity4.745730400085449
INFO:root:current mean train loss 1974.7316421150601
INFO:root:current train perplexity4.747163772583008
INFO:root:current mean train loss 1974.8582285868763
INFO:root:current train perplexity4.748307228088379
INFO:root:current mean train loss 1973.7129078981905
INFO:root:current train perplexity4.744688510894775
INFO:root:current mean train loss 1972.4635741293212
INFO:root:current train perplexity4.743506908416748
INFO:root:current mean train loss 1974.256309493654
INFO:root:current train perplexity4.746366024017334
INFO:root:current mean train loss 1974.0799146365814
INFO:root:current train perplexity4.747910976409912
INFO:root:current mean train loss 1975.445191382789
INFO:root:current train perplexity4.749532222747803
INFO:root:current mean train loss 1975.2617232455073
INFO:root:current train perplexity4.749362945556641
INFO:root:current mean train loss 1975.1653601106946
INFO:root:current train perplexity4.748020172119141
INFO:root:current mean train loss 1975.4223343943822
INFO:root:current train perplexity4.747269153594971

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:34<00:00, 454.49s/it]
INFO:root:final mean train loss: 1975.0115056040308
INFO:root:final train perplexity: 4.747474193572998
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:32<00:00, 32.31s/it]
INFO:root:eval mean loss: 1931.8072604997783
INFO:root:eval perplexity: 4.769933223724365
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.31s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.31s/it]
INFO:root:eval mean loss: 2373.5589504377217
INFO:root:eval perplexity: 6.966840744018555
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/99
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [14:27:14<08:34, 514.53s/it]
  0%|          | 0/1 [00:00<?, ?it/s][AINFO:root:current mean train loss 1970.3514716915968
INFO:root:current train perplexity4.766847133636475
INFO:root:current mean train loss 1969.782667222914
INFO:root:current train perplexity4.7618913650512695
INFO:root:current mean train loss 1979.8121935255983
INFO:root:current train perplexity4.768158912658691
INFO:root:current mean train loss 1980.8517337819044
INFO:root:current train perplexity4.757501125335693
INFO:root:current mean train loss 1977.504759729156
INFO:root:current train perplexity4.752964496612549
INFO:root:current mean train loss 1976.3048603280713
INFO:root:current train perplexity4.751521110534668
INFO:root:current mean train loss 1971.989832903283
INFO:root:current train perplexity4.742177963256836
INFO:root:current mean train loss 1970.7702596132713
INFO:root:current train perplexity4.738918781280518
INFO:root:current mean train loss 1974.4665084458263
INFO:root:current train perplexity4.7477240562438965
INFO:root:current mean train loss 1975.4359031413092
INFO:root:current train perplexity4.7439703941345215
INFO:root:current mean train loss 1975.2323850959594
INFO:root:current train perplexity4.745102405548096
INFO:root:current mean train loss 1974.752220605634
INFO:root:current train perplexity4.739696025848389
INFO:root:current mean train loss 1975.5111442006507
INFO:root:current train perplexity4.7410125732421875
INFO:root:current mean train loss 1975.9375602401976
INFO:root:current train perplexity4.74290132522583
INFO:root:current mean train loss 1976.6064751299448
INFO:root:current train perplexity4.746880054473877
INFO:root:current mean train loss 1976.455737937416
INFO:root:current train perplexity4.748530387878418
INFO:root:current mean train loss 1977.5946667611104
INFO:root:current train perplexity4.751410961151123
INFO:root:current mean train loss 1977.0763788876175
INFO:root:current train perplexity4.749717712402344
INFO:root:current mean train loss 1975.8100867438645
INFO:root:current train perplexity4.748822212219238
INFO:root:current mean train loss 1976.5393339863458
INFO:root:current train perplexity4.75089168548584

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.84s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:27<00:00, 447.84s/it]
INFO:root:final mean train loss: 1975.8927423320392
INFO:root:final train perplexity: 4.7507758140563965
INFO:root:epoch finished
INFO:root:start evaluating on validation

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.44s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:31<00:00, 31.44s/it]
INFO:root:eval mean loss: 1930.8946589476673
INFO:root:eval perplexity: 4.766414165496826
INFO:root:evalaution complete
INFO:root:start evaluating on test

  0%|          | 0/1 [00:00<?, ?it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.49s/it][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:30<00:00, 30.49s/it]
INFO:root:eval mean loss: 2372.7333079669493
INFO:root:eval perplexity: 6.962137699127197
INFO:root:evalaution complete
INFO:root:checkpoint. save model: multil6_minil12_not_concat_100e/100
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [14:35:44<00:00, 513.45s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [14:35:45<00:00, 525.45s/it]
INFO:root:evaluating final model
INFO:root:start evaluating on validation
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.43s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:42<00:00, 42.43s/it]
INFO:root:eval mean loss: 1930.8946589476673
INFO:root:eval perplexity: 4.766414165496826
INFO:root:evalaution complete
INFO:root:start evaluating on test
  0%|          | 0/1 [00:00<?, ?it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.57s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:37<00:00, 37.57s/it]
INFO:root:eval mean loss: 2372.7333079669493
INFO:root:eval perplexity: 6.962137699127197
INFO:root:evalaution complete
INFO:root:save model final: multil6_minil12_not_concat_100e/final
